Search.setIndex({"docnames": ["_dynamo", "amp", "autograd", "backends", "benchmark_utils", "bottleneck", "checkpoint", "community/build_ci_governance", "community/contribution_guide", "community/design", "community/governance", "community/persons_of_interest", "complex_numbers", "config_mod", "cpp_extension", "cpp_index", "cuda", "cuda._sanitizer", "cudnn_persistent_rnn", "cudnn_rnn_determinism", "data", "ddp_comm_hooks", "deploy", "distributed", "distributed.algorithms.join", "distributed.checkpoint", "distributed.elastic", "distributed.optim", "distributed.tensor.parallel", "distributions", "dlpack", "dynamo/custom-backends", "dynamo/deep-dive", "dynamo/faq", "dynamo/get-started", "dynamo/guards-overview", "dynamo/index", "dynamo/installation", "dynamo/troubleshooting", "elastic/agent", "elastic/customization", "elastic/errors", "elastic/events", "elastic/examples", "elastic/kubernetes", "elastic/metrics", "elastic/multiprocessing", "elastic/quickstart", "elastic/rendezvous", "elastic/run", "elastic/timer", "elastic/train_script", "fft", "fsdp", "func", "func.api", "func.batch_norm", "func.ux_limitations", "func.whirlwind_tour", "futures", "fx", "generated/onnx_diagnostics_rules/POE0001:node-missing-onnx-shape-inference", "generated/onnx_diagnostics_rules/POE0002:missing-custom-symbolic-function", "generated/onnx_diagnostics_rules/POE0003:missing-standard-symbolic-function", "generated/onnx_diagnostics_rules/POE0004:operator-supported-in-newer-opset-version", "generated/torch.Generator", "generated/torch.Tensor.abs", "generated/torch.Tensor.abs_", "generated/torch.Tensor.absolute", "generated/torch.Tensor.absolute_", "generated/torch.Tensor.acos", "generated/torch.Tensor.acos_", "generated/torch.Tensor.acosh", "generated/torch.Tensor.acosh_", "generated/torch.Tensor.add", "generated/torch.Tensor.add_", "generated/torch.Tensor.addbmm", "generated/torch.Tensor.addbmm_", "generated/torch.Tensor.addcdiv", "generated/torch.Tensor.addcdiv_", "generated/torch.Tensor.addcmul", "generated/torch.Tensor.addcmul_", "generated/torch.Tensor.addmm", "generated/torch.Tensor.addmm_", "generated/torch.Tensor.addmv", "generated/torch.Tensor.addmv_", "generated/torch.Tensor.addr", "generated/torch.Tensor.addr_", "generated/torch.Tensor.adjoint", "generated/torch.Tensor.all", "generated/torch.Tensor.allclose", "generated/torch.Tensor.amax", "generated/torch.Tensor.amin", "generated/torch.Tensor.aminmax", "generated/torch.Tensor.angle", "generated/torch.Tensor.any", "generated/torch.Tensor.apply_", "generated/torch.Tensor.arccos", "generated/torch.Tensor.arccos_", "generated/torch.Tensor.arccosh", "generated/torch.Tensor.arccosh_", "generated/torch.Tensor.arcsin", "generated/torch.Tensor.arcsin_", "generated/torch.Tensor.arcsinh", "generated/torch.Tensor.arcsinh_", "generated/torch.Tensor.arctan", "generated/torch.Tensor.arctan2", "generated/torch.Tensor.arctan2_", "generated/torch.Tensor.arctan_", "generated/torch.Tensor.arctanh", "generated/torch.Tensor.arctanh_", "generated/torch.Tensor.argmax", "generated/torch.Tensor.argmin", "generated/torch.Tensor.argsort", "generated/torch.Tensor.argwhere", "generated/torch.Tensor.as_strided", "generated/torch.Tensor.as_subclass", "generated/torch.Tensor.asin", "generated/torch.Tensor.asin_", "generated/torch.Tensor.asinh", "generated/torch.Tensor.asinh_", "generated/torch.Tensor.atan", "generated/torch.Tensor.atan2", "generated/torch.Tensor.atan2_", "generated/torch.Tensor.atan_", "generated/torch.Tensor.atanh", "generated/torch.Tensor.atanh_", "generated/torch.Tensor.backward", "generated/torch.Tensor.baddbmm", "generated/torch.Tensor.baddbmm_", "generated/torch.Tensor.bernoulli", "generated/torch.Tensor.bernoulli_", "generated/torch.Tensor.bfloat16", "generated/torch.Tensor.bincount", "generated/torch.Tensor.bitwise_and", "generated/torch.Tensor.bitwise_and_", "generated/torch.Tensor.bitwise_left_shift", "generated/torch.Tensor.bitwise_left_shift_", "generated/torch.Tensor.bitwise_not", "generated/torch.Tensor.bitwise_not_", "generated/torch.Tensor.bitwise_or", "generated/torch.Tensor.bitwise_or_", "generated/torch.Tensor.bitwise_right_shift", "generated/torch.Tensor.bitwise_right_shift_", "generated/torch.Tensor.bitwise_xor", "generated/torch.Tensor.bitwise_xor_", "generated/torch.Tensor.bmm", "generated/torch.Tensor.bool", "generated/torch.Tensor.broadcast_to", "generated/torch.Tensor.byte", "generated/torch.Tensor.cauchy_", "generated/torch.Tensor.ccol_indices", "generated/torch.Tensor.cdouble", "generated/torch.Tensor.ceil", "generated/torch.Tensor.ceil_", "generated/torch.Tensor.cfloat", "generated/torch.Tensor.chalf", "generated/torch.Tensor.char", "generated/torch.Tensor.cholesky", "generated/torch.Tensor.cholesky_inverse", "generated/torch.Tensor.cholesky_solve", "generated/torch.Tensor.chunk", "generated/torch.Tensor.clamp", "generated/torch.Tensor.clamp_", "generated/torch.Tensor.clip", "generated/torch.Tensor.clip_", "generated/torch.Tensor.clone", "generated/torch.Tensor.coalesce", "generated/torch.Tensor.col_indices", "generated/torch.Tensor.conj", "generated/torch.Tensor.conj_physical", "generated/torch.Tensor.conj_physical_", "generated/torch.Tensor.contiguous", "generated/torch.Tensor.copy_", "generated/torch.Tensor.copysign", "generated/torch.Tensor.copysign_", "generated/torch.Tensor.corrcoef", "generated/torch.Tensor.cos", "generated/torch.Tensor.cos_", "generated/torch.Tensor.cosh", "generated/torch.Tensor.cosh_", "generated/torch.Tensor.count_nonzero", "generated/torch.Tensor.cov", "generated/torch.Tensor.cpu", "generated/torch.Tensor.cross", "generated/torch.Tensor.crow_indices", "generated/torch.Tensor.cuda", "generated/torch.Tensor.cummax", "generated/torch.Tensor.cummin", "generated/torch.Tensor.cumprod", "generated/torch.Tensor.cumprod_", "generated/torch.Tensor.cumsum", "generated/torch.Tensor.cumsum_", "generated/torch.Tensor.data_ptr", "generated/torch.Tensor.deg2rad", "generated/torch.Tensor.dense_dim", "generated/torch.Tensor.dequantize", "generated/torch.Tensor.det", "generated/torch.Tensor.detach", "generated/torch.Tensor.detach_", "generated/torch.Tensor.device", "generated/torch.Tensor.diag", "generated/torch.Tensor.diag_embed", "generated/torch.Tensor.diagflat", "generated/torch.Tensor.diagonal", "generated/torch.Tensor.diagonal_scatter", "generated/torch.Tensor.diff", "generated/torch.Tensor.digamma", "generated/torch.Tensor.digamma_", "generated/torch.Tensor.dim", "generated/torch.Tensor.dist", "generated/torch.Tensor.div", "generated/torch.Tensor.div_", "generated/torch.Tensor.divide", "generated/torch.Tensor.divide_", "generated/torch.Tensor.dot", "generated/torch.Tensor.double", "generated/torch.Tensor.dsplit", "generated/torch.Tensor.element_size", "generated/torch.Tensor.eq", "generated/torch.Tensor.eq_", "generated/torch.Tensor.equal", "generated/torch.Tensor.erf", "generated/torch.Tensor.erf_", "generated/torch.Tensor.erfc", "generated/torch.Tensor.erfc_", "generated/torch.Tensor.erfinv", "generated/torch.Tensor.erfinv_", "generated/torch.Tensor.exp", "generated/torch.Tensor.exp_", "generated/torch.Tensor.expand", "generated/torch.Tensor.expand_as", "generated/torch.Tensor.expm1", "generated/torch.Tensor.expm1_", "generated/torch.Tensor.exponential_", "generated/torch.Tensor.fill_", "generated/torch.Tensor.fill_diagonal_", "generated/torch.Tensor.fix", "generated/torch.Tensor.fix_", "generated/torch.Tensor.flatten", "generated/torch.Tensor.flip", "generated/torch.Tensor.fliplr", "generated/torch.Tensor.flipud", "generated/torch.Tensor.float", "generated/torch.Tensor.float_power", "generated/torch.Tensor.float_power_", "generated/torch.Tensor.floor", "generated/torch.Tensor.floor_", "generated/torch.Tensor.floor_divide", "generated/torch.Tensor.floor_divide_", "generated/torch.Tensor.fmax", "generated/torch.Tensor.fmin", "generated/torch.Tensor.fmod", "generated/torch.Tensor.fmod_", "generated/torch.Tensor.frac", "generated/torch.Tensor.frac_", "generated/torch.Tensor.frexp", "generated/torch.Tensor.gather", "generated/torch.Tensor.gcd", "generated/torch.Tensor.gcd_", "generated/torch.Tensor.ge", "generated/torch.Tensor.ge_", "generated/torch.Tensor.geometric_", "generated/torch.Tensor.geqrf", "generated/torch.Tensor.ger", "generated/torch.Tensor.get_device", "generated/torch.Tensor.grad", "generated/torch.Tensor.greater", "generated/torch.Tensor.greater_", "generated/torch.Tensor.greater_equal", "generated/torch.Tensor.greater_equal_", "generated/torch.Tensor.gt", "generated/torch.Tensor.gt_", "generated/torch.Tensor.half", "generated/torch.Tensor.hardshrink", "generated/torch.Tensor.heaviside", "generated/torch.Tensor.histc", "generated/torch.Tensor.histogram", "generated/torch.Tensor.hsplit", "generated/torch.Tensor.hypot", "generated/torch.Tensor.hypot_", "generated/torch.Tensor.i0", "generated/torch.Tensor.i0_", "generated/torch.Tensor.igamma", "generated/torch.Tensor.igamma_", "generated/torch.Tensor.igammac", "generated/torch.Tensor.igammac_", "generated/torch.Tensor.imag", "generated/torch.Tensor.index_add", "generated/torch.Tensor.index_add_", "generated/torch.Tensor.index_copy", "generated/torch.Tensor.index_copy_", "generated/torch.Tensor.index_fill", "generated/torch.Tensor.index_fill_", "generated/torch.Tensor.index_put", "generated/torch.Tensor.index_put_", "generated/torch.Tensor.index_reduce", "generated/torch.Tensor.index_reduce_", "generated/torch.Tensor.index_select", "generated/torch.Tensor.indices", "generated/torch.Tensor.inner", "generated/torch.Tensor.int", "generated/torch.Tensor.int_repr", "generated/torch.Tensor.inverse", "generated/torch.Tensor.is_coalesced", "generated/torch.Tensor.is_complex", "generated/torch.Tensor.is_conj", "generated/torch.Tensor.is_contiguous", "generated/torch.Tensor.is_cuda", "generated/torch.Tensor.is_floating_point", "generated/torch.Tensor.is_inference", "generated/torch.Tensor.is_leaf", "generated/torch.Tensor.is_meta", "generated/torch.Tensor.is_pinned", "generated/torch.Tensor.is_quantized", "generated/torch.Tensor.is_set_to", "generated/torch.Tensor.is_shared", "generated/torch.Tensor.is_signed", "generated/torch.Tensor.is_sparse", "generated/torch.Tensor.is_sparse_csr", "generated/torch.Tensor.isclose", "generated/torch.Tensor.isfinite", "generated/torch.Tensor.isinf", "generated/torch.Tensor.isnan", "generated/torch.Tensor.isneginf", "generated/torch.Tensor.isposinf", "generated/torch.Tensor.isreal", "generated/torch.Tensor.istft", "generated/torch.Tensor.item", "generated/torch.Tensor.kthvalue", "generated/torch.Tensor.lcm", "generated/torch.Tensor.lcm_", "generated/torch.Tensor.ldexp", "generated/torch.Tensor.ldexp_", "generated/torch.Tensor.le", "generated/torch.Tensor.le_", "generated/torch.Tensor.lerp", "generated/torch.Tensor.lerp_", "generated/torch.Tensor.less", "generated/torch.Tensor.less_", "generated/torch.Tensor.less_equal", "generated/torch.Tensor.less_equal_", "generated/torch.Tensor.lgamma", "generated/torch.Tensor.lgamma_", "generated/torch.Tensor.log", "generated/torch.Tensor.log10", "generated/torch.Tensor.log10_", "generated/torch.Tensor.log1p", "generated/torch.Tensor.log1p_", "generated/torch.Tensor.log2", "generated/torch.Tensor.log2_", "generated/torch.Tensor.log_", "generated/torch.Tensor.log_normal_", "generated/torch.Tensor.logaddexp", "generated/torch.Tensor.logaddexp2", "generated/torch.Tensor.logcumsumexp", "generated/torch.Tensor.logdet", "generated/torch.Tensor.logical_and", "generated/torch.Tensor.logical_and_", "generated/torch.Tensor.logical_not", "generated/torch.Tensor.logical_not_", "generated/torch.Tensor.logical_or", "generated/torch.Tensor.logical_or_", "generated/torch.Tensor.logical_xor", "generated/torch.Tensor.logical_xor_", "generated/torch.Tensor.logit", "generated/torch.Tensor.logit_", "generated/torch.Tensor.logsumexp", "generated/torch.Tensor.long", "generated/torch.Tensor.lt", "generated/torch.Tensor.lt_", "generated/torch.Tensor.lu", "generated/torch.Tensor.lu_solve", "generated/torch.Tensor.map_", "generated/torch.Tensor.masked_fill", "generated/torch.Tensor.masked_fill_", "generated/torch.Tensor.masked_scatter", "generated/torch.Tensor.masked_scatter_", "generated/torch.Tensor.masked_select", "generated/torch.Tensor.matmul", "generated/torch.Tensor.matrix_exp", "generated/torch.Tensor.matrix_power", "generated/torch.Tensor.max", "generated/torch.Tensor.maximum", "generated/torch.Tensor.mean", "generated/torch.Tensor.median", "generated/torch.Tensor.min", "generated/torch.Tensor.minimum", "generated/torch.Tensor.mm", "generated/torch.Tensor.mode", "generated/torch.Tensor.moveaxis", "generated/torch.Tensor.movedim", "generated/torch.Tensor.msort", "generated/torch.Tensor.mul", "generated/torch.Tensor.mul_", "generated/torch.Tensor.multinomial", "generated/torch.Tensor.multiply", "generated/torch.Tensor.multiply_", "generated/torch.Tensor.mv", "generated/torch.Tensor.mvlgamma", "generated/torch.Tensor.mvlgamma_", "generated/torch.Tensor.nan_to_num", "generated/torch.Tensor.nan_to_num_", "generated/torch.Tensor.nanmean", "generated/torch.Tensor.nanmedian", "generated/torch.Tensor.nanquantile", "generated/torch.Tensor.nansum", "generated/torch.Tensor.narrow", "generated/torch.Tensor.narrow_copy", "generated/torch.Tensor.ndim", "generated/torch.Tensor.ndimension", "generated/torch.Tensor.ne", "generated/torch.Tensor.ne_", "generated/torch.Tensor.neg", "generated/torch.Tensor.neg_", "generated/torch.Tensor.negative", "generated/torch.Tensor.negative_", "generated/torch.Tensor.nelement", "generated/torch.Tensor.new_empty", "generated/torch.Tensor.new_full", "generated/torch.Tensor.new_ones", "generated/torch.Tensor.new_tensor", "generated/torch.Tensor.new_zeros", "generated/torch.Tensor.nextafter", "generated/torch.Tensor.nextafter_", "generated/torch.Tensor.nonzero", "generated/torch.Tensor.norm", "generated/torch.Tensor.normal_", "generated/torch.Tensor.not_equal", "generated/torch.Tensor.not_equal_", "generated/torch.Tensor.numel", "generated/torch.Tensor.numpy", "generated/torch.Tensor.orgqr", "generated/torch.Tensor.ormqr", "generated/torch.Tensor.outer", "generated/torch.Tensor.permute", "generated/torch.Tensor.pin_memory", "generated/torch.Tensor.pinverse", "generated/torch.Tensor.polygamma", "generated/torch.Tensor.polygamma_", "generated/torch.Tensor.positive", "generated/torch.Tensor.pow", "generated/torch.Tensor.pow_", "generated/torch.Tensor.prod", "generated/torch.Tensor.put_", "generated/torch.Tensor.q_per_channel_axis", "generated/torch.Tensor.q_per_channel_scales", "generated/torch.Tensor.q_per_channel_zero_points", "generated/torch.Tensor.q_scale", "generated/torch.Tensor.q_zero_point", "generated/torch.Tensor.qr", "generated/torch.Tensor.qscheme", "generated/torch.Tensor.quantile", "generated/torch.Tensor.rad2deg", "generated/torch.Tensor.random_", "generated/torch.Tensor.ravel", "generated/torch.Tensor.real", "generated/torch.Tensor.reciprocal", "generated/torch.Tensor.reciprocal_", "generated/torch.Tensor.record_stream", "generated/torch.Tensor.register_hook", "generated/torch.Tensor.remainder", "generated/torch.Tensor.remainder_", "generated/torch.Tensor.renorm", "generated/torch.Tensor.renorm_", "generated/torch.Tensor.repeat", "generated/torch.Tensor.repeat_interleave", "generated/torch.Tensor.requires_grad", "generated/torch.Tensor.requires_grad_", "generated/torch.Tensor.reshape", "generated/torch.Tensor.reshape_as", "generated/torch.Tensor.resize_", "generated/torch.Tensor.resize_as_", "generated/torch.Tensor.resolve_conj", "generated/torch.Tensor.resolve_neg", "generated/torch.Tensor.retain_grad", "generated/torch.Tensor.retains_grad", "generated/torch.Tensor.roll", "generated/torch.Tensor.rot90", "generated/torch.Tensor.round", "generated/torch.Tensor.round_", "generated/torch.Tensor.row_indices", "generated/torch.Tensor.rsqrt", "generated/torch.Tensor.rsqrt_", "generated/torch.Tensor.scatter", "generated/torch.Tensor.scatter_", "generated/torch.Tensor.scatter_add", "generated/torch.Tensor.scatter_add_", "generated/torch.Tensor.scatter_reduce", "generated/torch.Tensor.scatter_reduce_", "generated/torch.Tensor.select", "generated/torch.Tensor.select_scatter", "generated/torch.Tensor.set_", "generated/torch.Tensor.sgn", "generated/torch.Tensor.sgn_", "generated/torch.Tensor.share_memory_", "generated/torch.Tensor.short", "generated/torch.Tensor.sigmoid", "generated/torch.Tensor.sigmoid_", "generated/torch.Tensor.sign", "generated/torch.Tensor.sign_", "generated/torch.Tensor.signbit", "generated/torch.Tensor.sin", "generated/torch.Tensor.sin_", "generated/torch.Tensor.sinc", "generated/torch.Tensor.sinc_", "generated/torch.Tensor.sinh", "generated/torch.Tensor.sinh_", "generated/torch.Tensor.size", "generated/torch.Tensor.slice_scatter", "generated/torch.Tensor.slogdet", "generated/torch.Tensor.smm", "generated/torch.Tensor.softmax", "generated/torch.Tensor.sort", "generated/torch.Tensor.sparse_dim", "generated/torch.Tensor.sparse_mask", "generated/torch.Tensor.sparse_resize_", "generated/torch.Tensor.sparse_resize_and_clear_", "generated/torch.Tensor.split", "generated/torch.Tensor.sqrt", "generated/torch.Tensor.sqrt_", "generated/torch.Tensor.square", "generated/torch.Tensor.square_", "generated/torch.Tensor.squeeze", "generated/torch.Tensor.squeeze_", "generated/torch.Tensor.sspaddmm", "generated/torch.Tensor.std", "generated/torch.Tensor.stft", "generated/torch.Tensor.storage", "generated/torch.Tensor.storage_offset", "generated/torch.Tensor.storage_type", "generated/torch.Tensor.stride", "generated/torch.Tensor.sub", "generated/torch.Tensor.sub_", "generated/torch.Tensor.subtract", "generated/torch.Tensor.subtract_", "generated/torch.Tensor.sum", "generated/torch.Tensor.sum_to_size", "generated/torch.Tensor.svd", "generated/torch.Tensor.swapaxes", "generated/torch.Tensor.swapdims", "generated/torch.Tensor.symeig", "generated/torch.Tensor.t", "generated/torch.Tensor.t_", "generated/torch.Tensor.take", "generated/torch.Tensor.take_along_dim", "generated/torch.Tensor.tan", "generated/torch.Tensor.tan_", "generated/torch.Tensor.tanh", "generated/torch.Tensor.tanh_", "generated/torch.Tensor.tensor_split", "generated/torch.Tensor.tile", "generated/torch.Tensor.to", "generated/torch.Tensor.to_dense", "generated/torch.Tensor.to_mkldnn", "generated/torch.Tensor.to_sparse", "generated/torch.Tensor.to_sparse_bsc", "generated/torch.Tensor.to_sparse_bsr", "generated/torch.Tensor.to_sparse_coo", "generated/torch.Tensor.to_sparse_csc", "generated/torch.Tensor.to_sparse_csr", "generated/torch.Tensor.tolist", "generated/torch.Tensor.topk", "generated/torch.Tensor.trace", "generated/torch.Tensor.transpose", "generated/torch.Tensor.transpose_", "generated/torch.Tensor.triangular_solve", "generated/torch.Tensor.tril", "generated/torch.Tensor.tril_", "generated/torch.Tensor.triu", "generated/torch.Tensor.triu_", "generated/torch.Tensor.true_divide", "generated/torch.Tensor.true_divide_", "generated/torch.Tensor.trunc", "generated/torch.Tensor.trunc_", "generated/torch.Tensor.type", "generated/torch.Tensor.type_as", "generated/torch.Tensor.unbind", "generated/torch.Tensor.unflatten", "generated/torch.Tensor.unfold", "generated/torch.Tensor.uniform_", "generated/torch.Tensor.unique", "generated/torch.Tensor.unique_consecutive", "generated/torch.Tensor.unsqueeze", "generated/torch.Tensor.unsqueeze_", "generated/torch.Tensor.untyped_storage", "generated/torch.Tensor.values", "generated/torch.Tensor.var", "generated/torch.Tensor.vdot", "generated/torch.Tensor.view", "generated/torch.Tensor.view_as", "generated/torch.Tensor.vsplit", "generated/torch.Tensor.where", "generated/torch.Tensor.xlogy", "generated/torch.Tensor.xlogy_", "generated/torch.Tensor.zero_", "generated/torch._assert", "generated/torch.abs", "generated/torch.absolute", "generated/torch.acos", "generated/torch.acosh", "generated/torch.add", "generated/torch.addbmm", "generated/torch.addcdiv", "generated/torch.addcmul", "generated/torch.addmm", "generated/torch.addmv", "generated/torch.addr", "generated/torch.adjoint", "generated/torch.all", "generated/torch.allclose", "generated/torch.amax", "generated/torch.amin", "generated/torch.aminmax", "generated/torch.angle", "generated/torch.any", "generated/torch.ao.nn.intrinsic.BNReLU2d", "generated/torch.ao.nn.intrinsic.BNReLU3d", "generated/torch.ao.nn.intrinsic.ConvBn1d", "generated/torch.ao.nn.intrinsic.ConvBn2d", "generated/torch.ao.nn.intrinsic.ConvBn3d", "generated/torch.ao.nn.intrinsic.ConvBnReLU1d", "generated/torch.ao.nn.intrinsic.ConvBnReLU2d", "generated/torch.ao.nn.intrinsic.ConvBnReLU3d", "generated/torch.ao.nn.intrinsic.ConvReLU1d", "generated/torch.ao.nn.intrinsic.ConvReLU2d", "generated/torch.ao.nn.intrinsic.ConvReLU3d", "generated/torch.ao.nn.intrinsic.LinearReLU", "generated/torch.ao.nn.intrinsic.qat.ConvBn1d", "generated/torch.ao.nn.intrinsic.qat.ConvBn2d", "generated/torch.ao.nn.intrinsic.qat.ConvBn3d", "generated/torch.ao.nn.intrinsic.qat.ConvBnReLU1d", "generated/torch.ao.nn.intrinsic.qat.ConvBnReLU2d", "generated/torch.ao.nn.intrinsic.qat.ConvBnReLU3d", "generated/torch.ao.nn.intrinsic.qat.ConvReLU2d", "generated/torch.ao.nn.intrinsic.qat.ConvReLU3d", "generated/torch.ao.nn.intrinsic.qat.LinearReLU", "generated/torch.ao.nn.intrinsic.qat.freeze_bn_stats", "generated/torch.ao.nn.intrinsic.qat.update_bn_stats", "generated/torch.ao.nn.intrinsic.quantized.BNReLU2d", "generated/torch.ao.nn.intrinsic.quantized.BNReLU3d", "generated/torch.ao.nn.intrinsic.quantized.ConvReLU1d", "generated/torch.ao.nn.intrinsic.quantized.ConvReLU2d", "generated/torch.ao.nn.intrinsic.quantized.ConvReLU3d", "generated/torch.ao.nn.intrinsic.quantized.LinearReLU", "generated/torch.ao.nn.intrinsic.quantized.dynamic.LinearReLU", "generated/torch.ao.nn.qat.Conv2d", "generated/torch.ao.nn.qat.Conv3d", "generated/torch.ao.nn.qat.Linear", "generated/torch.ao.nn.qat.dynamic.Linear", "generated/torch.ao.nn.quantized.BatchNorm2d", "generated/torch.ao.nn.quantized.BatchNorm3d", "generated/torch.ao.nn.quantized.Conv1d", "generated/torch.ao.nn.quantized.Conv2d", "generated/torch.ao.nn.quantized.Conv3d", "generated/torch.ao.nn.quantized.ConvTranspose1d", "generated/torch.ao.nn.quantized.ConvTranspose2d", "generated/torch.ao.nn.quantized.ConvTranspose3d", "generated/torch.ao.nn.quantized.ELU", "generated/torch.ao.nn.quantized.Embedding", "generated/torch.ao.nn.quantized.EmbeddingBag", "generated/torch.ao.nn.quantized.FXFloatFunctional", "generated/torch.ao.nn.quantized.FloatFunctional", "generated/torch.ao.nn.quantized.GroupNorm", "generated/torch.ao.nn.quantized.Hardswish", "generated/torch.ao.nn.quantized.InstanceNorm1d", "generated/torch.ao.nn.quantized.InstanceNorm2d", "generated/torch.ao.nn.quantized.InstanceNorm3d", "generated/torch.ao.nn.quantized.LayerNorm", "generated/torch.ao.nn.quantized.LeakyReLU", "generated/torch.ao.nn.quantized.Linear", "generated/torch.ao.nn.quantized.QFunctional", "generated/torch.ao.nn.quantized.ReLU6", "generated/torch.ao.nn.quantized.Sigmoid", "generated/torch.ao.nn.quantized.dynamic.GRU", "generated/torch.ao.nn.quantized.dynamic.GRUCell", "generated/torch.ao.nn.quantized.dynamic.LSTM", "generated/torch.ao.nn.quantized.dynamic.LSTMCell", "generated/torch.ao.nn.quantized.dynamic.Linear", "generated/torch.ao.nn.quantized.dynamic.RNNCell", "generated/torch.ao.nn.quantized.functional.adaptive_avg_pool2d", "generated/torch.ao.nn.quantized.functional.adaptive_avg_pool3d", "generated/torch.ao.nn.quantized.functional.avg_pool2d", "generated/torch.ao.nn.quantized.functional.avg_pool3d", "generated/torch.ao.nn.quantized.functional.celu", "generated/torch.ao.nn.quantized.functional.clamp", "generated/torch.ao.nn.quantized.functional.conv1d", "generated/torch.ao.nn.quantized.functional.conv2d", "generated/torch.ao.nn.quantized.functional.conv3d", "generated/torch.ao.nn.quantized.functional.elu", "generated/torch.ao.nn.quantized.functional.hardsigmoid", "generated/torch.ao.nn.quantized.functional.hardswish", "generated/torch.ao.nn.quantized.functional.hardtanh", "generated/torch.ao.nn.quantized.functional.interpolate", "generated/torch.ao.nn.quantized.functional.leaky_relu", "generated/torch.ao.nn.quantized.functional.linear", "generated/torch.ao.nn.quantized.functional.max_pool1d", "generated/torch.ao.nn.quantized.functional.max_pool2d", "generated/torch.ao.nn.quantized.functional.threshold", "generated/torch.ao.nn.quantized.functional.upsample", "generated/torch.ao.nn.quantized.functional.upsample_bilinear", "generated/torch.ao.nn.quantized.functional.upsample_nearest", "generated/torch.ao.quantization.backend_config.BackendConfig", "generated/torch.ao.quantization.backend_config.BackendPatternConfig", "generated/torch.ao.quantization.backend_config.DTypeConfig", "generated/torch.ao.quantization.backend_config.ObservationType", "generated/torch.ao.quantization.fx.custom_config.ConvertCustomConfig", "generated/torch.ao.quantization.fx.custom_config.FuseCustomConfig", "generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig", "generated/torch.ao.quantization.fx.custom_config.StandaloneModuleConfigEntry", "generated/torch.ao.quantization.qconfig_mapping.QConfigMapping", "generated/torch.ao.quantization.qconfig_mapping.get_default_qat_qconfig_mapping", "generated/torch.ao.quantization.qconfig_mapping.get_default_qconfig_mapping", "generated/torch.arange", "generated/torch.arccos", "generated/torch.arccosh", "generated/torch.arcsin", "generated/torch.arcsinh", "generated/torch.arctan", "generated/torch.arctan2", "generated/torch.arctanh", "generated/torch.are_deterministic_algorithms_enabled", "generated/torch.argmax", "generated/torch.argmin", "generated/torch.argsort", "generated/torch.argwhere", "generated/torch.as_strided", "generated/torch.as_tensor", "generated/torch.asarray", "generated/torch.asin", "generated/torch.asinh", "generated/torch.atan", "generated/torch.atan2", "generated/torch.atanh", "generated/torch.atleast_1d", "generated/torch.atleast_2d", "generated/torch.atleast_3d", "generated/torch.autograd.Function.backward", "generated/torch.autograd.Function.forward", "generated/torch.autograd.Function.jvp", "generated/torch.autograd.backward", "generated/torch.autograd.forward_ad.dual_level", "generated/torch.autograd.forward_ad.make_dual", "generated/torch.autograd.forward_ad.unpack_dual", "generated/torch.autograd.function.FunctionCtx.mark_dirty", "generated/torch.autograd.function.FunctionCtx.mark_non_differentiable", "generated/torch.autograd.function.FunctionCtx.save_for_backward", "generated/torch.autograd.function.FunctionCtx.set_materialize_grads", "generated/torch.autograd.functional.hessian", "generated/torch.autograd.functional.hvp", "generated/torch.autograd.functional.jacobian", "generated/torch.autograd.functional.jvp", "generated/torch.autograd.functional.vhp", "generated/torch.autograd.functional.vjp", "generated/torch.autograd.grad", "generated/torch.autograd.gradcheck", "generated/torch.autograd.gradgradcheck", "generated/torch.autograd.profiler.load_nvprof", "generated/torch.autograd.profiler.profile.export_chrome_trace", "generated/torch.autograd.profiler.profile.key_averages", "generated/torch.autograd.profiler.profile.self_cpu_time_total", "generated/torch.autograd.profiler.profile.total_average", "generated/torch.autograd.set_multithreading_enabled", "generated/torch.baddbmm", "generated/torch.bartlett_window", "generated/torch.bernoulli", "generated/torch.bincount", "generated/torch.bitwise_and", "generated/torch.bitwise_left_shift", "generated/torch.bitwise_not", "generated/torch.bitwise_or", "generated/torch.bitwise_right_shift", "generated/torch.bitwise_xor", "generated/torch.blackman_window", "generated/torch.block_diag", "generated/torch.bmm", "generated/torch.broadcast_shapes", "generated/torch.broadcast_tensors", "generated/torch.broadcast_to", "generated/torch.bucketize", "generated/torch.can_cast", "generated/torch.cartesian_prod", "generated/torch.cat", "generated/torch.cdist", "generated/torch.ceil", "generated/torch.chain_matmul", "generated/torch.cholesky", "generated/torch.cholesky_inverse", "generated/torch.cholesky_solve", "generated/torch.chunk", "generated/torch.clamp", "generated/torch.clip", "generated/torch.clone", "generated/torch.column_stack", "generated/torch.combinations", "generated/torch.compile", "generated/torch.compiled_with_cxx11_abi", "generated/torch.complex", "generated/torch.concat", "generated/torch.concatenate", "generated/torch.conj", "generated/torch.conj_physical", "generated/torch.copysign", "generated/torch.corrcoef", "generated/torch.cos", "generated/torch.cosh", "generated/torch.count_nonzero", "generated/torch.cov", "generated/torch.cross", "generated/torch.cuda.CUDAGraph", "generated/torch.cuda.CUDAPluggableAllocator", "generated/torch.cuda.Event", "generated/torch.cuda.ExternalStream", "generated/torch.cuda.OutOfMemoryError", "generated/torch.cuda.Stream", "generated/torch.cuda.StreamContext", "generated/torch.cuda.caching_allocator_alloc", "generated/torch.cuda.caching_allocator_delete", "generated/torch.cuda.can_device_access_peer", "generated/torch.cuda.change_current_allocator", "generated/torch.cuda.comm.broadcast", "generated/torch.cuda.comm.broadcast_coalesced", "generated/torch.cuda.comm.gather", "generated/torch.cuda.comm.reduce_add", "generated/torch.cuda.comm.scatter", "generated/torch.cuda.current_blas_handle", "generated/torch.cuda.current_device", "generated/torch.cuda.current_stream", "generated/torch.cuda.default_stream", "generated/torch.cuda.device", "generated/torch.cuda.device_count", "generated/torch.cuda.device_of", "generated/torch.cuda.empty_cache", "generated/torch.cuda.get_allocator_backend", "generated/torch.cuda.get_arch_list", "generated/torch.cuda.get_device_capability", "generated/torch.cuda.get_device_name", "generated/torch.cuda.get_device_properties", "generated/torch.cuda.get_gencode_flags", "generated/torch.cuda.get_rng_state", "generated/torch.cuda.get_rng_state_all", "generated/torch.cuda.get_sync_debug_mode", "generated/torch.cuda.graph", "generated/torch.cuda.graph_pool_handle", "generated/torch.cuda.init", "generated/torch.cuda.initial_seed", "generated/torch.cuda.ipc_collect", "generated/torch.cuda.is_available", "generated/torch.cuda.is_current_stream_capturing", "generated/torch.cuda.is_initialized", "generated/torch.cuda.jiterator._create_jit_fn", "generated/torch.cuda.jiterator._create_multi_output_jit_fn", "generated/torch.cuda.list_gpu_processes", "generated/torch.cuda.make_graphed_callables", "generated/torch.cuda.manual_seed", "generated/torch.cuda.manual_seed_all", "generated/torch.cuda.max_memory_allocated", "generated/torch.cuda.max_memory_cached", "generated/torch.cuda.max_memory_reserved", "generated/torch.cuda.mem_get_info", "generated/torch.cuda.memory_allocated", "generated/torch.cuda.memory_cached", "generated/torch.cuda.memory_reserved", "generated/torch.cuda.memory_snapshot", "generated/torch.cuda.memory_stats", "generated/torch.cuda.memory_summary", "generated/torch.cuda.memory_usage", "generated/torch.cuda.nvtx.mark", "generated/torch.cuda.nvtx.range_pop", "generated/torch.cuda.nvtx.range_push", "generated/torch.cuda.reset_max_memory_allocated", "generated/torch.cuda.reset_max_memory_cached", "generated/torch.cuda.reset_peak_memory_stats", "generated/torch.cuda.seed", "generated/torch.cuda.seed_all", "generated/torch.cuda.set_device", "generated/torch.cuda.set_per_process_memory_fraction", "generated/torch.cuda.set_rng_state", "generated/torch.cuda.set_rng_state_all", "generated/torch.cuda.set_stream", "generated/torch.cuda.set_sync_debug_mode", "generated/torch.cuda.stream", "generated/torch.cuda.synchronize", "generated/torch.cuda.utilization", "generated/torch.cummax", "generated/torch.cummin", "generated/torch.cumprod", "generated/torch.cumsum", "generated/torch.cumulative_trapezoid", "generated/torch.deg2rad", "generated/torch.dequantize", "generated/torch.det", "generated/torch.diag", "generated/torch.diag_embed", "generated/torch.diagflat", "generated/torch.diagonal", "generated/torch.diagonal_scatter", "generated/torch.diff", "generated/torch.digamma", "generated/torch.dist", "generated/torch.div", "generated/torch.divide", "generated/torch.dot", "generated/torch.dsplit", "generated/torch.dstack", "generated/torch.einsum", "generated/torch.empty", "generated/torch.empty_like", "generated/torch.empty_strided", "generated/torch.enable_grad", "generated/torch.eq", "generated/torch.equal", "generated/torch.erf", "generated/torch.erfc", "generated/torch.erfinv", "generated/torch.exp", "generated/torch.exp2", "generated/torch.expm1", "generated/torch.eye", "generated/torch.fake_quantize_per_channel_affine", "generated/torch.fake_quantize_per_tensor_affine", "generated/torch.fft.fft", "generated/torch.fft.fft2", "generated/torch.fft.fftfreq", "generated/torch.fft.fftn", "generated/torch.fft.fftshift", "generated/torch.fft.hfft", "generated/torch.fft.hfft2", "generated/torch.fft.hfftn", "generated/torch.fft.ifft", "generated/torch.fft.ifft2", "generated/torch.fft.ifftn", "generated/torch.fft.ifftshift", "generated/torch.fft.ihfft", "generated/torch.fft.ihfft2", "generated/torch.fft.ihfftn", "generated/torch.fft.irfft", "generated/torch.fft.irfft2", "generated/torch.fft.irfftn", "generated/torch.fft.rfft", "generated/torch.fft.rfft2", "generated/torch.fft.rfftfreq", "generated/torch.fft.rfftn", "generated/torch.fix", "generated/torch.flatten", "generated/torch.flip", "generated/torch.fliplr", "generated/torch.flipud", "generated/torch.float_power", "generated/torch.floor", "generated/torch.floor_divide", "generated/torch.fmax", "generated/torch.fmin", "generated/torch.fmod", "generated/torch.frac", "generated/torch.frexp", "generated/torch.from_dlpack", "generated/torch.from_numpy", "generated/torch.frombuffer", "generated/torch.full", "generated/torch.full_like", "generated/torch.func.functional_call", "generated/torch.func.functionalize", "generated/torch.func.grad", "generated/torch.func.grad_and_value", "generated/torch.func.hessian", "generated/torch.func.jacfwd", "generated/torch.func.jacrev", "generated/torch.func.jvp", "generated/torch.func.stack_module_state", "generated/torch.func.vjp", "generated/torch.func.vmap", "generated/torch.gather", "generated/torch.gcd", "generated/torch.ge", "generated/torch.geqrf", "generated/torch.ger", "generated/torch.get_default_dtype", "generated/torch.get_deterministic_debug_mode", "generated/torch.get_float32_matmul_precision", "generated/torch.get_num_interop_threads", "generated/torch.get_num_threads", "generated/torch.get_rng_state", "generated/torch.gradient", "generated/torch.greater", "generated/torch.greater_equal", "generated/torch.gt", "generated/torch.hamming_window", "generated/torch.hann_window", "generated/torch.heaviside", "generated/torch.histc", "generated/torch.histogram", "generated/torch.histogramdd", "generated/torch.hsplit", "generated/torch.hspmm", "generated/torch.hstack", "generated/torch.hypot", "generated/torch.i0", "generated/torch.igamma", "generated/torch.igammac", "generated/torch.imag", "generated/torch.index_add", "generated/torch.index_copy", "generated/torch.index_reduce", "generated/torch.index_select", "generated/torch.inference_mode", "generated/torch.initial_seed", "generated/torch.inner", "generated/torch.inverse", "generated/torch.is_complex", "generated/torch.is_conj", "generated/torch.is_deterministic_algorithms_warn_only_enabled", "generated/torch.is_floating_point", "generated/torch.is_grad_enabled", "generated/torch.is_inference_mode_enabled", "generated/torch.is_nonzero", "generated/torch.is_storage", "generated/torch.is_tensor", "generated/torch.is_warn_always_enabled", "generated/torch.isclose", "generated/torch.isfinite", "generated/torch.isin", "generated/torch.isinf", "generated/torch.isnan", "generated/torch.isneginf", "generated/torch.isposinf", "generated/torch.isreal", "generated/torch.istft", "generated/torch.jit.Attribute", "generated/torch.jit.ScriptFunction", "generated/torch.jit.ScriptModule", "generated/torch.jit.annotate", "generated/torch.jit.enable_onednn_fusion", "generated/torch.jit.fork", "generated/torch.jit.freeze", "generated/torch.jit.ignore", "generated/torch.jit.isinstance", "generated/torch.jit.load", "generated/torch.jit.onednn_fusion_enabled", "generated/torch.jit.optimize_for_inference", "generated/torch.jit.save", "generated/torch.jit.script", "generated/torch.jit.script_if_tracing", "generated/torch.jit.set_fusion_strategy", "generated/torch.jit.strict_fusion", "generated/torch.jit.trace", "generated/torch.jit.trace_module", "generated/torch.jit.unused", "generated/torch.jit.wait", "generated/torch.kaiser_window", "generated/torch.kron", "generated/torch.kthvalue", "generated/torch.lcm", "generated/torch.ldexp", "generated/torch.le", "generated/torch.lerp", "generated/torch.less", "generated/torch.less_equal", "generated/torch.lgamma", "generated/torch.linalg.cholesky", "generated/torch.linalg.cholesky_ex", "generated/torch.linalg.cond", "generated/torch.linalg.cross", "generated/torch.linalg.det", "generated/torch.linalg.diagonal", "generated/torch.linalg.eig", "generated/torch.linalg.eigh", "generated/torch.linalg.eigvals", "generated/torch.linalg.eigvalsh", "generated/torch.linalg.householder_product", "generated/torch.linalg.inv", "generated/torch.linalg.inv_ex", "generated/torch.linalg.ldl_factor", "generated/torch.linalg.ldl_factor_ex", "generated/torch.linalg.ldl_solve", "generated/torch.linalg.lstsq", "generated/torch.linalg.lu", "generated/torch.linalg.lu_factor", "generated/torch.linalg.lu_factor_ex", "generated/torch.linalg.lu_solve", "generated/torch.linalg.matmul", "generated/torch.linalg.matrix_exp", "generated/torch.linalg.matrix_norm", "generated/torch.linalg.matrix_power", "generated/torch.linalg.matrix_rank", "generated/torch.linalg.multi_dot", "generated/torch.linalg.norm", "generated/torch.linalg.pinv", "generated/torch.linalg.qr", "generated/torch.linalg.slogdet", "generated/torch.linalg.solve", "generated/torch.linalg.solve_ex", "generated/torch.linalg.solve_triangular", "generated/torch.linalg.svd", "generated/torch.linalg.svdvals", "generated/torch.linalg.tensorinv", "generated/torch.linalg.tensorsolve", "generated/torch.linalg.vander", "generated/torch.linalg.vecdot", "generated/torch.linalg.vector_norm", "generated/torch.linspace", "generated/torch.load", "generated/torch.lobpcg", "generated/torch.log", "generated/torch.log10", "generated/torch.log1p", "generated/torch.log2", "generated/torch.logaddexp", "generated/torch.logaddexp2", "generated/torch.logcumsumexp", "generated/torch.logdet", "generated/torch.logical_and", "generated/torch.logical_not", "generated/torch.logical_or", "generated/torch.logical_xor", "generated/torch.logit", "generated/torch.logspace", "generated/torch.logsumexp", "generated/torch.lt", "generated/torch.lu", "generated/torch.lu_solve", "generated/torch.lu_unpack", "generated/torch.manual_seed", "generated/torch.masked_select", "generated/torch.matmul", "generated/torch.matrix_exp", "generated/torch.matrix_power", "generated/torch.max", "generated/torch.maximum", "generated/torch.mean", "generated/torch.median", "generated/torch.meshgrid", "generated/torch.min", "generated/torch.minimum", "generated/torch.mm", "generated/torch.mode", "generated/torch.moveaxis", "generated/torch.movedim", "generated/torch.msort", "generated/torch.mul", "generated/torch.multinomial", "generated/torch.multiply", "generated/torch.mv", "generated/torch.mvlgamma", "generated/torch.nan_to_num", "generated/torch.nanmean", "generated/torch.nanmedian", "generated/torch.nanquantile", "generated/torch.nansum", "generated/torch.narrow", "generated/torch.narrow_copy", "generated/torch.ne", "generated/torch.neg", "generated/torch.negative", "generated/torch.nextafter", "generated/torch.nn.AdaptiveAvgPool1d", "generated/torch.nn.AdaptiveAvgPool2d", "generated/torch.nn.AdaptiveAvgPool3d", "generated/torch.nn.AdaptiveLogSoftmaxWithLoss", "generated/torch.nn.AdaptiveMaxPool1d", "generated/torch.nn.AdaptiveMaxPool2d", "generated/torch.nn.AdaptiveMaxPool3d", "generated/torch.nn.AlphaDropout", "generated/torch.nn.AvgPool1d", "generated/torch.nn.AvgPool2d", "generated/torch.nn.AvgPool3d", "generated/torch.nn.BCELoss", "generated/torch.nn.BCEWithLogitsLoss", "generated/torch.nn.BatchNorm1d", "generated/torch.nn.BatchNorm2d", "generated/torch.nn.BatchNorm3d", "generated/torch.nn.Bilinear", "generated/torch.nn.CELU", "generated/torch.nn.CTCLoss", "generated/torch.nn.ChannelShuffle", "generated/torch.nn.ConstantPad1d", "generated/torch.nn.ConstantPad2d", "generated/torch.nn.ConstantPad3d", "generated/torch.nn.Conv1d", "generated/torch.nn.Conv2d", "generated/torch.nn.Conv3d", "generated/torch.nn.ConvTranspose1d", "generated/torch.nn.ConvTranspose2d", "generated/torch.nn.ConvTranspose3d", "generated/torch.nn.CosineEmbeddingLoss", "generated/torch.nn.CosineSimilarity", "generated/torch.nn.CrossEntropyLoss", "generated/torch.nn.DataParallel", "generated/torch.nn.Dropout", "generated/torch.nn.Dropout1d", "generated/torch.nn.Dropout2d", "generated/torch.nn.Dropout3d", "generated/torch.nn.ELU", "generated/torch.nn.Embedding", "generated/torch.nn.EmbeddingBag", "generated/torch.nn.FeatureAlphaDropout", "generated/torch.nn.Flatten", "generated/torch.nn.Fold", "generated/torch.nn.FractionalMaxPool2d", "generated/torch.nn.FractionalMaxPool3d", "generated/torch.nn.GELU", "generated/torch.nn.GLU", "generated/torch.nn.GRU", "generated/torch.nn.GRUCell", "generated/torch.nn.GaussianNLLLoss", "generated/torch.nn.GroupNorm", "generated/torch.nn.Hardshrink", "generated/torch.nn.Hardsigmoid", "generated/torch.nn.Hardswish", "generated/torch.nn.Hardtanh", "generated/torch.nn.HingeEmbeddingLoss", "generated/torch.nn.HuberLoss", "generated/torch.nn.Identity", "generated/torch.nn.InstanceNorm1d", "generated/torch.nn.InstanceNorm2d", "generated/torch.nn.InstanceNorm3d", "generated/torch.nn.KLDivLoss", "generated/torch.nn.L1Loss", "generated/torch.nn.LPPool1d", "generated/torch.nn.LPPool2d", "generated/torch.nn.LSTM", "generated/torch.nn.LSTMCell", "generated/torch.nn.LayerNorm", "generated/torch.nn.LazyBatchNorm1d", "generated/torch.nn.LazyBatchNorm2d", "generated/torch.nn.LazyBatchNorm3d", "generated/torch.nn.LazyConv1d", "generated/torch.nn.LazyConv2d", "generated/torch.nn.LazyConv3d", "generated/torch.nn.LazyConvTranspose1d", "generated/torch.nn.LazyConvTranspose2d", "generated/torch.nn.LazyConvTranspose3d", "generated/torch.nn.LazyInstanceNorm1d", "generated/torch.nn.LazyInstanceNorm2d", "generated/torch.nn.LazyInstanceNorm3d", "generated/torch.nn.LazyLinear", "generated/torch.nn.LeakyReLU", "generated/torch.nn.Linear", "generated/torch.nn.LocalResponseNorm", "generated/torch.nn.LogSigmoid", "generated/torch.nn.LogSoftmax", "generated/torch.nn.MSELoss", "generated/torch.nn.MarginRankingLoss", "generated/torch.nn.MaxPool1d", "generated/torch.nn.MaxPool2d", "generated/torch.nn.MaxPool3d", "generated/torch.nn.MaxUnpool1d", "generated/torch.nn.MaxUnpool2d", "generated/torch.nn.MaxUnpool3d", "generated/torch.nn.Mish", "generated/torch.nn.Module", "generated/torch.nn.ModuleDict", "generated/torch.nn.ModuleList", "generated/torch.nn.MultiLabelMarginLoss", "generated/torch.nn.MultiLabelSoftMarginLoss", "generated/torch.nn.MultiMarginLoss", "generated/torch.nn.MultiheadAttention", "generated/torch.nn.NLLLoss", "generated/torch.nn.PReLU", "generated/torch.nn.PairwiseDistance", "generated/torch.nn.ParameterDict", "generated/torch.nn.ParameterList", "generated/torch.nn.PixelShuffle", "generated/torch.nn.PixelUnshuffle", "generated/torch.nn.PoissonNLLLoss", "generated/torch.nn.RNN", "generated/torch.nn.RNNBase", "generated/torch.nn.RNNCell", "generated/torch.nn.RReLU", "generated/torch.nn.ReLU", "generated/torch.nn.ReLU6", "generated/torch.nn.ReflectionPad1d", "generated/torch.nn.ReflectionPad2d", "generated/torch.nn.ReflectionPad3d", "generated/torch.nn.ReplicationPad1d", "generated/torch.nn.ReplicationPad2d", "generated/torch.nn.ReplicationPad3d", "generated/torch.nn.SELU", "generated/torch.nn.Sequential", "generated/torch.nn.SiLU", "generated/torch.nn.Sigmoid", "generated/torch.nn.SmoothL1Loss", "generated/torch.nn.SoftMarginLoss", "generated/torch.nn.Softmax", "generated/torch.nn.Softmax2d", "generated/torch.nn.Softmin", "generated/torch.nn.Softplus", "generated/torch.nn.Softshrink", "generated/torch.nn.Softsign", "generated/torch.nn.SyncBatchNorm", "generated/torch.nn.Tanh", "generated/torch.nn.Tanhshrink", "generated/torch.nn.Threshold", "generated/torch.nn.Transformer", "generated/torch.nn.TransformerDecoder", "generated/torch.nn.TransformerDecoderLayer", "generated/torch.nn.TransformerEncoder", "generated/torch.nn.TransformerEncoderLayer", "generated/torch.nn.TripletMarginLoss", "generated/torch.nn.TripletMarginWithDistanceLoss", "generated/torch.nn.Unflatten", "generated/torch.nn.Unfold", "generated/torch.nn.Upsample", "generated/torch.nn.UpsamplingBilinear2d", "generated/torch.nn.UpsamplingNearest2d", "generated/torch.nn.ZeroPad2d", "generated/torch.nn.functional.adaptive_avg_pool1d", "generated/torch.nn.functional.adaptive_avg_pool2d", "generated/torch.nn.functional.adaptive_avg_pool3d", "generated/torch.nn.functional.adaptive_max_pool1d", "generated/torch.nn.functional.adaptive_max_pool2d", "generated/torch.nn.functional.adaptive_max_pool3d", "generated/torch.nn.functional.affine_grid", "generated/torch.nn.functional.alpha_dropout", "generated/torch.nn.functional.avg_pool1d", "generated/torch.nn.functional.avg_pool2d", "generated/torch.nn.functional.avg_pool3d", "generated/torch.nn.functional.batch_norm", "generated/torch.nn.functional.bilinear", "generated/torch.nn.functional.binary_cross_entropy", "generated/torch.nn.functional.binary_cross_entropy_with_logits", "generated/torch.nn.functional.celu", "generated/torch.nn.functional.conv1d", "generated/torch.nn.functional.conv2d", "generated/torch.nn.functional.conv3d", "generated/torch.nn.functional.conv_transpose1d", "generated/torch.nn.functional.conv_transpose2d", "generated/torch.nn.functional.conv_transpose3d", "generated/torch.nn.functional.cosine_embedding_loss", "generated/torch.nn.functional.cosine_similarity", "generated/torch.nn.functional.cross_entropy", "generated/torch.nn.functional.ctc_loss", "generated/torch.nn.functional.dropout", "generated/torch.nn.functional.dropout1d", "generated/torch.nn.functional.dropout2d", "generated/torch.nn.functional.dropout3d", "generated/torch.nn.functional.elu", "generated/torch.nn.functional.elu_", "generated/torch.nn.functional.embedding", "generated/torch.nn.functional.embedding_bag", "generated/torch.nn.functional.feature_alpha_dropout", "generated/torch.nn.functional.fold", "generated/torch.nn.functional.fractional_max_pool2d", "generated/torch.nn.functional.fractional_max_pool3d", "generated/torch.nn.functional.gaussian_nll_loss", "generated/torch.nn.functional.gelu", "generated/torch.nn.functional.glu", "generated/torch.nn.functional.grid_sample", "generated/torch.nn.functional.group_norm", "generated/torch.nn.functional.gumbel_softmax", "generated/torch.nn.functional.hardshrink", "generated/torch.nn.functional.hardsigmoid", "generated/torch.nn.functional.hardswish", "generated/torch.nn.functional.hardtanh", "generated/torch.nn.functional.hardtanh_", "generated/torch.nn.functional.hinge_embedding_loss", "generated/torch.nn.functional.huber_loss", "generated/torch.nn.functional.instance_norm", "generated/torch.nn.functional.interpolate", "generated/torch.nn.functional.kl_div", "generated/torch.nn.functional.l1_loss", "generated/torch.nn.functional.layer_norm", "generated/torch.nn.functional.leaky_relu", "generated/torch.nn.functional.leaky_relu_", "generated/torch.nn.functional.linear", "generated/torch.nn.functional.local_response_norm", "generated/torch.nn.functional.log_softmax", "generated/torch.nn.functional.logsigmoid", "generated/torch.nn.functional.lp_pool1d", "generated/torch.nn.functional.lp_pool2d", "generated/torch.nn.functional.margin_ranking_loss", "generated/torch.nn.functional.max_pool1d", "generated/torch.nn.functional.max_pool2d", "generated/torch.nn.functional.max_pool3d", "generated/torch.nn.functional.max_unpool1d", "generated/torch.nn.functional.max_unpool2d", "generated/torch.nn.functional.max_unpool3d", "generated/torch.nn.functional.mish", "generated/torch.nn.functional.mse_loss", "generated/torch.nn.functional.multi_margin_loss", "generated/torch.nn.functional.multilabel_margin_loss", "generated/torch.nn.functional.multilabel_soft_margin_loss", "generated/torch.nn.functional.nll_loss", "generated/torch.nn.functional.normalize", "generated/torch.nn.functional.one_hot", "generated/torch.nn.functional.pad", "generated/torch.nn.functional.pairwise_distance", "generated/torch.nn.functional.pdist", "generated/torch.nn.functional.pixel_shuffle", "generated/torch.nn.functional.pixel_unshuffle", "generated/torch.nn.functional.poisson_nll_loss", "generated/torch.nn.functional.prelu", "generated/torch.nn.functional.relu", "generated/torch.nn.functional.relu6", "generated/torch.nn.functional.relu_", "generated/torch.nn.functional.rrelu", "generated/torch.nn.functional.rrelu_", "generated/torch.nn.functional.selu", "generated/torch.nn.functional.sigmoid", "generated/torch.nn.functional.silu", "generated/torch.nn.functional.smooth_l1_loss", "generated/torch.nn.functional.soft_margin_loss", "generated/torch.nn.functional.softmax", "generated/torch.nn.functional.softmin", "generated/torch.nn.functional.softplus", "generated/torch.nn.functional.softshrink", "generated/torch.nn.functional.softsign", "generated/torch.nn.functional.tanh", "generated/torch.nn.functional.tanhshrink", "generated/torch.nn.functional.threshold", "generated/torch.nn.functional.threshold_", "generated/torch.nn.functional.torch.nn.parallel.data_parallel", "generated/torch.nn.functional.triplet_margin_loss", "generated/torch.nn.functional.triplet_margin_with_distance_loss", "generated/torch.nn.functional.unfold", "generated/torch.nn.functional.upsample", "generated/torch.nn.functional.upsample_bilinear", "generated/torch.nn.functional.upsample_nearest", "generated/torch.nn.modules.lazy.LazyModuleMixin", "generated/torch.nn.modules.module.register_module_backward_hook", "generated/torch.nn.modules.module.register_module_forward_hook", "generated/torch.nn.modules.module.register_module_forward_pre_hook", "generated/torch.nn.modules.module.register_module_full_backward_hook", "generated/torch.nn.parallel.DistributedDataParallel", "generated/torch.nn.parameter.Parameter", "generated/torch.nn.parameter.UninitializedBuffer", "generated/torch.nn.parameter.UninitializedParameter", "generated/torch.nn.quantizable.LSTM", "generated/torch.nn.quantizable.MultiheadAttention", "generated/torch.nn.utils.clip_grad_norm_", "generated/torch.nn.utils.clip_grad_value_", "generated/torch.nn.utils.parameters_to_vector", "generated/torch.nn.utils.parametrizations.orthogonal", "generated/torch.nn.utils.parametrizations.spectral_norm", "generated/torch.nn.utils.parametrize.ParametrizationList", "generated/torch.nn.utils.parametrize.cached", "generated/torch.nn.utils.parametrize.is_parametrized", "generated/torch.nn.utils.parametrize.register_parametrization", "generated/torch.nn.utils.parametrize.remove_parametrizations", "generated/torch.nn.utils.prune.BasePruningMethod", "generated/torch.nn.utils.prune.CustomFromMask", "generated/torch.nn.utils.prune.Identity", "generated/torch.nn.utils.prune.L1Unstructured", "generated/torch.nn.utils.prune.LnStructured", "generated/torch.nn.utils.prune.PruningContainer", "generated/torch.nn.utils.prune.RandomStructured", "generated/torch.nn.utils.prune.RandomUnstructured", "generated/torch.nn.utils.prune.custom_from_mask", "generated/torch.nn.utils.prune.global_unstructured", "generated/torch.nn.utils.prune.identity", "generated/torch.nn.utils.prune.is_pruned", "generated/torch.nn.utils.prune.l1_unstructured", "generated/torch.nn.utils.prune.ln_structured", "generated/torch.nn.utils.prune.random_structured", "generated/torch.nn.utils.prune.random_unstructured", "generated/torch.nn.utils.prune.remove", "generated/torch.nn.utils.remove_spectral_norm", "generated/torch.nn.utils.remove_weight_norm", "generated/torch.nn.utils.rnn.PackedSequence", "generated/torch.nn.utils.rnn.pack_padded_sequence", "generated/torch.nn.utils.rnn.pack_sequence", "generated/torch.nn.utils.rnn.pad_packed_sequence", "generated/torch.nn.utils.rnn.pad_sequence", "generated/torch.nn.utils.skip_init", "generated/torch.nn.utils.spectral_norm", "generated/torch.nn.utils.stateless.functional_call", "generated/torch.nn.utils.vector_to_parameters", "generated/torch.nn.utils.weight_norm", "generated/torch.no_grad", "generated/torch.nonzero", "generated/torch.norm", "generated/torch.normal", "generated/torch.not_equal", "generated/torch.numel", "generated/torch.ones", "generated/torch.ones_like", "generated/torch.onnx.JitScalarType", "generated/torch.optim.ASGD", "generated/torch.optim.Adadelta", "generated/torch.optim.Adagrad", "generated/torch.optim.Adam", "generated/torch.optim.AdamW", "generated/torch.optim.Adamax", "generated/torch.optim.LBFGS", "generated/torch.optim.NAdam", "generated/torch.optim.Optimizer.add_param_group", "generated/torch.optim.Optimizer.load_state_dict", "generated/torch.optim.Optimizer.state_dict", "generated/torch.optim.Optimizer.step", "generated/torch.optim.Optimizer.zero_grad", "generated/torch.optim.RAdam", "generated/torch.optim.RMSprop", "generated/torch.optim.Rprop", "generated/torch.optim.SGD", "generated/torch.optim.SparseAdam", "generated/torch.optim.lr_scheduler.ChainedScheduler", "generated/torch.optim.lr_scheduler.ConstantLR", "generated/torch.optim.lr_scheduler.CosineAnnealingLR", "generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts", "generated/torch.optim.lr_scheduler.CyclicLR", "generated/torch.optim.lr_scheduler.ExponentialLR", "generated/torch.optim.lr_scheduler.LambdaLR", "generated/torch.optim.lr_scheduler.LinearLR", "generated/torch.optim.lr_scheduler.MultiStepLR", "generated/torch.optim.lr_scheduler.MultiplicativeLR", "generated/torch.optim.lr_scheduler.OneCycleLR", "generated/torch.optim.lr_scheduler.PolynomialLR", "generated/torch.optim.lr_scheduler.ReduceLROnPlateau", "generated/torch.optim.lr_scheduler.SequentialLR", "generated/torch.optim.lr_scheduler.StepLR", "generated/torch.orgqr", "generated/torch.ormqr", "generated/torch.outer", "generated/torch.pca_lowrank", "generated/torch.permute", "generated/torch.pinverse", "generated/torch.poisson", "generated/torch.polar", "generated/torch.polygamma", "generated/torch.positive", "generated/torch.pow", "generated/torch.prod", "generated/torch.promote_types", "generated/torch.qr", "generated/torch.quantile", "generated/torch.quantization.DeQuantStub", "generated/torch.quantization.QuantStub", "generated/torch.quantization.QuantWrapper", "generated/torch.quantization.add_quant_dequant", "generated/torch.quantization.convert", "generated/torch.quantization.default_eval_fn", "generated/torch.quantization.fake_quantize.FakeQuantize", "generated/torch.quantization.fake_quantize.FakeQuantizeBase", "generated/torch.quantization.fake_quantize.FixedQParamsFakeQuantize", "generated/torch.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize", "generated/torch.quantization.fake_quantize.default_fake_quant", "generated/torch.quantization.fake_quantize.default_fused_act_fake_quant", "generated/torch.quantization.fake_quantize.default_fused_per_channel_wt_fake_quant", "generated/torch.quantization.fake_quantize.default_fused_wt_fake_quant", "generated/torch.quantization.fake_quantize.default_histogram_fake_quant", "generated/torch.quantization.fake_quantize.default_per_channel_weight_fake_quant", "generated/torch.quantization.fake_quantize.default_weight_fake_quant", "generated/torch.quantization.fake_quantize.disable_fake_quant", "generated/torch.quantization.fake_quantize.disable_observer", "generated/torch.quantization.fake_quantize.enable_fake_quant", "generated/torch.quantization.fake_quantize.enable_observer", "generated/torch.quantization.fuse_modules", "generated/torch.quantization.observer.HistogramObserver", "generated/torch.quantization.observer.MinMaxObserver", "generated/torch.quantization.observer.MovingAverageMinMaxObserver", "generated/torch.quantization.observer.MovingAveragePerChannelMinMaxObserver", "generated/torch.quantization.observer.NoopObserver", "generated/torch.quantization.observer.ObserverBase", "generated/torch.quantization.observer.PerChannelMinMaxObserver", "generated/torch.quantization.observer.PlaceholderObserver", "generated/torch.quantization.observer.RecordingObserver", "generated/torch.quantization.observer.default_debug_observer", "generated/torch.quantization.observer.default_dynamic_quant_observer", "generated/torch.quantization.observer.default_float_qparams_observer", "generated/torch.quantization.observer.default_histogram_observer", "generated/torch.quantization.observer.default_observer", "generated/torch.quantization.observer.default_per_channel_weight_observer", "generated/torch.quantization.observer.default_placeholder_observer", "generated/torch.quantization.observer.default_weight_observer", "generated/torch.quantization.observer.get_observer_state_dict", "generated/torch.quantization.observer.load_observer_state_dict", "generated/torch.quantization.prepare", "generated/torch.quantization.prepare_qat", "generated/torch.quantization.propagate_qconfig_", "generated/torch.quantization.qconfig.QConfig", "generated/torch.quantization.qconfig.default_activation_only_qconfig", "generated/torch.quantization.qconfig.default_debug_qconfig", "generated/torch.quantization.qconfig.default_dynamic_qconfig", "generated/torch.quantization.qconfig.default_per_channel_qconfig", "generated/torch.quantization.qconfig.default_qat_qconfig", "generated/torch.quantization.qconfig.default_qat_qconfig_v2", "generated/torch.quantization.qconfig.default_qconfig", "generated/torch.quantization.qconfig.default_weight_only_qconfig", "generated/torch.quantization.qconfig.float16_dynamic_qconfig", "generated/torch.quantization.qconfig.float16_static_qconfig", "generated/torch.quantization.qconfig.float_qparams_weight_only_qconfig", "generated/torch.quantization.qconfig.per_channel_dynamic_qconfig", "generated/torch.quantization.quantize", "generated/torch.quantization.quantize_dynamic", "generated/torch.quantization.quantize_fx.convert_fx", "generated/torch.quantization.quantize_fx.fuse_fx", "generated/torch.quantization.quantize_fx.prepare_fx", "generated/torch.quantization.quantize_fx.prepare_qat_fx", "generated/torch.quantization.quantize_qat", "generated/torch.quantization.swap_module", "generated/torch.quantize_per_channel", "generated/torch.quantize_per_tensor", "generated/torch.quantized_batch_norm", "generated/torch.quantized_max_pool1d", "generated/torch.quantized_max_pool2d", "generated/torch.quasirandom.SobolEngine", "generated/torch.rad2deg", "generated/torch.rand", "generated/torch.rand_like", "generated/torch.randint", "generated/torch.randint_like", "generated/torch.randn", "generated/torch.randn_like", "generated/torch.randperm", "generated/torch.range", "generated/torch.ravel", "generated/torch.real", "generated/torch.reciprocal", "generated/torch.remainder", "generated/torch.renorm", "generated/torch.repeat_interleave", "generated/torch.reshape", "generated/torch.resolve_conj", "generated/torch.resolve_neg", "generated/torch.result_type", "generated/torch.roll", "generated/torch.rot90", "generated/torch.round", "generated/torch.row_stack", "generated/torch.rsqrt", "generated/torch.save", "generated/torch.scatter", "generated/torch.scatter_add", "generated/torch.scatter_reduce", "generated/torch.searchsorted", "generated/torch.seed", "generated/torch.select", "generated/torch.select_scatter", "generated/torch.set_default_device", "generated/torch.set_default_dtype", "generated/torch.set_default_tensor_type", "generated/torch.set_deterministic_debug_mode", "generated/torch.set_float32_matmul_precision", "generated/torch.set_flush_denormal", "generated/torch.set_grad_enabled", "generated/torch.set_num_interop_threads", "generated/torch.set_num_threads", "generated/torch.set_printoptions", "generated/torch.set_rng_state", "generated/torch.set_warn_always", "generated/torch.sgn", "generated/torch.sigmoid", "generated/torch.sign", "generated/torch.signal.windows.bartlett", "generated/torch.signal.windows.blackman", "generated/torch.signal.windows.cosine", "generated/torch.signal.windows.exponential", "generated/torch.signal.windows.gaussian", "generated/torch.signal.windows.general_cosine", "generated/torch.signal.windows.general_hamming", "generated/torch.signal.windows.hamming", "generated/torch.signal.windows.hann", "generated/torch.signal.windows.kaiser", "generated/torch.signal.windows.nuttall", "generated/torch.signbit", "generated/torch.sin", "generated/torch.sinc", "generated/torch.sinh", "generated/torch.slice_scatter", "generated/torch.slogdet", "generated/torch.smm", "generated/torch.softmax", "generated/torch.sort", "generated/torch.sparse.addmm", "generated/torch.sparse.log_softmax", "generated/torch.sparse.mm", "generated/torch.sparse.sampled_addmm", "generated/torch.sparse.softmax", "generated/torch.sparse.spdiags", "generated/torch.sparse.sum", "generated/torch.sparse_bsc_tensor", "generated/torch.sparse_bsr_tensor", "generated/torch.sparse_compressed_tensor", "generated/torch.sparse_coo_tensor", "generated/torch.sparse_csc_tensor", "generated/torch.sparse_csr_tensor", "generated/torch.split", "generated/torch.sqrt", "generated/torch.square", "generated/torch.squeeze", "generated/torch.sspaddmm", "generated/torch.stack", "generated/torch.std", "generated/torch.std_mean", "generated/torch.stft", "generated/torch.sub", "generated/torch.subtract", "generated/torch.sum", "generated/torch.svd", "generated/torch.svd_lowrank", "generated/torch.swapaxes", "generated/torch.swapdims", "generated/torch.sym_float", "generated/torch.sym_int", "generated/torch.symeig", "generated/torch.t", "generated/torch.take", "generated/torch.take_along_dim", "generated/torch.tan", "generated/torch.tanh", "generated/torch.tensor", "generated/torch.tensor_split", "generated/torch.tensordot", "generated/torch.tile", "generated/torch.topk", "generated/torch.trace", "generated/torch.transpose", "generated/torch.trapezoid", "generated/torch.trapz", "generated/torch.triangular_solve", "generated/torch.tril", "generated/torch.tril_indices", "generated/torch.triu", "generated/torch.triu_indices", "generated/torch.true_divide", "generated/torch.trunc", "generated/torch.unbind", "generated/torch.unflatten", "generated/torch.unique", "generated/torch.unique_consecutive", "generated/torch.unsqueeze", "generated/torch.use_deterministic_algorithms", "generated/torch.vander", "generated/torch.var", "generated/torch.var_mean", "generated/torch.vdot", "generated/torch.view_as_complex", "generated/torch.view_as_real", "generated/torch.vmap", "generated/torch.vsplit", "generated/torch.vstack", "generated/torch.where", "generated/torch.xlogy", "generated/torch.zeros", "generated/torch.zeros_like", "hub", "index", "ir", "jit", "jit_builtin_functions", "jit_language_reference", "jit_language_reference_v2", "jit_python_reference", "jit_unsupported", "jit_utils", "library", "linalg", "masked", "mobile_optimizer", "model_zoo", "monitor", "multiprocessing", "name_inference", "named_tensor", "nested", "nn", "nn.functional", "nn.init", "notes/amp_examples", "notes/autograd", "notes/broadcasting", "notes/cpu_threading_torchscript_inference", "notes/cuda", "notes/ddp", "notes/extending", "notes/extending.func", "notes/faq", "notes/gradcheck", "notes/hip", "notes/large_scale_deployments", "notes/modules", "notes/mps", "notes/multiprocessing", "notes/numerical_accuracy", "notes/randomness", "notes/serialization", "notes/windows", "onnx", "onnx_diagnostics", "onnx_supported_aten_ops", "optim", "package", "pipeline", "profiler", "quantization", "quantization-accuracy-debugging", "quantization-backend-configuration", "quantization-support", "random", "rpc", "rpc/distributed_autograd", "rpc/rref", "signal", "sparse", "special", "storage", "tensor_attributes", "tensor_view", "tensorboard", "tensors", "testing", "torch", "torch.ao.ns._numeric_suite", "torch.ao.ns._numeric_suite_fx", "torch.overrides", "type_info"], "filenames": ["_dynamo.rst", "amp.rst", "autograd.rst", "backends.rst", "benchmark_utils.rst", "bottleneck.rst", "checkpoint.rst", "community/build_ci_governance.rst", "community/contribution_guide.rst", "community/design.rst", "community/governance.rst", "community/persons_of_interest.rst", "complex_numbers.rst", "config_mod.rst", "cpp_extension.rst", "cpp_index.rst", "cuda.rst", "cuda._sanitizer.rst", "cudnn_persistent_rnn.rst", "cudnn_rnn_determinism.rst", "data.rst", "ddp_comm_hooks.rst", "deploy.rst", "distributed.rst", "distributed.algorithms.join.rst", "distributed.checkpoint.rst", "distributed.elastic.rst", "distributed.optim.rst", "distributed.tensor.parallel.rst", "distributions.rst", "dlpack.rst", "dynamo/custom-backends.rst", "dynamo/deep-dive.rst", "dynamo/faq.rst", "dynamo/get-started.rst", "dynamo/guards-overview.rst", "dynamo/index.rst", "dynamo/installation.rst", "dynamo/troubleshooting.rst", "elastic/agent.rst", "elastic/customization.rst", "elastic/errors.rst", "elastic/events.rst", "elastic/examples.rst", "elastic/kubernetes.rst", "elastic/metrics.rst", "elastic/multiprocessing.rst", "elastic/quickstart.rst", "elastic/rendezvous.rst", "elastic/run.rst", "elastic/timer.rst", "elastic/train_script.rst", "fft.rst", "fsdp.rst", "func.rst", "func.api.rst", "func.batch_norm.rst", "func.ux_limitations.rst", "func.whirlwind_tour.rst", "futures.rst", "fx.rst", "generated/onnx_diagnostics_rules/POE0001:node-missing-onnx-shape-inference.md", "generated/onnx_diagnostics_rules/POE0002:missing-custom-symbolic-function.md", "generated/onnx_diagnostics_rules/POE0003:missing-standard-symbolic-function.md", "generated/onnx_diagnostics_rules/POE0004:operator-supported-in-newer-opset-version.md", "generated/torch.Generator.rst", "generated/torch.Tensor.abs.rst", "generated/torch.Tensor.abs_.rst", "generated/torch.Tensor.absolute.rst", "generated/torch.Tensor.absolute_.rst", "generated/torch.Tensor.acos.rst", "generated/torch.Tensor.acos_.rst", "generated/torch.Tensor.acosh.rst", "generated/torch.Tensor.acosh_.rst", "generated/torch.Tensor.add.rst", "generated/torch.Tensor.add_.rst", "generated/torch.Tensor.addbmm.rst", "generated/torch.Tensor.addbmm_.rst", "generated/torch.Tensor.addcdiv.rst", "generated/torch.Tensor.addcdiv_.rst", "generated/torch.Tensor.addcmul.rst", "generated/torch.Tensor.addcmul_.rst", "generated/torch.Tensor.addmm.rst", "generated/torch.Tensor.addmm_.rst", "generated/torch.Tensor.addmv.rst", "generated/torch.Tensor.addmv_.rst", "generated/torch.Tensor.addr.rst", "generated/torch.Tensor.addr_.rst", "generated/torch.Tensor.adjoint.rst", "generated/torch.Tensor.all.rst", "generated/torch.Tensor.allclose.rst", "generated/torch.Tensor.amax.rst", "generated/torch.Tensor.amin.rst", "generated/torch.Tensor.aminmax.rst", "generated/torch.Tensor.angle.rst", "generated/torch.Tensor.any.rst", "generated/torch.Tensor.apply_.rst", "generated/torch.Tensor.arccos.rst", "generated/torch.Tensor.arccos_.rst", "generated/torch.Tensor.arccosh.rst", "generated/torch.Tensor.arccosh_.rst", "generated/torch.Tensor.arcsin.rst", "generated/torch.Tensor.arcsin_.rst", "generated/torch.Tensor.arcsinh.rst", "generated/torch.Tensor.arcsinh_.rst", "generated/torch.Tensor.arctan.rst", "generated/torch.Tensor.arctan2.rst", "generated/torch.Tensor.arctan2_.rst", "generated/torch.Tensor.arctan_.rst", "generated/torch.Tensor.arctanh.rst", "generated/torch.Tensor.arctanh_.rst", "generated/torch.Tensor.argmax.rst", "generated/torch.Tensor.argmin.rst", "generated/torch.Tensor.argsort.rst", "generated/torch.Tensor.argwhere.rst", "generated/torch.Tensor.as_strided.rst", "generated/torch.Tensor.as_subclass.rst", "generated/torch.Tensor.asin.rst", "generated/torch.Tensor.asin_.rst", "generated/torch.Tensor.asinh.rst", "generated/torch.Tensor.asinh_.rst", "generated/torch.Tensor.atan.rst", "generated/torch.Tensor.atan2.rst", "generated/torch.Tensor.atan2_.rst", "generated/torch.Tensor.atan_.rst", "generated/torch.Tensor.atanh.rst", "generated/torch.Tensor.atanh_.rst", "generated/torch.Tensor.backward.rst", "generated/torch.Tensor.baddbmm.rst", "generated/torch.Tensor.baddbmm_.rst", "generated/torch.Tensor.bernoulli.rst", "generated/torch.Tensor.bernoulli_.rst", "generated/torch.Tensor.bfloat16.rst", "generated/torch.Tensor.bincount.rst", "generated/torch.Tensor.bitwise_and.rst", "generated/torch.Tensor.bitwise_and_.rst", "generated/torch.Tensor.bitwise_left_shift.rst", "generated/torch.Tensor.bitwise_left_shift_.rst", "generated/torch.Tensor.bitwise_not.rst", "generated/torch.Tensor.bitwise_not_.rst", "generated/torch.Tensor.bitwise_or.rst", "generated/torch.Tensor.bitwise_or_.rst", "generated/torch.Tensor.bitwise_right_shift.rst", "generated/torch.Tensor.bitwise_right_shift_.rst", "generated/torch.Tensor.bitwise_xor.rst", "generated/torch.Tensor.bitwise_xor_.rst", "generated/torch.Tensor.bmm.rst", "generated/torch.Tensor.bool.rst", "generated/torch.Tensor.broadcast_to.rst", "generated/torch.Tensor.byte.rst", "generated/torch.Tensor.cauchy_.rst", "generated/torch.Tensor.ccol_indices.rst", "generated/torch.Tensor.cdouble.rst", "generated/torch.Tensor.ceil.rst", "generated/torch.Tensor.ceil_.rst", "generated/torch.Tensor.cfloat.rst", "generated/torch.Tensor.chalf.rst", "generated/torch.Tensor.char.rst", "generated/torch.Tensor.cholesky.rst", "generated/torch.Tensor.cholesky_inverse.rst", "generated/torch.Tensor.cholesky_solve.rst", "generated/torch.Tensor.chunk.rst", "generated/torch.Tensor.clamp.rst", "generated/torch.Tensor.clamp_.rst", "generated/torch.Tensor.clip.rst", "generated/torch.Tensor.clip_.rst", "generated/torch.Tensor.clone.rst", "generated/torch.Tensor.coalesce.rst", "generated/torch.Tensor.col_indices.rst", "generated/torch.Tensor.conj.rst", "generated/torch.Tensor.conj_physical.rst", "generated/torch.Tensor.conj_physical_.rst", "generated/torch.Tensor.contiguous.rst", "generated/torch.Tensor.copy_.rst", "generated/torch.Tensor.copysign.rst", "generated/torch.Tensor.copysign_.rst", "generated/torch.Tensor.corrcoef.rst", "generated/torch.Tensor.cos.rst", "generated/torch.Tensor.cos_.rst", "generated/torch.Tensor.cosh.rst", "generated/torch.Tensor.cosh_.rst", "generated/torch.Tensor.count_nonzero.rst", "generated/torch.Tensor.cov.rst", "generated/torch.Tensor.cpu.rst", "generated/torch.Tensor.cross.rst", "generated/torch.Tensor.crow_indices.rst", "generated/torch.Tensor.cuda.rst", "generated/torch.Tensor.cummax.rst", "generated/torch.Tensor.cummin.rst", "generated/torch.Tensor.cumprod.rst", "generated/torch.Tensor.cumprod_.rst", "generated/torch.Tensor.cumsum.rst", "generated/torch.Tensor.cumsum_.rst", "generated/torch.Tensor.data_ptr.rst", "generated/torch.Tensor.deg2rad.rst", "generated/torch.Tensor.dense_dim.rst", "generated/torch.Tensor.dequantize.rst", "generated/torch.Tensor.det.rst", "generated/torch.Tensor.detach.rst", "generated/torch.Tensor.detach_.rst", "generated/torch.Tensor.device.rst", "generated/torch.Tensor.diag.rst", "generated/torch.Tensor.diag_embed.rst", "generated/torch.Tensor.diagflat.rst", "generated/torch.Tensor.diagonal.rst", "generated/torch.Tensor.diagonal_scatter.rst", "generated/torch.Tensor.diff.rst", "generated/torch.Tensor.digamma.rst", "generated/torch.Tensor.digamma_.rst", "generated/torch.Tensor.dim.rst", "generated/torch.Tensor.dist.rst", "generated/torch.Tensor.div.rst", "generated/torch.Tensor.div_.rst", "generated/torch.Tensor.divide.rst", "generated/torch.Tensor.divide_.rst", "generated/torch.Tensor.dot.rst", "generated/torch.Tensor.double.rst", "generated/torch.Tensor.dsplit.rst", "generated/torch.Tensor.element_size.rst", "generated/torch.Tensor.eq.rst", "generated/torch.Tensor.eq_.rst", "generated/torch.Tensor.equal.rst", "generated/torch.Tensor.erf.rst", "generated/torch.Tensor.erf_.rst", "generated/torch.Tensor.erfc.rst", "generated/torch.Tensor.erfc_.rst", "generated/torch.Tensor.erfinv.rst", "generated/torch.Tensor.erfinv_.rst", "generated/torch.Tensor.exp.rst", "generated/torch.Tensor.exp_.rst", "generated/torch.Tensor.expand.rst", "generated/torch.Tensor.expand_as.rst", "generated/torch.Tensor.expm1.rst", "generated/torch.Tensor.expm1_.rst", "generated/torch.Tensor.exponential_.rst", "generated/torch.Tensor.fill_.rst", "generated/torch.Tensor.fill_diagonal_.rst", "generated/torch.Tensor.fix.rst", "generated/torch.Tensor.fix_.rst", "generated/torch.Tensor.flatten.rst", "generated/torch.Tensor.flip.rst", "generated/torch.Tensor.fliplr.rst", "generated/torch.Tensor.flipud.rst", "generated/torch.Tensor.float.rst", "generated/torch.Tensor.float_power.rst", "generated/torch.Tensor.float_power_.rst", "generated/torch.Tensor.floor.rst", "generated/torch.Tensor.floor_.rst", "generated/torch.Tensor.floor_divide.rst", "generated/torch.Tensor.floor_divide_.rst", "generated/torch.Tensor.fmax.rst", "generated/torch.Tensor.fmin.rst", "generated/torch.Tensor.fmod.rst", "generated/torch.Tensor.fmod_.rst", "generated/torch.Tensor.frac.rst", "generated/torch.Tensor.frac_.rst", "generated/torch.Tensor.frexp.rst", "generated/torch.Tensor.gather.rst", "generated/torch.Tensor.gcd.rst", "generated/torch.Tensor.gcd_.rst", "generated/torch.Tensor.ge.rst", "generated/torch.Tensor.ge_.rst", "generated/torch.Tensor.geometric_.rst", "generated/torch.Tensor.geqrf.rst", "generated/torch.Tensor.ger.rst", "generated/torch.Tensor.get_device.rst", "generated/torch.Tensor.grad.rst", "generated/torch.Tensor.greater.rst", "generated/torch.Tensor.greater_.rst", "generated/torch.Tensor.greater_equal.rst", "generated/torch.Tensor.greater_equal_.rst", "generated/torch.Tensor.gt.rst", "generated/torch.Tensor.gt_.rst", "generated/torch.Tensor.half.rst", "generated/torch.Tensor.hardshrink.rst", "generated/torch.Tensor.heaviside.rst", "generated/torch.Tensor.histc.rst", "generated/torch.Tensor.histogram.rst", "generated/torch.Tensor.hsplit.rst", "generated/torch.Tensor.hypot.rst", "generated/torch.Tensor.hypot_.rst", "generated/torch.Tensor.i0.rst", "generated/torch.Tensor.i0_.rst", "generated/torch.Tensor.igamma.rst", "generated/torch.Tensor.igamma_.rst", "generated/torch.Tensor.igammac.rst", "generated/torch.Tensor.igammac_.rst", "generated/torch.Tensor.imag.rst", "generated/torch.Tensor.index_add.rst", "generated/torch.Tensor.index_add_.rst", "generated/torch.Tensor.index_copy.rst", "generated/torch.Tensor.index_copy_.rst", "generated/torch.Tensor.index_fill.rst", "generated/torch.Tensor.index_fill_.rst", "generated/torch.Tensor.index_put.rst", "generated/torch.Tensor.index_put_.rst", "generated/torch.Tensor.index_reduce.rst", "generated/torch.Tensor.index_reduce_.rst", "generated/torch.Tensor.index_select.rst", "generated/torch.Tensor.indices.rst", "generated/torch.Tensor.inner.rst", "generated/torch.Tensor.int.rst", "generated/torch.Tensor.int_repr.rst", "generated/torch.Tensor.inverse.rst", "generated/torch.Tensor.is_coalesced.rst", "generated/torch.Tensor.is_complex.rst", "generated/torch.Tensor.is_conj.rst", "generated/torch.Tensor.is_contiguous.rst", "generated/torch.Tensor.is_cuda.rst", "generated/torch.Tensor.is_floating_point.rst", "generated/torch.Tensor.is_inference.rst", "generated/torch.Tensor.is_leaf.rst", "generated/torch.Tensor.is_meta.rst", "generated/torch.Tensor.is_pinned.rst", "generated/torch.Tensor.is_quantized.rst", "generated/torch.Tensor.is_set_to.rst", "generated/torch.Tensor.is_shared.rst", "generated/torch.Tensor.is_signed.rst", "generated/torch.Tensor.is_sparse.rst", "generated/torch.Tensor.is_sparse_csr.rst", "generated/torch.Tensor.isclose.rst", "generated/torch.Tensor.isfinite.rst", "generated/torch.Tensor.isinf.rst", "generated/torch.Tensor.isnan.rst", "generated/torch.Tensor.isneginf.rst", "generated/torch.Tensor.isposinf.rst", "generated/torch.Tensor.isreal.rst", "generated/torch.Tensor.istft.rst", "generated/torch.Tensor.item.rst", "generated/torch.Tensor.kthvalue.rst", "generated/torch.Tensor.lcm.rst", "generated/torch.Tensor.lcm_.rst", "generated/torch.Tensor.ldexp.rst", "generated/torch.Tensor.ldexp_.rst", "generated/torch.Tensor.le.rst", "generated/torch.Tensor.le_.rst", "generated/torch.Tensor.lerp.rst", "generated/torch.Tensor.lerp_.rst", "generated/torch.Tensor.less.rst", "generated/torch.Tensor.less_.rst", "generated/torch.Tensor.less_equal.rst", "generated/torch.Tensor.less_equal_.rst", "generated/torch.Tensor.lgamma.rst", "generated/torch.Tensor.lgamma_.rst", "generated/torch.Tensor.log.rst", "generated/torch.Tensor.log10.rst", "generated/torch.Tensor.log10_.rst", "generated/torch.Tensor.log1p.rst", "generated/torch.Tensor.log1p_.rst", "generated/torch.Tensor.log2.rst", "generated/torch.Tensor.log2_.rst", "generated/torch.Tensor.log_.rst", "generated/torch.Tensor.log_normal_.rst", "generated/torch.Tensor.logaddexp.rst", "generated/torch.Tensor.logaddexp2.rst", "generated/torch.Tensor.logcumsumexp.rst", "generated/torch.Tensor.logdet.rst", "generated/torch.Tensor.logical_and.rst", "generated/torch.Tensor.logical_and_.rst", "generated/torch.Tensor.logical_not.rst", "generated/torch.Tensor.logical_not_.rst", "generated/torch.Tensor.logical_or.rst", "generated/torch.Tensor.logical_or_.rst", "generated/torch.Tensor.logical_xor.rst", "generated/torch.Tensor.logical_xor_.rst", "generated/torch.Tensor.logit.rst", "generated/torch.Tensor.logit_.rst", "generated/torch.Tensor.logsumexp.rst", "generated/torch.Tensor.long.rst", "generated/torch.Tensor.lt.rst", "generated/torch.Tensor.lt_.rst", "generated/torch.Tensor.lu.rst", "generated/torch.Tensor.lu_solve.rst", "generated/torch.Tensor.map_.rst", "generated/torch.Tensor.masked_fill.rst", "generated/torch.Tensor.masked_fill_.rst", "generated/torch.Tensor.masked_scatter.rst", "generated/torch.Tensor.masked_scatter_.rst", "generated/torch.Tensor.masked_select.rst", "generated/torch.Tensor.matmul.rst", "generated/torch.Tensor.matrix_exp.rst", "generated/torch.Tensor.matrix_power.rst", "generated/torch.Tensor.max.rst", "generated/torch.Tensor.maximum.rst", "generated/torch.Tensor.mean.rst", "generated/torch.Tensor.median.rst", "generated/torch.Tensor.min.rst", "generated/torch.Tensor.minimum.rst", "generated/torch.Tensor.mm.rst", "generated/torch.Tensor.mode.rst", "generated/torch.Tensor.moveaxis.rst", "generated/torch.Tensor.movedim.rst", "generated/torch.Tensor.msort.rst", "generated/torch.Tensor.mul.rst", "generated/torch.Tensor.mul_.rst", "generated/torch.Tensor.multinomial.rst", "generated/torch.Tensor.multiply.rst", "generated/torch.Tensor.multiply_.rst", "generated/torch.Tensor.mv.rst", "generated/torch.Tensor.mvlgamma.rst", "generated/torch.Tensor.mvlgamma_.rst", "generated/torch.Tensor.nan_to_num.rst", "generated/torch.Tensor.nan_to_num_.rst", "generated/torch.Tensor.nanmean.rst", "generated/torch.Tensor.nanmedian.rst", "generated/torch.Tensor.nanquantile.rst", "generated/torch.Tensor.nansum.rst", "generated/torch.Tensor.narrow.rst", "generated/torch.Tensor.narrow_copy.rst", "generated/torch.Tensor.ndim.rst", "generated/torch.Tensor.ndimension.rst", "generated/torch.Tensor.ne.rst", "generated/torch.Tensor.ne_.rst", "generated/torch.Tensor.neg.rst", "generated/torch.Tensor.neg_.rst", "generated/torch.Tensor.negative.rst", "generated/torch.Tensor.negative_.rst", "generated/torch.Tensor.nelement.rst", "generated/torch.Tensor.new_empty.rst", "generated/torch.Tensor.new_full.rst", "generated/torch.Tensor.new_ones.rst", "generated/torch.Tensor.new_tensor.rst", "generated/torch.Tensor.new_zeros.rst", "generated/torch.Tensor.nextafter.rst", "generated/torch.Tensor.nextafter_.rst", "generated/torch.Tensor.nonzero.rst", "generated/torch.Tensor.norm.rst", "generated/torch.Tensor.normal_.rst", "generated/torch.Tensor.not_equal.rst", "generated/torch.Tensor.not_equal_.rst", "generated/torch.Tensor.numel.rst", "generated/torch.Tensor.numpy.rst", "generated/torch.Tensor.orgqr.rst", "generated/torch.Tensor.ormqr.rst", "generated/torch.Tensor.outer.rst", "generated/torch.Tensor.permute.rst", "generated/torch.Tensor.pin_memory.rst", "generated/torch.Tensor.pinverse.rst", "generated/torch.Tensor.polygamma.rst", "generated/torch.Tensor.polygamma_.rst", "generated/torch.Tensor.positive.rst", "generated/torch.Tensor.pow.rst", "generated/torch.Tensor.pow_.rst", "generated/torch.Tensor.prod.rst", "generated/torch.Tensor.put_.rst", "generated/torch.Tensor.q_per_channel_axis.rst", "generated/torch.Tensor.q_per_channel_scales.rst", "generated/torch.Tensor.q_per_channel_zero_points.rst", "generated/torch.Tensor.q_scale.rst", "generated/torch.Tensor.q_zero_point.rst", "generated/torch.Tensor.qr.rst", "generated/torch.Tensor.qscheme.rst", "generated/torch.Tensor.quantile.rst", "generated/torch.Tensor.rad2deg.rst", "generated/torch.Tensor.random_.rst", "generated/torch.Tensor.ravel.rst", "generated/torch.Tensor.real.rst", "generated/torch.Tensor.reciprocal.rst", "generated/torch.Tensor.reciprocal_.rst", "generated/torch.Tensor.record_stream.rst", "generated/torch.Tensor.register_hook.rst", "generated/torch.Tensor.remainder.rst", "generated/torch.Tensor.remainder_.rst", "generated/torch.Tensor.renorm.rst", "generated/torch.Tensor.renorm_.rst", "generated/torch.Tensor.repeat.rst", "generated/torch.Tensor.repeat_interleave.rst", "generated/torch.Tensor.requires_grad.rst", "generated/torch.Tensor.requires_grad_.rst", "generated/torch.Tensor.reshape.rst", "generated/torch.Tensor.reshape_as.rst", "generated/torch.Tensor.resize_.rst", "generated/torch.Tensor.resize_as_.rst", "generated/torch.Tensor.resolve_conj.rst", "generated/torch.Tensor.resolve_neg.rst", "generated/torch.Tensor.retain_grad.rst", "generated/torch.Tensor.retains_grad.rst", "generated/torch.Tensor.roll.rst", "generated/torch.Tensor.rot90.rst", "generated/torch.Tensor.round.rst", "generated/torch.Tensor.round_.rst", "generated/torch.Tensor.row_indices.rst", "generated/torch.Tensor.rsqrt.rst", "generated/torch.Tensor.rsqrt_.rst", "generated/torch.Tensor.scatter.rst", "generated/torch.Tensor.scatter_.rst", "generated/torch.Tensor.scatter_add.rst", "generated/torch.Tensor.scatter_add_.rst", "generated/torch.Tensor.scatter_reduce.rst", "generated/torch.Tensor.scatter_reduce_.rst", "generated/torch.Tensor.select.rst", "generated/torch.Tensor.select_scatter.rst", "generated/torch.Tensor.set_.rst", "generated/torch.Tensor.sgn.rst", "generated/torch.Tensor.sgn_.rst", "generated/torch.Tensor.share_memory_.rst", "generated/torch.Tensor.short.rst", "generated/torch.Tensor.sigmoid.rst", "generated/torch.Tensor.sigmoid_.rst", "generated/torch.Tensor.sign.rst", "generated/torch.Tensor.sign_.rst", "generated/torch.Tensor.signbit.rst", "generated/torch.Tensor.sin.rst", "generated/torch.Tensor.sin_.rst", "generated/torch.Tensor.sinc.rst", "generated/torch.Tensor.sinc_.rst", "generated/torch.Tensor.sinh.rst", "generated/torch.Tensor.sinh_.rst", "generated/torch.Tensor.size.rst", "generated/torch.Tensor.slice_scatter.rst", "generated/torch.Tensor.slogdet.rst", "generated/torch.Tensor.smm.rst", "generated/torch.Tensor.softmax.rst", "generated/torch.Tensor.sort.rst", "generated/torch.Tensor.sparse_dim.rst", "generated/torch.Tensor.sparse_mask.rst", "generated/torch.Tensor.sparse_resize_.rst", "generated/torch.Tensor.sparse_resize_and_clear_.rst", "generated/torch.Tensor.split.rst", "generated/torch.Tensor.sqrt.rst", "generated/torch.Tensor.sqrt_.rst", "generated/torch.Tensor.square.rst", "generated/torch.Tensor.square_.rst", "generated/torch.Tensor.squeeze.rst", "generated/torch.Tensor.squeeze_.rst", "generated/torch.Tensor.sspaddmm.rst", "generated/torch.Tensor.std.rst", "generated/torch.Tensor.stft.rst", "generated/torch.Tensor.storage.rst", "generated/torch.Tensor.storage_offset.rst", "generated/torch.Tensor.storage_type.rst", "generated/torch.Tensor.stride.rst", "generated/torch.Tensor.sub.rst", "generated/torch.Tensor.sub_.rst", "generated/torch.Tensor.subtract.rst", "generated/torch.Tensor.subtract_.rst", "generated/torch.Tensor.sum.rst", "generated/torch.Tensor.sum_to_size.rst", "generated/torch.Tensor.svd.rst", "generated/torch.Tensor.swapaxes.rst", "generated/torch.Tensor.swapdims.rst", "generated/torch.Tensor.symeig.rst", "generated/torch.Tensor.t.rst", "generated/torch.Tensor.t_.rst", "generated/torch.Tensor.take.rst", "generated/torch.Tensor.take_along_dim.rst", "generated/torch.Tensor.tan.rst", "generated/torch.Tensor.tan_.rst", "generated/torch.Tensor.tanh.rst", "generated/torch.Tensor.tanh_.rst", "generated/torch.Tensor.tensor_split.rst", "generated/torch.Tensor.tile.rst", "generated/torch.Tensor.to.rst", "generated/torch.Tensor.to_dense.rst", "generated/torch.Tensor.to_mkldnn.rst", "generated/torch.Tensor.to_sparse.rst", "generated/torch.Tensor.to_sparse_bsc.rst", "generated/torch.Tensor.to_sparse_bsr.rst", "generated/torch.Tensor.to_sparse_coo.rst", "generated/torch.Tensor.to_sparse_csc.rst", "generated/torch.Tensor.to_sparse_csr.rst", "generated/torch.Tensor.tolist.rst", "generated/torch.Tensor.topk.rst", "generated/torch.Tensor.trace.rst", "generated/torch.Tensor.transpose.rst", "generated/torch.Tensor.transpose_.rst", "generated/torch.Tensor.triangular_solve.rst", "generated/torch.Tensor.tril.rst", "generated/torch.Tensor.tril_.rst", "generated/torch.Tensor.triu.rst", "generated/torch.Tensor.triu_.rst", "generated/torch.Tensor.true_divide.rst", "generated/torch.Tensor.true_divide_.rst", "generated/torch.Tensor.trunc.rst", "generated/torch.Tensor.trunc_.rst", "generated/torch.Tensor.type.rst", "generated/torch.Tensor.type_as.rst", "generated/torch.Tensor.unbind.rst", "generated/torch.Tensor.unflatten.rst", "generated/torch.Tensor.unfold.rst", "generated/torch.Tensor.uniform_.rst", "generated/torch.Tensor.unique.rst", "generated/torch.Tensor.unique_consecutive.rst", "generated/torch.Tensor.unsqueeze.rst", "generated/torch.Tensor.unsqueeze_.rst", "generated/torch.Tensor.untyped_storage.rst", "generated/torch.Tensor.values.rst", "generated/torch.Tensor.var.rst", "generated/torch.Tensor.vdot.rst", "generated/torch.Tensor.view.rst", "generated/torch.Tensor.view_as.rst", "generated/torch.Tensor.vsplit.rst", "generated/torch.Tensor.where.rst", "generated/torch.Tensor.xlogy.rst", "generated/torch.Tensor.xlogy_.rst", "generated/torch.Tensor.zero_.rst", "generated/torch._assert.rst", "generated/torch.abs.rst", "generated/torch.absolute.rst", "generated/torch.acos.rst", "generated/torch.acosh.rst", "generated/torch.add.rst", "generated/torch.addbmm.rst", "generated/torch.addcdiv.rst", "generated/torch.addcmul.rst", "generated/torch.addmm.rst", "generated/torch.addmv.rst", "generated/torch.addr.rst", "generated/torch.adjoint.rst", "generated/torch.all.rst", "generated/torch.allclose.rst", "generated/torch.amax.rst", "generated/torch.amin.rst", "generated/torch.aminmax.rst", "generated/torch.angle.rst", "generated/torch.any.rst", "generated/torch.ao.nn.intrinsic.BNReLU2d.rst", "generated/torch.ao.nn.intrinsic.BNReLU3d.rst", "generated/torch.ao.nn.intrinsic.ConvBn1d.rst", "generated/torch.ao.nn.intrinsic.ConvBn2d.rst", "generated/torch.ao.nn.intrinsic.ConvBn3d.rst", "generated/torch.ao.nn.intrinsic.ConvBnReLU1d.rst", "generated/torch.ao.nn.intrinsic.ConvBnReLU2d.rst", "generated/torch.ao.nn.intrinsic.ConvBnReLU3d.rst", "generated/torch.ao.nn.intrinsic.ConvReLU1d.rst", "generated/torch.ao.nn.intrinsic.ConvReLU2d.rst", "generated/torch.ao.nn.intrinsic.ConvReLU3d.rst", "generated/torch.ao.nn.intrinsic.LinearReLU.rst", "generated/torch.ao.nn.intrinsic.qat.ConvBn1d.rst", "generated/torch.ao.nn.intrinsic.qat.ConvBn2d.rst", "generated/torch.ao.nn.intrinsic.qat.ConvBn3d.rst", "generated/torch.ao.nn.intrinsic.qat.ConvBnReLU1d.rst", "generated/torch.ao.nn.intrinsic.qat.ConvBnReLU2d.rst", "generated/torch.ao.nn.intrinsic.qat.ConvBnReLU3d.rst", "generated/torch.ao.nn.intrinsic.qat.ConvReLU2d.rst", "generated/torch.ao.nn.intrinsic.qat.ConvReLU3d.rst", "generated/torch.ao.nn.intrinsic.qat.LinearReLU.rst", "generated/torch.ao.nn.intrinsic.qat.freeze_bn_stats.rst", "generated/torch.ao.nn.intrinsic.qat.update_bn_stats.rst", "generated/torch.ao.nn.intrinsic.quantized.BNReLU2d.rst", "generated/torch.ao.nn.intrinsic.quantized.BNReLU3d.rst", "generated/torch.ao.nn.intrinsic.quantized.ConvReLU1d.rst", "generated/torch.ao.nn.intrinsic.quantized.ConvReLU2d.rst", "generated/torch.ao.nn.intrinsic.quantized.ConvReLU3d.rst", "generated/torch.ao.nn.intrinsic.quantized.LinearReLU.rst", "generated/torch.ao.nn.intrinsic.quantized.dynamic.LinearReLU.rst", "generated/torch.ao.nn.qat.Conv2d.rst", "generated/torch.ao.nn.qat.Conv3d.rst", "generated/torch.ao.nn.qat.Linear.rst", "generated/torch.ao.nn.qat.dynamic.Linear.rst", "generated/torch.ao.nn.quantized.BatchNorm2d.rst", "generated/torch.ao.nn.quantized.BatchNorm3d.rst", "generated/torch.ao.nn.quantized.Conv1d.rst", "generated/torch.ao.nn.quantized.Conv2d.rst", "generated/torch.ao.nn.quantized.Conv3d.rst", "generated/torch.ao.nn.quantized.ConvTranspose1d.rst", "generated/torch.ao.nn.quantized.ConvTranspose2d.rst", "generated/torch.ao.nn.quantized.ConvTranspose3d.rst", "generated/torch.ao.nn.quantized.ELU.rst", "generated/torch.ao.nn.quantized.Embedding.rst", "generated/torch.ao.nn.quantized.EmbeddingBag.rst", "generated/torch.ao.nn.quantized.FXFloatFunctional.rst", "generated/torch.ao.nn.quantized.FloatFunctional.rst", "generated/torch.ao.nn.quantized.GroupNorm.rst", "generated/torch.ao.nn.quantized.Hardswish.rst", "generated/torch.ao.nn.quantized.InstanceNorm1d.rst", "generated/torch.ao.nn.quantized.InstanceNorm2d.rst", "generated/torch.ao.nn.quantized.InstanceNorm3d.rst", "generated/torch.ao.nn.quantized.LayerNorm.rst", "generated/torch.ao.nn.quantized.LeakyReLU.rst", "generated/torch.ao.nn.quantized.Linear.rst", "generated/torch.ao.nn.quantized.QFunctional.rst", "generated/torch.ao.nn.quantized.ReLU6.rst", "generated/torch.ao.nn.quantized.Sigmoid.rst", "generated/torch.ao.nn.quantized.dynamic.GRU.rst", "generated/torch.ao.nn.quantized.dynamic.GRUCell.rst", "generated/torch.ao.nn.quantized.dynamic.LSTM.rst", "generated/torch.ao.nn.quantized.dynamic.LSTMCell.rst", "generated/torch.ao.nn.quantized.dynamic.Linear.rst", "generated/torch.ao.nn.quantized.dynamic.RNNCell.rst", "generated/torch.ao.nn.quantized.functional.adaptive_avg_pool2d.rst", "generated/torch.ao.nn.quantized.functional.adaptive_avg_pool3d.rst", "generated/torch.ao.nn.quantized.functional.avg_pool2d.rst", "generated/torch.ao.nn.quantized.functional.avg_pool3d.rst", "generated/torch.ao.nn.quantized.functional.celu.rst", "generated/torch.ao.nn.quantized.functional.clamp.rst", "generated/torch.ao.nn.quantized.functional.conv1d.rst", "generated/torch.ao.nn.quantized.functional.conv2d.rst", "generated/torch.ao.nn.quantized.functional.conv3d.rst", "generated/torch.ao.nn.quantized.functional.elu.rst", "generated/torch.ao.nn.quantized.functional.hardsigmoid.rst", "generated/torch.ao.nn.quantized.functional.hardswish.rst", "generated/torch.ao.nn.quantized.functional.hardtanh.rst", "generated/torch.ao.nn.quantized.functional.interpolate.rst", "generated/torch.ao.nn.quantized.functional.leaky_relu.rst", "generated/torch.ao.nn.quantized.functional.linear.rst", "generated/torch.ao.nn.quantized.functional.max_pool1d.rst", "generated/torch.ao.nn.quantized.functional.max_pool2d.rst", "generated/torch.ao.nn.quantized.functional.threshold.rst", "generated/torch.ao.nn.quantized.functional.upsample.rst", "generated/torch.ao.nn.quantized.functional.upsample_bilinear.rst", "generated/torch.ao.nn.quantized.functional.upsample_nearest.rst", "generated/torch.ao.quantization.backend_config.BackendConfig.rst", "generated/torch.ao.quantization.backend_config.BackendPatternConfig.rst", "generated/torch.ao.quantization.backend_config.DTypeConfig.rst", "generated/torch.ao.quantization.backend_config.ObservationType.rst", "generated/torch.ao.quantization.fx.custom_config.ConvertCustomConfig.rst", "generated/torch.ao.quantization.fx.custom_config.FuseCustomConfig.rst", "generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.rst", "generated/torch.ao.quantization.fx.custom_config.StandaloneModuleConfigEntry.rst", "generated/torch.ao.quantization.qconfig_mapping.QConfigMapping.rst", "generated/torch.ao.quantization.qconfig_mapping.get_default_qat_qconfig_mapping.rst", "generated/torch.ao.quantization.qconfig_mapping.get_default_qconfig_mapping.rst", "generated/torch.arange.rst", "generated/torch.arccos.rst", "generated/torch.arccosh.rst", "generated/torch.arcsin.rst", "generated/torch.arcsinh.rst", "generated/torch.arctan.rst", "generated/torch.arctan2.rst", "generated/torch.arctanh.rst", "generated/torch.are_deterministic_algorithms_enabled.rst", "generated/torch.argmax.rst", "generated/torch.argmin.rst", "generated/torch.argsort.rst", "generated/torch.argwhere.rst", "generated/torch.as_strided.rst", "generated/torch.as_tensor.rst", "generated/torch.asarray.rst", "generated/torch.asin.rst", "generated/torch.asinh.rst", "generated/torch.atan.rst", "generated/torch.atan2.rst", "generated/torch.atanh.rst", "generated/torch.atleast_1d.rst", "generated/torch.atleast_2d.rst", "generated/torch.atleast_3d.rst", "generated/torch.autograd.Function.backward.rst", "generated/torch.autograd.Function.forward.rst", "generated/torch.autograd.Function.jvp.rst", "generated/torch.autograd.backward.rst", "generated/torch.autograd.forward_ad.dual_level.rst", "generated/torch.autograd.forward_ad.make_dual.rst", "generated/torch.autograd.forward_ad.unpack_dual.rst", "generated/torch.autograd.function.FunctionCtx.mark_dirty.rst", "generated/torch.autograd.function.FunctionCtx.mark_non_differentiable.rst", "generated/torch.autograd.function.FunctionCtx.save_for_backward.rst", "generated/torch.autograd.function.FunctionCtx.set_materialize_grads.rst", "generated/torch.autograd.functional.hessian.rst", "generated/torch.autograd.functional.hvp.rst", "generated/torch.autograd.functional.jacobian.rst", "generated/torch.autograd.functional.jvp.rst", "generated/torch.autograd.functional.vhp.rst", "generated/torch.autograd.functional.vjp.rst", "generated/torch.autograd.grad.rst", "generated/torch.autograd.gradcheck.rst", "generated/torch.autograd.gradgradcheck.rst", "generated/torch.autograd.profiler.load_nvprof.rst", "generated/torch.autograd.profiler.profile.export_chrome_trace.rst", "generated/torch.autograd.profiler.profile.key_averages.rst", "generated/torch.autograd.profiler.profile.self_cpu_time_total.rst", "generated/torch.autograd.profiler.profile.total_average.rst", "generated/torch.autograd.set_multithreading_enabled.rst", "generated/torch.baddbmm.rst", "generated/torch.bartlett_window.rst", "generated/torch.bernoulli.rst", "generated/torch.bincount.rst", "generated/torch.bitwise_and.rst", "generated/torch.bitwise_left_shift.rst", "generated/torch.bitwise_not.rst", "generated/torch.bitwise_or.rst", "generated/torch.bitwise_right_shift.rst", "generated/torch.bitwise_xor.rst", "generated/torch.blackman_window.rst", "generated/torch.block_diag.rst", "generated/torch.bmm.rst", "generated/torch.broadcast_shapes.rst", "generated/torch.broadcast_tensors.rst", "generated/torch.broadcast_to.rst", "generated/torch.bucketize.rst", "generated/torch.can_cast.rst", "generated/torch.cartesian_prod.rst", "generated/torch.cat.rst", "generated/torch.cdist.rst", "generated/torch.ceil.rst", "generated/torch.chain_matmul.rst", "generated/torch.cholesky.rst", "generated/torch.cholesky_inverse.rst", "generated/torch.cholesky_solve.rst", "generated/torch.chunk.rst", "generated/torch.clamp.rst", "generated/torch.clip.rst", "generated/torch.clone.rst", "generated/torch.column_stack.rst", "generated/torch.combinations.rst", "generated/torch.compile.rst", "generated/torch.compiled_with_cxx11_abi.rst", "generated/torch.complex.rst", "generated/torch.concat.rst", "generated/torch.concatenate.rst", "generated/torch.conj.rst", "generated/torch.conj_physical.rst", "generated/torch.copysign.rst", "generated/torch.corrcoef.rst", "generated/torch.cos.rst", "generated/torch.cosh.rst", "generated/torch.count_nonzero.rst", "generated/torch.cov.rst", "generated/torch.cross.rst", "generated/torch.cuda.CUDAGraph.rst", "generated/torch.cuda.CUDAPluggableAllocator.rst", "generated/torch.cuda.Event.rst", "generated/torch.cuda.ExternalStream.rst", "generated/torch.cuda.OutOfMemoryError.rst", "generated/torch.cuda.Stream.rst", "generated/torch.cuda.StreamContext.rst", "generated/torch.cuda.caching_allocator_alloc.rst", "generated/torch.cuda.caching_allocator_delete.rst", "generated/torch.cuda.can_device_access_peer.rst", "generated/torch.cuda.change_current_allocator.rst", "generated/torch.cuda.comm.broadcast.rst", "generated/torch.cuda.comm.broadcast_coalesced.rst", "generated/torch.cuda.comm.gather.rst", "generated/torch.cuda.comm.reduce_add.rst", "generated/torch.cuda.comm.scatter.rst", "generated/torch.cuda.current_blas_handle.rst", "generated/torch.cuda.current_device.rst", "generated/torch.cuda.current_stream.rst", "generated/torch.cuda.default_stream.rst", "generated/torch.cuda.device.rst", "generated/torch.cuda.device_count.rst", "generated/torch.cuda.device_of.rst", "generated/torch.cuda.empty_cache.rst", "generated/torch.cuda.get_allocator_backend.rst", "generated/torch.cuda.get_arch_list.rst", "generated/torch.cuda.get_device_capability.rst", "generated/torch.cuda.get_device_name.rst", "generated/torch.cuda.get_device_properties.rst", "generated/torch.cuda.get_gencode_flags.rst", "generated/torch.cuda.get_rng_state.rst", "generated/torch.cuda.get_rng_state_all.rst", "generated/torch.cuda.get_sync_debug_mode.rst", "generated/torch.cuda.graph.rst", "generated/torch.cuda.graph_pool_handle.rst", "generated/torch.cuda.init.rst", "generated/torch.cuda.initial_seed.rst", "generated/torch.cuda.ipc_collect.rst", "generated/torch.cuda.is_available.rst", "generated/torch.cuda.is_current_stream_capturing.rst", "generated/torch.cuda.is_initialized.rst", "generated/torch.cuda.jiterator._create_jit_fn.rst", "generated/torch.cuda.jiterator._create_multi_output_jit_fn.rst", "generated/torch.cuda.list_gpu_processes.rst", "generated/torch.cuda.make_graphed_callables.rst", "generated/torch.cuda.manual_seed.rst", "generated/torch.cuda.manual_seed_all.rst", "generated/torch.cuda.max_memory_allocated.rst", "generated/torch.cuda.max_memory_cached.rst", "generated/torch.cuda.max_memory_reserved.rst", "generated/torch.cuda.mem_get_info.rst", "generated/torch.cuda.memory_allocated.rst", "generated/torch.cuda.memory_cached.rst", "generated/torch.cuda.memory_reserved.rst", "generated/torch.cuda.memory_snapshot.rst", "generated/torch.cuda.memory_stats.rst", "generated/torch.cuda.memory_summary.rst", "generated/torch.cuda.memory_usage.rst", "generated/torch.cuda.nvtx.mark.rst", "generated/torch.cuda.nvtx.range_pop.rst", "generated/torch.cuda.nvtx.range_push.rst", "generated/torch.cuda.reset_max_memory_allocated.rst", "generated/torch.cuda.reset_max_memory_cached.rst", "generated/torch.cuda.reset_peak_memory_stats.rst", "generated/torch.cuda.seed.rst", "generated/torch.cuda.seed_all.rst", "generated/torch.cuda.set_device.rst", "generated/torch.cuda.set_per_process_memory_fraction.rst", "generated/torch.cuda.set_rng_state.rst", "generated/torch.cuda.set_rng_state_all.rst", "generated/torch.cuda.set_stream.rst", "generated/torch.cuda.set_sync_debug_mode.rst", "generated/torch.cuda.stream.rst", "generated/torch.cuda.synchronize.rst", "generated/torch.cuda.utilization.rst", "generated/torch.cummax.rst", "generated/torch.cummin.rst", "generated/torch.cumprod.rst", "generated/torch.cumsum.rst", "generated/torch.cumulative_trapezoid.rst", "generated/torch.deg2rad.rst", "generated/torch.dequantize.rst", "generated/torch.det.rst", "generated/torch.diag.rst", "generated/torch.diag_embed.rst", "generated/torch.diagflat.rst", "generated/torch.diagonal.rst", "generated/torch.diagonal_scatter.rst", "generated/torch.diff.rst", "generated/torch.digamma.rst", "generated/torch.dist.rst", "generated/torch.div.rst", "generated/torch.divide.rst", "generated/torch.dot.rst", "generated/torch.dsplit.rst", "generated/torch.dstack.rst", "generated/torch.einsum.rst", "generated/torch.empty.rst", "generated/torch.empty_like.rst", "generated/torch.empty_strided.rst", "generated/torch.enable_grad.rst", "generated/torch.eq.rst", "generated/torch.equal.rst", "generated/torch.erf.rst", "generated/torch.erfc.rst", "generated/torch.erfinv.rst", "generated/torch.exp.rst", "generated/torch.exp2.rst", "generated/torch.expm1.rst", "generated/torch.eye.rst", "generated/torch.fake_quantize_per_channel_affine.rst", "generated/torch.fake_quantize_per_tensor_affine.rst", "generated/torch.fft.fft.rst", "generated/torch.fft.fft2.rst", "generated/torch.fft.fftfreq.rst", "generated/torch.fft.fftn.rst", "generated/torch.fft.fftshift.rst", "generated/torch.fft.hfft.rst", "generated/torch.fft.hfft2.rst", "generated/torch.fft.hfftn.rst", "generated/torch.fft.ifft.rst", "generated/torch.fft.ifft2.rst", "generated/torch.fft.ifftn.rst", "generated/torch.fft.ifftshift.rst", "generated/torch.fft.ihfft.rst", "generated/torch.fft.ihfft2.rst", "generated/torch.fft.ihfftn.rst", "generated/torch.fft.irfft.rst", "generated/torch.fft.irfft2.rst", "generated/torch.fft.irfftn.rst", "generated/torch.fft.rfft.rst", "generated/torch.fft.rfft2.rst", "generated/torch.fft.rfftfreq.rst", "generated/torch.fft.rfftn.rst", "generated/torch.fix.rst", "generated/torch.flatten.rst", "generated/torch.flip.rst", "generated/torch.fliplr.rst", "generated/torch.flipud.rst", "generated/torch.float_power.rst", "generated/torch.floor.rst", "generated/torch.floor_divide.rst", "generated/torch.fmax.rst", "generated/torch.fmin.rst", "generated/torch.fmod.rst", "generated/torch.frac.rst", "generated/torch.frexp.rst", "generated/torch.from_dlpack.rst", "generated/torch.from_numpy.rst", "generated/torch.frombuffer.rst", "generated/torch.full.rst", "generated/torch.full_like.rst", "generated/torch.func.functional_call.rst", "generated/torch.func.functionalize.rst", "generated/torch.func.grad.rst", "generated/torch.func.grad_and_value.rst", "generated/torch.func.hessian.rst", "generated/torch.func.jacfwd.rst", "generated/torch.func.jacrev.rst", "generated/torch.func.jvp.rst", "generated/torch.func.stack_module_state.rst", "generated/torch.func.vjp.rst", "generated/torch.func.vmap.rst", "generated/torch.gather.rst", "generated/torch.gcd.rst", "generated/torch.ge.rst", "generated/torch.geqrf.rst", "generated/torch.ger.rst", "generated/torch.get_default_dtype.rst", "generated/torch.get_deterministic_debug_mode.rst", "generated/torch.get_float32_matmul_precision.rst", "generated/torch.get_num_interop_threads.rst", "generated/torch.get_num_threads.rst", "generated/torch.get_rng_state.rst", "generated/torch.gradient.rst", "generated/torch.greater.rst", "generated/torch.greater_equal.rst", "generated/torch.gt.rst", "generated/torch.hamming_window.rst", "generated/torch.hann_window.rst", "generated/torch.heaviside.rst", "generated/torch.histc.rst", "generated/torch.histogram.rst", "generated/torch.histogramdd.rst", "generated/torch.hsplit.rst", "generated/torch.hspmm.rst", "generated/torch.hstack.rst", "generated/torch.hypot.rst", "generated/torch.i0.rst", "generated/torch.igamma.rst", "generated/torch.igammac.rst", "generated/torch.imag.rst", "generated/torch.index_add.rst", "generated/torch.index_copy.rst", "generated/torch.index_reduce.rst", "generated/torch.index_select.rst", "generated/torch.inference_mode.rst", "generated/torch.initial_seed.rst", "generated/torch.inner.rst", "generated/torch.inverse.rst", "generated/torch.is_complex.rst", "generated/torch.is_conj.rst", "generated/torch.is_deterministic_algorithms_warn_only_enabled.rst", "generated/torch.is_floating_point.rst", "generated/torch.is_grad_enabled.rst", "generated/torch.is_inference_mode_enabled.rst", "generated/torch.is_nonzero.rst", "generated/torch.is_storage.rst", "generated/torch.is_tensor.rst", "generated/torch.is_warn_always_enabled.rst", "generated/torch.isclose.rst", "generated/torch.isfinite.rst", "generated/torch.isin.rst", "generated/torch.isinf.rst", "generated/torch.isnan.rst", "generated/torch.isneginf.rst", "generated/torch.isposinf.rst", "generated/torch.isreal.rst", "generated/torch.istft.rst", "generated/torch.jit.Attribute.rst", "generated/torch.jit.ScriptFunction.rst", "generated/torch.jit.ScriptModule.rst", "generated/torch.jit.annotate.rst", "generated/torch.jit.enable_onednn_fusion.rst", "generated/torch.jit.fork.rst", "generated/torch.jit.freeze.rst", "generated/torch.jit.ignore.rst", "generated/torch.jit.isinstance.rst", "generated/torch.jit.load.rst", "generated/torch.jit.onednn_fusion_enabled.rst", "generated/torch.jit.optimize_for_inference.rst", "generated/torch.jit.save.rst", "generated/torch.jit.script.rst", "generated/torch.jit.script_if_tracing.rst", "generated/torch.jit.set_fusion_strategy.rst", "generated/torch.jit.strict_fusion.rst", "generated/torch.jit.trace.rst", "generated/torch.jit.trace_module.rst", "generated/torch.jit.unused.rst", "generated/torch.jit.wait.rst", "generated/torch.kaiser_window.rst", "generated/torch.kron.rst", "generated/torch.kthvalue.rst", "generated/torch.lcm.rst", "generated/torch.ldexp.rst", "generated/torch.le.rst", "generated/torch.lerp.rst", "generated/torch.less.rst", "generated/torch.less_equal.rst", "generated/torch.lgamma.rst", "generated/torch.linalg.cholesky.rst", "generated/torch.linalg.cholesky_ex.rst", "generated/torch.linalg.cond.rst", "generated/torch.linalg.cross.rst", "generated/torch.linalg.det.rst", "generated/torch.linalg.diagonal.rst", "generated/torch.linalg.eig.rst", "generated/torch.linalg.eigh.rst", "generated/torch.linalg.eigvals.rst", "generated/torch.linalg.eigvalsh.rst", "generated/torch.linalg.householder_product.rst", "generated/torch.linalg.inv.rst", "generated/torch.linalg.inv_ex.rst", "generated/torch.linalg.ldl_factor.rst", "generated/torch.linalg.ldl_factor_ex.rst", "generated/torch.linalg.ldl_solve.rst", "generated/torch.linalg.lstsq.rst", "generated/torch.linalg.lu.rst", "generated/torch.linalg.lu_factor.rst", "generated/torch.linalg.lu_factor_ex.rst", "generated/torch.linalg.lu_solve.rst", "generated/torch.linalg.matmul.rst", "generated/torch.linalg.matrix_exp.rst", "generated/torch.linalg.matrix_norm.rst", "generated/torch.linalg.matrix_power.rst", "generated/torch.linalg.matrix_rank.rst", "generated/torch.linalg.multi_dot.rst", "generated/torch.linalg.norm.rst", "generated/torch.linalg.pinv.rst", "generated/torch.linalg.qr.rst", "generated/torch.linalg.slogdet.rst", "generated/torch.linalg.solve.rst", "generated/torch.linalg.solve_ex.rst", "generated/torch.linalg.solve_triangular.rst", "generated/torch.linalg.svd.rst", "generated/torch.linalg.svdvals.rst", "generated/torch.linalg.tensorinv.rst", "generated/torch.linalg.tensorsolve.rst", "generated/torch.linalg.vander.rst", "generated/torch.linalg.vecdot.rst", "generated/torch.linalg.vector_norm.rst", "generated/torch.linspace.rst", "generated/torch.load.rst", "generated/torch.lobpcg.rst", "generated/torch.log.rst", "generated/torch.log10.rst", "generated/torch.log1p.rst", "generated/torch.log2.rst", "generated/torch.logaddexp.rst", "generated/torch.logaddexp2.rst", "generated/torch.logcumsumexp.rst", "generated/torch.logdet.rst", "generated/torch.logical_and.rst", "generated/torch.logical_not.rst", "generated/torch.logical_or.rst", "generated/torch.logical_xor.rst", "generated/torch.logit.rst", "generated/torch.logspace.rst", "generated/torch.logsumexp.rst", "generated/torch.lt.rst", "generated/torch.lu.rst", "generated/torch.lu_solve.rst", "generated/torch.lu_unpack.rst", "generated/torch.manual_seed.rst", "generated/torch.masked_select.rst", "generated/torch.matmul.rst", "generated/torch.matrix_exp.rst", "generated/torch.matrix_power.rst", "generated/torch.max.rst", "generated/torch.maximum.rst", "generated/torch.mean.rst", "generated/torch.median.rst", "generated/torch.meshgrid.rst", "generated/torch.min.rst", "generated/torch.minimum.rst", "generated/torch.mm.rst", "generated/torch.mode.rst", "generated/torch.moveaxis.rst", "generated/torch.movedim.rst", "generated/torch.msort.rst", "generated/torch.mul.rst", "generated/torch.multinomial.rst", "generated/torch.multiply.rst", "generated/torch.mv.rst", "generated/torch.mvlgamma.rst", "generated/torch.nan_to_num.rst", "generated/torch.nanmean.rst", "generated/torch.nanmedian.rst", "generated/torch.nanquantile.rst", "generated/torch.nansum.rst", "generated/torch.narrow.rst", "generated/torch.narrow_copy.rst", "generated/torch.ne.rst", "generated/torch.neg.rst", "generated/torch.negative.rst", "generated/torch.nextafter.rst", "generated/torch.nn.AdaptiveAvgPool1d.rst", "generated/torch.nn.AdaptiveAvgPool2d.rst", "generated/torch.nn.AdaptiveAvgPool3d.rst", "generated/torch.nn.AdaptiveLogSoftmaxWithLoss.rst", "generated/torch.nn.AdaptiveMaxPool1d.rst", "generated/torch.nn.AdaptiveMaxPool2d.rst", "generated/torch.nn.AdaptiveMaxPool3d.rst", "generated/torch.nn.AlphaDropout.rst", "generated/torch.nn.AvgPool1d.rst", "generated/torch.nn.AvgPool2d.rst", "generated/torch.nn.AvgPool3d.rst", "generated/torch.nn.BCELoss.rst", "generated/torch.nn.BCEWithLogitsLoss.rst", "generated/torch.nn.BatchNorm1d.rst", "generated/torch.nn.BatchNorm2d.rst", "generated/torch.nn.BatchNorm3d.rst", "generated/torch.nn.Bilinear.rst", "generated/torch.nn.CELU.rst", "generated/torch.nn.CTCLoss.rst", "generated/torch.nn.ChannelShuffle.rst", "generated/torch.nn.ConstantPad1d.rst", "generated/torch.nn.ConstantPad2d.rst", "generated/torch.nn.ConstantPad3d.rst", "generated/torch.nn.Conv1d.rst", "generated/torch.nn.Conv2d.rst", "generated/torch.nn.Conv3d.rst", "generated/torch.nn.ConvTranspose1d.rst", "generated/torch.nn.ConvTranspose2d.rst", "generated/torch.nn.ConvTranspose3d.rst", "generated/torch.nn.CosineEmbeddingLoss.rst", "generated/torch.nn.CosineSimilarity.rst", "generated/torch.nn.CrossEntropyLoss.rst", "generated/torch.nn.DataParallel.rst", "generated/torch.nn.Dropout.rst", "generated/torch.nn.Dropout1d.rst", "generated/torch.nn.Dropout2d.rst", "generated/torch.nn.Dropout3d.rst", "generated/torch.nn.ELU.rst", "generated/torch.nn.Embedding.rst", "generated/torch.nn.EmbeddingBag.rst", "generated/torch.nn.FeatureAlphaDropout.rst", "generated/torch.nn.Flatten.rst", "generated/torch.nn.Fold.rst", "generated/torch.nn.FractionalMaxPool2d.rst", "generated/torch.nn.FractionalMaxPool3d.rst", "generated/torch.nn.GELU.rst", "generated/torch.nn.GLU.rst", "generated/torch.nn.GRU.rst", "generated/torch.nn.GRUCell.rst", "generated/torch.nn.GaussianNLLLoss.rst", "generated/torch.nn.GroupNorm.rst", "generated/torch.nn.Hardshrink.rst", "generated/torch.nn.Hardsigmoid.rst", "generated/torch.nn.Hardswish.rst", "generated/torch.nn.Hardtanh.rst", "generated/torch.nn.HingeEmbeddingLoss.rst", "generated/torch.nn.HuberLoss.rst", "generated/torch.nn.Identity.rst", "generated/torch.nn.InstanceNorm1d.rst", "generated/torch.nn.InstanceNorm2d.rst", "generated/torch.nn.InstanceNorm3d.rst", "generated/torch.nn.KLDivLoss.rst", "generated/torch.nn.L1Loss.rst", "generated/torch.nn.LPPool1d.rst", "generated/torch.nn.LPPool2d.rst", "generated/torch.nn.LSTM.rst", "generated/torch.nn.LSTMCell.rst", "generated/torch.nn.LayerNorm.rst", "generated/torch.nn.LazyBatchNorm1d.rst", "generated/torch.nn.LazyBatchNorm2d.rst", "generated/torch.nn.LazyBatchNorm3d.rst", "generated/torch.nn.LazyConv1d.rst", "generated/torch.nn.LazyConv2d.rst", "generated/torch.nn.LazyConv3d.rst", "generated/torch.nn.LazyConvTranspose1d.rst", "generated/torch.nn.LazyConvTranspose2d.rst", "generated/torch.nn.LazyConvTranspose3d.rst", "generated/torch.nn.LazyInstanceNorm1d.rst", "generated/torch.nn.LazyInstanceNorm2d.rst", "generated/torch.nn.LazyInstanceNorm3d.rst", "generated/torch.nn.LazyLinear.rst", "generated/torch.nn.LeakyReLU.rst", "generated/torch.nn.Linear.rst", "generated/torch.nn.LocalResponseNorm.rst", "generated/torch.nn.LogSigmoid.rst", "generated/torch.nn.LogSoftmax.rst", "generated/torch.nn.MSELoss.rst", "generated/torch.nn.MarginRankingLoss.rst", "generated/torch.nn.MaxPool1d.rst", "generated/torch.nn.MaxPool2d.rst", "generated/torch.nn.MaxPool3d.rst", "generated/torch.nn.MaxUnpool1d.rst", "generated/torch.nn.MaxUnpool2d.rst", "generated/torch.nn.MaxUnpool3d.rst", "generated/torch.nn.Mish.rst", "generated/torch.nn.Module.rst", "generated/torch.nn.ModuleDict.rst", "generated/torch.nn.ModuleList.rst", "generated/torch.nn.MultiLabelMarginLoss.rst", "generated/torch.nn.MultiLabelSoftMarginLoss.rst", "generated/torch.nn.MultiMarginLoss.rst", "generated/torch.nn.MultiheadAttention.rst", "generated/torch.nn.NLLLoss.rst", "generated/torch.nn.PReLU.rst", "generated/torch.nn.PairwiseDistance.rst", "generated/torch.nn.ParameterDict.rst", "generated/torch.nn.ParameterList.rst", "generated/torch.nn.PixelShuffle.rst", "generated/torch.nn.PixelUnshuffle.rst", "generated/torch.nn.PoissonNLLLoss.rst", "generated/torch.nn.RNN.rst", "generated/torch.nn.RNNBase.rst", "generated/torch.nn.RNNCell.rst", "generated/torch.nn.RReLU.rst", "generated/torch.nn.ReLU.rst", "generated/torch.nn.ReLU6.rst", "generated/torch.nn.ReflectionPad1d.rst", "generated/torch.nn.ReflectionPad2d.rst", "generated/torch.nn.ReflectionPad3d.rst", "generated/torch.nn.ReplicationPad1d.rst", "generated/torch.nn.ReplicationPad2d.rst", "generated/torch.nn.ReplicationPad3d.rst", "generated/torch.nn.SELU.rst", "generated/torch.nn.Sequential.rst", "generated/torch.nn.SiLU.rst", "generated/torch.nn.Sigmoid.rst", "generated/torch.nn.SmoothL1Loss.rst", "generated/torch.nn.SoftMarginLoss.rst", "generated/torch.nn.Softmax.rst", "generated/torch.nn.Softmax2d.rst", "generated/torch.nn.Softmin.rst", "generated/torch.nn.Softplus.rst", "generated/torch.nn.Softshrink.rst", "generated/torch.nn.Softsign.rst", "generated/torch.nn.SyncBatchNorm.rst", "generated/torch.nn.Tanh.rst", "generated/torch.nn.Tanhshrink.rst", "generated/torch.nn.Threshold.rst", "generated/torch.nn.Transformer.rst", "generated/torch.nn.TransformerDecoder.rst", "generated/torch.nn.TransformerDecoderLayer.rst", "generated/torch.nn.TransformerEncoder.rst", "generated/torch.nn.TransformerEncoderLayer.rst", "generated/torch.nn.TripletMarginLoss.rst", "generated/torch.nn.TripletMarginWithDistanceLoss.rst", "generated/torch.nn.Unflatten.rst", "generated/torch.nn.Unfold.rst", "generated/torch.nn.Upsample.rst", "generated/torch.nn.UpsamplingBilinear2d.rst", "generated/torch.nn.UpsamplingNearest2d.rst", "generated/torch.nn.ZeroPad2d.rst", "generated/torch.nn.functional.adaptive_avg_pool1d.rst", "generated/torch.nn.functional.adaptive_avg_pool2d.rst", "generated/torch.nn.functional.adaptive_avg_pool3d.rst", "generated/torch.nn.functional.adaptive_max_pool1d.rst", "generated/torch.nn.functional.adaptive_max_pool2d.rst", "generated/torch.nn.functional.adaptive_max_pool3d.rst", "generated/torch.nn.functional.affine_grid.rst", "generated/torch.nn.functional.alpha_dropout.rst", "generated/torch.nn.functional.avg_pool1d.rst", "generated/torch.nn.functional.avg_pool2d.rst", "generated/torch.nn.functional.avg_pool3d.rst", "generated/torch.nn.functional.batch_norm.rst", "generated/torch.nn.functional.bilinear.rst", "generated/torch.nn.functional.binary_cross_entropy.rst", "generated/torch.nn.functional.binary_cross_entropy_with_logits.rst", "generated/torch.nn.functional.celu.rst", "generated/torch.nn.functional.conv1d.rst", "generated/torch.nn.functional.conv2d.rst", "generated/torch.nn.functional.conv3d.rst", "generated/torch.nn.functional.conv_transpose1d.rst", "generated/torch.nn.functional.conv_transpose2d.rst", "generated/torch.nn.functional.conv_transpose3d.rst", "generated/torch.nn.functional.cosine_embedding_loss.rst", "generated/torch.nn.functional.cosine_similarity.rst", "generated/torch.nn.functional.cross_entropy.rst", "generated/torch.nn.functional.ctc_loss.rst", "generated/torch.nn.functional.dropout.rst", "generated/torch.nn.functional.dropout1d.rst", "generated/torch.nn.functional.dropout2d.rst", "generated/torch.nn.functional.dropout3d.rst", "generated/torch.nn.functional.elu.rst", "generated/torch.nn.functional.elu_.rst", "generated/torch.nn.functional.embedding.rst", "generated/torch.nn.functional.embedding_bag.rst", "generated/torch.nn.functional.feature_alpha_dropout.rst", "generated/torch.nn.functional.fold.rst", "generated/torch.nn.functional.fractional_max_pool2d.rst", "generated/torch.nn.functional.fractional_max_pool3d.rst", "generated/torch.nn.functional.gaussian_nll_loss.rst", "generated/torch.nn.functional.gelu.rst", "generated/torch.nn.functional.glu.rst", "generated/torch.nn.functional.grid_sample.rst", "generated/torch.nn.functional.group_norm.rst", "generated/torch.nn.functional.gumbel_softmax.rst", "generated/torch.nn.functional.hardshrink.rst", "generated/torch.nn.functional.hardsigmoid.rst", "generated/torch.nn.functional.hardswish.rst", "generated/torch.nn.functional.hardtanh.rst", "generated/torch.nn.functional.hardtanh_.rst", "generated/torch.nn.functional.hinge_embedding_loss.rst", "generated/torch.nn.functional.huber_loss.rst", "generated/torch.nn.functional.instance_norm.rst", "generated/torch.nn.functional.interpolate.rst", "generated/torch.nn.functional.kl_div.rst", "generated/torch.nn.functional.l1_loss.rst", "generated/torch.nn.functional.layer_norm.rst", "generated/torch.nn.functional.leaky_relu.rst", "generated/torch.nn.functional.leaky_relu_.rst", "generated/torch.nn.functional.linear.rst", "generated/torch.nn.functional.local_response_norm.rst", "generated/torch.nn.functional.log_softmax.rst", "generated/torch.nn.functional.logsigmoid.rst", "generated/torch.nn.functional.lp_pool1d.rst", "generated/torch.nn.functional.lp_pool2d.rst", "generated/torch.nn.functional.margin_ranking_loss.rst", "generated/torch.nn.functional.max_pool1d.rst", "generated/torch.nn.functional.max_pool2d.rst", "generated/torch.nn.functional.max_pool3d.rst", "generated/torch.nn.functional.max_unpool1d.rst", "generated/torch.nn.functional.max_unpool2d.rst", "generated/torch.nn.functional.max_unpool3d.rst", "generated/torch.nn.functional.mish.rst", "generated/torch.nn.functional.mse_loss.rst", "generated/torch.nn.functional.multi_margin_loss.rst", "generated/torch.nn.functional.multilabel_margin_loss.rst", "generated/torch.nn.functional.multilabel_soft_margin_loss.rst", "generated/torch.nn.functional.nll_loss.rst", "generated/torch.nn.functional.normalize.rst", "generated/torch.nn.functional.one_hot.rst", "generated/torch.nn.functional.pad.rst", "generated/torch.nn.functional.pairwise_distance.rst", "generated/torch.nn.functional.pdist.rst", "generated/torch.nn.functional.pixel_shuffle.rst", "generated/torch.nn.functional.pixel_unshuffle.rst", "generated/torch.nn.functional.poisson_nll_loss.rst", "generated/torch.nn.functional.prelu.rst", "generated/torch.nn.functional.relu.rst", "generated/torch.nn.functional.relu6.rst", "generated/torch.nn.functional.relu_.rst", "generated/torch.nn.functional.rrelu.rst", "generated/torch.nn.functional.rrelu_.rst", "generated/torch.nn.functional.selu.rst", "generated/torch.nn.functional.sigmoid.rst", "generated/torch.nn.functional.silu.rst", "generated/torch.nn.functional.smooth_l1_loss.rst", "generated/torch.nn.functional.soft_margin_loss.rst", "generated/torch.nn.functional.softmax.rst", "generated/torch.nn.functional.softmin.rst", "generated/torch.nn.functional.softplus.rst", "generated/torch.nn.functional.softshrink.rst", "generated/torch.nn.functional.softsign.rst", "generated/torch.nn.functional.tanh.rst", "generated/torch.nn.functional.tanhshrink.rst", "generated/torch.nn.functional.threshold.rst", "generated/torch.nn.functional.threshold_.rst", "generated/torch.nn.functional.torch.nn.parallel.data_parallel.rst", "generated/torch.nn.functional.triplet_margin_loss.rst", "generated/torch.nn.functional.triplet_margin_with_distance_loss.rst", "generated/torch.nn.functional.unfold.rst", "generated/torch.nn.functional.upsample.rst", "generated/torch.nn.functional.upsample_bilinear.rst", "generated/torch.nn.functional.upsample_nearest.rst", "generated/torch.nn.modules.lazy.LazyModuleMixin.rst", "generated/torch.nn.modules.module.register_module_backward_hook.rst", "generated/torch.nn.modules.module.register_module_forward_hook.rst", "generated/torch.nn.modules.module.register_module_forward_pre_hook.rst", "generated/torch.nn.modules.module.register_module_full_backward_hook.rst", "generated/torch.nn.parallel.DistributedDataParallel.rst", "generated/torch.nn.parameter.Parameter.rst", "generated/torch.nn.parameter.UninitializedBuffer.rst", "generated/torch.nn.parameter.UninitializedParameter.rst", "generated/torch.nn.quantizable.LSTM.rst", "generated/torch.nn.quantizable.MultiheadAttention.rst", "generated/torch.nn.utils.clip_grad_norm_.rst", "generated/torch.nn.utils.clip_grad_value_.rst", "generated/torch.nn.utils.parameters_to_vector.rst", "generated/torch.nn.utils.parametrizations.orthogonal.rst", "generated/torch.nn.utils.parametrizations.spectral_norm.rst", "generated/torch.nn.utils.parametrize.ParametrizationList.rst", "generated/torch.nn.utils.parametrize.cached.rst", "generated/torch.nn.utils.parametrize.is_parametrized.rst", "generated/torch.nn.utils.parametrize.register_parametrization.rst", "generated/torch.nn.utils.parametrize.remove_parametrizations.rst", "generated/torch.nn.utils.prune.BasePruningMethod.rst", "generated/torch.nn.utils.prune.CustomFromMask.rst", "generated/torch.nn.utils.prune.Identity.rst", "generated/torch.nn.utils.prune.L1Unstructured.rst", "generated/torch.nn.utils.prune.LnStructured.rst", "generated/torch.nn.utils.prune.PruningContainer.rst", "generated/torch.nn.utils.prune.RandomStructured.rst", "generated/torch.nn.utils.prune.RandomUnstructured.rst", "generated/torch.nn.utils.prune.custom_from_mask.rst", "generated/torch.nn.utils.prune.global_unstructured.rst", "generated/torch.nn.utils.prune.identity.rst", "generated/torch.nn.utils.prune.is_pruned.rst", "generated/torch.nn.utils.prune.l1_unstructured.rst", "generated/torch.nn.utils.prune.ln_structured.rst", "generated/torch.nn.utils.prune.random_structured.rst", "generated/torch.nn.utils.prune.random_unstructured.rst", "generated/torch.nn.utils.prune.remove.rst", "generated/torch.nn.utils.remove_spectral_norm.rst", "generated/torch.nn.utils.remove_weight_norm.rst", "generated/torch.nn.utils.rnn.PackedSequence.rst", "generated/torch.nn.utils.rnn.pack_padded_sequence.rst", "generated/torch.nn.utils.rnn.pack_sequence.rst", "generated/torch.nn.utils.rnn.pad_packed_sequence.rst", "generated/torch.nn.utils.rnn.pad_sequence.rst", "generated/torch.nn.utils.skip_init.rst", "generated/torch.nn.utils.spectral_norm.rst", "generated/torch.nn.utils.stateless.functional_call.rst", "generated/torch.nn.utils.vector_to_parameters.rst", "generated/torch.nn.utils.weight_norm.rst", "generated/torch.no_grad.rst", "generated/torch.nonzero.rst", "generated/torch.norm.rst", "generated/torch.normal.rst", "generated/torch.not_equal.rst", "generated/torch.numel.rst", "generated/torch.ones.rst", "generated/torch.ones_like.rst", "generated/torch.onnx.JitScalarType.rst", "generated/torch.optim.ASGD.rst", "generated/torch.optim.Adadelta.rst", "generated/torch.optim.Adagrad.rst", "generated/torch.optim.Adam.rst", "generated/torch.optim.AdamW.rst", "generated/torch.optim.Adamax.rst", "generated/torch.optim.LBFGS.rst", "generated/torch.optim.NAdam.rst", "generated/torch.optim.Optimizer.add_param_group.rst", "generated/torch.optim.Optimizer.load_state_dict.rst", "generated/torch.optim.Optimizer.state_dict.rst", "generated/torch.optim.Optimizer.step.rst", "generated/torch.optim.Optimizer.zero_grad.rst", "generated/torch.optim.RAdam.rst", "generated/torch.optim.RMSprop.rst", "generated/torch.optim.Rprop.rst", "generated/torch.optim.SGD.rst", "generated/torch.optim.SparseAdam.rst", "generated/torch.optim.lr_scheduler.ChainedScheduler.rst", "generated/torch.optim.lr_scheduler.ConstantLR.rst", "generated/torch.optim.lr_scheduler.CosineAnnealingLR.rst", "generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.rst", "generated/torch.optim.lr_scheduler.CyclicLR.rst", "generated/torch.optim.lr_scheduler.ExponentialLR.rst", "generated/torch.optim.lr_scheduler.LambdaLR.rst", "generated/torch.optim.lr_scheduler.LinearLR.rst", "generated/torch.optim.lr_scheduler.MultiStepLR.rst", "generated/torch.optim.lr_scheduler.MultiplicativeLR.rst", "generated/torch.optim.lr_scheduler.OneCycleLR.rst", "generated/torch.optim.lr_scheduler.PolynomialLR.rst", "generated/torch.optim.lr_scheduler.ReduceLROnPlateau.rst", "generated/torch.optim.lr_scheduler.SequentialLR.rst", "generated/torch.optim.lr_scheduler.StepLR.rst", "generated/torch.orgqr.rst", "generated/torch.ormqr.rst", "generated/torch.outer.rst", "generated/torch.pca_lowrank.rst", "generated/torch.permute.rst", "generated/torch.pinverse.rst", "generated/torch.poisson.rst", "generated/torch.polar.rst", "generated/torch.polygamma.rst", "generated/torch.positive.rst", "generated/torch.pow.rst", "generated/torch.prod.rst", "generated/torch.promote_types.rst", "generated/torch.qr.rst", "generated/torch.quantile.rst", "generated/torch.quantization.DeQuantStub.rst", "generated/torch.quantization.QuantStub.rst", "generated/torch.quantization.QuantWrapper.rst", "generated/torch.quantization.add_quant_dequant.rst", "generated/torch.quantization.convert.rst", "generated/torch.quantization.default_eval_fn.rst", "generated/torch.quantization.fake_quantize.FakeQuantize.rst", "generated/torch.quantization.fake_quantize.FakeQuantizeBase.rst", "generated/torch.quantization.fake_quantize.FixedQParamsFakeQuantize.rst", "generated/torch.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize.rst", "generated/torch.quantization.fake_quantize.default_fake_quant.rst", "generated/torch.quantization.fake_quantize.default_fused_act_fake_quant.rst", "generated/torch.quantization.fake_quantize.default_fused_per_channel_wt_fake_quant.rst", "generated/torch.quantization.fake_quantize.default_fused_wt_fake_quant.rst", "generated/torch.quantization.fake_quantize.default_histogram_fake_quant.rst", "generated/torch.quantization.fake_quantize.default_per_channel_weight_fake_quant.rst", "generated/torch.quantization.fake_quantize.default_weight_fake_quant.rst", "generated/torch.quantization.fake_quantize.disable_fake_quant.rst", "generated/torch.quantization.fake_quantize.disable_observer.rst", "generated/torch.quantization.fake_quantize.enable_fake_quant.rst", "generated/torch.quantization.fake_quantize.enable_observer.rst", "generated/torch.quantization.fuse_modules.rst", "generated/torch.quantization.observer.HistogramObserver.rst", "generated/torch.quantization.observer.MinMaxObserver.rst", "generated/torch.quantization.observer.MovingAverageMinMaxObserver.rst", "generated/torch.quantization.observer.MovingAveragePerChannelMinMaxObserver.rst", "generated/torch.quantization.observer.NoopObserver.rst", "generated/torch.quantization.observer.ObserverBase.rst", "generated/torch.quantization.observer.PerChannelMinMaxObserver.rst", "generated/torch.quantization.observer.PlaceholderObserver.rst", "generated/torch.quantization.observer.RecordingObserver.rst", "generated/torch.quantization.observer.default_debug_observer.rst", "generated/torch.quantization.observer.default_dynamic_quant_observer.rst", "generated/torch.quantization.observer.default_float_qparams_observer.rst", "generated/torch.quantization.observer.default_histogram_observer.rst", "generated/torch.quantization.observer.default_observer.rst", "generated/torch.quantization.observer.default_per_channel_weight_observer.rst", "generated/torch.quantization.observer.default_placeholder_observer.rst", "generated/torch.quantization.observer.default_weight_observer.rst", "generated/torch.quantization.observer.get_observer_state_dict.rst", "generated/torch.quantization.observer.load_observer_state_dict.rst", "generated/torch.quantization.prepare.rst", "generated/torch.quantization.prepare_qat.rst", "generated/torch.quantization.propagate_qconfig_.rst", "generated/torch.quantization.qconfig.QConfig.rst", "generated/torch.quantization.qconfig.default_activation_only_qconfig.rst", "generated/torch.quantization.qconfig.default_debug_qconfig.rst", "generated/torch.quantization.qconfig.default_dynamic_qconfig.rst", "generated/torch.quantization.qconfig.default_per_channel_qconfig.rst", "generated/torch.quantization.qconfig.default_qat_qconfig.rst", "generated/torch.quantization.qconfig.default_qat_qconfig_v2.rst", "generated/torch.quantization.qconfig.default_qconfig.rst", "generated/torch.quantization.qconfig.default_weight_only_qconfig.rst", "generated/torch.quantization.qconfig.float16_dynamic_qconfig.rst", "generated/torch.quantization.qconfig.float16_static_qconfig.rst", "generated/torch.quantization.qconfig.float_qparams_weight_only_qconfig.rst", "generated/torch.quantization.qconfig.per_channel_dynamic_qconfig.rst", "generated/torch.quantization.quantize.rst", "generated/torch.quantization.quantize_dynamic.rst", "generated/torch.quantization.quantize_fx.convert_fx.rst", "generated/torch.quantization.quantize_fx.fuse_fx.rst", "generated/torch.quantization.quantize_fx.prepare_fx.rst", "generated/torch.quantization.quantize_fx.prepare_qat_fx.rst", "generated/torch.quantization.quantize_qat.rst", "generated/torch.quantization.swap_module.rst", "generated/torch.quantize_per_channel.rst", "generated/torch.quantize_per_tensor.rst", "generated/torch.quantized_batch_norm.rst", "generated/torch.quantized_max_pool1d.rst", "generated/torch.quantized_max_pool2d.rst", "generated/torch.quasirandom.SobolEngine.rst", "generated/torch.rad2deg.rst", "generated/torch.rand.rst", "generated/torch.rand_like.rst", "generated/torch.randint.rst", "generated/torch.randint_like.rst", "generated/torch.randn.rst", "generated/torch.randn_like.rst", "generated/torch.randperm.rst", "generated/torch.range.rst", "generated/torch.ravel.rst", "generated/torch.real.rst", "generated/torch.reciprocal.rst", "generated/torch.remainder.rst", "generated/torch.renorm.rst", "generated/torch.repeat_interleave.rst", "generated/torch.reshape.rst", "generated/torch.resolve_conj.rst", "generated/torch.resolve_neg.rst", "generated/torch.result_type.rst", "generated/torch.roll.rst", "generated/torch.rot90.rst", "generated/torch.round.rst", "generated/torch.row_stack.rst", "generated/torch.rsqrt.rst", "generated/torch.save.rst", "generated/torch.scatter.rst", "generated/torch.scatter_add.rst", "generated/torch.scatter_reduce.rst", "generated/torch.searchsorted.rst", "generated/torch.seed.rst", "generated/torch.select.rst", "generated/torch.select_scatter.rst", "generated/torch.set_default_device.rst", "generated/torch.set_default_dtype.rst", "generated/torch.set_default_tensor_type.rst", "generated/torch.set_deterministic_debug_mode.rst", "generated/torch.set_float32_matmul_precision.rst", "generated/torch.set_flush_denormal.rst", "generated/torch.set_grad_enabled.rst", "generated/torch.set_num_interop_threads.rst", "generated/torch.set_num_threads.rst", "generated/torch.set_printoptions.rst", "generated/torch.set_rng_state.rst", "generated/torch.set_warn_always.rst", "generated/torch.sgn.rst", "generated/torch.sigmoid.rst", "generated/torch.sign.rst", "generated/torch.signal.windows.bartlett.rst", "generated/torch.signal.windows.blackman.rst", "generated/torch.signal.windows.cosine.rst", "generated/torch.signal.windows.exponential.rst", "generated/torch.signal.windows.gaussian.rst", "generated/torch.signal.windows.general_cosine.rst", "generated/torch.signal.windows.general_hamming.rst", "generated/torch.signal.windows.hamming.rst", "generated/torch.signal.windows.hann.rst", "generated/torch.signal.windows.kaiser.rst", "generated/torch.signal.windows.nuttall.rst", "generated/torch.signbit.rst", "generated/torch.sin.rst", "generated/torch.sinc.rst", "generated/torch.sinh.rst", "generated/torch.slice_scatter.rst", "generated/torch.slogdet.rst", "generated/torch.smm.rst", "generated/torch.softmax.rst", "generated/torch.sort.rst", "generated/torch.sparse.addmm.rst", "generated/torch.sparse.log_softmax.rst", "generated/torch.sparse.mm.rst", "generated/torch.sparse.sampled_addmm.rst", "generated/torch.sparse.softmax.rst", "generated/torch.sparse.spdiags.rst", "generated/torch.sparse.sum.rst", "generated/torch.sparse_bsc_tensor.rst", "generated/torch.sparse_bsr_tensor.rst", "generated/torch.sparse_compressed_tensor.rst", "generated/torch.sparse_coo_tensor.rst", "generated/torch.sparse_csc_tensor.rst", "generated/torch.sparse_csr_tensor.rst", "generated/torch.split.rst", "generated/torch.sqrt.rst", "generated/torch.square.rst", "generated/torch.squeeze.rst", "generated/torch.sspaddmm.rst", "generated/torch.stack.rst", "generated/torch.std.rst", "generated/torch.std_mean.rst", "generated/torch.stft.rst", "generated/torch.sub.rst", "generated/torch.subtract.rst", "generated/torch.sum.rst", "generated/torch.svd.rst", "generated/torch.svd_lowrank.rst", "generated/torch.swapaxes.rst", "generated/torch.swapdims.rst", "generated/torch.sym_float.rst", "generated/torch.sym_int.rst", "generated/torch.symeig.rst", "generated/torch.t.rst", "generated/torch.take.rst", "generated/torch.take_along_dim.rst", "generated/torch.tan.rst", "generated/torch.tanh.rst", "generated/torch.tensor.rst", "generated/torch.tensor_split.rst", "generated/torch.tensordot.rst", "generated/torch.tile.rst", "generated/torch.topk.rst", "generated/torch.trace.rst", "generated/torch.transpose.rst", "generated/torch.trapezoid.rst", "generated/torch.trapz.rst", "generated/torch.triangular_solve.rst", "generated/torch.tril.rst", "generated/torch.tril_indices.rst", "generated/torch.triu.rst", "generated/torch.triu_indices.rst", "generated/torch.true_divide.rst", "generated/torch.trunc.rst", "generated/torch.unbind.rst", "generated/torch.unflatten.rst", "generated/torch.unique.rst", "generated/torch.unique_consecutive.rst", "generated/torch.unsqueeze.rst", "generated/torch.use_deterministic_algorithms.rst", "generated/torch.vander.rst", "generated/torch.var.rst", "generated/torch.var_mean.rst", "generated/torch.vdot.rst", "generated/torch.view_as_complex.rst", "generated/torch.view_as_real.rst", "generated/torch.vmap.rst", "generated/torch.vsplit.rst", "generated/torch.vstack.rst", "generated/torch.where.rst", "generated/torch.xlogy.rst", "generated/torch.zeros.rst", "generated/torch.zeros_like.rst", "hub.rst", "index.rst", "ir.rst", "jit.rst", "jit_builtin_functions.rst", "jit_language_reference.rst", "jit_language_reference_v2.rst", "jit_python_reference.rst", "jit_unsupported.rst", "jit_utils.rst", "library.rst", "linalg.rst", "masked.rst", "mobile_optimizer.rst", "model_zoo.rst", "monitor.rst", "multiprocessing.rst", "name_inference.rst", "named_tensor.rst", "nested.rst", "nn.rst", "nn.functional.rst", "nn.init.rst", "notes/amp_examples.rst", "notes/autograd.rst", "notes/broadcasting.rst", "notes/cpu_threading_torchscript_inference.rst", "notes/cuda.rst", "notes/ddp.rst", "notes/extending.rst", "notes/extending.func.rst", "notes/faq.rst", "notes/gradcheck.rst", "notes/hip.rst", "notes/large_scale_deployments.rst", "notes/modules.rst", "notes/mps.rst", "notes/multiprocessing.rst", "notes/numerical_accuracy.rst", "notes/randomness.rst", "notes/serialization.rst", "notes/windows.rst", "onnx.rst", "onnx_diagnostics.rst", "onnx_supported_aten_ops.rst", "optim.rst", "package.rst", "pipeline.rst", "profiler.rst", "quantization.rst", "quantization-accuracy-debugging.rst", "quantization-backend-configuration.rst", "quantization-support.rst", "random.rst", "rpc.rst", "rpc/distributed_autograd.rst", "rpc/rref.rst", "signal.rst", "sparse.rst", "special.rst", "storage.rst", "tensor_attributes.rst", "tensor_view.rst", "tensorboard.rst", "tensors.rst", "testing.rst", "torch.rst", "torch.ao.ns._numeric_suite.rst", "torch.ao.ns._numeric_suite_fx.rst", "torch.overrides.rst", "type_info.rst"], "titles": ["torch._dynamo", "Automatic Mixed Precision package - torch.amp", "Automatic differentiation package - torch.autograd", "torch.backends", "Benchmark Utils - torch.utils.benchmark", "torch.utils.bottleneck", "torch.utils.checkpoint", "PyTorch Governance | Build + CI", "PyTorch Contribution Guide", "PyTorch Design Philosophy", "PyTorch Governance | Mechanics", "PyTorch Governance | Maintainers", "Complex Numbers", "torch.__config__", "torch.utils.cpp_extension", "C++", "torch.cuda", "CUDA Stream Sanitizer", "&lt;no title&gt;", "&lt;no title&gt;", "torch.utils.data", "DDP Communication Hooks", "torch::deploy has been moved to pytorch/multipy", "Distributed communication package - torch.distributed", "Generic Join Context Manager", "Distributed Checkpoint", "Torch Distributed Elastic", "Distributed Optimizers", "Tensor Parallelism", "Probability distributions - torch.distributions", "torch.utils.dlpack", "Custom Backends", "TorchDynamo Deeper Dive", "Frequently Asked Questions", "Getting Started", "Guards Overview", "TorchDynamo Overview", "Installing TorchDynamo", "TorchDynamo Troubleshooting", "Elastic Agent", "Customization", "Error Propagation", "Events", "Examples", "TorchElastic Kubernetes", "Metrics", "Multiprocessing", "Quickstart", "Rendezvous", "torchrun (Elastic Launch)", "Expiration Timers", "Train script", "torch.fft", "FullyShardedDataParallel", "torch.func", "torch.func API Reference", "Patching Batch Norm", "UX Limitations", "torch.func Whirlwind Tour", "torch.futures", "torch.fx", "POE0001:node-missing-onnx-shape-inference", "POE0002:missing-custom-symbolic-function", "POE0003:missing-standard-symbolic-function", "POE0004:operator-supported-in-newer-opset-version", "Generator", "torch.Tensor.abs", "torch.Tensor.abs_", "torch.Tensor.absolute", "torch.Tensor.absolute_", "torch.Tensor.acos", "torch.Tensor.acos_", "torch.Tensor.acosh", "torch.Tensor.acosh_", "torch.Tensor.add", "torch.Tensor.add_", "torch.Tensor.addbmm", "torch.Tensor.addbmm_", "torch.Tensor.addcdiv", "torch.Tensor.addcdiv_", "torch.Tensor.addcmul", "torch.Tensor.addcmul_", "torch.Tensor.addmm", "torch.Tensor.addmm_", "torch.Tensor.addmv", "torch.Tensor.addmv_", "torch.Tensor.addr", "torch.Tensor.addr_", "torch.Tensor.adjoint", "torch.Tensor.all", "torch.Tensor.allclose", "torch.Tensor.amax", "torch.Tensor.amin", "torch.Tensor.aminmax", "torch.Tensor.angle", "torch.Tensor.any", "torch.Tensor.apply_", "torch.Tensor.arccos", "torch.Tensor.arccos_", "torch.Tensor.arccosh", "torch.Tensor.arccosh_", "torch.Tensor.arcsin", "torch.Tensor.arcsin_", "torch.Tensor.arcsinh", "torch.Tensor.arcsinh_", "torch.Tensor.arctan", "torch.Tensor.arctan2", "torch.Tensor.arctan2_", "torch.Tensor.arctan_", "torch.Tensor.arctanh", "torch.Tensor.arctanh_", "torch.Tensor.argmax", "torch.Tensor.argmin", "torch.Tensor.argsort", "torch.Tensor.argwhere", "torch.Tensor.as_strided", "torch.Tensor.as_subclass", "torch.Tensor.asin", "torch.Tensor.asin_", "torch.Tensor.asinh", "torch.Tensor.asinh_", "torch.Tensor.atan", "torch.Tensor.atan2", "torch.Tensor.atan2_", "torch.Tensor.atan_", "torch.Tensor.atanh", "torch.Tensor.atanh_", "torch.Tensor.backward", "torch.Tensor.baddbmm", "torch.Tensor.baddbmm_", "torch.Tensor.bernoulli", "torch.Tensor.bernoulli_", "torch.Tensor.bfloat16", "torch.Tensor.bincount", "torch.Tensor.bitwise_and", "torch.Tensor.bitwise_and_", "torch.Tensor.bitwise_left_shift", "torch.Tensor.bitwise_left_shift_", "torch.Tensor.bitwise_not", "torch.Tensor.bitwise_not_", "torch.Tensor.bitwise_or", "torch.Tensor.bitwise_or_", "torch.Tensor.bitwise_right_shift", "torch.Tensor.bitwise_right_shift_", "torch.Tensor.bitwise_xor", "torch.Tensor.bitwise_xor_", "torch.Tensor.bmm", "torch.Tensor.bool", "torch.Tensor.broadcast_to", "torch.Tensor.byte", "torch.Tensor.cauchy_", "torch.Tensor.ccol_indices", "torch.Tensor.cdouble", "torch.Tensor.ceil", "torch.Tensor.ceil_", "torch.Tensor.cfloat", "torch.Tensor.chalf", "torch.Tensor.char", "torch.Tensor.cholesky", "torch.Tensor.cholesky_inverse", "torch.Tensor.cholesky_solve", "torch.Tensor.chunk", "torch.Tensor.clamp", "torch.Tensor.clamp_", "torch.Tensor.clip", "torch.Tensor.clip_", "torch.Tensor.clone", "torch.Tensor.coalesce", "torch.Tensor.col_indices", "torch.Tensor.conj", "torch.Tensor.conj_physical", "torch.Tensor.conj_physical_", "torch.Tensor.contiguous", "torch.Tensor.copy_", "torch.Tensor.copysign", "torch.Tensor.copysign_", "torch.Tensor.corrcoef", "torch.Tensor.cos", "torch.Tensor.cos_", "torch.Tensor.cosh", "torch.Tensor.cosh_", "torch.Tensor.count_nonzero", "torch.Tensor.cov", "torch.Tensor.cpu", "torch.Tensor.cross", "torch.Tensor.crow_indices", "torch.Tensor.cuda", "torch.Tensor.cummax", "torch.Tensor.cummin", "torch.Tensor.cumprod", "torch.Tensor.cumprod_", "torch.Tensor.cumsum", "torch.Tensor.cumsum_", "torch.Tensor.data_ptr", "torch.Tensor.deg2rad", "torch.Tensor.dense_dim", "torch.Tensor.dequantize", "torch.Tensor.det", "torch.Tensor.detach", "torch.Tensor.detach_", "torch.Tensor.device", "torch.Tensor.diag", "torch.Tensor.diag_embed", "torch.Tensor.diagflat", "torch.Tensor.diagonal", "torch.Tensor.diagonal_scatter", "torch.Tensor.diff", "torch.Tensor.digamma", "torch.Tensor.digamma_", "torch.Tensor.dim", "torch.Tensor.dist", "torch.Tensor.div", "torch.Tensor.div_", "torch.Tensor.divide", "torch.Tensor.divide_", "torch.Tensor.dot", "torch.Tensor.double", "torch.Tensor.dsplit", "torch.Tensor.element_size", "torch.Tensor.eq", "torch.Tensor.eq_", "torch.Tensor.equal", "torch.Tensor.erf", "torch.Tensor.erf_", "torch.Tensor.erfc", "torch.Tensor.erfc_", "torch.Tensor.erfinv", "torch.Tensor.erfinv_", "torch.Tensor.exp", "torch.Tensor.exp_", "torch.Tensor.expand", "torch.Tensor.expand_as", "torch.Tensor.expm1", "torch.Tensor.expm1_", "torch.Tensor.exponential_", "torch.Tensor.fill_", "torch.Tensor.fill_diagonal_", "torch.Tensor.fix", "torch.Tensor.fix_", "torch.Tensor.flatten", "torch.Tensor.flip", "torch.Tensor.fliplr", "torch.Tensor.flipud", "torch.Tensor.float", "torch.Tensor.float_power", "torch.Tensor.float_power_", "torch.Tensor.floor", "torch.Tensor.floor_", "torch.Tensor.floor_divide", "torch.Tensor.floor_divide_", "torch.Tensor.fmax", "torch.Tensor.fmin", "torch.Tensor.fmod", "torch.Tensor.fmod_", "torch.Tensor.frac", "torch.Tensor.frac_", "torch.Tensor.frexp", "torch.Tensor.gather", "torch.Tensor.gcd", "torch.Tensor.gcd_", "torch.Tensor.ge", "torch.Tensor.ge_", "torch.Tensor.geometric_", "torch.Tensor.geqrf", "torch.Tensor.ger", "torch.Tensor.get_device", "torch.Tensor.grad", "torch.Tensor.greater", "torch.Tensor.greater_", "torch.Tensor.greater_equal", "torch.Tensor.greater_equal_", "torch.Tensor.gt", "torch.Tensor.gt_", "torch.Tensor.half", "torch.Tensor.hardshrink", "torch.Tensor.heaviside", "torch.Tensor.histc", "torch.Tensor.histogram", "torch.Tensor.hsplit", "torch.Tensor.hypot", "torch.Tensor.hypot_", "torch.Tensor.i0", "torch.Tensor.i0_", "torch.Tensor.igamma", "torch.Tensor.igamma_", "torch.Tensor.igammac", "torch.Tensor.igammac_", "torch.Tensor.imag", "torch.Tensor.index_add", "torch.Tensor.index_add_", "torch.Tensor.index_copy", "torch.Tensor.index_copy_", "torch.Tensor.index_fill", "torch.Tensor.index_fill_", "torch.Tensor.index_put", "torch.Tensor.index_put_", "torch.Tensor.index_reduce", "torch.Tensor.index_reduce_", "torch.Tensor.index_select", "torch.Tensor.indices", "torch.Tensor.inner", "torch.Tensor.int", "torch.Tensor.int_repr", "torch.Tensor.inverse", "torch.Tensor.is_coalesced", "torch.Tensor.is_complex", "torch.Tensor.is_conj", "torch.Tensor.is_contiguous", "torch.Tensor.is_cuda", "torch.Tensor.is_floating_point", "torch.Tensor.is_inference", "torch.Tensor.is_leaf", "torch.Tensor.is_meta", "torch.Tensor.is_pinned", "torch.Tensor.is_quantized", "torch.Tensor.is_set_to", "torch.Tensor.is_shared", "torch.Tensor.is_signed", "torch.Tensor.is_sparse", "torch.Tensor.is_sparse_csr", "torch.Tensor.isclose", "torch.Tensor.isfinite", "torch.Tensor.isinf", "torch.Tensor.isnan", "torch.Tensor.isneginf", "torch.Tensor.isposinf", "torch.Tensor.isreal", "torch.Tensor.istft", "torch.Tensor.item", "torch.Tensor.kthvalue", "torch.Tensor.lcm", "torch.Tensor.lcm_", "torch.Tensor.ldexp", "torch.Tensor.ldexp_", "torch.Tensor.le", "torch.Tensor.le_", "torch.Tensor.lerp", "torch.Tensor.lerp_", "torch.Tensor.less", "torch.Tensor.less_", "torch.Tensor.less_equal", "torch.Tensor.less_equal_", "torch.Tensor.lgamma", "torch.Tensor.lgamma_", "torch.Tensor.log", "torch.Tensor.log10", "torch.Tensor.log10_", "torch.Tensor.log1p", "torch.Tensor.log1p_", "torch.Tensor.log2", "torch.Tensor.log2_", "torch.Tensor.log_", "torch.Tensor.log_normal_", "torch.Tensor.logaddexp", "torch.Tensor.logaddexp2", "torch.Tensor.logcumsumexp", "torch.Tensor.logdet", "torch.Tensor.logical_and", "torch.Tensor.logical_and_", "torch.Tensor.logical_not", "torch.Tensor.logical_not_", "torch.Tensor.logical_or", "torch.Tensor.logical_or_", "torch.Tensor.logical_xor", "torch.Tensor.logical_xor_", "torch.Tensor.logit", "torch.Tensor.logit_", "torch.Tensor.logsumexp", "torch.Tensor.long", "torch.Tensor.lt", "torch.Tensor.lt_", "torch.Tensor.lu", "torch.Tensor.lu_solve", "torch.Tensor.map_", "torch.Tensor.masked_fill", "torch.Tensor.masked_fill_", "torch.Tensor.masked_scatter", "torch.Tensor.masked_scatter_", "torch.Tensor.masked_select", "torch.Tensor.matmul", "torch.Tensor.matrix_exp", "torch.Tensor.matrix_power", "torch.Tensor.max", "torch.Tensor.maximum", "torch.Tensor.mean", "torch.Tensor.median", "torch.Tensor.min", "torch.Tensor.minimum", "torch.Tensor.mm", "torch.Tensor.mode", "torch.Tensor.moveaxis", "torch.Tensor.movedim", "torch.Tensor.msort", "torch.Tensor.mul", "torch.Tensor.mul_", "torch.Tensor.multinomial", "torch.Tensor.multiply", "torch.Tensor.multiply_", "torch.Tensor.mv", "torch.Tensor.mvlgamma", "torch.Tensor.mvlgamma_", "torch.Tensor.nan_to_num", "torch.Tensor.nan_to_num_", "torch.Tensor.nanmean", "torch.Tensor.nanmedian", "torch.Tensor.nanquantile", "torch.Tensor.nansum", "torch.Tensor.narrow", "torch.Tensor.narrow_copy", "torch.Tensor.ndim", "torch.Tensor.ndimension", "torch.Tensor.ne", "torch.Tensor.ne_", "torch.Tensor.neg", "torch.Tensor.neg_", "torch.Tensor.negative", "torch.Tensor.negative_", "torch.Tensor.nelement", "torch.Tensor.new_empty", "torch.Tensor.new_full", "torch.Tensor.new_ones", "torch.Tensor.new_tensor", "torch.Tensor.new_zeros", "torch.Tensor.nextafter", "torch.Tensor.nextafter_", "torch.Tensor.nonzero", "torch.Tensor.norm", "torch.Tensor.normal_", "torch.Tensor.not_equal", "torch.Tensor.not_equal_", "torch.Tensor.numel", "torch.Tensor.numpy", "torch.Tensor.orgqr", "torch.Tensor.ormqr", "torch.Tensor.outer", "torch.Tensor.permute", "torch.Tensor.pin_memory", "torch.Tensor.pinverse", "torch.Tensor.polygamma", "torch.Tensor.polygamma_", "torch.Tensor.positive", "torch.Tensor.pow", "torch.Tensor.pow_", "torch.Tensor.prod", "torch.Tensor.put_", "torch.Tensor.q_per_channel_axis", "torch.Tensor.q_per_channel_scales", "torch.Tensor.q_per_channel_zero_points", "torch.Tensor.q_scale", "torch.Tensor.q_zero_point", "torch.Tensor.qr", "torch.Tensor.qscheme", "torch.Tensor.quantile", "torch.Tensor.rad2deg", "torch.Tensor.random_", "torch.Tensor.ravel", "torch.Tensor.real", "torch.Tensor.reciprocal", "torch.Tensor.reciprocal_", "torch.Tensor.record_stream", "torch.Tensor.register_hook", "torch.Tensor.remainder", "torch.Tensor.remainder_", "torch.Tensor.renorm", "torch.Tensor.renorm_", "torch.Tensor.repeat", "torch.Tensor.repeat_interleave", "torch.Tensor.requires_grad", "torch.Tensor.requires_grad_", "torch.Tensor.reshape", "torch.Tensor.reshape_as", "torch.Tensor.resize_", "torch.Tensor.resize_as_", "torch.Tensor.resolve_conj", "torch.Tensor.resolve_neg", "torch.Tensor.retain_grad", "torch.Tensor.retains_grad", "torch.Tensor.roll", "torch.Tensor.rot90", "torch.Tensor.round", "torch.Tensor.round_", "torch.Tensor.row_indices", "torch.Tensor.rsqrt", "torch.Tensor.rsqrt_", "torch.Tensor.scatter", "torch.Tensor.scatter_", "torch.Tensor.scatter_add", "torch.Tensor.scatter_add_", "torch.Tensor.scatter_reduce", "torch.Tensor.scatter_reduce_", "torch.Tensor.select", "torch.Tensor.select_scatter", "torch.Tensor.set_", "torch.Tensor.sgn", "torch.Tensor.sgn_", "torch.Tensor.share_memory_", "torch.Tensor.short", "torch.Tensor.sigmoid", "torch.Tensor.sigmoid_", "torch.Tensor.sign", "torch.Tensor.sign_", "torch.Tensor.signbit", "torch.Tensor.sin", "torch.Tensor.sin_", "torch.Tensor.sinc", "torch.Tensor.sinc_", "torch.Tensor.sinh", "torch.Tensor.sinh_", "torch.Tensor.size", "torch.Tensor.slice_scatter", "torch.Tensor.slogdet", "torch.Tensor.smm", "torch.Tensor.softmax", "torch.Tensor.sort", "torch.Tensor.sparse_dim", "torch.Tensor.sparse_mask", "torch.Tensor.sparse_resize_", "torch.Tensor.sparse_resize_and_clear_", "torch.Tensor.split", "torch.Tensor.sqrt", "torch.Tensor.sqrt_", "torch.Tensor.square", "torch.Tensor.square_", "torch.Tensor.squeeze", "torch.Tensor.squeeze_", "torch.Tensor.sspaddmm", "torch.Tensor.std", "torch.Tensor.stft", "torch.Tensor.storage", "torch.Tensor.storage_offset", "torch.Tensor.storage_type", "torch.Tensor.stride", "torch.Tensor.sub", "torch.Tensor.sub_", "torch.Tensor.subtract", "torch.Tensor.subtract_", "torch.Tensor.sum", "torch.Tensor.sum_to_size", "torch.Tensor.svd", "torch.Tensor.swapaxes", "torch.Tensor.swapdims", "torch.Tensor.symeig", "torch.Tensor.t", "torch.Tensor.t_", "torch.Tensor.take", "torch.Tensor.take_along_dim", "torch.Tensor.tan", "torch.Tensor.tan_", "torch.Tensor.tanh", "torch.Tensor.tanh_", "torch.Tensor.tensor_split", "torch.Tensor.tile", "torch.Tensor.to", "torch.Tensor.to_dense", "torch.Tensor.to_mkldnn", "torch.Tensor.to_sparse", "torch.Tensor.to_sparse_bsc", "torch.Tensor.to_sparse_bsr", "torch.Tensor.to_sparse_coo", "torch.Tensor.to_sparse_csc", "torch.Tensor.to_sparse_csr", "torch.Tensor.tolist", "torch.Tensor.topk", "torch.Tensor.trace", "torch.Tensor.transpose", "torch.Tensor.transpose_", "torch.Tensor.triangular_solve", "torch.Tensor.tril", "torch.Tensor.tril_", "torch.Tensor.triu", "torch.Tensor.triu_", "torch.Tensor.true_divide", "torch.Tensor.true_divide_", "torch.Tensor.trunc", "torch.Tensor.trunc_", "torch.Tensor.type", "torch.Tensor.type_as", "torch.Tensor.unbind", "torch.Tensor.unflatten", "torch.Tensor.unfold", "torch.Tensor.uniform_", "torch.Tensor.unique", "torch.Tensor.unique_consecutive", "torch.Tensor.unsqueeze", "torch.Tensor.unsqueeze_", "torch.Tensor.untyped_storage", "torch.Tensor.values", "torch.Tensor.var", "torch.Tensor.vdot", "torch.Tensor.view", "torch.Tensor.view_as", "torch.Tensor.vsplit", "torch.Tensor.where", "torch.Tensor.xlogy", "torch.Tensor.xlogy_", "torch.Tensor.zero_", "torch._assert", "torch.abs", "torch.absolute", "torch.acos", "torch.acosh", "torch.add", "torch.addbmm", "torch.addcdiv", "torch.addcmul", "torch.addmm", "torch.addmv", "torch.addr", "torch.adjoint", "torch.all", "torch.allclose", "torch.amax", "torch.amin", "torch.aminmax", "torch.angle", "torch.any", "BNReLU2d", "BNReLU3d", "ConvBn1d", "ConvBn2d", "ConvBn3d", "ConvBnReLU1d", "ConvBnReLU2d", "ConvBnReLU3d", "ConvReLU1d", "ConvReLU2d", "ConvReLU3d", "LinearReLU", "ConvBn1d", "ConvBn2d", "ConvBn3d", "ConvBnReLU1d", "ConvBnReLU2d", "ConvBnReLU3d", "ConvReLU2d", "ConvReLU3d", "LinearReLU", "freeze_bn_stats", "update_bn_stats", "BNReLU2d", "BNReLU3d", "ConvReLU1d", "ConvReLU2d", "ConvReLU3d", "LinearReLU", "LinearReLU", "Conv2d", "Conv3d", "Linear", "Linear", "BatchNorm2d", "BatchNorm3d", "Conv1d", "Conv2d", "Conv3d", "ConvTranspose1d", "ConvTranspose2d", "ConvTranspose3d", "ELU", "Embedding", "EmbeddingBag", "FXFloatFunctional", "FloatFunctional", "GroupNorm", "Hardswish", "InstanceNorm1d", "InstanceNorm2d", "InstanceNorm3d", "LayerNorm", "LeakyReLU", "Linear", "QFunctional", "ReLU6", "Sigmoid", "GRU", "GRUCell", "LSTM", "LSTMCell", "Linear", "RNNCell", "adaptive_avg_pool2d", "adaptive_avg_pool3d", "avg_pool2d", "avg_pool3d", "celu", "clamp", "conv1d", "conv2d", "conv3d", "elu", "hardsigmoid", "hardswish", "hardtanh", "interpolate", "leaky_relu", "linear", "max_pool1d", "max_pool2d", "threshold", "upsample", "upsample_bilinear", "upsample_nearest", "BackendConfig", "BackendPatternConfig", "DTypeConfig", "ObservationType", "ConvertCustomConfig", "FuseCustomConfig", "PrepareCustomConfig", "StandaloneModuleConfigEntry", "QConfigMapping", "get_default_qat_qconfig_mapping", "get_default_qconfig_mapping", "torch.arange", "torch.arccos", "torch.arccosh", "torch.arcsin", "torch.arcsinh", "torch.arctan", "torch.arctan2", "torch.arctanh", "torch.are_deterministic_algorithms_enabled", "torch.argmax", "torch.argmin", "torch.argsort", "torch.argwhere", "torch.as_strided", "torch.as_tensor", "torch.asarray", "torch.asin", "torch.asinh", "torch.atan", "torch.atan2", "torch.atanh", "torch.atleast_1d", "torch.atleast_2d", "torch.atleast_3d", "torch.autograd.Function.backward", "torch.autograd.Function.forward", "torch.autograd.Function.jvp", "torch.autograd.backward", "dual_level", "torch.autograd.forward_ad.make_dual", "torch.autograd.forward_ad.unpack_dual", "torch.autograd.function.FunctionCtx.mark_dirty", "torch.autograd.function.FunctionCtx.mark_non_differentiable", "torch.autograd.function.FunctionCtx.save_for_backward", "torch.autograd.function.FunctionCtx.set_materialize_grads", "torch.autograd.functional.hessian", "torch.autograd.functional.hvp", "torch.autograd.functional.jacobian", "torch.autograd.functional.jvp", "torch.autograd.functional.vhp", "torch.autograd.functional.vjp", "torch.autograd.grad", "torch.autograd.gradcheck", "torch.autograd.gradgradcheck", "torch.autograd.profiler.load_nvprof", "torch.autograd.profiler.profile.export_chrome_trace", "torch.autograd.profiler.profile.key_averages", "torch.autograd.profiler.profile.self_cpu_time_total", "torch.autograd.profiler.profile.total_average", "set_multithreading_enabled", "torch.baddbmm", "torch.bartlett_window", "torch.bernoulli", "torch.bincount", "torch.bitwise_and", "torch.bitwise_left_shift", "torch.bitwise_not", "torch.bitwise_or", "torch.bitwise_right_shift", "torch.bitwise_xor", "torch.blackman_window", "torch.block_diag", "torch.bmm", "torch.broadcast_shapes", "torch.broadcast_tensors", "torch.broadcast_to", "torch.bucketize", "torch.can_cast", "torch.cartesian_prod", "torch.cat", "torch.cdist", "torch.ceil", "torch.chain_matmul", "torch.cholesky", "torch.cholesky_inverse", "torch.cholesky_solve", "torch.chunk", "torch.clamp", "torch.clip", "torch.clone", "torch.column_stack", "torch.combinations", "torch.compile", "torch.compiled_with_cxx11_abi", "torch.complex", "torch.concat", "torch.concatenate", "torch.conj", "torch.conj_physical", "torch.copysign", "torch.corrcoef", "torch.cos", "torch.cosh", "torch.count_nonzero", "torch.cov", "torch.cross", "CUDAGraph", "CUDAPluggableAllocator", "Event", "ExternalStream", "torch.cuda.OutOfMemoryError", "Stream", "StreamContext", "torch.cuda.caching_allocator_alloc", "torch.cuda.caching_allocator_delete", "torch.cuda.can_device_access_peer", "torch.cuda.change_current_allocator", "torch.cuda.comm.broadcast", "torch.cuda.comm.broadcast_coalesced", "torch.cuda.comm.gather", "torch.cuda.comm.reduce_add", "torch.cuda.comm.scatter", "torch.cuda.current_blas_handle", "torch.cuda.current_device", "torch.cuda.current_stream", "torch.cuda.default_stream", "device", "torch.cuda.device_count", "device_of", "torch.cuda.empty_cache", "torch.cuda.get_allocator_backend", "torch.cuda.get_arch_list", "torch.cuda.get_device_capability", "torch.cuda.get_device_name", "torch.cuda.get_device_properties", "torch.cuda.get_gencode_flags", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state_all", "torch.cuda.get_sync_debug_mode", "graph", "torch.cuda.graph_pool_handle", "torch.cuda.init", "torch.cuda.initial_seed", "torch.cuda.ipc_collect", "torch.cuda.is_available", "torch.cuda.is_current_stream_capturing", "torch.cuda.is_initialized", "torch.cuda.jiterator._create_jit_fn", "torch.cuda.jiterator._create_multi_output_jit_fn", "torch.cuda.list_gpu_processes", "torch.cuda.make_graphed_callables", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_cached", "torch.cuda.max_memory_reserved", "torch.cuda.mem_get_info", "torch.cuda.memory_allocated", "torch.cuda.memory_cached", "torch.cuda.memory_reserved", "torch.cuda.memory_snapshot", "torch.cuda.memory_stats", "torch.cuda.memory_summary", "torch.cuda.memory_usage", "torch.cuda.nvtx.mark", "torch.cuda.nvtx.range_pop", "torch.cuda.nvtx.range_push", "torch.cuda.reset_max_memory_allocated", "torch.cuda.reset_max_memory_cached", "torch.cuda.reset_peak_memory_stats", "torch.cuda.seed", "torch.cuda.seed_all", "torch.cuda.set_device", "torch.cuda.set_per_process_memory_fraction", "torch.cuda.set_rng_state", "torch.cuda.set_rng_state_all", "torch.cuda.set_stream", "torch.cuda.set_sync_debug_mode", "torch.cuda.stream", "torch.cuda.synchronize", "torch.cuda.utilization", "torch.cummax", "torch.cummin", "torch.cumprod", "torch.cumsum", "torch.cumulative_trapezoid", "torch.deg2rad", "torch.dequantize", "torch.det", "torch.diag", "torch.diag_embed", "torch.diagflat", "torch.diagonal", "torch.diagonal_scatter", "torch.diff", "torch.digamma", "torch.dist", "torch.div", "torch.divide", "torch.dot", "torch.dsplit", "torch.dstack", "torch.einsum", "torch.empty", "torch.empty_like", "torch.empty_strided", "enable_grad", "torch.eq", "torch.equal", "torch.erf", "torch.erfc", "torch.erfinv", "torch.exp", "torch.exp2", "torch.expm1", "torch.eye", "torch.fake_quantize_per_channel_affine", "torch.fake_quantize_per_tensor_affine", "torch.fft.fft", "torch.fft.fft2", "torch.fft.fftfreq", "torch.fft.fftn", "torch.fft.fftshift", "torch.fft.hfft", "torch.fft.hfft2", "torch.fft.hfftn", "torch.fft.ifft", "torch.fft.ifft2", "torch.fft.ifftn", "torch.fft.ifftshift", "torch.fft.ihfft", "torch.fft.ihfft2", "torch.fft.ihfftn", "torch.fft.irfft", "torch.fft.irfft2", "torch.fft.irfftn", "torch.fft.rfft", "torch.fft.rfft2", "torch.fft.rfftfreq", "torch.fft.rfftn", "torch.fix", "torch.flatten", "torch.flip", "torch.fliplr", "torch.flipud", "torch.float_power", "torch.floor", "torch.floor_divide", "torch.fmax", "torch.fmin", "torch.fmod", "torch.frac", "torch.frexp", "torch.from_dlpack", "torch.from_numpy", "torch.frombuffer", "torch.full", "torch.full_like", "torch.func.functional_call", "torch.func.functionalize", "torch.func.grad", "torch.func.grad_and_value", "torch.func.hessian", "torch.func.jacfwd", "torch.func.jacrev", "torch.func.jvp", "torch.func.stack_module_state", "torch.func.vjp", "torch.func.vmap", "torch.gather", "torch.gcd", "torch.ge", "torch.geqrf", "torch.ger", "torch.get_default_dtype", "torch.get_deterministic_debug_mode", "torch.get_float32_matmul_precision", "torch.get_num_interop_threads", "torch.get_num_threads", "torch.get_rng_state", "torch.gradient", "torch.greater", "torch.greater_equal", "torch.gt", "torch.hamming_window", "torch.hann_window", "torch.heaviside", "torch.histc", "torch.histogram", "torch.histogramdd", "torch.hsplit", "torch.hspmm", "torch.hstack", "torch.hypot", "torch.i0", "torch.igamma", "torch.igammac", "torch.imag", "torch.index_add", "torch.index_copy", "torch.index_reduce", "torch.index_select", "inference_mode", "torch.initial_seed", "torch.inner", "torch.inverse", "torch.is_complex", "torch.is_conj", "torch.is_deterministic_algorithms_warn_only_enabled", "torch.is_floating_point", "torch.is_grad_enabled", "torch.is_inference_mode_enabled", "torch.is_nonzero", "torch.is_storage", "torch.is_tensor", "torch.is_warn_always_enabled", "torch.isclose", "torch.isfinite", "torch.isin", "torch.isinf", "torch.isnan", "torch.isneginf", "torch.isposinf", "torch.isreal", "torch.istft", "Attribute", "ScriptFunction", "ScriptModule", "torch.jit.annotate", "torch.jit.enable_onednn_fusion", "torch.jit.fork", "torch.jit.freeze", "torch.jit.ignore", "torch.jit.isinstance", "torch.jit.load", "torch.jit.onednn_fusion_enabled", "torch.jit.optimize_for_inference", "torch.jit.save", "torch.jit.script", "torch.jit.script_if_tracing", "torch.jit.set_fusion_strategy", "strict_fusion", "torch.jit.trace", "torch.jit.trace_module", "torch.jit.unused", "torch.jit.wait", "torch.kaiser_window", "torch.kron", "torch.kthvalue", "torch.lcm", "torch.ldexp", "torch.le", "torch.lerp", "torch.less", "torch.less_equal", "torch.lgamma", "torch.linalg.cholesky", "torch.linalg.cholesky_ex", "torch.linalg.cond", "torch.linalg.cross", "torch.linalg.det", "torch.linalg.diagonal", "torch.linalg.eig", "torch.linalg.eigh", "torch.linalg.eigvals", "torch.linalg.eigvalsh", "torch.linalg.householder_product", "torch.linalg.inv", "torch.linalg.inv_ex", "torch.linalg.ldl_factor", "torch.linalg.ldl_factor_ex", "torch.linalg.ldl_solve", "torch.linalg.lstsq", "torch.linalg.lu", "torch.linalg.lu_factor", "torch.linalg.lu_factor_ex", "torch.linalg.lu_solve", "torch.linalg.matmul", "torch.linalg.matrix_exp", "torch.linalg.matrix_norm", "torch.linalg.matrix_power", "torch.linalg.matrix_rank", "torch.linalg.multi_dot", "torch.linalg.norm", "torch.linalg.pinv", "torch.linalg.qr", "torch.linalg.slogdet", "torch.linalg.solve", "torch.linalg.solve_ex", "torch.linalg.solve_triangular", "torch.linalg.svd", "torch.linalg.svdvals", "torch.linalg.tensorinv", "torch.linalg.tensorsolve", "torch.linalg.vander", "torch.linalg.vecdot", "torch.linalg.vector_norm", "torch.linspace", "torch.load", "torch.lobpcg", "torch.log", "torch.log10", "torch.log1p", "torch.log2", "torch.logaddexp", "torch.logaddexp2", "torch.logcumsumexp", "torch.logdet", "torch.logical_and", "torch.logical_not", "torch.logical_or", "torch.logical_xor", "torch.logit", "torch.logspace", "torch.logsumexp", "torch.lt", "torch.lu", "torch.lu_solve", "torch.lu_unpack", "torch.manual_seed", "torch.masked_select", "torch.matmul", "torch.matrix_exp", "torch.matrix_power", "torch.max", "torch.maximum", "torch.mean", "torch.median", "torch.meshgrid", "torch.min", "torch.minimum", "torch.mm", "torch.mode", "torch.moveaxis", "torch.movedim", "torch.msort", "torch.mul", "torch.multinomial", "torch.multiply", "torch.mv", "torch.mvlgamma", "torch.nan_to_num", "torch.nanmean", "torch.nanmedian", "torch.nanquantile", "torch.nansum", "torch.narrow", "torch.narrow_copy", "torch.ne", "torch.neg", "torch.negative", "torch.nextafter", "AdaptiveAvgPool1d", "AdaptiveAvgPool2d", "AdaptiveAvgPool3d", "AdaptiveLogSoftmaxWithLoss", "AdaptiveMaxPool1d", "AdaptiveMaxPool2d", "AdaptiveMaxPool3d", "AlphaDropout", "AvgPool1d", "AvgPool2d", "AvgPool3d", "BCELoss", "BCEWithLogitsLoss", "BatchNorm1d", "BatchNorm2d", "BatchNorm3d", "Bilinear", "CELU", "CTCLoss", "ChannelShuffle", "ConstantPad1d", "ConstantPad2d", "ConstantPad3d", "Conv1d", "Conv2d", "Conv3d", "ConvTranspose1d", "ConvTranspose2d", "ConvTranspose3d", "CosineEmbeddingLoss", "CosineSimilarity", "CrossEntropyLoss", "DataParallel", "Dropout", "Dropout1d", "Dropout2d", "Dropout3d", "ELU", "Embedding", "EmbeddingBag", "FeatureAlphaDropout", "Flatten", "Fold", "FractionalMaxPool2d", "FractionalMaxPool3d", "GELU", "GLU", "GRU", "GRUCell", "GaussianNLLLoss", "GroupNorm", "Hardshrink", "Hardsigmoid", "Hardswish", "Hardtanh", "HingeEmbeddingLoss", "HuberLoss", "Identity", "InstanceNorm1d", "InstanceNorm2d", "InstanceNorm3d", "KLDivLoss", "L1Loss", "LPPool1d", "LPPool2d", "LSTM", "LSTMCell", "LayerNorm", "LazyBatchNorm1d", "LazyBatchNorm2d", "LazyBatchNorm3d", "LazyConv1d", "LazyConv2d", "LazyConv3d", "LazyConvTranspose1d", "LazyConvTranspose2d", "LazyConvTranspose3d", "LazyInstanceNorm1d", "LazyInstanceNorm2d", "LazyInstanceNorm3d", "LazyLinear", "LeakyReLU", "Linear", "LocalResponseNorm", "LogSigmoid", "LogSoftmax", "MSELoss", "MarginRankingLoss", "MaxPool1d", "MaxPool2d", "MaxPool3d", "MaxUnpool1d", "MaxUnpool2d", "MaxUnpool3d", "Mish", "Module", "ModuleDict", "ModuleList", "MultiLabelMarginLoss", "MultiLabelSoftMarginLoss", "MultiMarginLoss", "MultiheadAttention", "NLLLoss", "PReLU", "PairwiseDistance", "ParameterDict", "ParameterList", "PixelShuffle", "PixelUnshuffle", "PoissonNLLLoss", "RNN", "RNNBase", "RNNCell", "RReLU", "ReLU", "ReLU6", "ReflectionPad1d", "ReflectionPad2d", "ReflectionPad3d", "ReplicationPad1d", "ReplicationPad2d", "ReplicationPad3d", "SELU", "Sequential", "SiLU", "Sigmoid", "SmoothL1Loss", "SoftMarginLoss", "Softmax", "Softmax2d", "Softmin", "Softplus", "Softshrink", "Softsign", "SyncBatchNorm", "Tanh", "Tanhshrink", "Threshold", "Transformer", "TransformerDecoder", "TransformerDecoderLayer", "TransformerEncoder", "TransformerEncoderLayer", "TripletMarginLoss", "TripletMarginWithDistanceLoss", "Unflatten", "Unfold", "Upsample", "UpsamplingBilinear2d", "UpsamplingNearest2d", "ZeroPad2d", "torch.nn.functional.adaptive_avg_pool1d", "torch.nn.functional.adaptive_avg_pool2d", "torch.nn.functional.adaptive_avg_pool3d", "torch.nn.functional.adaptive_max_pool1d", "torch.nn.functional.adaptive_max_pool2d", "torch.nn.functional.adaptive_max_pool3d", "torch.nn.functional.affine_grid", "torch.nn.functional.alpha_dropout", "torch.nn.functional.avg_pool1d", "torch.nn.functional.avg_pool2d", "torch.nn.functional.avg_pool3d", "torch.nn.functional.batch_norm", "torch.nn.functional.bilinear", "torch.nn.functional.binary_cross_entropy", "torch.nn.functional.binary_cross_entropy_with_logits", "torch.nn.functional.celu", "torch.nn.functional.conv1d", "torch.nn.functional.conv2d", "torch.nn.functional.conv3d", "torch.nn.functional.conv_transpose1d", "torch.nn.functional.conv_transpose2d", "torch.nn.functional.conv_transpose3d", "torch.nn.functional.cosine_embedding_loss", "torch.nn.functional.cosine_similarity", "torch.nn.functional.cross_entropy", "torch.nn.functional.ctc_loss", "torch.nn.functional.dropout", "torch.nn.functional.dropout1d", "torch.nn.functional.dropout2d", "torch.nn.functional.dropout3d", "torch.nn.functional.elu", "torch.nn.functional.elu_", "torch.nn.functional.embedding", "torch.nn.functional.embedding_bag", "torch.nn.functional.feature_alpha_dropout", "torch.nn.functional.fold", "torch.nn.functional.fractional_max_pool2d", "torch.nn.functional.fractional_max_pool3d", "torch.nn.functional.gaussian_nll_loss", "torch.nn.functional.gelu", "torch.nn.functional.glu", "torch.nn.functional.grid_sample", "torch.nn.functional.group_norm", "torch.nn.functional.gumbel_softmax", "torch.nn.functional.hardshrink", "torch.nn.functional.hardsigmoid", "torch.nn.functional.hardswish", "torch.nn.functional.hardtanh", "torch.nn.functional.hardtanh_", "torch.nn.functional.hinge_embedding_loss", "torch.nn.functional.huber_loss", "torch.nn.functional.instance_norm", "torch.nn.functional.interpolate", "torch.nn.functional.kl_div", "torch.nn.functional.l1_loss", "torch.nn.functional.layer_norm", "torch.nn.functional.leaky_relu", "torch.nn.functional.leaky_relu_", "torch.nn.functional.linear", "torch.nn.functional.local_response_norm", "torch.nn.functional.log_softmax", "torch.nn.functional.logsigmoid", "torch.nn.functional.lp_pool1d", "torch.nn.functional.lp_pool2d", "torch.nn.functional.margin_ranking_loss", "torch.nn.functional.max_pool1d", "torch.nn.functional.max_pool2d", "torch.nn.functional.max_pool3d", "torch.nn.functional.max_unpool1d", "torch.nn.functional.max_unpool2d", "torch.nn.functional.max_unpool3d", "torch.nn.functional.mish", "torch.nn.functional.mse_loss", "torch.nn.functional.multi_margin_loss", "torch.nn.functional.multilabel_margin_loss", "torch.nn.functional.multilabel_soft_margin_loss", "torch.nn.functional.nll_loss", "torch.nn.functional.normalize", "torch.nn.functional.one_hot", "torch.nn.functional.pad", "torch.nn.functional.pairwise_distance", "torch.nn.functional.pdist", "torch.nn.functional.pixel_shuffle", "torch.nn.functional.pixel_unshuffle", "torch.nn.functional.poisson_nll_loss", "torch.nn.functional.prelu", "torch.nn.functional.relu", "torch.nn.functional.relu6", "torch.nn.functional.relu_", "torch.nn.functional.rrelu", "torch.nn.functional.rrelu_", "torch.nn.functional.selu", "torch.nn.functional.sigmoid", "torch.nn.functional.silu", "torch.nn.functional.smooth_l1_loss", "torch.nn.functional.soft_margin_loss", "torch.nn.functional.softmax", "torch.nn.functional.softmin", "torch.nn.functional.softplus", "torch.nn.functional.softshrink", "torch.nn.functional.softsign", "torch.nn.functional.tanh", "torch.nn.functional.tanhshrink", "torch.nn.functional.threshold", "torch.nn.functional.threshold_", "torch.nn.functional.torch.nn.parallel.data_parallel", "torch.nn.functional.triplet_margin_loss", "torch.nn.functional.triplet_margin_with_distance_loss", "torch.nn.functional.unfold", "torch.nn.functional.upsample", "torch.nn.functional.upsample_bilinear", "torch.nn.functional.upsample_nearest", "LazyModuleMixin", "torch.nn.modules.module.register_module_backward_hook", "torch.nn.modules.module.register_module_forward_hook", "torch.nn.modules.module.register_module_forward_pre_hook", "torch.nn.modules.module.register_module_full_backward_hook", "DistributedDataParallel", "Parameter", "UninitializedBuffer", "UninitializedParameter", "LSTM", "MultiheadAttention", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.parameters_to_vector", "torch.nn.utils.parametrizations.orthogonal", "torch.nn.utils.parametrizations.spectral_norm", "ParametrizationList", "torch.nn.utils.parametrize.cached", "torch.nn.utils.parametrize.is_parametrized", "torch.nn.utils.parametrize.register_parametrization", "torch.nn.utils.parametrize.remove_parametrizations", "BasePruningMethod", "CustomFromMask", "Identity", "L1Unstructured", "LnStructured", "PruningContainer", "RandomStructured", "RandomUnstructured", "torch.nn.utils.prune.custom_from_mask", "torch.nn.utils.prune.global_unstructured", "torch.nn.utils.prune.identity", "torch.nn.utils.prune.is_pruned", "torch.nn.utils.prune.l1_unstructured", "torch.nn.utils.prune.ln_structured", "torch.nn.utils.prune.random_structured", "torch.nn.utils.prune.random_unstructured", "torch.nn.utils.prune.remove", "torch.nn.utils.remove_spectral_norm", "torch.nn.utils.remove_weight_norm", "PackedSequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.skip_init", "torch.nn.utils.spectral_norm", "torch.nn.utils.stateless.functional_call", "torch.nn.utils.vector_to_parameters", "torch.nn.utils.weight_norm", "no_grad", "torch.nonzero", "torch.norm", "torch.normal", "torch.not_equal", "torch.numel", "torch.ones", "torch.ones_like", "JitScalarType", "ASGD", "Adadelta", "Adagrad", "Adam", "AdamW", "Adamax", "LBFGS", "NAdam", "torch.optim.Optimizer.add_param_group", "torch.optim.Optimizer.load_state_dict", "torch.optim.Optimizer.state_dict", "torch.optim.Optimizer.step", "torch.optim.Optimizer.zero_grad", "RAdam", "RMSprop", "Rprop", "SGD", "SparseAdam", "ChainedScheduler", "ConstantLR", "CosineAnnealingLR", "CosineAnnealingWarmRestarts", "CyclicLR", "ExponentialLR", "LambdaLR", "LinearLR", "MultiStepLR", "MultiplicativeLR", "OneCycleLR", "PolynomialLR", "ReduceLROnPlateau", "SequentialLR", "StepLR", "torch.orgqr", "torch.ormqr", "torch.outer", "torch.pca_lowrank", "torch.permute", "torch.pinverse", "torch.poisson", "torch.polar", "torch.polygamma", "torch.positive", "torch.pow", "torch.prod", "torch.promote_types", "torch.qr", "torch.quantile", "DeQuantStub", "QuantStub", "QuantWrapper", "add_quant_dequant", "convert", "default_eval_fn", "FakeQuantize", "FakeQuantizeBase", "FixedQParamsFakeQuantize", "FusedMovingAvgObsFakeQuantize", "default_fake_quant", "default_fused_act_fake_quant", "default_fused_per_channel_wt_fake_quant", "default_fused_wt_fake_quant", "default_histogram_fake_quant", "default_per_channel_weight_fake_quant", "default_weight_fake_quant", "disable_fake_quant", "disable_observer", "enable_fake_quant", "enable_observer", "fuse_modules", "HistogramObserver", "MinMaxObserver", "MovingAverageMinMaxObserver", "MovingAveragePerChannelMinMaxObserver", "NoopObserver", "ObserverBase", "PerChannelMinMaxObserver", "PlaceholderObserver", "RecordingObserver", "default_debug_observer", "default_dynamic_quant_observer", "default_float_qparams_observer", "default_histogram_observer", "default_observer", "default_per_channel_weight_observer", "default_placeholder_observer", "default_weight_observer", "get_observer_state_dict", "load_observer_state_dict", "prepare", "prepare_qat", "propagate_qconfig", "QConfig", "default_activation_only_qconfig", "default_debug_qconfig", "default_dynamic_qconfig", "default_per_channel_qconfig", "default_qat_qconfig", "default_qat_qconfig_v2", "default_qconfig", "default_weight_only_qconfig", "float16_dynamic_qconfig", "float16_static_qconfig", "float_qparams_weight_only_qconfig", "per_channel_dynamic_qconfig", "quantize", "quantize_dynamic", "convert_fx", "fuse_fx", "prepare_fx", "prepare_qat_fx", "quantize_qat", "swap_module", "torch.quantize_per_channel", "torch.quantize_per_tensor", "torch.quantized_batch_norm", "torch.quantized_max_pool1d", "torch.quantized_max_pool2d", "SobolEngine", "torch.rad2deg", "torch.rand", "torch.rand_like", "torch.randint", "torch.randint_like", "torch.randn", "torch.randn_like", "torch.randperm", "torch.range", "torch.ravel", "torch.real", "torch.reciprocal", "torch.remainder", "torch.renorm", "torch.repeat_interleave", "torch.reshape", "torch.resolve_conj", "torch.resolve_neg", "torch.result_type", "torch.roll", "torch.rot90", "torch.round", "torch.row_stack", "torch.rsqrt", "torch.save", "torch.scatter", "torch.scatter_add", "torch.scatter_reduce", "torch.searchsorted", "torch.seed", "torch.select", "torch.select_scatter", "torch.set_default_device", "torch.set_default_dtype", "torch.set_default_tensor_type", "torch.set_deterministic_debug_mode", "torch.set_float32_matmul_precision", "torch.set_flush_denormal", "set_grad_enabled", "torch.set_num_interop_threads", "torch.set_num_threads", "torch.set_printoptions", "torch.set_rng_state", "torch.set_warn_always", "torch.sgn", "torch.sigmoid", "torch.sign", "torch.signal.windows.bartlett", "torch.signal.windows.blackman", "torch.signal.windows.cosine", "torch.signal.windows.exponential", "torch.signal.windows.gaussian", "torch.signal.windows.general_cosine", "torch.signal.windows.general_hamming", "torch.signal.windows.hamming", "torch.signal.windows.hann", "torch.signal.windows.kaiser", "torch.signal.windows.nuttall", "torch.signbit", "torch.sin", "torch.sinc", "torch.sinh", "torch.slice_scatter", "torch.slogdet", "torch.smm", "torch.softmax", "torch.sort", "torch.sparse.addmm", "torch.sparse.log_softmax", "torch.sparse.mm", "torch.sparse.sampled_addmm", "torch.sparse.softmax", "torch.sparse.spdiags", "torch.sparse.sum", "torch.sparse_bsc_tensor", "torch.sparse_bsr_tensor", "torch.sparse_compressed_tensor", "torch.sparse_coo_tensor", "torch.sparse_csc_tensor", "torch.sparse_csr_tensor", "torch.split", "torch.sqrt", "torch.square", "torch.squeeze", "torch.sspaddmm", "torch.stack", "torch.std", "torch.std_mean", "torch.stft", "torch.sub", "torch.subtract", "torch.sum", "torch.svd", "torch.svd_lowrank", "torch.swapaxes", "torch.swapdims", "torch.sym_float", "torch.sym_int", "torch.symeig", "torch.t", "torch.take", "torch.take_along_dim", "torch.tan", "torch.tanh", "torch.tensor", "torch.tensor_split", "torch.tensordot", "torch.tile", "torch.topk", "torch.trace", "torch.transpose", "torch.trapezoid", "torch.trapz", "torch.triangular_solve", "torch.tril", "torch.tril_indices", "torch.triu", "torch.triu_indices", "torch.true_divide", "torch.trunc", "torch.unbind", "torch.unflatten", "torch.unique", "torch.unique_consecutive", "torch.unsqueeze", "torch.use_deterministic_algorithms", "torch.vander", "torch.var", "torch.var_mean", "torch.vdot", "torch.view_as_complex", "torch.view_as_real", "torch.vmap", "torch.vsplit", "torch.vstack", "torch.where", "torch.xlogy", "torch.zeros", "torch.zeros_like", "torch.hub", "PyTorch documentation", "IRs", "TorchScript", "TorchScript Builtins", "TorchScript Language Reference", "TorchScript Language Reference", "Python Language Reference Coverage", "TorchScript Unsupported PyTorch Constructs", "JIT Utils - torch.utils.jit", "torch.library", "torch.linalg", "torch.masked", "torch.utils.mobile_optimizer", "torch.utils.model_zoo", "torch.monitor", "Multiprocessing package - torch.multiprocessing", "Named Tensors operator coverage", "Named Tensors", "torch.nested", "torch.nn", "torch.nn.functional", "torch.nn.init", "CUDA Automatic Mixed Precision examples", "Autograd mechanics", "Broadcasting semantics", "CPU threading and TorchScript inference", "CUDA semantics", "Distributed Data Parallel", "Extending PyTorch", "Extending torch.func with autograd.Function", "Frequently Asked Questions", "Gradcheck mechanics", "HIP (ROCm) semantics", "Features for large-scale deployments", "Modules", "MPS backend", "Multiprocessing best practices", "Numerical accuracy", "Reproducibility", "Serialization semantics", "Windows FAQ", "torch.onnx", "torch.onnx diagnostics", "ONNX supported TorchScript operators", "torch.optim", "torch.package", "Pipeline Parallelism", "torch.profiler", "Quantization", "Quantization Accuracy Debugging", "Quantization Backend Configuration", "Quantization API Reference", "torch.random", "Distributed RPC Framework", "Distributed Autograd Design", "Remote Reference Protocol", "torch.signal", "torch.sparse", "torch.special", "torch.Storage", "Tensor Attributes", "Tensor Views", "torch.utils.tensorboard", "torch.Tensor", "torch.testing", "torch", "torch.ao.ns._numeric_suite", "torch.ao.ns._numeric_suite_fx", "torch.overrides", "Type Info"], "terms": {"thi": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 14, 15, 16, 17, 19, 20, 21, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 46, 47, 48, 49, 50, 51, 53, 54, 56, 57, 59, 60, 61, 96, 127, 131, 172, 173, 183, 186, 198, 199, 200, 231, 236, 265, 266, 289, 297, 299, 311, 313, 316, 328, 418, 419, 420, 421, 422, 431, 459, 460, 465, 467, 468, 469, 470, 471, 472, 475, 476, 485, 487, 489, 495, 527, 537, 561, 575, 576, 586, 589, 590, 600, 602, 605, 609, 610, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 650, 651, 658, 662, 663, 664, 665, 666, 667, 668, 669, 671, 673, 689, 690, 691, 692, 693, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 710, 722, 723, 724, 725, 726, 733, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 759, 762, 763, 766, 768, 771, 775, 776, 783, 785, 786, 789, 790, 792, 800, 801, 803, 808, 809, 810, 811, 812, 814, 815, 816, 819, 829, 831, 834, 835, 836, 838, 839, 842, 843, 844, 845, 850, 851, 852, 853, 854, 855, 856, 858, 860, 863, 864, 865, 870, 871, 873, 874, 875, 879, 880, 881, 886, 887, 888, 893, 895, 896, 900, 903, 904, 905, 909, 921, 922, 924, 925, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 944, 945, 946, 947, 948, 951, 952, 953, 956, 958, 961, 962, 963, 965, 966, 967, 968, 969, 970, 971, 973, 975, 976, 977, 983, 987, 993, 995, 1005, 1017, 1027, 1028, 1030, 1031, 1033, 1035, 1036, 1037, 1039, 1040, 1041, 1044, 1045, 1046, 1047, 1049, 1050, 1051, 1052, 1053, 1059, 1060, 1061, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1081, 1082, 1084, 1085, 1086, 1087, 1088, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1101, 1102, 1105, 1107, 1110, 1119, 1120, 1124, 1127, 1129, 1130, 1131, 1132, 1134, 1135, 1136, 1142, 1145, 1146, 1147, 1148, 1150, 1158, 1162, 1166, 1167, 1168, 1169, 1170, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1187, 1188, 1189, 1190, 1191, 1193, 1194, 1195, 1197, 1198, 1199, 1202, 1203, 1205, 1210, 1211, 1213, 1214, 1215, 1216, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1235, 1237, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1253, 1256, 1257, 1260, 1262, 1265, 1266, 1278, 1281, 1283, 1286, 1289, 1295, 1296, 1297, 1298, 1301, 1302, 1303, 1304, 1312, 1322, 1323, 1324, 1325, 1326, 1327, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1338, 1339, 1340, 1342, 1343, 1347, 1349, 1351, 1358, 1364, 1366, 1371, 1372, 1373, 1383, 1385, 1387, 1402, 1403, 1411, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1428, 1432, 1433, 1434, 1435, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1448, 1451, 1452, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1467, 1468, 1470, 1471, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1496, 1497, 1498, 1499, 1502, 1503, 1505, 1507, 1509, 1511, 1512, 1513, 1517, 1521, 1523, 1525, 1526, 1527, 1528, 1531, 1532, 1534, 1542, 1543, 1544, 1545, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1584, 1586, 1587, 1595, 1599, 1604, 1608, 1610, 1617, 1624, 1626, 1627, 1628, 1630, 1631, 1632, 1634, 1637, 1639, 1640, 1658, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1679, 1680, 1682, 1683, 1684, 1687, 1688, 1690, 1691, 1694, 1695, 1697, 1701, 1703, 1707, 1709, 1717, 1718, 1719, 1720, 1721, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1745, 1747, 1748, 1750, 1751, 1752, 1753, 1754, 1757, 1758, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1793, 1794, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805], "modul": [0, 1, 2, 4, 6, 7, 9, 12, 14, 17, 21, 23, 27, 31, 33, 38, 40, 42, 45, 48, 49, 53, 54, 56, 460, 602, 605, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 652, 653, 654, 659, 660, 661, 670, 675, 676, 677, 678, 679, 702, 703, 706, 707, 708, 710, 763, 775, 795, 853, 961, 969, 971, 1005, 1028, 1030, 1031, 1033, 1034, 1035, 1036, 1037, 1039, 1040, 1041, 1045, 1046, 1047, 1101, 1124, 1134, 1158, 1162, 1168, 1169, 1170, 1171, 1178, 1179, 1180, 1181, 1182, 1183, 1187, 1188, 1189, 1190, 1191, 1193, 1194, 1195, 1203, 1205, 1213, 1214, 1215, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1237, 1251, 1252, 1260, 1261, 1266, 1278, 1283, 1289, 1293, 1338, 1339, 1411, 1418, 1423, 1424, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1461, 1463, 1464, 1465, 1467, 1525, 1526, 1527, 1528, 1529, 1531, 1532, 1534, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1566, 1567, 1568, 1570, 1577, 1582, 1583, 1584, 1585, 1586, 1587, 1589, 1620, 1728, 1735, 1736, 1742, 1748, 1750, 1751, 1753, 1754, 1757, 1761, 1762, 1763, 1766, 1769, 1771, 1772, 1774, 1776, 1777, 1780, 1782, 1783, 1786, 1787, 1789, 1792, 1793, 1794, 1798, 1801, 1802, 1803, 1804], "an": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 14, 15, 17, 20, 21, 23, 24, 27, 29, 30, 32, 33, 35, 36, 39, 40, 41, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 59, 60, 65, 127, 131, 167, 198, 218, 230, 289, 291, 297, 299, 304, 311, 485, 487, 489, 508, 516, 531, 579, 586, 589, 603, 604, 655, 656, 657, 670, 674, 679, 693, 699, 701, 702, 705, 706, 708, 710, 726, 727, 728, 737, 739, 740, 742, 744, 746, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 766, 782, 792, 800, 801, 803, 809, 811, 812, 814, 820, 821, 822, 823, 824, 842, 843, 850, 851, 853, 865, 867, 876, 880, 881, 890, 903, 905, 907, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 945, 948, 956, 958, 961, 962, 965, 966, 967, 969, 971, 972, 975, 983, 991, 992, 993, 1028, 1030, 1033, 1034, 1037, 1040, 1041, 1043, 1045, 1046, 1047, 1048, 1059, 1060, 1065, 1066, 1071, 1073, 1075, 1078, 1079, 1083, 1086, 1088, 1091, 1092, 1099, 1101, 1102, 1119, 1121, 1124, 1130, 1140, 1149, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1169, 1170, 1171, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1188, 1189, 1190, 1191, 1193, 1194, 1195, 1197, 1198, 1199, 1202, 1210, 1214, 1215, 1218, 1219, 1220, 1222, 1232, 1233, 1234, 1235, 1237, 1238, 1240, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1251, 1252, 1256, 1257, 1258, 1260, 1261, 1262, 1263, 1265, 1267, 1269, 1278, 1281, 1283, 1284, 1285, 1289, 1294, 1296, 1297, 1298, 1301, 1303, 1304, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1314, 1322, 1323, 1324, 1325, 1326, 1327, 1332, 1338, 1339, 1341, 1342, 1343, 1347, 1358, 1365, 1366, 1368, 1369, 1371, 1372, 1373, 1400, 1415, 1417, 1418, 1420, 1423, 1428, 1429, 1430, 1431, 1432, 1435, 1436, 1437, 1444, 1461, 1466, 1470, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1486, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1523, 1526, 1551, 1554, 1586, 1587, 1589, 1593, 1594, 1595, 1614, 1616, 1620, 1628, 1631, 1640, 1646, 1668, 1669, 1673, 1676, 1684, 1688, 1694, 1700, 1701, 1717, 1718, 1719, 1721, 1726, 1727, 1728, 1729, 1734, 1736, 1738, 1739, 1740, 1741, 1742, 1743, 1745, 1747, 1748, 1750, 1751, 1752, 1753, 1754, 1755, 1757, 1758, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1782, 1783, 1784, 1785, 1786, 1789, 1790, 1791, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805], "earli": [0, 17, 21, 35, 39, 59, 1189, 1190, 1191, 1195, 1736, 1784, 1785, 1802, 1803], "prototyp": [0, 17, 23, 748, 750, 754, 755, 756, 1039, 1736, 1747, 1750, 1753, 1754, 1770, 1775, 1787, 1789, 1796, 1802, 1803], "subject": [0, 3, 4, 12, 17, 23, 27, 53, 59, 60, 713, 1423, 1741, 1752, 1753, 1759, 1764, 1778, 1782, 1783, 1784, 1785, 1789, 1796, 1802, 1803], "chang": [0, 1, 2, 3, 4, 8, 12, 17, 21, 23, 27, 29, 34, 35, 38, 39, 47, 53, 54, 57, 59, 60, 116, 198, 230, 297, 431, 468, 471, 489, 492, 527, 589, 725, 755, 756, 800, 801, 808, 809, 810, 819, 829, 831, 842, 843, 850, 851, 853, 893, 941, 977, 983, 1004, 1027, 1030, 1040, 1041, 1060, 1071, 1073, 1074, 1075, 1078, 1091, 1131, 1190, 1193, 1211, 1216, 1220, 1250, 1281, 1302, 1312, 1347, 1359, 1371, 1372, 1373, 1418, 1419, 1423, 1425, 1426, 1434, 1437, 1438, 1469, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1496, 1499, 1502, 1503, 1505, 1507, 1509, 1523, 1547, 1628, 1632, 1668, 1679, 1682, 1683, 1684, 1694, 1706, 1723, 1724, 1735, 1736, 1738, 1747, 1748, 1750, 1751, 1752, 1753, 1754, 1758, 1759, 1760, 1761, 1762, 1764, 1765, 1767, 1768, 1770, 1773, 1775, 1777, 1778, 1780, 1781, 1782, 1783, 1784, 1785, 1789, 1791, 1793, 1795, 1796, 1797, 1798, 1799, 1801, 1802, 1803], "allow_in_graph": 0, "fn": [0, 31, 34, 35, 38, 39, 40, 41, 45, 50, 53, 60, 963, 971, 1030, 1031, 1042, 1047, 1250, 1728, 1738, 1740, 1741, 1745, 1751, 1769, 1789], "sourc": [0, 1, 2, 3, 4, 5, 6, 10, 13, 14, 17, 20, 21, 23, 24, 27, 29, 30, 33, 35, 38, 39, 40, 41, 42, 45, 46, 48, 50, 53, 59, 60, 127, 173, 186, 288, 289, 297, 316, 327, 371, 377, 390, 391, 426, 444, 460, 485, 487, 489, 492, 495, 518, 527, 528, 530, 558, 575, 578, 581, 582, 596, 611, 612, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 721, 734, 735, 736, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 761, 762, 774, 776, 777, 781, 783, 785, 795, 796, 809, 810, 811, 812, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 905, 909, 956, 958, 972, 978, 979, 982, 1001, 1002, 1003, 1005, 1006, 1011, 1016, 1017, 1018, 1028, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1101, 1102, 1122, 1131, 1136, 1137, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1307, 1308, 1312, 1313, 1317, 1319, 1320, 1321, 1328, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1340, 1341, 1344, 1346, 1347, 1348, 1349, 1351, 1352, 1353, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1365, 1366, 1368, 1369, 1370, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1390, 1392, 1393, 1395, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1406, 1407, 1408, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1470, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1513, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1564, 1565, 1566, 1567, 1568, 1569, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1595, 1620, 1625, 1628, 1629, 1630, 1631, 1632, 1634, 1637, 1638, 1639, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1669, 1676, 1684, 1689, 1692, 1693, 1702, 1721, 1735, 1738, 1739, 1740, 1745, 1747, 1748, 1750, 1751, 1753, 1754, 1757, 1766, 1768, 1769, 1773, 1777, 1778, 1780, 1782, 1783, 1784, 1788, 1789, 1790, 1795, 1798, 1800, 1802, 1803, 1804], "custom": [0, 1, 2, 4, 6, 14, 15, 20, 23, 24, 26, 27, 35, 41, 44, 45, 47, 53, 471, 706, 707, 708, 746, 810, 819, 881, 1030, 1250, 1293, 1298, 1299, 1439, 1448, 1463, 1499, 1529, 1546, 1566, 1568, 1584, 1585, 1586, 1587, 1736, 1742, 1745, 1751, 1752, 1759, 1769, 1774, 1775, 1776, 1778, 1787, 1802], "which": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 14, 15, 17, 20, 21, 24, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 46, 47, 48, 49, 50, 53, 57, 59, 60, 65, 127, 265, 289, 291, 293, 295, 297, 311, 445, 459, 460, 471, 485, 487, 489, 508, 531, 576, 579, 589, 596, 600, 613, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 674, 678, 695, 710, 724, 728, 733, 740, 741, 742, 748, 749, 750, 751, 752, 753, 754, 759, 766, 779, 782, 785, 789, 805, 806, 807, 808, 809, 814, 820, 821, 822, 823, 824, 835, 836, 837, 864, 866, 870, 871, 882, 883, 888, 892, 893, 894, 895, 896, 905, 921, 926, 929, 933, 936, 939, 944, 945, 946, 947, 948, 953, 956, 962, 965, 966, 967, 968, 971, 972, 975, 992, 1004, 1015, 1021, 1027, 1028, 1030, 1031, 1033, 1039, 1040, 1041, 1045, 1062, 1065, 1066, 1075, 1079, 1081, 1082, 1085, 1086, 1090, 1092, 1093, 1095, 1098, 1099, 1101, 1107, 1123, 1130, 1135, 1140, 1146, 1149, 1150, 1156, 1157, 1158, 1160, 1161, 1162, 1164, 1165, 1168, 1169, 1170, 1173, 1179, 1180, 1182, 1183, 1186, 1187, 1194, 1201, 1202, 1211, 1213, 1214, 1215, 1216, 1218, 1219, 1220, 1222, 1240, 1244, 1245, 1246, 1247, 1248, 1250, 1253, 1255, 1256, 1278, 1281, 1283, 1285, 1289, 1298, 1299, 1329, 1346, 1347, 1349, 1359, 1366, 1384, 1385, 1402, 1403, 1411, 1418, 1423, 1432, 1434, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1455, 1467, 1470, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1513, 1527, 1528, 1529, 1531, 1547, 1551, 1554, 1566, 1582, 1583, 1584, 1586, 1590, 1604, 1608, 1610, 1611, 1615, 1617, 1624, 1628, 1637, 1639, 1657, 1662, 1664, 1665, 1667, 1668, 1676, 1679, 1701, 1706, 1707, 1710, 1711, 1712, 1713, 1717, 1718, 1720, 1721, 1728, 1735, 1738, 1740, 1741, 1743, 1747, 1748, 1749, 1750, 1751, 1753, 1754, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1774, 1776, 1777, 1781, 1782, 1783, 1784, 1785, 1787, 1788, 1789, 1790, 1791, 1793, 1794, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805], "function": [0, 1, 3, 4, 6, 8, 9, 10, 12, 14, 15, 16, 17, 19, 20, 24, 27, 30, 31, 32, 33, 35, 38, 39, 41, 45, 46, 48, 49, 53, 56, 57, 59, 65, 96, 127, 172, 236, 265, 274, 297, 460, 465, 468, 489, 512, 527, 605, 609, 610, 614, 615, 662, 671, 672, 674, 678, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 706, 707, 708, 710, 725, 726, 740, 741, 742, 743, 754, 755, 756, 759, 762, 764, 773, 775, 783, 785, 789, 792, 795, 800, 801, 808, 809, 810, 812, 814, 816, 819, 835, 836, 839, 844, 845, 850, 851, 853, 854, 855, 856, 858, 863, 864, 870, 871, 873, 874, 875, 879, 888, 893, 895, 896, 903, 905, 909, 921, 922, 924, 944, 948, 951, 952, 953, 956, 958, 961, 963, 964, 965, 966, 967, 968, 970, 971, 975, 976, 983, 987, 988, 989, 991, 993, 1001, 1002, 1003, 1005, 1017, 1027, 1028, 1029, 1030, 1031, 1033, 1035, 1036, 1040, 1041, 1042, 1043, 1045, 1047, 1049, 1050, 1051, 1053, 1058, 1059, 1060, 1061, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1077, 1078, 1079, 1081, 1084, 1085, 1086, 1087, 1088, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1101, 1102, 1105, 1107, 1116, 1119, 1120, 1124, 1127, 1130, 1132, 1134, 1135, 1136, 1142, 1145, 1146, 1162, 1166, 1172, 1173, 1175, 1176, 1177, 1184, 1188, 1192, 1195, 1200, 1201, 1202, 1203, 1204, 1206, 1207, 1208, 1209, 1210, 1216, 1218, 1219, 1220, 1221, 1236, 1239, 1240, 1242, 1249, 1250, 1255, 1258, 1265, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1278, 1279, 1280, 1281, 1283, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1293, 1295, 1297, 1298, 1299, 1301, 1303, 1305, 1419, 1422, 1423, 1432, 1433, 1437, 1448, 1458, 1459, 1460, 1462, 1463, 1464, 1465, 1468, 1470, 1471, 1475, 1483, 1488, 1495, 1498, 1499, 1501, 1504, 1505, 1506, 1511, 1512, 1513, 1517, 1523, 1527, 1528, 1529, 1530, 1532, 1546, 1552, 1554, 1566, 1569, 1582, 1584, 1586, 1587, 1588, 1595, 1599, 1604, 1617, 1626, 1627, 1628, 1631, 1634, 1640, 1648, 1652, 1653, 1658, 1661, 1663, 1664, 1665, 1667, 1673, 1680, 1684, 1690, 1691, 1694, 1697, 1701, 1703, 1707, 1717, 1718, 1719, 1721, 1725, 1726, 1727, 1728, 1729, 1734, 1735, 1736, 1737, 1742, 1745, 1749, 1750, 1751, 1753, 1757, 1760, 1762, 1763, 1764, 1766, 1769, 1770, 1773, 1775, 1778, 1780, 1781, 1782, 1783, 1784, 1786, 1788, 1789, 1790, 1791, 1796, 1798, 1800, 1801, 1802, 1803], "torchdynamo": [0, 9, 31, 34, 35], "includ": [0, 1, 2, 3, 4, 5, 6, 8, 10, 14, 15, 20, 21, 23, 31, 32, 33, 34, 37, 38, 45, 48, 49, 53, 60, 297, 489, 555, 682, 683, 933, 935, 991, 1028, 1030, 1031, 1059, 1163, 1164, 1165, 1171, 1173, 1187, 1196, 1204, 1237, 1246, 1247, 1248, 1250, 1300, 1314, 1315, 1316, 1331, 1344, 1364, 1423, 1459, 1460, 1462, 1584, 1586, 1653, 1710, 1711, 1712, 1713, 1735, 1738, 1740, 1741, 1747, 1748, 1750, 1751, 1759, 1761, 1762, 1766, 1769, 1770, 1775, 1777, 1783, 1784, 1789, 1791, 1798, 1801, 1804], "gener": [0, 2, 3, 4, 8, 9, 14, 20, 21, 23, 29, 32, 33, 34, 35, 38, 41, 42, 49, 53, 54, 55, 130, 131, 150, 234, 262, 352, 395, 427, 454, 756, 765, 839, 842, 850, 851, 854, 855, 873, 874, 876, 877, 878, 905, 927, 928, 962, 971, 982, 987, 1006, 1034, 1039, 1050, 1061, 1066, 1075, 1092, 1093, 1097, 1102, 1122, 1130, 1140, 1186, 1197, 1211, 1293, 1301, 1302, 1312, 1418, 1433, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1464, 1471, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1511, 1513, 1516, 1595, 1597, 1599, 1600, 1601, 1603, 1625, 1638, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1689, 1702, 1706, 1722, 1728, 1736, 1738, 1739, 1740, 1741, 1742, 1743, 1748, 1752, 1757, 1759, 1762, 1764, 1766, 1767, 1769, 1770, 1776, 1777, 1778, 1780, 1781, 1783, 1788, 1789, 1790, 1793, 1796, 1798, 1800, 1802, 1804], "graph": [0, 2, 6, 9, 23, 29, 31, 32, 34, 35, 36, 53, 116, 127, 198, 199, 661, 702, 703, 706, 707, 708, 740, 746, 754, 809, 843, 848, 853, 962, 1030, 1033, 1034, 1039, 1041, 1045, 1423, 1480, 1481, 1551, 1554, 1736, 1741, 1748, 1755, 1758, 1763, 1764, 1767, 1770, 1771, 1777, 1781, 1785, 1786, 1787, 1789, 1790, 1791, 1793, 1798, 1803], "similar": [0, 8, 10, 20, 23, 29, 33, 35, 38, 45, 53, 57, 59, 60, 465, 487, 628, 629, 630, 631, 632, 633, 636, 646, 647, 648, 649, 659, 660, 670, 678, 725, 776, 781, 794, 951, 952, 1030, 1184, 1185, 1197, 1210, 1213, 1214, 1215, 1250, 1298, 1329, 1458, 1470, 1471, 1517, 1534, 1610, 1617, 1665, 1697, 1703, 1719, 1740, 1741, 1751, 1752, 1754, 1759, 1761, 1762, 1764, 1765, 1767, 1773, 1777, 1781, 1782, 1784, 1789, 1790, 1793, 1794, 1799, 1805], "fx": [0, 9, 31, 32, 33, 34, 35, 36, 38, 661, 706, 707, 708, 709, 962, 1585, 1736, 1785, 1786], "wrap": [0, 1, 2, 15, 20, 21, 23, 27, 33, 35, 38, 41, 50, 53, 57, 60, 236, 812, 962, 1030, 1045, 1187, 1250, 1289, 1421, 1423, 1435, 1461, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1527, 1528, 1738, 1739, 1741, 1747, 1758, 1759, 1762, 1763, 1764, 1765, 1770, 1776, 1777, 1782, 1783, 1784, 1789, 1790, 1804], "my_custom_funct": [0, 60], "optim": [0, 1, 2, 3, 8, 9, 12, 14, 15, 21, 23, 24, 29, 31, 33, 35, 36, 38, 53, 60, 755, 759, 795, 905, 1030, 1034, 1039, 1041, 1045, 1046, 1085, 1102, 1168, 1169, 1170, 1186, 1193, 1213, 1214, 1215, 1250, 1253, 1254, 1255, 1256, 1282, 1289, 1297, 1418, 1423, 1432, 1437, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1513, 1547, 1736, 1738, 1740, 1748, 1753, 1757, 1761, 1762, 1763, 1764, 1766, 1767, 1770, 1772, 1777, 1783, 1784, 1793], "def": [0, 1, 2, 20, 21, 23, 24, 29, 31, 33, 34, 35, 38, 39, 40, 41, 45, 46, 49, 50, 51, 53, 55, 57, 58, 59, 60, 373, 702, 703, 738, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 795, 909, 961, 962, 963, 965, 966, 967, 969, 970, 971, 1005, 1028, 1030, 1031, 1033, 1034, 1035, 1036, 1040, 1041, 1044, 1045, 1046, 1047, 1250, 1251, 1252, 1260, 1261, 1299, 1418, 1423, 1437, 1468, 1586, 1587, 1728, 1735, 1738, 1740, 1741, 1745, 1753, 1758, 1759, 1761, 1763, 1764, 1765, 1766, 1770, 1772, 1774, 1775, 1776, 1777, 1780, 1781, 1782, 1783, 1784, 1789, 1790, 1791, 1804], "x": [0, 1, 2, 4, 12, 14, 20, 21, 23, 29, 31, 32, 33, 34, 35, 38, 39, 45, 53, 55, 56, 57, 58, 59, 60, 150, 230, 234, 262, 265, 287, 289, 291, 293, 297, 328, 352, 421, 456, 465, 471, 529, 531, 555, 579, 580, 589, 608, 672, 674, 684, 693, 694, 698, 699, 726, 732, 734, 735, 736, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 777, 778, 779, 782, 783, 795, 800, 803, 806, 807, 850, 851, 888, 895, 899, 900, 905, 909, 919, 920, 921, 922, 924, 925, 930, 931, 933, 935, 939, 940, 942, 945, 946, 947, 955, 961, 963, 965, 966, 967, 968, 969, 970, 971, 983, 1000, 1004, 1005, 1017, 1035, 1036, 1040, 1041, 1044, 1045, 1046, 1047, 1051, 1061, 1074, 1075, 1079, 1082, 1086, 1090, 1092, 1095, 1096, 1097, 1098, 1099, 1102, 1107, 1108, 1109, 1117, 1120, 1123, 1124, 1131, 1144, 1145, 1149, 1150, 1156, 1157, 1166, 1167, 1168, 1169, 1170, 1172, 1184, 1186, 1192, 1198, 1199, 1200, 1202, 1203, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1213, 1214, 1215, 1217, 1218, 1219, 1220, 1221, 1222, 1236, 1239, 1240, 1241, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1257, 1258, 1259, 1260, 1261, 1265, 1267, 1268, 1269, 1270, 1277, 1279, 1280, 1281, 1282, 1284, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1298, 1299, 1302, 1321, 1345, 1347, 1351, 1352, 1358, 1362, 1366, 1377, 1382, 1387, 1391, 1393, 1397, 1398, 1399, 1403, 1404, 1406, 1407, 1408, 1415, 1418, 1433, 1435, 1437, 1458, 1459, 1460, 1461, 1462, 1468, 1469, 1470, 1478, 1499, 1513, 1514, 1531, 1534, 1548, 1549, 1586, 1587, 1590, 1592, 1606, 1609, 1610, 1612, 1613, 1615, 1616, 1620, 1624, 1634, 1662, 1665, 1679, 1682, 1683, 1684, 1690, 1691, 1695, 1701, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1719, 1720, 1722, 1723, 1724, 1726, 1727, 1728, 1731, 1735, 1738, 1739, 1740, 1741, 1742, 1751, 1752, 1753, 1757, 1759, 1760, 1761, 1762, 1764, 1765, 1766, 1767, 1768, 1770, 1771, 1776, 1777, 1781, 1784, 1789, 1793, 1794, 1796, 1798, 1799, 1801, 1802, 1803], "add": [0, 1, 2, 4, 8, 15, 16, 20, 23, 27, 31, 32, 38, 45, 48, 53, 58, 59, 60, 75, 266, 289, 485, 487, 602, 603, 604, 607, 661, 662, 671, 703, 823, 853, 905, 962, 1030, 1041, 1158, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1226, 1227, 1228, 1229, 1230, 1231, 1250, 1252, 1256, 1257, 1261, 1264, 1349, 1390, 1418, 1420, 1421, 1422, 1423, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1490, 1491, 1492, 1493, 1494, 1527, 1566, 1584, 1586, 1587, 1680, 1735, 1737, 1738, 1739, 1740, 1741, 1745, 1748, 1750, 1752, 1754, 1758, 1760, 1761, 1764, 1765, 1768, 1769, 1770, 1777, 1778, 1779, 1781, 1783, 1784, 1785, 1786, 1789, 1790, 1791, 1793, 1796, 1797, 1798, 1802, 1803, 1804], "1": [0, 1, 2, 4, 12, 14, 17, 18, 19, 20, 21, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 45, 46, 48, 51, 53, 57, 58, 59, 60, 65, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 113, 128, 129, 150, 168, 182, 185, 202, 204, 205, 206, 218, 230, 234, 239, 262, 265, 287, 288, 289, 291, 293, 297, 328, 352, 418, 420, 421, 427, 444, 454, 456, 460, 465, 468, 471, 485, 487, 489, 508, 509, 513, 515, 525, 526, 527, 529, 531, 532, 533, 534, 535, 553, 555, 556, 557, 579, 580, 587, 589, 597, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 628, 629, 630, 631, 632, 633, 634, 635, 639, 640, 641, 642, 643, 646, 647, 650, 651, 652, 653, 654, 655, 656, 657, 658, 660, 665, 666, 667, 670, 671, 672, 674, 684, 686, 687, 688, 689, 692, 696, 697, 699, 705, 711, 713, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 738, 741, 744, 746, 747, 748, 749, 750, 751, 752, 753, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 776, 777, 778, 779, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 793, 794, 796, 797, 800, 801, 802, 803, 804, 805, 806, 807, 808, 814, 850, 851, 866, 876, 880, 883, 884, 885, 886, 887, 888, 889, 892, 893, 894, 895, 896, 897, 899, 900, 902, 903, 904, 905, 908, 909, 910, 911, 915, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 961, 962, 963, 965, 966, 967, 968, 970, 971, 972, 973, 974, 983, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 1000, 1001, 1004, 1005, 1007, 1015, 1017, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1030, 1034, 1040, 1041, 1045, 1046, 1049, 1050, 1051, 1053, 1054, 1055, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1072, 1073, 1075, 1076, 1077, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1105, 1107, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1117, 1118, 1119, 1120, 1123, 1124, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1135, 1136, 1137, 1138, 1139, 1140, 1142, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1192, 1193, 1194, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1207, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1288, 1289, 1292, 1293, 1295, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1312, 1314, 1317, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1329, 1330, 1331, 1336, 1337, 1338, 1339, 1341, 1342, 1343, 1345, 1346, 1347, 1349, 1351, 1353, 1354, 1355, 1356, 1357, 1365, 1367, 1371, 1372, 1373, 1379, 1382, 1383, 1384, 1385, 1387, 1388, 1389, 1391, 1395, 1396, 1397, 1398, 1400, 1402, 1403, 1404, 1406, 1411, 1412, 1413, 1414, 1415, 1418, 1423, 1427, 1432, 1433, 1437, 1442, 1443, 1445, 1446, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1458, 1459, 1460, 1461, 1463, 1464, 1465, 1467, 1468, 1469, 1470, 1471, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1511, 1512, 1513, 1514, 1516, 1517, 1520, 1521, 1523, 1524, 1547, 1548, 1549, 1550, 1553, 1555, 1586, 1587, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1619, 1620, 1624, 1627, 1628, 1629, 1630, 1631, 1633, 1634, 1637, 1640, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1657, 1658, 1662, 1663, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1737, 1739, 1740, 1741, 1742, 1745, 1747, 1748, 1751, 1752, 1753, 1754, 1757, 1758, 1759, 1760, 1761, 1762, 1764, 1766, 1767, 1768, 1770, 1773, 1774, 1775, 1776, 1777, 1778, 1780, 1781, 1782, 1783, 1784, 1786, 1789, 1790, 1791, 1793, 1794, 1796, 1797, 1798, 1799, 1800, 1801, 1803, 1804, 1805], "return": [0, 1, 2, 3, 4, 6, 12, 13, 14, 20, 21, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 46, 48, 50, 53, 54, 55, 57, 58, 59, 60, 65, 96, 130, 132, 147, 149, 152, 155, 156, 157, 167, 168, 172, 173, 183, 185, 186, 193, 195, 196, 198, 209, 216, 218, 230, 236, 243, 265, 273, 287, 295, 299, 301, 302, 304, 305, 306, 307, 309, 313, 315, 317, 328, 352, 368, 418, 419, 420, 421, 422, 431, 445, 446, 447, 448, 449, 451, 456, 460, 468, 469, 470, 485, 487, 496, 508, 514, 515, 527, 528, 529, 530, 531, 552, 553, 554, 555, 561, 575, 576, 579, 581, 585, 586, 589, 600, 608, 609, 611, 612, 613, 614, 615, 680, 681, 684, 685, 689, 690, 691, 692, 695, 698, 702, 703, 704, 706, 707, 708, 710, 711, 712, 713, 721, 722, 723, 724, 725, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 759, 760, 761, 764, 765, 766, 773, 774, 776, 779, 781, 783, 784, 785, 786, 787, 788, 789, 790, 792, 794, 795, 796, 800, 801, 803, 804, 805, 807, 808, 809, 811, 812, 814, 818, 820, 821, 822, 823, 824, 825, 826, 827, 828, 830, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 845, 847, 848, 849, 850, 851, 852, 853, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 868, 869, 870, 871, 872, 881, 883, 884, 885, 886, 887, 888, 889, 890, 892, 893, 894, 895, 896, 899, 905, 906, 907, 908, 909, 910, 915, 918, 919, 920, 921, 922, 923, 924, 925, 941, 944, 945, 946, 947, 948, 949, 953, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 974, 975, 978, 979, 980, 981, 982, 986, 987, 988, 990, 991, 992, 996, 1000, 1004, 1005, 1006, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1026, 1027, 1028, 1030, 1031, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1049, 1051, 1054, 1055, 1059, 1060, 1061, 1065, 1066, 1067, 1068, 1071, 1072, 1073, 1075, 1076, 1077, 1078, 1079, 1082, 1083, 1084, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1096, 1097, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1109, 1110, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1135, 1140, 1145, 1146, 1148, 1149, 1150, 1151, 1152, 1154, 1158, 1159, 1160, 1161, 1166, 1167, 1184, 1185, 1186, 1187, 1194, 1198, 1199, 1210, 1216, 1217, 1240, 1241, 1242, 1243, 1244, 1245, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1260, 1261, 1264, 1278, 1281, 1282, 1283, 1284, 1285, 1289, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1317, 1319, 1320, 1321, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1346, 1347, 1348, 1349, 1351, 1352, 1353, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1365, 1366, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1390, 1392, 1393, 1395, 1397, 1399, 1400, 1401, 1402, 1403, 1409, 1411, 1412, 1413, 1414, 1418, 1419, 1420, 1421, 1422, 1423, 1428, 1429, 1431, 1432, 1433, 1434, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1449, 1450, 1451, 1452, 1453, 1454, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1467, 1468, 1469, 1470, 1471, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1486, 1487, 1488, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1513, 1514, 1516, 1519, 1520, 1521, 1522, 1523, 1528, 1546, 1564, 1568, 1569, 1582, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1609, 1610, 1611, 1612, 1613, 1614, 1617, 1619, 1624, 1625, 1626, 1627, 1633, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1657, 1658, 1662, 1664, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1683, 1684, 1687, 1688, 1689, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1702, 1704, 1705, 1706, 1709, 1710, 1711, 1712, 1713, 1715, 1716, 1717, 1718, 1719, 1720, 1722, 1724, 1726, 1727, 1728, 1731, 1733, 1734, 1735, 1738, 1742, 1745, 1748, 1749, 1750, 1751, 1753, 1754, 1757, 1758, 1759, 1761, 1762, 1764, 1765, 1767, 1768, 1769, 1770, 1773, 1775, 1776, 1777, 1778, 1780, 1781, 1782, 1783, 1784, 1788, 1789, 1790, 1793, 1794, 1795, 1796, 1797, 1799, 1800, 1801, 1802, 1803, 1804, 1805], "Will": [0, 11, 23, 53, 60, 1673, 1740, 1753, 1777], "captur": [0, 2, 15, 32, 33, 35, 38, 60, 809, 811, 842, 848, 853, 1033, 1480, 1481, 1738, 1742, 1764, 1765, 1768, 1777, 1781, 1784, 1803], "singl": [0, 3, 4, 14, 21, 23, 27, 29, 33, 34, 35, 36, 38, 39, 41, 47, 48, 53, 54, 56, 57, 58, 59, 60, 230, 611, 612, 680, 681, 682, 683, 686, 687, 688, 741, 748, 749, 750, 751, 752, 753, 754, 764, 773, 777, 803, 807, 850, 853, 961, 963, 964, 967, 971, 987, 988, 992, 1015, 1029, 1030, 1045, 1046, 1049, 1107, 1131, 1156, 1157, 1160, 1161, 1164, 1165, 1167, 1178, 1179, 1180, 1182, 1183, 1186, 1187, 1198, 1199, 1205, 1218, 1219, 1222, 1244, 1245, 1250, 1258, 1262, 1263, 1278, 1289, 1306, 1307, 1308, 1309, 1310, 1311, 1314, 1315, 1316, 1322, 1323, 1324, 1325, 1326, 1327, 1342, 1343, 1344, 1371, 1372, 1373, 1414, 1421, 1423, 1429, 1430, 1431, 1465, 1466, 1483, 1488, 1494, 1499, 1520, 1546, 1611, 1676, 1682, 1683, 1718, 1719, 1721, 1723, 1724, 1728, 1736, 1738, 1740, 1741, 1747, 1751, 1753, 1754, 1759, 1761, 1762, 1764, 1765, 1767, 1770, 1772, 1773, 1774, 1775, 1777, 1780, 1781, 1782, 1783, 1784, 1790, 1791, 1793, 1796, 1799, 1800, 1803], "contain": [0, 1, 2, 3, 4, 6, 12, 14, 15, 20, 23, 24, 27, 29, 35, 37, 38, 39, 41, 42, 46, 49, 53, 59, 60, 65, 127, 131, 168, 172, 185, 266, 287, 289, 291, 295, 297, 444, 456, 575, 579, 602, 613, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 674, 725, 740, 748, 749, 750, 751, 752, 753, 754, 759, 763, 764, 765, 773, 775, 779, 802, 803, 807, 810, 820, 821, 822, 823, 824, 853, 905, 939, 940, 942, 948, 968, 970, 971, 987, 988, 991, 992, 1000, 1004, 1021, 1028, 1030, 1031, 1036, 1037, 1040, 1045, 1046, 1049, 1060, 1066, 1067, 1068, 1069, 1071, 1073, 1075, 1076, 1092, 1101, 1119, 1123, 1130, 1140, 1146, 1158, 1167, 1186, 1187, 1193, 1194, 1197, 1202, 1203, 1205, 1210, 1220, 1221, 1242, 1250, 1251, 1252, 1257, 1260, 1265, 1267, 1278, 1282, 1289, 1301, 1330, 1338, 1339, 1341, 1411, 1418, 1420, 1421, 1423, 1433, 1434, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1449, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1463, 1464, 1467, 1469, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1487, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1513, 1516, 1546, 1565, 1569, 1606, 1620, 1624, 1683, 1684, 1688, 1694, 1702, 1709, 1711, 1713, 1718, 1719, 1724, 1728, 1736, 1738, 1740, 1741, 1742, 1747, 1750, 1753, 1754, 1758, 1759, 1763, 1764, 1765, 1766, 1767, 1769, 1770, 1773, 1775, 1777, 1780, 1781, 1782, 1783, 1784, 1786, 1787, 1789, 1791, 1793, 1795, 1796, 1798, 1799, 1801, 1802, 1803, 1804], "disallow_in_graph": 0, "exclud": [0, 10, 21, 32, 48, 60, 992, 1194, 1339, 1387, 1710, 1711, 1712, 1713, 1768, 1781, 1790], "forc": [0, 1, 2, 14, 17, 32, 37, 53, 431, 728, 846, 1033, 1044, 1048, 1639, 1735, 1738, 1741, 1758, 1762, 1798], "break": [0, 8, 29, 32, 35, 53, 56, 60, 740, 795, 1030, 1075, 1250, 1617, 1637, 1736, 1742, 1763, 1780], "sub": [0, 41, 53, 59, 533, 1041, 1045, 1046, 1127, 1130, 1132, 1262, 1263, 1293, 1294, 1296, 1546, 1586, 1587, 1609, 1686, 1701, 1735, 1737, 1738, 1739, 1752, 1754, 1759, 1777, 1779, 1793, 1796], "give": [0, 1, 4, 5, 8, 10, 17, 20, 21, 27, 34, 38, 47, 53, 60, 755, 756, 807, 923, 925, 926, 928, 932, 941, 965, 966, 967, 1043, 1059, 1066, 1178, 1179, 1180, 1255, 1301, 1302, 1432, 1469, 1684, 1721, 1735, 1738, 1751, 1753, 1757, 1759, 1762, 1764, 1765, 1767, 1768, 1770, 1774, 1777, 1780, 1782, 1793, 1804], "two": [0, 1, 2, 4, 5, 7, 9, 12, 14, 15, 17, 20, 21, 23, 24, 27, 29, 31, 34, 38, 39, 45, 46, 48, 49, 53, 57, 60, 555, 579, 589, 608, 610, 674, 703, 735, 738, 750, 755, 783, 785, 814, 818, 856, 858, 884, 885, 893, 902, 905, 911, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 951, 952, 961, 969, 991, 993, 1019, 1028, 1030, 1040, 1043, 1050, 1053, 1055, 1060, 1062, 1065, 1066, 1071, 1072, 1077, 1082, 1085, 1086, 1088, 1089, 1091, 1093, 1098, 1101, 1124, 1127, 1130, 1132, 1135, 1147, 1164, 1166, 1167, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1197, 1202, 1210, 1211, 1217, 1219, 1220, 1241, 1242, 1244, 1250, 1253, 1254, 1255, 1257, 1258, 1264, 1265, 1281, 1282, 1297, 1298, 1299, 1301, 1319, 1320, 1330, 1349, 1359, 1366, 1382, 1390, 1432, 1437, 1459, 1467, 1469, 1470, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1487, 1490, 1491, 1492, 1493, 1494, 1498, 1499, 1501, 1505, 1524, 1604, 1617, 1668, 1673, 1688, 1702, 1706, 1707, 1709, 1725, 1729, 1735, 1737, 1738, 1740, 1741, 1745, 1747, 1752, 1753, 1754, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1767, 1770, 1775, 1776, 1777, 1780, 1781, 1782, 1784, 1785, 1789, 1790, 1791, 1793, 1794, 1798, 1799, 1800, 1802, 1803], "each": [0, 1, 2, 6, 10, 14, 20, 21, 23, 24, 27, 29, 32, 33, 34, 35, 38, 39, 41, 46, 49, 50, 51, 53, 54, 56, 57, 58, 60, 74, 96, 130, 131, 373, 465, 485, 487, 489, 516, 579, 589, 597, 599, 602, 609, 611, 612, 615, 674, 702, 713, 725, 734, 735, 736, 737, 739, 740, 745, 754, 763, 766, 775, 779, 783, 784, 786, 789, 793, 807, 820, 824, 853, 856, 858, 864, 866, 872, 878, 883, 884, 885, 888, 889, 900, 903, 905, 922, 924, 925, 926, 927, 928, 930, 931, 934, 935, 936, 937, 938, 940, 942, 946, 947, 949, 954, 958, 963, 964, 968, 970, 971, 972, 983, 989, 991, 992, 993, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1030, 1045, 1046, 1051, 1083, 1101, 1102, 1117, 1119, 1127, 1129, 1130, 1131, 1132, 1135, 1137, 1140, 1146, 1148, 1158, 1163, 1166, 1167, 1171, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1187, 1188, 1189, 1190, 1191, 1193, 1194, 1195, 1197, 1202, 1203, 1205, 1210, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1222, 1230, 1231, 1235, 1237, 1241, 1242, 1250, 1253, 1254, 1255, 1256, 1257, 1258, 1264, 1265, 1267, 1278, 1281, 1282, 1284, 1289, 1292, 1298, 1299, 1301, 1317, 1319, 1320, 1325, 1326, 1327, 1330, 1331, 1333, 1334, 1335, 1338, 1339, 1340, 1344, 1347, 1357, 1359, 1382, 1383, 1385, 1387, 1390, 1409, 1418, 1422, 1423, 1428, 1458, 1459, 1461, 1469, 1470, 1471, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1487, 1490, 1491, 1492, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1509, 1516, 1520, 1521, 1524, 1568, 1569, 1584, 1586, 1587, 1596, 1604, 1609, 1610, 1615, 1619, 1624, 1637, 1648, 1654, 1669, 1670, 1671, 1672, 1674, 1675, 1676, 1687, 1688, 1694, 1701, 1703, 1704, 1707, 1718, 1719, 1722, 1728, 1729, 1735, 1740, 1741, 1752, 1753, 1754, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1769, 1770, 1772, 1773, 1774, 1775, 1777, 1780, 1782, 1783, 1784, 1789, 1790, 1791, 1793, 1794, 1796, 1798, 1799, 1800, 1802, 1803], "op": [0, 2, 5, 23, 33, 34, 35, 38, 60, 127, 475, 495, 576, 671, 702, 703, 710, 740, 746, 754, 785, 815, 829, 831, 835, 836, 850, 851, 875, 879, 881, 962, 980, 1031, 1043, 1045, 1046, 1107, 1266, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1511, 1551, 1554, 1586, 1587, 1635, 1709, 1736, 1737, 1741, 1745, 1747, 1748, 1750, 1752, 1753, 1761, 1762, 1763, 1764, 1772, 1781, 1783, 1784, 1785, 1786, 1787, 1795, 1797, 1799, 1803], "graph_break": 0, "backend": [0, 2, 14, 32, 33, 35, 36, 47, 51, 53, 655, 656, 657, 702, 711, 712, 748, 754, 795, 833, 864, 905, 962, 1043, 1073, 1075, 1093, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1347, 1385, 1423, 1584, 1586, 1587, 1632, 1736, 1737, 1739, 1740, 1745, 1748, 1761, 1762, 1773, 1774, 1777, 1785, 1787, 1793], "inductor": [0, 34, 38, 795], "nopython": [0, 33, 34, 35, 38], "fals": [0, 1, 2, 4, 6, 14, 20, 21, 23, 24, 27, 29, 33, 35, 38, 39, 53, 56, 60, 89, 90, 91, 92, 93, 95, 111, 112, 113, 127, 158, 159, 160, 173, 186, 236, 277, 294, 295, 297, 304, 308, 311, 312, 314, 318, 319, 320, 327, 329, 367, 371, 382, 384, 385, 386, 389, 395, 403, 404, 405, 406, 418, 419, 420, 421, 422, 426, 431, 433, 443, 444, 452, 467, 468, 476, 489, 513, 526, 527, 536, 541, 552, 566, 575, 581, 582, 587, 589, 609, 610, 611, 612, 613, 615, 628, 629, 630, 631, 632, 633, 659, 660, 665, 666, 667, 669, 672, 674, 682, 683, 690, 692, 693, 694, 696, 697, 699, 713, 722, 723, 724, 728, 740, 741, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 759, 762, 764, 767, 770, 772, 773, 779, 780, 786, 787, 788, 794, 795, 800, 811, 848, 853, 865, 905, 906, 907, 908, 910, 911, 918, 922, 923, 924, 925, 930, 931, 936, 937, 938, 940, 941, 942, 958, 959, 960, 963, 964, 966, 967, 968, 970, 972, 974, 986, 987, 988, 991, 992, 1005, 1015, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1030, 1035, 1036, 1045, 1046, 1047, 1049, 1051, 1054, 1059, 1060, 1071, 1072, 1073, 1074, 1076, 1077, 1078, 1079, 1082, 1084, 1086, 1087, 1090, 1091, 1092, 1093, 1094, 1099, 1100, 1101, 1111, 1112, 1113, 1114, 1116, 1117, 1118, 1119, 1121, 1123, 1127, 1129, 1130, 1132, 1135, 1140, 1145, 1146, 1147, 1148, 1151, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1184, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1198, 1199, 1202, 1203, 1204, 1205, 1207, 1208, 1209, 1210, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1235, 1236, 1237, 1241, 1242, 1243, 1244, 1245, 1249, 1250, 1253, 1254, 1255, 1256, 1257, 1259, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1277, 1279, 1281, 1282, 1289, 1292, 1293, 1295, 1296, 1297, 1298, 1299, 1302, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1319, 1320, 1321, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1340, 1344, 1347, 1349, 1351, 1352, 1353, 1358, 1359, 1362, 1368, 1369, 1371, 1372, 1373, 1377, 1382, 1386, 1390, 1392, 1393, 1395, 1396, 1397, 1399, 1409, 1412, 1413, 1415, 1423, 1425, 1427, 1428, 1429, 1432, 1434, 1437, 1438, 1450, 1459, 1460, 1461, 1462, 1468, 1469, 1470, 1474, 1475, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1511, 1521, 1523, 1524, 1529, 1540, 1541, 1546, 1547, 1548, 1549, 1550, 1552, 1553, 1554, 1566, 1567, 1574, 1577, 1582, 1583, 1588, 1593, 1594, 1595, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1612, 1613, 1620, 1624, 1632, 1633, 1634, 1637, 1639, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1662, 1670, 1671, 1672, 1673, 1674, 1675, 1682, 1683, 1684, 1687, 1688, 1694, 1700, 1704, 1709, 1718, 1721, 1722, 1723, 1724, 1731, 1733, 1734, 1735, 1737, 1738, 1739, 1740, 1741, 1747, 1748, 1749, 1751, 1753, 1754, 1758, 1759, 1762, 1763, 1764, 1766, 1770, 1773, 1774, 1777, 1778, 1781, 1782, 1783, 1785, 1786, 1788, 1789, 1793, 1794, 1795, 1797, 1798, 1800, 1801, 1803, 1804], "guard_export_fn": 0, "none": [0, 1, 2, 3, 4, 14, 17, 20, 21, 23, 24, 27, 29, 31, 35, 38, 39, 41, 45, 46, 48, 50, 53, 57, 58, 59, 60, 89, 91, 92, 93, 95, 111, 112, 115, 127, 130, 131, 133, 150, 162, 163, 164, 165, 181, 182, 184, 186, 189, 190, 191, 192, 206, 211, 212, 213, 214, 234, 262, 266, 277, 311, 327, 329, 352, 382, 384, 385, 386, 389, 395, 401, 402, 403, 404, 405, 406, 418, 419, 420, 421, 422, 426, 427, 443, 452, 454, 460, 466, 475, 485, 492, 508, 509, 523, 524, 526, 527, 536, 552, 555, 562, 575, 581, 582, 587, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 609, 611, 612, 613, 614, 615, 628, 629, 630, 631, 632, 633, 634, 635, 636, 639, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 659, 660, 663, 665, 666, 667, 668, 669, 680, 681, 682, 683, 693, 694, 695, 696, 697, 699, 700, 701, 703, 704, 708, 713, 714, 715, 716, 717, 718, 719, 720, 722, 723, 726, 727, 728, 729, 730, 731, 732, 733, 737, 738, 739, 740, 741, 742, 743, 746, 747, 749, 751, 752, 753, 754, 755, 756, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 775, 779, 782, 784, 785, 786, 787, 788, 790, 791, 793, 795, 797, 798, 799, 801, 802, 804, 805, 806, 807, 808, 809, 811, 812, 814, 815, 816, 820, 822, 823, 824, 827, 828, 829, 835, 836, 842, 852, 856, 857, 858, 859, 860, 861, 862, 864, 865, 866, 870, 871, 872, 876, 879, 881, 882, 883, 884, 885, 886, 887, 888, 889, 892, 897, 898, 900, 901, 902, 904, 906, 907, 908, 910, 912, 913, 914, 915, 916, 917, 918, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 948, 949, 950, 951, 952, 953, 954, 955, 959, 960, 961, 962, 963, 967, 969, 971, 972, 973, 974, 975, 976, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 994, 995, 996, 997, 998, 999, 1001, 1002, 1003, 1004, 1007, 1008, 1024, 1025, 1027, 1029, 1030, 1034, 1037, 1039, 1040, 1041, 1043, 1045, 1046, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1123, 1124, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1150, 1151, 1152, 1153, 1154, 1156, 1157, 1158, 1160, 1161, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1187, 1193, 1194, 1196, 1198, 1199, 1200, 1203, 1204, 1205, 1209, 1210, 1211, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1237, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1260, 1261, 1264, 1266, 1267, 1281, 1282, 1283, 1284, 1285, 1289, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1302, 1303, 1304, 1307, 1308, 1312, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1330, 1331, 1338, 1339, 1344, 1345, 1347, 1348, 1355, 1357, 1358, 1359, 1360, 1361, 1364, 1366, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1378, 1379, 1380, 1381, 1382, 1383, 1385, 1387, 1390, 1400, 1401, 1402, 1403, 1411, 1412, 1413, 1415, 1416, 1417, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1432, 1433, 1436, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1448, 1451, 1452, 1458, 1460, 1461, 1462, 1464, 1465, 1467, 1469, 1470, 1471, 1472, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1511, 1512, 1513, 1516, 1517, 1518, 1520, 1521, 1523, 1524, 1525, 1526, 1529, 1531, 1546, 1547, 1548, 1549, 1550, 1553, 1554, 1566, 1567, 1568, 1582, 1583, 1584, 1585, 1586, 1587, 1592, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1607, 1608, 1609, 1610, 1615, 1617, 1618, 1619, 1624, 1637, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1661, 1662, 1664, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1694, 1697, 1698, 1699, 1700, 1702, 1704, 1707, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1718, 1719, 1722, 1723, 1724, 1725, 1728, 1730, 1731, 1732, 1733, 1734, 1735, 1737, 1738, 1739, 1740, 1741, 1742, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1757, 1759, 1762, 1764, 1765, 1770, 1772, 1775, 1777, 1778, 1781, 1782, 1783, 1784, 1786, 1788, 1789, 1794, 1795, 1796, 1798, 1800, 1802, 1803, 1804], "guard_fail_fn": 0, "disabl": [0, 1, 3, 24, 29, 32, 33, 38, 53, 60, 762, 853, 905, 909, 961, 1005, 1030, 1032, 1045, 1046, 1250, 1256, 1289, 1297, 1423, 1424, 1465, 1468, 1542, 1543, 1633, 1634, 1637, 1736, 1740, 1758, 1761, 1762, 1763, 1764, 1768, 1773, 1774, 1777, 1782, 1788, 1800], "dynam": [0, 1, 14, 15, 20, 32, 33, 36, 38, 645, 649, 674, 675, 676, 677, 678, 679, 706, 795, 810, 1037, 1043, 1045, 1101, 1432, 1554, 1583, 1584, 1740, 1741, 1742, 1757, 1762, 1770, 1773, 1777, 1780, 1781, 1785], "The": [0, 1, 2, 3, 4, 6, 8, 9, 12, 14, 15, 17, 20, 21, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 53, 57, 58, 59, 65, 127, 168, 173, 185, 186, 198, 231, 266, 287, 289, 291, 295, 297, 373, 375, 377, 421, 431, 456, 459, 460, 465, 467, 470, 471, 485, 487, 489, 508, 515, 555, 575, 589, 590, 600, 603, 604, 605, 606, 610, 611, 612, 613, 662, 671, 674, 680, 681, 682, 683, 686, 687, 688, 693, 694, 696, 697, 699, 700, 701, 702, 703, 706, 708, 710, 725, 726, 728, 732, 733, 737, 738, 740, 741, 742, 743, 748, 749, 751, 752, 753, 754, 755, 756, 758, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 780, 781, 787, 794, 797, 803, 807, 810, 811, 817, 823, 839, 850, 851, 853, 854, 855, 864, 876, 877, 878, 888, 892, 893, 894, 895, 896, 897, 899, 905, 906, 910, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 944, 953, 955, 956, 957, 958, 959, 962, 965, 968, 970, 971, 974, 975, 983, 986, 987, 988, 989, 990, 991, 992, 994, 996, 1000, 1004, 1007, 1027, 1030, 1033, 1035, 1037, 1040, 1041, 1043, 1045, 1046, 1049, 1050, 1054, 1055, 1059, 1060, 1061, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1075, 1076, 1077, 1079, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1092, 1093, 1094, 1096, 1099, 1101, 1102, 1117, 1118, 1119, 1120, 1122, 1123, 1124, 1130, 1140, 1146, 1149, 1151, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1187, 1193, 1194, 1195, 1197, 1198, 1199, 1202, 1203, 1204, 1205, 1210, 1211, 1213, 1214, 1215, 1216, 1217, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1237, 1240, 1241, 1242, 1243, 1244, 1245, 1250, 1253, 1255, 1257, 1264, 1265, 1267, 1268, 1278, 1279, 1281, 1289, 1292, 1293, 1298, 1299, 1301, 1302, 1312, 1315, 1316, 1330, 1331, 1338, 1339, 1340, 1342, 1343, 1346, 1347, 1349, 1358, 1359, 1371, 1372, 1373, 1382, 1385, 1399, 1415, 1418, 1420, 1421, 1422, 1423, 1425, 1426, 1428, 1429, 1430, 1431, 1432, 1433, 1435, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1448, 1449, 1451, 1452, 1455, 1461, 1463, 1464, 1467, 1469, 1470, 1471, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1513, 1514, 1517, 1520, 1523, 1531, 1534, 1547, 1548, 1549, 1550, 1553, 1555, 1565, 1566, 1584, 1589, 1593, 1594, 1595, 1597, 1599, 1601, 1606, 1608, 1610, 1612, 1613, 1615, 1620, 1627, 1628, 1629, 1630, 1637, 1638, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1658, 1665, 1666, 1668, 1670, 1671, 1672, 1673, 1674, 1675, 1679, 1682, 1683, 1684, 1688, 1689, 1694, 1696, 1702, 1703, 1704, 1706, 1707, 1710, 1711, 1712, 1713, 1720, 1721, 1722, 1723, 1724, 1726, 1728, 1731, 1735, 1738, 1739, 1740, 1742, 1743, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1780, 1781, 1782, 1783, 1784, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1805], "main": [0, 4, 20, 21, 23, 24, 29, 33, 35, 39, 40, 41, 46, 48, 49, 50, 51, 60, 236, 468, 892, 893, 894, 895, 896, 1092, 1349, 1668, 1710, 1711, 1712, 1713, 1735, 1738, 1750, 1751, 1753, 1754, 1758, 1759, 1762, 1763, 1764, 1765, 1776, 1778, 1789, 1790, 1798, 1799], "entrypoint": [0, 39, 41, 46, 49, 1751], "do": [0, 1, 2, 5, 8, 9, 10, 12, 14, 15, 20, 21, 23, 27, 30, 35, 37, 38, 39, 41, 48, 49, 50, 53, 54, 55, 57, 58, 59, 60, 467, 485, 487, 489, 672, 741, 746, 755, 781, 794, 853, 884, 885, 886, 887, 956, 958, 967, 972, 992, 1005, 1017, 1027, 1033, 1041, 1045, 1075, 1093, 1102, 1109, 1119, 1121, 1130, 1140, 1150, 1162, 1172, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1207, 1208, 1209, 1236, 1268, 1269, 1270, 1277, 1292, 1332, 1333, 1334, 1335, 1338, 1339, 1340, 1349, 1351, 1366, 1418, 1423, 1471, 1476, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493, 1511, 1517, 1551, 1554, 1588, 1721, 1735, 1736, 1738, 1739, 1741, 1743, 1745, 1751, 1752, 1753, 1758, 1759, 1760, 1762, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1780, 1783, 1784, 1785, 1789, 1791, 1794, 1795, 1796, 1797, 1798, 1800], "call": [0, 1, 2, 3, 4, 9, 12, 14, 15, 17, 20, 21, 23, 24, 27, 29, 30, 31, 33, 35, 38, 39, 48, 50, 53, 54, 55, 57, 58, 59, 60, 127, 266, 299, 311, 431, 459, 460, 527, 552, 586, 589, 613, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 695, 740, 744, 745, 746, 747, 748, 750, 751, 754, 778, 809, 812, 814, 842, 844, 854, 855, 864, 870, 871, 873, 874, 903, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 961, 962, 971, 975, 993, 1005, 1015, 1030, 1033, 1035, 1040, 1041, 1042, 1049, 1085, 1093, 1097, 1099, 1101, 1102, 1131, 1162, 1168, 1169, 1170, 1187, 1188, 1189, 1190, 1191, 1193, 1195, 1197, 1235, 1246, 1247, 1248, 1250, 1257, 1258, 1278, 1289, 1301, 1325, 1326, 1327, 1333, 1334, 1335, 1340, 1358, 1415, 1419, 1420, 1421, 1422, 1423, 1434, 1437, 1444, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1460, 1464, 1465, 1467, 1468, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1486, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1527, 1529, 1552, 1582, 1586, 1587, 1601, 1628, 1635, 1636, 1682, 1683, 1684, 1702, 1721, 1723, 1724, 1728, 1729, 1735, 1738, 1742, 1745, 1750, 1751, 1753, 1754, 1755, 1758, 1759, 1761, 1762, 1763, 1764, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1776, 1777, 1778, 1780, 1781, 1782, 1783, 1784, 1789, 1790, 1791, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1802, 1804, 1805], "extract": [0, 17, 31, 34, 36, 60, 1193, 1197, 1301, 1338, 1414, 1564, 1789, 1803], "paramet": [0, 1, 2, 3, 4, 6, 12, 14, 20, 21, 23, 24, 27, 29, 30, 32, 33, 39, 42, 46, 48, 50, 53, 55, 59, 60, 65, 127, 132, 147, 149, 152, 155, 156, 157, 172, 173, 183, 186, 216, 230, 231, 236, 243, 273, 289, 291, 293, 295, 297, 301, 307, 368, 375, 377, 418, 419, 420, 421, 422, 431, 444, 465, 468, 469, 470, 471, 472, 485, 487, 489, 492, 496, 508, 515, 516, 517, 531, 537, 555, 575, 576, 579, 589, 590, 597, 599, 600, 601, 602, 603, 604, 605, 606, 607, 609, 610, 611, 612, 613, 614, 615, 652, 653, 654, 655, 656, 657, 658, 659, 660, 664, 669, 670, 672, 673, 674, 678, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 691, 693, 694, 695, 696, 697, 699, 700, 701, 711, 712, 713, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 740, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 792, 793, 794, 795, 797, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 814, 815, 816, 817, 819, 820, 821, 822, 823, 824, 827, 828, 829, 831, 835, 836, 837, 839, 842, 850, 851, 852, 853, 854, 855, 856, 858, 859, 860, 862, 864, 865, 866, 867, 869, 870, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 892, 893, 894, 895, 896, 897, 899, 900, 902, 903, 904, 905, 906, 907, 908, 910, 915, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 955, 956, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 983, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 1000, 1004, 1005, 1007, 1009, 1010, 1012, 1015, 1016, 1017, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1036, 1037, 1040, 1041, 1042, 1043, 1045, 1046, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1058, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1137, 1138, 1139, 1140, 1142, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1281, 1282, 1283, 1285, 1286, 1287, 1289, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1314, 1315, 1316, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1338, 1339, 1340, 1342, 1343, 1344, 1346, 1347, 1349, 1351, 1358, 1359, 1366, 1371, 1372, 1373, 1382, 1383, 1384, 1385, 1387, 1388, 1389, 1390, 1391, 1402, 1403, 1411, 1415, 1416, 1417, 1418, 1423, 1425, 1426, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1469, 1470, 1471, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1511, 1512, 1513, 1514, 1516, 1517, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1528, 1529, 1531, 1532, 1533, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1566, 1567, 1568, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1614, 1615, 1616, 1617, 1619, 1620, 1624, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1637, 1638, 1639, 1640, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1657, 1658, 1660, 1662, 1663, 1664, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1687, 1688, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1706, 1707, 1709, 1710, 1711, 1712, 1713, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1733, 1734, 1735, 1736, 1738, 1741, 1743, 1745, 1748, 1749, 1751, 1753, 1754, 1755, 1757, 1758, 1759, 1762, 1763, 1764, 1768, 1769, 1770, 1772, 1774, 1775, 1777, 1778, 1781, 1782, 1783, 1784, 1788, 1789, 1790, 1793, 1794, 1795, 1798, 1800, 1802, 1803, 1804], "One": [0, 4, 9, 14, 23, 56, 57, 60, 555, 774, 962, 971, 1021, 1302, 1384, 1432, 1435, 1499, 1507, 1599, 1600, 1717, 1728, 1738, 1740, 1741, 1753, 1754, 1760, 1761, 1762, 1764, 1769, 1782, 1791, 1798], "thing": [0, 2, 4, 8, 9, 23, 33, 35, 38, 57, 60, 962, 1039, 1131, 1166, 1349, 1663, 1740, 1759, 1762, 1764, 1765, 1766, 1767, 1772, 1777, 1781, 1784, 1785, 1791], "either": [0, 2, 9, 10, 14, 17, 20, 21, 23, 27, 29, 33, 34, 39, 41, 46, 48, 49, 50, 53, 57, 59, 60, 131, 198, 289, 297, 485, 487, 589, 648, 652, 653, 654, 659, 660, 670, 678, 693, 699, 738, 746, 755, 756, 782, 795, 814, 821, 905, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 958, 962, 1007, 1023, 1030, 1045, 1085, 1100, 1101, 1116, 1131, 1156, 1157, 1160, 1161, 1164, 1165, 1166, 1167, 1178, 1179, 1180, 1182, 1183, 1184, 1186, 1194, 1204, 1210, 1217, 1219, 1241, 1242, 1244, 1245, 1250, 1253, 1254, 1255, 1256, 1257, 1264, 1265, 1267, 1281, 1282, 1297, 1298, 1300, 1302, 1303, 1304, 1319, 1320, 1330, 1358, 1359, 1382, 1390, 1415, 1421, 1423, 1450, 1470, 1483, 1505, 1520, 1522, 1528, 1583, 1629, 1684, 1688, 1731, 1735, 1738, 1740, 1741, 1743, 1753, 1757, 1759, 1760, 1762, 1764, 1765, 1766, 1767, 1769, 1770, 1772, 1774, 1777, 1780, 1781, 1782, 1784, 1790, 1791, 1793, 1794, 1797, 1800, 1805], "callabl": [0, 4, 20, 21, 23, 27, 29, 31, 35, 39, 41, 46, 48, 50, 53, 59, 60, 96, 373, 795, 850, 851, 853, 962, 963, 964, 970, 971, 1030, 1033, 1041, 1045, 1101, 1102, 1250, 1293, 1295, 1297, 1299, 1423, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1488, 1490, 1491, 1492, 1493, 1494, 1501, 1504, 1569, 1728, 1735, 1738, 1740, 1741, 1742, 1750, 1762, 1770, 1777, 1781, 1782, 1783, 1789, 1800, 1802, 1803, 1804], "take": [0, 1, 2, 3, 4, 5, 8, 10, 14, 20, 21, 23, 27, 29, 31, 32, 33, 35, 39, 47, 48, 49, 50, 53, 55, 56, 57, 58, 59, 60, 674, 748, 749, 750, 751, 752, 753, 755, 756, 788, 808, 844, 893, 895, 896, 921, 923, 926, 929, 933, 934, 936, 939, 962, 963, 964, 965, 966, 967, 968, 970, 971, 1062, 1084, 1087, 1158, 1167, 1194, 1198, 1199, 1202, 1220, 1244, 1245, 1246, 1247, 1248, 1250, 1258, 1265, 1293, 1303, 1304, 1342, 1343, 1360, 1384, 1423, 1491, 1495, 1520, 1530, 1546, 1548, 1554, 1587, 1709, 1728, 1735, 1738, 1739, 1741, 1747, 1748, 1751, 1752, 1753, 1754, 1758, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1768, 1770, 1774, 1776, 1777, 1779, 1781, 1783, 1784, 1789, 1790, 1791, 1793, 1796, 1797, 1798, 1802], "graphmodul": [0, 31, 34, 35, 38, 1584, 1585, 1586, 1587, 1803], "example_input": [0, 31, 35, 708, 709, 1041, 1045, 1586, 1587, 1784, 1803], "python": [0, 1, 2, 4, 5, 10, 14, 15, 17, 20, 23, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 45, 46, 48, 49, 53, 60, 328, 561, 596, 695, 728, 748, 749, 750, 751, 752, 753, 755, 756, 781, 782, 794, 844, 850, 851, 853, 900, 905, 908, 923, 925, 953, 958, 962, 963, 964, 965, 966, 967, 968, 970, 971, 991, 992, 1006, 1028, 1030, 1031, 1033, 1034, 1035, 1040, 1041, 1045, 1101, 1187, 1251, 1252, 1260, 1261, 1411, 1423, 1514, 1517, 1593, 1604, 1608, 1611, 1629, 1728, 1735, 1745, 1751, 1753, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1769, 1772, 1775, 1776, 1778, 1781, 1784, 1788, 1789, 1790, 1791, 1799, 1800], "run": [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14, 15, 17, 20, 21, 23, 24, 27, 29, 31, 33, 34, 35, 37, 38, 39, 40, 41, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 127, 702, 708, 740, 754, 755, 756, 852, 853, 962, 967, 971, 1005, 1030, 1031, 1033, 1034, 1037, 1039, 1041, 1043, 1045, 1046, 1075, 1101, 1102, 1130, 1168, 1169, 1170, 1187, 1213, 1214, 1215, 1223, 1224, 1225, 1232, 1233, 1234, 1250, 1278, 1289, 1418, 1423, 1478, 1480, 1481, 1482, 1484, 1490, 1494, 1530, 1547, 1548, 1549, 1550, 1553, 1582, 1586, 1587, 1588, 1632, 1636, 1667, 1711, 1713, 1721, 1728, 1736, 1738, 1741, 1748, 1750, 1751, 1757, 1758, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1780, 1781, 1782, 1784, 1787, 1788, 1789, 1790, 1791, 1793, 1798, 1801, 1802, 1803], "faster": [0, 1, 3, 9, 12, 20, 21, 33, 34, 36, 53, 749, 755, 756, 961, 1059, 1060, 1065, 1066, 1070, 1075, 1083, 1085, 1087, 1090, 1093, 1095, 1099, 1102, 1266, 1283, 1387, 1402, 1423, 1432, 1480, 1492, 1670, 1671, 1672, 1674, 1675, 1748, 1759, 1762, 1767, 1784, 1793, 1798], "can": [0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 20, 21, 23, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 127, 131, 230, 299, 311, 431, 460, 485, 487, 516, 586, 589, 603, 645, 655, 656, 657, 662, 671, 672, 674, 682, 683, 686, 687, 688, 699, 702, 703, 710, 727, 728, 737, 738, 739, 740, 741, 742, 743, 746, 748, 749, 750, 751, 752, 753, 754, 755, 756, 758, 762, 765, 782, 788, 795, 800, 809, 811, 814, 820, 822, 824, 831, 832, 850, 852, 856, 858, 860, 864, 865, 888, 905, 906, 909, 910, 923, 925, 926, 927, 928, 941, 944, 961, 962, 963, 964, 966, 967, 968, 970, 971, 974, 975, 983, 986, 991, 992, 1005, 1021, 1027, 1028, 1030, 1031, 1033, 1034, 1036, 1040, 1041, 1043, 1045, 1046, 1051, 1054, 1061, 1069, 1072, 1076, 1077, 1082, 1085, 1088, 1089, 1093, 1099, 1101, 1118, 1119, 1121, 1131, 1147, 1149, 1150, 1151, 1156, 1157, 1158, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1187, 1188, 1192, 1193, 1194, 1195, 1198, 1199, 1202, 1207, 1208, 1209, 1211, 1217, 1219, 1220, 1223, 1224, 1225, 1236, 1240, 1241, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1251, 1252, 1255, 1256, 1257, 1259, 1260, 1261, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1277, 1278, 1281, 1286, 1289, 1292, 1293, 1295, 1296, 1297, 1299, 1300, 1302, 1314, 1315, 1316, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1342, 1343, 1358, 1371, 1372, 1373, 1391, 1415, 1418, 1419, 1420, 1421, 1422, 1423, 1425, 1426, 1429, 1437, 1458, 1459, 1463, 1468, 1470, 1474, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1489, 1490, 1491, 1492, 1493, 1494, 1496, 1497, 1498, 1499, 1502, 1503, 1505, 1509, 1511, 1520, 1524, 1528, 1529, 1531, 1546, 1548, 1551, 1552, 1554, 1565, 1569, 1583, 1584, 1586, 1587, 1588, 1597, 1601, 1611, 1617, 1620, 1632, 1634, 1635, 1637, 1662, 1670, 1671, 1672, 1673, 1674, 1675, 1679, 1682, 1683, 1684, 1688, 1700, 1704, 1707, 1709, 1717, 1720, 1723, 1724, 1728, 1733, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1745, 1747, 1748, 1750, 1751, 1752, 1753, 1754, 1755, 1758, 1760, 1761, 1762, 1763, 1764, 1765, 1767, 1768, 1769, 1770, 1772, 1773, 1774, 1775, 1776, 1777, 1780, 1781, 1782, 1783, 1784, 1785, 1787, 1789, 1790, 1791, 1793, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805], "also": [0, 1, 2, 3, 4, 6, 8, 9, 10, 12, 14, 15, 17, 20, 21, 23, 27, 29, 30, 31, 33, 37, 38, 45, 48, 53, 57, 58, 59, 60, 131, 195, 198, 199, 230, 299, 485, 487, 489, 514, 586, 655, 656, 657, 674, 728, 737, 738, 746, 764, 773, 787, 808, 850, 853, 864, 886, 887, 905, 909, 925, 956, 962, 968, 970, 971, 972, 975, 977, 987, 988, 992, 1005, 1030, 1033, 1034, 1036, 1039, 1043, 1045, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1081, 1082, 1083, 1084, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1097, 1098, 1131, 1137, 1138, 1146, 1158, 1166, 1168, 1169, 1170, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1194, 1197, 1202, 1216, 1220, 1250, 1257, 1265, 1279, 1281, 1289, 1298, 1299, 1301, 1325, 1326, 1327, 1347, 1384, 1399, 1418, 1423, 1435, 1437, 1447, 1449, 1451, 1452, 1453, 1454, 1468, 1495, 1501, 1505, 1508, 1511, 1532, 1546, 1586, 1601, 1608, 1620, 1630, 1645, 1646, 1663, 1665, 1679, 1688, 1695, 1697, 1700, 1706, 1707, 1718, 1719, 1728, 1731, 1735, 1736, 1738, 1740, 1741, 1745, 1747, 1748, 1751, 1752, 1753, 1754, 1757, 1758, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1772, 1773, 1774, 1775, 1776, 1777, 1780, 1781, 1782, 1784, 1789, 1790, 1793, 1794, 1796, 1797, 1798, 1799, 1800, 1801, 1803, 1804], "provid": [0, 1, 2, 4, 8, 9, 10, 12, 14, 15, 20, 21, 23, 24, 27, 29, 33, 35, 36, 37, 38, 39, 41, 46, 48, 49, 50, 51, 53, 59, 60, 127, 575, 605, 652, 653, 654, 659, 660, 662, 670, 671, 674, 678, 740, 749, 751, 752, 753, 774, 779, 782, 787, 788, 807, 819, 864, 905, 925, 961, 971, 983, 991, 992, 1027, 1030, 1036, 1037, 1041, 1043, 1045, 1060, 1077, 1102, 1134, 1181, 1182, 1183, 1186, 1202, 1203, 1211, 1216, 1220, 1221, 1246, 1247, 1248, 1250, 1256, 1257, 1260, 1265, 1267, 1278, 1293, 1295, 1297, 1319, 1320, 1423, 1428, 1439, 1459, 1465, 1505, 1508, 1513, 1525, 1526, 1531, 1532, 1546, 1552, 1569, 1583, 1614, 1624, 1670, 1671, 1672, 1673, 1674, 1675, 1711, 1713, 1728, 1735, 1738, 1740, 1741, 1745, 1747, 1748, 1750, 1751, 1752, 1753, 1762, 1763, 1764, 1765, 1767, 1770, 1771, 1773, 1777, 1778, 1780, 1781, 1782, 1784, 1785, 1787, 1789, 1790, 1791, 1793, 1794, 1795, 1796, 1798, 1799, 1800, 1801, 1805], "addit": [0, 1, 2, 4, 6, 8, 10, 14, 15, 20, 23, 24, 29, 33, 37, 38, 42, 48, 49, 53, 59, 60, 311, 485, 579, 663, 665, 666, 667, 668, 672, 695, 864, 1027, 1030, 1034, 1039, 1044, 1158, 1169, 1170, 1171, 1181, 1182, 1183, 1194, 1201, 1204, 1211, 1214, 1215, 1229, 1230, 1231, 1235, 1236, 1237, 1238, 1240, 1246, 1247, 1248, 1250, 1256, 1258, 1283, 1285, 1289, 1293, 1297, 1299, 1318, 1325, 1326, 1327, 1364, 1423, 1483, 1546, 1584, 1718, 1719, 1726, 1738, 1740, 1741, 1750, 1752, 1753, 1754, 1759, 1761, 1762, 1764, 1765, 1769, 1772, 1773, 1776, 1777, 1778, 1783, 1784, 1785, 1787, 1789, 1790, 1791, 1793, 1797, 1800], "context": [0, 1, 3, 27, 35, 39, 48, 49, 53, 60, 127, 702, 737, 738, 739, 740, 741, 754, 762, 815, 829, 831, 842, 848, 853, 860, 879, 881, 909, 963, 967, 970, 1005, 1030, 1250, 1418, 1423, 1435, 1437, 1468, 1634, 1736, 1741, 1742, 1751, 1758, 1759, 1762, 1764, 1768, 1769, 1772, 1777, 1778, 1781, 1783, 1788, 1789, 1791, 1796, 1801], "like": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 14, 15, 20, 21, 23, 29, 33, 34, 35, 38, 46, 48, 49, 53, 54, 55, 56, 57, 58, 60, 312, 561, 589, 674, 703, 726, 746, 755, 756, 764, 773, 850, 851, 860, 900, 905, 906, 926, 948, 951, 952, 958, 962, 965, 966, 967, 971, 987, 988, 1028, 1030, 1031, 1037, 1040, 1045, 1049, 1076, 1077, 1088, 1101, 1158, 1166, 1194, 1197, 1213, 1214, 1215, 1250, 1251, 1252, 1260, 1261, 1278, 1301, 1341, 1359, 1414, 1418, 1423, 1424, 1425, 1426, 1433, 1458, 1474, 1517, 1569, 1585, 1597, 1601, 1620, 1629, 1632, 1688, 1697, 1728, 1733, 1735, 1736, 1738, 1740, 1741, 1747, 1751, 1752, 1753, 1758, 1759, 1762, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1775, 1776, 1777, 1782, 1783, 1784, 1787, 1789, 1790, 1793, 1795, 1796, 1800, 1803, 1804], "jit": [0, 1, 12, 14, 31, 34, 36, 850, 851, 881, 980, 1028, 1029, 1030, 1044, 1476, 1635, 1636, 1736, 1740, 1743, 1748, 1753, 1761, 1769, 1775, 1777, 1784, 1789, 1798], "fuser": [0, 703, 1043, 1738], "fuser2": 0, "set": [0, 1, 2, 3, 4, 6, 9, 10, 13, 14, 19, 20, 21, 23, 24, 27, 29, 32, 33, 35, 38, 39, 41, 46, 48, 49, 50, 51, 53, 56, 59, 60, 65, 127, 131, 230, 306, 418, 419, 420, 421, 422, 431, 468, 492, 552, 655, 657, 674, 693, 699, 702, 703, 704, 706, 707, 708, 710, 713, 726, 738, 740, 747, 748, 749, 750, 751, 752, 753, 754, 762, 774, 779, 790, 794, 801, 819, 833, 842, 854, 855, 873, 874, 875, 876, 877, 878, 879, 880, 906, 908, 961, 977, 992, 1010, 1011, 1030, 1034, 1037, 1039, 1041, 1043, 1045, 1046, 1065, 1066, 1069, 1075, 1082, 1084, 1086, 1087, 1099, 1100, 1101, 1102, 1116, 1119, 1122, 1158, 1162, 1166, 1167, 1168, 1169, 1170, 1171, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1187, 1188, 1189, 1190, 1191, 1195, 1202, 1205, 1210, 1211, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1235, 1237, 1241, 1242, 1246, 1247, 1248, 1250, 1253, 1254, 1255, 1257, 1260, 1264, 1265, 1281, 1282, 1289, 1298, 1299, 1312, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1330, 1331, 1332, 1333, 1334, 1335, 1340, 1347, 1351, 1358, 1359, 1368, 1369, 1382, 1384, 1390, 1415, 1423, 1425, 1426, 1428, 1433, 1438, 1465, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1509, 1523, 1529, 1548, 1549, 1550, 1553, 1554, 1569, 1583, 1584, 1586, 1587, 1595, 1597, 1601, 1603, 1604, 1612, 1613, 1624, 1625, 1628, 1629, 1630, 1631, 1632, 1634, 1635, 1636, 1637, 1638, 1639, 1654, 1668, 1682, 1683, 1700, 1710, 1711, 1712, 1713, 1721, 1723, 1724, 1735, 1737, 1738, 1740, 1741, 1742, 1745, 1748, 1749, 1750, 1751, 1754, 1757, 1758, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1772, 1773, 1774, 1776, 1778, 1779, 1780, 1782, 1783, 1784, 1785, 1787, 1788, 1789, 1798, 1800, 1802, 1803, 1804], "backend_ctx_ctor": 0, "attribut": [0, 1, 2, 12, 20, 21, 23, 24, 30, 35, 60, 127, 266, 467, 468, 643, 652, 653, 654, 655, 656, 657, 659, 660, 670, 678, 706, 707, 708, 737, 740, 742, 746, 956, 1029, 1030, 1031, 1033, 1034, 1040, 1041, 1102, 1187, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1250, 1293, 1423, 1424, 1436, 1437, 1438, 1459, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1528, 1534, 1566, 1567, 1568, 1583, 1584, 1736, 1739, 1742, 1754, 1758, 1759, 1762, 1764, 1765, 1770, 1775, 1777, 1781, 1784, 1789, 1799, 1800, 1804, 1805], "see": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 14, 15, 16, 19, 20, 23, 24, 29, 32, 34, 35, 37, 38, 40, 48, 49, 51, 53, 57, 58, 59, 60, 66, 70, 72, 74, 76, 78, 80, 82, 84, 86, 89, 90, 91, 92, 93, 94, 95, 97, 99, 101, 103, 105, 106, 109, 111, 112, 113, 114, 115, 117, 119, 121, 122, 125, 127, 128, 130, 131, 132, 133, 134, 136, 138, 140, 142, 144, 146, 147, 148, 149, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 166, 169, 170, 174, 176, 177, 179, 181, 182, 184, 187, 188, 189, 191, 194, 195, 197, 201, 202, 203, 204, 205, 206, 207, 210, 211, 213, 215, 216, 217, 219, 221, 222, 224, 226, 228, 231, 232, 237, 239, 240, 241, 242, 243, 244, 246, 248, 250, 251, 252, 254, 256, 257, 258, 260, 263, 264, 267, 269, 271, 273, 274, 275, 276, 277, 278, 279, 281, 283, 285, 289, 297, 298, 299, 300, 301, 303, 304, 310, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 332, 334, 336, 338, 340, 342, 344, 345, 347, 349, 353, 354, 355, 356, 357, 359, 361, 363, 365, 367, 368, 369, 371, 372, 378, 379, 380, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 395, 396, 398, 399, 401, 403, 404, 405, 406, 407, 408, 411, 413, 415, 423, 425, 426, 428, 430, 432, 433, 434, 435, 437, 438, 440, 441, 443, 450, 452, 453, 455, 457, 461, 463, 465, 466, 467, 469, 470, 471, 473, 474, 477, 478, 479, 482, 487, 489, 490, 491, 493, 496, 497, 499, 501, 502, 504, 506, 509, 510, 511, 513, 514, 518, 519, 521, 523, 525, 526, 527, 532, 534, 536, 538, 539, 540, 541, 542, 544, 545, 546, 548, 550, 551, 562, 563, 564, 566, 567, 569, 571, 573, 577, 578, 581, 582, 583, 586, 587, 588, 590, 591, 592, 593, 609, 611, 612, 615, 646, 647, 648, 649, 652, 653, 654, 655, 656, 657, 659, 660, 662, 670, 671, 674, 675, 676, 677, 678, 679, 680, 681, 682, 685, 686, 687, 688, 693, 694, 695, 696, 697, 698, 699, 703, 713, 722, 723, 724, 727, 738, 740, 741, 742, 743, 745, 746, 750, 754, 759, 764, 766, 773, 775, 778, 792, 805, 809, 810, 811, 812, 814, 816, 817, 819, 832, 833, 842, 843, 853, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 870, 871, 872, 900, 903, 905, 906, 908, 909, 918, 923, 941, 944, 959, 964, 965, 966, 968, 975, 983, 987, 988, 992, 993, 1001, 1002, 1003, 1005, 1030, 1034, 1041, 1045, 1046, 1048, 1049, 1051, 1061, 1069, 1072, 1075, 1077, 1084, 1086, 1087, 1095, 1099, 1100, 1102, 1108, 1110, 1116, 1117, 1119, 1127, 1129, 1130, 1131, 1132, 1134, 1135, 1138, 1145, 1147, 1148, 1158, 1166, 1167, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1187, 1193, 1194, 1202, 1204, 1210, 1211, 1216, 1217, 1220, 1241, 1242, 1246, 1247, 1248, 1249, 1250, 1253, 1254, 1255, 1256, 1257, 1262, 1263, 1264, 1265, 1268, 1277, 1279, 1281, 1282, 1294, 1295, 1296, 1297, 1298, 1299, 1302, 1306, 1307, 1308, 1309, 1310, 1311, 1313, 1314, 1315, 1316, 1317, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1340, 1341, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1384, 1385, 1386, 1388, 1389, 1390, 1391, 1392, 1393, 1395, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1412, 1413, 1414, 1415, 1416, 1417, 1423, 1424, 1427, 1428, 1432, 1433, 1434, 1437, 1443, 1452, 1461, 1464, 1467, 1468, 1469, 1470, 1474, 1511, 1521, 1522, 1568, 1584, 1585, 1586, 1587, 1597, 1599, 1601, 1603, 1604, 1608, 1611, 1614, 1620, 1629, 1632, 1634, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1657, 1664, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1682, 1683, 1684, 1687, 1695, 1697, 1700, 1706, 1707, 1711, 1713, 1721, 1723, 1724, 1729, 1731, 1733, 1735, 1736, 1738, 1739, 1740, 1741, 1742, 1746, 1747, 1749, 1751, 1752, 1753, 1754, 1755, 1758, 1759, 1760, 1762, 1763, 1764, 1765, 1766, 1767, 1769, 1770, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1782, 1783, 1784, 1785, 1789, 1790, 1793, 1794, 1796, 1797, 1799, 1800, 1801, 1804, 1805], "aotautogradmemoryefficientfusionwithcontext": 0, "usag": [0, 1, 2, 5, 8, 10, 15, 20, 23, 27, 29, 30, 33, 38, 39, 42, 45, 46, 48, 50, 53, 60, 662, 671, 702, 703, 704, 706, 707, 708, 710, 738, 856, 875, 879, 905, 956, 961, 965, 966, 967, 1043, 1102, 1423, 1542, 1543, 1544, 1545, 1583, 1738, 1741, 1750, 1753, 1758, 1759, 1764, 1766, 1777, 1791, 1798, 1799, 1801, 1802, 1803], "Or": [0, 8, 35, 39, 60, 790, 1768, 1771, 1777, 1793], "string": [0, 4, 13, 14, 20, 23, 33, 35, 38, 39, 45, 46, 48, 60, 575, 710, 833, 850, 851, 905, 962, 1030, 1037, 1040, 1101, 1178, 1179, 1180, 1250, 1251, 1260, 1293, 1295, 1297, 1322, 1323, 1324, 1448, 1523, 1546, 1620, 1628, 1630, 1735, 1739, 1740, 1741, 1742, 1753, 1759, 1764, 1769, 1770, 1777, 1781, 1783, 1789, 1795, 1796, 1798, 1803, 1804], "name": [0, 2, 3, 4, 14, 21, 23, 29, 31, 32, 33, 35, 38, 39, 41, 42, 45, 46, 48, 50, 53, 60, 613, 661, 662, 671, 702, 706, 707, 708, 710, 759, 810, 836, 961, 969, 1028, 1030, 1031, 1037, 1040, 1045, 1046, 1060, 1065, 1066, 1072, 1073, 1075, 1076, 1077, 1078, 1088, 1089, 1091, 1093, 1094, 1101, 1250, 1300, 1432, 1433, 1434, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1464, 1465, 1467, 1476, 1546, 1552, 1568, 1583, 1620, 1630, 1722, 1735, 1736, 1738, 1739, 1741, 1742, 1745, 1749, 1750, 1751, 1757, 1759, 1762, 1763, 1764, 1767, 1769, 1770, 1777, 1778, 1779, 1781, 1782, 1783, 1789, 1790, 1795, 1798, 1800, 1801, 1802, 1803, 1804, 1805], "list_backend": [0, 31, 34], "If": [0, 1, 2, 3, 4, 5, 6, 8, 10, 12, 14, 15, 18, 20, 21, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 59, 60, 74, 127, 131, 172, 183, 186, 230, 291, 295, 297, 418, 419, 420, 421, 422, 431, 444, 454, 468, 471, 489, 492, 508, 516, 552, 555, 575, 579, 589, 602, 605, 606, 607, 609, 611, 612, 613, 615, 670, 674, 678, 693, 695, 699, 708, 710, 713, 722, 723, 724, 725, 726, 727, 728, 737, 739, 740, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 763, 764, 766, 773, 775, 776, 777, 779, 783, 785, 786, 787, 788, 789, 790, 797, 800, 801, 802, 806, 807, 808, 811, 812, 814, 816, 819, 820, 822, 824, 831, 842, 848, 853, 854, 873, 876, 886, 887, 888, 892, 893, 894, 895, 896, 905, 906, 907, 908, 918, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 944, 948, 956, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 970, 971, 972, 983, 987, 988, 990, 991, 992, 993, 1004, 1007, 1021, 1027, 1030, 1033, 1034, 1035, 1037, 1039, 1041, 1042, 1045, 1046, 1049, 1050, 1051, 1055, 1059, 1060, 1065, 1066, 1068, 1069, 1071, 1072, 1073, 1075, 1076, 1077, 1079, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1090, 1092, 1093, 1095, 1096, 1097, 1099, 1100, 1101, 1102, 1112, 1116, 1117, 1119, 1121, 1124, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1140, 1142, 1144, 1145, 1146, 1147, 1148, 1149, 1158, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1173, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1188, 1189, 1190, 1191, 1193, 1194, 1195, 1197, 1198, 1199, 1202, 1203, 1204, 1210, 1211, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1226, 1227, 1228, 1229, 1230, 1231, 1235, 1237, 1241, 1242, 1243, 1244, 1245, 1250, 1251, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1264, 1265, 1267, 1271, 1272, 1273, 1274, 1275, 1276, 1281, 1282, 1289, 1293, 1295, 1296, 1297, 1298, 1299, 1301, 1302, 1305, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1330, 1331, 1332, 1333, 1334, 1335, 1338, 1339, 1340, 1342, 1343, 1347, 1349, 1351, 1358, 1359, 1364, 1366, 1368, 1369, 1371, 1372, 1373, 1382, 1383, 1384, 1387, 1390, 1391, 1402, 1403, 1414, 1415, 1423, 1424, 1428, 1432, 1433, 1434, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1448, 1451, 1452, 1453, 1454, 1458, 1459, 1460, 1461, 1463, 1464, 1465, 1468, 1469, 1470, 1474, 1475, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1509, 1511, 1512, 1517, 1521, 1523, 1524, 1548, 1549, 1550, 1553, 1583, 1586, 1593, 1594, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1609, 1610, 1615, 1617, 1620, 1624, 1626, 1628, 1631, 1632, 1637, 1639, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1662, 1664, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1679, 1682, 1683, 1684, 1687, 1688, 1694, 1700, 1701, 1703, 1704, 1706, 1707, 1709, 1710, 1711, 1712, 1713, 1718, 1719, 1721, 1722, 1723, 1724, 1728, 1733, 1734, 1735, 1738, 1741, 1743, 1745, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1758, 1759, 1760, 1762, 1764, 1765, 1766, 1767, 1768, 1769, 1772, 1773, 1774, 1775, 1776, 1777, 1780, 1781, 1782, 1783, 1784, 1785, 1788, 1789, 1790, 1791, 1793, 1794, 1795, 1796, 1798, 1799, 1800, 1804], "true": [0, 1, 2, 3, 4, 6, 14, 20, 21, 23, 24, 27, 29, 32, 33, 34, 35, 38, 39, 50, 53, 57, 58, 59, 60, 127, 173, 186, 236, 295, 297, 304, 305, 306, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 319, 327, 371, 375, 377, 421, 431, 433, 444, 450, 460, 467, 468, 476, 488, 489, 527, 538, 541, 552, 562, 566, 575, 581, 589, 603, 608, 609, 610, 611, 612, 613, 615, 634, 635, 636, 641, 642, 643, 644, 645, 646, 647, 648, 649, 652, 653, 654, 655, 656, 657, 660, 663, 668, 670, 674, 675, 678, 679, 682, 683, 693, 699, 700, 721, 723, 724, 728, 737, 740, 741, 744, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 762, 764, 767, 770, 772, 773, 779, 780, 786, 787, 788, 794, 795, 800, 811, 848, 900, 909, 910, 911, 927, 928, 934, 935, 958, 962, 963, 964, 966, 967, 968, 970, 971, 972, 974, 986, 987, 988, 991, 992, 1003, 1005, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1030, 1034, 1035, 1036, 1039, 1045, 1046, 1047, 1049, 1051, 1054, 1059, 1060, 1071, 1072, 1073, 1076, 1077, 1078, 1079, 1082, 1084, 1086, 1087, 1088, 1090, 1091, 1092, 1093, 1095, 1096, 1099, 1101, 1102, 1111, 1112, 1113, 1114, 1117, 1118, 1119, 1121, 1123, 1127, 1129, 1130, 1131, 1132, 1135, 1140, 1145, 1148, 1151, 1154, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1188, 1189, 1190, 1191, 1193, 1194, 1195, 1198, 1199, 1202, 1203, 1204, 1205, 1210, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1237, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1253, 1254, 1255, 1256, 1257, 1259, 1264, 1265, 1266, 1267, 1281, 1282, 1289, 1293, 1295, 1296, 1297, 1298, 1299, 1302, 1303, 1312, 1314, 1315, 1316, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1330, 1331, 1332, 1333, 1334, 1335, 1338, 1339, 1340, 1342, 1343, 1347, 1349, 1351, 1357, 1358, 1359, 1371, 1372, 1373, 1382, 1390, 1415, 1416, 1418, 1423, 1424, 1426, 1427, 1428, 1429, 1432, 1433, 1436, 1437, 1438, 1450, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1467, 1468, 1469, 1470, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1509, 1511, 1513, 1521, 1523, 1524, 1529, 1535, 1539, 1546, 1554, 1557, 1570, 1572, 1574, 1578, 1581, 1584, 1593, 1594, 1595, 1612, 1613, 1620, 1623, 1624, 1632, 1633, 1634, 1637, 1639, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1662, 1665, 1682, 1683, 1684, 1687, 1688, 1694, 1700, 1704, 1709, 1718, 1719, 1721, 1722, 1723, 1724, 1728, 1731, 1735, 1737, 1739, 1740, 1741, 1747, 1749, 1751, 1752, 1753, 1754, 1758, 1759, 1760, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1773, 1774, 1775, 1777, 1781, 1782, 1783, 1784, 1785, 1786, 1788, 1789, 1790, 1793, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1804], "error": [0, 1, 2, 6, 9, 14, 16, 17, 20, 21, 23, 24, 26, 29, 34, 46, 48, 49, 53, 56, 57, 59, 60, 167, 198, 289, 291, 297, 299, 304, 516, 527, 586, 589, 713, 726, 728, 746, 748, 749, 750, 751, 752, 753, 754, 819, 853, 864, 876, 880, 903, 965, 966, 968, 971, 993, 1030, 1035, 1044, 1059, 1060, 1069, 1071, 1073, 1076, 1077, 1078, 1088, 1091, 1101, 1119, 1140, 1166, 1167, 1200, 1211, 1217, 1241, 1250, 1279, 1281, 1345, 1356, 1378, 1399, 1400, 1423, 1425, 1426, 1429, 1470, 1519, 1547, 1624, 1631, 1679, 1684, 1721, 1728, 1729, 1735, 1736, 1738, 1740, 1741, 1747, 1751, 1752, 1753, 1754, 1758, 1759, 1762, 1764, 1765, 1767, 1768, 1774, 1777, 1778, 1781, 1787, 1789, 1794, 1799, 1800, 1802, 1803], "whole": [0, 20, 23, 35, 971, 1027, 1030, 1250, 1278, 1289, 1423, 1728, 1759, 1763, 1772, 1773, 1781], "program": [0, 2, 4, 5, 9, 17, 20, 23, 33, 34, 36, 38, 40, 49, 51, 60, 589, 800, 801, 856, 858, 962, 1632, 1738, 1740, 1742, 1759, 1762, 1766, 1769, 1771, 1772, 1775, 1776, 1798], "turn": [0, 14, 20, 34, 35, 57, 60, 721, 1018, 1045, 1294, 1296, 1670, 1671, 1672, 1673, 1674, 1675, 1747, 1759, 1762, 1773, 1774, 1777, 1783, 1784, 1790, 1793], "decor": [0, 1, 2, 29, 36, 41, 45, 49, 60, 746, 909, 1005, 1035, 1041, 1047, 1468, 1738, 1740, 1741, 1745, 1758, 1759, 1764, 1782, 1789, 1804], "shape": [0, 2, 9, 12, 21, 23, 29, 32, 33, 38, 53, 55, 58, 60, 74, 148, 168, 185, 195, 375, 377, 418, 420, 422, 444, 469, 470, 485, 487, 489, 515, 537, 589, 601, 603, 604, 613, 659, 660, 670, 672, 674, 678, 680, 681, 682, 683, 686, 687, 688, 695, 726, 732, 745, 749, 751, 752, 753, 759, 765, 766, 768, 771, 776, 778, 782, 783, 795, 802, 823, 895, 896, 897, 899, 900, 905, 906, 908, 910, 925, 926, 927, 928, 936, 937, 938, 944, 950, 951, 952, 953, 959, 966, 967, 969, 970, 971, 972, 974, 986, 991, 992, 996, 1004, 1007, 1021, 1027, 1043, 1045, 1046, 1049, 1054, 1055, 1059, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1118, 1119, 1123, 1131, 1136, 1137, 1139, 1140, 1151, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1262, 1263, 1264, 1265, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1314, 1315, 1316, 1318, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1329, 1330, 1338, 1339, 1343, 1347, 1349, 1358, 1359, 1364, 1371, 1372, 1373, 1383, 1384, 1387, 1388, 1389, 1391, 1415, 1418, 1423, 1425, 1426, 1428, 1432, 1434, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1448, 1451, 1452, 1471, 1474, 1476, 1511, 1520, 1524, 1593, 1594, 1597, 1599, 1600, 1601, 1608, 1610, 1611, 1615, 1624, 1627, 1652, 1665, 1666, 1668, 1671, 1673, 1679, 1684, 1685, 1688, 1694, 1696, 1703, 1707, 1717, 1718, 1719, 1728, 1731, 1733, 1737, 1738, 1739, 1741, 1752, 1753, 1754, 1759, 1760, 1762, 1764, 1765, 1766, 1778, 1779, 1783, 1786, 1789, 1793, 1794, 1798, 1799, 1800], "support": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 14, 15, 16, 17, 20, 21, 23, 27, 29, 30, 34, 35, 36, 37, 38, 40, 41, 48, 49, 53, 56, 57, 59, 60, 287, 297, 431, 555, 589, 601, 602, 603, 605, 609, 611, 612, 615, 645, 652, 653, 654, 686, 687, 688, 693, 699, 700, 701, 702, 703, 704, 708, 741, 746, 755, 756, 763, 764, 768, 771, 773, 775, 787, 788, 802, 808, 810, 814, 850, 851, 853, 900, 902, 905, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 950, 951, 952, 953, 955, 956, 957, 968, 970, 987, 988, 1000, 1027, 1034, 1041, 1045, 1049, 1050, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1074, 1075, 1076, 1077, 1078, 1079, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1102, 1120, 1124, 1128, 1133, 1134, 1139, 1178, 1179, 1180, 1181, 1182, 1183, 1190, 1193, 1194, 1197, 1217, 1237, 1255, 1256, 1289, 1299, 1301, 1322, 1323, 1324, 1325, 1326, 1327, 1329, 1330, 1339, 1341, 1347, 1358, 1364, 1414, 1415, 1417, 1423, 1470, 1475, 1480, 1483, 1511, 1523, 1533, 1584, 1586, 1587, 1607, 1608, 1629, 1632, 1633, 1663, 1665, 1668, 1685, 1688, 1709, 1711, 1713, 1725, 1726, 1727, 1734, 1735, 1736, 1738, 1740, 1742, 1743, 1745, 1748, 1750, 1751, 1755, 1759, 1760, 1761, 1762, 1763, 1764, 1768, 1770, 1772, 1773, 1775, 1776, 1778, 1780, 1781, 1782, 1783, 1787, 1789, 1794, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1804], "exampl": [0, 1, 2, 3, 4, 6, 8, 9, 10, 14, 17, 20, 21, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 38, 39, 41, 42, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59, 64, 65, 168, 185, 218, 230, 236, 265, 287, 289, 291, 293, 297, 311, 328, 418, 419, 420, 421, 422, 444, 454, 456, 460, 465, 468, 471, 485, 487, 489, 508, 515, 529, 531, 552, 553, 555, 556, 557, 558, 559, 560, 561, 579, 589, 597, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 636, 644, 645, 652, 653, 654, 655, 656, 657, 659, 660, 662, 670, 671, 672, 674, 675, 676, 677, 678, 679, 686, 687, 688, 699, 702, 703, 704, 705, 706, 707, 708, 710, 713, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 763, 765, 766, 767, 768, 769, 770, 771, 772, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 793, 794, 795, 797, 800, 801, 802, 803, 804, 805, 806, 807, 808, 850, 851, 856, 858, 884, 885, 886, 887, 888, 889, 892, 893, 894, 895, 896, 897, 899, 900, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 915, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 961, 962, 963, 964, 969, 971, 972, 973, 974, 977, 983, 986, 989, 990, 991, 992, 993, 995, 996, 1000, 1004, 1005, 1007, 1015, 1017, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1030, 1031, 1033, 1034, 1035, 1036, 1037, 1039, 1040, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1050, 1051, 1052, 1053, 1054, 1055, 1058, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1079, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1103, 1104, 1105, 1106, 1107, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1117, 1118, 1119, 1120, 1121, 1123, 1124, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1142, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1312, 1314, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1329, 1330, 1331, 1338, 1339, 1342, 1343, 1347, 1349, 1382, 1384, 1385, 1388, 1389, 1415, 1418, 1423, 1427, 1432, 1433, 1435, 1437, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1460, 1461, 1462, 1463, 1464, 1465, 1467, 1468, 1469, 1470, 1471, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1498, 1499, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1512, 1514, 1516, 1517, 1519, 1520, 1521, 1522, 1523, 1524, 1529, 1542, 1543, 1544, 1545, 1546, 1552, 1566, 1584, 1585, 1586, 1587, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1599, 1601, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1619, 1620, 1624, 1626, 1627, 1628, 1629, 1630, 1633, 1634, 1637, 1640, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1657, 1658, 1662, 1665, 1666, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1682, 1683, 1685, 1687, 1688, 1690, 1691, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1709, 1710, 1711, 1712, 1713, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1733, 1734, 1735, 1736, 1738, 1740, 1741, 1742, 1745, 1747, 1749, 1750, 1752, 1753, 1754, 1757, 1759, 1760, 1761, 1762, 1766, 1768, 1769, 1770, 1772, 1773, 1774, 1775, 1778, 1780, 1781, 1782, 1783, 1784, 1785, 1789, 1791, 1793, 1794, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804], "toy_exampl": [0, 31, 32, 33, 35, 38], "b": [0, 1, 2, 4, 12, 20, 23, 29, 31, 32, 33, 34, 35, 38, 46, 60, 236, 311, 373, 589, 601, 602, 662, 671, 695, 728, 744, 746, 747, 763, 774, 775, 777, 781, 783, 785, 788, 793, 802, 808, 850, 851, 897, 900, 904, 905, 950, 951, 952, 953, 958, 962, 973, 995, 1007, 1033, 1040, 1041, 1049, 1050, 1052, 1061, 1062, 1070, 1074, 1075, 1079, 1082, 1083, 1084, 1085, 1086, 1087, 1090, 1091, 1092, 1095, 1096, 1099, 1102, 1111, 1113, 1114, 1120, 1128, 1133, 1135, 1139, 1171, 1193, 1194, 1201, 1237, 1318, 1339, 1346, 1364, 1432, 1459, 1460, 1461, 1462, 1470, 1491, 1493, 1524, 1552, 1595, 1608, 1611, 1627, 1639, 1658, 1665, 1670, 1671, 1672, 1674, 1675, 1679, 1685, 1687, 1702, 1709, 1710, 1712, 1725, 1730, 1737, 1738, 1739, 1740, 1741, 1752, 1753, 1754, 1757, 1758, 1760, 1762, 1766, 1767, 1768, 1773, 1775, 1783, 1784, 1790, 1791, 1793, 1794, 1797, 1798, 1803], "optimize_assert": 0, "hook": [0, 24, 27, 33, 35, 36, 53, 460, 662, 671, 746, 853, 1030, 1187, 1250, 1419, 1420, 1421, 1422, 1423, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1455, 1464, 1467, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1736, 1755, 1763, 1764, 1769, 1781, 1784], "export": [0, 15, 17, 23, 30, 51, 64, 758, 811, 1033, 1035, 1041, 1047, 1459, 1460, 1738, 1740, 1741, 1764, 1778, 1779, 1783, 1784, 1789], "same": [0, 1, 2, 4, 8, 14, 15, 16, 17, 20, 21, 23, 24, 27, 29, 33, 35, 39, 45, 46, 48, 49, 50, 51, 53, 56, 57, 59, 60, 116, 130, 172, 198, 231, 287, 289, 291, 295, 297, 315, 418, 419, 420, 421, 422, 444, 456, 469, 470, 472, 485, 487, 489, 492, 515, 552, 589, 590, 602, 605, 609, 611, 612, 613, 615, 636, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 659, 660, 670, 672, 675, 676, 677, 678, 679, 693, 699, 703, 705, 726, 727, 728, 742, 745, 748, 749, 750, 751, 752, 753, 755, 756, 763, 765, 766, 775, 777, 779, 782, 787, 789, 797, 808, 809, 811, 821, 823, 842, 853, 888, 893, 895, 896, 902, 905, 907, 908, 911, 921, 922, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 942, 953, 957, 958, 960, 961, 962, 965, 966, 967, 968, 969, 970, 971, 972, 975, 983, 991, 992, 1000, 1004, 1021, 1027, 1030, 1040, 1041, 1045, 1046, 1050, 1051, 1059, 1060, 1061, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1074, 1075, 1076, 1077, 1079, 1081, 1082, 1083, 1084, 1087, 1088, 1089, 1090, 1092, 1093, 1094, 1097, 1117, 1121, 1123, 1124, 1127, 1129, 1130, 1131, 1132, 1135, 1145, 1148, 1149, 1150, 1156, 1157, 1160, 1161, 1162, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1194, 1195, 1197, 1200, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1219, 1222, 1232, 1233, 1234, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1253, 1254, 1255, 1256, 1258, 1259, 1264, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1301, 1302, 1305, 1312, 1318, 1319, 1320, 1322, 1323, 1324, 1330, 1339, 1347, 1349, 1358, 1359, 1415, 1423, 1432, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1448, 1451, 1452, 1458, 1462, 1470, 1471, 1475, 1490, 1511, 1516, 1517, 1520, 1521, 1525, 1526, 1532, 1534, 1546, 1547, 1550, 1552, 1553, 1584, 1586, 1598, 1600, 1602, 1606, 1608, 1610, 1611, 1615, 1624, 1627, 1640, 1663, 1670, 1671, 1672, 1674, 1675, 1681, 1682, 1683, 1687, 1688, 1696, 1707, 1718, 1719, 1720, 1721, 1723, 1724, 1725, 1728, 1734, 1735, 1738, 1740, 1741, 1750, 1751, 1752, 1753, 1754, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1772, 1773, 1774, 1775, 1777, 1781, 1782, 1784, 1787, 1789, 1790, 1791, 1793, 1795, 1796, 1797, 1798, 1799, 1800, 1802, 1803, 1804], "don": [0, 1, 2, 5, 8, 10, 12, 23, 33, 35, 47, 54, 56, 57, 60, 127, 699, 740, 741, 754, 880, 961, 1045, 1123, 1213, 1214, 1215, 1302, 1415, 1418, 1423, 1471, 1480, 1481, 1631, 1735, 1738, 1742, 1751, 1752, 1753, 1759, 1762, 1764, 1766, 1770, 1772, 1776, 1777, 1780, 1781, 1782, 1784, 1789, 1790, 1793, 1804], "t": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 20, 21, 23, 29, 30, 34, 35, 38, 41, 47, 48, 54, 56, 57, 58, 59, 60, 127, 289, 291, 297, 431, 508, 543, 603, 604, 613, 674, 695, 699, 725, 726, 727, 737, 739, 740, 741, 744, 746, 749, 754, 755, 756, 786, 787, 788, 793, 807, 809, 812, 832, 850, 851, 880, 903, 921, 926, 927, 928, 929, 933, 934, 935, 936, 937, 938, 939, 940, 942, 944, 956, 957, 958, 961, 962, 963, 971, 972, 983, 993, 1027, 1028, 1030, 1031, 1033, 1036, 1037, 1041, 1043, 1045, 1048, 1050, 1059, 1060, 1066, 1068, 1069, 1072, 1079, 1087, 1088, 1093, 1101, 1102, 1110, 1123, 1136, 1137, 1138, 1147, 1167, 1171, 1173, 1178, 1179, 1180, 1187, 1193, 1194, 1202, 1211, 1213, 1214, 1215, 1216, 1220, 1237, 1250, 1265, 1281, 1283, 1293, 1301, 1302, 1318, 1322, 1323, 1324, 1331, 1338, 1339, 1359, 1364, 1383, 1402, 1415, 1418, 1420, 1421, 1423, 1424, 1432, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1448, 1459, 1461, 1462, 1471, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1497, 1507, 1513, 1519, 1523, 1551, 1554, 1605, 1630, 1631, 1640, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1663, 1665, 1684, 1688, 1689, 1694, 1697, 1700, 1706, 1709, 1728, 1729, 1735, 1737, 1738, 1739, 1740, 1742, 1750, 1751, 1752, 1753, 1754, 1758, 1759, 1760, 1761, 1762, 1764, 1765, 1767, 1769, 1770, 1772, 1775, 1776, 1777, 1779, 1780, 1781, 1782, 1784, 1789, 1790, 1791, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1804], "ani": [0, 1, 2, 3, 4, 5, 6, 8, 10, 12, 14, 17, 20, 21, 23, 24, 27, 29, 31, 32, 33, 34, 35, 38, 39, 41, 42, 46, 47, 48, 49, 51, 53, 57, 59, 60, 127, 230, 471, 516, 589, 613, 672, 695, 702, 703, 704, 706, 707, 708, 709, 710, 713, 737, 738, 739, 740, 746, 748, 754, 755, 756, 777, 781, 782, 800, 811, 846, 853, 864, 921, 922, 924, 925, 926, 928, 932, 936, 937, 938, 953, 961, 962, 969, 971, 992, 1029, 1030, 1034, 1036, 1040, 1041, 1043, 1045, 1051, 1059, 1061, 1065, 1066, 1070, 1075, 1076, 1077, 1082, 1083, 1086, 1090, 1093, 1099, 1101, 1155, 1156, 1157, 1159, 1160, 1161, 1162, 1166, 1167, 1171, 1172, 1178, 1179, 1180, 1187, 1188, 1192, 1196, 1197, 1200, 1201, 1204, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1216, 1217, 1236, 1237, 1239, 1240, 1241, 1249, 1250, 1258, 1260, 1261, 1264, 1268, 1269, 1270, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1299, 1300, 1301, 1318, 1322, 1323, 1324, 1364, 1383, 1384, 1418, 1423, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1449, 1459, 1460, 1462, 1463, 1465, 1470, 1499, 1532, 1542, 1543, 1544, 1545, 1551, 1552, 1554, 1604, 1620, 1635, 1637, 1688, 1728, 1735, 1738, 1739, 1740, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1758, 1759, 1761, 1762, 1764, 1765, 1767, 1768, 1769, 1770, 1771, 1772, 1774, 1777, 1779, 1781, 1782, 1784, 1789, 1790, 1791, 1793, 1795, 1798, 1800, 1802, 1803, 1804], "compil": [0, 14, 15, 31, 32, 34, 36, 60, 810, 834, 838, 850, 851, 962, 1028, 1031, 1034, 1035, 1041, 1042, 1043, 1045, 1046, 1047, 1737, 1738, 1740, 1741, 1742, 1743, 1758, 1761, 1763, 1769, 1776, 1777], "just": [0, 2, 3, 8, 14, 21, 23, 29, 31, 32, 33, 34, 35, 36, 37, 39, 46, 60, 561, 603, 613, 737, 739, 759, 800, 801, 1045, 1046, 1084, 1087, 1092, 1093, 1119, 1189, 1190, 1191, 1195, 1423, 1437, 1438, 1495, 1527, 1551, 1554, 1710, 1711, 1712, 1713, 1735, 1738, 1751, 1758, 1759, 1764, 1765, 1767, 1769, 1770, 1771, 1775, 1781, 1782, 1789, 1790, 1797, 1799, 1803], "us": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 14, 15, 16, 18, 20, 24, 27, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 45, 46, 47, 48, 49, 50, 53, 54, 56, 57, 58, 59, 65, 74, 96, 127, 131, 168, 185, 295, 297, 311, 318, 319, 381, 421, 431, 459, 460, 468, 471, 485, 489, 492, 515, 528, 555, 589, 602, 605, 628, 629, 630, 631, 632, 633, 636, 645, 646, 647, 648, 649, 662, 671, 674, 682, 683, 686, 687, 688, 693, 695, 699, 700, 701, 703, 705, 706, 707, 708, 710, 713, 726, 727, 728, 737, 738, 739, 740, 741, 742, 743, 745, 746, 748, 749, 750, 751, 754, 755, 756, 759, 762, 763, 764, 765, 773, 775, 776, 783, 785, 787, 795, 800, 803, 805, 808, 809, 810, 811, 812, 814, 816, 817, 819, 821, 831, 832, 835, 836, 842, 846, 850, 852, 853, 854, 856, 858, 859, 865, 873, 875, 876, 882, 886, 887, 888, 897, 905, 906, 908, 918, 919, 920, 923, 925, 933, 935, 939, 941, 948, 950, 953, 959, 961, 962, 963, 965, 966, 967, 968, 970, 971, 975, 976, 980, 981, 983, 987, 988, 989, 990, 1004, 1005, 1017, 1027, 1028, 1030, 1031, 1034, 1035, 1036, 1037, 1039, 1040, 1041, 1042, 1043, 1045, 1046, 1047, 1049, 1051, 1053, 1061, 1065, 1066, 1068, 1069, 1070, 1072, 1073, 1074, 1075, 1076, 1077, 1082, 1083, 1084, 1086, 1087, 1093, 1094, 1095, 1099, 1100, 1101, 1102, 1107, 1110, 1116, 1119, 1120, 1123, 1124, 1129, 1130, 1131, 1134, 1140, 1145, 1147, 1148, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1173, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1187, 1188, 1189, 1190, 1191, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1202, 1203, 1204, 1205, 1210, 1211, 1213, 1214, 1215, 1216, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1237, 1238, 1243, 1244, 1245, 1246, 1247, 1250, 1252, 1256, 1257, 1258, 1259, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1281, 1283, 1286, 1289, 1297, 1298, 1299, 1300, 1302, 1305, 1312, 1314, 1315, 1316, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1332, 1333, 1334, 1335, 1338, 1339, 1340, 1342, 1343, 1347, 1349, 1356, 1358, 1359, 1366, 1371, 1372, 1373, 1383, 1385, 1391, 1400, 1402, 1403, 1411, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1428, 1429, 1432, 1433, 1434, 1435, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1448, 1451, 1452, 1459, 1460, 1461, 1463, 1464, 1465, 1467, 1468, 1470, 1471, 1474, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1502, 1503, 1505, 1506, 1508, 1509, 1511, 1521, 1523, 1524, 1527, 1531, 1534, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1565, 1583, 1584, 1586, 1587, 1590, 1593, 1594, 1595, 1597, 1599, 1601, 1603, 1604, 1610, 1617, 1620, 1625, 1626, 1628, 1629, 1630, 1632, 1634, 1635, 1636, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1657, 1662, 1664, 1666, 1667, 1670, 1671, 1672, 1673, 1674, 1675, 1684, 1687, 1688, 1689, 1694, 1700, 1704, 1707, 1711, 1713, 1718, 1720, 1721, 1725, 1728, 1733, 1735, 1736, 1737, 1738, 1739, 1741, 1742, 1743, 1745, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1757, 1758, 1761, 1763, 1765, 1766, 1768, 1769, 1770, 1772, 1773, 1774, 1775, 1776, 1778, 1783, 1785, 1787, 1788, 1789, 1790, 1791, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804], "prior": [0, 10, 21, 23, 33, 39, 747, 1102, 1295, 1297, 1448, 1760, 1762, 1764, 1780, 1784], "manag": [0, 1, 2, 3, 8, 27, 29, 33, 35, 39, 46, 48, 49, 50, 53, 60, 65, 459, 741, 762, 809, 810, 812, 815, 816, 817, 819, 829, 831, 832, 833, 842, 843, 853, 856, 858, 859, 860, 862, 863, 864, 865, 870, 871, 872, 879, 881, 909, 963, 967, 970, 1005, 1423, 1434, 1435, 1437, 1468, 1634, 1736, 1741, 1742, 1759, 1766, 1769, 1777, 1778, 1782, 1783, 1788, 1789, 1790, 1796, 1801], "reset": [0, 2, 674, 740, 809, 856, 858, 870, 871, 872, 1202, 1266, 1513, 1548, 1553, 1595, 1689, 1750, 1777, 1788], "clear": [0, 3, 9, 10, 50, 60, 1030, 1250, 1251, 1260, 1735, 1759, 1762, 1770, 1775, 1778, 1779, 1780], "all": [0, 1, 2, 3, 4, 6, 7, 8, 10, 12, 14, 15, 17, 20, 21, 23, 24, 27, 29, 33, 34, 35, 37, 38, 39, 41, 45, 46, 47, 48, 49, 50, 51, 53, 56, 57, 58, 59, 60, 65, 127, 236, 289, 291, 297, 311, 459, 485, 487, 489, 517, 531, 579, 582, 589, 602, 603, 608, 610, 614, 615, 674, 703, 704, 710, 722, 725, 737, 738, 739, 740, 741, 744, 745, 746, 748, 749, 750, 751, 752, 753, 754, 755, 756, 759, 760, 761, 765, 774, 776, 781, 782, 786, 789, 790, 794, 806, 811, 812, 814, 815, 822, 823, 832, 840, 844, 850, 854, 855, 863, 864, 870, 871, 873, 874, 878, 880, 882, 922, 923, 924, 925, 928, 931, 932, 935, 938, 940, 942, 958, 961, 962, 968, 969, 970, 972, 992, 995, 1026, 1027, 1030, 1037, 1040, 1041, 1044, 1045, 1065, 1092, 1101, 1117, 1119, 1127, 1129, 1132, 1145, 1146, 1147, 1148, 1158, 1165, 1167, 1171, 1173, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1187, 1193, 1194, 1197, 1202, 1203, 1204, 1205, 1210, 1216, 1217, 1220, 1221, 1237, 1241, 1245, 1246, 1247, 1248, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1260, 1261, 1265, 1267, 1271, 1272, 1273, 1274, 1275, 1276, 1289, 1293, 1295, 1297, 1298, 1301, 1305, 1312, 1318, 1339, 1344, 1349, 1368, 1369, 1402, 1418, 1419, 1420, 1421, 1422, 1423, 1428, 1429, 1432, 1437, 1444, 1448, 1458, 1462, 1469, 1470, 1471, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1487, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1499, 1502, 1503, 1506, 1507, 1508, 1509, 1521, 1528, 1546, 1568, 1583, 1586, 1667, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1679, 1681, 1682, 1683, 1684, 1687, 1694, 1701, 1703, 1710, 1711, 1712, 1713, 1716, 1719, 1723, 1724, 1726, 1730, 1735, 1738, 1739, 1740, 1741, 1747, 1748, 1750, 1751, 1752, 1753, 1754, 1757, 1758, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1770, 1772, 1773, 1774, 1775, 1776, 1778, 1779, 1781, 1782, 1783, 1784, 1788, 1789, 1790, 1791, 1793, 1794, 1795, 1796, 1798, 1800, 1802, 1803, 1804], "cach": [0, 1, 3, 4, 29, 33, 38, 60, 459, 832, 833, 850, 853, 858, 860, 862, 864, 871, 876, 1424, 1437, 1751, 1766], "restor": [0, 3, 6, 27, 32, 60, 65, 950, 1100, 1116, 1615, 1637, 1770, 1775], "initi": [0, 2, 4, 5, 9, 16, 17, 20, 21, 27, 35, 39, 41, 48, 49, 51, 53, 65, 468, 552, 628, 629, 630, 631, 632, 633, 636, 646, 647, 648, 649, 659, 660, 670, 674, 678, 727, 811, 819, 839, 844, 845, 848, 849, 873, 977, 1006, 1028, 1030, 1042, 1043, 1101, 1102, 1119, 1168, 1169, 1170, 1171, 1173, 1181, 1182, 1183, 1187, 1193, 1194, 1202, 1203, 1205, 1213, 1214, 1215, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1237, 1250, 1258, 1265, 1267, 1289, 1299, 1418, 1423, 1425, 1426, 1432, 1434, 1437, 1463, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1509, 1586, 1587, 1628, 1629, 1630, 1670, 1671, 1672, 1673, 1674, 1675, 1700, 1736, 1739, 1740, 1741, 1750, 1757, 1759, 1762, 1763, 1764, 1769, 1776, 1777, 1780, 1781, 1782, 1788, 1789, 1790], "state": [0, 1, 2, 3, 6, 10, 20, 23, 27, 29, 32, 33, 39, 41, 48, 51, 53, 60, 65, 662, 674, 839, 840, 844, 849, 853, 863, 877, 878, 962, 969, 982, 1030, 1033, 1045, 1102, 1202, 1203, 1220, 1221, 1250, 1265, 1267, 1418, 1420, 1421, 1422, 1423, 1424, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1486, 1487, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1564, 1595, 1638, 1748, 1758, 1759, 1762, 1763, 1764, 1768, 1772, 1775, 1777, 1780, 1788, 1802], "valid": [0, 2, 23, 29, 35, 38, 46, 48, 60, 61, 661, 662, 671, 786, 850, 905, 1028, 1030, 1031, 1051, 1065, 1066, 1075, 1076, 1077, 1088, 1093, 1124, 1178, 1179, 1180, 1322, 1323, 1324, 1347, 1418, 1443, 1448, 1452, 1476, 1495, 1496, 1501, 1502, 1503, 1504, 1506, 1507, 1508, 1509, 1523, 1528, 1738, 1739, 1740, 1741, 1753, 1754, 1759, 1762, 1764, 1768, 1777, 1780, 1783, 1789, 1790], "pass": [0, 1, 2, 4, 6, 7, 8, 14, 20, 21, 23, 24, 27, 29, 33, 35, 38, 39, 40, 41, 45, 46, 47, 48, 49, 50, 51, 53, 55, 57, 59, 60, 127, 230, 421, 485, 487, 489, 531, 728, 737, 738, 739, 740, 746, 754, 779, 795, 809, 842, 853, 895, 926, 927, 928, 936, 937, 938, 944, 958, 961, 962, 966, 967, 968, 970, 992, 1028, 1030, 1031, 1034, 1039, 1041, 1045, 1046, 1074, 1090, 1092, 1101, 1158, 1159, 1160, 1161, 1187, 1193, 1194, 1198, 1199, 1250, 1255, 1256, 1278, 1294, 1295, 1296, 1297, 1302, 1312, 1342, 1343, 1347, 1358, 1359, 1385, 1418, 1420, 1421, 1422, 1423, 1435, 1437, 1439, 1444, 1458, 1461, 1463, 1465, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1551, 1554, 1584, 1586, 1620, 1624, 1628, 1688, 1735, 1738, 1742, 1745, 1748, 1750, 1751, 1752, 1753, 1754, 1757, 1758, 1759, 1761, 1763, 1764, 1765, 1767, 1769, 1770, 1773, 1777, 1780, 1781, 1782, 1789, 1791, 1793, 1794, 1796, 1798, 1799, 1800, 1803, 1804], "foo": [0, 4, 14, 23, 45, 46, 59, 60, 710, 795, 961, 962, 969, 1028, 1033, 1037, 1040, 1041, 1044, 1045, 1465, 1552, 1584, 1735, 1738, 1740, 1741, 1745, 1764, 1770, 1777, 1781, 1800], "skip": [0, 1, 35, 48, 905, 958, 1059, 1060, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1584, 1658, 1738, 1758, 1759, 1762, 1763, 1764, 1770, 1780, 1783], "frame": [0, 9, 32, 33, 36, 38, 1027, 1684, 1766, 1798], "associ": [0, 2, 9, 10, 23, 33, 35, 38, 42, 742, 817, 867, 869, 991, 992, 1030, 1079, 1090, 1092, 1101, 1173, 1250, 1260, 1331, 1423, 1433, 1646, 1648, 1738, 1741, 1752, 1753, 1759, 1767, 1770, 1773, 1781, 1782, 1783, 1789, 1790, 1796, 1799], "code": [0, 2, 4, 5, 9, 10, 12, 14, 15, 20, 21, 23, 29, 31, 32, 35, 36, 38, 39, 49, 50, 57, 58, 59, 96, 850, 851, 962, 1005, 1030, 1034, 1035, 1040, 1041, 1042, 1045, 1046, 1047, 1060, 1071, 1073, 1101, 1266, 1278, 1423, 1636, 1735, 1736, 1740, 1741, 1753, 1759, 1760, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1772, 1775, 1776, 1777, 1778, 1780, 1788, 1789, 1790, 1791, 1796, 1797, 1801, 1804], "still": [0, 1, 2, 3, 8, 9, 20, 23, 29, 34, 35, 38, 39, 48, 59, 60, 745, 750, 1034, 1039, 1047, 1217, 1241, 1423, 1425, 1426, 1507, 1531, 1620, 1737, 1738, 1741, 1751, 1752, 1753, 1754, 1758, 1759, 1762, 1763, 1764, 1766, 1768, 1775, 1776, 1777, 1780, 1781, 1782, 1784, 1789, 1790, 1791, 1793], "process": [0, 1, 2, 4, 12, 14, 21, 23, 24, 29, 33, 35, 38, 39, 40, 41, 42, 48, 49, 50, 51, 53, 60, 811, 846, 852, 876, 1030, 1040, 1102, 1166, 1167, 1184, 1186, 1193, 1194, 1210, 1217, 1241, 1242, 1246, 1247, 1248, 1250, 1253, 1254, 1255, 1257, 1264, 1281, 1282, 1289, 1293, 1295, 1297, 1298, 1319, 1320, 1330, 1359, 1382, 1390, 1423, 1502, 1508, 1639, 1653, 1735, 1736, 1738, 1750, 1751, 1752, 1753, 1759, 1761, 1762, 1763, 1764, 1769, 1770, 1772, 1774, 1776, 1777, 1781, 1782, 1783, 1784, 1789, 1791, 1793, 1795, 1802], "recurs": [0, 2, 29, 32, 35, 53, 60, 897, 1030, 1041, 1043, 1250, 1497, 1740, 1764, 1770, 1781, 1789], "invok": [0, 1, 3, 9, 15, 17, 20, 23, 35, 46, 48, 49, 59, 60, 748, 750, 850, 851, 1030, 1033, 1039, 1187, 1250, 1421, 1499, 1505, 1738, 1741, 1742, 1748, 1758, 1761, 1762, 1763, 1764, 1765, 1769, 1770, 1781, 1789, 1790], "class": [0, 1, 2, 3, 4, 15, 20, 21, 23, 24, 27, 29, 31, 32, 35, 38, 39, 40, 42, 45, 46, 48, 50, 53, 57, 59, 65, 528, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 741, 744, 745, 746, 747, 762, 809, 810, 811, 812, 814, 815, 829, 831, 842, 881, 909, 969, 1005, 1028, 1029, 1030, 1033, 1035, 1036, 1040, 1041, 1044, 1045, 1046, 1047, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1320, 1330, 1382, 1384, 1418, 1423, 1424, 1425, 1426, 1427, 1428, 1434, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1458, 1463, 1468, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1487, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1557, 1558, 1559, 1560, 1561, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1595, 1634, 1736, 1739, 1742, 1745, 1747, 1750, 1751, 1753, 1758, 1759, 1762, 1764, 1765, 1766, 1770, 1772, 1775, 1778, 1782, 1783, 1784, 1786, 1787, 1789, 1790, 1793, 1795, 1796, 1798, 1800, 1801, 1802, 1803, 1804, 1805], "optimizedmodul": 0, "mod": [0, 31, 38, 60, 637, 638, 648, 652, 653, 654, 659, 660, 670, 678, 961, 1033, 1034, 1039, 1046, 1465, 1542, 1543, 1544, 1545, 1564, 1565, 1589, 1740, 1741, 1781, 1802], "dynamo_ctx": 0, "origin": [0, 2, 12, 17, 20, 21, 23, 32, 33, 35, 38, 41, 53, 56, 59, 60, 183, 186, 198, 459, 516, 575, 579, 589, 710, 780, 785, 812, 925, 926, 928, 932, 936, 937, 938, 944, 961, 1004, 1027, 1037, 1041, 1042, 1045, 1046, 1123, 1137, 1158, 1162, 1174, 1186, 1187, 1279, 1289, 1330, 1399, 1432, 1433, 1434, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1458, 1461, 1464, 1465, 1467, 1505, 1514, 1529, 1566, 1567, 1582, 1583, 1615, 1626, 1662, 1676, 1694, 1707, 1718, 1719, 1738, 1741, 1751, 1753, 1759, 1762, 1764, 1766, 1769, 1772, 1773, 1775, 1777, 1781, 1782, 1784, 1785, 1795, 1802, 1803, 1804], "nn": [0, 1, 4, 6, 15, 20, 21, 23, 24, 27, 31, 35, 38, 49, 53, 54, 60, 274, 512, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 710, 850, 853, 905, 961, 969, 1028, 1030, 1031, 1033, 1034, 1035, 1036, 1039, 1040, 1041, 1045, 1046, 1047, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1418, 1423, 1424, 1425, 1426, 1427, 1428, 1434, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1458, 1546, 1570, 1577, 1584, 1585, 1586, 1587, 1589, 1661, 1684, 1721, 1735, 1736, 1738, 1739, 1743, 1753, 1754, 1758, 1763, 1766, 1770, 1772, 1773, 1774, 1777, 1780, 1781, 1782, 1784, 1786, 1789, 1798, 1800, 1803], "object": [0, 1, 2, 4, 6, 7, 9, 14, 20, 21, 23, 24, 27, 29, 30, 31, 32, 35, 39, 41, 48, 50, 53, 59, 60, 65, 183, 186, 575, 710, 728, 738, 739, 759, 761, 831, 842, 881, 905, 944, 956, 958, 963, 964, 966, 967, 968, 970, 1016, 1017, 1030, 1036, 1037, 1040, 1041, 1045, 1046, 1061, 1082, 1086, 1099, 1101, 1102, 1122, 1187, 1189, 1190, 1191, 1195, 1213, 1214, 1215, 1250, 1260, 1289, 1423, 1435, 1450, 1459, 1460, 1463, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1486, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1586, 1620, 1692, 1693, 1735, 1740, 1741, 1742, 1745, 1748, 1749, 1751, 1755, 1759, 1761, 1762, 1764, 1765, 1766, 1767, 1769, 1772, 1774, 1775, 1776, 1777, 1780, 1784, 1786, 1787, 1788, 1789, 1791, 1795, 1796, 1798, 1800, 1804, 1805], "later": [0, 1, 2, 4, 8, 19, 21, 23, 35, 53, 59, 60, 659, 660, 670, 678, 758, 842, 1101, 1220, 1243, 1244, 1245, 1265, 1279, 1371, 1372, 1373, 1399, 1423, 1688, 1738, 1759, 1761, 1762, 1763, 1770, 1775, 1790, 1791], "patch": [0, 8, 55, 1197, 1301], "its": [0, 1, 2, 5, 6, 8, 9, 10, 14, 15, 17, 20, 21, 22, 23, 24, 27, 29, 32, 33, 34, 35, 39, 40, 48, 49, 50, 53, 59, 60, 127, 431, 460, 476, 485, 487, 489, 555, 589, 722, 723, 724, 726, 727, 728, 740, 743, 762, 787, 788, 797, 803, 807, 815, 842, 844, 853, 888, 892, 895, 905, 908, 953, 958, 962, 963, 964, 967, 970, 991, 992, 996, 1010, 1030, 1040, 1065, 1066, 1070, 1075, 1082, 1084, 1087, 1088, 1093, 1099, 1124, 1138, 1166, 1168, 1169, 1170, 1178, 1179, 1180, 1181, 1182, 1183, 1187, 1213, 1214, 1215, 1250, 1251, 1260, 1281, 1289, 1347, 1358, 1385, 1391, 1418, 1422, 1424, 1425, 1426, 1433, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1459, 1463, 1467, 1471, 1480, 1481, 1482, 1484, 1490, 1491, 1494, 1514, 1551, 1554, 1604, 1608, 1612, 1613, 1629, 1630, 1634, 1654, 1689, 1706, 1707, 1709, 1717, 1726, 1738, 1740, 1741, 1745, 1748, 1750, 1751, 1758, 1759, 1760, 1762, 1763, 1764, 1766, 1767, 1770, 1774, 1775, 1776, 1777, 1780, 1781, 1782, 1789, 1790, 1791, 1793, 1796, 1797, 1799, 1802, 1803], "forward": [0, 1, 6, 8, 9, 14, 21, 23, 24, 27, 29, 31, 33, 34, 35, 38, 53, 54, 55, 58, 60, 127, 198, 199, 662, 671, 674, 706, 707, 708, 737, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 750, 751, 754, 755, 762, 853, 897, 909, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 962, 964, 965, 966, 968, 969, 1005, 1030, 1033, 1034, 1035, 1036, 1040, 1041, 1045, 1046, 1047, 1162, 1166, 1187, 1188, 1189, 1190, 1191, 1193, 1194, 1195, 1202, 1220, 1235, 1246, 1247, 1248, 1250, 1251, 1252, 1256, 1257, 1260, 1261, 1265, 1278, 1293, 1294, 1295, 1296, 1297, 1333, 1334, 1335, 1340, 1385, 1418, 1420, 1421, 1422, 1423, 1428, 1435, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1455, 1464, 1467, 1468, 1532, 1548, 1552, 1586, 1587, 1595, 1634, 1663, 1721, 1736, 1737, 1738, 1740, 1741, 1748, 1751, 1753, 1757, 1758, 1759, 1761, 1762, 1763, 1765, 1766, 1767, 1769, 1770, 1773, 1775, 1777, 1780, 1781, 1782, 1783, 1784, 1789, 1802, 1803], "method": [0, 1, 4, 8, 10, 14, 15, 17, 20, 23, 24, 27, 29, 30, 31, 32, 34, 35, 38, 39, 40, 46, 48, 53, 59, 60, 198, 199, 299, 459, 460, 469, 470, 471, 492, 586, 703, 706, 707, 708, 710, 722, 723, 724, 740, 744, 745, 746, 747, 844, 956, 983, 1028, 1030, 1031, 1033, 1034, 1035, 1040, 1041, 1045, 1046, 1047, 1075, 1093, 1094, 1101, 1102, 1147, 1150, 1158, 1166, 1193, 1250, 1251, 1252, 1260, 1261, 1278, 1347, 1418, 1423, 1433, 1434, 1437, 1439, 1441, 1444, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1455, 1461, 1464, 1478, 1479, 1480, 1482, 1492, 1524, 1529, 1531, 1566, 1569, 1669, 1684, 1688, 1735, 1736, 1738, 1741, 1742, 1748, 1750, 1751, 1752, 1753, 1757, 1758, 1759, 1762, 1764, 1765, 1766, 1767, 1770, 1772, 1775, 1778, 1780, 1781, 1784, 1786, 1789, 1791, 1795, 1796, 1798, 1799, 1801, 1804], "self": [0, 1, 2, 10, 17, 20, 21, 23, 31, 35, 38, 39, 40, 45, 50, 53, 57, 60, 74, 116, 127, 130, 131, 132, 147, 149, 152, 155, 156, 157, 167, 168, 172, 173, 185, 193, 195, 209, 216, 230, 231, 234, 235, 243, 262, 266, 273, 287, 289, 291, 293, 295, 297, 299, 301, 302, 304, 305, 306, 307, 309, 317, 352, 368, 373, 375, 377, 427, 444, 454, 456, 469, 470, 471, 472, 485, 487, 489, 492, 496, 508, 514, 515, 516, 517, 529, 531, 552, 553, 555, 576, 579, 580, 586, 589, 590, 592, 595, 760, 961, 962, 969, 1000, 1028, 1029, 1030, 1033, 1034, 1035, 1036, 1040, 1041, 1045, 1046, 1047, 1158, 1162, 1195, 1249, 1250, 1251, 1252, 1256, 1260, 1261, 1277, 1279, 1289, 1295, 1297, 1377, 1399, 1418, 1434, 1435, 1437, 1443, 1445, 1458, 1465, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1520, 1586, 1587, 1606, 1737, 1738, 1739, 1740, 1741, 1745, 1750, 1752, 1753, 1757, 1759, 1760, 1761, 1764, 1766, 1770, 1775, 1777, 1781, 1782, 1784, 1789, 1795], "conveni": [1, 4, 8, 14, 35, 45, 48, 49, 58, 971, 1087, 1418, 1728, 1735, 1740, 1745, 1758, 1759, 1762, 1764, 1769, 1770, 1781, 1788], "where": [1, 2, 3, 4, 5, 8, 9, 10, 12, 14, 15, 20, 21, 23, 27, 29, 33, 34, 35, 38, 39, 41, 48, 49, 50, 51, 53, 55, 56, 57, 60, 130, 200, 230, 375, 377, 459, 609, 611, 612, 615, 672, 674, 695, 725, 743, 748, 750, 758, 764, 773, 779, 786, 787, 788, 803, 807, 812, 822, 824, 884, 885, 888, 892, 910, 921, 922, 924, 927, 928, 930, 931, 933, 934, 935, 937, 938, 940, 942, 966, 967, 968, 970, 971, 974, 983, 986, 987, 988, 989, 1019, 1020, 1022, 1023, 1026, 1027, 1028, 1031, 1043, 1049, 1050, 1051, 1054, 1059, 1060, 1061, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1081, 1082, 1083, 1084, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1097, 1098, 1099, 1101, 1102, 1107, 1110, 1117, 1118, 1119, 1120, 1124, 1127, 1129, 1130, 1131, 1132, 1135, 1140, 1145, 1146, 1148, 1151, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1192, 1193, 1194, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1262, 1263, 1264, 1265, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1279, 1280, 1281, 1282, 1283, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1318, 1330, 1331, 1338, 1343, 1345, 1346, 1364, 1365, 1382, 1384, 1385, 1388, 1389, 1391, 1399, 1423, 1425, 1426, 1428, 1432, 1459, 1460, 1461, 1462, 1469, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1487, 1490, 1491, 1492, 1493, 1494, 1497, 1498, 1499, 1511, 1521, 1523, 1524, 1548, 1549, 1609, 1610, 1646, 1652, 1653, 1658, 1662, 1666, 1667, 1670, 1671, 1672, 1673, 1674, 1675, 1682, 1683, 1684, 1687, 1688, 1694, 1700, 1709, 1710, 1711, 1712, 1713, 1718, 1719, 1723, 1724, 1725, 1726, 1727, 1728, 1737, 1738, 1739, 1741, 1742, 1747, 1749, 1751, 1754, 1757, 1758, 1759, 1760, 1762, 1764, 1765, 1766, 1767, 1770, 1773, 1774, 1777, 1779, 1780, 1781, 1782, 1784, 1787, 1789, 1791, 1793, 1794, 1796, 1798, 1803, 1804], "some": [1, 2, 4, 6, 8, 9, 10, 14, 19, 20, 21, 23, 29, 33, 34, 35, 38, 39, 41, 49, 50, 53, 56, 57, 58, 59, 60, 450, 468, 538, 605, 662, 860, 864, 867, 905, 926, 928, 936, 937, 938, 953, 962, 971, 1005, 1027, 1028, 1030, 1031, 1040, 1043, 1045, 1075, 1093, 1099, 1124, 1131, 1134, 1158, 1162, 1166, 1167, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1187, 1188, 1210, 1213, 1214, 1215, 1216, 1217, 1220, 1241, 1242, 1250, 1253, 1254, 1255, 1257, 1264, 1265, 1281, 1282, 1298, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1330, 1331, 1332, 1359, 1364, 1382, 1385, 1390, 1418, 1423, 1424, 1425, 1426, 1432, 1463, 1493, 1499, 1505, 1523, 1608, 1632, 1639, 1653, 1688, 1728, 1735, 1738, 1739, 1740, 1741, 1742, 1745, 1746, 1747, 1748, 1751, 1752, 1753, 1758, 1759, 1762, 1764, 1765, 1766, 1767, 1769, 1770, 1772, 1773, 1774, 1775, 1776, 1777, 1780, 1781, 1783, 1784, 1785, 1787, 1789, 1790, 1791, 1793, 1798], "oper": [1, 3, 5, 6, 8, 9, 12, 15, 17, 20, 29, 30, 32, 33, 34, 35, 36, 38, 45, 46, 48, 49, 54, 58, 59, 60, 61, 62, 63, 230, 289, 297, 311, 328, 377, 418, 419, 420, 421, 422, 465, 468, 485, 487, 489, 561, 602, 605, 655, 656, 657, 661, 662, 671, 672, 682, 683, 693, 699, 702, 703, 705, 713, 737, 739, 744, 746, 763, 764, 766, 768, 771, 773, 775, 777, 782, 785, 788, 792, 801, 812, 814, 841, 850, 880, 884, 885, 886, 887, 900, 905, 906, 907, 908, 918, 923, 941, 953, 956, 958, 959, 960, 961, 962, 963, 965, 966, 967, 968, 971, 978, 981, 987, 988, 1005, 1030, 1040, 1041, 1045, 1046, 1049, 1059, 1072, 1082, 1085, 1086, 1099, 1100, 1109, 1116, 1124, 1129, 1134, 1145, 1148, 1162, 1167, 1172, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1197, 1198, 1199, 1207, 1208, 1209, 1210, 1212, 1217, 1236, 1241, 1246, 1247, 1248, 1250, 1263, 1268, 1269, 1270, 1277, 1292, 1293, 1295, 1297, 1301, 1315, 1316, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1332, 1333, 1334, 1335, 1339, 1340, 1342, 1343, 1347, 1351, 1358, 1364, 1366, 1372, 1373, 1383, 1385, 1389, 1402, 1403, 1414, 1415, 1416, 1417, 1423, 1425, 1426, 1461, 1465, 1470, 1474, 1475, 1491, 1497, 1507, 1511, 1520, 1521, 1531, 1551, 1554, 1584, 1586, 1587, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1608, 1614, 1631, 1632, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1664, 1666, 1667, 1670, 1671, 1672, 1673, 1674, 1675, 1679, 1687, 1694, 1700, 1721, 1728, 1731, 1733, 1734, 1736, 1737, 1738, 1742, 1745, 1758, 1760, 1761, 1762, 1763, 1765, 1766, 1770, 1771, 1772, 1773, 1774, 1778, 1783, 1785, 1787, 1788, 1789, 1790, 1794, 1796, 1797, 1800], "float": [1, 2, 4, 12, 20, 21, 23, 27, 29, 34, 39, 42, 50, 53, 60, 130, 131, 196, 289, 291, 293, 297, 309, 375, 448, 454, 485, 601, 603, 608, 610, 614, 648, 652, 653, 654, 658, 659, 660, 662, 669, 670, 675, 676, 677, 678, 679, 684, 685, 686, 687, 688, 689, 691, 693, 694, 695, 699, 702, 703, 704, 708, 713, 728, 755, 756, 764, 765, 773, 780, 783, 787, 797, 802, 803, 807, 808, 876, 888, 899, 900, 910, 923, 941, 950, 951, 952, 953, 955, 974, 977, 986, 987, 988, 991, 992, 1012, 1019, 1020, 1022, 1023, 1024, 1025, 1028, 1030, 1045, 1046, 1049, 1053, 1055, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1074, 1075, 1076, 1077, 1079, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1102, 1107, 1116, 1118, 1120, 1139, 1140, 1144, 1146, 1147, 1148, 1151, 1154, 1158, 1162, 1168, 1169, 1170, 1172, 1184, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1198, 1199, 1204, 1205, 1206, 1209, 1210, 1211, 1213, 1214, 1215, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1236, 1238, 1242, 1250, 1255, 1256, 1258, 1259, 1264, 1268, 1271, 1272, 1273, 1274, 1275, 1281, 1287, 1289, 1292, 1293, 1295, 1297, 1298, 1299, 1302, 1303, 1304, 1329, 1330, 1332, 1333, 1334, 1335, 1338, 1339, 1340, 1344, 1349, 1358, 1383, 1390, 1415, 1423, 1428, 1429, 1430, 1433, 1442, 1443, 1445, 1446, 1448, 1451, 1452, 1453, 1454, 1461, 1462, 1464, 1470, 1471, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1502, 1503, 1505, 1507, 1509, 1511, 1517, 1520, 1524, 1531, 1547, 1566, 1567, 1582, 1583, 1586, 1587, 1590, 1591, 1592, 1604, 1608, 1609, 1629, 1630, 1633, 1637, 1646, 1647, 1649, 1650, 1652, 1685, 1688, 1692, 1707, 1709, 1721, 1737, 1738, 1739, 1740, 1741, 1742, 1747, 1750, 1751, 1752, 1754, 1755, 1757, 1758, 1762, 1764, 1766, 1770, 1773, 1777, 1779, 1781, 1783, 1784, 1785, 1789, 1793, 1794, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1805], "datatyp": [1, 60, 728, 1027, 1030, 1250, 1425, 1426, 1632, 1773, 1777], "other": [1, 2, 3, 4, 5, 8, 9, 10, 14, 15, 17, 20, 21, 24, 27, 29, 30, 33, 34, 35, 38, 39, 41, 45, 46, 48, 49, 53, 54, 56, 57, 58, 59, 60, 74, 75, 90, 106, 107, 110, 122, 123, 126, 127, 136, 137, 142, 143, 173, 174, 175, 184, 210, 215, 219, 220, 221, 231, 250, 251, 258, 259, 260, 261, 267, 268, 269, 270, 271, 272, 279, 280, 283, 284, 285, 286, 289, 291, 297, 300, 320, 328, 330, 331, 332, 333, 334, 335, 338, 339, 340, 341, 353, 354, 369, 370, 383, 387, 411, 412, 423, 424, 428, 429, 470, 492, 532, 533, 534, 535, 552, 555, 588, 589, 590, 593, 594, 601, 610, 652, 653, 654, 655, 656, 657, 713, 719, 726, 727, 732, 738, 740, 741, 754, 755, 756, 762, 767, 768, 770, 771, 772, 774, 779, 802, 808, 809, 812, 814, 816, 822, 832, 853, 893, 899, 900, 901, 902, 909, 910, 911, 925, 932, 950, 951, 952, 953, 956, 962, 963, 964, 965, 968, 970, 972, 973, 974, 984, 985, 986, 995, 996, 998, 999, 1004, 1005, 1007, 1019, 1028, 1030, 1034, 1041, 1050, 1052, 1053, 1054, 1056, 1057, 1062, 1080, 1082, 1085, 1086, 1099, 1107, 1108, 1109, 1111, 1113, 1114, 1117, 1118, 1124, 1127, 1128, 1132, 1133, 1137, 1139, 1141, 1151, 1154, 1178, 1179, 1180, 1181, 1182, 1183, 1185, 1187, 1197, 1204, 1216, 1250, 1251, 1260, 1278, 1293, 1297, 1301, 1322, 1323, 1324, 1349, 1358, 1415, 1418, 1423, 1448, 1468, 1472, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1496, 1497, 1502, 1503, 1509, 1511, 1546, 1554, 1586, 1604, 1608, 1624, 1629, 1632, 1634, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1670, 1671, 1672, 1673, 1674, 1675, 1679, 1685, 1686, 1700, 1706, 1710, 1712, 1725, 1726, 1732, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1745, 1748, 1751, 1752, 1753, 1754, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1770, 1771, 1772, 1773, 1775, 1777, 1780, 1784, 1785, 1789, 1790, 1791, 1794, 1798, 1799, 1800, 1804], "lower": [1, 2, 9, 21, 23, 29, 33, 38, 53, 774, 779, 786, 787, 788, 790, 919, 920, 990, 991, 1059, 1066, 1068, 1076, 1077, 1084, 1087, 1092, 1130, 1140, 1147, 1158, 1268, 1322, 1323, 1324, 1395, 1396, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1499, 1505, 1507, 1522, 1524, 1584, 1609, 1624, 1632, 1668, 1694, 1709, 1710, 1711, 1737, 1738, 1739, 1741, 1755, 1757, 1759, 1770, 1779, 1784, 1794, 1800], "point": [1, 2, 8, 9, 10, 12, 20, 21, 24, 27, 32, 33, 34, 35, 39, 45, 48, 49, 53, 60, 65, 130, 131, 297, 309, 315, 454, 614, 652, 653, 654, 655, 656, 657, 658, 663, 664, 665, 666, 667, 668, 669, 670, 673, 675, 676, 677, 678, 679, 689, 691, 693, 694, 695, 699, 713, 728, 749, 751, 752, 753, 755, 756, 764, 765, 773, 802, 803, 807, 856, 858, 867, 870, 871, 951, 952, 953, 977, 983, 987, 988, 992, 1012, 1027, 1030, 1045, 1046, 1053, 1055, 1076, 1077, 1100, 1102, 1107, 1116, 1147, 1154, 1163, 1164, 1165, 1178, 1179, 1180, 1181, 1182, 1183, 1197, 1243, 1244, 1245, 1250, 1301, 1302, 1312, 1338, 1347, 1358, 1415, 1423, 1470, 1477, 1508, 1524, 1531, 1547, 1548, 1549, 1550, 1553, 1586, 1587, 1590, 1591, 1595, 1604, 1617, 1629, 1630, 1637, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1721, 1736, 1738, 1740, 1741, 1742, 1745, 1750, 1755, 1757, 1758, 1759, 1763, 1767, 1770, 1773, 1778, 1782, 1783, 1784, 1785, 1787, 1789, 1790, 1793, 1796, 1798, 1799, 1800, 1801, 1802, 1805], "lower_precision_fp": 1, "half": [1, 2, 11, 21, 29, 589, 919, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 1030, 1092, 1098, 1178, 1179, 1180, 1181, 1182, 1183, 1198, 1199, 1201, 1250, 1342, 1343, 1346, 1476, 1499, 1617, 1684, 1752, 1770, 1773, 1795, 1796, 1799, 1801], "linear": [1, 3, 10, 21, 23, 24, 27, 29, 38, 53, 55, 58, 60, 405, 445, 446, 447, 448, 449, 452, 627, 636, 644, 645, 679, 702, 703, 705, 710, 750, 788, 814, 905, 961, 963, 969, 971, 1030, 1034, 1041, 1055, 1061, 1072, 1073, 1074, 1075, 1076, 1077, 1079, 1090, 1092, 1120, 1147, 1166, 1172, 1192, 1200, 1201, 1209, 1235, 1250, 1252, 1265, 1267, 1269, 1277, 1279, 1286, 1289, 1300, 1302, 1336, 1345, 1346, 1358, 1392, 1399, 1404, 1415, 1418, 1423, 1432, 1433, 1437, 1447, 1448, 1449, 1450, 1451, 1453, 1454, 1455, 1456, 1457, 1463, 1464, 1467, 1502, 1505, 1513, 1524, 1546, 1570, 1577, 1583, 1584, 1586, 1587, 1721, 1728, 1736, 1739, 1740, 1746, 1748, 1754, 1757, 1762, 1763, 1764, 1766, 1770, 1775, 1777, 1779, 1780, 1782, 1784, 1785, 1786, 1787, 1789], "layer": [1, 9, 21, 23, 27, 33, 53, 56, 674, 1163, 1164, 1165, 1167, 1168, 1169, 1170, 1171, 1178, 1179, 1180, 1181, 1182, 1183, 1189, 1190, 1191, 1195, 1202, 1203, 1205, 1213, 1214, 1215, 1220, 1221, 1222, 1235, 1237, 1243, 1244, 1245, 1256, 1257, 1265, 1267, 1278, 1289, 1293, 1294, 1295, 1296, 1297, 1361, 1423, 1427, 1428, 1432, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1490, 1491, 1492, 1493, 1494, 1569, 1583, 1736, 1757, 1762, 1764, 1766, 1769, 1770, 1775, 1780, 1782, 1784, 1785, 1787, 1803], "convolut": [1, 2, 3, 652, 653, 654, 655, 656, 657, 686, 687, 688, 795, 1039, 1178, 1179, 1180, 1181, 1182, 1183, 1189, 1190, 1191, 1195, 1226, 1227, 1228, 1229, 1230, 1231, 1262, 1263, 1268, 1298, 1299, 1301, 1322, 1323, 1324, 1325, 1326, 1327, 1346, 1347, 1632, 1736, 1737, 1739, 1748, 1757, 1761, 1762, 1767, 1770, 1779, 1783, 1784, 1787], "ar": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 17, 18, 19, 20, 21, 23, 24, 27, 29, 32, 34, 35, 37, 38, 39, 40, 41, 42, 45, 46, 48, 49, 50, 53, 55, 56, 57, 59, 60, 65, 74, 127, 230, 295, 297, 311, 312, 315, 352, 421, 444, 454, 459, 471, 485, 489, 515, 552, 561, 589, 605, 606, 607, 613, 670, 674, 675, 677, 678, 679, 693, 696, 697, 699, 700, 701, 702, 703, 705, 706, 707, 708, 710, 713, 722, 723, 734, 735, 736, 738, 740, 746, 748, 749, 750, 751, 752, 753, 755, 756, 764, 773, 774, 776, 777, 779, 782, 788, 797, 802, 803, 806, 807, 810, 811, 812, 814, 815, 817, 821, 833, 844, 850, 853, 854, 864, 873, 880, 888, 893, 897, 900, 905, 921, 922, 923, 924, 926, 928, 933, 935, 941, 944, 946, 947, 951, 952, 953, 962, 967, 970, 971, 975, 983, 987, 988, 990, 992, 1005, 1007, 1019, 1020, 1022, 1023, 1026, 1027, 1028, 1030, 1031, 1034, 1036, 1037, 1040, 1043, 1045, 1046, 1051, 1059, 1060, 1061, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1082, 1084, 1085, 1086, 1087, 1088, 1090, 1091, 1092, 1093, 1094, 1096, 1099, 1100, 1101, 1102, 1111, 1112, 1113, 1114, 1116, 1117, 1119, 1121, 1122, 1124, 1127, 1130, 1131, 1132, 1135, 1137, 1140, 1144, 1145, 1146, 1147, 1148, 1158, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1187, 1188, 1189, 1190, 1191, 1194, 1195, 1197, 1202, 1203, 1204, 1205, 1210, 1213, 1214, 1215, 1216, 1217, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1237, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1264, 1265, 1267, 1278, 1281, 1282, 1283, 1289, 1293, 1295, 1297, 1298, 1299, 1301, 1302, 1312, 1318, 1319, 1320, 1330, 1331, 1339, 1340, 1341, 1347, 1358, 1359, 1382, 1385, 1387, 1390, 1414, 1415, 1416, 1417, 1418, 1422, 1423, 1424, 1425, 1426, 1428, 1429, 1430, 1431, 1432, 1433, 1435, 1437, 1444, 1458, 1462, 1463, 1464, 1466, 1468, 1470, 1471, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1501, 1504, 1505, 1517, 1523, 1524, 1531, 1546, 1547, 1548, 1549, 1550, 1553, 1568, 1583, 1584, 1585, 1586, 1587, 1595, 1604, 1607, 1608, 1615, 1617, 1628, 1629, 1632, 1662, 1663, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1680, 1683, 1684, 1687, 1688, 1694, 1695, 1697, 1701, 1703, 1704, 1706, 1707, 1709, 1710, 1711, 1712, 1713, 1721, 1722, 1723, 1724, 1728, 1736, 1738, 1739, 1740, 1741, 1742, 1743, 1747, 1748, 1750, 1751, 1752, 1753, 1754, 1755, 1757, 1758, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1782, 1783, 1784, 1785, 1787, 1788, 1789, 1790, 1791, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1804, 1805], "much": [1, 5, 8, 10, 15, 20, 21, 33, 35, 127, 740, 749, 754, 1065, 1066, 1093, 1102, 1194, 1423, 1448, 1505, 1738, 1759, 1762, 1767, 1770, 1775, 1781, 1782, 1789, 1790, 1793], "reduct": [1, 3, 23, 38, 53, 297, 485, 489, 1075, 1107, 1147, 1166, 1167, 1173, 1184, 1186, 1194, 1204, 1210, 1211, 1216, 1217, 1241, 1242, 1253, 1254, 1255, 1257, 1264, 1281, 1282, 1298, 1299, 1319, 1320, 1328, 1330, 1331, 1339, 1344, 1355, 1356, 1359, 1360, 1370, 1378, 1379, 1380, 1381, 1382, 1390, 1400, 1401, 1412, 1413, 1423, 1524, 1739, 1752, 1763, 1767, 1781, 1784], "often": [1, 3, 5, 8, 9, 14, 20, 23, 29, 33, 38, 49, 56, 60, 127, 740, 754, 1045, 1076, 1077, 1086, 1135, 1193, 1213, 1214, 1215, 1312, 1320, 1338, 1347, 1418, 1432, 1507, 1741, 1759, 1762, 1766, 1769, 1770, 1773, 1774, 1781, 1789, 1798], "requir": [1, 2, 6, 9, 10, 14, 15, 20, 21, 23, 24, 27, 29, 32, 33, 34, 39, 47, 48, 53, 56, 57, 59, 60, 96, 127, 198, 311, 431, 468, 485, 487, 489, 531, 728, 737, 740, 745, 748, 749, 750, 751, 752, 753, 754, 808, 809, 863, 905, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 946, 947, 971, 972, 1043, 1069, 1100, 1102, 1116, 1186, 1193, 1194, 1293, 1294, 1295, 1296, 1297, 1299, 1339, 1418, 1423, 1424, 1435, 1437, 1439, 1483, 1493, 1511, 1551, 1554, 1672, 1684, 1721, 1728, 1735, 1738, 1741, 1743, 1747, 1748, 1751, 1753, 1754, 1758, 1759, 1761, 1762, 1763, 1764, 1766, 1767, 1768, 1769, 1770, 1772, 1775, 1777, 1781, 1782, 1784, 1785, 1789, 1790, 1791, 1793, 1798, 1800, 1801, 1803, 1804], "rang": [1, 2, 4, 20, 23, 24, 27, 29, 31, 35, 38, 48, 49, 51, 60, 65, 277, 454, 600, 675, 677, 679, 733, 765, 790, 868, 869, 876, 905, 955, 969, 990, 991, 992, 1096, 1107, 1122, 1131, 1147, 1158, 1186, 1196, 1198, 1199, 1203, 1209, 1221, 1240, 1252, 1257, 1261, 1267, 1283, 1284, 1285, 1289, 1342, 1343, 1347, 1402, 1423, 1430, 1495, 1496, 1498, 1499, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1524, 1547, 1548, 1549, 1550, 1551, 1553, 1554, 1555, 1667, 1720, 1738, 1739, 1741, 1759, 1761, 1762, 1766, 1770, 1772, 1773, 1777, 1779, 1780, 1783, 1784, 1787, 1788, 1794, 1796, 1798, 1799, 1800, 1801], "tri": [1, 3, 4, 8, 20, 29, 33, 41, 60, 552, 1030, 1250, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1740, 1741, 1751, 1766, 1777, 1781], "match": [1, 2, 4, 23, 27, 29, 33, 35, 37, 48, 60, 127, 289, 291, 297, 446, 447, 471, 472, 552, 555, 609, 615, 693, 710, 726, 740, 754, 755, 756, 808, 811, 822, 823, 824, 853, 897, 905, 971, 1007, 1030, 1043, 1045, 1062, 1101, 1123, 1185, 1194, 1250, 1302, 1319, 1320, 1358, 1384, 1391, 1415, 1423, 1437, 1471, 1590, 1624, 1668, 1670, 1671, 1672, 1673, 1674, 1675, 1702, 1728, 1738, 1741, 1747, 1752, 1754, 1759, 1760, 1762, 1764, 1770, 1775, 1777, 1780, 1781, 1782, 1784, 1785, 1786, 1789, 1796, 1800, 1802], "appropri": [1, 8, 9, 10, 23, 24, 29, 33, 35, 53, 59, 60, 741, 853, 1045, 1741, 1742, 1745, 1753, 1767, 1782, 1784, 1789, 1790, 1791, 1795, 1804], "ordinarili": [1, 1758], "train": [1, 2, 15, 20, 21, 23, 24, 26, 27, 33, 34, 36, 38, 39, 46, 47, 48, 49, 53, 56, 60, 628, 629, 630, 631, 632, 633, 634, 635, 636, 646, 647, 648, 649, 711, 712, 852, 853, 856, 858, 865, 969, 1005, 1030, 1035, 1041, 1044, 1045, 1158, 1162, 1168, 1169, 1170, 1186, 1187, 1188, 1193, 1194, 1205, 1213, 1214, 1215, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1250, 1256, 1257, 1289, 1297, 1313, 1317, 1332, 1333, 1334, 1335, 1338, 1339, 1340, 1395, 1396, 1423, 1433, 1435, 1437, 1464, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1499, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1531, 1533, 1566, 1567, 1582, 1584, 1586, 1587, 1588, 1735, 1737, 1738, 1739, 1748, 1750, 1757, 1759, 1762, 1763, 1766, 1771, 1773, 1775, 1777, 1780, 1781, 1782, 1783, 1787, 1789, 1791, 1798], "gradscal": [1, 1758, 1762], "togeth": [1, 4, 10, 20, 23, 29, 31, 33, 54, 58, 60, 674, 850, 905, 961, 963, 967, 969, 970, 975, 1069, 1202, 1220, 1265, 1358, 1423, 1429, 1707, 1748, 1758, 1764, 1765, 1766, 1769, 1770, 1784, 1789, 1790, 1791, 1798], "shown": [1, 21, 31, 40, 49, 850, 860, 1222, 1437, 1505, 1637, 1738, 1741, 1758, 1762, 1764, 1766, 1770, 1782, 1784, 1793], "recip": [1, 4, 27, 1250, 1423, 1439, 1758, 1770], "howev": [1, 3, 4, 5, 6, 8, 10, 14, 15, 20, 21, 23, 27, 29, 33, 39, 45, 53, 54, 55, 57, 59, 60, 454, 516, 741, 748, 811, 832, 853, 893, 895, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 961, 962, 966, 967, 970, 971, 1030, 1033, 1034, 1040, 1042, 1069, 1084, 1085, 1087, 1101, 1102, 1119, 1166, 1178, 1179, 1180, 1181, 1182, 1183, 1187, 1194, 1250, 1322, 1323, 1324, 1347, 1418, 1423, 1458, 1470, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1670, 1671, 1672, 1673, 1674, 1675, 1728, 1736, 1741, 1754, 1758, 1759, 1762, 1764, 1768, 1770, 1772, 1774, 1775, 1776, 1777, 1781, 1782, 1789, 1791, 1793], "modular": [1, 1758], "mai": [1, 2, 3, 4, 5, 8, 9, 10, 14, 19, 20, 21, 23, 27, 29, 30, 33, 35, 38, 39, 41, 45, 47, 48, 53, 54, 57, 59, 60, 173, 198, 230, 289, 297, 431, 487, 489, 527, 575, 589, 605, 706, 707, 708, 746, 748, 750, 754, 759, 766, 777, 789, 800, 801, 803, 805, 808, 809, 811, 812, 832, 842, 843, 844, 850, 851, 853, 864, 866, 883, 905, 944, 948, 953, 956, 958, 965, 966, 968, 992, 1027, 1030, 1033, 1034, 1039, 1040, 1042, 1043, 1045, 1051, 1060, 1061, 1065, 1066, 1067, 1069, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1085, 1087, 1088, 1091, 1092, 1093, 1099, 1101, 1102, 1107, 1124, 1134, 1158, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1216, 1220, 1250, 1257, 1265, 1295, 1297, 1302, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1339, 1347, 1349, 1358, 1364, 1385, 1414, 1415, 1416, 1417, 1418, 1423, 1432, 1434, 1435, 1437, 1470, 1499, 1523, 1586, 1608, 1611, 1629, 1632, 1639, 1657, 1668, 1684, 1688, 1709, 1721, 1735, 1736, 1738, 1740, 1741, 1745, 1747, 1748, 1750, 1753, 1758, 1759, 1760, 1761, 1762, 1764, 1765, 1766, 1770, 1773, 1774, 1775, 1776, 1777, 1781, 1783, 1784, 1785, 1787, 1789, 1791, 1793, 1795, 1801, 1804], "separ": [1, 2, 4, 10, 14, 20, 23, 27, 48, 49, 53, 54, 56, 58, 59, 60, 674, 738, 905, 922, 924, 930, 931, 934, 935, 940, 942, 961, 1040, 1075, 1090, 1205, 1213, 1214, 1215, 1256, 1258, 1366, 1428, 1471, 1735, 1739, 1741, 1758, 1759, 1761, 1762, 1765, 1775, 1780, 1781, 1790, 1793, 1794, 1798], "desir": [1, 2, 4, 20, 23, 29, 38, 53, 60, 65, 132, 147, 149, 152, 155, 156, 157, 172, 183, 186, 216, 230, 243, 273, 301, 368, 418, 419, 420, 421, 422, 469, 471, 472, 492, 496, 516, 517, 531, 552, 555, 575, 576, 589, 713, 727, 764, 773, 792, 854, 855, 877, 878, 886, 887, 906, 907, 908, 918, 923, 941, 958, 959, 960, 987, 988, 1030, 1049, 1100, 1116, 1122, 1129, 1145, 1147, 1148, 1166, 1250, 1300, 1366, 1402, 1403, 1418, 1458, 1470, 1474, 1475, 1514, 1521, 1524, 1590, 1591, 1595, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1638, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1664, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1687, 1700, 1711, 1713, 1733, 1734, 1752, 1753, 1754, 1758, 1759, 1762, 1765, 1768, 1770, 1775, 1782, 1788, 1789, 1794, 1795, 1796], "As": [1, 2, 9, 21, 23, 29, 35, 38, 53, 56, 60, 230, 777, 905, 1034, 1061, 1065, 1066, 1076, 1077, 1088, 1093, 1189, 1190, 1191, 1195, 1216, 1250, 1281, 1414, 1469, 1475, 1734, 1738, 1740, 1741, 1747, 1754, 1759, 1762, 1764, 1766, 1770, 1773, 1776, 1777, 1781, 1782, 1789, 1790, 1791, 1793, 1801], "section": [1, 2, 8, 20, 29, 31, 35, 37, 38, 39, 40, 60, 96, 864, 905, 983, 1187, 1202, 1220, 1248, 1265, 1330, 1461, 1701, 1738, 1739, 1740, 1741, 1742, 1751, 1753, 1754, 1758, 1759, 1762, 1763, 1764, 1765, 1767, 1768, 1770, 1772, 1790, 1798], "infer": [1, 2, 3, 4, 12, 15, 29, 33, 34, 48, 552, 589, 713, 727, 728, 824, 958, 959, 992, 1005, 1014, 1028, 1031, 1039, 1044, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1302, 1358, 1384, 1418, 1468, 1505, 1586, 1587, 1604, 1611, 1629, 1630, 1670, 1671, 1672, 1673, 1674, 1675, 1700, 1717, 1736, 1738, 1740, 1741, 1745, 1752, 1754, 1770, 1777, 1778, 1783, 1784, 1785, 1787, 1793], "onli": [1, 2, 3, 4, 5, 6, 8, 9, 10, 14, 20, 21, 23, 24, 27, 29, 30, 33, 34, 35, 38, 39, 46, 48, 49, 53, 57, 59, 60, 96, 230, 287, 297, 299, 311, 328, 418, 419, 420, 421, 422, 431, 454, 459, 485, 487, 489, 528, 559, 560, 586, 589, 611, 612, 652, 653, 654, 655, 657, 686, 687, 688, 693, 699, 700, 701, 703, 708, 726, 741, 744, 745, 746, 747, 748, 750, 755, 764, 765, 773, 810, 811, 812, 814, 820, 822, 824, 850, 851, 853, 873, 902, 906, 908, 921, 922, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 944, 951, 952, 956, 957, 962, 971, 983, 987, 988, 992, 1000, 1011, 1019, 1028, 1030, 1033, 1034, 1041, 1045, 1046, 1049, 1060, 1065, 1066, 1068, 1069, 1070, 1071, 1073, 1075, 1076, 1077, 1078, 1088, 1090, 1091, 1093, 1094, 1101, 1102, 1119, 1124, 1158, 1181, 1182, 1183, 1186, 1187, 1193, 1194, 1197, 1220, 1250, 1253, 1255, 1256, 1258, 1266, 1289, 1301, 1302, 1330, 1339, 1341, 1347, 1358, 1385, 1414, 1415, 1418, 1420, 1421, 1422, 1423, 1425, 1426, 1428, 1438, 1458, 1459, 1460, 1470, 1480, 1483, 1494, 1497, 1501, 1504, 1505, 1507, 1511, 1523, 1528, 1533, 1546, 1548, 1549, 1552, 1583, 1597, 1601, 1603, 1605, 1628, 1632, 1633, 1635, 1639, 1669, 1679, 1684, 1688, 1694, 1700, 1711, 1713, 1718, 1719, 1721, 1725, 1726, 1727, 1728, 1735, 1739, 1740, 1741, 1745, 1747, 1748, 1750, 1751, 1752, 1753, 1754, 1757, 1758, 1759, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1772, 1773, 1774, 1775, 1776, 1777, 1780, 1781, 1782, 1783, 1784, 1787, 1789, 1790, 1791, 1793, 1794, 1796, 1797, 1798, 1799, 1800, 1801], "For": [1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 17, 20, 21, 23, 24, 29, 31, 32, 33, 35, 37, 38, 39, 45, 46, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 173, 198, 230, 265, 289, 291, 297, 311, 328, 444, 454, 465, 471, 485, 487, 489, 555, 561, 575, 589, 602, 603, 604, 605, 606, 609, 615, 652, 653, 654, 655, 656, 657, 674, 702, 703, 755, 763, 767, 769, 770, 772, 775, 784, 788, 842, 856, 858, 864, 886, 887, 888, 905, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 949, 969, 971, 972, 983, 992, 1007, 1030, 1040, 1041, 1043, 1045, 1046, 1061, 1065, 1066, 1069, 1072, 1073, 1074, 1075, 1077, 1086, 1087, 1089, 1093, 1102, 1109, 1117, 1124, 1130, 1134, 1158, 1162, 1166, 1167, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1187, 1193, 1194, 1196, 1197, 1202, 1204, 1211, 1216, 1220, 1222, 1250, 1253, 1254, 1255, 1256, 1264, 1265, 1271, 1272, 1273, 1274, 1275, 1276, 1281, 1286, 1300, 1301, 1305, 1322, 1323, 1324, 1347, 1383, 1385, 1404, 1418, 1422, 1423, 1427, 1435, 1458, 1459, 1460, 1462, 1470, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1507, 1546, 1583, 1584, 1617, 1626, 1673, 1679, 1688, 1701, 1703, 1707, 1715, 1726, 1727, 1728, 1735, 1736, 1738, 1741, 1743, 1745, 1747, 1748, 1750, 1752, 1753, 1754, 1755, 1758, 1759, 1760, 1761, 1762, 1764, 1765, 1766, 1767, 1768, 1770, 1772, 1773, 1774, 1777, 1780, 1781, 1782, 1783, 1784, 1785, 1789, 1790, 1791, 1793, 1795, 1796, 1797, 1798, 1799, 1800, 1804], "api": [1, 3, 4, 9, 10, 21, 23, 24, 36, 39, 40, 41, 45, 46, 47, 48, 49, 53, 54, 59, 741, 742, 743, 751, 762, 784, 809, 842, 843, 844, 850, 851, 853, 879, 909, 949, 962, 965, 966, 968, 971, 1040, 1041, 1043, 1423, 1468, 1476, 1532, 1552, 1586, 1617, 1634, 1715, 1728, 1735, 1745, 1747, 1748, 1751, 1752, 1754, 1759, 1763, 1775, 1777, 1785, 1789, 1790, 1793, 1798, 1804], "arg": [1, 2, 4, 5, 6, 14, 20, 21, 23, 27, 29, 31, 32, 35, 38, 39, 40, 46, 47, 49, 50, 51, 53, 59, 60, 64, 552, 575, 648, 663, 665, 666, 667, 668, 674, 676, 677, 738, 744, 745, 853, 961, 965, 966, 967, 971, 1030, 1033, 1119, 1166, 1167, 1184, 1186, 1202, 1210, 1212, 1217, 1220, 1241, 1242, 1250, 1253, 1254, 1255, 1257, 1264, 1265, 1278, 1281, 1282, 1289, 1298, 1309, 1310, 1311, 1319, 1320, 1330, 1342, 1343, 1359, 1382, 1390, 1418, 1423, 1439, 1444, 1458, 1463, 1465, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1552, 1586, 1665, 1689, 1719, 1725, 1728, 1735, 1739, 1741, 1742, 1751, 1753, 1759, 1762, 1763, 1764, 1765, 1772, 1777, 1778, 1781, 1782, 1789, 1790, 1791, 1795, 1803, 1804], "equival": [1, 4, 6, 20, 21, 27, 29, 35, 41, 48, 49, 57, 60, 132, 147, 149, 152, 155, 156, 157, 216, 231, 243, 273, 295, 301, 368, 421, 431, 470, 472, 496, 576, 582, 589, 590, 592, 608, 658, 662, 669, 671, 673, 699, 700, 701, 724, 738, 776, 778, 781, 783, 786, 793, 794, 893, 897, 900, 903, 904, 905, 907, 922, 924, 927, 930, 931, 934, 935, 937, 940, 942, 960, 962, 965, 967, 971, 993, 995, 1007, 1029, 1030, 1040, 1045, 1046, 1049, 1061, 1082, 1086, 1094, 1099, 1131, 1136, 1138, 1145, 1158, 1168, 1169, 1170, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1193, 1194, 1205, 1211, 1213, 1214, 1215, 1216, 1220, 1222, 1250, 1281, 1289, 1301, 1303, 1366, 1387, 1415, 1416, 1417, 1423, 1475, 1595, 1598, 1602, 1626, 1632, 1640, 1662, 1667, 1680, 1690, 1691, 1695, 1700, 1719, 1728, 1729, 1730, 1734, 1738, 1740, 1741, 1759, 1777, 1781, 1785, 1793, 1794, 1796, 1799, 1800, 1804, 1805], "now": [1, 2, 6, 23, 30, 34, 35, 38, 45, 49, 50, 53, 57, 60, 198, 468, 747, 754, 822, 850, 870, 871, 956, 977, 1027, 1028, 1034, 1045, 1079, 1247, 1266, 1302, 1418, 1437, 1448, 1483, 1629, 1684, 1738, 1747, 1752, 1753, 1758, 1759, 1760, 1762, 1763, 1764, 1765, 1770, 1771, 1777, 1781, 1784, 1790, 1791, 1793, 1801, 1804], "device_typ": [1, 1758], "dtype": [1, 2, 12, 17, 18, 20, 23, 32, 38, 53, 60, 130, 131, 168, 185, 189, 190, 191, 192, 218, 287, 289, 291, 293, 295, 297, 384, 403, 406, 418, 419, 420, 421, 422, 426, 431, 443, 454, 456, 485, 487, 536, 552, 575, 589, 603, 605, 608, 609, 613, 615, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 659, 660, 663, 665, 666, 667, 668, 669, 670, 672, 674, 675, 678, 679, 686, 687, 688, 704, 713, 727, 728, 744, 746, 748, 750, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 780, 787, 797, 800, 801, 807, 808, 823, 886, 887, 906, 907, 908, 918, 922, 923, 924, 930, 931, 941, 948, 953, 955, 957, 958, 959, 960, 977, 987, 988, 1000, 1030, 1034, 1043, 1049, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1079, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1111, 1112, 1113, 1114, 1116, 1119, 1120, 1124, 1128, 1129, 1130, 1133, 1134, 1140, 1144, 1145, 1146, 1148, 1158, 1167, 1168, 1169, 1170, 1171, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1193, 1194, 1197, 1202, 1203, 1205, 1213, 1214, 1215, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1237, 1250, 1256, 1257, 1258, 1265, 1266, 1267, 1271, 1272, 1273, 1274, 1275, 1289, 1293, 1295, 1297, 1301, 1302, 1303, 1304, 1314, 1330, 1331, 1364, 1366, 1402, 1403, 1418, 1425, 1426, 1427, 1428, 1434, 1437, 1438, 1458, 1470, 1474, 1475, 1476, 1511, 1517, 1521, 1522, 1531, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1557, 1558, 1561, 1563, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1583, 1584, 1586, 1587, 1590, 1591, 1592, 1593, 1594, 1595, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1606, 1614, 1617, 1629, 1630, 1632, 1633, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1661, 1664, 1667, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1687, 1688, 1697, 1700, 1711, 1713, 1718, 1721, 1726, 1727, 1731, 1733, 1734, 1736, 1737, 1738, 1739, 1740, 1741, 1743, 1747, 1753, 1754, 1762, 1764, 1770, 1773, 1777, 1779, 1784, 1785, 1786, 1793, 1794, 1795, 1798, 1799, 1800, 1805], "enabl": [1, 2, 3, 9, 17, 18, 20, 21, 23, 24, 27, 29, 33, 35, 38, 39, 49, 53, 475, 476, 674, 741, 746, 762, 809, 853, 905, 909, 1005, 1013, 1014, 1032, 1038, 1202, 1220, 1265, 1266, 1296, 1423, 1434, 1435, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1468, 1493, 1544, 1545, 1633, 1634, 1637, 1721, 1741, 1747, 1748, 1754, 1758, 1759, 1760, 1761, 1762, 1769, 1771, 1773, 1774, 1777, 1782, 1783, 1788, 1789, 1790, 1793, 1801, 1803, 1804], "cache_en": [1, 853], "instanc": [1, 4, 20, 23, 24, 27, 29, 30, 35, 39, 45, 48, 49, 50, 53, 57, 60, 116, 589, 662, 671, 703, 705, 809, 905, 956, 1028, 1030, 1041, 1045, 1102, 1193, 1194, 1197, 1213, 1214, 1215, 1222, 1250, 1260, 1294, 1296, 1297, 1301, 1357, 1423, 1427, 1433, 1444, 1458, 1464, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1552, 1554, 1569, 1583, 1673, 1701, 1738, 1740, 1742, 1748, 1751, 1753, 1758, 1759, 1762, 1763, 1764, 1766, 1770, 1774, 1781, 1784, 1789, 1790, 1791, 1793, 1795, 1800, 1804], "serv": [1, 8, 9, 15, 23, 33, 1737, 1747, 1778, 1780, 1789, 1790], "allow": [1, 2, 3, 4, 6, 8, 9, 10, 12, 14, 15, 20, 21, 23, 24, 29, 32, 33, 34, 35, 38, 39, 40, 48, 49, 53, 54, 56, 57, 58, 60, 127, 485, 740, 742, 754, 755, 780, 794, 850, 853, 876, 905, 966, 1030, 1035, 1047, 1085, 1107, 1149, 1163, 1164, 1165, 1186, 1187, 1204, 1243, 1244, 1245, 1250, 1253, 1256, 1278, 1293, 1423, 1428, 1430, 1469, 1492, 1529, 1531, 1552, 1721, 1735, 1740, 1741, 1747, 1752, 1753, 1754, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1767, 1768, 1769, 1770, 1772, 1773, 1775, 1777, 1780, 1781, 1782, 1783, 1784, 1786, 1789, 1793, 1796, 1797, 1798, 1800], "region": [1, 4, 29, 33, 45, 682, 683, 1163, 1164, 1165, 1198, 1199, 1209, 1211, 1243, 1244, 1245, 1315, 1316, 1342, 1343, 1372, 1373, 1694, 1738, 1751, 1758, 1762], "your": [1, 2, 3, 5, 8, 9, 10, 12, 14, 15, 16, 20, 23, 27, 29, 33, 34, 37, 38, 40, 41, 45, 47, 48, 49, 50, 51, 53, 57, 59, 60, 740, 746, 748, 749, 754, 1005, 1030, 1034, 1035, 1039, 1042, 1045, 1046, 1047, 1250, 1257, 1423, 1434, 1437, 1468, 1633, 1718, 1738, 1740, 1741, 1745, 1751, 1752, 1753, 1755, 1758, 1759, 1760, 1762, 1764, 1765, 1766, 1768, 1769, 1770, 1771, 1773, 1774, 1776, 1777, 1778, 1780, 1782, 1785, 1788, 1790, 1793, 1798, 1799, 1801, 1804], "script": [1, 5, 17, 20, 23, 26, 31, 34, 37, 38, 39, 41, 47, 49, 50, 1031, 1033, 1034, 1035, 1036, 1039, 1040, 1042, 1044, 1045, 1047, 1735, 1736, 1740, 1741, 1748, 1761, 1769, 1771, 1775, 1781, 1784, 1789], "In": [1, 3, 4, 5, 6, 8, 10, 15, 17, 20, 23, 27, 29, 32, 33, 35, 38, 41, 48, 49, 50, 53, 55, 56, 57, 59, 60, 65, 67, 69, 71, 73, 75, 77, 79, 81, 83, 85, 87, 98, 100, 102, 104, 107, 108, 110, 118, 120, 123, 124, 126, 129, 131, 135, 137, 139, 141, 143, 145, 154, 163, 171, 175, 178, 180, 190, 192, 198, 208, 212, 214, 220, 223, 225, 227, 229, 233, 238, 245, 247, 249, 253, 255, 259, 261, 268, 270, 272, 280, 282, 284, 286, 331, 333, 335, 337, 339, 341, 343, 346, 348, 350, 351, 358, 360, 362, 364, 366, 370, 394, 397, 400, 402, 412, 414, 416, 424, 429, 439, 442, 458, 462, 464, 480, 483, 494, 498, 500, 503, 505, 507, 520, 522, 524, 533, 535, 543, 547, 549, 565, 568, 570, 572, 574, 584, 594, 674, 710, 746, 779, 800, 801, 808, 853, 864, 875, 876, 880, 881, 905, 926, 928, 936, 937, 938, 953, 963, 967, 970, 1028, 1030, 1039, 1042, 1043, 1045, 1061, 1070, 1075, 1076, 1077, 1085, 1088, 1093, 1098, 1102, 1107, 1110, 1119, 1124, 1130, 1131, 1145, 1163, 1164, 1165, 1167, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1187, 1189, 1190, 1191, 1195, 1197, 1202, 1211, 1216, 1220, 1235, 1243, 1244, 1245, 1250, 1256, 1293, 1295, 1297, 1301, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1337, 1347, 1354, 1359, 1363, 1391, 1394, 1396, 1410, 1423, 1432, 1437, 1438, 1468, 1494, 1505, 1507, 1532, 1552, 1608, 1624, 1626, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1688, 1689, 1709, 1721, 1725, 1726, 1735, 1736, 1737, 1738, 1740, 1741, 1747, 1751, 1752, 1753, 1754, 1757, 1758, 1761, 1762, 1764, 1765, 1766, 1767, 1769, 1770, 1772, 1773, 1774, 1775, 1777, 1780, 1781, 1783, 1784, 1785, 1786, 1789, 1790, 1791, 1793, 1798, 1800], "chosen": [1, 33, 38, 57, 893, 1051, 1637, 1662, 1704, 1754, 1758, 1762, 1764, 1777, 1784], "improv": [1, 2, 4, 10, 14, 18, 21, 23, 38, 53, 60, 674, 748, 750, 754, 803, 983, 1188, 1202, 1220, 1265, 1296, 1423, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1507, 1736, 1738, 1758, 1763, 1764, 1765, 1773, 1774, 1778, 1784, 1785, 1789], "perform": [1, 2, 3, 4, 5, 6, 12, 14, 18, 19, 20, 21, 23, 24, 27, 29, 31, 33, 34, 35, 36, 39, 48, 49, 53, 59, 60, 96, 183, 186, 431, 552, 575, 589, 602, 603, 604, 605, 606, 607, 674, 695, 741, 746, 748, 750, 751, 754, 755, 763, 775, 800, 801, 810, 816, 864, 886, 887, 900, 925, 948, 950, 961, 962, 965, 994, 1005, 1030, 1039, 1040, 1045, 1073, 1075, 1078, 1082, 1085, 1086, 1090, 1091, 1099, 1100, 1102, 1107, 1116, 1129, 1134, 1142, 1145, 1148, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1190, 1193, 1194, 1202, 1220, 1250, 1258, 1265, 1278, 1293, 1296, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1366, 1383, 1402, 1403, 1418, 1423, 1425, 1426, 1433, 1437, 1458, 1463, 1465, 1470, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1513, 1521, 1583, 1586, 1614, 1628, 1632, 1660, 1664, 1665, 1666, 1667, 1687, 1689, 1721, 1736, 1738, 1741, 1750, 1751, 1752, 1753, 1755, 1757, 1758, 1759, 1761, 1762, 1763, 1764, 1765, 1767, 1768, 1771, 1773, 1774, 1777, 1781, 1783, 1784, 1785, 1787, 1789, 1790, 1791, 1793, 1794, 1795, 1796, 1797, 1798, 1800, 1804], "while": [1, 3, 4, 8, 9, 12, 14, 20, 21, 23, 24, 29, 33, 34, 35, 38, 50, 53, 57, 59, 60, 611, 612, 710, 732, 812, 881, 962, 992, 1030, 1033, 1045, 1046, 1102, 1146, 1158, 1174, 1211, 1213, 1214, 1215, 1220, 1250, 1256, 1281, 1289, 1293, 1366, 1423, 1428, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1470, 1624, 1742, 1747, 1753, 1754, 1758, 1759, 1762, 1765, 1766, 1767, 1770, 1772, 1774, 1777, 1780, 1782, 1784, 1787, 1789, 1791, 1793, 1794, 1797, 1798, 1799], "maintain": [1, 8, 9, 20, 21, 23, 29, 35, 53, 60, 1162, 1190, 1195, 1340, 1423, 1458, 1470, 1736, 1754, 1758, 1759, 1762, 1764, 1770, 1784], "accuraci": [1, 21, 33, 1093, 1736, 1750, 1758, 1770, 1798, 1802], "detail": [1, 2, 3, 4, 8, 9, 12, 13, 14, 15, 16, 17, 20, 23, 24, 29, 35, 38, 39, 49, 53, 58, 60, 127, 299, 467, 586, 652, 653, 654, 655, 656, 657, 674, 680, 681, 682, 685, 686, 687, 688, 693, 694, 696, 697, 698, 699, 703, 721, 738, 740, 741, 742, 743, 746, 755, 778, 805, 810, 814, 816, 817, 819, 832, 833, 842, 853, 856, 858, 859, 860, 862, 863, 864, 865, 870, 871, 872, 888, 905, 944, 966, 975, 978, 979, 983, 1011, 1018, 1030, 1034, 1045, 1069, 1087, 1094, 1102, 1108, 1110, 1130, 1158, 1162, 1172, 1181, 1182, 1183, 1187, 1193, 1194, 1195, 1198, 1199, 1202, 1220, 1250, 1256, 1262, 1263, 1265, 1277, 1298, 1306, 1307, 1308, 1309, 1310, 1311, 1313, 1314, 1315, 1316, 1317, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1348, 1350, 1351, 1352, 1353, 1355, 1356, 1357, 1359, 1360, 1361, 1362, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1386, 1388, 1389, 1390, 1391, 1392, 1393, 1395, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1412, 1413, 1414, 1418, 1423, 1424, 1428, 1461, 1469, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1499, 1511, 1523, 1584, 1585, 1586, 1587, 1620, 1631, 1657, 1664, 1707, 1721, 1735, 1738, 1739, 1740, 1741, 1747, 1759, 1760, 1762, 1763, 1764, 1765, 1766, 1767, 1769, 1770, 1773, 1774, 1775, 1777, 1778, 1781, 1782, 1784, 1786, 1789, 1790, 1791, 1793, 1797, 1798, 1800, 1801, 1804], "when": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 17, 20, 21, 23, 24, 27, 29, 30, 32, 35, 38, 39, 40, 41, 42, 46, 47, 48, 49, 50, 51, 53, 56, 57, 58, 59, 60, 61, 74, 127, 168, 185, 236, 289, 297, 421, 469, 470, 485, 487, 489, 515, 531, 552, 589, 602, 605, 682, 683, 693, 699, 713, 725, 728, 740, 748, 749, 750, 751, 752, 753, 754, 755, 756, 763, 766, 775, 783, 786, 794, 800, 801, 805, 811, 813, 822, 824, 846, 852, 853, 865, 888, 905, 944, 948, 953, 958, 962, 963, 968, 969, 970, 971, 983, 1005, 1019, 1020, 1022, 1023, 1026, 1030, 1031, 1033, 1041, 1042, 1043, 1045, 1046, 1050, 1051, 1059, 1060, 1061, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1075, 1076, 1077, 1078, 1079, 1082, 1083, 1084, 1086, 1087, 1088, 1089, 1090, 1091, 1093, 1094, 1095, 1099, 1100, 1101, 1102, 1110, 1116, 1119, 1124, 1130, 1131, 1134, 1140, 1145, 1146, 1147, 1158, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1187, 1193, 1194, 1197, 1200, 1202, 1203, 1205, 1210, 1211, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1237, 1241, 1242, 1243, 1244, 1245, 1250, 1253, 1254, 1255, 1256, 1257, 1258, 1264, 1265, 1277, 1278, 1281, 1282, 1283, 1284, 1286, 1289, 1295, 1296, 1297, 1298, 1300, 1301, 1302, 1303, 1304, 1312, 1314, 1315, 1316, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1330, 1331, 1339, 1345, 1347, 1358, 1359, 1382, 1385, 1387, 1390, 1391, 1404, 1415, 1416, 1417, 1418, 1422, 1423, 1424, 1425, 1426, 1428, 1432, 1433, 1434, 1435, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1461, 1464, 1468, 1469, 1470, 1471, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1489, 1490, 1491, 1492, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1509, 1511, 1513, 1520, 1523, 1524, 1528, 1552, 1568, 1583, 1611, 1617, 1624, 1629, 1632, 1639, 1657, 1663, 1665, 1667, 1668, 1669, 1679, 1684, 1688, 1694, 1695, 1700, 1702, 1707, 1711, 1713, 1718, 1721, 1728, 1731, 1735, 1736, 1738, 1740, 1748, 1750, 1751, 1752, 1753, 1757, 1759, 1760, 1761, 1762, 1763, 1766, 1767, 1768, 1769, 1770, 1772, 1773, 1774, 1775, 1776, 1780, 1781, 1782, 1783, 1788, 1789, 1790, 1791, 1794, 1796, 1797, 1798, 1799, 1800], "enter": [1, 23, 741, 1005], "tensor": [1, 3, 6, 8, 9, 14, 16, 17, 20, 21, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 38, 53, 56, 57, 58, 59, 60, 65, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 636, 648, 652, 653, 654, 655, 656, 657, 658, 659, 660, 662, 664, 669, 670, 671, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 698, 699, 700, 701, 713, 714, 715, 716, 717, 718, 719, 720, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 820, 821, 822, 823, 824, 831, 839, 840, 846, 850, 853, 856, 860, 870, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 970, 971, 972, 973, 974, 975, 976, 977, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1007, 1008, 1009, 1010, 1012, 1015, 1017, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1030, 1031, 1033, 1034, 1036, 1037, 1040, 1041, 1043, 1045, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1158, 1162, 1163, 1166, 1167, 1171, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1187, 1188, 1189, 1190, 1191, 1193, 1194, 1195, 1196, 1197, 1202, 1203, 1204, 1210, 1216, 1217, 1220, 1221, 1237, 1240, 1241, 1242, 1243, 1246, 1247, 1248, 1250, 1253, 1254, 1255, 1256, 1257, 1258, 1260, 1261, 1262, 1263, 1265, 1267, 1271, 1272, 1273, 1274, 1275, 1276, 1282, 1283, 1284, 1285, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1422, 1423, 1424, 1425, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1455, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1489, 1490, 1491, 1492, 1493, 1494, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1523, 1524, 1525, 1526, 1527, 1530, 1531, 1532, 1533, 1534, 1547, 1548, 1549, 1550, 1552, 1553, 1555, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1626, 1627, 1628, 1629, 1630, 1633, 1634, 1637, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1694, 1695, 1696, 1697, 1698, 1699, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1736, 1737, 1738, 1740, 1741, 1745, 1747, 1755, 1757, 1758, 1760, 1761, 1762, 1763, 1765, 1766, 1768, 1770, 1771, 1772, 1773, 1774, 1776, 1779, 1780, 1781, 1782, 1783, 1785, 1788, 1789, 1790, 1794, 1795, 1798, 1800, 1802, 1803, 1804], "you": [1, 2, 4, 5, 6, 8, 9, 10, 12, 14, 15, 16, 19, 20, 21, 23, 27, 29, 31, 32, 35, 36, 37, 38, 39, 40, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 59, 60, 127, 230, 311, 421, 471, 605, 662, 671, 695, 737, 738, 739, 740, 745, 746, 748, 749, 750, 754, 777, 809, 831, 842, 844, 853, 854, 873, 905, 961, 962, 965, 966, 967, 968, 971, 1005, 1030, 1034, 1035, 1042, 1045, 1046, 1047, 1075, 1093, 1101, 1124, 1131, 1134, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1220, 1246, 1247, 1248, 1250, 1255, 1256, 1257, 1265, 1284, 1293, 1295, 1297, 1302, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1358, 1364, 1414, 1415, 1418, 1423, 1427, 1428, 1433, 1459, 1465, 1468, 1480, 1481, 1505, 1523, 1611, 1620, 1628, 1670, 1671, 1672, 1674, 1675, 1728, 1735, 1738, 1740, 1741, 1743, 1745, 1747, 1748, 1750, 1751, 1752, 1754, 1757, 1758, 1759, 1760, 1762, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1774, 1775, 1776, 1777, 1780, 1781, 1782, 1784, 1785, 1788, 1789, 1790, 1791, 1793, 1796, 1797, 1798, 1799, 1800, 1801, 1804], "should": [1, 2, 4, 5, 6, 10, 14, 15, 17, 20, 21, 23, 24, 27, 29, 30, 31, 33, 34, 35, 38, 39, 40, 41, 46, 47, 48, 49, 50, 53, 57, 59, 60, 96, 127, 131, 289, 297, 373, 377, 418, 419, 420, 421, 422, 460, 468, 485, 487, 489, 602, 605, 606, 674, 686, 687, 688, 703, 705, 708, 710, 711, 712, 713, 737, 738, 739, 740, 744, 745, 746, 747, 748, 749, 750, 754, 763, 764, 765, 766, 773, 786, 807, 811, 823, 824, 842, 844, 853, 896, 906, 907, 908, 918, 923, 926, 927, 928, 936, 937, 938, 941, 956, 958, 959, 960, 962, 963, 967, 969, 970, 971, 987, 988, 991, 992, 1027, 1028, 1030, 1031, 1035, 1039, 1041, 1042, 1045, 1046, 1047, 1049, 1074, 1099, 1100, 1101, 1107, 1116, 1119, 1120, 1121, 1158, 1166, 1167, 1171, 1184, 1186, 1187, 1189, 1190, 1191, 1194, 1195, 1216, 1242, 1250, 1256, 1257, 1258, 1277, 1298, 1302, 1312, 1318, 1322, 1323, 1324, 1325, 1326, 1327, 1330, 1339, 1347, 1418, 1420, 1421, 1422, 1423, 1428, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1448, 1451, 1452, 1453, 1454, 1458, 1459, 1460, 1463, 1474, 1475, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1488, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1523, 1532, 1552, 1566, 1567, 1584, 1590, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1611, 1627, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1670, 1671, 1672, 1673, 1674, 1675, 1688, 1694, 1700, 1709, 1728, 1733, 1734, 1735, 1736, 1738, 1740, 1741, 1745, 1747, 1749, 1750, 1751, 1753, 1754, 1757, 1758, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1770, 1772, 1773, 1774, 1776, 1777, 1780, 1781, 1782, 1783, 1784, 1785, 1789, 1791, 1793, 1797, 1798, 1800, 1801, 1804], "model": [1, 2, 3, 4, 5, 6, 9, 10, 21, 23, 24, 27, 29, 33, 34, 35, 38, 47, 49, 51, 53, 54, 55, 56, 57, 58, 60, 64, 702, 706, 707, 708, 710, 795, 854, 873, 961, 962, 963, 969, 971, 1005, 1030, 1034, 1035, 1039, 1041, 1045, 1047, 1101, 1158, 1187, 1204, 1215, 1216, 1250, 1256, 1278, 1289, 1293, 1295, 1296, 1297, 1346, 1423, 1424, 1431, 1433, 1435, 1448, 1466, 1483, 1488, 1493, 1494, 1499, 1505, 1507, 1529, 1530, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1552, 1553, 1554, 1564, 1565, 1566, 1567, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1684, 1728, 1736, 1738, 1740, 1741, 1742, 1748, 1749, 1754, 1759, 1761, 1762, 1763, 1764, 1768, 1770, 1771, 1772, 1773, 1774, 1775, 1777, 1778, 1783, 1785, 1789, 1790, 1792, 1793, 1794, 1798, 1802, 1803], "s": [1, 2, 3, 4, 5, 8, 9, 10, 14, 15, 17, 20, 21, 23, 24, 27, 29, 30, 31, 33, 34, 35, 38, 39, 41, 44, 45, 46, 48, 49, 53, 55, 57, 59, 60, 436, 454, 465, 468, 485, 515, 529, 553, 596, 605, 610, 611, 612, 674, 703, 706, 707, 708, 710, 723, 725, 726, 727, 728, 741, 743, 744, 745, 749, 750, 751, 752, 756, 779, 781, 794, 800, 801, 802, 807, 809, 811, 815, 829, 833, 842, 844, 849, 850, 853, 854, 855, 873, 874, 875, 881, 897, 900, 902, 903, 905, 919, 920, 922, 923, 924, 927, 928, 930, 931, 934, 935, 937, 938, 939, 940, 942, 944, 945, 946, 947, 948, 951, 952, 953, 958, 959, 961, 962, 963, 964, 965, 966, 967, 969, 971, 975, 983, 991, 992, 993, 1017, 1019, 1027, 1028, 1030, 1034, 1040, 1041, 1045, 1060, 1061, 1071, 1072, 1073, 1075, 1078, 1082, 1084, 1086, 1087, 1091, 1092, 1093, 1094, 1099, 1101, 1102, 1117, 1124, 1129, 1131, 1134, 1136, 1137, 1144, 1145, 1148, 1150, 1156, 1157, 1158, 1166, 1167, 1168, 1169, 1170, 1173, 1187, 1193, 1204, 1250, 1251, 1256, 1260, 1266, 1278, 1281, 1283, 1289, 1293, 1295, 1297, 1303, 1304, 1319, 1320, 1331, 1344, 1347, 1358, 1359, 1364, 1402, 1415, 1418, 1422, 1423, 1424, 1428, 1437, 1448, 1461, 1463, 1470, 1471, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1489, 1490, 1491, 1492, 1493, 1494, 1499, 1511, 1513, 1517, 1524, 1548, 1551, 1554, 1586, 1587, 1604, 1607, 1608, 1611, 1612, 1613, 1615, 1617, 1624, 1631, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1682, 1683, 1684, 1687, 1688, 1689, 1690, 1691, 1694, 1697, 1701, 1703, 1709, 1723, 1724, 1725, 1728, 1729, 1735, 1737, 1738, 1739, 1740, 1741, 1742, 1745, 1747, 1749, 1750, 1751, 1752, 1753, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1772, 1773, 1775, 1776, 1777, 1779, 1780, 1782, 1783, 1784, 1786, 1787, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1803, 1804], "es": 1, "network": [1, 2, 8, 9, 15, 27, 29, 48, 853, 1030, 1045, 1046, 1162, 1168, 1169, 1170, 1173, 1181, 1182, 1183, 1187, 1188, 1189, 1190, 1191, 1192, 1195, 1204, 1216, 1220, 1250, 1257, 1262, 1263, 1268, 1277, 1279, 1289, 1293, 1295, 1297, 1312, 1346, 1347, 1399, 1418, 1433, 1435, 1461, 1464, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1490, 1491, 1492, 1493, 1494, 1499, 1505, 1569, 1738, 1740, 1741, 1757, 1758, 1773, 1774, 1777, 1780, 1784, 1789, 1790, 1791], "loss": [1, 2, 21, 23, 24, 27, 29, 53, 963, 1027, 1065, 1066, 1075, 1093, 1158, 1166, 1167, 1173, 1184, 1186, 1193, 1204, 1210, 1211, 1216, 1217, 1241, 1242, 1253, 1254, 1255, 1257, 1264, 1281, 1282, 1298, 1299, 1319, 1320, 1330, 1331, 1344, 1359, 1382, 1390, 1423, 1459, 1483, 1488, 1494, 1498, 1507, 1632, 1735, 1736, 1750, 1753, 1759, 1762, 1763, 1766, 1767, 1770, 1780, 1784, 1785, 1789, 1790, 1798], "comput": [1, 4, 6, 8, 9, 12, 14, 16, 20, 21, 23, 29, 33, 34, 39, 41, 53, 54, 55, 127, 266, 460, 467, 597, 599, 613, 614, 674, 682, 683, 737, 740, 741, 742, 744, 745, 748, 749, 750, 751, 752, 753, 754, 755, 756, 762, 767, 768, 769, 770, 771, 772, 783, 785, 786, 787, 794, 801, 803, 808, 850, 853, 888, 897, 899, 902, 905, 909, 910, 921, 922, 923, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 948, 950, 951, 952, 954, 962, 963, 964, 965, 966, 967, 968, 970, 971, 973, 974, 975, 983, 986, 989, 990, 991, 992, 1005, 1007, 1030, 1033, 1041, 1049, 1050, 1052, 1054, 1058, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1074, 1075, 1076, 1077, 1078, 1079, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1092, 1093, 1094, 1095, 1096, 1098, 1099, 1100, 1102, 1110, 1111, 1112, 1113, 1114, 1116, 1117, 1118, 1119, 1128, 1129, 1130, 1133, 1145, 1147, 1151, 1158, 1162, 1163, 1164, 1165, 1168, 1169, 1170, 1181, 1182, 1183, 1185, 1186, 1188, 1193, 1194, 1202, 1205, 1213, 1214, 1215, 1216, 1218, 1219, 1220, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1240, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1256, 1257, 1259, 1264, 1265, 1283, 1285, 1289, 1296, 1298, 1299, 1302, 1314, 1315, 1316, 1329, 1330, 1338, 1339, 1346, 1347, 1349, 1358, 1366, 1371, 1372, 1373, 1374, 1375, 1376, 1387, 1390, 1402, 1403, 1418, 1420, 1422, 1423, 1424, 1429, 1432, 1435, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1451, 1452, 1459, 1463, 1467, 1468, 1470, 1478, 1480, 1481, 1482, 1484, 1490, 1491, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1511, 1517, 1523, 1524, 1532, 1534, 1547, 1548, 1549, 1550, 1552, 1553, 1593, 1594, 1608, 1609, 1632, 1634, 1640, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1663, 1664, 1665, 1666, 1667, 1684, 1688, 1689, 1694, 1702, 1707, 1725, 1728, 1736, 1738, 1741, 1747, 1750, 1752, 1753, 1755, 1758, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1770, 1771, 1777, 1780, 1784, 1787, 1789, 1793, 1794, 1799, 1802], "backward": [1, 2, 6, 10, 23, 24, 27, 29, 33, 34, 38, 53, 57, 60, 266, 311, 460, 468, 475, 476, 485, 487, 489, 602, 605, 674, 706, 707, 708, 738, 742, 743, 744, 745, 746, 747, 749, 751, 754, 755, 762, 763, 775, 853, 909, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 961, 962, 1030, 1102, 1110, 1124, 1134, 1166, 1167, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1187, 1193, 1202, 1203, 1204, 1217, 1220, 1221, 1237, 1241, 1242, 1250, 1257, 1264, 1265, 1298, 1299, 1319, 1320, 1330, 1331, 1347, 1358, 1382, 1385, 1419, 1422, 1423, 1437, 1468, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1498, 1511, 1523, 1663, 1665, 1669, 1688, 1694, 1721, 1735, 1736, 1739, 1741, 1753, 1754, 1757, 1758, 1759, 1763, 1764, 1765, 1766, 1769, 1770, 1772, 1773, 1780, 1781, 1783, 1784, 1789, 1793, 1794, 1799], "under": [1, 2, 4, 5, 10, 20, 23, 33, 35, 38, 48, 53, 54, 56, 57, 59, 61, 755, 758, 780, 1005, 1030, 1173, 1250, 1312, 1338, 1339, 1432, 1434, 1437, 1609, 1737, 1751, 1758, 1759, 1762, 1763, 1765, 1767, 1772, 1781, 1782, 1784, 1788, 1791, 1794, 1798, 1801, 1803], "recommend": [1, 2, 20, 21, 23, 29, 33, 37, 39, 48, 49, 53, 59, 60, 65, 421, 740, 800, 801, 808, 926, 927, 928, 936, 937, 938, 1017, 1033, 1075, 1102, 1158, 1187, 1359, 1423, 1595, 1718, 1735, 1738, 1751, 1753, 1757, 1758, 1759, 1761, 1762, 1764, 1765, 1770, 1772, 1773, 1775, 1777, 1781, 1784], "correspond": [1, 2, 8, 17, 20, 21, 23, 27, 29, 38, 48, 53, 60, 446, 447, 485, 487, 489, 515, 516, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 737, 739, 740, 745, 748, 750, 755, 787, 802, 853, 872, 900, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 983, 992, 1019, 1030, 1046, 1060, 1065, 1066, 1071, 1074, 1093, 1100, 1102, 1116, 1131, 1140, 1187, 1193, 1220, 1250, 1256, 1296, 1338, 1347, 1384, 1422, 1423, 1428, 1433, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1464, 1470, 1499, 1516, 1517, 1529, 1564, 1566, 1582, 1583, 1584, 1589, 1592, 1615, 1624, 1640, 1682, 1683, 1688, 1717, 1720, 1723, 1724, 1735, 1738, 1739, 1741, 1745, 1750, 1752, 1753, 1758, 1762, 1763, 1764, 1765, 1767, 1769, 1770, 1774, 1777, 1781, 1783, 1784, 1789, 1790, 1793, 1794, 1795, 1798, 1800, 1802, 1803], "devic": [1, 2, 3, 6, 9, 14, 17, 20, 21, 23, 24, 32, 34, 38, 49, 50, 53, 59, 60, 65, 173, 183, 186, 265, 289, 297, 311, 418, 419, 420, 421, 422, 487, 489, 552, 602, 605, 639, 640, 641, 642, 643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 663, 665, 666, 667, 668, 669, 713, 725, 727, 728, 748, 750, 763, 764, 766, 773, 775, 810, 811, 812, 814, 815, 816, 817, 818, 820, 821, 822, 823, 824, 826, 827, 828, 831, 835, 836, 837, 839, 840, 848, 850, 851, 852, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 870, 871, 872, 875, 876, 877, 878, 882, 883, 906, 907, 908, 918, 923, 941, 959, 960, 987, 988, 1030, 1034, 1037, 1040, 1043, 1049, 1059, 1060, 1061, 1065, 1066, 1067, 1068, 1070, 1071, 1072, 1073, 1076, 1077, 1078, 1084, 1087, 1088, 1090, 1091, 1093, 1094, 1100, 1101, 1116, 1119, 1124, 1130, 1134, 1158, 1168, 1169, 1170, 1171, 1178, 1179, 1180, 1181, 1182, 1183, 1187, 1193, 1194, 1203, 1205, 1213, 1214, 1215, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1237, 1250, 1256, 1258, 1266, 1267, 1289, 1293, 1295, 1297, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1339, 1358, 1364, 1411, 1415, 1416, 1417, 1418, 1423, 1425, 1426, 1427, 1428, 1458, 1463, 1469, 1471, 1474, 1475, 1483, 1523, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1628, 1632, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1666, 1670, 1671, 1672, 1673, 1674, 1675, 1688, 1700, 1702, 1711, 1713, 1721, 1733, 1734, 1736, 1737, 1738, 1739, 1740, 1741, 1743, 1748, 1752, 1754, 1758, 1763, 1765, 1766, 1768, 1770, 1771, 1774, 1777, 1779, 1781, 1782, 1783, 1784, 1788, 1789, 1793, 1795, 1799, 1800], "creat": [1, 2, 4, 6, 7, 8, 10, 14, 20, 21, 23, 27, 29, 31, 33, 35, 36, 38, 39, 40, 46, 48, 49, 50, 51, 59, 60, 65, 127, 199, 230, 311, 552, 553, 648, 652, 653, 654, 659, 660, 670, 678, 702, 703, 704, 706, 707, 708, 710, 726, 727, 728, 740, 742, 754, 774, 776, 792, 793, 802, 810, 819, 850, 851, 860, 893, 908, 957, 958, 959, 1027, 1030, 1033, 1042, 1048, 1053, 1059, 1060, 1066, 1068, 1087, 1100, 1116, 1131, 1140, 1166, 1184, 1193, 1194, 1197, 1211, 1217, 1241, 1242, 1250, 1253, 1254, 1255, 1278, 1281, 1282, 1289, 1298, 1299, 1301, 1423, 1437, 1458, 1463, 1476, 1546, 1547, 1552, 1627, 1658, 1668, 1673, 1700, 1707, 1736, 1741, 1742, 1745, 1748, 1751, 1758, 1759, 1762, 1763, 1764, 1765, 1767, 1770, 1771, 1772, 1775, 1777, 1778, 1780, 1781, 1783, 1784, 1789, 1790, 1791, 1793, 1795, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1805], "default": [1, 3, 4, 6, 10, 12, 14, 17, 23, 24, 27, 29, 33, 38, 39, 40, 45, 46, 47, 48, 49, 51, 53, 56, 57, 58, 60, 127, 132, 147, 149, 152, 155, 156, 157, 172, 183, 186, 216, 243, 266, 273, 301, 307, 368, 418, 419, 420, 421, 422, 431, 468, 471, 472, 492, 496, 552, 555, 610, 613, 628, 629, 630, 631, 632, 633, 636, 646, 647, 648, 649, 669, 672, 674, 682, 683, 684, 686, 687, 688, 693, 699, 703, 708, 710, 711, 712, 713, 727, 728, 740, 741, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 764, 773, 779, 783, 786, 787, 788, 792, 795, 807, 808, 811, 814, 816, 822, 823, 824, 827, 828, 835, 836, 839, 850, 852, 853, 856, 858, 859, 860, 862, 864, 865, 866, 870, 871, 872, 876, 877, 880, 882, 883, 886, 887, 888, 893, 894, 895, 896, 897, 900, 905, 906, 907, 908, 918, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 958, 959, 960, 962, 963, 964, 965, 966, 967, 968, 970, 971, 975, 977, 983, 987, 988, 991, 992, 1019, 1021, 1027, 1030, 1031, 1034, 1041, 1045, 1046, 1049, 1050, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1116, 1119, 1121, 1127, 1129, 1130, 1131, 1135, 1144, 1145, 1147, 1148, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1264, 1265, 1267, 1268, 1269, 1270, 1277, 1281, 1282, 1286, 1287, 1289, 1292, 1293, 1295, 1296, 1297, 1298, 1299, 1301, 1302, 1309, 1310, 1311, 1312, 1314, 1315, 1316, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1338, 1339, 1340, 1344, 1346, 1347, 1349, 1351, 1358, 1359, 1366, 1371, 1372, 1373, 1382, 1383, 1385, 1390, 1402, 1403, 1411, 1415, 1423, 1424, 1425, 1426, 1428, 1429, 1432, 1433, 1434, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1459, 1460, 1462, 1463, 1464, 1467, 1469, 1470, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1511, 1513, 1521, 1523, 1524, 1530, 1546, 1547, 1548, 1549, 1550, 1553, 1569, 1583, 1593, 1594, 1595, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1607, 1610, 1616, 1617, 1620, 1624, 1628, 1629, 1630, 1631, 1632, 1637, 1639, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1664, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1682, 1683, 1684, 1687, 1688, 1689, 1694, 1700, 1701, 1707, 1709, 1711, 1713, 1718, 1719, 1721, 1722, 1723, 1724, 1728, 1733, 1734, 1735, 1736, 1738, 1741, 1745, 1748, 1749, 1751, 1754, 1757, 1758, 1761, 1763, 1764, 1765, 1766, 1768, 1770, 1773, 1775, 1776, 1777, 1780, 1781, 1782, 1783, 1784, 1788, 1789, 1793, 1794, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1805], "net": [1, 7, 15, 39, 56, 60, 1030, 1045, 1046, 1187, 1250, 1423, 1448, 1498, 1740, 1741, 1758, 1759, 1762, 1770, 1798], "sgd": [1, 20, 21, 27, 1193, 1418, 1423, 1499, 1505, 1507, 1758, 1762, 1763, 1770, 1780, 1789, 1790], "target": [1, 14, 27, 31, 32, 35, 38, 53, 58, 59, 60, 471, 680, 681, 702, 780, 963, 1030, 1039, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1166, 1167, 1173, 1184, 1186, 1198, 1199, 1204, 1210, 1211, 1216, 1217, 1241, 1242, 1246, 1247, 1248, 1250, 1253, 1254, 1255, 1256, 1257, 1264, 1281, 1282, 1293, 1302, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1319, 1320, 1328, 1330, 1331, 1342, 1343, 1344, 1355, 1356, 1359, 1360, 1370, 1378, 1379, 1380, 1381, 1382, 1390, 1400, 1401, 1423, 1428, 1493, 1529, 1584, 1586, 1587, 1721, 1739, 1741, 1758, 1759, 1762, 1772, 1777, 1780, 1781, 1784, 1785, 1789, 1798, 1802], "data": [1, 2, 3, 4, 8, 12, 17, 18, 21, 23, 27, 29, 30, 33, 34, 35, 39, 42, 45, 48, 50, 53, 60, 116, 127, 172, 173, 302, 305, 309, 312, 317, 418, 421, 454, 465, 469, 471, 589, 652, 653, 654, 674, 686, 687, 688, 695, 702, 703, 704, 713, 727, 728, 738, 740, 764, 773, 779, 812, 886, 887, 906, 907, 908, 918, 919, 920, 923, 925, 926, 928, 936, 937, 938, 941, 944, 945, 946, 947, 956, 958, 959, 960, 962, 969, 987, 988, 990, 1009, 1012, 1037, 1041, 1045, 1049, 1100, 1101, 1102, 1116, 1121, 1129, 1131, 1145, 1147, 1148, 1171, 1173, 1178, 1179, 1180, 1187, 1202, 1205, 1213, 1214, 1215, 1220, 1222, 1237, 1257, 1265, 1266, 1302, 1312, 1317, 1318, 1322, 1323, 1324, 1357, 1364, 1366, 1402, 1403, 1423, 1424, 1425, 1426, 1458, 1459, 1460, 1461, 1470, 1474, 1475, 1476, 1499, 1505, 1513, 1521, 1524, 1530, 1547, 1548, 1549, 1550, 1551, 1553, 1555, 1590, 1591, 1595, 1597, 1598, 1600, 1601, 1602, 1603, 1604, 1611, 1624, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1664, 1667, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1687, 1688, 1700, 1709, 1711, 1713, 1720, 1721, 1733, 1734, 1736, 1738, 1739, 1742, 1747, 1750, 1751, 1754, 1758, 1759, 1760, 1762, 1764, 1765, 1769, 1772, 1774, 1775, 1776, 1779, 1780, 1781, 1782, 1784, 1787, 1789, 1791, 1793, 1794, 1795, 1796, 1797, 1798, 1800, 1801, 1802, 1803], "zero_grad": [1, 2, 27, 1030, 1250, 1423, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1498, 1758, 1762, 1766, 1770, 1772, 1780], "output": [1, 2, 5, 6, 8, 17, 20, 21, 23, 27, 29, 31, 32, 33, 34, 35, 38, 39, 45, 46, 57, 58, 60, 116, 289, 297, 418, 419, 420, 422, 485, 489, 537, 589, 597, 599, 600, 601, 602, 603, 604, 605, 606, 607, 609, 611, 612, 613, 614, 615, 636, 644, 645, 652, 653, 654, 655, 656, 657, 658, 659, 660, 663, 664, 665, 666, 667, 668, 669, 670, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 686, 687, 688, 689, 691, 693, 694, 695, 696, 697, 699, 700, 701, 702, 703, 704, 705, 708, 713, 722, 723, 726, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 763, 765, 766, 767, 768, 769, 770, 771, 772, 775, 779, 782, 783, 784, 785, 786, 787, 788, 790, 793, 801, 802, 804, 805, 808, 820, 822, 823, 824, 850, 851, 853, 863, 864, 884, 885, 886, 887, 889, 892, 893, 895, 897, 900, 902, 904, 905, 906, 907, 908, 910, 915, 918, 919, 920, 921, 922, 923, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 948, 949, 950, 951, 952, 953, 955, 959, 960, 962, 963, 964, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 983, 986, 989, 990, 991, 992, 994, 995, 996, 1004, 1007, 1024, 1025, 1027, 1030, 1034, 1041, 1045, 1046, 1050, 1051, 1052, 1053, 1054, 1055, 1058, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1111, 1112, 1113, 1114, 1116, 1117, 1118, 1119, 1120, 1121, 1123, 1124, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1138, 1139, 1140, 1142, 1144, 1145, 1146, 1147, 1148, 1150, 1151, 1152, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1262, 1263, 1264, 1265, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1314, 1315, 1316, 1318, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1329, 1330, 1331, 1338, 1339, 1341, 1342, 1343, 1344, 1347, 1349, 1358, 1359, 1364, 1366, 1371, 1372, 1373, 1382, 1383, 1387, 1388, 1389, 1390, 1411, 1415, 1416, 1417, 1420, 1422, 1423, 1427, 1428, 1433, 1434, 1435, 1438, 1459, 1461, 1462, 1464, 1467, 1469, 1470, 1471, 1474, 1475, 1498, 1511, 1512, 1520, 1521, 1524, 1531, 1534, 1546, 1583, 1586, 1587, 1588, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1607, 1608, 1609, 1610, 1612, 1613, 1617, 1619, 1624, 1632, 1637, 1640, 1642, 1654, 1655, 1657, 1662, 1665, 1666, 1668, 1669, 1677, 1678, 1680, 1681, 1682, 1683, 1684, 1685, 1687, 1688, 1694, 1697, 1698, 1699, 1704, 1707, 1709, 1710, 1712, 1715, 1717, 1718, 1719, 1721, 1722, 1723, 1724, 1725, 1728, 1730, 1731, 1733, 1734, 1735, 1738, 1739, 1741, 1748, 1752, 1753, 1754, 1758, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1770, 1773, 1777, 1780, 1781, 1782, 1783, 1784, 1786, 1790, 1793, 1794, 1796, 1797, 1798, 1800, 1802, 1803], "loss_fn": [1, 27, 1493, 1758, 1762, 1763, 1772, 1780], "exit": [1, 2, 3, 5, 17, 23, 35, 39, 48, 53, 59, 60, 741, 1423, 1741, 1751, 1759, 1772, 1777, 1791], "befor": [1, 2, 4, 7, 8, 14, 17, 20, 21, 23, 24, 27, 29, 35, 36, 38, 40, 45, 47, 48, 49, 50, 53, 60, 74, 127, 661, 740, 744, 746, 793, 811, 886, 887, 888, 897, 905, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 946, 947, 950, 958, 961, 1030, 1041, 1043, 1082, 1086, 1099, 1129, 1145, 1148, 1187, 1193, 1194, 1197, 1250, 1251, 1252, 1289, 1293, 1301, 1347, 1366, 1402, 1403, 1418, 1420, 1421, 1422, 1423, 1433, 1464, 1467, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1507, 1521, 1524, 1525, 1526, 1527, 1615, 1624, 1635, 1636, 1664, 1667, 1670, 1671, 1672, 1674, 1675, 1684, 1687, 1707, 1718, 1738, 1740, 1741, 1751, 1758, 1759, 1762, 1763, 1764, 1767, 1769, 1770, 1773, 1775, 1776, 1780, 1781, 1782, 1784, 1789, 1790, 1791, 1793, 1794, 1798, 1800], "step": [1, 2, 3, 5, 10, 14, 20, 21, 23, 24, 27, 29, 33, 35, 38, 49, 53, 60, 509, 579, 602, 682, 683, 713, 741, 742, 743, 766, 790, 989, 1077, 1100, 1102, 1116, 1119, 1131, 1198, 1199, 1220, 1315, 1316, 1342, 1343, 1423, 1458, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1582, 1595, 1604, 1658, 1737, 1738, 1739, 1753, 1758, 1759, 1762, 1763, 1764, 1766, 1770, 1772, 1774, 1776, 1777, 1778, 1781, 1783, 1784, 1789, 1790, 1793, 1798], "along": [1, 14, 17, 20, 23, 29, 37, 41, 48, 289, 291, 293, 297, 465, 485, 487, 489, 602, 613, 723, 724, 789, 806, 808, 822, 824, 888, 896, 897, 904, 905, 921, 926, 929, 933, 936, 939, 945, 971, 972, 995, 1004, 1007, 1051, 1062, 1098, 1138, 1145, 1149, 1150, 1159, 1160, 1161, 1185, 1198, 1199, 1240, 1243, 1244, 1245, 1283, 1285, 1312, 1329, 1342, 1343, 1346, 1349, 1366, 1371, 1372, 1373, 1383, 1402, 1403, 1443, 1445, 1452, 1453, 1462, 1469, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1490, 1491, 1492, 1493, 1494, 1505, 1524, 1547, 1609, 1610, 1615, 1626, 1662, 1664, 1667, 1668, 1676, 1681, 1697, 1701, 1704, 1707, 1716, 1725, 1728, 1730, 1735, 1740, 1745, 1754, 1760, 1764, 1766, 1769, 1770, 1781, 1784, 1794], "more": [1, 2, 3, 4, 5, 9, 10, 12, 14, 15, 16, 19, 20, 21, 23, 24, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 44, 47, 48, 49, 50, 53, 56, 57, 58, 60, 127, 230, 231, 289, 297, 465, 467, 470, 487, 489, 516, 590, 685, 694, 698, 710, 721, 734, 735, 736, 738, 740, 746, 748, 750, 754, 755, 756, 766, 774, 777, 779, 785, 786, 787, 788, 811, 812, 814, 816, 817, 832, 851, 856, 858, 859, 860, 862, 863, 864, 865, 870, 871, 872, 876, 883, 888, 894, 903, 905, 909, 921, 922, 924, 926, 945, 946, 947, 948, 962, 963, 964, 965, 966, 967, 968, 970, 971, 978, 979, 983, 992, 993, 1005, 1011, 1015, 1017, 1018, 1030, 1043, 1046, 1059, 1060, 1061, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1097, 1099, 1102, 1105, 1108, 1110, 1120, 1121, 1146, 1158, 1162, 1167, 1172, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1193, 1194, 1195, 1211, 1220, 1250, 1256, 1262, 1263, 1264, 1265, 1277, 1289, 1297, 1312, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1336, 1338, 1339, 1347, 1350, 1351, 1352, 1353, 1358, 1362, 1366, 1367, 1377, 1384, 1391, 1392, 1393, 1395, 1397, 1398, 1399, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1414, 1415, 1416, 1417, 1418, 1423, 1424, 1428, 1432, 1434, 1435, 1468, 1469, 1470, 1511, 1522, 1523, 1584, 1585, 1586, 1614, 1620, 1624, 1634, 1664, 1688, 1694, 1707, 1709, 1721, 1728, 1729, 1735, 1736, 1737, 1738, 1740, 1741, 1747, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1757, 1759, 1761, 1762, 1763, 1764, 1766, 1767, 1768, 1769, 1770, 1773, 1775, 1777, 1778, 1780, 1781, 1782, 1783, 1784, 1785, 1790, 1791, 1793, 1796, 1797, 1798, 1799, 1800, 1801, 1804, 1805], "complex": [1, 2, 4, 8, 9, 21, 23, 34, 60, 287, 305, 456, 601, 608, 755, 756, 788, 800, 801, 900, 926, 948, 953, 983, 1000, 1009, 1020, 1022, 1023, 1026, 1027, 1030, 1050, 1059, 1060, 1061, 1065, 1066, 1067, 1068, 1069, 1070, 1072, 1079, 1082, 1084, 1086, 1087, 1088, 1089, 1093, 1094, 1098, 1099, 1100, 1102, 1110, 1116, 1128, 1133, 1139, 1178, 1179, 1180, 1217, 1250, 1322, 1323, 1324, 1432, 1470, 1517, 1595, 1608, 1629, 1640, 1684, 1685, 1688, 1694, 1721, 1725, 1726, 1727, 1736, 1739, 1741, 1742, 1772, 1779, 1795, 1796, 1799, 1800, 1801], "scenario": [1, 20, 23, 33, 48, 1476, 1762, 1767, 1777, 1783, 1789], "e": [1, 2, 3, 4, 6, 8, 12, 14, 15, 20, 21, 23, 24, 27, 29, 30, 35, 39, 40, 41, 42, 46, 47, 48, 49, 51, 53, 56, 57, 59, 60, 65, 127, 234, 311, 352, 552, 589, 662, 671, 674, 706, 708, 710, 737, 740, 745, 755, 756, 774, 776, 779, 839, 853, 877, 905, 915, 956, 962, 967, 980, 1005, 1009, 1010, 1012, 1015, 1027, 1030, 1036, 1037, 1045, 1065, 1066, 1081, 1093, 1101, 1102, 1103, 1105, 1107, 1124, 1135, 1166, 1167, 1168, 1169, 1170, 1173, 1178, 1179, 1180, 1186, 1187, 1189, 1190, 1191, 1193, 1194, 1195, 1197, 1202, 1205, 1210, 1213, 1214, 1215, 1216, 1217, 1220, 1222, 1223, 1224, 1225, 1241, 1250, 1251, 1256, 1257, 1259, 1260, 1264, 1265, 1281, 1289, 1293, 1297, 1298, 1299, 1301, 1322, 1323, 1324, 1331, 1333, 1334, 1335, 1338, 1339, 1340, 1347, 1358, 1390, 1415, 1417, 1418, 1422, 1423, 1424, 1425, 1426, 1428, 1433, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1458, 1459, 1463, 1467, 1470, 1516, 1583, 1584, 1586, 1587, 1592, 1610, 1617, 1624, 1628, 1635, 1640, 1684, 1688, 1694, 1735, 1738, 1739, 1740, 1741, 1742, 1745, 1747, 1748, 1751, 1752, 1753, 1754, 1758, 1759, 1760, 1761, 1762, 1764, 1765, 1766, 1768, 1769, 1770, 1773, 1775, 1777, 1780, 1781, 1783, 1784, 1789, 1790, 1791, 1793, 1794, 1796, 1797, 1798, 1800, 1804, 1805], "g": [1, 2, 3, 4, 6, 8, 12, 14, 15, 20, 21, 23, 27, 29, 30, 39, 40, 41, 42, 46, 47, 48, 49, 51, 53, 56, 57, 59, 60, 552, 589, 662, 671, 674, 706, 708, 710, 737, 745, 755, 756, 776, 853, 905, 956, 962, 966, 967, 980, 983, 1005, 1027, 1030, 1036, 1037, 1045, 1101, 1173, 1174, 1187, 1189, 1190, 1191, 1195, 1197, 1202, 1210, 1216, 1220, 1221, 1250, 1251, 1260, 1265, 1281, 1331, 1333, 1334, 1335, 1340, 1347, 1423, 1424, 1425, 1426, 1467, 1470, 1478, 1479, 1480, 1481, 1484, 1490, 1491, 1492, 1493, 1584, 1586, 1587, 1610, 1617, 1628, 1635, 1653, 1684, 1735, 1738, 1740, 1741, 1742, 1745, 1747, 1751, 1758, 1759, 1762, 1764, 1765, 1766, 1767, 1769, 1770, 1773, 1774, 1777, 1780, 1781, 1783, 1784, 1789, 1793, 1796, 1797, 1798, 1804], "penalti": [1, 695, 864, 1477, 1478, 1479, 1480, 1482, 1484, 1490, 1491, 1493, 1785], "multipl": [1, 2, 3, 4, 20, 21, 23, 24, 29, 30, 33, 41, 48, 49, 50, 53, 57, 59, 60, 168, 185, 291, 485, 602, 604, 605, 611, 612, 722, 723, 726, 754, 783, 785, 803, 807, 822, 823, 824, 850, 903, 905, 908, 958, 966, 967, 968, 970, 971, 975, 979, 993, 994, 1043, 1046, 1051, 1052, 1067, 1068, 1069, 1085, 1090, 1095, 1096, 1124, 1127, 1132, 1134, 1166, 1167, 1181, 1182, 1183, 1184, 1186, 1194, 1197, 1210, 1216, 1217, 1238, 1241, 1242, 1253, 1254, 1255, 1257, 1264, 1281, 1282, 1298, 1301, 1319, 1320, 1330, 1339, 1359, 1382, 1390, 1423, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1492, 1500, 1501, 1502, 1503, 1504, 1509, 1511, 1569, 1632, 1660, 1665, 1666, 1670, 1671, 1672, 1674, 1675, 1701, 1702, 1709, 1717, 1721, 1728, 1729, 1735, 1736, 1740, 1741, 1751, 1752, 1753, 1754, 1759, 1761, 1763, 1765, 1767, 1769, 1770, 1772, 1773, 1774, 1775, 1776, 1777, 1780, 1781, 1783, 1784, 1785, 1789, 1790, 1791, 1793, 1803], "autograd": [1, 5, 6, 8, 9, 23, 27, 29, 33, 54, 116, 311, 418, 419, 420, 421, 422, 468, 605, 713, 727, 728, 741, 762, 764, 773, 792, 853, 906, 907, 908, 918, 923, 941, 958, 959, 960, 961, 962, 971, 987, 988, 1005, 1030, 1049, 1069, 1100, 1116, 1124, 1134, 1204, 1250, 1256, 1297, 1349, 1364, 1423, 1474, 1475, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1636, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1670, 1671, 1672, 1673, 1674, 1675, 1700, 1728, 1733, 1734, 1736, 1739, 1743, 1747, 1754, 1757, 1762, 1763, 1766, 1767, 1769, 1770, 1783, 1799, 1800, 1801, 1804], "autocastmodel": 1, "produc": [1, 8, 14, 20, 23, 30, 31, 33, 34, 35, 38, 40, 42, 45, 50, 57, 58, 59, 60, 65, 648, 652, 653, 654, 659, 660, 670, 678, 702, 766, 786, 846, 936, 937, 938, 956, 966, 967, 971, 983, 1041, 1045, 1046, 1049, 1065, 1066, 1069, 1076, 1077, 1088, 1093, 1127, 1130, 1131, 1132, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1226, 1227, 1228, 1229, 1230, 1231, 1256, 1331, 1339, 1347, 1358, 1415, 1416, 1417, 1470, 1523, 1595, 1604, 1688, 1721, 1728, 1738, 1740, 1741, 1751, 1752, 1758, 1759, 1760, 1762, 1764, 1768, 1769, 1770, 1773, 1774, 1775, 1776, 1777, 1793, 1797], "after": [1, 2, 8, 10, 14, 20, 21, 23, 24, 27, 32, 33, 35, 38, 48, 50, 53, 59, 60, 236, 740, 741, 744, 809, 811, 846, 853, 904, 962, 1015, 1030, 1034, 1085, 1124, 1154, 1187, 1235, 1250, 1253, 1293, 1295, 1297, 1312, 1347, 1418, 1420, 1423, 1437, 1439, 1443, 1445, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1498, 1499, 1505, 1507, 1527, 1582, 1584, 1586, 1587, 1628, 1684, 1707, 1730, 1735, 1740, 1741, 1750, 1751, 1757, 1758, 1759, 1762, 1763, 1764, 1766, 1767, 1769, 1770, 1772, 1773, 1777, 1780, 1781, 1783, 1784, 1789, 1790, 1791, 1792, 1794, 1796, 1798], "them": [1, 2, 4, 6, 8, 9, 10, 12, 14, 15, 20, 23, 33, 34, 35, 38, 39, 40, 45, 48, 50, 53, 57, 59, 60, 127, 198, 230, 740, 746, 750, 777, 853, 890, 893, 905, 1051, 1060, 1071, 1085, 1097, 1101, 1129, 1148, 1174, 1193, 1250, 1283, 1285, 1402, 1427, 1444, 1459, 1462, 1495, 1667, 1669, 1687, 1735, 1740, 1741, 1747, 1748, 1750, 1751, 1752, 1753, 1754, 1758, 1759, 1760, 1762, 1764, 1765, 1766, 1768, 1769, 1770, 1774, 1776, 1780, 1782, 1783, 1784, 1785, 1789, 1790, 1791, 1793, 1794, 1798, 1799, 1802], "differ": [1, 2, 4, 6, 9, 14, 17, 20, 23, 27, 29, 33, 34, 35, 36, 38, 39, 40, 41, 45, 46, 48, 49, 51, 53, 54, 57, 58, 60, 173, 459, 465, 589, 602, 605, 611, 612, 703, 705, 713, 727, 728, 755, 756, 763, 775, 776, 807, 888, 893, 895, 897, 905, 945, 946, 947, 951, 952, 958, 966, 967, 971, 983, 1004, 1030, 1040, 1045, 1059, 1065, 1066, 1076, 1077, 1085, 1088, 1093, 1097, 1124, 1134, 1158, 1168, 1169, 1170, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1187, 1203, 1211, 1213, 1214, 1215, 1216, 1220, 1221, 1237, 1250, 1253, 1256, 1271, 1272, 1274, 1275, 1276, 1278, 1281, 1289, 1295, 1297, 1299, 1302, 1305, 1312, 1347, 1358, 1360, 1371, 1372, 1373, 1418, 1423, 1425, 1426, 1428, 1432, 1470, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1487, 1489, 1490, 1491, 1492, 1493, 1494, 1499, 1507, 1513, 1523, 1529, 1550, 1552, 1553, 1586, 1587, 1610, 1682, 1683, 1688, 1707, 1718, 1719, 1721, 1723, 1724, 1728, 1735, 1738, 1740, 1741, 1743, 1747, 1751, 1752, 1754, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1767, 1770, 1772, 1773, 1774, 1776, 1780, 1781, 1782, 1783, 1784, 1785, 1789, 1791, 1793, 1796, 1798, 1799, 1800, 1803], "caus": [1, 2, 3, 4, 6, 14, 17, 20, 23, 27, 41, 47, 48, 49, 57, 60, 527, 589, 725, 728, 740, 958, 1041, 1045, 1065, 1066, 1093, 1358, 1359, 1415, 1418, 1423, 1469, 1639, 1684, 1721, 1738, 1741, 1751, 1760, 1762, 1764, 1766, 1772, 1774, 1776, 1777, 1781, 1784, 1785, 1791, 1793], "mismatch": [1, 23, 60, 728, 1031, 1740, 1758, 1763, 1764, 1766, 1777, 1800], "so": [1, 2, 3, 4, 8, 10, 14, 16, 20, 21, 23, 24, 27, 29, 30, 33, 34, 35, 38, 40, 41, 48, 49, 51, 53, 56, 57, 59, 60, 311, 431, 468, 741, 746, 748, 749, 754, 792, 810, 832, 893, 895, 922, 923, 924, 925, 926, 927, 928, 930, 931, 934, 935, 936, 937, 938, 939, 940, 941, 942, 956, 958, 961, 965, 966, 968, 1017, 1027, 1030, 1033, 1034, 1039, 1041, 1043, 1085, 1087, 1097, 1102, 1107, 1119, 1178, 1179, 1180, 1181, 1182, 1183, 1187, 1194, 1197, 1204, 1250, 1266, 1283, 1285, 1301, 1312, 1322, 1323, 1324, 1347, 1402, 1403, 1418, 1423, 1469, 1480, 1481, 1584, 1654, 1667, 1679, 1684, 1688, 1706, 1718, 1722, 1738, 1740, 1741, 1748, 1750, 1751, 1752, 1753, 1754, 1757, 1758, 1759, 1762, 1763, 1764, 1765, 1767, 1768, 1769, 1770, 1772, 1773, 1774, 1775, 1776, 1777, 1780, 1781, 1784, 1788, 1789, 1793, 1794, 1796, 1798, 1799, 1801], "cast": [1, 7, 21, 46, 53, 311, 575, 576, 780, 886, 887, 1030, 1082, 1086, 1099, 1129, 1145, 1148, 1250, 1366, 1402, 1403, 1470, 1521, 1664, 1667, 1673, 1687, 1692, 1693, 1738, 1758, 1773, 1777, 1794, 1795, 1796], "back": [1, 2, 3, 14, 20, 21, 23, 29, 34, 35, 37, 48, 53, 57, 60, 755, 792, 925, 962, 1031, 1043, 1095, 1101, 1296, 1428, 1565, 1669, 1735, 1738, 1741, 1759, 1764, 1765, 1772, 1773, 1774, 1777, 1780, 1781, 1784, 1789, 1793, 1804], "from": [1, 2, 4, 6, 7, 8, 9, 10, 14, 15, 17, 20, 21, 23, 24, 27, 29, 30, 31, 33, 34, 35, 38, 39, 41, 42, 45, 46, 48, 50, 51, 53, 54, 56, 57, 58, 59, 65, 130, 131, 150, 173, 198, 199, 234, 262, 289, 291, 295, 297, 352, 377, 421, 427, 444, 446, 447, 454, 459, 460, 465, 485, 487, 489, 515, 517, 531, 552, 579, 580, 582, 589, 628, 629, 630, 631, 632, 633, 636, 644, 645, 648, 652, 653, 654, 655, 656, 657, 659, 660, 670, 674, 678, 686, 687, 688, 695, 702, 703, 704, 706, 707, 708, 710, 713, 727, 728, 739, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 755, 756, 764, 765, 773, 774, 779, 780, 792, 810, 811, 814, 822, 823, 824, 842, 846, 864, 889, 905, 925, 927, 928, 933, 934, 935, 939, 940, 941, 942, 945, 946, 947, 956, 957, 958, 959, 961, 962, 963, 965, 966, 967, 968, 987, 988, 992, 1007, 1027, 1028, 1030, 1031, 1033, 1035, 1036, 1037, 1040, 1041, 1053, 1069, 1073, 1082, 1085, 1086, 1099, 1100, 1101, 1102, 1116, 1120, 1121, 1134, 1140, 1149, 1150, 1158, 1162, 1168, 1169, 1170, 1171, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1187, 1188, 1189, 1190, 1191, 1193, 1194, 1195, 1197, 1202, 1203, 1204, 1205, 1211, 1213, 1214, 1215, 1216, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1237, 1250, 1251, 1252, 1256, 1260, 1261, 1265, 1267, 1268, 1289, 1294, 1295, 1299, 1301, 1302, 1312, 1332, 1333, 1334, 1335, 1339, 1340, 1344, 1347, 1349, 1358, 1371, 1372, 1373, 1385, 1414, 1418, 1423, 1428, 1429, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1450, 1452, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1467, 1471, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1486, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1511, 1513, 1516, 1524, 1525, 1526, 1529, 1532, 1552, 1554, 1568, 1583, 1585, 1586, 1587, 1589, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1610, 1611, 1614, 1616, 1617, 1624, 1637, 1668, 1670, 1671, 1672, 1673, 1674, 1675, 1684, 1685, 1689, 1694, 1697, 1700, 1709, 1711, 1713, 1718, 1719, 1721, 1722, 1731, 1736, 1738, 1739, 1740, 1741, 1743, 1745, 1747, 1748, 1749, 1750, 1751, 1753, 1754, 1755, 1757, 1759, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1772, 1773, 1774, 1775, 1780, 1782, 1784, 1785, 1789, 1790, 1791, 1793, 1794, 1796, 1798, 1799, 1800, 1801, 1802, 1803, 1804], "alreadi": [1, 2, 12, 20, 21, 23, 24, 48, 49, 53, 59, 60, 172, 183, 186, 436, 459, 495, 552, 575, 576, 702, 710, 727, 819, 844, 1030, 1039, 1101, 1250, 1421, 1423, 1458, 1568, 1583, 1716, 1718, 1735, 1738, 1747, 1749, 1752, 1753, 1758, 1759, 1762, 1764, 1767, 1772, 1777, 1780, 1781, 1784, 1790, 1791, 1795, 1797], "incur": [1, 6, 21, 53, 785, 1772, 1789], "overhead": [1, 2, 4, 5, 9, 21, 23, 33, 34, 35, 53, 695, 795, 1041, 1423, 1761, 1762, 1763, 1768, 1769, 1782, 1783, 1790, 1793, 1799], "here": [1, 2, 8, 9, 10, 15, 17, 20, 21, 23, 24, 29, 33, 34, 35, 38, 47, 49, 55, 56, 57, 59, 60, 552, 805, 817, 905, 922, 924, 925, 930, 931, 932, 934, 935, 940, 942, 961, 969, 1028, 1041, 1168, 1169, 1170, 1181, 1182, 1183, 1213, 1214, 1215, 1258, 1289, 1347, 1349, 1434, 1491, 1505, 1657, 1735, 1738, 1740, 1741, 1743, 1752, 1753, 1754, 1758, 1759, 1762, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1776, 1777, 1780, 1781, 1782, 1784, 1793, 1797, 1798, 1800], "assum": [1, 12, 20, 23, 29, 32, 39, 41, 48, 49, 53, 56, 58, 60, 708, 888, 923, 926, 928, 936, 937, 938, 941, 1021, 1027, 1028, 1031, 1045, 1065, 1066, 1068, 1075, 1084, 1087, 1090, 1092, 1102, 1173, 1242, 1302, 1331, 1423, 1434, 1437, 1462, 1495, 1496, 1501, 1502, 1503, 1506, 1508, 1509, 1513, 1689, 1707, 1709, 1735, 1738, 1740, 1741, 1752, 1759, 1762, 1764, 1765, 1767, 1769, 1773, 1777, 1780, 1781, 1782, 1789, 1790, 1791, 1793], "a_float32": 1, "rand": [1, 2, 17, 29, 60, 311, 609, 615, 748, 749, 750, 751, 752, 753, 807, 850, 851, 922, 924, 927, 928, 930, 931, 934, 935, 937, 938, 940, 942, 963, 1036, 1041, 1045, 1046, 1047, 1103, 1104, 1106, 1216, 1293, 1294, 1295, 1296, 1297, 1319, 1338, 1339, 1423, 1437, 1516, 1592, 1593, 1594, 1598, 1738, 1739, 1740, 1741, 1743, 1752, 1753, 1777, 1779, 1782, 1784, 1789, 1790, 1794, 1797, 1798, 1801], "8": [1, 2, 14, 19, 20, 21, 23, 29, 32, 35, 37, 38, 39, 289, 291, 293, 297, 444, 485, 489, 531, 579, 589, 601, 602, 613, 614, 659, 660, 675, 677, 679, 687, 688, 751, 766, 774, 785, 788, 789, 793, 850, 851, 884, 888, 903, 908, 921, 937, 938, 944, 945, 948, 955, 983, 992, 993, 1053, 1082, 1085, 1086, 1087, 1095, 1097, 1100, 1101, 1149, 1150, 1155, 1156, 1157, 1159, 1160, 1161, 1174, 1185, 1220, 1246, 1247, 1253, 1255, 1257, 1264, 1265, 1268, 1271, 1272, 1273, 1274, 1275, 1276, 1289, 1293, 1294, 1295, 1296, 1297, 1301, 1323, 1326, 1329, 1385, 1390, 1395, 1396, 1470, 1471, 1480, 1481, 1482, 1484, 1490, 1491, 1494, 1499, 1507, 1512, 1516, 1520, 1548, 1549, 1550, 1553, 1605, 1615, 1616, 1617, 1624, 1637, 1644, 1647, 1652, 1658, 1662, 1668, 1670, 1671, 1676, 1684, 1688, 1694, 1696, 1701, 1702, 1703, 1705, 1707, 1716, 1721, 1722, 1729, 1738, 1742, 1747, 1762, 1764, 1775, 1777, 1779, 1781, 1782, 1783, 1784, 1787, 1789, 1793, 1794, 1796, 1797, 1799], "b_float32": 1, "c_float32": 1, "d_float32": 1, "mm": [1, 787, 788, 795, 1034, 1085, 1124, 1260, 1261, 1523, 1688, 1721, 1737, 1739, 1740, 1752, 1758, 1761, 1764, 1773, 1779, 1793], "list": [1, 2, 4, 6, 7, 8, 10, 14, 15, 17, 20, 21, 23, 24, 27, 29, 31, 34, 35, 38, 39, 48, 50, 53, 57, 59, 60, 161, 217, 278, 418, 420, 422, 550, 555, 561, 591, 702, 703, 706, 707, 708, 710, 727, 734, 735, 736, 777, 778, 781, 785, 789, 794, 834, 840, 890, 903, 905, 906, 945, 959, 969, 983, 993, 1030, 1034, 1036, 1041, 1043, 1045, 1046, 1129, 1131, 1148, 1187, 1193, 1222, 1250, 1252, 1261, 1278, 1289, 1300, 1338, 1411, 1423, 1424, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1455, 1458, 1459, 1460, 1461, 1462, 1470, 1474, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1487, 1490, 1491, 1492, 1493, 1494, 1495, 1499, 1501, 1503, 1504, 1505, 1507, 1508, 1530, 1546, 1566, 1586, 1591, 1593, 1594, 1597, 1601, 1616, 1653, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1682, 1683, 1687, 1700, 1701, 1702, 1718, 1719, 1721, 1723, 1724, 1729, 1733, 1735, 1738, 1739, 1742, 1743, 1748, 1750, 1752, 1753, 1754, 1764, 1768, 1770, 1773, 1774, 1775, 1779, 1780, 1781, 1782, 1783, 1784, 1789, 1790, 1793, 1795, 1796, 1797, 1798, 1799, 1801, 1802, 1803, 1804], "No": [1, 10, 51, 59, 747, 1423, 1468, 1740, 1762, 1777, 1787, 1797, 1800], "manual": [1, 20, 23, 46, 48, 49, 51, 53, 60, 726, 754, 992, 1034, 1166, 1167, 1186, 1254, 1255, 1257, 1278, 1297, 1319, 1320, 1330, 1382, 1437, 1458, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1529, 1566, 1738, 1741, 1751, 1758, 1762, 1764, 1765, 1766, 1767, 1770, 1776, 1777, 1784, 1785, 1798], "e_float16": 1, "handl": [1, 6, 10, 12, 14, 20, 21, 23, 24, 27, 33, 34, 35, 39, 40, 41, 48, 49, 53, 59, 60, 460, 738, 747, 802, 811, 825, 852, 865, 905, 951, 952, 971, 1030, 1060, 1187, 1250, 1299, 1347, 1419, 1420, 1421, 1422, 1423, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1568, 1608, 1654, 1689, 1728, 1735, 1750, 1751, 1753, 1762, 1764, 1765, 1766, 1767, 1772, 1777, 1781, 1784, 1789, 1791, 1800], "f_float16": 1, "g_float32": 1, "epoch": [1, 20, 41, 51, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1750, 1758, 1780, 1798], "eval": [1, 60, 969, 1030, 1034, 1039, 1045, 1168, 1169, 1170, 1213, 1214, 1215, 1223, 1224, 1225, 1232, 1233, 1234, 1250, 1256, 1289, 1297, 1433, 1546, 1585, 1586, 1741, 1748, 1770, 1777, 1784, 1803, 1804], "trace": [1, 2, 15, 17, 20, 21, 23, 31, 33, 34, 35, 41, 757, 758, 759, 795, 905, 1033, 1041, 1042, 1046, 1102, 1736, 1739, 1740, 1741, 1743, 1759, 1762, 1763, 1775, 1779, 1781, 1798], "testmodel": 1, "__init__": [1, 2, 20, 21, 23, 29, 31, 38, 53, 60, 969, 1028, 1031, 1033, 1036, 1041, 1045, 1046, 1047, 1250, 1251, 1252, 1260, 1261, 1418, 1586, 1587, 1738, 1740, 1741, 1750, 1759, 1764, 1766, 1770, 1775, 1777, 1781, 1784, 1798], "input_s": [1, 674, 675, 679, 1202, 1203, 1220, 1221, 1265, 1266, 1267, 1427, 1739], "num_class": [1, 34, 1384, 1739], "super": [1, 10, 20, 21, 23, 31, 38, 60, 969, 1028, 1033, 1036, 1041, 1045, 1046, 1047, 1250, 1251, 1252, 1260, 1261, 1262, 1263, 1418, 1505, 1586, 1587, 1738, 1740, 1741, 1742, 1759, 1764, 1770, 1775, 1777, 1781, 1784], "fc1": [1, 21, 1418, 1782], "2": [1, 2, 4, 12, 14, 17, 18, 19, 20, 21, 23, 24, 27, 29, 30, 32, 33, 34, 35, 38, 39, 41, 46, 48, 53, 57, 58, 59, 60, 150, 168, 185, 202, 210, 230, 236, 289, 291, 293, 297, 311, 352, 418, 419, 420, 421, 422, 454, 460, 465, 468, 471, 485, 487, 489, 515, 529, 531, 552, 553, 555, 561, 579, 589, 597, 599, 600, 601, 602, 605, 606, 607, 608, 609, 611, 613, 614, 615, 652, 653, 654, 655, 656, 657, 659, 660, 669, 672, 674, 676, 703, 713, 722, 723, 724, 725, 726, 727, 728, 732, 734, 735, 736, 738, 746, 748, 749, 750, 751, 752, 753, 764, 766, 767, 768, 769, 770, 771, 772, 773, 774, 776, 777, 778, 779, 781, 782, 783, 785, 786, 787, 788, 789, 793, 794, 797, 800, 801, 802, 803, 806, 807, 808, 880, 884, 887, 888, 892, 893, 894, 895, 896, 897, 899, 900, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 915, 918, 919, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 944, 945, 946, 947, 948, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 962, 963, 966, 967, 968, 970, 971, 972, 973, 974, 983, 986, 987, 988, 989, 990, 991, 992, 993, 995, 996, 1004, 1005, 1007, 1017, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1030, 1033, 1034, 1039, 1041, 1043, 1045, 1049, 1050, 1051, 1053, 1054, 1055, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1072, 1073, 1074, 1075, 1076, 1077, 1079, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1090, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1106, 1107, 1108, 1109, 1116, 1118, 1119, 1120, 1121, 1123, 1124, 1127, 1128, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1142, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1154, 1157, 1162, 1163, 1164, 1165, 1166, 1167, 1172, 1173, 1174, 1175, 1176, 1178, 1179, 1180, 1181, 1182, 1183, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1200, 1201, 1202, 1204, 1206, 1207, 1208, 1209, 1211, 1218, 1219, 1220, 1221, 1222, 1236, 1238, 1239, 1240, 1241, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1252, 1253, 1255, 1256, 1258, 1259, 1261, 1262, 1263, 1264, 1265, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1277, 1279, 1280, 1281, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1298, 1300, 1301, 1302, 1303, 1304, 1305, 1312, 1314, 1319, 1320, 1331, 1338, 1339, 1345, 1347, 1349, 1351, 1358, 1364, 1371, 1372, 1373, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1412, 1418, 1423, 1427, 1429, 1432, 1433, 1437, 1449, 1450, 1451, 1452, 1454, 1455, 1458, 1460, 1461, 1463, 1464, 1468, 1469, 1470, 1471, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1502, 1506, 1507, 1508, 1512, 1513, 1514, 1516, 1517, 1520, 1521, 1523, 1524, 1548, 1590, 1591, 1592, 1593, 1594, 1595, 1597, 1599, 1601, 1603, 1604, 1605, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1620, 1624, 1626, 1627, 1628, 1629, 1630, 1631, 1634, 1637, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1658, 1662, 1663, 1665, 1666, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1682, 1683, 1684, 1685, 1687, 1688, 1689, 1690, 1691, 1694, 1695, 1696, 1698, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1709, 1710, 1711, 1712, 1713, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1733, 1734, 1737, 1739, 1740, 1741, 1742, 1747, 1748, 1751, 1752, 1753, 1754, 1757, 1758, 1759, 1760, 1761, 1763, 1764, 1767, 1768, 1770, 1771, 1773, 1774, 1775, 1776, 1777, 1778, 1780, 1781, 1782, 1783, 1784, 1786, 1787, 1789, 1790, 1791, 1793, 1794, 1796, 1797, 1798, 1799, 1800, 1801, 1803], "we": [1, 2, 3, 6, 8, 9, 10, 12, 14, 15, 20, 21, 23, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 48, 49, 51, 53, 54, 55, 56, 57, 59, 60, 468, 628, 629, 630, 631, 632, 633, 634, 635, 636, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 659, 660, 670, 675, 676, 677, 678, 679, 693, 699, 703, 713, 740, 741, 744, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 764, 773, 808, 814, 864, 905, 923, 925, 926, 927, 928, 935, 940, 941, 942, 956, 965, 966, 968, 971, 983, 987, 988, 1004, 1028, 1030, 1033, 1034, 1041, 1043, 1045, 1085, 1088, 1093, 1101, 1102, 1121, 1140, 1158, 1166, 1167, 1216, 1250, 1302, 1347, 1349, 1358, 1415, 1421, 1423, 1432, 1434, 1443, 1445, 1448, 1452, 1453, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1496, 1502, 1507, 1524, 1525, 1526, 1528, 1566, 1582, 1584, 1586, 1587, 1728, 1735, 1736, 1738, 1740, 1741, 1743, 1745, 1747, 1748, 1751, 1752, 1753, 1754, 1759, 1762, 1764, 1765, 1766, 1767, 1768, 1770, 1772, 1773, 1776, 1777, 1780, 1781, 1782, 1784, 1785, 1787, 1789, 1790, 1791, 1793, 1796, 1798, 1801, 1802, 1803], "suggest": [1, 10, 21, 38, 54, 1184, 1735, 1743, 1758, 1759, 1766, 1793], "issu": [1, 3, 4, 6, 10, 11, 12, 14, 19, 20, 23, 30, 33, 34, 53, 54, 56, 57, 60, 748, 754, 956, 967, 971, 1075, 1119, 1131, 1216, 1220, 1265, 1302, 1358, 1359, 1728, 1735, 1736, 1741, 1743, 1747, 1751, 1752, 1753, 1754, 1758, 1759, 1762, 1764, 1772, 1773, 1774, 1776, 1777, 1781, 1784, 1785, 1789, 1793, 1794], "http": [1, 3, 4, 5, 8, 10, 14, 15, 21, 22, 23, 29, 34, 37, 48, 49, 53, 127, 646, 647, 648, 649, 659, 660, 670, 675, 676, 677, 678, 679, 702, 740, 905, 962, 1102, 1131, 1173, 1220, 1268, 1269, 1293, 1296, 1299, 1467, 1513, 1595, 1653, 1721, 1735, 1742, 1749, 1759, 1760, 1767, 1768, 1770, 1774, 1776, 1777, 1781, 1783, 1798, 1805], "github": [1, 8, 10, 14, 22, 23, 33, 38, 44, 53, 54, 57, 127, 702, 740, 754, 962, 1131, 1293, 1499, 1735, 1743, 1747, 1764, 1767, 1774, 1777, 1783, 1784, 1793, 1794], "com": [1, 8, 14, 22, 23, 47, 49, 53, 127, 702, 740, 962, 1131, 1293, 1721, 1735, 1749, 1767, 1768, 1774, 1776, 1777, 1783], "pytorch": [1, 2, 3, 4, 5, 6, 12, 13, 14, 16, 17, 20, 21, 26, 27, 29, 30, 33, 35, 36, 37, 38, 39, 41, 48, 49, 53, 54, 58, 60, 62, 63, 127, 555, 614, 646, 647, 648, 649, 659, 660, 670, 675, 676, 677, 678, 679, 702, 703, 740, 780, 785, 786, 796, 808, 814, 832, 833, 844, 849, 905, 950, 956, 962, 963, 967, 970, 971, 976, 1016, 1017, 1040, 1060, 1071, 1073, 1074, 1075, 1078, 1091, 1100, 1116, 1119, 1120, 1131, 1166, 1173, 1216, 1293, 1423, 1458, 1464, 1470, 1523, 1542, 1543, 1544, 1545, 1620, 1629, 1639, 1684, 1688, 1694, 1709, 1721, 1728, 1735, 1737, 1740, 1741, 1745, 1747, 1749, 1750, 1753, 1754, 1755, 1760, 1761, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1776, 1780, 1781, 1783, 1784, 1785, 1786, 1789, 1790, 1793, 1794, 1796, 1797, 1798, 1804, 1805], "75956": 1, "_c": [1, 20, 21, 23, 59, 748, 754, 1029, 1041, 1476, 1739, 1741, 1750, 1769, 1773, 1776, 1777], "_jit_set_autocast_mod": 1, "randn": [1, 2, 12, 23, 29, 31, 33, 34, 35, 38, 55, 57, 58, 60, 265, 287, 456, 515, 552, 556, 557, 558, 559, 560, 561, 589, 599, 600, 601, 602, 603, 604, 605, 606, 611, 612, 615, 636, 644, 645, 652, 653, 654, 655, 656, 657, 670, 672, 674, 675, 676, 677, 678, 679, 686, 687, 688, 722, 723, 724, 726, 729, 730, 731, 732, 733, 763, 775, 782, 784, 785, 786, 787, 788, 790, 802, 803, 804, 805, 806, 808, 884, 885, 886, 887, 892, 893, 894, 895, 899, 905, 919, 920, 949, 961, 962, 963, 965, 966, 967, 968, 969, 970, 971, 1000, 1004, 1007, 1041, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1079, 1083, 1084, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1098, 1105, 1109, 1110, 1117, 1119, 1120, 1121, 1123, 1124, 1127, 1129, 1130, 1132, 1134, 1135, 1136, 1137, 1138, 1139, 1142, 1152, 1155, 1156, 1157, 1159, 1160, 1161, 1162, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1182, 1183, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1248, 1249, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1267, 1268, 1269, 1270, 1276, 1277, 1279, 1280, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1298, 1300, 1301, 1305, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1329, 1330, 1331, 1342, 1343, 1349, 1382, 1388, 1389, 1427, 1473, 1514, 1519, 1520, 1521, 1523, 1524, 1586, 1587, 1602, 1606, 1607, 1619, 1655, 1657, 1662, 1665, 1666, 1669, 1677, 1678, 1687, 1688, 1694, 1695, 1698, 1699, 1702, 1706, 1709, 1710, 1712, 1715, 1717, 1721, 1726, 1727, 1728, 1731, 1739, 1740, 1741, 1743, 1752, 1753, 1754, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1768, 1770, 1774, 1775, 1777, 1779, 1781, 1784, 1789, 1793, 1794, 1796, 1798, 1801, 1803], "freez": [1, 1030, 1039, 1193, 1194, 1250, 1759], "_": [1, 2, 4, 20, 21, 23, 24, 27, 31, 35, 38, 41, 58, 60, 597, 599, 600, 614, 713, 729, 730, 731, 732, 733, 741, 747, 765, 784, 801, 802, 804, 805, 807, 949, 954, 968, 970, 996, 1050, 1058, 1109, 1117, 1168, 1169, 1170, 1213, 1214, 1215, 1289, 1423, 1433, 1464, 1491, 1493, 1513, 1601, 1604, 1607, 1619, 1634, 1640, 1642, 1648, 1655, 1657, 1677, 1688, 1694, 1698, 1699, 1759, 1762, 1765, 1766, 1770, 1776, 1781, 1783, 1794], "3": [1, 2, 4, 5, 7, 10, 12, 17, 18, 20, 21, 23, 27, 29, 30, 32, 33, 34, 35, 37, 38, 39, 41, 46, 48, 53, 55, 57, 58, 59, 60, 168, 185, 230, 236, 265, 289, 291, 293, 297, 418, 419, 420, 421, 422, 444, 460, 465, 468, 471, 485, 487, 489, 508, 515, 529, 531, 553, 555, 579, 589, 597, 601, 602, 603, 604, 605, 606, 607, 608, 609, 613, 614, 615, 652, 653, 654, 655, 656, 657, 660, 662, 671, 674, 675, 676, 677, 679, 686, 687, 688, 699, 703, 713, 723, 724, 726, 727, 728, 735, 736, 748, 749, 750, 751, 752, 753, 763, 765, 766, 767, 768, 769, 770, 771, 772, 774, 775, 776, 777, 778, 779, 781, 782, 783, 785, 786, 787, 788, 789, 793, 794, 797, 800, 801, 806, 807, 808, 850, 851, 853, 887, 888, 889, 892, 893, 894, 895, 896, 897, 899, 900, 902, 903, 904, 905, 906, 907, 908, 910, 918, 921, 926, 929, 933, 939, 944, 945, 946, 947, 948, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 961, 963, 968, 969, 971, 972, 973, 974, 983, 986, 989, 990, 991, 992, 993, 995, 996, 1004, 1005, 1007, 1015, 1017, 1019, 1021, 1030, 1034, 1036, 1039, 1041, 1045, 1046, 1050, 1051, 1052, 1053, 1054, 1055, 1059, 1061, 1062, 1063, 1065, 1066, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1079, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1107, 1110, 1112, 1116, 1117, 1118, 1119, 1120, 1121, 1123, 1124, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1136, 1137, 1138, 1139, 1140, 1142, 1144, 1145, 1146, 1148, 1149, 1150, 1151, 1163, 1164, 1165, 1166, 1167, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1182, 1183, 1186, 1193, 1194, 1197, 1198, 1199, 1200, 1202, 1203, 1205, 1207, 1208, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1251, 1253, 1255, 1257, 1262, 1263, 1265, 1267, 1268, 1271, 1272, 1273, 1274, 1275, 1276, 1283, 1284, 1285, 1289, 1297, 1301, 1302, 1303, 1304, 1305, 1312, 1314, 1319, 1320, 1323, 1324, 1326, 1327, 1330, 1338, 1339, 1342, 1343, 1345, 1347, 1351, 1352, 1358, 1366, 1382, 1384, 1385, 1388, 1389, 1395, 1396, 1402, 1403, 1415, 1423, 1427, 1433, 1447, 1449, 1451, 1452, 1453, 1454, 1458, 1460, 1461, 1462, 1464, 1469, 1470, 1471, 1473, 1474, 1475, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1502, 1505, 1506, 1508, 1512, 1514, 1516, 1520, 1521, 1523, 1524, 1552, 1586, 1587, 1592, 1593, 1594, 1595, 1596, 1597, 1599, 1601, 1603, 1604, 1605, 1608, 1609, 1610, 1611, 1612, 1613, 1615, 1616, 1617, 1620, 1624, 1628, 1629, 1630, 1637, 1640, 1642, 1644, 1646, 1647, 1648, 1652, 1653, 1654, 1662, 1665, 1666, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1687, 1688, 1690, 1691, 1694, 1695, 1696, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1709, 1710, 1711, 1712, 1713, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1725, 1728, 1729, 1730, 1731, 1733, 1734, 1737, 1738, 1739, 1740, 1741, 1742, 1747, 1751, 1752, 1753, 1754, 1757, 1758, 1759, 1760, 1762, 1763, 1764, 1765, 1767, 1770, 1771, 1775, 1776, 1777, 1778, 1780, 1781, 1784, 1786, 1789, 1790, 1791, 1793, 1794, 1796, 1797, 1798, 1799, 1800, 1801, 1803], "bug": [1, 14, 17, 23, 33, 38, 60, 965, 966, 968, 1119, 1758, 1772, 1793], "what": [1, 2, 4, 6, 8, 9, 10, 23, 29, 31, 33, 35, 38, 41, 45, 46, 55, 57, 60, 966, 1045, 1046, 1119, 1178, 1179, 1180, 1181, 1182, 1183, 1197, 1244, 1245, 1278, 1301, 1371, 1372, 1373, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1490, 1491, 1492, 1493, 1494, 1524, 1735, 1736, 1738, 1740, 1741, 1752, 1764, 1765, 1767, 1770, 1777, 1780, 1783, 1784, 1789, 1790, 1793], "observ": [1, 21, 33, 38, 39, 48, 670, 702, 703, 705, 706, 708, 803, 807, 1043, 1131, 1166, 1167, 1168, 1169, 1170, 1184, 1186, 1210, 1213, 1214, 1215, 1216, 1217, 1241, 1242, 1253, 1254, 1255, 1257, 1264, 1281, 1282, 1289, 1298, 1319, 1320, 1330, 1359, 1382, 1390, 1526, 1527, 1529, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1543, 1545, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1584, 1586, 1587, 1589, 1758, 1759, 1762, 1763, 1769, 1785, 1803], "pleas": [1, 2, 5, 7, 8, 9, 10, 12, 15, 21, 23, 29, 38, 40, 43, 44, 48, 49, 53, 54, 55, 56, 57, 58, 60, 230, 231, 470, 590, 605, 646, 647, 648, 649, 655, 656, 657, 659, 660, 670, 675, 676, 677, 678, 679, 741, 742, 743, 748, 750, 751, 754, 777, 888, 961, 965, 966, 967, 968, 971, 1030, 1093, 1124, 1134, 1173, 1181, 1216, 1250, 1347, 1359, 1364, 1385, 1414, 1423, 1427, 1428, 1464, 1465, 1501, 1586, 1587, 1728, 1743, 1747, 1752, 1753, 1754, 1755, 1758, 1759, 1764, 1765, 1768, 1773, 1774, 1776, 1777, 1780, 1781, 1784, 1789, 1790, 1793, 1794, 1797, 1798, 1800], "file": [1, 2, 4, 7, 8, 10, 12, 14, 17, 20, 33, 39, 41, 46, 48, 50, 56, 57, 60, 748, 754, 757, 758, 810, 846, 965, 966, 968, 1005, 1037, 1040, 1101, 1620, 1735, 1738, 1741, 1742, 1743, 1749, 1752, 1753, 1754, 1759, 1762, 1764, 1769, 1774, 1775, 1776, 1777, 1783, 1784, 1790, 1793, 1795, 1798], "subregion": 1, "nest": [1, 2, 6, 14, 53, 60, 561, 703, 706, 708, 741, 750, 868, 869, 963, 971, 1030, 1033, 1045, 1250, 1296, 1728, 1736, 1765, 1777, 1783, 1789], "local": [1, 23, 27, 32, 33, 35, 38, 39, 46, 48, 49, 50, 51, 53, 60, 762, 850, 909, 962, 1005, 1030, 1102, 1189, 1190, 1191, 1195, 1197, 1238, 1250, 1301, 1341, 1365, 1414, 1423, 1424, 1468, 1634, 1735, 1736, 1740, 1751, 1758, 1762, 1763, 1766, 1777, 1781, 1782, 1786, 1789, 1790, 1791, 1798], "want": [1, 2, 8, 9, 10, 14, 20, 23, 29, 31, 32, 33, 34, 45, 55, 56, 57, 59, 60, 421, 468, 471, 695, 846, 961, 962, 1042, 1045, 1046, 1131, 1198, 1199, 1302, 1342, 1343, 1358, 1415, 1423, 1424, 1465, 1468, 1528, 1566, 1620, 1735, 1745, 1747, 1758, 1759, 1761, 1762, 1764, 1765, 1767, 1770, 1777, 1780, 1781, 1784, 1793, 1798, 1799, 1802], "particular": [1, 4, 8, 20, 33, 37, 38, 39, 45, 48, 49, 53, 60, 531, 880, 971, 1030, 1124, 1187, 1250, 1586, 1587, 1728, 1738, 1740, 1747, 1754, 1759, 1762, 1764, 1766, 1769, 1770, 1773, 1777, 1780, 1793, 1795, 1804], "explicit": [1, 9, 23, 53, 60, 842, 983, 1017, 1359, 1628, 1702, 1735, 1736, 1737, 1741, 1742, 1752, 1758, 1762, 1764, 1781, 1796, 1797], "control": [1, 2, 3, 14, 20, 21, 23, 24, 29, 31, 34, 35, 39, 44, 47, 48, 669, 724, 728, 741, 764, 773, 892, 893, 894, 895, 896, 987, 988, 1041, 1042, 1043, 1045, 1060, 1066, 1068, 1071, 1073, 1076, 1078, 1082, 1088, 1091, 1093, 1099, 1119, 1158, 1178, 1179, 1180, 1181, 1182, 1183, 1197, 1236, 1244, 1245, 1301, 1423, 1511, 1531, 1583, 1586, 1632, 1633, 1647, 1662, 1668, 1684, 1688, 1694, 1704, 1710, 1711, 1712, 1713, 1738, 1759, 1761, 1762, 1763, 1770, 1772, 1773, 1775, 1777, 1784, 1791, 1793], "execut": [1, 2, 3, 4, 5, 6, 8, 14, 15, 20, 23, 27, 32, 33, 35, 36, 38, 39, 40, 42, 49, 53, 57, 59, 60, 814, 824, 883, 962, 1030, 1031, 1033, 1045, 1046, 1101, 1187, 1250, 1420, 1422, 1423, 1635, 1736, 1738, 1740, 1742, 1748, 1758, 1759, 1760, 1761, 1766, 1769, 1770, 1772, 1774, 1776, 1777, 1783, 1784, 1789, 1790, 1793], "surround": [1, 60, 1527, 1740, 1758, 1762], "ensur": [1, 2, 5, 7, 8, 10, 20, 23, 24, 27, 33, 38, 39, 48, 49, 51, 53, 59, 60, 454, 459, 744, 746, 962, 1030, 1162, 1243, 1250, 1253, 1254, 1293, 1347, 1371, 1372, 1373, 1423, 1428, 1547, 1636, 1735, 1738, 1740, 1747, 1749, 1751, 1758, 1759, 1762, 1764, 1765, 1767, 1772, 1774, 1781, 1784, 1785, 1789, 1790], "necessari": [1, 2, 4, 10, 14, 20, 33, 38, 39, 48, 49, 53, 59, 65, 168, 185, 531, 561, 747, 962, 1004, 1041, 1256, 1459, 1460, 1738, 1741, 1753, 1757, 1759, 1760, 1762, 1763, 1768, 1770, 1773, 1776, 1781, 1784, 1789, 1790, 1791, 1796], "becaus": [1, 2, 4, 5, 6, 8, 9, 14, 20, 21, 23, 27, 29, 33, 34, 35, 38, 41, 53, 57, 59, 60, 468, 750, 755, 756, 926, 927, 928, 936, 937, 938, 963, 967, 970, 971, 1027, 1031, 1034, 1037, 1076, 1077, 1101, 1119, 1168, 1169, 1170, 1187, 1289, 1418, 1423, 1424, 1497, 1604, 1684, 1728, 1736, 1738, 1741, 1743, 1751, 1752, 1753, 1758, 1759, 1760, 1762, 1763, 1764, 1766, 1767, 1768, 1769, 1770, 1771, 1773, 1777, 1781, 1784, 1785, 1789, 1791, 1793, 1798, 1800, 1803, 1804], "wa": [1, 2, 4, 8, 17, 21, 23, 35, 46, 47, 48, 49, 53, 59, 60, 311, 459, 468, 699, 702, 710, 785, 796, 811, 812, 834, 838, 853, 866, 883, 925, 971, 1027, 1036, 1045, 1060, 1071, 1073, 1077, 1101, 1119, 1140, 1220, 1246, 1247, 1248, 1279, 1302, 1312, 1347, 1399, 1415, 1423, 1424, 1461, 1499, 1505, 1682, 1683, 1718, 1719, 1723, 1724, 1728, 1735, 1738, 1740, 1741, 1742, 1745, 1747, 1750, 1751, 1758, 1759, 1760, 1762, 1764, 1765, 1766, 1769, 1771, 1777, 1780, 1782, 1784, 1788, 1789, 1800], "f_float32": 1, "re": [1, 2, 5, 6, 8, 14, 20, 23, 27, 30, 33, 34, 38, 45, 48, 53, 54, 55, 56, 57, 59, 60, 775, 956, 1030, 1034, 1250, 1402, 1424, 1461, 1615, 1667, 1738, 1741, 1747, 1751, 1758, 1759, 1762, 1764, 1765, 1767, 1772, 1784, 1790, 1791, 1794, 1804], "again": [1, 6, 17, 20, 23, 27, 35, 39, 56, 1140, 1759, 1765, 1770], "regardless": [1, 20, 33, 47, 53, 801, 1034, 1039, 1718, 1758, 1762, 1775, 1789, 1800], "g_float16": 1, "thread": [1, 2, 4, 20, 23, 32, 39, 50, 53, 59, 762, 811, 909, 980, 981, 1005, 1187, 1468, 1634, 1635, 1636, 1736, 1738, 1750, 1758, 1762, 1769, 1772, 1789, 1791, 1801], "new": [1, 2, 6, 9, 14, 17, 20, 22, 23, 29, 32, 33, 35, 38, 39, 48, 49, 53, 54, 57, 58, 59, 60, 198, 230, 287, 421, 456, 460, 468, 471, 515, 552, 555, 589, 600, 674, 710, 727, 729, 730, 731, 732, 733, 742, 778, 779, 784, 793, 802, 804, 805, 812, 814, 889, 893, 915, 919, 920, 946, 947, 949, 962, 971, 1000, 1004, 1005, 1019, 1020, 1023, 1026, 1030, 1036, 1041, 1043, 1103, 1104, 1105, 1106, 1123, 1149, 1152, 1168, 1169, 1170, 1202, 1213, 1214, 1215, 1250, 1251, 1256, 1260, 1289, 1300, 1302, 1358, 1422, 1423, 1433, 1437, 1439, 1443, 1444, 1445, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1462, 1464, 1507, 1528, 1546, 1547, 1596, 1606, 1607, 1611, 1612, 1613, 1619, 1620, 1624, 1629, 1630, 1640, 1642, 1653, 1655, 1657, 1677, 1678, 1681, 1696, 1698, 1699, 1715, 1717, 1720, 1726, 1727, 1728, 1735, 1738, 1740, 1741, 1745, 1747, 1748, 1751, 1752, 1753, 1754, 1755, 1759, 1762, 1764, 1765, 1768, 1769, 1770, 1771, 1772, 1774, 1775, 1776, 1777, 1778, 1781, 1783, 1784, 1791, 1793, 1794, 1795, 1797, 1798, 1799, 1800, 1803], "must": [1, 4, 7, 10, 14, 20, 23, 27, 29, 30, 35, 37, 38, 39, 46, 49, 50, 53, 56, 57, 59, 60, 65, 74, 116, 130, 131, 173, 236, 289, 291, 297, 373, 375, 377, 485, 515, 516, 537, 555, 589, 602, 603, 604, 605, 606, 607, 613, 662, 671, 686, 687, 688, 706, 708, 726, 732, 737, 738, 739, 741, 747, 749, 751, 752, 753, 755, 756, 763, 765, 767, 768, 769, 770, 771, 772, 775, 779, 782, 797, 807, 810, 811, 820, 821, 822, 824, 850, 851, 853, 893, 895, 896, 897, 899, 902, 903, 905, 926, 927, 928, 933, 935, 936, 937, 938, 939, 946, 947, 956, 958, 961, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 983, 992, 993, 996, 1007, 1027, 1030, 1040, 1045, 1052, 1055, 1084, 1085, 1086, 1087, 1093, 1095, 1096, 1099, 1102, 1120, 1122, 1123, 1124, 1130, 1137, 1140, 1146, 1149, 1150, 1154, 1167, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1187, 1193, 1194, 1197, 1204, 1205, 1211, 1243, 1250, 1253, 1256, 1281, 1287, 1302, 1320, 1329, 1331, 1339, 1358, 1371, 1372, 1373, 1391, 1423, 1448, 1458, 1459, 1463, 1470, 1503, 1505, 1512, 1513, 1516, 1517, 1520, 1584, 1585, 1593, 1594, 1615, 1624, 1627, 1636, 1652, 1663, 1665, 1666, 1668, 1670, 1671, 1672, 1673, 1674, 1675, 1684, 1689, 1697, 1701, 1702, 1706, 1711, 1713, 1717, 1721, 1725, 1726, 1728, 1729, 1731, 1738, 1739, 1740, 1741, 1747, 1751, 1752, 1753, 1754, 1757, 1758, 1759, 1760, 1762, 1763, 1764, 1765, 1768, 1772, 1775, 1776, 1777, 1781, 1782, 1784, 1788, 1789, 1790, 1791, 1793, 1794, 1795, 1800, 1804], "affect": [1, 2, 3, 8, 10, 17, 19, 30, 53, 198, 199, 699, 762, 812, 814, 909, 956, 977, 1005, 1030, 1220, 1250, 1265, 1302, 1415, 1468, 1628, 1631, 1632, 1634, 1758, 1759, 1762, 1767, 1770, 1773, 1774, 1795], "dataparallel": [1, 23, 1411, 1423, 1461, 1736, 1759, 1766, 1772, 1789], "parallel": [1, 13, 14, 20, 21, 23, 24, 27, 33, 48, 49, 53, 980, 981, 1033, 1187, 1256, 1289, 1347, 1423, 1635, 1636, 1736, 1741, 1758, 1759, 1761, 1772, 1776, 1789, 1791], "distributeddataparallel": [1, 20, 21, 23, 24, 27, 49, 53, 1187, 1289, 1772, 1782, 1789], "than": [1, 4, 5, 6, 7, 9, 10, 12, 14, 20, 21, 23, 24, 29, 30, 33, 34, 38, 39, 41, 45, 48, 49, 50, 53, 57, 60, 127, 230, 471, 516, 589, 609, 615, 693, 699, 740, 749, 750, 759, 766, 777, 784, 785, 789, 790, 814, 822, 860, 864, 876, 893, 894, 945, 946, 947, 949, 953, 958, 974, 986, 990, 1004, 1015, 1027, 1028, 1031, 1041, 1050, 1051, 1054, 1059, 1060, 1066, 1070, 1075, 1083, 1084, 1086, 1087, 1090, 1095, 1105, 1118, 1121, 1127, 1130, 1132, 1135, 1140, 1150, 1166, 1167, 1178, 1179, 1180, 1187, 1193, 1194, 1211, 1242, 1256, 1264, 1281, 1287, 1297, 1298, 1299, 1312, 1322, 1323, 1324, 1338, 1339, 1347, 1358, 1384, 1414, 1415, 1418, 1423, 1432, 1433, 1434, 1435, 1461, 1464, 1470, 1480, 1505, 1507, 1521, 1522, 1608, 1609, 1637, 1669, 1670, 1671, 1672, 1674, 1675, 1703, 1711, 1713, 1721, 1735, 1737, 1738, 1740, 1741, 1743, 1753, 1754, 1755, 1757, 1759, 1760, 1762, 1764, 1765, 1766, 1767, 1770, 1772, 1773, 1774, 1775, 1777, 1781, 1782, 1784, 1785, 1789, 1793, 1794, 1796, 1798, 1799, 1800], "one": [1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 14, 15, 17, 20, 21, 23, 24, 27, 29, 31, 33, 34, 35, 36, 38, 39, 41, 45, 48, 50, 51, 53, 57, 58, 59, 60, 127, 198, 230, 328, 459, 485, 492, 516, 531, 613, 662, 671, 710, 711, 712, 728, 734, 740, 741, 742, 744, 750, 766, 777, 779, 789, 793, 812, 814, 819, 820, 824, 851, 873, 883, 894, 905, 909, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 935, 936, 937, 938, 939, 941, 944, 948, 951, 952, 953, 962, 963, 964, 965, 966, 967, 968, 970, 971, 983, 992, 993, 1005, 1009, 1012, 1015, 1034, 1039, 1043, 1049, 1050, 1060, 1061, 1071, 1072, 1073, 1074, 1075, 1077, 1082, 1086, 1088, 1090, 1093, 1099, 1100, 1116, 1124, 1128, 1133, 1140, 1146, 1158, 1163, 1166, 1167, 1168, 1169, 1170, 1173, 1178, 1181, 1182, 1183, 1194, 1198, 1199, 1204, 1213, 1214, 1215, 1217, 1218, 1219, 1229, 1230, 1231, 1241, 1250, 1254, 1256, 1289, 1297, 1302, 1312, 1322, 1325, 1326, 1327, 1342, 1343, 1344, 1349, 1384, 1414, 1418, 1423, 1424, 1431, 1433, 1434, 1438, 1448, 1459, 1466, 1467, 1468, 1469, 1470, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1501, 1503, 1504, 1505, 1590, 1591, 1608, 1624, 1632, 1634, 1637, 1640, 1679, 1688, 1701, 1706, 1707, 1709, 1717, 1720, 1721, 1728, 1736, 1738, 1741, 1745, 1748, 1750, 1751, 1752, 1753, 1754, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1767, 1769, 1770, 1772, 1774, 1776, 1777, 1780, 1781, 1782, 1784, 1785, 1789, 1791, 1793, 1794, 1795, 1796, 1798, 1799, 1800], "gpu": [1, 2, 3, 4, 5, 8, 14, 16, 18, 20, 21, 33, 34, 36, 38, 39, 49, 50, 53, 59, 173, 186, 265, 308, 575, 674, 816, 817, 820, 821, 822, 823, 824, 830, 831, 832, 839, 845, 846, 852, 854, 855, 856, 858, 859, 860, 862, 863, 864, 865, 870, 871, 872, 873, 874, 877, 883, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 953, 1030, 1039, 1076, 1101, 1130, 1158, 1187, 1202, 1220, 1250, 1265, 1266, 1289, 1411, 1423, 1458, 1688, 1736, 1738, 1748, 1762, 1768, 1770, 1771, 1773, 1774, 1776, 1784, 1789, 1793, 1795, 1799, 1801], "per": [1, 14, 20, 21, 23, 24, 27, 30, 39, 41, 49, 50, 53, 54, 58, 445, 446, 447, 748, 750, 815, 888, 919, 963, 971, 1102, 1166, 1167, 1168, 1169, 1170, 1184, 1186, 1187, 1194, 1205, 1210, 1213, 1214, 1215, 1216, 1217, 1222, 1241, 1242, 1250, 1253, 1254, 1255, 1256, 1257, 1264, 1281, 1282, 1289, 1293, 1294, 1295, 1296, 1297, 1298, 1319, 1320, 1330, 1359, 1382, 1390, 1423, 1427, 1428, 1467, 1471, 1483, 1499, 1505, 1513, 1533, 1547, 1550, 1553, 1590, 1637, 1639, 1689, 1703, 1707, 1728, 1750, 1753, 1755, 1761, 1762, 1763, 1765, 1769, 1782, 1784, 1785, 1787, 1790, 1793, 1798, 1803], "work": [1, 2, 3, 4, 6, 8, 9, 10, 12, 14, 15, 16, 23, 24, 27, 29, 30, 31, 33, 34, 35, 38, 39, 48, 49, 50, 51, 53, 54, 57, 60, 96, 127, 328, 418, 419, 420, 421, 422, 459, 559, 560, 740, 754, 809, 811, 812, 814, 842, 853, 854, 873, 906, 908, 925, 945, 946, 947, 962, 1030, 1034, 1041, 1042, 1065, 1066, 1093, 1094, 1102, 1187, 1247, 1250, 1266, 1283, 1385, 1402, 1423, 1505, 1549, 1586, 1587, 1597, 1601, 1603, 1629, 1635, 1697, 1700, 1735, 1738, 1741, 1742, 1751, 1752, 1753, 1754, 1757, 1759, 1761, 1762, 1763, 1764, 1765, 1767, 1768, 1770, 1772, 1775, 1776, 1777, 1781, 1782, 1784, 1787, 1789, 1790, 1799, 1801, 1804], "str": [1, 2, 3, 4, 14, 20, 21, 23, 27, 29, 33, 35, 38, 39, 42, 46, 48, 50, 53, 60, 297, 485, 489, 575, 693, 699, 702, 703, 704, 706, 707, 708, 710, 748, 750, 757, 758, 783, 795, 810, 820, 821, 822, 824, 833, 834, 836, 837, 838, 850, 851, 852, 864, 865, 867, 869, 880, 900, 905, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 961, 962, 966, 969, 971, 979, 1028, 1029, 1030, 1031, 1033, 1034, 1036, 1039, 1075, 1088, 1093, 1094, 1101, 1102, 1131, 1147, 1166, 1167, 1173, 1178, 1179, 1180, 1184, 1186, 1194, 1200, 1204, 1210, 1211, 1216, 1217, 1226, 1227, 1228, 1241, 1242, 1250, 1251, 1253, 1254, 1255, 1257, 1260, 1264, 1267, 1278, 1281, 1282, 1293, 1295, 1297, 1298, 1299, 1300, 1302, 1319, 1320, 1330, 1331, 1339, 1344, 1347, 1358, 1359, 1382, 1390, 1415, 1432, 1433, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1449, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1464, 1465, 1467, 1483, 1499, 1505, 1507, 1524, 1620, 1624, 1631, 1632, 1684, 1728, 1735, 1737, 1738, 1739, 1740, 1741, 1742, 1748, 1749, 1750, 1751, 1753, 1757, 1759, 1777, 1778, 1779, 1781, 1782, 1783, 1789, 1795, 1798, 1800, 1802, 1803, 1804], "whether": [1, 2, 3, 8, 14, 20, 21, 23, 24, 29, 33, 35, 38, 39, 47, 48, 53, 60, 295, 297, 444, 489, 589, 609, 611, 612, 615, 722, 723, 728, 737, 744, 747, 748, 750, 755, 756, 762, 764, 773, 786, 787, 788, 794, 795, 796, 849, 865, 971, 987, 988, 1005, 1027, 1030, 1038, 1046, 1051, 1059, 1060, 1066, 1068, 1071, 1072, 1073, 1074, 1076, 1077, 1078, 1079, 1084, 1086, 1087, 1090, 1091, 1092, 1093, 1101, 1117, 1119, 1127, 1129, 1130, 1132, 1135, 1140, 1145, 1146, 1147, 1148, 1173, 1184, 1210, 1216, 1250, 1259, 1264, 1299, 1309, 1310, 1311, 1331, 1359, 1390, 1423, 1432, 1434, 1437, 1450, 1470, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493, 1499, 1511, 1521, 1524, 1633, 1634, 1682, 1683, 1684, 1687, 1688, 1694, 1704, 1709, 1718, 1719, 1721, 1723, 1724, 1728, 1735, 1741, 1747, 1749, 1754, 1758, 1759, 1762, 1764, 1768, 1777, 1778, 1782, 1784, 1789, 1793, 1795, 1797, 1798, 1803], "bool": [1, 2, 3, 4, 6, 14, 20, 21, 23, 24, 27, 29, 39, 42, 48, 50, 53, 59, 60, 127, 173, 186, 221, 236, 295, 297, 304, 305, 306, 307, 309, 310, 315, 317, 418, 419, 420, 421, 422, 431, 444, 468, 489, 575, 609, 610, 611, 612, 613, 615, 672, 693, 694, 699, 704, 713, 722, 723, 724, 728, 740, 748, 749, 750, 751, 752, 753, 754, 755, 756, 762, 764, 767, 769, 770, 772, 773, 779, 780, 786, 787, 788, 794, 795, 811, 818, 847, 853, 865, 906, 907, 908, 911, 918, 923, 941, 957, 958, 959, 960, 963, 964, 966, 967, 968, 970, 972, 987, 988, 991, 992, 1005, 1015, 1019, 1021, 1027, 1030, 1034, 1036, 1045, 1046, 1049, 1051, 1059, 1060, 1071, 1072, 1073, 1074, 1076, 1077, 1078, 1079, 1082, 1084, 1086, 1087, 1090, 1091, 1092, 1093, 1099, 1100, 1101, 1102, 1111, 1112, 1113, 1114, 1116, 1117, 1119, 1121, 1127, 1129, 1130, 1132, 1135, 1140, 1145, 1146, 1147, 1148, 1149, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1198, 1199, 1203, 1204, 1205, 1207, 1208, 1209, 1210, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1236, 1237, 1241, 1242, 1243, 1244, 1245, 1250, 1253, 1254, 1255, 1256, 1257, 1259, 1264, 1267, 1268, 1269, 1270, 1277, 1281, 1282, 1289, 1292, 1293, 1295, 1296, 1297, 1298, 1299, 1302, 1312, 1319, 1320, 1330, 1331, 1332, 1333, 1334, 1335, 1338, 1339, 1340, 1344, 1347, 1349, 1351, 1358, 1359, 1382, 1390, 1415, 1423, 1424, 1428, 1429, 1432, 1434, 1436, 1437, 1438, 1459, 1460, 1461, 1462, 1470, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1511, 1513, 1519, 1521, 1523, 1524, 1546, 1593, 1594, 1595, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1624, 1629, 1633, 1634, 1639, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1662, 1670, 1671, 1672, 1673, 1674, 1675, 1682, 1683, 1684, 1687, 1688, 1694, 1700, 1704, 1709, 1718, 1719, 1721, 1722, 1723, 1724, 1733, 1734, 1735, 1737, 1738, 1739, 1740, 1741, 1749, 1750, 1751, 1752, 1753, 1754, 1768, 1775, 1777, 1778, 1779, 1781, 1782, 1783, 1788, 1789, 1795, 1796, 1798, 1799, 1800, 1803, 1804], "option": [1, 2, 4, 6, 14, 20, 23, 27, 29, 32, 33, 34, 35, 38, 39, 42, 46, 47, 48, 50, 51, 53, 60, 65, 127, 132, 147, 149, 152, 155, 156, 157, 172, 183, 186, 216, 243, 273, 301, 307, 368, 418, 419, 420, 421, 422, 460, 471, 472, 485, 492, 496, 508, 531, 552, 555, 597, 599, 600, 601, 602, 603, 604, 605, 606, 607, 609, 610, 611, 612, 613, 614, 615, 672, 693, 694, 699, 702, 704, 709, 710, 713, 724, 726, 727, 728, 729, 730, 731, 732, 733, 740, 748, 749, 750, 751, 752, 753, 754, 755, 756, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 775, 779, 782, 784, 785, 786, 787, 788, 790, 792, 793, 794, 801, 802, 804, 805, 806, 807, 808, 809, 811, 812, 814, 816, 820, 822, 823, 824, 827, 828, 835, 836, 839, 842, 850, 851, 852, 856, 858, 859, 860, 862, 864, 865, 866, 870, 871, 872, 876, 877, 882, 883, 884, 885, 886, 887, 889, 892, 893, 894, 895, 896, 897, 899, 900, 902, 904, 905, 906, 907, 908, 910, 915, 918, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 948, 949, 950, 951, 952, 953, 955, 958, 959, 960, 962, 965, 966, 967, 972, 973, 974, 975, 983, 986, 987, 988, 989, 990, 991, 994, 995, 996, 1004, 1007, 1019, 1021, 1024, 1025, 1027, 1028, 1030, 1031, 1034, 1036, 1043, 1045, 1046, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1058, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1111, 1112, 1113, 1114, 1116, 1117, 1118, 1119, 1120, 1121, 1123, 1124, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1138, 1139, 1140, 1142, 1144, 1145, 1146, 1147, 1148, 1150, 1151, 1152, 1154, 1156, 1157, 1158, 1160, 1161, 1162, 1164, 1165, 1166, 1167, 1172, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1197, 1198, 1199, 1200, 1204, 1207, 1208, 1209, 1210, 1211, 1216, 1217, 1222, 1226, 1227, 1228, 1229, 1230, 1231, 1236, 1241, 1242, 1246, 1247, 1248, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1259, 1260, 1261, 1264, 1268, 1269, 1270, 1277, 1281, 1282, 1289, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1301, 1302, 1303, 1304, 1312, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1329, 1330, 1331, 1338, 1339, 1342, 1343, 1344, 1347, 1349, 1358, 1359, 1366, 1371, 1372, 1373, 1382, 1383, 1390, 1402, 1403, 1415, 1422, 1423, 1424, 1428, 1432, 1433, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1464, 1467, 1469, 1470, 1471, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1488, 1490, 1491, 1492, 1493, 1494, 1498, 1511, 1512, 1513, 1516, 1520, 1521, 1523, 1524, 1531, 1584, 1587, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1607, 1608, 1609, 1610, 1617, 1619, 1624, 1637, 1640, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1657, 1658, 1662, 1663, 1664, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1687, 1688, 1689, 1694, 1697, 1698, 1699, 1700, 1701, 1704, 1706, 1709, 1710, 1711, 1712, 1713, 1715, 1718, 1719, 1721, 1722, 1723, 1724, 1725, 1730, 1731, 1733, 1734, 1735, 1738, 1739, 1741, 1743, 1745, 1748, 1749, 1750, 1754, 1757, 1762, 1764, 1765, 1766, 1769, 1770, 1774, 1778, 1781, 1783, 1784, 1789, 1793, 1794, 1796, 1798, 1800, 1803], "torch_dtyp": 1, "weight": [1, 20, 23, 29, 33, 53, 58, 60, 133, 277, 336, 337, 468, 628, 629, 630, 631, 632, 633, 634, 635, 636, 646, 647, 648, 649, 652, 653, 654, 655, 656, 657, 659, 660, 663, 665, 666, 667, 668, 670, 674, 675, 677, 678, 679, 686, 687, 688, 695, 702, 703, 704, 766, 807, 961, 963, 969, 971, 991, 992, 1030, 1034, 1039, 1041, 1046, 1055, 1140, 1166, 1167, 1171, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1193, 1194, 1202, 1203, 1205, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1237, 1250, 1254, 1255, 1256, 1257, 1258, 1265, 1267, 1279, 1293, 1317, 1318, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1330, 1338, 1339, 1348, 1357, 1361, 1364, 1379, 1381, 1382, 1391, 1399, 1418, 1423, 1427, 1428, 1432, 1433, 1435, 1437, 1448, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1463, 1464, 1467, 1477, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1493, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1583, 1584, 1586, 1587, 1592, 1728, 1735, 1736, 1737, 1739, 1740, 1741, 1748, 1753, 1754, 1757, 1764, 1766, 1770, 1775, 1784, 1785, 1786, 1787, 1793, 1798, 1802, 1803], "insid": [1, 2, 8, 20, 35, 48, 53, 57, 59, 60, 744, 745, 746, 747, 817, 853, 963, 967, 970, 1041, 1423, 1738, 1740, 1741, 1748, 1758, 1762, 1764, 1765, 1769, 1777, 1802], "custom_fwd": [1, 1758], "fwd": 1, "cast_input": [1, 1758], "helper": [1, 4, 6, 23, 60, 1289, 1735, 1736, 1740, 1762, 1763, 1777, 1781, 1789, 1804], "subclass": [1, 2, 14, 20, 29, 32, 35, 41, 57, 60, 116, 508, 737, 738, 739, 1028, 1031, 1040, 1250, 1424, 1439, 1444, 1463, 1738, 1741, 1742, 1747, 1758, 1770, 1777, 1778, 1789, 1804], "page": [1, 7, 8, 10, 20, 24, 49, 51, 1102, 1293, 1295, 1297, 1762, 1763, 1770, 1779, 1789], "incom": [1, 23, 50, 695, 1171, 1237, 1318, 1364, 1547, 1548, 1549, 1550, 1553, 1751, 1759], "non": [1, 2, 4, 6, 14, 19, 21, 23, 24, 29, 33, 34, 39, 41, 48, 50, 51, 53, 59, 65, 127, 311, 476, 485, 489, 516, 614, 653, 654, 655, 656, 657, 659, 660, 670, 674, 678, 679, 686, 687, 688, 713, 725, 737, 739, 740, 745, 747, 755, 756, 766, 779, 782, 800, 801, 806, 864, 951, 952, 958, 962, 967, 971, 1007, 1030, 1033, 1042, 1045, 1046, 1065, 1066, 1073, 1077, 1078, 1091, 1093, 1102, 1112, 1119, 1124, 1129, 1140, 1145, 1146, 1150, 1163, 1164, 1165, 1179, 1180, 1182, 1183, 1186, 1196, 1202, 1219, 1220, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1253, 1255, 1256, 1257, 1265, 1267, 1281, 1293, 1330, 1349, 1377, 1382, 1422, 1423, 1427, 1428, 1469, 1516, 1566, 1624, 1625, 1640, 1652, 1666, 1670, 1671, 1672, 1673, 1674, 1675, 1702, 1718, 1728, 1735, 1736, 1738, 1740, 1741, 1743, 1751, 1754, 1757, 1760, 1764, 1765, 1766, 1770, 1774, 1777, 1782, 1783, 1788, 1789, 1791, 1793, 1794, 1796, 1797, 1798, 1800, 1804], "intern": [1, 4, 9, 10, 14, 20, 21, 23, 29, 33, 35, 38, 39, 45, 57, 60, 809, 842, 863, 962, 1030, 1066, 1068, 1084, 1087, 1110, 1168, 1169, 1170, 1204, 1289, 1322, 1323, 1324, 1347, 1434, 1476, 1632, 1673, 1721, 1742, 1758, 1759, 1761, 1762, 1767, 1773, 1774, 1790, 1791, 1795, 1797], "current": [1, 2, 3, 4, 6, 7, 8, 10, 12, 14, 20, 23, 27, 29, 33, 35, 38, 39, 41, 48, 49, 53, 54, 59, 60, 65, 127, 186, 198, 459, 469, 470, 471, 655, 657, 695, 703, 708, 713, 738, 740, 741, 748, 749, 750, 755, 764, 773, 795, 809, 810, 811, 812, 814, 819, 822, 823, 825, 826, 827, 828, 831, 832, 833, 835, 836, 839, 841, 842, 845, 847, 848, 852, 853, 854, 856, 858, 859, 860, 862, 864, 865, 866, 870, 871, 872, 873, 875, 877, 879, 882, 883, 906, 908, 918, 923, 941, 957, 959, 977, 978, 979, 987, 988, 1013, 1014, 1030, 1034, 1045, 1049, 1100, 1102, 1116, 1131, 1190, 1193, 1197, 1250, 1289, 1301, 1341, 1347, 1358, 1414, 1415, 1417, 1423, 1438, 1442, 1443, 1444, 1445, 1446, 1451, 1452, 1453, 1454, 1474, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1487, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1523, 1584, 1586, 1587, 1597, 1599, 1601, 1603, 1604, 1628, 1632, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1670, 1671, 1672, 1673, 1674, 1675, 1711, 1713, 1718, 1733, 1736, 1738, 1740, 1741, 1742, 1743, 1745, 1747, 1750, 1751, 1754, 1758, 1759, 1762, 1763, 1768, 1769, 1770, 1771, 1775, 1776, 1777, 1778, 1780, 1781, 1782, 1784, 1787, 1789, 1790, 1793, 1795, 1796, 1798, 1799, 1802, 1804], "outsid": [1, 6, 10, 20, 41, 53, 57, 600, 733, 961, 963, 967, 970, 1031, 1347, 1423, 1496, 1497, 1502, 1503, 1509, 1740, 1741, 1757, 1759, 1762, 1765, 1766, 1800], "ha": [1, 2, 6, 7, 8, 9, 10, 12, 14, 15, 16, 18, 20, 21, 23, 24, 27, 29, 30, 32, 33, 34, 35, 37, 38, 39, 41, 45, 47, 48, 49, 50, 51, 53, 54, 56, 57, 58, 59, 60, 65, 127, 173, 186, 231, 236, 311, 418, 419, 420, 421, 422, 446, 447, 468, 470, 515, 552, 575, 576, 590, 605, 609, 611, 612, 613, 615, 674, 693, 695, 699, 701, 722, 723, 725, 737, 740, 742, 744, 750, 755, 756, 765, 783, 786, 787, 800, 801, 802, 808, 811, 812, 814, 819, 846, 849, 850, 893, 895, 909, 941, 953, 961, 962, 965, 966, 971, 983, 992, 993, 1004, 1027, 1030, 1034, 1037, 1040, 1041, 1042, 1045, 1050, 1051, 1059, 1060, 1061, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1079, 1081, 1083, 1084, 1087, 1088, 1089, 1090, 1092, 1093, 1094, 1096, 1097, 1101, 1110, 1117, 1119, 1124, 1127, 1129, 1130, 1131, 1132, 1134, 1135, 1145, 1146, 1147, 1148, 1166, 1167, 1168, 1169, 1170, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1187, 1188, 1194, 1197, 1198, 1199, 1202, 1205, 1210, 1213, 1214, 1215, 1220, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1242, 1243, 1244, 1245, 1250, 1254, 1255, 1256, 1257, 1258, 1265, 1281, 1283, 1289, 1297, 1301, 1302, 1312, 1322, 1323, 1324, 1330, 1339, 1342, 1343, 1347, 1358, 1382, 1384, 1385, 1387, 1391, 1402, 1415, 1417, 1418, 1420, 1421, 1423, 1428, 1432, 1434, 1436, 1439, 1443, 1445, 1448, 1458, 1459, 1464, 1465, 1469, 1471, 1477, 1497, 1498, 1499, 1501, 1505, 1507, 1511, 1521, 1523, 1524, 1528, 1529, 1566, 1568, 1583, 1589, 1590, 1591, 1608, 1610, 1620, 1632, 1654, 1666, 1667, 1668, 1679, 1681, 1682, 1683, 1684, 1687, 1688, 1694, 1703, 1709, 1723, 1724, 1728, 1738, 1740, 1741, 1747, 1750, 1751, 1752, 1753, 1754, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1768, 1769, 1770, 1772, 1773, 1775, 1776, 1777, 1780, 1781, 1782, 1783, 1784, 1785, 1788, 1789, 1790, 1791, 1793, 1795, 1796, 1798, 1799, 1800, 1801], "effect": [1, 4, 8, 14, 20, 21, 23, 29, 50, 57, 60, 173, 186, 575, 693, 699, 842, 888, 971, 1030, 1072, 1073, 1074, 1075, 1131, 1158, 1173, 1181, 1182, 1183, 1188, 1189, 1190, 1191, 1195, 1250, 1256, 1302, 1358, 1385, 1415, 1420, 1423, 1424, 1428, 1444, 1491, 1499, 1668, 1688, 1707, 1728, 1735, 1738, 1748, 1757, 1758, 1759, 1762, 1764, 1784, 1787, 1795, 1796, 1798], "custom_bwd": [1, 1758], "bwd": 1, "valu": [1, 2, 3, 4, 6, 8, 9, 10, 12, 14, 17, 20, 21, 24, 27, 29, 32, 33, 35, 38, 39, 40, 42, 45, 46, 48, 49, 53, 55, 57, 59, 60, 65, 78, 79, 80, 81, 96, 127, 131, 198, 211, 212, 213, 214, 230, 235, 236, 248, 249, 275, 287, 289, 291, 292, 293, 294, 295, 297, 299, 302, 328, 374, 375, 393, 394, 396, 397, 444, 454, 456, 485, 487, 489, 508, 515, 531, 555, 571, 572, 597, 600, 603, 604, 607, 611, 612, 613, 670, 678, 684, 685, 693, 698, 699, 701, 703, 705, 710, 713, 722, 723, 724, 728, 733, 737, 739, 740, 742, 743, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 764, 765, 766, 773, 779, 783, 788, 790, 802, 803, 806, 812, 841, 850, 851, 864, 876, 884, 885, 888, 896, 897, 910, 919, 920, 922, 924, 926, 927, 928, 933, 935, 936, 937, 938, 939, 948, 953, 959, 961, 962, 963, 964, 968, 969, 970, 972, 974, 978, 979, 983, 986, 987, 988, 989, 990, 991, 992, 1000, 1015, 1020, 1021, 1022, 1023, 1026, 1027, 1028, 1030, 1031, 1033, 1036, 1037, 1045, 1048, 1050, 1051, 1054, 1058, 1059, 1061, 1063, 1065, 1066, 1067, 1068, 1069, 1072, 1073, 1074, 1075, 1079, 1082, 1084, 1086, 1087, 1089, 1093, 1094, 1099, 1100, 1101, 1102, 1105, 1110, 1116, 1118, 1119, 1122, 1127, 1129, 1130, 1132, 1135, 1138, 1140, 1144, 1145, 1146, 1147, 1150, 1151, 1154, 1158, 1163, 1164, 1165, 1166, 1168, 1169, 1170, 1171, 1172, 1173, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1192, 1193, 1194, 1195, 1197, 1204, 1205, 1206, 1209, 1210, 1211, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1235, 1237, 1240, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1251, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1264, 1278, 1281, 1283, 1284, 1285, 1286, 1287, 1289, 1292, 1293, 1295, 1297, 1298, 1299, 1301, 1302, 1319, 1320, 1322, 1323, 1324, 1329, 1330, 1339, 1340, 1344, 1347, 1349, 1358, 1359, 1360, 1371, 1372, 1373, 1382, 1383, 1384, 1385, 1387, 1390, 1409, 1410, 1415, 1417, 1418, 1421, 1423, 1428, 1430, 1432, 1433, 1434, 1435, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1451, 1452, 1458, 1461, 1462, 1463, 1465, 1469, 1470, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1499, 1505, 1513, 1517, 1520, 1524, 1531, 1534, 1547, 1548, 1549, 1550, 1553, 1554, 1555, 1584, 1591, 1592, 1604, 1606, 1608, 1609, 1610, 1615, 1616, 1617, 1624, 1627, 1637, 1640, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1658, 1662, 1665, 1666, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1684, 1688, 1689, 1697, 1701, 1704, 1707, 1710, 1711, 1712, 1713, 1715, 1718, 1719, 1720, 1731, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1742, 1747, 1749, 1750, 1751, 1754, 1757, 1758, 1759, 1761, 1762, 1764, 1765, 1766, 1767, 1768, 1770, 1774, 1775, 1777, 1779, 1780, 1781, 1783, 1784, 1787, 1788, 1789, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1803], "small": [1, 4, 8, 10, 20, 21, 23, 29, 38, 48, 713, 755, 756, 821, 864, 1092, 1093, 1105, 1107, 1158, 1185, 1259, 1264, 1278, 1302, 1329, 1383, 1390, 1423, 1496, 1502, 1511, 1688, 1738, 1740, 1741, 1762, 1764, 1766, 1770, 1773, 1775, 1777, 1781, 1784, 1785, 1794, 1800], "magnitud": [1, 802, 1467, 1640, 1757, 1758, 1762], "represent": [1, 4, 14, 20, 23, 33, 38, 46, 60, 454, 672, 812, 921, 922, 924, 948, 975, 1030, 1069, 1072, 1074, 1077, 1144, 1250, 1256, 1511, 1554, 1736, 1738, 1741, 1754, 1764, 1773, 1777, 1781, 1784, 1793, 1800, 1805], "These": [1, 3, 4, 9, 14, 15, 20, 23, 24, 29, 33, 35, 38, 54, 56, 58, 60, 728, 807, 905, 1027, 1030, 1072, 1137, 1158, 1250, 1418, 1433, 1736, 1738, 1739, 1740, 1741, 1750, 1752, 1753, 1755, 1758, 1759, 1762, 1763, 1764, 1770, 1773, 1775, 1777, 1781, 1787, 1789, 1790, 1796, 1801, 1804], "flush": [1, 2, 864, 1040, 1620, 1633, 1773, 1798], "zero": [1, 2, 3, 21, 23, 24, 27, 29, 34, 50, 53, 57, 60, 127, 236, 291, 485, 487, 515, 516, 595, 607, 614, 628, 629, 630, 631, 632, 633, 634, 635, 641, 642, 643, 646, 647, 652, 653, 654, 655, 656, 657, 658, 663, 664, 665, 666, 667, 668, 669, 670, 673, 674, 678, 682, 683, 686, 687, 688, 689, 691, 694, 695, 725, 734, 735, 736, 740, 745, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 765, 766, 786, 787, 788, 793, 802, 806, 853, 864, 868, 869, 896, 900, 918, 919, 920, 921, 922, 924, 925, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 944, 953, 958, 961, 989, 990, 993, 1015, 1027, 1030, 1041, 1059, 1060, 1061, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1075, 1076, 1077, 1078, 1079, 1081, 1082, 1083, 1084, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1097, 1102, 1110, 1111, 1112, 1113, 1114, 1119, 1120, 1140, 1144, 1148, 1162, 1163, 1164, 1165, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1185, 1188, 1189, 1190, 1191, 1193, 1194, 1195, 1197, 1202, 1203, 1205, 1218, 1219, 1220, 1221, 1222, 1226, 1227, 1228, 1229, 1230, 1231, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1256, 1259, 1262, 1263, 1264, 1265, 1267, 1287, 1293, 1301, 1302, 1305, 1314, 1315, 1316, 1325, 1326, 1327, 1329, 1331, 1332, 1333, 1334, 1335, 1339, 1340, 1347, 1368, 1369, 1383, 1384, 1385, 1428, 1442, 1443, 1444, 1445, 1460, 1465, 1469, 1473, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1511, 1523, 1531, 1547, 1548, 1549, 1550, 1553, 1590, 1591, 1592, 1608, 1617, 1627, 1654, 1658, 1666, 1670, 1671, 1672, 1673, 1674, 1675, 1679, 1688, 1694, 1700, 1701, 1703, 1709, 1734, 1738, 1739, 1741, 1743, 1750, 1751, 1752, 1753, 1757, 1759, 1762, 1764, 1770, 1773, 1776, 1777, 1779, 1781, 1783, 1784, 1787, 1793, 1794, 1796, 1798, 1799, 1800, 1801], "underflow": [1, 1216, 1758], "updat": [1, 10, 12, 20, 21, 27, 39, 48, 53, 56, 60, 198, 485, 487, 674, 1030, 1168, 1169, 1170, 1187, 1193, 1194, 1202, 1213, 1214, 1215, 1250, 1251, 1260, 1289, 1338, 1339, 1433, 1437, 1477, 1483, 1488, 1490, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1509, 1531, 1532, 1552, 1735, 1738, 1748, 1758, 1759, 1762, 1763, 1764, 1770, 1772, 1775, 1776, 1777, 1779, 1780, 1782, 1784, 1789, 1790, 1791, 1798], "lost": [1, 39, 49, 51, 1187, 1246, 1247, 1248], "To": [1, 2, 3, 4, 5, 6, 7, 10, 14, 15, 20, 21, 23, 24, 27, 29, 33, 35, 37, 38, 39, 40, 46, 47, 49, 50, 53, 57, 60, 311, 471, 528, 741, 754, 792, 810, 854, 873, 893, 895, 905, 933, 935, 939, 950, 1030, 1031, 1033, 1034, 1040, 1041, 1075, 1097, 1102, 1130, 1158, 1190, 1216, 1246, 1247, 1248, 1250, 1303, 1304, 1423, 1427, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1467, 1505, 1513, 1524, 1628, 1636, 1689, 1694, 1735, 1738, 1740, 1741, 1745, 1751, 1752, 1753, 1755, 1758, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1770, 1771, 1775, 1777, 1780, 1781, 1782, 1783, 1784, 1789, 1790, 1791, 1793, 1796, 1797, 1798, 1799], "prevent": [1, 8, 9, 20, 21, 23, 24, 35, 39, 53, 60, 746, 811, 886, 887, 1027, 1129, 1145, 1148, 1188, 1256, 1281, 1366, 1402, 1403, 1418, 1423, 1428, 1521, 1664, 1667, 1687, 1711, 1713, 1721, 1751, 1758, 1759, 1762, 1763, 1766, 1770, 1781, 1783, 1791, 1793, 1794], "multipli": [1, 23, 33, 289, 297, 397, 485, 601, 602, 603, 604, 605, 606, 607, 674, 693, 699, 700, 701, 763, 775, 876, 888, 905, 983, 994, 1053, 1065, 1066, 1070, 1083, 1085, 1087, 1093, 1095, 1124, 1134, 1139, 1142, 1166, 1178, 1179, 1180, 1183, 1202, 1220, 1302, 1303, 1304, 1358, 1415, 1416, 1417, 1437, 1496, 1502, 1504, 1511, 1660, 1663, 1665, 1666, 1680, 1684, 1685, 1688, 1707, 1739, 1752, 1762, 1767, 1770, 1773, 1779, 1793, 1794], "factor": [1, 4, 21, 29, 33, 60, 605, 606, 607, 763, 786, 787, 788, 1072, 1073, 1074, 1077, 1079, 1119, 1120, 1121, 1188, 1211, 1238, 1262, 1263, 1388, 1389, 1491, 1492, 1493, 1495, 1496, 1498, 1500, 1501, 1502, 1503, 1504, 1507, 1508, 1509, 1523, 1531, 1547, 1646, 1666, 1688, 1757, 1758, 1784], "flow": [1, 31, 34, 35, 792, 1042, 1045, 1312, 1347, 1423, 1738, 1757, 1759, 1762, 1764, 1775, 1777, 1791], "through": [1, 6, 8, 10, 15, 20, 23, 29, 33, 35, 36, 37, 38, 41, 57, 59, 60, 468, 702, 710, 746, 755, 756, 816, 853, 932, 965, 971, 1028, 1031, 1033, 1045, 1046, 1048, 1065, 1066, 1087, 1093, 1110, 1257, 1294, 1295, 1296, 1297, 1349, 1418, 1423, 1437, 1523, 1568, 1586, 1587, 1694, 1728, 1735, 1736, 1740, 1741, 1745, 1750, 1751, 1752, 1753, 1759, 1762, 1764, 1766, 1767, 1769, 1770, 1776, 1777, 1781, 1782, 1784, 1787, 1789, 1790, 1791, 1793, 1797, 1801, 1803, 1805], "word": [1, 2, 9, 23, 48, 49, 56, 59, 60, 779, 1158, 1178, 1179, 1180, 1193, 1194, 1293, 1338, 1339, 1358, 1415, 1423, 1432, 1624, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1740, 1759, 1766, 1781, 1790], "have": [1, 2, 4, 6, 7, 8, 9, 10, 12, 14, 20, 23, 24, 27, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 45, 46, 47, 48, 49, 50, 51, 53, 54, 56, 57, 60, 65, 130, 131, 198, 199, 289, 291, 297, 311, 373, 377, 421, 431, 444, 459, 460, 475, 485, 487, 489, 492, 515, 589, 605, 609, 611, 612, 613, 615, 706, 708, 728, 737, 740, 748, 750, 764, 765, 773, 782, 783, 807, 814, 822, 823, 853, 864, 896, 904, 911, 925, 935, 940, 942, 956, 961, 962, 971, 972, 973, 987, 988, 991, 992, 1004, 1005, 1027, 1029, 1030, 1033, 1034, 1037, 1039, 1041, 1042, 1043, 1044, 1045, 1046, 1051, 1052, 1061, 1065, 1066, 1082, 1089, 1090, 1093, 1095, 1101, 1110, 1112, 1117, 1124, 1127, 1129, 1130, 1131, 1132, 1134, 1135, 1140, 1145, 1146, 1148, 1150, 1158, 1162, 1166, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1187, 1193, 1194, 1198, 1199, 1204, 1209, 1213, 1214, 1215, 1242, 1250, 1253, 1254, 1255, 1256, 1257, 1297, 1299, 1329, 1338, 1339, 1342, 1343, 1347, 1364, 1382, 1384, 1387, 1420, 1421, 1422, 1423, 1424, 1429, 1430, 1432, 1434, 1437, 1461, 1463, 1468, 1470, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1521, 1569, 1612, 1613, 1627, 1640, 1663, 1665, 1669, 1670, 1671, 1672, 1674, 1675, 1682, 1683, 1684, 1687, 1688, 1694, 1697, 1701, 1707, 1709, 1721, 1723, 1724, 1726, 1728, 1730, 1735, 1738, 1739, 1740, 1741, 1743, 1745, 1747, 1748, 1750, 1751, 1752, 1753, 1754, 1757, 1758, 1759, 1760, 1762, 1763, 1764, 1765, 1766, 1767, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1780, 1781, 1782, 1784, 1785, 1788, 1789, 1790, 1791, 1793, 1795, 1796, 1797, 1798, 1799, 1800, 1804], "larger": [1, 10, 23, 29, 35, 60, 230, 471, 756, 766, 864, 962, 1084, 1087, 1158, 1187, 1193, 1194, 1242, 1299, 1302, 1338, 1339, 1759, 1762, 1766, 1767, 1769, 1773, 1775, 1793, 1798], "thei": [1, 2, 4, 6, 8, 10, 12, 16, 17, 20, 23, 29, 30, 33, 34, 38, 48, 53, 56, 59, 60, 297, 311, 312, 602, 605, 606, 613, 706, 707, 708, 710, 738, 746, 756, 763, 853, 909, 956, 961, 969, 1005, 1019, 1020, 1027, 1030, 1037, 1042, 1051, 1065, 1066, 1072, 1093, 1101, 1123, 1127, 1130, 1132, 1135, 1140, 1163, 1164, 1165, 1181, 1182, 1183, 1197, 1235, 1243, 1244, 1245, 1250, 1256, 1266, 1278, 1301, 1347, 1349, 1418, 1423, 1424, 1429, 1432, 1434, 1435, 1458, 1461, 1468, 1501, 1504, 1532, 1552, 1569, 1584, 1628, 1634, 1684, 1688, 1721, 1722, 1735, 1738, 1740, 1741, 1743, 1745, 1747, 1748, 1750, 1751, 1752, 1753, 1754, 1755, 1757, 1758, 1759, 1762, 1763, 1764, 1765, 1768, 1770, 1772, 1773, 1775, 1776, 1777, 1780, 1781, 1782, 1784, 1789, 1793, 1798, 1800, 1801, 1802, 1804], "grad": [1, 2, 6, 23, 29, 54, 57, 60, 127, 311, 431, 460, 467, 468, 475, 476, 728, 737, 740, 741, 747, 748, 750, 755, 756, 853, 909, 961, 962, 964, 968, 970, 971, 1005, 1013, 1030, 1102, 1250, 1423, 1468, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1634, 1665, 1721, 1728, 1736, 1738, 1739, 1752, 1753, 1754, 1758, 1763, 1764, 1765, 1767, 1770, 1772, 1779, 1789, 1790, 1793, 1799], "unscal": 1, "doe": [1, 2, 4, 5, 6, 8, 9, 10, 14, 23, 27, 29, 34, 35, 38, 39, 41, 45, 47, 48, 50, 53, 56, 57, 59, 60, 127, 230, 311, 431, 555, 589, 611, 612, 662, 671, 674, 728, 762, 775, 844, 848, 896, 905, 909, 958, 961, 971, 1004, 1029, 1031, 1034, 1040, 1045, 1055, 1060, 1072, 1073, 1077, 1078, 1085, 1091, 1093, 1099, 1102, 1119, 1123, 1124, 1130, 1134, 1142, 1168, 1169, 1170, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1190, 1193, 1194, 1197, 1202, 1203, 1213, 1214, 1215, 1220, 1221, 1223, 1224, 1225, 1232, 1233, 1234, 1244, 1245, 1251, 1257, 1260, 1265, 1267, 1289, 1301, 1330, 1382, 1423, 1434, 1437, 1441, 1465, 1468, 1470, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1508, 1512, 1517, 1527, 1586, 1624, 1627, 1628, 1632, 1634, 1658, 1663, 1688, 1706, 1709, 1721, 1728, 1734, 1735, 1736, 1738, 1740, 1741, 1743, 1748, 1751, 1752, 1753, 1754, 1758, 1760, 1761, 1762, 1763, 1764, 1765, 1767, 1770, 1772, 1773, 1774, 1777, 1781, 1782, 1784, 1789, 1791, 1793, 1796, 1800], "interfer": [1, 33, 1750, 1762, 1777], "learn": [1, 8, 9, 15, 29, 35, 47, 60, 1171, 1184, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1210, 1235, 1237, 1258, 1279, 1298, 1299, 1399, 1423, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1736, 1745, 1755, 1757, 1768, 1770, 1771, 1777, 1781, 1784, 1789, 1791], "rate": [1, 9, 21, 29, 1189, 1190, 1191, 1195, 1296, 1423, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1516, 1736, 1769, 1798], "init_scal": 1, "65536": 1, "0": [1, 2, 4, 12, 14, 17, 20, 21, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 46, 48, 49, 50, 53, 56, 57, 58, 59, 60, 65, 131, 133, 150, 161, 168, 185, 201, 202, 203, 204, 205, 230, 236, 239, 265, 274, 276, 287, 289, 291, 293, 297, 328, 401, 402, 418, 421, 422, 427, 454, 456, 460, 468, 479, 480, 485, 487, 489, 492, 509, 514, 515, 518, 527, 529, 531, 550, 552, 553, 555, 556, 557, 561, 567, 568, 569, 570, 577, 579, 580, 589, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 615, 628, 629, 630, 631, 632, 633, 634, 635, 639, 640, 641, 642, 643, 646, 647, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 662, 665, 666, 667, 669, 670, 671, 672, 674, 682, 683, 684, 686, 687, 688, 689, 692, 694, 696, 697, 699, 704, 705, 708, 710, 712, 713, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 745, 748, 749, 750, 752, 755, 756, 759, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 776, 777, 779, 782, 783, 784, 785, 786, 787, 788, 789, 790, 793, 798, 799, 802, 803, 804, 805, 806, 807, 808, 814, 822, 824, 850, 851, 876, 880, 884, 885, 886, 887, 888, 889, 892, 893, 894, 895, 896, 897, 899, 900, 903, 905, 907, 908, 915, 918, 919, 920, 921, 922, 923, 924, 925, 926, 929, 930, 931, 932, 933, 934, 935, 936, 939, 940, 941, 942, 944, 945, 946, 947, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 961, 963, 964, 965, 966, 967, 969, 970, 971, 972, 973, 983, 987, 989, 990, 991, 992, 993, 996, 1000, 1004, 1007, 1015, 1026, 1027, 1028, 1030, 1034, 1036, 1037, 1041, 1049, 1050, 1051, 1052, 1053, 1055, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1071, 1072, 1073, 1074, 1075, 1076, 1081, 1082, 1083, 1084, 1086, 1087, 1088, 1089, 1091, 1096, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1119, 1123, 1127, 1128, 1129, 1130, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1142, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1152, 1154, 1156, 1157, 1158, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1202, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1236, 1238, 1240, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1264, 1265, 1266, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1277, 1281, 1283, 1284, 1285, 1287, 1289, 1292, 1293, 1295, 1297, 1298, 1299, 1301, 1302, 1305, 1312, 1313, 1314, 1315, 1316, 1317, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1345, 1347, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1362, 1363, 1365, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1382, 1383, 1384, 1385, 1386, 1387, 1390, 1391, 1393, 1395, 1396, 1397, 1400, 1402, 1405, 1411, 1412, 1413, 1414, 1415, 1418, 1423, 1427, 1428, 1429, 1432, 1433, 1437, 1442, 1443, 1445, 1446, 1447, 1448, 1450, 1451, 1452, 1453, 1454, 1455, 1458, 1459, 1461, 1462, 1463, 1464, 1465, 1467, 1469, 1470, 1471, 1475, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1514, 1516, 1517, 1519, 1520, 1521, 1523, 1524, 1531, 1534, 1535, 1536, 1539, 1540, 1548, 1549, 1550, 1553, 1557, 1558, 1559, 1560, 1570, 1572, 1573, 1574, 1575, 1576, 1580, 1581, 1590, 1591, 1592, 1593, 1594, 1595, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1606, 1607, 1608, 1609, 1610, 1611, 1614, 1615, 1616, 1617, 1619, 1620, 1624, 1626, 1627, 1628, 1631, 1633, 1637, 1640, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1657, 1658, 1662, 1663, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1681, 1682, 1683, 1684, 1685, 1687, 1688, 1690, 1691, 1694, 1695, 1696, 1698, 1699, 1700, 1701, 1702, 1706, 1707, 1709, 1710, 1711, 1712, 1713, 1715, 1716, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1726, 1727, 1728, 1729, 1731, 1733, 1734, 1735, 1737, 1738, 1739, 1740, 1741, 1747, 1752, 1753, 1754, 1757, 1758, 1759, 1760, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1773, 1774, 1775, 1776, 1777, 1778, 1780, 1781, 1782, 1783, 1784, 1786, 1787, 1789, 1790, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1804, 1805], "growth_factor": 1, "backoff_factor": 1, "5": [1, 2, 11, 12, 14, 17, 18, 20, 21, 23, 29, 32, 33, 38, 46, 57, 58, 59, 60, 131, 168, 185, 236, 265, 274, 289, 291, 293, 297, 418, 444, 471, 485, 487, 489, 508, 515, 529, 531, 556, 557, 558, 559, 560, 579, 601, 602, 606, 613, 653, 654, 655, 656, 657, 659, 660, 674, 676, 687, 688, 713, 734, 735, 736, 748, 751, 753, 763, 766, 773, 774, 775, 779, 781, 785, 788, 789, 790, 793, 802, 806, 884, 886, 888, 895, 897, 899, 900, 903, 904, 905, 908, 921, 923, 925, 926, 932, 933, 936, 941, 944, 945, 948, 951, 953, 954, 955, 963, 965, 966, 967, 968, 969, 970, 971, 973, 983, 989, 991, 993, 995, 996, 1007, 1015, 1019, 1036, 1040, 1041, 1050, 1051, 1052, 1055, 1058, 1059, 1076, 1079, 1082, 1085, 1086, 1087, 1088, 1093, 1094, 1097, 1099, 1100, 1102, 1103, 1104, 1105, 1106, 1112, 1116, 1123, 1124, 1130, 1131, 1135, 1147, 1149, 1150, 1152, 1155, 1156, 1157, 1159, 1160, 1161, 1162, 1163, 1167, 1168, 1169, 1170, 1174, 1175, 1176, 1177, 1179, 1180, 1182, 1183, 1184, 1186, 1188, 1189, 1190, 1191, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1202, 1204, 1205, 1206, 1211, 1213, 1214, 1215, 1216, 1217, 1220, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1238, 1241, 1246, 1247, 1250, 1257, 1260, 1264, 1265, 1271, 1272, 1273, 1274, 1275, 1278, 1281, 1287, 1289, 1293, 1295, 1297, 1299, 1300, 1301, 1302, 1303, 1304, 1313, 1314, 1322, 1323, 1325, 1326, 1330, 1332, 1333, 1334, 1335, 1338, 1339, 1340, 1342, 1343, 1345, 1347, 1350, 1358, 1382, 1384, 1390, 1405, 1415, 1416, 1417, 1423, 1427, 1437, 1447, 1450, 1452, 1453, 1455, 1460, 1461, 1463, 1469, 1470, 1471, 1473, 1474, 1483, 1490, 1492, 1496, 1502, 1506, 1512, 1514, 1516, 1517, 1519, 1520, 1523, 1524, 1586, 1587, 1592, 1593, 1594, 1595, 1599, 1604, 1605, 1608, 1609, 1615, 1616, 1617, 1624, 1637, 1644, 1646, 1647, 1648, 1649, 1652, 1653, 1662, 1666, 1668, 1669, 1670, 1671, 1673, 1676, 1684, 1687, 1688, 1689, 1690, 1691, 1694, 1696, 1698, 1700, 1701, 1702, 1704, 1705, 1707, 1716, 1717, 1721, 1722, 1728, 1729, 1730, 1733, 1738, 1739, 1740, 1741, 1742, 1747, 1753, 1754, 1757, 1758, 1759, 1760, 1762, 1764, 1766, 1767, 1770, 1771, 1775, 1776, 1777, 1778, 1780, 1782, 1784, 1789, 1793, 1794, 1796, 1798, 1799, 1800], "growth_interv": 1, "2000": [1, 23, 27, 923, 925, 932, 941, 954, 1107, 1302, 1499, 1592, 1642, 1643, 1700], "get_backoff_factor": 1, "backoff": [1, 1789], "get_growth_factor": 1, "growth": [1, 9], "get_growth_interv": 1, "int": [1, 3, 4, 17, 20, 21, 23, 27, 29, 35, 39, 42, 45, 46, 48, 49, 51, 53, 60, 65, 193, 195, 209, 218, 230, 289, 291, 293, 297, 410, 417, 418, 420, 422, 430, 445, 449, 465, 469, 471, 485, 487, 489, 492, 508, 514, 516, 517, 529, 531, 537, 555, 579, 589, 609, 611, 612, 613, 615, 669, 670, 689, 691, 693, 694, 699, 700, 701, 722, 723, 724, 726, 746, 764, 766, 773, 780, 782, 789, 794, 806, 807, 808, 810, 812, 814, 816, 817, 820, 821, 822, 823, 824, 826, 827, 828, 829, 830, 835, 836, 837, 839, 841, 845, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 864, 865, 866, 870, 871, 872, 875, 876, 877, 880, 882, 883, 884, 885, 886, 887, 888, 892, 893, 894, 895, 896, 897, 903, 906, 908, 918, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 944, 958, 959, 963, 964, 965, 966, 967, 971, 972, 978, 980, 981, 983, 987, 988, 990, 991, 992, 993, 1004, 1006, 1027, 1028, 1030, 1031, 1033, 1036, 1041, 1049, 1051, 1061, 1062, 1082, 1083, 1086, 1095, 1096, 1097, 1098, 1099, 1100, 1102, 1109, 1116, 1117, 1122, 1127, 1129, 1130, 1132, 1135, 1137, 1140, 1145, 1146, 1147, 1148, 1149, 1150, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1163, 1164, 1165, 1168, 1169, 1170, 1171, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1185, 1186, 1187, 1193, 1194, 1196, 1197, 1198, 1199, 1201, 1203, 1205, 1213, 1214, 1215, 1218, 1219, 1221, 1222, 1226, 1227, 1228, 1229, 1230, 1231, 1235, 1237, 1238, 1240, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1252, 1255, 1257, 1258, 1261, 1262, 1263, 1267, 1271, 1272, 1273, 1274, 1275, 1276, 1283, 1285, 1286, 1289, 1293, 1295, 1297, 1298, 1300, 1301, 1302, 1303, 1304, 1305, 1329, 1330, 1331, 1338, 1339, 1346, 1349, 1358, 1366, 1382, 1383, 1384, 1388, 1389, 1402, 1403, 1411, 1415, 1416, 1417, 1423, 1433, 1442, 1443, 1445, 1446, 1448, 1451, 1452, 1453, 1454, 1459, 1461, 1464, 1467, 1470, 1471, 1473, 1474, 1476, 1483, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1513, 1514, 1521, 1524, 1547, 1590, 1591, 1592, 1593, 1594, 1595, 1597, 1599, 1600, 1601, 1603, 1609, 1610, 1611, 1614, 1615, 1616, 1617, 1620, 1625, 1626, 1627, 1631, 1635, 1636, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1658, 1662, 1664, 1667, 1668, 1669, 1676, 1679, 1681, 1682, 1683, 1684, 1687, 1689, 1693, 1697, 1701, 1702, 1704, 1706, 1707, 1710, 1711, 1712, 1713, 1716, 1717, 1718, 1719, 1720, 1722, 1723, 1724, 1728, 1729, 1733, 1737, 1738, 1739, 1740, 1741, 1742, 1750, 1751, 1752, 1754, 1757, 1762, 1765, 1777, 1779, 1782, 1783, 1784, 1788, 1789, 1794, 1795, 1796, 1798, 1799, 1800, 1805], "interv": [1, 29, 50, 713, 803, 955, 983, 1508, 1597, 1598, 1646, 1750, 1762, 1783], "get_scal": [1, 1758], "sync": [1, 23, 27, 53, 59, 60, 1423, 1762, 1763, 1782], "is_en": 1, "indic": [1, 2, 3, 4, 20, 21, 23, 24, 29, 35, 38, 48, 168, 185, 198, 289, 291, 293, 294, 295, 297, 444, 485, 487, 489, 515, 544, 545, 555, 586, 611, 612, 659, 660, 722, 723, 724, 725, 726, 745, 755, 756, 779, 786, 787, 809, 811, 812, 814, 847, 884, 885, 908, 963, 964, 966, 967, 968, 970, 971, 972, 983, 1004, 1028, 1030, 1035, 1043, 1046, 1047, 1051, 1060, 1071, 1073, 1084, 1087, 1101, 1109, 1117, 1119, 1121, 1127, 1130, 1132, 1135, 1140, 1146, 1150, 1158, 1159, 1160, 1161, 1186, 1193, 1194, 1198, 1199, 1244, 1245, 1246, 1247, 1248, 1253, 1255, 1256, 1309, 1310, 1311, 1330, 1338, 1339, 1342, 1343, 1359, 1374, 1375, 1376, 1384, 1411, 1423, 1428, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1451, 1452, 1469, 1470, 1503, 1505, 1524, 1624, 1662, 1665, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1696, 1697, 1701, 1704, 1710, 1711, 1712, 1713, 1718, 1719, 1721, 1728, 1731, 1737, 1738, 1739, 1741, 1745, 1752, 1753, 1764, 1777, 1779, 1789, 1793, 1797, 1798, 1800], "load_state_dict": [1, 21, 27, 53, 1030, 1101, 1250, 1418, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1735, 1770, 1775, 1784], "state_dict": [1, 21, 27, 53, 1030, 1250, 1418, 1451, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1486, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1564, 1565, 1735, 1749, 1763, 1770, 1772, 1775, 1777, 1784, 1802], "load": [1, 2, 12, 14, 15, 21, 27, 34, 38, 53, 758, 810, 1034, 1040, 1045, 1194, 1418, 1423, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1486, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1565, 1587, 1620, 1736, 1738, 1748, 1749, 1753, 1759, 1762, 1769, 1770, 1774, 1776, 1777, 1798], "scaler": [1, 1758, 1762], "dict": [1, 4, 6, 20, 21, 23, 24, 27, 29, 39, 42, 46, 50, 53, 55, 60, 702, 703, 704, 706, 707, 708, 710, 795, 850, 851, 864, 872, 961, 969, 971, 1028, 1029, 1030, 1031, 1036, 1041, 1045, 1046, 1101, 1102, 1187, 1197, 1250, 1251, 1260, 1301, 1418, 1423, 1448, 1465, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1564, 1728, 1735, 1738, 1739, 1741, 1742, 1749, 1750, 1764, 1770, 1775, 1777, 1779, 1780, 1789, 1790, 1798, 1802, 1803, 1804], "unmodifi": [1, 23, 36], "iter": [1, 2, 3, 4, 8, 21, 23, 24, 27, 29, 33, 35, 38, 49, 51, 53, 60, 820, 821, 822, 823, 824, 853, 856, 858, 878, 1030, 1102, 1250, 1251, 1252, 1260, 1261, 1423, 1424, 1429, 1430, 1431, 1433, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1448, 1464, 1466, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1497, 1498, 1499, 1502, 1513, 1648, 1689, 1739, 1741, 1742, 1751, 1753, 1758, 1759, 1760, 1762, 1763, 1764, 1767, 1770, 1780, 1783, 1788, 1798, 1804], "set_backoff_factor": 1, "new_factor": 1, "new_scal": 1, "set_growth_factor": 1, "set_growth_interv": 1, "new_interv": 1, "It": [1, 2, 4, 5, 6, 8, 9, 16, 17, 20, 21, 23, 24, 29, 33, 34, 35, 36, 38, 39, 41, 45, 46, 47, 48, 49, 50, 53, 55, 57, 58, 59, 60, 65, 127, 173, 446, 447, 485, 487, 489, 528, 737, 738, 739, 740, 744, 762, 800, 801, 824, 829, 835, 836, 854, 855, 873, 874, 882, 928, 957, 962, 965, 971, 972, 991, 1027, 1030, 1031, 1036, 1040, 1062, 1066, 1070, 1073, 1075, 1077, 1078, 1083, 1087, 1088, 1090, 1091, 1093, 1095, 1098, 1099, 1101, 1102, 1110, 1158, 1167, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1187, 1197, 1244, 1245, 1246, 1247, 1248, 1250, 1257, 1278, 1281, 1301, 1303, 1349, 1359, 1402, 1420, 1421, 1423, 1433, 1434, 1437, 1458, 1461, 1462, 1468, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1487, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1511, 1595, 1608, 1624, 1634, 1640, 1647, 1667, 1717, 1728, 1735, 1740, 1741, 1750, 1751, 1753, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1776, 1777, 1778, 1780, 1781, 1782, 1784, 1789, 1790, 1791, 1794, 1795, 1797, 1801], "five": [1, 1741, 1775], "entri": [1, 4, 23, 24, 27, 29, 35, 46, 48, 49, 291, 759, 850, 851, 895, 946, 947, 1004, 1030, 1050, 1193, 1194, 1250, 1256, 1338, 1339, 1422, 1428, 1443, 1444, 1452, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1487, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1583, 1584, 1667, 1738, 1741, 1742, 1747, 1754, 1759, 1763, 1764, 1767, 1770, 1778, 1784, 1793, 1798, 1802], "_growth_track": 1, "number": [1, 2, 3, 4, 5, 6, 8, 14, 20, 21, 23, 27, 29, 34, 38, 39, 46, 47, 48, 51, 53, 54, 56, 58, 60, 65, 131, 150, 195, 209, 230, 289, 328, 352, 373, 377, 419, 444, 446, 447, 454, 465, 469, 471, 485, 487, 489, 514, 516, 517, 529, 555, 561, 580, 589, 601, 602, 603, 604, 605, 606, 607, 614, 672, 674, 682, 683, 686, 687, 688, 695, 713, 725, 738, 755, 763, 765, 766, 775, 777, 781, 789, 790, 794, 802, 806, 807, 816, 821, 830, 839, 840, 851, 853, 854, 855, 864, 873, 874, 877, 878, 897, 900, 902, 905, 906, 910, 918, 948, 950, 953, 958, 960, 972, 974, 980, 981, 982, 983, 986, 990, 991, 992, 1004, 1006, 1028, 1030, 1043, 1050, 1053, 1054, 1061, 1075, 1084, 1093, 1097, 1102, 1107, 1118, 1122, 1130, 1139, 1140, 1144, 1148, 1151, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1163, 1164, 1165, 1166, 1167, 1168, 1171, 1172, 1173, 1174, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1192, 1193, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1216, 1217, 1220, 1221, 1226, 1227, 1228, 1229, 1230, 1231, 1236, 1237, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1249, 1250, 1253, 1254, 1255, 1256, 1257, 1258, 1264, 1265, 1267, 1268, 1269, 1270, 1277, 1279, 1280, 1281, 1282, 1283, 1285, 1286, 1287, 1288, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1314, 1315, 1316, 1318, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1330, 1331, 1338, 1339, 1342, 1343, 1348, 1358, 1359, 1361, 1364, 1371, 1372, 1373, 1382, 1384, 1390, 1391, 1418, 1423, 1433, 1437, 1442, 1443, 1445, 1446, 1448, 1451, 1452, 1453, 1454, 1458, 1459, 1460, 1462, 1464, 1469, 1470, 1471, 1473, 1474, 1483, 1496, 1497, 1498, 1499, 1502, 1503, 1505, 1506, 1507, 1513, 1516, 1520, 1547, 1595, 1597, 1598, 1599, 1601, 1602, 1603, 1608, 1610, 1611, 1614, 1615, 1616, 1617, 1625, 1629, 1633, 1635, 1636, 1637, 1638, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1663, 1666, 1668, 1670, 1671, 1672, 1673, 1674, 1675, 1680, 1681, 1682, 1683, 1684, 1685, 1689, 1701, 1702, 1703, 1711, 1713, 1718, 1719, 1722, 1723, 1724, 1725, 1726, 1727, 1733, 1736, 1739, 1740, 1741, 1742, 1743, 1747, 1750, 1751, 1754, 1757, 1760, 1762, 1764, 1767, 1770, 1773, 1775, 1777, 1780, 1781, 1782, 1783, 1785, 1788, 1789, 1790, 1793, 1794, 1795, 1796, 1798, 1799, 1800, 1801, 1805], "recent": [1, 2, 8, 9, 38, 51, 59, 1005, 1015, 1740, 1741, 1754, 1764, 1773, 1774, 1793, 1800], "consecut": [1, 23, 582, 1460, 1495, 1707, 1718, 1719, 1753, 1777], "unskip": 1, "empti": [1, 4, 23, 39, 46, 53, 57, 60, 297, 485, 487, 508, 516, 708, 765, 766, 776, 782, 905, 907, 1028, 1031, 1055, 1075, 1076, 1081, 1088, 1111, 1112, 1113, 1114, 1121, 1166, 1167, 1186, 1194, 1257, 1320, 1339, 1385, 1463, 1475, 1476, 1673, 1688, 1694, 1700, 1734, 1738, 1739, 1740, 1741, 1743, 1748, 1752, 1753, 1757, 1760, 1762, 1764, 1777, 1779, 1781, 1793, 1794, 1801], "wish": [1, 968, 1758, 1764, 1765], "checkpoint": [1, 27, 49, 51, 53, 758, 1101, 1423, 1735, 1736, 1749, 1766, 1782, 1791], "kwarg": [1, 2, 6, 14, 23, 24, 27, 31, 32, 38, 48, 53, 60, 552, 575, 674, 676, 677, 738, 795, 812, 814, 850, 851, 961, 970, 971, 1030, 1033, 1035, 1093, 1119, 1202, 1212, 1220, 1250, 1265, 1309, 1310, 1311, 1342, 1343, 1418, 1422, 1423, 1439, 1444, 1448, 1458, 1463, 1465, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1549, 1550, 1552, 1555, 1620, 1719, 1728, 1735, 1741, 1742, 1764, 1765, 1770, 1778, 1789, 1795, 1803, 1804], "carri": [1, 312, 1529, 1566, 1567, 1582, 1583, 1760, 1784], "out": [1, 2, 3, 4, 8, 9, 10, 12, 15, 17, 20, 23, 29, 33, 34, 35, 45, 46, 49, 54, 60, 288, 290, 292, 294, 374, 376, 421, 468, 484, 486, 488, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 609, 611, 612, 613, 614, 615, 670, 674, 678, 686, 687, 688, 693, 695, 699, 713, 714, 715, 716, 717, 718, 719, 720, 725, 729, 730, 731, 732, 733, 741, 742, 743, 746, 755, 763, 765, 766, 767, 768, 769, 770, 771, 772, 775, 779, 782, 784, 785, 786, 787, 788, 790, 791, 793, 797, 798, 799, 801, 802, 804, 805, 808, 813, 820, 822, 824, 851, 852, 864, 865, 876, 880, 884, 885, 886, 887, 889, 892, 897, 898, 900, 901, 902, 904, 905, 906, 910, 912, 913, 914, 915, 916, 917, 918, 921, 922, 923, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 948, 949, 950, 951, 952, 953, 954, 955, 958, 959, 962, 963, 965, 966, 968, 971, 972, 973, 974, 975, 976, 984, 985, 986, 989, 990, 991, 992, 994, 995, 996, 997, 998, 999, 1001, 1002, 1003, 1004, 1005, 1007, 1008, 1024, 1025, 1030, 1041, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1076, 1077, 1078, 1079, 1080, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1098, 1099, 1100, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1123, 1124, 1126, 1127, 1128, 1129, 1130, 1132, 1133, 1134, 1135, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1150, 1151, 1152, 1153, 1154, 1155, 1159, 1160, 1161, 1163, 1164, 1165, 1171, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1188, 1189, 1190, 1191, 1193, 1195, 1198, 1199, 1202, 1203, 1218, 1219, 1220, 1235, 1237, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1262, 1263, 1265, 1267, 1271, 1272, 1273, 1274, 1275, 1276, 1293, 1294, 1295, 1296, 1297, 1301, 1302, 1303, 1304, 1305, 1318, 1322, 1323, 1324, 1325, 1326, 1327, 1333, 1334, 1335, 1340, 1343, 1347, 1358, 1364, 1383, 1385, 1415, 1423, 1442, 1443, 1444, 1445, 1469, 1470, 1471, 1472, 1474, 1475, 1511, 1512, 1516, 1517, 1518, 1520, 1523, 1524, 1529, 1564, 1566, 1567, 1582, 1583, 1595, 1596, 1597, 1599, 1601, 1603, 1604, 1607, 1608, 1609, 1613, 1617, 1618, 1619, 1621, 1622, 1623, 1624, 1640, 1641, 1642, 1654, 1655, 1656, 1657, 1662, 1665, 1666, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1685, 1686, 1688, 1694, 1697, 1698, 1699, 1702, 1704, 1706, 1709, 1710, 1712, 1714, 1715, 1721, 1723, 1724, 1725, 1728, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1738, 1739, 1741, 1747, 1750, 1751, 1753, 1754, 1759, 1760, 1762, 1763, 1764, 1765, 1770, 1772, 1777, 1781, 1784, 1785, 1787, 1789, 1790, 1791, 1794, 1796, 1798, 1799, 1803, 1804], "follow": [1, 2, 3, 4, 8, 10, 12, 14, 15, 17, 18, 19, 20, 21, 23, 27, 29, 31, 32, 33, 35, 37, 38, 39, 45, 46, 47, 48, 49, 53, 55, 57, 60, 460, 589, 674, 693, 699, 702, 703, 704, 706, 707, 708, 710, 737, 738, 739, 742, 779, 784, 850, 864, 905, 923, 925, 949, 958, 969, 983, 1030, 1031, 1039, 1043, 1050, 1061, 1072, 1082, 1085, 1086, 1099, 1102, 1121, 1124, 1158, 1167, 1173, 1194, 1197, 1202, 1220, 1250, 1256, 1265, 1281, 1297, 1301, 1366, 1420, 1421, 1422, 1423, 1432, 1470, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1502, 1505, 1513, 1524, 1532, 1546, 1547, 1548, 1549, 1550, 1552, 1553, 1586, 1587, 1617, 1624, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1664, 1665, 1666, 1673, 1684, 1707, 1715, 1721, 1735, 1738, 1739, 1740, 1741, 1742, 1743, 1747, 1748, 1749, 1751, 1752, 1753, 1754, 1757, 1758, 1759, 1760, 1761, 1762, 1764, 1765, 1766, 1767, 1768, 1770, 1772, 1773, 1774, 1775, 1776, 1777, 1780, 1781, 1782, 1784, 1785, 1787, 1789, 1790, 1791, 1793, 1794, 1796, 1797, 1799, 1800, 1804, 1805], "unscale_": [1, 1758], "unless": [1, 2, 5, 8, 21, 23, 50, 53, 54, 60, 127, 471, 744, 766, 1030, 1073, 1078, 1091, 1101, 1130, 1204, 1250, 1297, 1421, 1448, 1488, 1568, 1583, 1624, 1721, 1741, 1759, 1762, 1774, 1777, 1781, 1785], "explicitli": [1, 9, 14, 23, 41, 53, 844, 893, 895, 905, 992, 1070, 1083, 1087, 1095, 1137, 1358, 1415, 1505, 1684, 1738, 1740, 1741, 1742, 1762, 1764, 1767, 1769, 1775, 1777, 1781, 1782, 1788, 1789, 1793], "earlier": [1, 2, 7, 1688, 1762, 1766, 1769, 1775, 1777, 1783], "part": [1, 4, 5, 6, 7, 8, 10, 14, 15, 17, 21, 23, 29, 33, 38, 48, 49, 53, 57, 60, 754, 797, 905, 1020, 1022, 1023, 1026, 1030, 1040, 1042, 1045, 1046, 1060, 1066, 1068, 1077, 1084, 1087, 1250, 1289, 1423, 1435, 1497, 1524, 1569, 1669, 1707, 1710, 1711, 1712, 1713, 1735, 1736, 1738, 1740, 1741, 1748, 1749, 1758, 1759, 1762, 1764, 1766, 1767, 1770, 1775, 1777, 1781, 1782, 1784, 1789, 1790, 1791, 1793, 1798, 1800], "check": [1, 5, 12, 14, 20, 23, 24, 29, 32, 33, 35, 37, 38, 39, 48, 53, 198, 316, 471, 610, 744, 746, 747, 755, 756, 811, 812, 814, 818, 846, 1017, 1027, 1030, 1045, 1046, 1059, 1060, 1065, 1066, 1068, 1071, 1073, 1078, 1084, 1087, 1091, 1093, 1094, 1119, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1250, 1418, 1423, 1434, 1437, 1450, 1460, 1586, 1735, 1736, 1740, 1741, 1742, 1752, 1753, 1758, 1762, 1764, 1765, 1766, 1769, 1770, 1771, 1774, 1777, 1780, 1781, 1782, 1783, 1789, 1798, 1800, 1804], "inf": [1, 29, 38, 53, 600, 602, 605, 606, 607, 733, 763, 779, 1019, 1020, 1022, 1024, 1025, 1061, 1076, 1082, 1086, 1089, 1099, 1110, 1144, 1240, 1283, 1293, 1429, 1443, 1452, 1470, 1617, 1624, 1758, 1759, 1765, 1773, 1794, 1800], "nan": [1, 2, 29, 401, 402, 600, 602, 605, 606, 607, 610, 613, 614, 729, 733, 763, 779, 951, 952, 953, 990, 1019, 1020, 1022, 1023, 1069, 1076, 1089, 1092, 1105, 1110, 1128, 1129, 1133, 1144, 1145, 1146, 1147, 1148, 1347, 1429, 1517, 1619, 1624, 1677, 1709, 1739, 1747, 1758, 1759, 1765, 1773, 1794, 1800], "found": [1, 8, 15, 17, 31, 34, 48, 60, 779, 808, 884, 885, 1030, 1034, 1051, 1127, 1130, 1132, 1135, 1146, 1162, 1172, 1195, 1250, 1277, 1624, 1735, 1738, 1741, 1754, 1758, 1764, 1767, 1770, 1772, 1777, 1781, 1783, 1784, 1789, 1798, 1804], "otherwis": [1, 2, 4, 6, 8, 10, 12, 14, 20, 23, 24, 30, 41, 53, 54, 57, 60, 65, 186, 297, 304, 308, 312, 314, 318, 319, 467, 476, 531, 552, 553, 555, 575, 589, 602, 603, 604, 605, 606, 609, 611, 612, 613, 615, 674, 682, 683, 698, 708, 713, 742, 750, 755, 763, 779, 848, 905, 911, 944, 956, 1021, 1030, 1033, 1036, 1042, 1051, 1075, 1090, 1099, 1101, 1102, 1117, 1122, 1127, 1129, 1130, 1132, 1134, 1135, 1145, 1148, 1164, 1165, 1184, 1186, 1189, 1190, 1191, 1195, 1202, 1206, 1207, 1208, 1209, 1211, 1220, 1236, 1250, 1254, 1255, 1256, 1257, 1258, 1260, 1265, 1266, 1268, 1281, 1287, 1289, 1292, 1293, 1295, 1297, 1298, 1299, 1315, 1316, 1349, 1351, 1352, 1356, 1391, 1400, 1423, 1428, 1432, 1437, 1458, 1462, 1468, 1488, 1511, 1513, 1521, 1523, 1548, 1549, 1586, 1587, 1595, 1604, 1611, 1624, 1632, 1640, 1682, 1683, 1684, 1687, 1694, 1717, 1718, 1719, 1723, 1724, 1731, 1735, 1738, 1740, 1741, 1747, 1748, 1752, 1758, 1764, 1765, 1772, 1777, 1785, 1787, 1788, 1789, 1791, 1794, 1795, 1796, 1797, 1798, 1800, 1804], "avoid": [1, 9, 10, 20, 29, 33, 35, 46, 49, 53, 60, 65, 168, 185, 421, 695, 713, 740, 776, 864, 1030, 1075, 1101, 1185, 1216, 1217, 1241, 1250, 1259, 1264, 1301, 1329, 1359, 1383, 1390, 1423, 1433, 1610, 1639, 1684, 1700, 1718, 1736, 1750, 1753, 1759, 1761, 1762, 1766, 1767, 1770, 1782, 1789, 1790, 1797, 1798, 1799], "corrupt": [1, 23, 48, 1187, 1762, 1772], "param": [1, 2, 27, 29, 40, 48, 53, 55, 60, 678, 961, 969, 1030, 1048, 1250, 1256, 1260, 1261, 1423, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1489, 1490, 1491, 1492, 1493, 1494, 1507, 1613, 1739, 1745, 1748, 1757, 1758, 1762, 1763, 1780, 1804], "appli": [1, 2, 4, 6, 9, 21, 27, 29, 32, 39, 41, 48, 53, 57, 58, 60, 96, 297, 373, 445, 485, 489, 652, 653, 654, 655, 656, 657, 672, 674, 680, 681, 682, 683, 684, 685, 686, 687, 688, 694, 695, 696, 697, 698, 744, 746, 747, 755, 762, 768, 771, 802, 893, 895, 900, 909, 921, 922, 924, 925, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 953, 961, 962, 970, 971, 1030, 1034, 1079, 1102, 1119, 1155, 1156, 1157, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1192, 1198, 1199, 1200, 1201, 1202, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1222, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1249, 1250, 1253, 1254, 1255, 1256, 1257, 1258, 1264, 1265, 1268, 1269, 1270, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1293, 1295, 1296, 1297, 1298, 1299, 1303, 1304, 1306, 1307, 1308, 1309, 1310, 1311, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1340, 1342, 1343, 1344, 1345, 1348, 1350, 1351, 1352, 1353, 1357, 1358, 1359, 1361, 1362, 1364, 1365, 1366, 1367, 1368, 1369, 1371, 1372, 1373, 1377, 1382, 1390, 1391, 1392, 1393, 1397, 1398, 1399, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1418, 1422, 1423, 1428, 1432, 1433, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1458, 1459, 1464, 1465, 1467, 1468, 1470, 1478, 1490, 1494, 1507, 1520, 1542, 1543, 1544, 1545, 1568, 1583, 1590, 1591, 1592, 1593, 1594, 1634, 1664, 1667, 1684, 1718, 1719, 1720, 1728, 1738, 1741, 1747, 1751, 1753, 1758, 1759, 1762, 1763, 1764, 1765, 1767, 1770, 1773, 1777, 1780, 1781, 1782, 1784, 1787, 1790, 1793, 1794], "argument": [1, 2, 4, 5, 6, 9, 10, 14, 17, 20, 23, 24, 27, 29, 39, 46, 49, 51, 53, 57, 59, 60, 65, 127, 173, 186, 289, 297, 418, 419, 420, 421, 422, 460, 485, 489, 531, 552, 575, 597, 599, 600, 601, 602, 603, 604, 605, 606, 607, 609, 611, 612, 613, 614, 615, 652, 653, 654, 655, 656, 657, 703, 713, 728, 729, 730, 731, 732, 733, 737, 738, 739, 740, 744, 745, 746, 749, 751, 752, 753, 754, 762, 763, 764, 765, 767, 768, 769, 770, 771, 772, 773, 775, 779, 782, 784, 785, 786, 787, 788, 790, 792, 793, 797, 801, 802, 804, 805, 807, 808, 829, 831, 835, 836, 842, 850, 851, 853, 875, 879, 884, 885, 886, 887, 888, 889, 892, 893, 894, 895, 896, 897, 900, 902, 903, 904, 906, 907, 908, 910, 915, 918, 921, 922, 923, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 948, 949, 950, 951, 952, 953, 955, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 970, 971, 972, 973, 974, 975, 983, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 1004, 1007, 1024, 1025, 1027, 1030, 1033, 1041, 1045, 1046, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1058, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1111, 1112, 1113, 1114, 1116, 1117, 1118, 1120, 1121, 1123, 1124, 1127, 1128, 1129, 1130, 1132, 1133, 1134, 1135, 1138, 1139, 1140, 1142, 1144, 1145, 1146, 1147, 1148, 1150, 1151, 1152, 1154, 1168, 1169, 1170, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1194, 1197, 1200, 1202, 1209, 1212, 1213, 1214, 1215, 1216, 1220, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1246, 1247, 1248, 1250, 1251, 1256, 1257, 1258, 1265, 1289, 1297, 1301, 1303, 1304, 1345, 1347, 1383, 1418, 1420, 1421, 1422, 1423, 1427, 1436, 1437, 1439, 1443, 1444, 1448, 1452, 1458, 1465, 1469, 1471, 1474, 1475, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1499, 1511, 1512, 1516, 1517, 1520, 1521, 1523, 1524, 1531, 1547, 1548, 1549, 1552, 1553, 1554, 1569, 1582, 1583, 1586, 1588, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1607, 1608, 1609, 1610, 1617, 1619, 1624, 1628, 1634, 1640, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1657, 1662, 1666, 1668, 1670, 1671, 1672, 1673, 1674, 1675, 1677, 1678, 1680, 1681, 1682, 1683, 1684, 1685, 1687, 1688, 1694, 1697, 1698, 1699, 1700, 1702, 1703, 1704, 1706, 1707, 1709, 1710, 1711, 1712, 1713, 1715, 1718, 1721, 1723, 1724, 1728, 1729, 1730, 1731, 1733, 1734, 1735, 1739, 1740, 1741, 1743, 1745, 1751, 1752, 1753, 1754, 1758, 1759, 1760, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1774, 1777, 1780, 1781, 1782, 1783, 1784, 1785, 1787, 1788, 1789, 1793, 1794, 1795, 1796, 1798, 1800, 1804, 1805], "keyword": [1, 2, 6, 20, 23, 24, 27, 53, 57, 60, 65, 289, 297, 418, 419, 420, 421, 422, 597, 599, 600, 601, 602, 603, 604, 605, 606, 607, 609, 611, 612, 613, 614, 615, 713, 728, 729, 730, 731, 732, 733, 763, 764, 765, 767, 768, 769, 770, 771, 772, 773, 775, 779, 782, 784, 786, 787, 788, 790, 792, 793, 797, 801, 802, 804, 805, 807, 808, 820, 822, 824, 850, 851, 884, 885, 886, 887, 888, 889, 892, 897, 900, 902, 904, 906, 907, 908, 910, 915, 918, 921, 922, 923, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 948, 949, 950, 951, 952, 953, 955, 958, 959, 960, 961, 972, 973, 974, 975, 983, 986, 987, 988, 989, 990, 991, 992, 994, 995, 996, 1004, 1007, 1024, 1025, 1030, 1033, 1045, 1046, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1058, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1111, 1112, 1113, 1114, 1116, 1117, 1118, 1120, 1121, 1123, 1124, 1127, 1128, 1129, 1130, 1132, 1133, 1134, 1135, 1138, 1139, 1140, 1142, 1144, 1145, 1146, 1147, 1148, 1150, 1151, 1152, 1154, 1187, 1209, 1212, 1250, 1420, 1421, 1423, 1437, 1439, 1444, 1448, 1465, 1469, 1471, 1474, 1475, 1511, 1512, 1516, 1517, 1520, 1521, 1523, 1524, 1586, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1607, 1608, 1609, 1610, 1617, 1619, 1624, 1640, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1657, 1662, 1666, 1668, 1670, 1671, 1672, 1673, 1674, 1675, 1677, 1678, 1680, 1681, 1682, 1683, 1685, 1687, 1688, 1694, 1697, 1698, 1699, 1700, 1704, 1707, 1709, 1710, 1711, 1712, 1713, 1715, 1721, 1723, 1724, 1725, 1730, 1731, 1733, 1734, 1735, 1741, 1742, 1753, 1754, 1764, 1773, 1777, 1780, 1789, 1794, 1798, 1801, 1804], "closur": [1, 27, 1483, 1488, 1494], "divid": [1, 6, 21, 23, 27, 214, 555, 824, 900, 903, 923, 941, 950, 992, 993, 1040, 1166, 1167, 1173, 1174, 1184, 1210, 1211, 1217, 1241, 1242, 1253, 1254, 1255, 1264, 1281, 1282, 1298, 1299, 1319, 1320, 1330, 1331, 1359, 1382, 1390, 1423, 1688, 1729, 1739, 1779], "case": [1, 2, 4, 5, 9, 10, 12, 14, 15, 20, 21, 23, 27, 29, 33, 35, 38, 39, 40, 41, 48, 50, 51, 53, 54, 56, 57, 58, 59, 60, 127, 131, 173, 328, 468, 471, 674, 698, 713, 740, 748, 750, 754, 764, 766, 802, 808, 832, 854, 855, 873, 874, 875, 905, 926, 928, 936, 937, 938, 953, 963, 967, 970, 989, 1015, 1028, 1031, 1039, 1042, 1043, 1045, 1059, 1061, 1065, 1066, 1070, 1075, 1076, 1077, 1079, 1085, 1088, 1093, 1095, 1099, 1101, 1102, 1107, 1110, 1119, 1130, 1140, 1158, 1163, 1164, 1165, 1166, 1167, 1178, 1179, 1180, 1182, 1183, 1184, 1186, 1189, 1190, 1191, 1192, 1194, 1195, 1197, 1206, 1207, 1208, 1209, 1210, 1211, 1217, 1218, 1219, 1236, 1241, 1243, 1244, 1245, 1256, 1257, 1258, 1268, 1281, 1287, 1292, 1297, 1299, 1301, 1312, 1330, 1339, 1347, 1351, 1352, 1382, 1384, 1391, 1423, 1425, 1426, 1432, 1434, 1437, 1438, 1469, 1470, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1505, 1528, 1548, 1549, 1551, 1554, 1583, 1608, 1611, 1624, 1626, 1640, 1643, 1688, 1689, 1717, 1721, 1731, 1735, 1741, 1746, 1751, 1752, 1753, 1757, 1758, 1759, 1760, 1761, 1762, 1764, 1765, 1766, 1767, 1770, 1772, 1773, 1775, 1777, 1781, 1782, 1784, 1785, 1787, 1788, 1789, 1790, 1791, 1793, 1794, 1795, 1797, 1798, 1799, 1800, 1804, 1805], "need": [1, 2, 3, 4, 6, 7, 8, 9, 10, 14, 15, 20, 21, 23, 24, 27, 29, 32, 35, 38, 40, 41, 46, 48, 49, 51, 53, 55, 56, 57, 60, 127, 230, 444, 467, 471, 555, 737, 740, 744, 745, 754, 776, 777, 785, 844, 853, 860, 893, 895, 905, 926, 928, 948, 961, 1030, 1123, 1140, 1186, 1193, 1246, 1247, 1248, 1250, 1256, 1293, 1295, 1297, 1322, 1323, 1324, 1414, 1423, 1427, 1428, 1437, 1439, 1443, 1445, 1471, 1547, 1548, 1549, 1552, 1553, 1554, 1569, 1583, 1605, 1610, 1624, 1681, 1694, 1707, 1736, 1738, 1740, 1741, 1747, 1748, 1751, 1753, 1754, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1769, 1772, 1773, 1774, 1775, 1776, 1777, 1780, 1781, 1782, 1784, 1787, 1789, 1790, 1791, 1793, 1795, 1796, 1800, 1801, 1803, 1804], "modifi": [1, 2, 17, 20, 21, 23, 24, 27, 32, 33, 36, 38, 53, 60, 236, 460, 744, 746, 747, 800, 801, 983, 1027, 1030, 1033, 1034, 1049, 1193, 1250, 1293, 1295, 1297, 1338, 1339, 1420, 1421, 1422, 1423, 1429, 1430, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1488, 1490, 1491, 1492, 1493, 1494, 1497, 1505, 1528, 1566, 1567, 1568, 1652, 1738, 1741, 1752, 1758, 1759, 1762, 1764, 1765, 1770, 1775, 1781, 1782, 1784, 1789, 1794, 1797, 1799, 1803], "inspect": [1, 2, 23, 33, 34, 60, 758, 1030, 1041, 1758, 1764, 1769, 1781, 1785, 1796, 1804], "between": [1, 2, 3, 4, 8, 16, 17, 21, 23, 29, 30, 33, 35, 38, 48, 49, 50, 53, 59, 60, 173, 485, 579, 589, 605, 606, 607, 611, 612, 686, 687, 688, 713, 732, 740, 742, 749, 751, 752, 753, 755, 756, 783, 807, 811, 818, 866, 883, 888, 905, 921, 922, 923, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 956, 983, 990, 1027, 1030, 1041, 1065, 1066, 1088, 1093, 1147, 1166, 1167, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1185, 1186, 1189, 1190, 1191, 1195, 1197, 1211, 1217, 1226, 1227, 1228, 1229, 1230, 1231, 1241, 1243, 1244, 1245, 1250, 1253, 1254, 1255, 1259, 1278, 1281, 1282, 1283, 1298, 1299, 1301, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1329, 1330, 1346, 1371, 1372, 1373, 1387, 1402, 1423, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1448, 1451, 1452, 1453, 1454, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1487, 1490, 1491, 1492, 1493, 1494, 1498, 1499, 1505, 1507, 1516, 1524, 1534, 1582, 1593, 1594, 1599, 1600, 1604, 1629, 1681, 1682, 1683, 1684, 1688, 1706, 1707, 1723, 1724, 1738, 1740, 1741, 1742, 1747, 1751, 1754, 1758, 1759, 1761, 1762, 1763, 1767, 1768, 1770, 1772, 1774, 1775, 1777, 1780, 1782, 1784, 1785, 1789, 1791, 1793, 1795, 1798, 1802], "dure": [1, 2, 6, 14, 17, 21, 23, 31, 33, 34, 35, 38, 39, 40, 42, 48, 53, 59, 60, 311, 475, 476, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 737, 738, 746, 852, 853, 865, 866, 883, 1040, 1042, 1043, 1045, 1101, 1162, 1168, 1169, 1170, 1187, 1188, 1193, 1194, 1213, 1214, 1215, 1289, 1295, 1297, 1332, 1338, 1339, 1418, 1423, 1425, 1426, 1463, 1508, 1555, 1669, 1711, 1713, 1740, 1747, 1748, 1750, 1752, 1758, 1759, 1761, 1762, 1763, 1764, 1765, 1767, 1769, 1770, 1773, 1774, 1777, 1781, 1783, 1784, 1787, 1789, 1791, 1800], "simpl": [1, 15, 17, 21, 34, 35, 41, 48, 58, 60, 807, 864, 963, 969, 970, 971, 1030, 1034, 1041, 1168, 1169, 1170, 1193, 1223, 1224, 1225, 1250, 1289, 1338, 1645, 1728, 1735, 1738, 1742, 1754, 1761, 1762, 1763, 1764, 1766, 1767, 1769, 1777, 1781, 1789, 1793], "clip": [1, 53, 803, 1429, 1430, 1739, 1765, 1777, 1779], "util": [1, 8, 16, 33, 38, 49, 53, 54, 59, 60, 648, 652, 653, 654, 659, 660, 670, 674, 678, 824, 956, 1030, 1202, 1220, 1250, 1265, 1419, 1420, 1421, 1422, 1423, 1428, 1434, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1458, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1499, 1505, 1527, 1530, 1692, 1693, 1736, 1741, 1750, 1758, 1760, 1761, 1762, 1764, 1766, 1767, 1769, 1770, 1777, 1780, 1781, 1782], "clip_grad_norm_": [1, 53, 1758], "max_norm": [1, 53, 659, 660, 1193, 1194, 1338, 1339, 1429, 1739, 1758], "own": [1, 8, 10, 23, 24, 27, 29, 34, 40, 48, 50, 53, 60, 842, 939, 958, 992, 1030, 1101, 1178, 1179, 1180, 1181, 1182, 1183, 1250, 1434, 1437, 1741, 1755, 1758, 1762, 1781, 1784, 1785, 1789, 1791, 1793], "onc": [1, 2, 8, 10, 15, 20, 21, 23, 24, 27, 29, 30, 32, 33, 35, 40, 41, 48, 53, 56, 57, 59, 60, 744, 745, 746, 748, 750, 905, 1030, 1034, 1101, 1187, 1250, 1423, 1435, 1437, 1503, 1507, 1523, 1635, 1639, 1738, 1741, 1748, 1750, 1751, 1758, 1759, 1761, 1762, 1764, 1767, 1769, 1770, 1780, 1781, 1798], "assign": [1, 2, 8, 10, 11, 20, 23, 39, 48, 49, 57, 60, 1028, 1031, 1158, 1186, 1250, 1257, 1260, 1261, 1424, 1437, 1566, 1567, 1568, 1738, 1742, 1758, 1764, 1765, 1766, 1777, 1784, 1790, 1791, 1797, 1798], "been": [1, 2, 10, 12, 20, 21, 23, 24, 27, 29, 33, 38, 39, 41, 48, 51, 53, 56, 60, 674, 744, 812, 814, 819, 846, 849, 904, 909, 962, 1033, 1034, 1039, 1044, 1101, 1202, 1209, 1220, 1265, 1312, 1347, 1423, 1434, 1439, 1443, 1445, 1463, 1464, 1477, 1497, 1498, 1499, 1505, 1507, 1523, 1684, 1730, 1750, 1751, 1752, 1753, 1758, 1759, 1761, 1762, 1767, 1768, 1770, 1772, 1774, 1776, 1777, 1780, 1781, 1789, 1791, 1793, 1798], "accumul": [1, 2, 3, 33, 38, 53, 127, 266, 289, 294, 295, 297, 444, 602, 740, 754, 1099, 1423, 1478, 1479, 1721, 1738, 1739, 1750, 1759, 1762, 1763, 1766, 1773, 1780, 1785, 1789, 1790, 1793], "twice": [1, 59, 589, 749, 1758, 1759, 1766, 1767], "given": [1, 2, 3, 4, 8, 10, 14, 20, 21, 23, 24, 27, 29, 33, 35, 38, 39, 46, 48, 50, 53, 58, 59, 60, 127, 196, 289, 291, 293, 297, 302, 352, 373, 377, 445, 446, 447, 448, 449, 451, 485, 487, 489, 556, 557, 576, 579, 609, 611, 612, 614, 615, 674, 693, 699, 702, 710, 713, 724, 737, 739, 740, 742, 744, 746, 748, 749, 750, 751, 752, 753, 756, 765, 766, 769, 777, 781, 782, 788, 789, 794, 795, 801, 803, 806, 807, 808, 811, 812, 814, 815, 816, 827, 828, 831, 835, 836, 852, 856, 858, 859, 860, 862, 864, 865, 866, 870, 871, 872, 881, 882, 883, 890, 892, 897, 905, 921, 922, 923, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 945, 961, 969, 970, 996, 1027, 1030, 1037, 1045, 1046, 1051, 1055, 1065, 1067, 1068, 1077, 1079, 1085, 1093, 1102, 1109, 1111, 1112, 1113, 1114, 1117, 1127, 1129, 1131, 1132, 1135, 1148, 1158, 1166, 1167, 1173, 1178, 1179, 1180, 1182, 1183, 1184, 1186, 1187, 1193, 1194, 1198, 1199, 1202, 1210, 1220, 1242, 1246, 1247, 1248, 1250, 1252, 1254, 1255, 1257, 1259, 1261, 1265, 1278, 1284, 1298, 1299, 1302, 1303, 1304, 1312, 1322, 1323, 1324, 1325, 1326, 1327, 1330, 1331, 1338, 1339, 1342, 1343, 1347, 1358, 1382, 1411, 1415, 1416, 1417, 1420, 1421, 1422, 1428, 1433, 1458, 1463, 1464, 1467, 1470, 1471, 1501, 1504, 1506, 1508, 1511, 1516, 1521, 1524, 1531, 1532, 1534, 1548, 1552, 1565, 1568, 1583, 1590, 1591, 1604, 1610, 1615, 1626, 1627, 1658, 1662, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1679, 1684, 1687, 1689, 1696, 1697, 1702, 1704, 1706, 1716, 1721, 1735, 1736, 1738, 1741, 1747, 1749, 1751, 1754, 1755, 1757, 1758, 1759, 1761, 1762, 1763, 1764, 1765, 1767, 1769, 1770, 1774, 1775, 1777, 1780, 1784, 1789, 1790, 1793, 1794, 1795, 1798, 1800, 1803, 1804], "trigger": [1, 8, 10, 23, 32, 33, 38, 48, 53, 59, 198, 880, 1637, 1758, 1762, 1763, 1769, 1775, 1789], "runtimeerror": [1, 2, 14, 23, 27, 57, 60, 65, 555, 613, 744, 776, 953, 1005, 1015, 1030, 1059, 1060, 1061, 1069, 1070, 1071, 1073, 1077, 1083, 1090, 1095, 1096, 1122, 1140, 1250, 1476, 1626, 1721, 1738, 1740, 1741, 1752, 1754, 1758, 1760, 1766, 1774, 1776, 1777, 1784, 1788, 1793, 1796], "spars": [1, 2, 12, 167, 168, 185, 195, 198, 299, 304, 318, 319, 514, 515, 516, 517, 555, 556, 557, 558, 559, 560, 586, 605, 659, 660, 880, 972, 994, 1015, 1102, 1124, 1134, 1150, 1193, 1194, 1283, 1338, 1339, 1364, 1494, 1513, 1626, 1660, 1670, 1671, 1672, 1673, 1674, 1675, 1680, 1689, 1706, 1721, 1736, 1739, 1743, 1747, 1757, 1773, 1774, 1779, 1786, 1796, 1797, 1800], "place": [1, 4, 8, 12, 20, 21, 23, 30, 35, 39, 53, 56, 60, 65, 67, 69, 71, 73, 75, 77, 79, 81, 83, 85, 87, 98, 100, 102, 104, 107, 108, 110, 118, 120, 123, 124, 126, 129, 135, 137, 139, 141, 143, 145, 154, 163, 171, 175, 178, 180, 190, 192, 198, 199, 208, 212, 214, 220, 223, 225, 227, 229, 230, 233, 236, 238, 245, 247, 249, 253, 255, 259, 261, 268, 270, 272, 280, 282, 284, 286, 288, 290, 292, 294, 331, 333, 335, 337, 339, 341, 343, 346, 348, 350, 351, 358, 360, 362, 364, 366, 370, 374, 376, 394, 397, 400, 402, 412, 414, 416, 424, 429, 439, 442, 458, 460, 462, 464, 468, 471, 480, 483, 484, 486, 488, 494, 498, 500, 503, 505, 507, 520, 522, 524, 533, 535, 543, 547, 549, 565, 568, 570, 572, 574, 575, 584, 594, 672, 744, 746, 777, 820, 821, 823, 824, 844, 905, 956, 961, 962, 1030, 1074, 1092, 1140, 1162, 1172, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1195, 1207, 1208, 1209, 1236, 1250, 1267, 1268, 1269, 1270, 1277, 1292, 1332, 1333, 1334, 1335, 1337, 1338, 1339, 1340, 1351, 1354, 1363, 1394, 1396, 1410, 1414, 1418, 1422, 1423, 1429, 1430, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1465, 1529, 1546, 1566, 1567, 1582, 1583, 1615, 1617, 1621, 1622, 1623, 1668, 1702, 1736, 1738, 1740, 1741, 1747, 1753, 1758, 1762, 1764, 1769, 1780, 1781, 1782, 1789, 1790, 1795, 1797, 1799], "replac": [1, 2, 14, 20, 21, 23, 34, 47, 49, 55, 56, 57, 58, 60, 96, 395, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 661, 786, 853, 905, 961, 962, 1035, 1037, 1047, 1119, 1120, 1140, 1144, 1281, 1292, 1418, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1465, 1467, 1523, 1546, 1567, 1583, 1684, 1688, 1694, 1709, 1738, 1739, 1741, 1748, 1762, 1765, 1767, 1769, 1772, 1776, 1777, 1779, 1781, 1784, 1800], "were": [1, 2, 3, 4, 17, 23, 33, 38, 39, 48, 51, 53, 57, 59, 60, 127, 297, 311, 444, 710, 737, 739, 740, 754, 853, 962, 971, 1037, 1101, 1312, 1423, 1429, 1434, 1444, 1461, 1490, 1624, 1628, 1696, 1703, 1728, 1740, 1747, 1758, 1762, 1764, 1775, 1777, 1781], "reduc": [1, 3, 4, 14, 21, 23, 24, 27, 33, 38, 53, 297, 485, 488, 489, 602, 609, 611, 612, 613, 615, 722, 723, 795, 821, 832, 1003, 1082, 1086, 1088, 1093, 1099, 1117, 1127, 1129, 1130, 1132, 1135, 1145, 1146, 1147, 1148, 1166, 1167, 1168, 1169, 1170, 1184, 1186, 1194, 1210, 1216, 1217, 1241, 1242, 1253, 1254, 1255, 1257, 1264, 1281, 1282, 1289, 1298, 1319, 1320, 1328, 1330, 1339, 1355, 1358, 1359, 1360, 1370, 1378, 1379, 1380, 1381, 1382, 1383, 1390, 1400, 1401, 1412, 1415, 1423, 1433, 1468, 1483, 1507, 1521, 1523, 1524, 1547, 1548, 1549, 1550, 1553, 1555, 1623, 1669, 1682, 1683, 1687, 1688, 1707, 1723, 1724, 1737, 1739, 1751, 1752, 1759, 1761, 1763, 1764, 1770, 1774, 1775, 1776, 1779, 1780, 1781, 1782, 1784, 1793, 1804], "occur": [1, 12, 20, 23, 33, 34, 38, 41, 42, 48, 53, 57, 173, 291, 867, 905, 1027, 1033, 1043, 1073, 1173, 1289, 1331, 1470, 1740, 1750, 1753, 1758, 1759, 1762, 1766, 1773, 1777, 1783, 1789, 1791, 1797, 1800, 1804], "increas": [1, 2, 4, 8, 21, 23, 29, 33, 45, 53, 710, 745, 779, 832, 864, 905, 991, 992, 1158, 1167, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1262, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1388, 1389, 1492, 1498, 1499, 1503, 1505, 1507, 1624, 1632, 1707, 1722, 1739, 1761, 1762, 1768, 1785, 1793], "directli": [1, 2, 4, 8, 10, 14, 15, 20, 21, 23, 29, 30, 33, 34, 38, 39, 47, 53, 60, 528, 648, 661, 738, 746, 888, 956, 962, 975, 1060, 1256, 1283, 1302, 1358, 1402, 1459, 1707, 1738, 1740, 1741, 1750, 1759, 1762, 1763, 1764, 1765, 1767, 1769, 1770, 1771, 1772, 1775, 1781, 1783, 1784, 1789, 1793, 1798, 1800], "fill": [1, 23, 35, 131, 150, 234, 235, 236, 262, 293, 297, 352, 375, 418, 419, 420, 422, 427, 454, 580, 595, 766, 893, 906, 908, 959, 960, 1060, 1071, 1073, 1194, 1293, 1339, 1385, 1474, 1475, 1597, 1598, 1599, 1600, 1601, 1602, 1688, 1733, 1734, 1737, 1739, 1745, 1753, 1754, 1757, 1762, 1764, 1775, 1779, 1793, 1800], "further": [1, 2, 5, 10, 14, 21, 23, 59, 975, 1034, 1069, 1158, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1423, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1511, 1737, 1741, 1747, 1770, 1772, 1781, 1783, 1791, 1798, 1803], "floattensor": [1, 23, 297, 460, 602, 603, 604, 605, 606, 755, 756, 763, 977, 1193, 1194, 1253, 1293, 1428, 1630, 1796, 1799], "end": [1, 8, 9, 10, 20, 21, 23, 29, 37, 38, 41, 45, 56, 60, 336, 337, 509, 674, 698, 713, 764, 802, 809, 868, 895, 905, 944, 958, 983, 989, 990, 1027, 1030, 1050, 1055, 1085, 1095, 1097, 1100, 1102, 1116, 1149, 1150, 1165, 1166, 1167, 1184, 1186, 1192, 1196, 1202, 1203, 1206, 1207, 1208, 1209, 1210, 1211, 1217, 1220, 1221, 1236, 1241, 1244, 1245, 1250, 1252, 1257, 1258, 1261, 1265, 1268, 1278, 1281, 1287, 1292, 1299, 1330, 1339, 1351, 1352, 1423, 1432, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493, 1497, 1502, 1529, 1548, 1549, 1604, 1637, 1640, 1643, 1658, 1707, 1718, 1719, 1731, 1737, 1738, 1739, 1740, 1741, 1751, 1758, 1759, 1762, 1763, 1764, 1766, 1767, 1773, 1776, 1777, 1780, 1783, 1784, 1787, 1789, 1794], "float64": [1, 12, 216, 419, 422, 552, 797, 948, 957, 977, 1012, 1030, 1059, 1065, 1066, 1068, 1070, 1086, 1250, 1480, 1517, 1590, 1629, 1630, 1633, 1670, 1671, 1672, 1673, 1674, 1675, 1700, 1726, 1731, 1770, 1773, 1793, 1795, 1796, 1799, 1800, 1805], "variant": [1, 21, 1060, 1071, 1084, 1087, 1147, 1150, 1480, 1481, 1482, 1494, 1583, 1709, 1736, 1737, 1769, 1787, 1799], "suppli": [1, 6, 8, 14, 15, 23, 33, 38, 842, 1741, 1762, 1793], "won": [1, 6, 9, 21, 33, 35, 38, 48, 56, 431, 1030, 1041, 1250, 1383, 1420, 1421, 1735, 1759, 1764, 1789, 1801], "go": [1, 2, 8, 15, 20, 23, 31, 33, 35, 45, 50, 60, 471, 472, 531, 745, 1102, 1163, 1164, 1165, 1243, 1244, 1245, 1740, 1741, 1747, 1751, 1752, 1753, 1759, 1761, 1762, 1764, 1765, 1769, 1770, 1772, 1776, 1777, 1781, 1796, 1798], "addmm": [1, 83, 1680, 1737, 1739, 1752, 1773, 1779, 1793], "c": [1, 2, 4, 9, 10, 14, 20, 23, 29, 33, 34, 35, 36, 38, 46, 56, 60, 236, 311, 471, 492, 589, 601, 725, 728, 746, 774, 785, 788, 803, 844, 850, 897, 900, 905, 951, 952, 953, 962, 963, 967, 970, 973, 983, 1030, 1040, 1052, 1059, 1061, 1065, 1066, 1067, 1068, 1069, 1070, 1075, 1076, 1079, 1081, 1085, 1086, 1088, 1090, 1092, 1093, 1139, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1163, 1164, 1165, 1167, 1168, 1169, 1170, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1186, 1189, 1190, 1191, 1195, 1197, 1198, 1199, 1205, 1213, 1214, 1215, 1218, 1219, 1221, 1222, 1232, 1233, 1234, 1238, 1243, 1244, 1245, 1246, 1247, 1248, 1253, 1254, 1255, 1257, 1262, 1263, 1271, 1272, 1273, 1274, 1275, 1276, 1284, 1289, 1300, 1301, 1302, 1303, 1304, 1305, 1312, 1330, 1331, 1343, 1347, 1382, 1388, 1389, 1432, 1460, 1462, 1469, 1470, 1511, 1549, 1592, 1608, 1646, 1679, 1702, 1719, 1736, 1737, 1738, 1739, 1740, 1741, 1745, 1752, 1753, 1761, 1762, 1763, 1765, 1767, 1769, 1776, 1778, 1781, 1790, 1791, 1793, 1794, 1797, 1798, 1804], "addmm_": [1, 1739, 1752, 1793], "d": [1, 12, 21, 23, 29, 33, 34, 54, 60, 289, 297, 311, 444, 485, 487, 489, 515, 555, 589, 602, 606, 713, 728, 746, 763, 764, 766, 773, 774, 775, 779, 785, 892, 894, 904, 905, 918, 922, 923, 924, 925, 930, 931, 934, 935, 940, 941, 942, 945, 946, 947, 971, 972, 987, 988, 995, 1004, 1027, 1031, 1035, 1072, 1073, 1123, 1134, 1142, 1157, 1165, 1166, 1170, 1180, 1184, 1185, 1189, 1190, 1191, 1193, 1195, 1197, 1202, 1204, 1215, 1220, 1222, 1234, 1245, 1259, 1265, 1289, 1298, 1299, 1301, 1312, 1347, 1358, 1364, 1391, 1414, 1415, 1433, 1464, 1469, 1470, 1492, 1512, 1595, 1604, 1616, 1624, 1629, 1679, 1684, 1695, 1696, 1702, 1705, 1710, 1711, 1712, 1713, 1722, 1728, 1730, 1735, 1739, 1747, 1752, 1753, 1754, 1757, 1759, 1762, 1764, 1765, 1767, 1768, 1775, 1777, 1789, 1790, 1793, 1794, 1798, 1799], "cannot": [1, 4, 9, 10, 20, 21, 23, 29, 30, 34, 41, 48, 53, 54, 57, 58, 59, 60, 62, 63, 199, 230, 495, 516, 728, 926, 928, 936, 937, 938, 944, 961, 1027, 1035, 1140, 1173, 1193, 1302, 1331, 1423, 1476, 1689, 1735, 1738, 1739, 1740, 1741, 1742, 1743, 1750, 1753, 1754, 1759, 1763, 1764, 1775, 1776, 1777, 1784, 1789, 1791, 1793, 1795, 1796, 1804], "best": [1, 2, 8, 15, 17, 20, 23, 29, 33, 36, 49, 53, 56, 759, 782, 1045, 1046, 1075, 1507, 1586, 1587, 1736, 1738, 1740, 1751, 1757, 1758, 1759, 1764, 1766, 1781, 1789, 1793], "stabil": [1, 33, 38, 1061, 1117, 1167, 1168, 1169, 1170, 1204, 1205, 1213, 1214, 1215, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1286, 1289, 1344, 1404, 1433, 1464, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1494, 1592, 1765], "respect": [1, 9, 23, 24, 27, 29, 46, 48, 53, 58, 59, 60, 173, 186, 460, 552, 575, 605, 606, 607, 674, 733, 739, 740, 754, 756, 790, 807, 893, 895, 896, 963, 964, 965, 966, 967, 968, 970, 983, 1030, 1061, 1065, 1066, 1075, 1085, 1088, 1090, 1093, 1102, 1134, 1144, 1166, 1173, 1181, 1182, 1183, 1187, 1202, 1204, 1220, 1250, 1251, 1265, 1295, 1297, 1298, 1299, 1300, 1302, 1347, 1422, 1439, 1443, 1445, 1493, 1507, 1547, 1569, 1663, 1665, 1688, 1702, 1753, 1758, 1762, 1764, 1767, 1770, 1771, 1782, 1787, 1793, 1794, 1795, 1800], "describ": [1, 6, 8, 9, 10, 12, 20, 21, 27, 37, 39, 40, 46, 48, 53, 60, 485, 702, 703, 704, 706, 707, 708, 780, 833, 850, 867, 905, 983, 1050, 1090, 1158, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1188, 1189, 1190, 1191, 1192, 1195, 1197, 1198, 1199, 1205, 1208, 1211, 1213, 1214, 1215, 1217, 1222, 1241, 1243, 1244, 1245, 1256, 1257, 1264, 1268, 1281, 1289, 1298, 1299, 1301, 1330, 1342, 1343, 1352, 1385, 1505, 1569, 1584, 1684, 1707, 1736, 1738, 1740, 1741, 1757, 1758, 1759, 1762, 1763, 1766, 1767, 1769, 1770, 1775, 1777, 1781, 1783, 1784, 1787, 1790, 1791, 1800], "alwai": [1, 8, 14, 16, 20, 21, 23, 46, 50, 53, 60, 316, 421, 431, 728, 745, 748, 754, 764, 773, 783, 789, 853, 864, 892, 900, 921, 922, 924, 925, 926, 927, 928, 936, 937, 938, 939, 941, 944, 948, 987, 988, 1030, 1040, 1045, 1060, 1065, 1066, 1067, 1068, 1070, 1071, 1083, 1086, 1087, 1088, 1089, 1093, 1095, 1146, 1166, 1168, 1169, 1170, 1187, 1213, 1214, 1215, 1223, 1224, 1225, 1232, 1233, 1234, 1250, 1286, 1289, 1418, 1423, 1458, 1612, 1613, 1639, 1684, 1688, 1718, 1721, 1741, 1742, 1751, 1754, 1759, 1760, 1761, 1762, 1763, 1764, 1767, 1769, 1770, 1781, 1782, 1788, 1789, 1791, 1793, 1796, 1799, 1800], "expos": [1, 2, 9, 23, 27, 53, 59, 60, 958, 1759, 1762, 1769, 1781, 1784, 1804], "namespac": [1, 60, 880, 1738, 1742, 1745, 1764, 1770, 1777, 1782, 1787, 1804], "below": [1, 2, 10, 14, 20, 21, 23, 29, 31, 33, 35, 38, 39, 40, 45, 48, 49, 50, 51, 60, 662, 671, 850, 892, 893, 894, 895, 896, 905, 933, 935, 939, 975, 983, 1030, 1046, 1086, 1087, 1092, 1099, 1131, 1181, 1182, 1183, 1202, 1204, 1211, 1220, 1222, 1246, 1247, 1248, 1250, 1265, 1281, 1302, 1330, 1356, 1400, 1423, 1427, 1437, 1469, 1546, 1629, 1668, 1697, 1707, 1710, 1711, 1712, 1713, 1738, 1740, 1741, 1743, 1747, 1751, 1752, 1758, 1759, 1762, 1763, 1764, 1767, 1768, 1770, 1772, 1774, 1775, 1777, 1780, 1781, 1782, 1784, 1786, 1789, 1790, 1791, 1794, 1797, 1800], "defin": [1, 2, 3, 4, 6, 10, 14, 15, 20, 21, 23, 24, 29, 35, 39, 40, 46, 48, 49, 53, 57, 60, 418, 420, 422, 489, 537, 702, 703, 704, 737, 738, 739, 864, 888, 905, 906, 925, 953, 959, 973, 975, 989, 991, 992, 1019, 1030, 1052, 1059, 1061, 1065, 1066, 1067, 1068, 1069, 1070, 1075, 1076, 1079, 1081, 1082, 1086, 1087, 1088, 1090, 1092, 1093, 1099, 1135, 1187, 1192, 1206, 1207, 1208, 1209, 1216, 1218, 1219, 1250, 1256, 1268, 1283, 1285, 1290, 1292, 1312, 1347, 1402, 1418, 1423, 1443, 1445, 1452, 1453, 1471, 1474, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1496, 1497, 1499, 1502, 1505, 1523, 1529, 1531, 1566, 1584, 1585, 1586, 1587, 1597, 1599, 1601, 1608, 1637, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1667, 1694, 1707, 1710, 1711, 1712, 1713, 1731, 1733, 1735, 1738, 1741, 1743, 1745, 1751, 1752, 1754, 1759, 1762, 1763, 1767, 1768, 1770, 1776, 1777, 1780, 1781, 1782, 1783, 1784, 1787, 1789, 1793, 1794, 1799, 1800, 1801, 1804], "unlist": 1, "downstream": [1, 4, 33, 35, 38, 1750], "numer": [1, 20, 29, 33, 38, 54, 58, 603, 755, 756, 779, 1034, 1045, 1046, 1061, 1065, 1066, 1070, 1075, 1083, 1084, 1087, 1090, 1093, 1095, 1117, 1119, 1167, 1168, 1169, 1170, 1205, 1213, 1214, 1215, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1283, 1286, 1289, 1359, 1366, 1402, 1404, 1433, 1464, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1494, 1592, 1624, 1688, 1736, 1741, 1742, 1746, 1748, 1762, 1764, 1765, 1777, 1784, 1794, 1799, 1805], "stabl": [1, 2, 3, 23, 29, 48, 49, 646, 647, 648, 649, 659, 660, 670, 675, 676, 677, 678, 679, 724, 905, 1065, 1066, 1070, 1075, 1083, 1087, 1090, 1093, 1095, 1102, 1167, 1662, 1694, 1736, 1739, 1757, 1760, 1774, 1789], "believ": [1, 9], "unstabl": [1, 29, 1065, 1066, 1093, 1110, 1119, 1366, 1688, 1794], "__matmul__": 1, "addbmm": [1, 77, 763, 1739, 1773, 1779], "addmv": [1, 85, 1739, 1752, 1779], "addr": [1, 87, 1739, 1779], "baddbmm": [1, 129, 1739, 1773, 1779], "bmm": [1, 795, 1721, 1737, 1739, 1752, 1754, 1773, 1774, 1779, 1793], "chain_matmul": [1, 1739, 1779], "multi_dot": [1, 785], "conv1d": [1, 624, 628, 631, 641, 655, 1181, 1189, 1226, 1721, 1739, 1779, 1784, 1786], "conv2d": [1, 625, 629, 632, 634, 642, 656, 702, 1030, 1039, 1041, 1045, 1046, 1182, 1190, 1227, 1250, 1251, 1257, 1278, 1301, 1452, 1546, 1721, 1738, 1739, 1748, 1777, 1779, 1784, 1786, 1787, 1798, 1803], "conv3d": [1, 626, 630, 633, 635, 643, 657, 1183, 1191, 1228, 1721, 1739, 1779, 1784, 1786], "conv_transpose1d": [1, 1739, 1779], "conv_transpose2d": [1, 1739, 1779], "conv_transpose3d": [1, 1739, 1779], "grucel": [1, 1773, 1784, 1786, 1787], "lstmcell": [1, 1773, 1784, 1786, 1787], "matmul": [1, 3, 12, 775, 795, 970, 1134, 1301, 1513, 1523, 1632, 1688, 1694, 1739, 1752, 1754, 1762, 1773, 1779, 1786, 1793], "mv": [1, 12, 1041, 1721, 1739, 1752, 1779, 1793], "prelu": [1, 1251, 1739, 1779, 1786], "rnncell": [1, 1784, 1786, 1787], "__pow__": 1, "__rdiv__": 1, "__rpow__": 1, "__rtruediv__": 1, "aco": [1, 71, 714, 1737, 1739, 1752, 1779, 1800], "asin": [1, 118, 716, 1737, 1739, 1752, 1779, 1793], "cosh": [1, 180, 600, 1737, 1739, 1752, 1779], "cosine_embedding_loss": [1, 1739, 1779], "cdist": [1, 1762, 1779], "cosine_similar": [1, 1299, 1739, 1779], "cross_entropi": [1, 1739], "cumprod": [1, 190, 1739, 1752, 1779], "cumsum": [1, 192, 888, 1721, 1739, 1752, 1779], "dist": [1, 21, 23, 24, 27, 29, 49, 53, 786, 787, 1059, 1065, 1066, 1067, 1069, 1070, 1071, 1075, 1076, 1087, 1088, 1091, 1093, 1094, 1117, 1120, 1259, 1289, 1423, 1432, 1688, 1739, 1763, 1779, 1789, 1791], "erfinv": [1, 227, 1739, 1752, 1779, 1793, 1794], "exp": [1, 2, 29, 229, 684, 750, 751, 753, 948, 1089, 1109, 1117, 1167, 1172, 1186, 1192, 1216, 1239, 1240, 1254, 1264, 1277, 1280, 1282, 1283, 1285, 1286, 1290, 1321, 1367, 1390, 1397, 1398, 1402, 1404, 1407, 1432, 1520, 1646, 1647, 1667, 1684, 1737, 1739, 1752, 1759, 1777, 1779, 1794], "expm1": [1, 233, 1737, 1739, 1752, 1779, 1793, 1794], "group_norm": [1, 1739, 1779, 1786], "hinge_embedding_loss": [1, 1739, 1779], "kl_div": [1, 1739, 1779], "l1_loss": [1, 1739, 1779], "layer_norm": [1, 1222, 1739, 1779, 1786], "log": [1, 14, 20, 21, 29, 32, 33, 35, 38, 39, 41, 42, 45, 46, 50, 351, 352, 915, 1105, 1107, 1109, 1110, 1117, 1158, 1166, 1167, 1186, 1204, 1216, 1239, 1240, 1254, 1257, 1264, 1282, 1283, 1286, 1344, 1349, 1359, 1366, 1367, 1382, 1390, 1402, 1404, 1423, 1736, 1737, 1739, 1750, 1752, 1759, 1762, 1764, 1777, 1778, 1779, 1783, 1794, 1798, 1801, 1802, 1803], "log_softmax": [1, 1173, 1216, 1331, 1382, 1402, 1739, 1753, 1779, 1794], "log10": [1, 346, 1737, 1739, 1752, 1779], "log1p": [1, 348, 1737, 1739, 1752, 1779, 1793, 1794], "log2": [1, 350, 1737, 1739, 1752, 1779, 1794], "margin_ranking_loss": [1, 1739, 1779], "mse_loss": [1, 961, 1739, 1779], "multilabel_margin_loss": [1, 1739, 1779], "multi_margin_loss": [1, 1739, 1779], "nll_loss": [1, 1739, 1779], "norm": [1, 29, 53, 55, 60, 618, 619, 620, 621, 622, 623, 783, 899, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 1061, 1065, 1074, 1075, 1082, 1087, 1099, 1193, 1194, 1241, 1259, 1294, 1295, 1296, 1297, 1298, 1338, 1339, 1383, 1387, 1429, 1433, 1442, 1443, 1448, 1451, 1452, 1464, 1467, 1482, 1609, 1739, 1743, 1758, 1759, 1767, 1770, 1773, 1779], "normal": [1, 2, 21, 27, 48, 53, 60, 312, 327, 352, 427, 527, 807, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 991, 1027, 1030, 1035, 1065, 1107, 1162, 1168, 1169, 1170, 1189, 1190, 1191, 1195, 1205, 1213, 1214, 1215, 1222, 1232, 1233, 1234, 1238, 1277, 1289, 1293, 1294, 1295, 1296, 1297, 1317, 1347, 1348, 1357, 1361, 1365, 1391, 1429, 1430, 1433, 1448, 1456, 1457, 1464, 1467, 1491, 1507, 1592, 1601, 1602, 1609, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1684, 1721, 1735, 1736, 1737, 1738, 1739, 1743, 1752, 1757, 1759, 1762, 1765, 1777, 1779, 1781, 1786, 1789, 1794, 1798, 1800, 1801, 1805], "pdist": [1, 1259, 1739, 1779], "poisson_nll_loss": [1, 1739, 1779], "pow": [1, 2, 442, 468, 748, 749, 752, 948, 1737, 1739, 1741, 1752, 1758, 1759, 1779, 1793, 1799], "prod": [1, 45, 297, 489, 922, 924, 927, 928, 930, 931, 934, 935, 937, 938, 940, 942, 1095, 1096, 1193, 1197, 1301, 1737, 1739, 1752, 1779, 1793], "reciproc": [1, 458, 1619, 1737, 1739, 1752, 1779], "rsqrt": [1, 483, 1737, 1739, 1752, 1779], "sinh": [1, 507, 730, 1737, 1739, 1752, 1779, 1793], "smooth_l1_loss": [1, 1739, 1779], "soft_margin_loss": [1, 1739, 1779], "softmax": [1, 29, 705, 1158, 1186, 1216, 1240, 1284, 1330, 1349, 1359, 1366, 1403, 1664, 1739, 1752, 1753, 1754, 1762, 1779, 1786, 1793, 1794], "softmin": [1, 1739], "softplu": [1, 29, 1249, 1377, 1739, 1779], "sum": [1, 2, 20, 23, 24, 27, 29, 31, 32, 33, 35, 38, 39, 53, 57, 58, 60, 468, 489, 537, 660, 740, 748, 749, 750, 751, 752, 753, 754, 760, 807, 822, 823, 824, 887, 888, 905, 965, 966, 967, 970, 1007, 1061, 1082, 1086, 1099, 1107, 1108, 1109, 1117, 1140, 1148, 1166, 1167, 1173, 1183, 1184, 1186, 1187, 1194, 1197, 1204, 1210, 1211, 1216, 1217, 1218, 1219, 1241, 1242, 1253, 1254, 1255, 1257, 1264, 1281, 1282, 1283, 1285, 1298, 1299, 1301, 1319, 1320, 1330, 1331, 1339, 1344, 1349, 1359, 1368, 1369, 1382, 1390, 1402, 1403, 1423, 1448, 1453, 1454, 1470, 1499, 1610, 1648, 1665, 1667, 1705, 1707, 1721, 1736, 1737, 1739, 1741, 1745, 1750, 1752, 1758, 1759, 1762, 1763, 1764, 1765, 1770, 1773, 1777, 1779, 1789, 1790, 1793, 1794, 1799], "renorm": [1, 464, 1193, 1194, 1338, 1339, 1739, 1779], "tan": [1, 547, 731, 1737, 1739, 1752, 1779, 1793, 1798], "triplet_margin_loss": [1, 1739, 1779], "addcdiv": [1, 79, 1739, 1779], "addcmul": [1, 81, 1739, 1779], "atan2": [1, 123, 719, 1737, 1739, 1752, 1779], "bilinear": [1, 693, 699, 700, 905, 1302, 1303, 1347, 1358, 1415, 1416, 1721, 1739, 1779], "cross": [1, 8, 9, 29, 35, 39, 1166, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1319, 1320, 1330, 1739, 1762, 1776, 1779], "dot": [1, 3, 14, 57, 58, 589, 749, 751, 752, 753, 884, 885, 886, 887, 963, 971, 1007, 1050, 1097, 1098, 1124, 1166, 1167, 1186, 1197, 1210, 1217, 1241, 1256, 1257, 1296, 1299, 1684, 1725, 1726, 1727, 1728, 1739, 1752, 1767, 1779, 1781], "grid_sampl": [1, 1312, 1721, 1739, 1779], "index_put": [1, 1721, 1739, 1779], "scatter_add": [1, 1737, 1739, 1779], "tensordot": [1, 1007, 1095, 1096, 1743, 1762, 1779], "binari": [1, 3, 14, 15, 21, 29, 37, 39, 41, 46, 48, 60, 131, 765, 1123, 1166, 1167, 1256, 1319, 1320, 1428, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1736, 1742, 1752, 1753, 1769, 1777, 1781, 1798], "nativ": [1, 3, 12, 21, 53, 60, 833, 962, 1040, 1632, 1738, 1741, 1751, 1762, 1764, 1781, 1789], "without": [1, 2, 4, 6, 8, 9, 10, 14, 17, 20, 21, 23, 24, 27, 29, 33, 34, 38, 41, 48, 53, 54, 58, 59, 60, 230, 589, 792, 812, 814, 848, 926, 927, 928, 936, 937, 938, 1027, 1028, 1030, 1031, 1076, 1077, 1092, 1099, 1140, 1168, 1169, 1170, 1190, 1194, 1213, 1214, 1215, 1247, 1250, 1258, 1289, 1297, 1339, 1418, 1423, 1449, 1463, 1499, 1595, 1611, 1628, 1629, 1716, 1735, 1740, 1741, 1747, 1748, 1750, 1751, 1753, 1758, 1759, 1760, 1762, 1763, 1764, 1767, 1768, 1770, 1772, 1774, 1775, 1777, 1781, 1782, 1784, 1788, 1789, 1793, 1798, 1803, 1805], "intervent": [1, 9, 1789], "mixtur": [1, 29, 1186, 1330], "bceloss": [1, 1167, 1319], "aren": [1, 9, 57, 60, 962, 1752, 1759, 1790, 1804], "mean": [1, 3, 4, 6, 8, 9, 15, 17, 20, 21, 23, 27, 29, 33, 35, 48, 50, 53, 54, 56, 58, 59, 60, 230, 297, 311, 352, 427, 467, 489, 672, 674, 695, 705, 763, 776, 807, 961, 963, 1040, 1130, 1140, 1145, 1149, 1150, 1156, 1157, 1158, 1160, 1161, 1162, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1184, 1186, 1188, 1192, 1194, 1195, 1196, 1200, 1201, 1202, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1220, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1236, 1237, 1239, 1240, 1241, 1242, 1249, 1253, 1254, 1255, 1257, 1258, 1264, 1265, 1268, 1269, 1270, 1277, 1279, 1280, 1281, 1282, 1283, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1298, 1299, 1300, 1318, 1319, 1320, 1328, 1330, 1331, 1339, 1340, 1344, 1355, 1356, 1359, 1360, 1364, 1370, 1378, 1379, 1380, 1381, 1382, 1390, 1400, 1401, 1412, 1413, 1423, 1471, 1586, 1587, 1592, 1601, 1602, 1646, 1682, 1683, 1689, 1723, 1724, 1735, 1737, 1738, 1739, 1740, 1750, 1751, 1752, 1753, 1754, 1757, 1758, 1759, 1762, 1763, 1764, 1766, 1767, 1770, 1776, 1777, 1779, 1780, 1781, 1783, 1784, 1785, 1786, 1789, 1790, 1791, 1793], "doesn": [1, 2, 3, 8, 9, 12, 20, 23, 56, 57, 59, 60, 744, 754, 812, 832, 962, 971, 1037, 1043, 1069, 1093, 1101, 1110, 1178, 1179, 1180, 1187, 1216, 1283, 1322, 1323, 1324, 1359, 1402, 1423, 1424, 1448, 1483, 1551, 1554, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1663, 1665, 1728, 1737, 1738, 1741, 1742, 1752, 1754, 1759, 1760, 1762, 1764, 1765, 1769, 1772, 1776, 1780, 1782, 1790, 1793], "help": [1, 2, 5, 8, 9, 12, 14, 20, 21, 23, 34, 35, 38, 45, 48, 53, 57, 60, 755, 756, 759, 832, 864, 962, 963, 971, 1030, 1031, 1049, 1131, 1189, 1190, 1191, 1195, 1250, 1432, 1639, 1728, 1735, 1741, 1747, 1752, 1753, 1758, 1759, 1760, 1762, 1763, 1765, 1768, 1770, 1773, 1778, 1781, 1789, 1790, 1793, 1801], "revers": [1, 29, 58, 60, 485, 703, 748, 750, 923, 925, 945, 965, 967, 970, 1097, 1220, 1263, 1389, 1423, 1427, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1455, 1709, 1722, 1739, 1740, 1741, 1759, 1763, 1765, 1779, 1799], "therefor": [1, 4, 6, 20, 21, 23, 29, 30, 35, 46, 53, 56, 421, 754, 764, 773, 853, 939, 956, 958, 987, 988, 1042, 1045, 1075, 1088, 1193, 1194, 1301, 1338, 1339, 1347, 1499, 1741, 1758, 1759, 1762, 1764, 1766, 1769, 1777, 1791], "rais": [1, 2, 6, 8, 14, 23, 27, 29, 35, 38, 39, 41, 48, 53, 57, 59, 60, 65, 289, 291, 297, 613, 746, 748, 749, 750, 751, 752, 753, 755, 756, 776, 785, 813, 876, 948, 953, 1028, 1030, 1035, 1037, 1045, 1047, 1059, 1061, 1069, 1070, 1073, 1077, 1078, 1083, 1090, 1091, 1095, 1096, 1101, 1122, 1250, 1437, 1438, 1443, 1445, 1448, 1458, 1476, 1626, 1721, 1735, 1742, 1747, 1751, 1759, 1762, 1764, 1766, 1773, 1777, 1781, 1782, 1788, 1789, 1800, 1804], "mani": [1, 4, 8, 12, 14, 20, 21, 23, 29, 31, 33, 34, 35, 38, 48, 53, 57, 60, 65, 377, 737, 739, 748, 750, 905, 1042, 1173, 1658, 1703, 1710, 1711, 1712, 1713, 1738, 1740, 1752, 1757, 1759, 1760, 1761, 1762, 1764, 1765, 1769, 1770, 1773, 1777, 1780, 1784, 1791, 1793, 1796, 1798, 1799, 1801], "sigmoid": [1, 29, 60, 498, 674, 1166, 1167, 1193, 1202, 1203, 1220, 1221, 1279, 1319, 1346, 1399, 1737, 1739, 1752, 1753, 1757, 1779, 1786, 1794], "right": [1, 3, 8, 10, 23, 29, 33, 36, 53, 60, 713, 764, 771, 773, 774, 779, 784, 899, 905, 946, 949, 950, 954, 987, 988, 992, 996, 1027, 1049, 1074, 1079, 1090, 1092, 1093, 1101, 1107, 1108, 1140, 1158, 1163, 1164, 1165, 1166, 1167, 1178, 1179, 1180, 1197, 1204, 1217, 1218, 1219, 1238, 1239, 1240, 1241, 1243, 1244, 1245, 1253, 1254, 1255, 1259, 1260, 1266, 1298, 1301, 1302, 1303, 1304, 1347, 1367, 1385, 1430, 1437, 1483, 1497, 1498, 1548, 1604, 1624, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1684, 1702, 1707, 1709, 1722, 1735, 1739, 1741, 1751, 1752, 1753, 1764, 1767, 1777, 1787, 1791, 1794], "entropi": [1, 29, 1166, 1186, 1254, 1319, 1320, 1330, 1794], "combin": [1, 4, 20, 21, 23, 31, 35, 48, 58, 59, 589, 605, 628, 629, 630, 631, 632, 633, 634, 635, 703, 710, 738, 864, 934, 935, 940, 942, 992, 1124, 1134, 1167, 1186, 1197, 1211, 1256, 1301, 1341, 1364, 1444, 1738, 1739, 1740, 1758, 1762, 1765, 1777, 1779, 1782, 1784, 1787, 1789], "bcewithlogitsloss": [1, 1320], "bcewithlogit": 1, "safe": [1, 23, 33, 35, 38, 48, 59, 60, 854, 855, 873, 874, 1423, 1480, 1481, 1738, 1741, 1758, 1759, 1762, 1765, 1769, 1789], "_convolut": [1, 1779], "avg_pool3d": [1, 1739, 1779, 1786], "grid_sampler_2d": [1, 1737, 1739, 1779], "_grid_sampler_2d_cpu_fallback": [1, 1779], "grid_sampler_3d": [1, 1739, 1779], "polar": [1, 29, 1089, 1739, 1779], "quantil": [1, 1130, 1147, 1739, 1779, 1794], "nanquantil": [1, 1739, 1779], "stft": [1, 764, 773, 987, 988, 1027, 1049, 1739, 1779], "view_as_complex": [1, 12, 1739, 1779], "choleski": [1, 3, 29, 787, 788, 1060, 1066, 1102, 1739, 1779], "cholesky_invers": [1, 3, 1739, 1779], "cholesky_solv": [1, 3, 1739, 1779], "invers": [1, 29, 599, 600, 730, 733, 782, 787, 788, 921, 922, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 942, 1027, 1070, 1071, 1083, 1087, 1090, 1095, 1096, 1181, 1182, 1183, 1193, 1194, 1197, 1246, 1247, 1248, 1301, 1338, 1339, 1374, 1375, 1376, 1434, 1437, 1461, 1499, 1505, 1717, 1736, 1739, 1741, 1773, 1779, 1794], "lu_solv": [1, 3, 1077, 1739, 1779], "orgqr": [1, 1739, 1779], "ormqr": [1, 975, 1069, 1739, 1779], "pinvers": [1, 1075, 1739, 1779], "max_pool3d": [1, 1739, 1779, 1786], "max_unpool2d": [1, 1342, 1372, 1739, 1779], "max_unpool3d": [1, 1343, 1373, 1739, 1779], "adaptive_avg_pool3d": [1, 1739, 1764, 1779, 1786], "reflection_pad1d": [1, 1739, 1779], "reflection_pad2d": [1, 1739, 1779], "replication_pad1d": [1, 1739, 1779], "replication_pad2d": [1, 1739, 1779], "replication_pad3d": [1, 1739, 1779], "ctc_loss": [1, 1173, 1739, 1779], "fft_fft": [1, 1739, 1779], "fft_ifft": [1, 1739, 1779], "fft_fft2": [1, 1739, 1779], "fft_ifft2": [1, 1739, 1779], "fft_fftn": [1, 1739, 1779], "fft_ifftn": [1, 1739, 1779], "fft_rfft": [1, 1739, 1779], "fft_irfft": [1, 1739, 1779], "fft_rfft2": [1, 1739, 1779], "fft_irfft2": [1, 1739, 1779], "fft_rfftn": [1, 1739, 1779], "fft_irfftn": [1, 1739, 1779], "fft_hfft": [1, 1739, 1779], "fft_ihfft": [1, 1739, 1779], "linalg_matrix_norm": [1, 1739, 1779], "linalg_cond": [1, 1739, 1779], "linalg_matrix_rank": [1, 1739, 1779], "linalg_solv": [1, 1739, 1779], "linalg_choleski": [1, 1739, 1779], "linalg_svdv": [1, 1739, 1779], "linalg_eigv": [1, 1739, 1779], "linalg_eigvalsh": [1, 1739, 1779], "linalg_inv": [1, 1739, 1779], "linalg_householder_product": [1, 1739, 1779], "linalg_tensorinv": [1, 1739, 1779], "linalg_tensorsolv": [1, 1739, 1779], "fake_quantize_per_tensor_affin": [1, 1739, 1779], "eig": [1, 1066, 1067, 1093, 1773], "geqrf": [1, 1069, 1511, 1739, 1779], "lstsq": [1, 975, 1061, 1087], "_lu_with_info": [1, 1779], "qr": [1, 3, 975, 1065, 1066, 1069, 1075, 1093, 1432, 1511, 1739, 1779], "solv": [1, 8, 12, 33, 788, 975, 1061, 1070, 1072, 1073, 1076, 1077, 1079, 1083, 1091, 1092, 1096, 1102, 1120, 1709, 1759, 1767, 1773, 1776], "svd": [1, 3, 12, 1065, 1066, 1075, 1087, 1094, 1110, 1437, 1513, 1689, 1737, 1739, 1773, 1779, 1793], "symeig": [1, 1739, 1779], "triangular_solv": [1, 1739, 1779], "fractional_max_pool2d": [1, 1739, 1779], "fractional_max_pool3d": [1, 1739, 1779], "adaptive_max_pool3d": [1, 1739, 1779], "multilabel_margin_loss_forward": [1, 1779], "linalg_qr": [1, 1739, 1779], "linalg_cholesky_ex": [1, 1739, 1779], "linalg_svd": [1, 1739, 1779], "linalg_eig": [1, 1739, 1779], "linalg_eigh": [1, 1739, 1779], "linalg_lstsq": [1, 1739, 1779], "linalg_inv_ex": [1, 1739, 1779], "cat": [1, 23, 29, 60, 515, 661, 662, 671, 703, 705, 798, 799, 1131, 1269, 1669, 1737, 1738, 1739, 1752, 1777, 1779, 1781, 1784, 1786, 1793, 1802], "stack": [1, 9, 17, 20, 21, 23, 29, 32, 33, 35, 38, 41, 57, 60, 674, 759, 793, 868, 869, 904, 969, 971, 995, 1131, 1173, 1202, 1220, 1221, 1265, 1294, 1296, 1462, 1728, 1730, 1736, 1739, 1754, 1762, 1763, 1766, 1778, 1779, 1781, 1783, 1786, 1793], "index_copi": [1, 1721, 1739, 1779], "implement": [2, 3, 6, 9, 16, 20, 21, 23, 24, 27, 29, 35, 40, 45, 46, 49, 53, 57, 60, 127, 485, 487, 489, 603, 652, 653, 654, 655, 656, 657, 693, 695, 699, 703, 726, 728, 740, 749, 755, 756, 805, 905, 948, 953, 958, 965, 966, 968, 1030, 1037, 1039, 1040, 1043, 1085, 1088, 1101, 1102, 1130, 1158, 1173, 1187, 1218, 1219, 1250, 1256, 1262, 1269, 1286, 1295, 1297, 1347, 1385, 1404, 1423, 1432, 1433, 1437, 1448, 1461, 1463, 1464, 1467, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1497, 1499, 1505, 1523, 1532, 1547, 1548, 1549, 1552, 1553, 1554, 1595, 1608, 1617, 1620, 1657, 1688, 1689, 1702, 1718, 1721, 1740, 1741, 1742, 1745, 1747, 1751, 1754, 1755, 1757, 1758, 1759, 1761, 1762, 1764, 1765, 1766, 1769, 1770, 1772, 1773, 1774, 1775, 1776, 1780, 1781, 1782, 1784, 1787, 1789, 1790, 1793, 1794, 1797, 1799, 1801, 1804], "arbitrari": [2, 4, 23, 27, 33, 38, 230, 738, 888, 1093, 1101, 1187, 1193, 1217, 1241, 1301, 1319, 1320, 1338, 1359, 1385, 1458, 1688, 1707, 1741, 1759, 1765, 1769, 1770, 1780, 1782, 1784, 1793, 1801, 1804], "scalar": [2, 23, 29, 74, 127, 131, 236, 289, 419, 561, 603, 604, 652, 653, 654, 655, 656, 657, 727, 728, 740, 748, 749, 752, 754, 768, 771, 779, 803, 807, 900, 905, 920, 953, 959, 983, 990, 1007, 1021, 1054, 1055, 1124, 1131, 1147, 1158, 1166, 1167, 1173, 1184, 1186, 1187, 1204, 1210, 1211, 1216, 1217, 1222, 1242, 1253, 1254, 1255, 1257, 1264, 1281, 1282, 1298, 1299, 1349, 1391, 1469, 1474, 1475, 1476, 1507, 1520, 1522, 1524, 1607, 1608, 1624, 1671, 1672, 1673, 1674, 1675, 1700, 1718, 1719, 1731, 1733, 1734, 1737, 1739, 1740, 1741, 1750, 1754, 1757, 1759, 1764, 1767, 1777, 1789, 1793, 1796, 1798, 1800, 1801], "minim": [2, 8, 9, 33, 38, 723, 1132, 1477, 1478, 1479, 1480, 1481, 1482, 1491, 1492, 1493, 1494, 1507, 1547, 1735, 1750, 1758, 1762, 1770, 1772, 1775, 1782, 1784, 1801], "exist": [2, 8, 9, 10, 12, 14, 20, 23, 24, 29, 31, 39, 41, 46, 48, 49, 53, 60, 230, 471, 702, 710, 726, 748, 749, 750, 751, 752, 753, 754, 755, 848, 1030, 1034, 1045, 1065, 1070, 1076, 1077, 1102, 1147, 1250, 1251, 1260, 1735, 1737, 1738, 1745, 1747, 1751, 1752, 1754, 1755, 1759, 1760, 1762, 1764, 1765, 1768, 1769, 1770, 1771, 1773, 1777, 1781, 1782, 1783, 1784, 1789, 1791, 1793, 1797, 1799, 1801], "declar": [2, 10, 14, 20, 49, 1740, 1741, 1742, 1764, 1777, 1781, 1782, 1801], "requires_grad": [2, 6, 29, 32, 58, 311, 418, 419, 420, 421, 422, 460, 468, 713, 728, 744, 746, 747, 755, 756, 764, 773, 853, 906, 907, 908, 909, 918, 923, 941, 958, 959, 960, 963, 971, 987, 988, 1005, 1030, 1049, 1100, 1116, 1166, 1167, 1186, 1193, 1194, 1204, 1216, 1217, 1241, 1242, 1250, 1256, 1257, 1264, 1297, 1298, 1319, 1320, 1330, 1382, 1423, 1424, 1425, 1426, 1463, 1468, 1474, 1475, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1634, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1665, 1670, 1671, 1672, 1673, 1674, 1675, 1700, 1721, 1728, 1733, 1734, 1737, 1739, 1743, 1752, 1753, 1754, 1762, 1764, 1765, 1770, 1775, 1777, 1779, 1789, 1790, 1799, 1800, 1801], "type": [2, 3, 4, 14, 15, 16, 21, 23, 24, 27, 29, 30, 31, 32, 34, 35, 39, 41, 42, 46, 48, 49, 50, 53, 57, 59, 60, 65, 127, 168, 173, 185, 302, 305, 309, 317, 418, 419, 420, 421, 422, 454, 530, 576, 601, 602, 603, 604, 605, 606, 652, 653, 654, 663, 665, 666, 667, 668, 670, 678, 680, 681, 684, 685, 686, 687, 688, 689, 690, 691, 692, 695, 698, 702, 703, 704, 706, 707, 708, 710, 711, 712, 713, 727, 737, 738, 739, 748, 749, 750, 751, 752, 753, 754, 755, 756, 763, 764, 766, 767, 768, 769, 770, 771, 772, 773, 774, 776, 777, 779, 780, 781, 782, 783, 785, 794, 795, 818, 826, 827, 828, 830, 833, 834, 835, 836, 837, 838, 839, 840, 841, 845, 847, 850, 851, 852, 853, 856, 857, 858, 859, 860, 861, 862, 864, 865, 866, 881, 883, 886, 887, 900, 905, 906, 907, 908, 918, 919, 920, 923, 941, 948, 950, 951, 952, 953, 956, 958, 959, 960, 961, 962, 963, 964, 966, 969, 971, 973, 977, 978, 979, 982, 987, 988, 990, 991, 992, 1006, 1009, 1012, 1015, 1026, 1027, 1028, 1030, 1031, 1033, 1036, 1039, 1041, 1043, 1045, 1046, 1048, 1049, 1052, 1061, 1065, 1082, 1086, 1093, 1099, 1100, 1101, 1102, 1116, 1119, 1122, 1129, 1131, 1139, 1145, 1148, 1158, 1162, 1178, 1179, 1180, 1187, 1194, 1240, 1250, 1251, 1252, 1256, 1260, 1261, 1278, 1283, 1284, 1285, 1293, 1294, 1295, 1296, 1297, 1307, 1308, 1312, 1313, 1317, 1319, 1320, 1321, 1322, 1323, 1324, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1340, 1341, 1344, 1346, 1347, 1348, 1349, 1351, 1352, 1353, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1365, 1366, 1368, 1369, 1370, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1390, 1392, 1393, 1395, 1397, 1399, 1400, 1401, 1402, 1403, 1409, 1412, 1413, 1414, 1419, 1420, 1421, 1422, 1423, 1427, 1428, 1429, 1431, 1432, 1433, 1434, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1456, 1457, 1459, 1460, 1461, 1462, 1464, 1465, 1467, 1469, 1470, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1513, 1521, 1522, 1523, 1529, 1547, 1548, 1549, 1550, 1551, 1553, 1555, 1568, 1582, 1583, 1584, 1585, 1586, 1587, 1590, 1591, 1592, 1593, 1594, 1595, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1607, 1608, 1610, 1613, 1614, 1624, 1625, 1628, 1629, 1630, 1632, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1664, 1667, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1684, 1685, 1687, 1688, 1689, 1694, 1700, 1709, 1711, 1713, 1718, 1719, 1722, 1728, 1731, 1733, 1734, 1735, 1736, 1737, 1738, 1742, 1748, 1749, 1750, 1752, 1754, 1757, 1758, 1761, 1762, 1767, 1768, 1769, 1770, 1773, 1776, 1778, 1779, 1782, 1783, 1784, 1786, 1787, 1788, 1789, 1793, 1794, 1795, 1796, 1798, 1800, 1801, 1802, 1803, 1804], "doubl": [2, 4, 39, 454, 460, 589, 663, 665, 666, 667, 668, 670, 680, 681, 695, 744, 746, 751, 755, 756, 780, 787, 797, 808, 853, 920, 948, 983, 1030, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1074, 1075, 1076, 1077, 1079, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1110, 1111, 1112, 1113, 1114, 1120, 1194, 1250, 1307, 1310, 1339, 1418, 1476, 1511, 1517, 1670, 1671, 1672, 1674, 1675, 1688, 1700, 1709, 1731, 1741, 1752, 1762, 1764, 1765, 1773, 1777, 1781, 1795, 1796, 1799, 1801], "bfloat16": [2, 21, 53, 1012, 1030, 1081, 1098, 1250, 1476, 1480, 1632, 1752, 1762, 1795, 1796, 1799, 1800, 1801, 1805], "cfloat": [2, 12, 23, 287, 456, 589, 787, 808, 1000, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1074, 1075, 1076, 1077, 1079, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1120, 1511, 1606, 1688, 1709, 1727, 1796, 1799, 1801], "cdoubl": [2, 12, 787, 808, 1030, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1074, 1075, 1076, 1077, 1079, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1120, 1250, 1511, 1688, 1709, 1796, 1799, 1801], "beta": [2, 12, 54, 59, 76, 77, 82, 83, 84, 85, 86, 87, 128, 129, 297, 489, 525, 602, 605, 606, 607, 763, 809, 842, 843, 850, 851, 853, 987, 1049, 1124, 1134, 1168, 1169, 1170, 1205, 1211, 1213, 1214, 1215, 1222, 1238, 1281, 1286, 1289, 1364, 1365, 1400, 1404, 1480, 1481, 1482, 1484, 1490, 1494, 1592, 1650, 1652, 1663, 1666, 1680, 1736, 1737, 1739, 1748, 1762, 1777, 1784, 1789, 1793, 1796], "even": [2, 9, 20, 21, 23, 34, 35, 39, 53, 59, 60, 515, 552, 706, 707, 708, 740, 807, 921, 922, 923, 924, 925, 926, 927, 928, 936, 937, 938, 941, 970, 1015, 1042, 1059, 1061, 1065, 1066, 1067, 1068, 1082, 1086, 1088, 1089, 1093, 1094, 1099, 1124, 1130, 1187, 1289, 1322, 1323, 1324, 1385, 1423, 1432, 1468, 1470, 1505, 1617, 1628, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1688, 1726, 1738, 1741, 1742, 1750, 1754, 1758, 1759, 1762, 1764, 1766, 1768, 1770, 1772, 1773, 1774, 1775, 1781, 1782, 1791, 1796], "though": [2, 23, 60, 127, 738, 740, 750, 921, 922, 924, 1028, 1031, 1124, 1470, 1738, 1742, 1753, 1754, 1759, 1765, 1772, 1773, 1784], "signatur": [2, 20, 34, 35, 41, 53, 60, 373, 460, 527, 810, 1030, 1250, 1420, 1421, 1422, 1423, 1437, 1458, 1470, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1684, 1762, 1764, 1765, 1777, 1781, 1782, 1789, 1793, 1804], "veri": [2, 5, 8, 9, 17, 20, 21, 23, 33, 34, 35, 38, 58, 60, 805, 963, 969, 971, 1092, 1213, 1214, 1215, 1423, 1424, 1432, 1483, 1505, 1511, 1653, 1657, 1709, 1728, 1740, 1751, 1759, 1764, 1766, 1767, 1768, 1770, 1772, 1773, 1776, 1780, 1781, 1788, 1789, 1790, 1793], "unlik": [2, 4, 8, 29, 34, 53, 58, 465, 902, 941, 944, 948, 1005, 1065, 1066, 1085, 1088, 1093, 1097, 1127, 1130, 1132, 1222, 1425, 1426, 1607, 1629, 1725, 1740, 1741, 1751, 1754, 1762, 1772, 1774, 1796], "coverag": [2, 8, 34, 54, 60, 965, 966, 1736, 1738, 1743, 1753, 1784, 1793, 1804], "plan": [2, 3, 8, 10, 23, 38, 741, 1423, 1523, 1754, 1759, 1764, 1781, 1793], "consid": [2, 6, 9, 21, 23, 39, 48, 53, 57, 59, 60, 610, 693, 699, 748, 750, 751, 755, 788, 807, 892, 893, 894, 895, 896, 926, 961, 1019, 1023, 1026, 1030, 1070, 1072, 1073, 1074, 1075, 1083, 1084, 1087, 1092, 1095, 1186, 1197, 1250, 1253, 1301, 1312, 1347, 1358, 1415, 1424, 1432, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1465, 1493, 1626, 1646, 1694, 1710, 1711, 1712, 1713, 1735, 1738, 1741, 1745, 1747, 1758, 1759, 1760, 1764, 1766, 1767, 1770, 1773, 1781, 1783, 1785, 1790, 1791, 1793, 1796, 1799, 1800, 1804], "ad": [2, 4, 10, 14, 20, 21, 23, 27, 29, 33, 34, 37, 45, 53, 56, 57, 58, 59, 60, 198, 199, 289, 295, 444, 487, 602, 603, 604, 605, 606, 607, 713, 741, 742, 743, 748, 749, 750, 751, 755, 762, 763, 905, 909, 965, 966, 968, 1005, 1030, 1043, 1107, 1163, 1164, 1165, 1167, 1168, 1169, 1170, 1178, 1179, 1180, 1181, 1182, 1183, 1197, 1205, 1213, 1214, 1215, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1256, 1257, 1259, 1264, 1278, 1289, 1293, 1301, 1325, 1326, 1327, 1344, 1371, 1372, 1373, 1419, 1420, 1421, 1422, 1423, 1424, 1428, 1437, 1444, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1468, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1490, 1491, 1492, 1493, 1494, 1592, 1593, 1594, 1634, 1663, 1666, 1680, 1735, 1736, 1737, 1738, 1740, 1745, 1750, 1753, 1758, 1765, 1767, 1769, 1770, 1781, 1784, 1793, 1798], "tutori": [2, 4, 10, 15, 23, 24, 27, 60, 741, 742, 743, 746, 1736, 1738, 1745, 1747, 1755, 1764, 1769, 1770, 1775, 1777, 1784], "how": [2, 4, 6, 8, 9, 10, 15, 16, 20, 23, 34, 35, 37, 40, 48, 49, 50, 53, 54, 55, 57, 60, 699, 702, 703, 705, 741, 742, 743, 746, 888, 909, 962, 969, 983, 1005, 1030, 1040, 1101, 1197, 1250, 1301, 1302, 1385, 1415, 1423, 1458, 1468, 1569, 1584, 1586, 1587, 1608, 1632, 1634, 1647, 1658, 1736, 1738, 1740, 1741, 1745, 1747, 1749, 1751, 1752, 1753, 1755, 1758, 1761, 1763, 1765, 1766, 1767, 1770, 1772, 1774, 1775, 1777, 1782, 1784, 1787, 1789, 1790, 1791, 1798], "major": [2, 7, 8, 9, 10, 33, 34, 835, 1359, 1688, 1736, 1741], "build": [2, 9, 10, 14, 15, 23, 29, 34, 37, 38, 60, 1030, 1039, 1250, 1296, 1312, 1347, 1736, 1738, 1747, 1755, 1759, 1777, 1782, 1784, 1790, 1798, 1799], "basic": [2, 4, 8, 10, 33, 35, 48, 60, 965, 966, 967, 1036, 1102, 1423, 1499, 1736, 1742, 1755, 1760, 1762, 1763, 1767, 1781, 1790, 1797, 1798], "abov": [2, 4, 15, 23, 29, 31, 32, 33, 34, 35, 38, 41, 48, 50, 54, 58, 60, 589, 702, 703, 728, 764, 773, 788, 864, 888, 892, 893, 894, 895, 896, 905, 975, 987, 988, 1030, 1031, 1050, 1061, 1065, 1066, 1084, 1086, 1087, 1090, 1093, 1096, 1099, 1102, 1166, 1197, 1250, 1278, 1286, 1301, 1418, 1471, 1499, 1523, 1599, 1600, 1632, 1637, 1650, 1668, 1684, 1707, 1710, 1711, 1712, 1713, 1735, 1738, 1740, 1741, 1747, 1759, 1760, 1761, 1762, 1764, 1765, 1767, 1770, 1774, 1775, 1777, 1781, 1784, 1789, 1790, 1791, 1793, 1794, 1800], "jacobian": [2, 29, 54, 55, 57, 740, 742, 748, 751, 753, 754, 755, 756, 966, 967, 968, 970, 971, 1728, 1759, 1764, 1767], "hessian": [2, 54, 57, 749, 752, 966, 967, 1757, 1765], "etc": [2, 4, 6, 12, 20, 21, 23, 29, 32, 35, 39, 48, 49, 53, 1027, 1030, 1186, 1250, 1423, 1584, 1585, 1586, 1610, 1735, 1740, 1741, 1747, 1764, 1765, 1766, 1770, 1772, 1777, 1780, 1781, 1784, 1789, 1793, 1795, 1798, 1801], "user": [2, 6, 8, 9, 10, 11, 12, 15, 20, 21, 23, 24, 29, 30, 33, 34, 35, 38, 39, 41, 45, 48, 49, 51, 53, 54, 57, 59, 60, 127, 311, 648, 652, 653, 654, 659, 660, 670, 678, 710, 740, 746, 754, 812, 844, 956, 961, 962, 1030, 1101, 1250, 1293, 1295, 1296, 1297, 1421, 1423, 1434, 1448, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1529, 1531, 1566, 1586, 1587, 1735, 1736, 1738, 1740, 1741, 1745, 1747, 1751, 1753, 1754, 1758, 1759, 1760, 1762, 1764, 1767, 1768, 1769, 1770, 1772, 1777, 1778, 1782, 1783, 1784, 1786, 1789, 1790, 1793, 1797, 1798, 1800, 1804], "input": [2, 3, 4, 6, 10, 12, 15, 18, 20, 21, 23, 24, 27, 29, 30, 38, 41, 53, 54, 55, 56, 57, 58, 60, 65, 127, 236, 256, 277, 456, 489, 581, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 609, 610, 611, 612, 613, 614, 615, 636, 644, 645, 652, 653, 654, 655, 656, 657, 659, 660, 670, 672, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 708, 713, 714, 715, 716, 717, 718, 719, 720, 722, 723, 724, 725, 726, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 744, 746, 748, 749, 750, 751, 752, 753, 754, 755, 756, 759, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 778, 779, 781, 783, 784, 786, 787, 788, 789, 790, 791, 792, 794, 797, 800, 801, 802, 803, 804, 805, 806, 807, 808, 823, 850, 851, 853, 884, 885, 886, 887, 889, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 905, 907, 910, 911, 912, 913, 914, 915, 916, 917, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 960, 961, 962, 963, 964, 965, 966, 967, 968, 971, 972, 973, 974, 975, 976, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1007, 1008, 1009, 1010, 1012, 1015, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1030, 1033, 1034, 1036, 1041, 1043, 1045, 1046, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1117, 1118, 1120, 1122, 1123, 1124, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1262, 1263, 1264, 1265, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1414, 1415, 1416, 1417, 1418, 1420, 1421, 1422, 1423, 1427, 1428, 1435, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1449, 1451, 1452, 1453, 1454, 1458, 1459, 1460, 1462, 1465, 1468, 1469, 1470, 1472, 1473, 1475, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493, 1498, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1523, 1524, 1527, 1528, 1529, 1530, 1531, 1532, 1534, 1546, 1547, 1565, 1566, 1567, 1568, 1582, 1583, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1596, 1598, 1600, 1602, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1619, 1621, 1622, 1623, 1626, 1627, 1629, 1640, 1641, 1642, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1677, 1678, 1679, 1680, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1694, 1695, 1696, 1697, 1698, 1699, 1701, 1703, 1704, 1705, 1706, 1709, 1710, 1712, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1732, 1734, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1745, 1747, 1748, 1753, 1754, 1755, 1757, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1769, 1770, 1773, 1774, 1775, 1777, 1780, 1782, 1783, 1784, 1785, 1787, 1788, 1789, 1790, 1793, 1794, 1796, 1797, 1800, 1802, 1803, 1804], "lambda": [2, 20, 29, 56, 58, 59, 60, 234, 460, 783, 963, 968, 970, 971, 1065, 1066, 1067, 1068, 1101, 1206, 1287, 1299, 1387, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1493, 1499, 1501, 1504, 1728, 1742, 1759, 1764, 1765, 1780, 1781, 1789, 1800, 1804], "f": [2, 11, 21, 23, 29, 35, 39, 40, 45, 46, 54, 55, 57, 58, 59, 60, 150, 234, 262, 311, 352, 742, 743, 923, 925, 932, 941, 962, 963, 965, 966, 967, 968, 970, 971, 983, 1030, 1037, 1040, 1041, 1101, 1216, 1218, 1219, 1221, 1250, 1299, 1314, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1329, 1330, 1331, 1338, 1339, 1342, 1343, 1349, 1382, 1384, 1385, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493, 1620, 1728, 1738, 1740, 1741, 1752, 1753, 1759, 1762, 1764, 1766, 1767, 1768, 1770, 1776, 1777, 1781, 1782, 1793, 1798, 1800, 1804], "three": [2, 7, 10, 23, 27, 53, 55, 57, 60, 736, 903, 905, 983, 992, 1073, 1076, 1077, 1078, 1093, 1121, 1165, 1180, 1183, 1222, 1245, 1432, 1470, 1499, 1632, 1741, 1759, 1762, 1763, 1764, 1777, 1781, 1782, 1784, 1789, 1791, 1793, 1798], "anoth": [2, 8, 20, 21, 23, 29, 30, 33, 35, 39, 50, 53, 60, 459, 809, 811, 812, 814, 956, 1039, 1065, 1066, 1069, 1093, 1193, 1194, 1251, 1260, 1418, 1433, 1628, 1738, 1740, 1741, 1758, 1759, 1761, 1762, 1764, 1770, 1772, 1776, 1781, 1782, 1790, 1791, 1793, 1799, 1801], "constant": [2, 20, 34, 35, 60, 658, 689, 888, 945, 946, 947, 1027, 1030, 1034, 1045, 1077, 1102, 1175, 1176, 1177, 1194, 1197, 1204, 1259, 1281, 1301, 1344, 1347, 1385, 1433, 1491, 1496, 1499, 1549, 1550, 1707, 1739, 1741, 1758, 1764, 1770, 1774, 1777, 1780, 1793], "boolean": [2, 14, 29, 48, 60, 375, 377, 737, 767, 769, 770, 772, 811, 812, 814, 910, 974, 986, 1019, 1020, 1021, 1022, 1023, 1026, 1054, 1102, 1118, 1123, 1151, 1168, 1169, 1170, 1205, 1213, 1214, 1215, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1250, 1289, 1434, 1437, 1523, 1682, 1683, 1694, 1704, 1723, 1724, 1740, 1742, 1764, 1796, 1798, 1799, 1800], "flag": [2, 3, 14, 23, 24, 30, 33, 38, 49, 51, 53, 56, 57, 60, 721, 748, 750, 762, 764, 773, 786, 787, 838, 956, 963, 964, 966, 967, 968, 970, 971, 987, 988, 1005, 1011, 1018, 1121, 1256, 1358, 1359, 1423, 1428, 1434, 1437, 1632, 1634, 1639, 1709, 1721, 1728, 1736, 1738, 1741, 1751, 1759, 1762, 1764, 1773, 1774, 1777, 1781, 1784, 1798, 1799], "inform": [2, 3, 4, 5, 8, 9, 10, 16, 17, 19, 20, 21, 23, 24, 27, 35, 37, 38, 39, 40, 41, 44, 48, 49, 53, 55, 60, 168, 185, 231, 289, 297, 470, 487, 489, 590, 750, 755, 756, 766, 909, 940, 942, 962, 1005, 1027, 1030, 1046, 1059, 1066, 1075, 1178, 1179, 1180, 1181, 1182, 1183, 1211, 1220, 1250, 1256, 1265, 1277, 1293, 1295, 1297, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1339, 1358, 1415, 1416, 1417, 1423, 1428, 1458, 1468, 1522, 1614, 1634, 1639, 1721, 1738, 1741, 1747, 1754, 1755, 1759, 1761, 1762, 1763, 1764, 1769, 1770, 1773, 1778, 1781, 1783, 1784, 1796, 1798, 1799, 1800, 1803, 1805], "well": [2, 4, 6, 8, 10, 14, 21, 23, 31, 37, 48, 53, 57, 58, 60, 589, 850, 966, 967, 1030, 1034, 1040, 1045, 1065, 1066, 1067, 1069, 1075, 1088, 1093, 1168, 1169, 1170, 1186, 1220, 1250, 1289, 1368, 1369, 1423, 1523, 1528, 1550, 1553, 1586, 1738, 1741, 1747, 1752, 1754, 1758, 1759, 1762, 1764, 1765, 1767, 1770, 1772, 1774, 1777, 1781, 1784, 1787, 1789, 1791, 1793, 1797, 1798, 1801], "relat": [2, 7, 8, 10, 20, 23, 39, 52, 57, 983, 1069, 1197, 1281, 1301, 1423, 1513, 1754, 1759, 1781, 1789, 1793, 1794, 1800, 1804], "mechan": [2, 9, 23, 42, 46, 48, 60, 727, 909, 1005, 1030, 1250, 1468, 1634, 1700, 1736, 1751, 1754, 1763, 1764, 1769, 1770, 1787, 1789, 1790], "confus": [2, 9, 35, 1030, 1250, 1759, 1762, 1781, 1793], "receiv": [2, 8, 10, 20, 23, 27, 29, 35, 57, 59, 864, 1030, 1250, 1422, 1423, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1508, 1741, 1750, 1751, 1758, 1772, 1782, 1789, 1790, 1791, 1793], "memori": [2, 3, 4, 6, 12, 21, 27, 29, 30, 33, 34, 53, 60, 127, 132, 147, 149, 152, 155, 156, 157, 172, 183, 186, 216, 230, 243, 273, 301, 307, 313, 315, 316, 368, 418, 419, 420, 421, 422, 431, 436, 459, 471, 472, 495, 496, 552, 575, 589, 677, 726, 728, 740, 746, 755, 756, 777, 792, 795, 809, 810, 813, 816, 817, 819, 832, 833, 842, 843, 846, 850, 852, 853, 856, 858, 859, 860, 862, 863, 864, 865, 866, 870, 871, 872, 876, 905, 906, 907, 908, 956, 957, 958, 960, 961, 962, 967, 971, 1030, 1047, 1075, 1194, 1220, 1221, 1250, 1293, 1294, 1295, 1414, 1423, 1427, 1432, 1458, 1468, 1475, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1597, 1598, 1600, 1601, 1602, 1603, 1700, 1721, 1728, 1734, 1736, 1738, 1748, 1751, 1753, 1754, 1759, 1764, 1772, 1777, 1782, 1783, 1784, 1789, 1793, 1795, 1796, 1797, 1799, 1800], "overlap": [2, 20, 21, 23, 27, 33, 53, 60, 726, 755, 756, 908, 962, 1027, 1197, 1301, 1423, 1684, 1721, 1762, 1763, 1796], "dens": [2, 27, 195, 516, 517, 556, 557, 558, 559, 560, 764, 773, 987, 988, 1049, 1102, 1660, 1663, 1665, 1666, 1669, 1670, 1671, 1672, 1674, 1675, 1680, 1689, 1721, 1754, 1774, 1793, 1796], "stride": [2, 12, 32, 38, 115, 198, 230, 315, 418, 419, 420, 421, 422, 471, 492, 515, 553, 555, 589, 628, 629, 630, 631, 632, 633, 634, 635, 641, 642, 643, 646, 647, 652, 653, 654, 655, 656, 657, 682, 683, 686, 687, 688, 696, 697, 713, 726, 764, 773, 906, 908, 918, 923, 941, 959, 960, 987, 988, 994, 1030, 1039, 1043, 1049, 1100, 1116, 1134, 1163, 1164, 1165, 1178, 1179, 1180, 1181, 1182, 1183, 1197, 1218, 1219, 1226, 1227, 1228, 1229, 1230, 1231, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1262, 1301, 1314, 1315, 1316, 1322, 1323, 1324, 1325, 1326, 1327, 1341, 1368, 1369, 1371, 1372, 1373, 1374, 1375, 1376, 1414, 1423, 1474, 1593, 1594, 1597, 1599, 1600, 1601, 1603, 1604, 1611, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1665, 1694, 1706, 1711, 1713, 1726, 1733, 1737, 1739, 1742, 1752, 1777, 1779, 1789, 1793, 1795, 1796, 1798, 1799, 1800], "thu": [2, 12, 20, 23, 29, 49, 60, 699, 710, 905, 926, 1093, 1124, 1190, 1302, 1415, 1423, 1491, 1550, 1553, 1673, 1738, 1741, 1747, 1748, 1759, 1761, 1766, 1767, 1769, 1770, 1777, 1784, 1789, 1793, 1797, 1799, 1800], "rowmajor": [2, 1423], "contigu": [2, 12, 21, 307, 471, 492, 589, 1196, 1253, 1387, 1423, 1605, 1611, 1688, 1694, 1739, 1753, 1754, 1779, 1786, 1793, 1795, 1797], "create_graph": [2, 127, 740, 748, 749, 750, 751, 752, 753, 754, 1739, 1758], "preserv": [2, 20, 29, 60, 471, 693, 699, 710, 724, 727, 946, 947, 962, 1034, 1040, 1251, 1260, 1302, 1358, 1415, 1620, 1624, 1662, 1700, 1738, 1748, 1752, 1754, 1757, 1762, 1765, 1774, 1777, 1789, 1793, 1796], "attempt": [2, 9, 14, 23, 33, 38, 48, 49, 57, 789, 803, 1034, 1040, 1119, 1425, 1426, 1721, 1738, 1741, 1752, 1753, 1758, 1762, 1764, 1776, 1781, 1789], "guarante": [2, 6, 10, 20, 23, 27, 29, 48, 50, 57, 59, 60, 724, 1030, 1039, 1187, 1250, 1423, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1662, 1721, 1759, 1761, 1762, 1773, 1774, 1781, 1783, 1785, 1789, 1791], "preexist": 2, "behavior": [2, 3, 8, 14, 19, 21, 23, 24, 27, 29, 30, 35, 38, 41, 46, 49, 53, 57, 59, 60, 230, 295, 444, 485, 589, 603, 699, 726, 777, 781, 794, 900, 905, 908, 950, 957, 958, 962, 1030, 1040, 1043, 1045, 1075, 1082, 1086, 1099, 1100, 1101, 1116, 1124, 1131, 1187, 1190, 1211, 1220, 1250, 1265, 1289, 1302, 1312, 1347, 1414, 1415, 1418, 1419, 1423, 1469, 1470, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1517, 1523, 1554, 1604, 1611, 1653, 1688, 1694, 1707, 1721, 1735, 1738, 1742, 1743, 1745, 1752, 1754, 1759, 1760, 1762, 1764, 1765, 1773, 1774, 1775, 1777, 1780, 1781, 1782, 1785, 1786, 1789, 1794, 1797], "let": [2, 8, 9, 20, 21, 29, 31, 34, 35, 38, 49, 57, 60, 459, 468, 790, 983, 1030, 1049, 1059, 1061, 1065, 1066, 1067, 1068, 1069, 1070, 1075, 1076, 1079, 1081, 1088, 1090, 1092, 1093, 1250, 1423, 1432, 1700, 1745, 1752, 1753, 1759, 1762, 1763, 1764, 1765, 1770, 1772, 1773, 1774, 1775, 1776, 1781, 1790, 1791, 1793, 1798], "first": [2, 5, 6, 8, 10, 14, 17, 20, 21, 23, 24, 27, 29, 31, 32, 33, 35, 38, 39, 41, 45, 48, 49, 53, 58, 60, 193, 230, 266, 561, 582, 602, 605, 607, 610, 674, 703, 710, 722, 723, 732, 737, 738, 739, 754, 755, 763, 767, 768, 770, 771, 772, 775, 777, 779, 793, 808, 811, 821, 893, 895, 896, 897, 902, 905, 910, 923, 925, 944, 958, 963, 964, 966, 967, 968, 970, 971, 974, 983, 986, 994, 995, 996, 1007, 1019, 1028, 1037, 1042, 1043, 1049, 1054, 1059, 1062, 1069, 1085, 1088, 1095, 1096, 1098, 1101, 1102, 1118, 1124, 1127, 1130, 1131, 1132, 1134, 1138, 1140, 1146, 1151, 1154, 1158, 1164, 1165, 1171, 1179, 1180, 1182, 1183, 1193, 1194, 1196, 1201, 1202, 1216, 1219, 1220, 1235, 1242, 1244, 1245, 1265, 1278, 1329, 1414, 1418, 1423, 1434, 1435, 1437, 1448, 1458, 1480, 1481, 1482, 1483, 1484, 1490, 1498, 1502, 1505, 1507, 1513, 1523, 1524, 1546, 1582, 1584, 1615, 1616, 1624, 1652, 1665, 1668, 1673, 1701, 1702, 1706, 1711, 1713, 1719, 1722, 1725, 1728, 1730, 1735, 1738, 1740, 1741, 1747, 1749, 1751, 1752, 1754, 1758, 1759, 1762, 1764, 1766, 1767, 1770, 1772, 1773, 1774, 1775, 1776, 1777, 1780, 1782, 1783, 1784, 1789, 1790, 1791, 1793, 1794, 1798, 1802, 1804], "accord": [2, 10, 38, 39, 728, 765, 777, 903, 993, 1090, 1123, 1140, 1158, 1194, 1418, 1423, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1499, 1505, 1524, 1529, 1586, 1587, 1653, 1676, 1701, 1729, 1741, 1750, 1753, 1757, 1770, 1774, 1776, 1781, 1791, 1800], "retain": [2, 10, 23, 609, 611, 612, 615, 722, 723, 728, 1034, 1051, 1082, 1086, 1099, 1117, 1127, 1129, 1130, 1132, 1135, 1145, 1146, 1147, 1148, 1470, 1521, 1524, 1620, 1682, 1683, 1687, 1710, 1711, 1712, 1713, 1723, 1724, 1751, 1772], "over": [2, 10, 20, 21, 23, 24, 29, 33, 35, 38, 39, 46, 49, 53, 54, 55, 56, 57, 58, 60, 454, 613, 652, 653, 654, 655, 656, 657, 680, 681, 686, 687, 688, 696, 697, 759, 782, 864, 866, 883, 884, 885, 886, 887, 905, 961, 965, 967, 969, 971, 983, 991, 1030, 1045, 1062, 1082, 1086, 1098, 1099, 1101, 1109, 1129, 1131, 1148, 1155, 1156, 1157, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1194, 1197, 1198, 1199, 1205, 1210, 1211, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1222, 1238, 1241, 1242, 1243, 1244, 1245, 1250, 1253, 1254, 1255, 1257, 1264, 1278, 1281, 1282, 1284, 1289, 1298, 1301, 1306, 1307, 1308, 1309, 1310, 1311, 1314, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1330, 1331, 1342, 1343, 1359, 1365, 1368, 1369, 1371, 1372, 1373, 1382, 1383, 1390, 1421, 1429, 1467, 1593, 1594, 1609, 1667, 1669, 1682, 1683, 1684, 1687, 1702, 1717, 1723, 1724, 1728, 1741, 1750, 1751, 1752, 1753, 1758, 1760, 1761, 1763, 1764, 1765, 1767, 1770, 1772, 1773, 1780, 1789, 1790, 1793, 1801], "time": [2, 4, 5, 8, 9, 10, 14, 20, 21, 23, 24, 27, 29, 30, 31, 32, 33, 35, 36, 38, 39, 45, 48, 49, 50, 57, 59, 60, 65, 266, 289, 460, 465, 589, 601, 602, 603, 604, 605, 606, 607, 610, 659, 660, 670, 674, 678, 682, 683, 725, 754, 760, 763, 775, 783, 785, 800, 807, 811, 812, 814, 853, 866, 883, 886, 897, 926, 927, 928, 934, 945, 946, 947, 955, 958, 967, 968, 970, 971, 1019, 1027, 1030, 1037, 1042, 1045, 1046, 1050, 1055, 1059, 1060, 1061, 1065, 1066, 1067, 1068, 1069, 1070, 1074, 1075, 1076, 1079, 1081, 1085, 1088, 1090, 1092, 1093, 1101, 1102, 1124, 1134, 1139, 1140, 1142, 1152, 1160, 1161, 1163, 1164, 1165, 1167, 1168, 1169, 1170, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1187, 1194, 1197, 1198, 1199, 1202, 1213, 1214, 1215, 1220, 1222, 1236, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1262, 1263, 1265, 1286, 1289, 1301, 1302, 1303, 1304, 1312, 1315, 1316, 1342, 1343, 1387, 1388, 1389, 1404, 1420, 1421, 1422, 1423, 1432, 1433, 1435, 1437, 1469, 1501, 1511, 1512, 1523, 1531, 1533, 1552, 1569, 1610, 1616, 1665, 1679, 1684, 1685, 1702, 1728, 1736, 1740, 1741, 1742, 1748, 1751, 1757, 1759, 1761, 1763, 1764, 1766, 1767, 1769, 1770, 1772, 1774, 1776, 1777, 1780, 1781, 1782, 1783, 1784, 1785, 1789, 1790, 1791, 1793, 1798, 1803], "4": [2, 4, 12, 17, 18, 20, 21, 23, 27, 29, 30, 32, 33, 35, 38, 39, 46, 48, 57, 60, 168, 185, 218, 230, 265, 287, 289, 291, 293, 297, 418, 419, 444, 456, 460, 465, 468, 471, 485, 489, 508, 515, 527, 529, 531, 579, 589, 599, 600, 601, 602, 605, 607, 608, 609, 611, 612, 613, 615, 653, 655, 656, 657, 660, 662, 671, 674, 687, 688, 713, 722, 723, 724, 729, 730, 731, 732, 733, 735, 736, 746, 748, 751, 752, 753, 763, 766, 769, 773, 774, 775, 779, 781, 784, 785, 788, 789, 790, 793, 797, 802, 803, 804, 805, 808, 885, 888, 895, 897, 899, 900, 903, 904, 905, 908, 910, 920, 921, 923, 925, 933, 939, 941, 944, 945, 946, 947, 948, 949, 950, 953, 955, 956, 958, 961, 963, 969, 970, 971, 972, 973, 974, 983, 986, 990, 991, 992, 993, 995, 996, 1000, 1004, 1007, 1019, 1021, 1027, 1036, 1041, 1043, 1050, 1051, 1052, 1053, 1054, 1055, 1059, 1061, 1062, 1068, 1070, 1072, 1073, 1074, 1077, 1079, 1082, 1084, 1086, 1088, 1090, 1092, 1095, 1096, 1097, 1099, 1100, 1103, 1105, 1106, 1111, 1113, 1114, 1116, 1118, 1123, 1124, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1138, 1139, 1140, 1148, 1149, 1150, 1151, 1158, 1163, 1174, 1175, 1176, 1179, 1180, 1182, 1183, 1191, 1193, 1194, 1195, 1197, 1201, 1202, 1220, 1221, 1246, 1247, 1253, 1255, 1257, 1262, 1263, 1265, 1271, 1272, 1273, 1274, 1275, 1289, 1301, 1302, 1303, 1304, 1305, 1312, 1314, 1323, 1326, 1338, 1339, 1347, 1358, 1382, 1385, 1388, 1389, 1414, 1415, 1416, 1417, 1418, 1423, 1432, 1437, 1448, 1460, 1461, 1463, 1469, 1470, 1471, 1473, 1475, 1477, 1490, 1495, 1496, 1502, 1506, 1507, 1508, 1512, 1516, 1517, 1520, 1521, 1523, 1524, 1552, 1591, 1595, 1597, 1599, 1601, 1603, 1604, 1605, 1606, 1607, 1608, 1610, 1611, 1615, 1616, 1617, 1619, 1620, 1624, 1637, 1644, 1646, 1647, 1652, 1653, 1655, 1657, 1662, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1684, 1687, 1690, 1691, 1694, 1696, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1707, 1710, 1711, 1712, 1713, 1715, 1716, 1717, 1719, 1720, 1721, 1722, 1725, 1726, 1727, 1728, 1729, 1730, 1734, 1738, 1739, 1740, 1741, 1742, 1747, 1751, 1753, 1754, 1757, 1759, 1760, 1762, 1763, 1764, 1770, 1772, 1775, 1776, 1777, 1778, 1781, 1782, 1784, 1786, 1789, 1793, 1794, 1796, 1797, 1798, 1799, 1800, 1803], "fact": [2, 4, 9, 53, 467, 764, 773, 801, 983, 987, 988, 1065, 1066, 1093, 1738, 1764, 1767, 1777, 1790, 1793], "phase": [2, 21, 33, 38, 1065, 1066, 1505, 1688, 1739, 1776], "recreat": [2, 1759], "everi": [2, 3, 9, 10, 20, 21, 23, 27, 29, 33, 35, 38, 39, 53, 57, 60, 454, 460, 582, 695, 744, 888, 905, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 962, 983, 992, 1030, 1061, 1075, 1085, 1088, 1119, 1162, 1188, 1189, 1190, 1191, 1195, 1243, 1250, 1283, 1285, 1289, 1333, 1334, 1335, 1340, 1371, 1372, 1373, 1387, 1403, 1420, 1421, 1422, 1423, 1433, 1464, 1467, 1468, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1547, 1688, 1719, 1741, 1750, 1758, 1759, 1762, 1763, 1764, 1765, 1767, 1771, 1777, 1780, 1781, 1782, 1783, 1784, 1785, 1789, 1790, 1791, 1795, 1798, 1800], "altern": [2, 10, 20, 23, 33, 37, 60, 965, 966, 992, 1037, 1101, 1278, 1295, 1297, 1366, 1423, 1475, 1546, 1631, 1721, 1734, 1735, 1742, 1759, 1768, 1770, 1773, 1774, 1776], "never": [2, 6, 8, 21, 23, 48, 49, 198, 199, 727, 783, 1027, 1076, 1077, 1088, 1101, 1423, 1458, 1759, 1762, 1764, 1781, 1782, 1789, 1800], "long": [2, 8, 10, 20, 33, 38, 48, 59, 663, 665, 666, 667, 668, 670, 677, 695, 962, 1006, 1130, 1135, 1146, 1173, 1186, 1194, 1220, 1221, 1257, 1331, 1427, 1476, 1522, 1697, 1701, 1711, 1713, 1718, 1736, 1741, 1747, 1751, 1752, 1753, 1759, 1760, 1762, 1764, 1766, 1772, 1774, 1777, 1781, 1783, 1788, 1795, 1796, 1798, 1799], "hard": [2, 8, 9, 23, 33, 34, 49, 905, 1102, 1206, 1349, 1350, 1738, 1739, 1740, 1759, 1777, 1781], "matter": [2, 5, 23, 53, 744, 893, 905, 1037, 1040, 1045, 1423, 1754, 1759, 1781], "discourag": [2, 875, 879, 1759, 1789], "most": [2, 4, 5, 8, 9, 15, 20, 23, 27, 29, 30, 32, 33, 34, 35, 38, 39, 40, 47, 48, 50, 51, 57, 58, 59, 60, 471, 703, 744, 745, 746, 751, 755, 759, 875, 888, 905, 962, 1005, 1015, 1028, 1031, 1135, 1158, 1297, 1347, 1423, 1437, 1488, 1707, 1735, 1738, 1740, 1741, 1743, 1747, 1751, 1753, 1754, 1759, 1762, 1764, 1772, 1773, 1774, 1780, 1783, 1784, 1790, 1791, 1793, 1796, 1798, 1800], "aggress": [2, 33, 1027, 1759, 1789], "buffer": [2, 5, 20, 21, 23, 33, 53, 728, 821, 853, 958, 961, 969, 1030, 1037, 1040, 1051, 1101, 1168, 1169, 1170, 1187, 1223, 1224, 1225, 1250, 1289, 1423, 1425, 1434, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1455, 1463, 1465, 1491, 1620, 1662, 1704, 1740, 1755, 1759, 1763, 1764, 1770, 1775, 1777, 1782], "free": [2, 8, 23, 29, 39, 48, 49, 60, 859, 876, 1033, 1045, 1102, 1748, 1757, 1759, 1762, 1764, 1766, 1772, 1776, 1777], "reus": [2, 23, 33, 38, 60, 459, 1737, 1759, 1762, 1789], "make": [2, 3, 4, 5, 6, 9, 14, 15, 20, 21, 23, 26, 29, 33, 34, 36, 37, 38, 39, 40, 45, 48, 49, 50, 51, 53, 57, 60, 116, 199, 468, 693, 699, 740, 786, 787, 788, 811, 812, 814, 893, 909, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 945, 946, 947, 1005, 1030, 1034, 1039, 1040, 1059, 1060, 1072, 1073, 1074, 1102, 1166, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1211, 1250, 1260, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1347, 1349, 1358, 1415, 1423, 1432, 1448, 1463, 1468, 1501, 1586, 1587, 1629, 1662, 1670, 1671, 1672, 1674, 1675, 1694, 1704, 1721, 1735, 1738, 1740, 1741, 1745, 1750, 1751, 1752, 1754, 1758, 1759, 1760, 1762, 1763, 1764, 1765, 1766, 1767, 1770, 1772, 1774, 1776, 1777, 1780, 1781, 1783, 1784, 1785, 1789, 1790, 1791, 1793, 1796, 1798, 1802, 1804], "effici": [2, 3, 4, 9, 12, 20, 29, 53, 54, 58, 127, 740, 745, 754, 785, 975, 1047, 1085, 1102, 1121, 1158, 1189, 1190, 1191, 1194, 1195, 1256, 1262, 1263, 1297, 1748, 1754, 1759, 1763, 1764, 1767, 1771, 1773, 1782, 1784, 1789, 1790, 1793, 1796, 1797, 1801], "few": [2, 8, 9, 21, 33, 34, 35, 38, 39, 905, 962, 1194, 1423, 1735, 1741, 1759, 1762, 1764, 1766, 1768, 1773, 1776, 1777, 1782, 1784, 1787, 1797, 1799, 1801], "occas": [2, 8, 1759], "actual": [2, 9, 33, 34, 35, 39, 41, 53, 57, 60, 800, 923, 941, 1041, 1045, 1181, 1182, 1183, 1347, 1423, 1449, 1499, 1527, 1735, 1740, 1741, 1752, 1762, 1763, 1764, 1767, 1772, 1776, 1784, 1789, 1795, 1800], "signific": [2, 4, 34, 1507, 1759, 1762, 1793], "amount": [2, 3, 4, 5, 8, 20, 23, 38, 39, 48, 60, 756, 832, 858, 860, 864, 1027, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1197, 1238, 1253, 1301, 1330, 1442, 1443, 1445, 1446, 1448, 1450, 1451, 1452, 1453, 1454, 1455, 1753, 1759, 1761, 1762, 1765, 1766, 1768, 1789, 1793], "heavi": [2, 23, 1759, 1776], "pressur": [2, 1759], "might": [2, 4, 5, 10, 14, 15, 17, 23, 27, 29, 33, 34, 35, 38, 48, 57, 59, 60, 127, 459, 740, 808, 1045, 1046, 1347, 1423, 1424, 1735, 1738, 1750, 1754, 1759, 1761, 1762, 1763, 1764, 1767, 1769, 1774, 1777, 1781, 1782, 1784, 1789, 1790, 1791, 1793, 1797, 1799, 1800], "keep": [2, 4, 8, 20, 21, 27, 35, 39, 48, 53, 812, 1101, 1168, 1169, 1170, 1174, 1193, 1213, 1214, 1215, 1259, 1289, 1347, 1358, 1423, 1444, 1609, 1735, 1736, 1738, 1751, 1753, 1754, 1759, 1762, 1763, 1765, 1766, 1767, 1772, 1778, 1780, 1784, 1789, 1790, 1791], "track": [2, 6, 33, 35, 39, 311, 817, 856, 858, 870, 871, 872, 961, 962, 1005, 1131, 1168, 1169, 1170, 1213, 1214, 1215, 1223, 1224, 1225, 1232, 1233, 1234, 1289, 1423, 1444, 1750, 1751, 1753, 1754, 1759, 1762, 1764, 1765, 1766, 1769, 1770, 1778, 1780, 1782, 1783, 1790, 1791, 1793], "afterward": [2, 1250, 1418, 1423, 1778], "start": [2, 4, 5, 9, 10, 12, 20, 21, 23, 33, 37, 39, 45, 47, 48, 49, 50, 53, 59, 60, 407, 408, 468, 509, 614, 713, 856, 858, 869, 870, 871, 927, 928, 944, 958, 1028, 1042, 1055, 1100, 1116, 1149, 1150, 1158, 1163, 1164, 1165, 1194, 1196, 1243, 1244, 1245, 1251, 1253, 1339, 1385, 1423, 1439, 1443, 1445, 1458, 1477, 1499, 1505, 1604, 1635, 1658, 1670, 1671, 1672, 1674, 1675, 1735, 1736, 1737, 1739, 1740, 1745, 1747, 1751, 1753, 1759, 1760, 1762, 1763, 1766, 1770, 1771, 1772, 1776, 1777, 1778, 1780, 1783, 1789, 1790, 1791, 1793], "sure": [2, 8, 10, 20, 23, 30, 33, 37, 38, 40, 49, 51, 53, 56, 60, 740, 909, 956, 1005, 1034, 1045, 1046, 1102, 1423, 1468, 1501, 1586, 1587, 1704, 1741, 1752, 1759, 1763, 1766, 1767, 1776, 1777, 1783, 1784, 1789, 1790, 1791, 1798], "longer": [2, 23, 38, 50, 57, 603, 738, 755, 756, 1027, 1034, 1423, 1470, 1750, 1759, 1762, 1789, 1791], "find": [2, 8, 14, 23, 33, 35, 38, 48, 57, 60, 905, 983, 1051, 1102, 1181, 1182, 1183, 1220, 1513, 1524, 1624, 1689, 1735, 1748, 1751, 1753, 1759, 1761, 1762, 1763, 1764, 1766, 1767, 1772, 1774, 1777, 1779, 1784, 1789, 1793, 1796, 1798, 1800, 1802, 1804], "quick": [2, 8, 56, 1747, 1770], "guid": [2, 9, 10, 20, 35, 1041, 1736, 1762, 1765, 1781, 1784], "expect": [2, 4, 6, 8, 10, 20, 21, 23, 27, 33, 38, 39, 46, 48, 50, 53, 57, 58, 60, 613, 674, 710, 748, 749, 750, 751, 752, 753, 853, 926, 928, 945, 946, 947, 966, 967, 1004, 1027, 1030, 1045, 1046, 1074, 1095, 1096, 1130, 1169, 1170, 1186, 1202, 1203, 1204, 1205, 1214, 1215, 1216, 1220, 1221, 1222, 1232, 1233, 1234, 1250, 1256, 1257, 1265, 1267, 1283, 1289, 1293, 1295, 1297, 1302, 1344, 1358, 1382, 1390, 1391, 1402, 1415, 1416, 1417, 1418, 1423, 1459, 1508, 1629, 1695, 1726, 1735, 1736, 1743, 1759, 1762, 1763, 1766, 1767, 1770, 1777, 1780, 1781, 1784, 1785, 1786, 1793, 1798, 1800], "instead": [2, 4, 6, 9, 10, 14, 20, 21, 23, 29, 33, 35, 39, 45, 48, 49, 53, 56, 57, 60, 198, 381, 431, 471, 662, 671, 682, 683, 703, 708, 728, 738, 748, 749, 750, 751, 754, 755, 779, 785, 940, 942, 966, 967, 968, 970, 971, 976, 1017, 1028, 1030, 1031, 1035, 1059, 1060, 1066, 1068, 1084, 1087, 1093, 1099, 1130, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1184, 1186, 1187, 1189, 1190, 1191, 1195, 1202, 1210, 1216, 1217, 1218, 1219, 1220, 1241, 1242, 1243, 1244, 1245, 1250, 1253, 1254, 1255, 1257, 1264, 1265, 1277, 1281, 1282, 1283, 1289, 1298, 1314, 1315, 1316, 1319, 1320, 1330, 1340, 1347, 1359, 1371, 1372, 1373, 1382, 1390, 1402, 1423, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1498, 1499, 1505, 1554, 1593, 1594, 1604, 1624, 1628, 1669, 1684, 1688, 1721, 1728, 1738, 1740, 1741, 1747, 1753, 1757, 1758, 1759, 1763, 1764, 1765, 1766, 1767, 1768, 1772, 1774, 1775, 1776, 1777, 1780, 1781, 1783, 1784, 1790, 1793, 1800, 1803, 1804], "var": [2, 35, 41, 46, 48, 51, 1168, 1169, 1170, 1204, 1205, 1213, 1214, 1215, 1222, 1289, 1344, 1592, 1724, 1737, 1739, 1741, 1752, 1779], "detach": [2, 6, 199, 421, 431, 792, 961, 1030, 1173, 1250, 1331, 1349, 1700, 1738, 1739, 1752, 1754, 1766, 1777, 1779, 1786, 1793, 1797, 1799], "register_hook": [2, 1752, 1759], "factori": [2, 3, 12, 29, 39, 42, 46, 57, 905, 1552, 1628, 1736, 1739, 1753, 1762, 1779, 1796], "ones": [2, 20, 23, 27, 29, 33, 38, 53, 57, 58, 59, 60, 127, 230, 289, 377, 418, 419, 421, 487, 740, 749, 751, 752, 753, 754, 755, 765, 777, 888, 896, 918, 961, 968, 970, 1005, 1027, 1030, 1041, 1050, 1076, 1092, 1101, 1167, 1193, 1197, 1204, 1205, 1222, 1250, 1254, 1255, 1257, 1259, 1301, 1414, 1418, 1423, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1448, 1449, 1462, 1465, 1475, 1476, 1584, 1592, 1609, 1627, 1658, 1703, 1707, 1731, 1739, 1741, 1743, 1752, 1753, 1759, 1760, 1762, 1764, 1771, 1773, 1774, 1777, 1779, 1780, 1781, 1784, 1789, 1791, 1794, 1796, 1799], "autograd_tensor": 2, "base": [2, 4, 8, 10, 14, 15, 20, 23, 24, 27, 29, 32, 33, 34, 35, 39, 41, 46, 48, 49, 50, 53, 57, 60, 705, 746, 762, 807, 868, 869, 903, 905, 948, 983, 993, 1032, 1043, 1055, 1093, 1104, 1106, 1108, 1116, 1187, 1250, 1253, 1254, 1255, 1259, 1293, 1295, 1297, 1364, 1423, 1432, 1439, 1443, 1445, 1477, 1478, 1479, 1480, 1481, 1482, 1491, 1492, 1493, 1494, 1520, 1528, 1532, 1534, 1548, 1549, 1550, 1552, 1553, 1586, 1587, 1595, 1620, 1634, 1688, 1689, 1701, 1711, 1713, 1729, 1736, 1739, 1741, 1761, 1762, 1763, 1764, 1770, 1778, 1782, 1783, 1784, 1789, 1790, 1793, 1794, 1797, 1798, 1800, 1802, 1803], "static": [2, 4, 9, 14, 24, 29, 32, 35, 39, 53, 706, 708, 737, 738, 739, 795, 1043, 1293, 1423, 1554, 1582, 1584, 1586, 1738, 1739, 1740, 1741, 1762, 1769, 1778, 1782, 1785, 1789, 1795], "Then": [2, 23, 49, 60, 1197, 1301, 1434, 1760, 1763, 1764, 1765, 1773, 1774, 1777, 1780, 1781, 1789, 1790, 1802], "ctx": [2, 46, 737, 738, 739, 744, 745, 746, 747, 1758, 1764, 1765, 1777], "gradcheck": [2, 756, 1736, 1764], "extend": [2, 20, 23, 29, 40, 50, 60, 738, 746, 1252, 1261, 1586, 1736, 1745, 1759, 1769, 1771, 1772, 1777, 1779, 1781, 1787, 1793, 1804], "staticmethod": [2, 738, 744, 745, 746, 747, 1741, 1758, 1764, 1777, 1789], "i": [2, 6, 8, 9, 10, 14, 20, 21, 23, 24, 27, 29, 30, 48, 51, 53, 56, 57, 60, 65, 127, 130, 131, 289, 291, 297, 485, 487, 489, 515, 589, 597, 599, 600, 602, 614, 675, 677, 679, 713, 729, 730, 731, 732, 733, 740, 748, 750, 755, 756, 765, 766, 779, 784, 785, 801, 802, 804, 805, 807, 839, 877, 897, 905, 915, 921, 922, 923, 924, 925, 927, 928, 930, 931, 933, 934, 935, 937, 938, 939, 940, 942, 949, 954, 956, 958, 967, 969, 972, 996, 1009, 1010, 1012, 1015, 1027, 1030, 1049, 1058, 1065, 1066, 1067, 1068, 1069, 1070, 1077, 1093, 1098, 1102, 1103, 1104, 1106, 1109, 1117, 1119, 1124, 1135, 1158, 1166, 1167, 1168, 1169, 1170, 1178, 1179, 1180, 1182, 1183, 1186, 1187, 1189, 1190, 1191, 1193, 1194, 1195, 1196, 1197, 1203, 1217, 1221, 1222, 1223, 1224, 1225, 1240, 1241, 1250, 1252, 1253, 1254, 1255, 1256, 1257, 1259, 1261, 1264, 1267, 1282, 1283, 1285, 1289, 1293, 1297, 1298, 1299, 1300, 1301, 1322, 1323, 1324, 1333, 1334, 1335, 1338, 1339, 1340, 1358, 1382, 1390, 1402, 1415, 1417, 1418, 1422, 1423, 1428, 1432, 1433, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1458, 1459, 1463, 1484, 1492, 1498, 1516, 1524, 1583, 1595, 1601, 1604, 1607, 1619, 1624, 1640, 1642, 1648, 1655, 1657, 1667, 1668, 1669, 1673, 1677, 1682, 1683, 1684, 1688, 1694, 1698, 1699, 1707, 1710, 1711, 1712, 1713, 1723, 1724, 1725, 1736, 1738, 1739, 1740, 1741, 1742, 1748, 1751, 1752, 1753, 1754, 1758, 1760, 1761, 1762, 1764, 1766, 1767, 1770, 1775, 1776, 1777, 1784, 1789, 1791, 1793, 1794, 1796, 1798, 1800, 1805], "result": [2, 4, 5, 8, 9, 10, 14, 17, 20, 21, 23, 29, 35, 38, 39, 41, 46, 49, 53, 57, 58, 59, 60, 130, 198, 199, 230, 231, 291, 311, 373, 468, 470, 527, 555, 590, 602, 603, 604, 605, 606, 609, 611, 612, 613, 615, 674, 703, 725, 727, 742, 743, 748, 749, 750, 751, 752, 753, 755, 756, 763, 766, 777, 781, 786, 792, 794, 803, 805, 820, 822, 824, 850, 851, 864, 884, 885, 886, 887, 888, 900, 905, 923, 926, 932, 941, 948, 950, 953, 957, 958, 961, 962, 963, 966, 967, 970, 971, 975, 991, 992, 994, 1007, 1021, 1030, 1033, 1034, 1041, 1045, 1046, 1048, 1050, 1051, 1055, 1069, 1071, 1073, 1074, 1082, 1086, 1088, 1090, 1091, 1092, 1099, 1109, 1110, 1117, 1127, 1129, 1130, 1131, 1132, 1134, 1135, 1145, 1148, 1187, 1189, 1190, 1191, 1195, 1197, 1202, 1216, 1220, 1250, 1265, 1301, 1329, 1347, 1358, 1411, 1414, 1415, 1423, 1432, 1434, 1465, 1468, 1469, 1470, 1471, 1505, 1511, 1513, 1520, 1521, 1524, 1595, 1608, 1614, 1629, 1657, 1666, 1668, 1669, 1680, 1682, 1683, 1684, 1687, 1688, 1689, 1696, 1700, 1701, 1706, 1707, 1709, 1710, 1712, 1723, 1724, 1728, 1738, 1739, 1740, 1741, 1747, 1748, 1752, 1753, 1754, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1770, 1773, 1774, 1777, 1778, 1780, 1782, 1783, 1785, 1786, 1789, 1790, 1793, 1796, 1798, 1799, 1800, 1803, 1804], "save_for_backward": [2, 738, 745, 747, 1758, 1759, 1764, 1765, 1777], "grad_output": [2, 737, 744, 754, 756, 1030, 1250, 1422, 1737, 1739, 1759, 1762, 1764, 1765, 1770], "saved_tensor": [2, 745, 746, 747, 1758, 1759, 1764, 1765], "avail": [2, 3, 9, 10, 14, 15, 20, 23, 33, 34, 38, 39, 48, 49, 830, 832, 833, 844, 847, 854, 855, 873, 874, 876, 905, 1036, 1093, 1094, 1119, 1293, 1302, 1358, 1415, 1513, 1632, 1684, 1689, 1721, 1735, 1736, 1738, 1740, 1741, 1745, 1747, 1751, 1759, 1762, 1764, 1768, 1770, 1771, 1774, 1776, 1781, 1783, 1784, 1785, 1789, 1803, 1804], "cost": [2, 4, 5, 9, 10, 21, 38, 53, 785, 1085, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1762, 1774, 1785, 1790], "both": [2, 3, 4, 14, 20, 21, 23, 24, 29, 32, 33, 34, 35, 36, 38, 41, 46, 47, 48, 49, 53, 59, 60, 74, 315, 645, 682, 683, 686, 687, 688, 743, 749, 750, 751, 752, 753, 763, 807, 831, 900, 921, 951, 952, 953, 973, 975, 983, 990, 1007, 1020, 1021, 1027, 1030, 1043, 1051, 1052, 1100, 1116, 1124, 1130, 1163, 1164, 1168, 1169, 1170, 1175, 1178, 1179, 1180, 1181, 1182, 1183, 1197, 1205, 1211, 1213, 1214, 1215, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1243, 1244, 1245, 1250, 1256, 1289, 1301, 1302, 1314, 1315, 1316, 1322, 1323, 1324, 1325, 1326, 1327, 1371, 1372, 1373, 1423, 1437, 1505, 1593, 1594, 1663, 1665, 1684, 1688, 1694, 1706, 1707, 1738, 1740, 1741, 1747, 1752, 1753, 1755, 1758, 1759, 1760, 1764, 1765, 1767, 1770, 1773, 1774, 1775, 1777, 1781, 1782, 1784, 1787, 1789, 1791, 1793, 1794, 1800, 1802, 1803], "cpu": [2, 5, 14, 16, 20, 23, 34, 36, 38, 53, 65, 96, 173, 265, 302, 311, 418, 419, 420, 421, 422, 431, 552, 561, 713, 727, 728, 760, 764, 773, 805, 811, 820, 821, 822, 824, 906, 908, 918, 923, 941, 953, 958, 959, 980, 981, 987, 988, 1030, 1037, 1039, 1040, 1049, 1059, 1061, 1065, 1066, 1067, 1068, 1070, 1072, 1075, 1077, 1078, 1084, 1087, 1090, 1093, 1094, 1100, 1101, 1116, 1119, 1130, 1187, 1193, 1250, 1293, 1411, 1423, 1458, 1459, 1471, 1474, 1523, 1597, 1599, 1601, 1603, 1604, 1628, 1633, 1635, 1636, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1657, 1670, 1671, 1672, 1673, 1674, 1675, 1688, 1700, 1701, 1702, 1711, 1713, 1718, 1721, 1733, 1736, 1738, 1739, 1741, 1745, 1748, 1751, 1752, 1754, 1762, 1765, 1768, 1770, 1772, 1773, 1774, 1776, 1777, 1779, 1782, 1783, 1785, 1788, 1789, 1793, 1795, 1796, 1799, 1800, 1801], "There": [2, 7, 8, 10, 14, 19, 23, 33, 35, 37, 38, 48, 54, 57, 58, 60, 703, 738, 962, 1187, 1220, 1265, 1423, 1427, 1463, 1735, 1738, 1740, 1741, 1747, 1753, 1759, 1762, 1764, 1765, 1766, 1769, 1772, 1776, 1777, 1781, 1784, 1785, 1789, 1791, 1799, 1801], "moment": [2, 35, 686, 687, 688, 803, 1480, 1481, 1482, 1484, 1490, 1494, 1748, 1751, 1754, 1783, 1789], "nvprof": [2, 5, 757, 1762], "regist": [2, 15, 21, 23, 27, 29, 34, 48, 50, 53, 60, 460, 702, 703, 710, 853, 1030, 1101, 1250, 1251, 1252, 1260, 1261, 1278, 1419, 1420, 1421, 1422, 1423, 1424, 1432, 1433, 1434, 1435, 1437, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1745, 1750, 1751, 1763, 1764, 1769, 1770, 1777, 1781, 1789], "activ": [2, 6, 8, 10, 38, 50, 58, 702, 703, 704, 705, 810, 819, 833, 846, 864, 961, 963, 971, 1102, 1162, 1189, 1190, 1191, 1195, 1205, 1222, 1249, 1251, 1268, 1279, 1293, 1295, 1297, 1340, 1377, 1399, 1423, 1435, 1436, 1437, 1465, 1470, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1586, 1587, 1728, 1736, 1737, 1748, 1751, 1762, 1764, 1770, 1777, 1780, 1782, 1783, 1784, 1785, 1786, 1789, 1793, 1802, 1803], "emit_nvtx": [2, 5], "vtune": [2, 5], "emit_itt": [2, 5], "use_cuda": [2, 1783], "record_shap": [2, 1783], "with_flop": [2, 1783], "profile_memori": [2, 1783], "with_stack": [2, 1783], "with_modul": [2, 1783], "use_kineto": 2, "use_cpu": 2, "experimental_config": [2, 1783], "hold": [2, 23, 35, 46, 48, 50, 51, 53, 59, 60, 508, 1102, 1197, 1251, 1252, 1260, 1261, 1301, 1418, 1423, 1425, 1426, 1434, 1444, 1458, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1487, 1490, 1491, 1492, 1493, 1494, 1670, 1671, 1672, 1673, 1674, 1675, 1760, 1762, 1764, 1766, 1769, 1772, 1780, 1783, 1789, 1790, 1791, 1793, 1795, 1796, 1798, 1799], "summari": [2, 4, 49, 865, 1637, 1736, 1750, 1798, 1803], "hood": [2, 35, 59, 1751, 1759, 1762, 1763, 1772, 1781, 1791], "record": [2, 6, 27, 33, 38, 40, 41, 42, 46, 49, 59, 60, 418, 419, 420, 421, 422, 468, 713, 764, 773, 811, 812, 814, 906, 907, 908, 918, 923, 941, 958, 959, 960, 987, 988, 1030, 1045, 1049, 1100, 1116, 1187, 1250, 1474, 1475, 1547, 1548, 1549, 1550, 1553, 1555, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1670, 1671, 1672, 1673, 1674, 1675, 1700, 1733, 1734, 1738, 1740, 1754, 1758, 1759, 1762, 1764, 1777, 1778, 1783, 1789, 1798, 1799, 1800, 1802, 1803], "event": [2, 26, 29, 39, 47, 50, 59, 759, 760, 761, 812, 814, 864, 867, 1045, 1046, 1107, 1736, 1750, 1751, 1762, 1783, 1798], "being": [2, 4, 10, 20, 23, 27, 29, 33, 34, 35, 38, 39, 41, 48, 49, 50, 53, 57, 59, 60, 74, 674, 703, 748, 754, 793, 812, 866, 883, 918, 951, 952, 962, 969, 970, 1019, 1030, 1034, 1119, 1128, 1133, 1166, 1167, 1184, 1186, 1193, 1194, 1198, 1199, 1204, 1210, 1217, 1241, 1242, 1250, 1253, 1254, 1255, 1256, 1257, 1264, 1281, 1282, 1298, 1312, 1319, 1320, 1330, 1342, 1343, 1347, 1359, 1382, 1390, 1423, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1451, 1452, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1523, 1524, 1531, 1682, 1683, 1684, 1723, 1724, 1738, 1741, 1747, 1750, 1752, 1753, 1754, 1758, 1759, 1762, 1764, 1765, 1766, 1767, 1770, 1772, 1773, 1777, 1781, 1784, 1787, 1789, 1790, 1793, 1800, 1802, 1804], "those": [2, 3, 5, 14, 20, 21, 23, 27, 29, 32, 33, 34, 35, 38, 57, 59, 60, 822, 832, 893, 895, 971, 1045, 1087, 1093, 1101, 1158, 1166, 1167, 1184, 1186, 1194, 1210, 1217, 1241, 1242, 1253, 1254, 1255, 1257, 1264, 1281, 1282, 1298, 1302, 1319, 1320, 1330, 1339, 1359, 1382, 1390, 1494, 1552, 1632, 1688, 1707, 1728, 1740, 1752, 1753, 1758, 1759, 1762, 1764, 1765, 1768, 1770, 1774, 1775, 1777, 1780, 1787, 1789, 1791], "report": [2, 4, 5, 17, 23, 33, 38, 41, 49, 59, 60, 864, 965, 966, 968, 1758, 1762, 1782, 1793], "runtim": [2, 4, 6, 14, 23, 33, 60, 726, 759, 903, 905, 993, 1030, 1045, 1250, 1425, 1426, 1519, 1555, 1721, 1729, 1741, 1752, 1753, 1759, 1762, 1764, 1772, 1777], "note": [2, 3, 4, 6, 9, 12, 14, 15, 17, 19, 20, 21, 23, 27, 29, 30, 33, 34, 38, 39, 46, 48, 50, 53, 58, 59, 60, 127, 198, 352, 471, 472, 485, 487, 489, 655, 656, 657, 703, 713, 732, 740, 746, 748, 749, 750, 751, 752, 753, 754, 756, 785, 808, 881, 888, 893, 905, 926, 956, 958, 971, 972, 983, 1005, 1017, 1027, 1028, 1030, 1031, 1036, 1102, 1124, 1166, 1167, 1173, 1181, 1182, 1183, 1184, 1186, 1193, 1194, 1202, 1204, 1210, 1216, 1217, 1220, 1241, 1242, 1250, 1251, 1253, 1254, 1255, 1256, 1257, 1260, 1261, 1264, 1265, 1281, 1282, 1289, 1293, 1298, 1302, 1319, 1320, 1330, 1338, 1339, 1347, 1358, 1359, 1382, 1385, 1390, 1391, 1403, 1418, 1423, 1428, 1470, 1476, 1491, 1497, 1499, 1505, 1507, 1523, 1528, 1531, 1569, 1586, 1595, 1669, 1670, 1671, 1672, 1674, 1675, 1680, 1684, 1688, 1707, 1721, 1728, 1735, 1738, 1739, 1742, 1747, 1751, 1754, 1755, 1759, 1760, 1761, 1763, 1764, 1765, 1767, 1768, 1769, 1770, 1772, 1773, 1774, 1775, 1777, 1778, 1781, 1783, 1785, 1787, 1790, 1791, 1793, 1797, 1798, 1805], "propag": [2, 26, 29, 35, 39, 48, 60, 485, 602, 605, 606, 607, 611, 612, 613, 614, 680, 681, 682, 683, 693, 696, 697, 699, 700, 701, 763, 951, 952, 1145, 1566, 1568, 1669, 1736, 1751, 1752, 1758, 1762, 1764, 1767, 1769, 1789, 1802, 1803], "async": [2, 23, 24, 59, 575, 1423, 1742, 1762, 1769, 1795], "task": [2, 4, 8, 21, 54, 58, 1033, 1048, 1213, 1214, 1215, 1741, 1761, 1769, 1770, 1776], "cuda": [2, 4, 5, 6, 12, 14, 19, 20, 21, 23, 27, 33, 34, 38, 53, 65, 127, 265, 289, 297, 311, 316, 487, 489, 495, 552, 713, 725, 727, 740, 754, 764, 766, 773, 809, 810, 811, 812, 814, 815, 829, 831, 842, 906, 907, 908, 918, 921, 922, 923, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 959, 987, 988, 1030, 1049, 1051, 1059, 1060, 1061, 1065, 1066, 1067, 1068, 1070, 1071, 1072, 1073, 1075, 1076, 1077, 1078, 1084, 1087, 1090, 1091, 1093, 1094, 1100, 1101, 1116, 1119, 1135, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1187, 1193, 1220, 1250, 1265, 1289, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1339, 1347, 1358, 1385, 1415, 1416, 1417, 1418, 1423, 1425, 1426, 1469, 1471, 1474, 1480, 1481, 1523, 1597, 1599, 1601, 1603, 1604, 1628, 1632, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1666, 1670, 1671, 1672, 1673, 1674, 1675, 1688, 1700, 1702, 1711, 1713, 1718, 1721, 1733, 1736, 1739, 1745, 1752, 1754, 1764, 1765, 1770, 1773, 1777, 1779, 1782, 1783, 1788, 1789, 1795, 1796, 1799, 1800, 1801], "cudaev": 2, "approxim": [2, 4, 21, 27, 48, 60, 983, 1093, 1102, 1158, 1200, 1264, 1279, 1286, 1345, 1390, 1399, 1433, 1477, 1513, 1689, 1707, 1737, 1739, 1741, 1762, 1763, 1764, 1767, 1777, 1805], "4u": 2, "about": [2, 9, 10, 16, 20, 23, 24, 27, 33, 35, 38, 39, 41, 45, 47, 49, 54, 57, 60, 231, 470, 590, 755, 756, 816, 817, 832, 856, 858, 859, 860, 862, 863, 864, 865, 870, 871, 872, 962, 1059, 1066, 1194, 1458, 1505, 1631, 1735, 1738, 1740, 1741, 1745, 1747, 1761, 1762, 1763, 1764, 1766, 1769, 1772, 1773, 1775, 1781, 1783, 1784, 1787, 1790, 1791, 1793, 1797, 1799], "dimens": [2, 12, 20, 23, 29, 53, 57, 58, 60, 195, 209, 230, 236, 289, 291, 293, 297, 407, 408, 445, 446, 447, 465, 485, 487, 489, 508, 514, 516, 517, 531, 555, 579, 589, 602, 608, 609, 611, 612, 613, 615, 672, 693, 695, 699, 722, 723, 724, 725, 734, 735, 736, 754, 774, 782, 785, 786, 787, 788, 789, 808, 822, 824, 884, 885, 886, 887, 888, 893, 894, 895, 896, 897, 903, 905, 921, 922, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 942, 944, 971, 972, 983, 992, 993, 1004, 1007, 1027, 1050, 1051, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1081, 1082, 1083, 1084, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1109, 1110, 1117, 1120, 1124, 1127, 1129, 1130, 1131, 1132, 1135, 1137, 1138, 1145, 1146, 1147, 1148, 1149, 1150, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1179, 1180, 1182, 1183, 1184, 1185, 1186, 1187, 1190, 1192, 1193, 1194, 1196, 1197, 1200, 1201, 1204, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1219, 1220, 1222, 1230, 1231, 1236, 1237, 1238, 1239, 1240, 1241, 1244, 1245, 1249, 1256, 1257, 1258, 1259, 1262, 1263, 1264, 1268, 1269, 1270, 1277, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1295, 1297, 1298, 1299, 1300, 1301, 1312, 1318, 1322, 1323, 1324, 1325, 1326, 1327, 1329, 1346, 1347, 1348, 1349, 1358, 1361, 1364, 1365, 1366, 1383, 1384, 1385, 1402, 1403, 1415, 1428, 1432, 1433, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1459, 1460, 1462, 1464, 1467, 1469, 1470, 1511, 1514, 1521, 1523, 1524, 1590, 1595, 1609, 1610, 1611, 1615, 1624, 1626, 1627, 1637, 1658, 1662, 1664, 1667, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1679, 1681, 1682, 1683, 1684, 1687, 1688, 1694, 1695, 1697, 1701, 1702, 1703, 1704, 1706, 1707, 1709, 1710, 1711, 1712, 1713, 1716, 1717, 1718, 1719, 1720, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1736, 1737, 1739, 1740, 1741, 1754, 1757, 1760, 1762, 1765, 1766, 1767, 1773, 1782, 1784, 1793, 1794, 1796, 1798, 1799], "collect": [2, 4, 8, 20, 24, 27, 33, 35, 38, 39, 48, 53, 59, 60, 783, 846, 906, 992, 1131, 1423, 1448, 1474, 1531, 1532, 1552, 1586, 1587, 1597, 1601, 1733, 1736, 1739, 1740, 1741, 1750, 1762, 1763, 1765, 1780, 1783, 1784, 1787, 1791, 1793, 1798, 1800], "group": [2, 4, 10, 20, 21, 24, 27, 33, 38, 39, 45, 48, 49, 50, 51, 53, 56, 60, 582, 628, 629, 630, 631, 632, 633, 634, 635, 641, 642, 643, 646, 647, 652, 653, 654, 655, 656, 657, 686, 687, 688, 728, 759, 1174, 1178, 1179, 1180, 1181, 1182, 1183, 1205, 1226, 1227, 1228, 1229, 1230, 1231, 1289, 1322, 1323, 1324, 1325, 1326, 1327, 1348, 1423, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1487, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1719, 1735, 1736, 1737, 1739, 1741, 1751, 1757, 1762, 1763, 1777, 1780, 1781, 1783, 1789, 1798], "prof": [2, 33, 38, 45, 1783], "key_averag": [2, 1783], "group_by_input_shap": [2, 759, 1783], "skew": [2, 4, 5, 1081, 1432], "neglig": [2, 1042, 1632], "bottom": [2, 1347, 1747], "But": [2, 8, 35, 59, 459, 1045, 1075, 1423, 1759, 1764, 1766, 1767, 1781, 1782, 1793, 1797, 1804], "total": [2, 4, 5, 8, 20, 21, 23, 45, 47, 48, 49, 53, 725, 760, 824, 859, 864, 876, 958, 991, 992, 1173, 1197, 1210, 1217, 1241, 1256, 1301, 1384, 1423, 1429, 1469, 1471, 1473, 1499, 1505, 1610, 1637, 1684, 1735, 1740, 1750, 1762, 1768, 1780], "artifici": [2, 1793], "estim": [2, 4, 20, 29, 803, 807, 983, 1027, 1168, 1169, 1170, 1200, 1204, 1205, 1213, 1214, 1215, 1222, 1289, 1345, 1433, 1491, 1653, 1783], "flop": [2, 1783], "hardwar": [2, 9, 33, 38, 1065, 1066, 1093, 1584, 1586, 1587, 1721, 1762, 1774, 1785], "matrix": [2, 3, 21, 23, 29, 33, 168, 185, 602, 605, 606, 607, 763, 765, 774, 775, 783, 785, 786, 787, 788, 803, 807, 888, 892, 893, 895, 905, 971, 975, 979, 994, 1050, 1059, 1060, 1061, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1074, 1075, 1076, 1077, 1079, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1092, 1093, 1094, 1095, 1097, 1099, 1102, 1110, 1119, 1121, 1124, 1134, 1140, 1142, 1193, 1194, 1220, 1301, 1338, 1339, 1432, 1437, 1464, 1470, 1511, 1512, 1513, 1523, 1632, 1660, 1663, 1665, 1666, 1668, 1670, 1671, 1672, 1673, 1674, 1675, 1680, 1688, 1689, 1694, 1702, 1705, 1707, 1709, 1710, 1711, 1712, 1713, 1722, 1728, 1736, 1741, 1752, 1753, 1754, 1757, 1761, 1762, 1764, 1767, 1770, 1773, 1783, 1793, 1798, 1799], "2d": [2, 29, 559, 560, 616, 619, 622, 653, 656, 680, 682, 687, 693, 697, 699, 700, 701, 788, 803, 807, 893, 905, 1085, 1086, 1156, 1160, 1164, 1168, 1169, 1179, 1182, 1186, 1190, 1194, 1198, 1213, 1214, 1219, 1244, 1253, 1255, 1256, 1257, 1302, 1303, 1304, 1307, 1310, 1312, 1315, 1323, 1326, 1334, 1339, 1342, 1369, 1372, 1382, 1385, 1428, 1433, 1464, 1594, 1668, 1673, 1709, 1748, 1757, 1764, 1783, 1784, 1793], "alloc": [2, 5, 12, 17, 21, 29, 39, 48, 230, 307, 418, 419, 420, 421, 422, 459, 810, 812, 814, 816, 817, 819, 831, 832, 833, 856, 858, 860, 862, 863, 864, 865, 871, 872, 876, 906, 908, 1597, 1601, 1603, 1628, 1700, 1751, 1754, 1759, 1763, 1768, 1783, 1796], "dealloc": [2, 958, 1751, 1762, 1766, 1768, 1783], "line": [2, 5, 17, 23, 33, 34, 35, 36, 38, 60, 759, 905, 962, 1005, 1030, 1040, 1250, 1312, 1347, 1637, 1738, 1741, 1742, 1754, 1760, 1764, 1767, 1768, 1774, 1776, 1777, 1783, 1793], "hierarchi": [2, 60, 1034, 1568, 1742, 1764, 1783, 1784], "callstack": [2, 23, 1783], "A": [2, 3, 4, 6, 8, 9, 10, 14, 17, 20, 21, 23, 24, 27, 29, 33, 34, 35, 37, 38, 39, 45, 48, 49, 50, 53, 54, 58, 59, 65, 531, 552, 555, 566, 596, 608, 613, 628, 629, 630, 631, 632, 633, 634, 635, 636, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 659, 660, 670, 675, 676, 677, 678, 679, 702, 761, 764, 773, 774, 776, 781, 786, 787, 794, 795, 803, 807, 811, 812, 814, 821, 823, 824, 890, 905, 910, 918, 919, 920, 932, 962, 963, 964, 965, 966, 967, 968, 970, 971, 974, 983, 986, 987, 988, 992, 1020, 1021, 1022, 1023, 1026, 1028, 1030, 1033, 1037, 1040, 1042, 1045, 1046, 1050, 1054, 1059, 1060, 1061, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1099, 1102, 1110, 1118, 1119, 1120, 1121, 1125, 1151, 1167, 1171, 1173, 1186, 1193, 1194, 1203, 1204, 1212, 1221, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1240, 1249, 1250, 1256, 1278, 1283, 1285, 1293, 1298, 1299, 1312, 1318, 1330, 1338, 1349, 1359, 1366, 1377, 1402, 1403, 1418, 1423, 1424, 1425, 1426, 1427, 1428, 1432, 1434, 1437, 1459, 1460, 1476, 1480, 1482, 1483, 1488, 1492, 1494, 1498, 1499, 1501, 1504, 1505, 1507, 1513, 1523, 1527, 1546, 1583, 1584, 1586, 1587, 1590, 1591, 1592, 1593, 1594, 1605, 1611, 1617, 1620, 1653, 1662, 1664, 1667, 1679, 1683, 1684, 1688, 1689, 1694, 1704, 1709, 1710, 1711, 1712, 1713, 1717, 1718, 1719, 1720, 1721, 1724, 1728, 1731, 1735, 1737, 1738, 1739, 1740, 1741, 1745, 1747, 1748, 1752, 1753, 1757, 1758, 1761, 1762, 1764, 1765, 1766, 1772, 1773, 1775, 1777, 1778, 1781, 1782, 1783, 1784, 1789, 1790, 1791, 1793, 1794, 1795, 1796, 1798, 1799, 1803, 1804, 1805], "aten": [2, 3, 4, 14, 17, 38, 850, 962, 1140, 1476, 1738, 1739, 1745, 1761, 1776, 1779, 1783, 1784], "torchscript": [2, 4, 9, 27, 34, 60, 589, 1028, 1031, 1033, 1034, 1035, 1036, 1041, 1045, 1047, 1736, 1742, 1775, 1777, 1783, 1789], "eager": [2, 9, 33, 34, 38, 881, 1028, 1031, 1041, 1636, 1741, 1762, 1783, 1785, 1787], "experiment": [2, 3, 21, 23, 27, 38, 53, 56, 60, 748, 750, 754, 880, 962, 1060, 1071, 1073, 1074, 1078, 1091, 1423, 1736, 1738, 1740, 1752, 1753, 1763, 1774, 1776, 1781, 1782, 1783], "kineto": [2, 1783], "_experimentalconfig": [2, 1783], "librari": [2, 3, 4, 5, 9, 10, 12, 14, 15, 20, 23, 30, 33, 34, 46, 50, 54, 57, 58, 60, 805, 812, 834, 838, 850, 956, 1042, 1073, 1119, 1657, 1750, 1761, 1762, 1763, 1764, 1765, 1766, 1769, 1770, 1772, 1773, 1776, 1777, 1781, 1783, 1784, 1789, 1804], "compat": [2, 14, 20, 29, 39, 53, 57, 60, 469, 470, 575, 589, 706, 707, 708, 738, 776, 800, 801, 1030, 1035, 1047, 1060, 1071, 1084, 1087, 1250, 1358, 1476, 1611, 1735, 1736, 1740, 1741, 1751, 1752, 1758, 1764, 1775, 1781, 1783, 1784, 1789, 1795], "100": [2, 20, 23, 27, 29, 31, 35, 60, 276, 652, 653, 656, 657, 990, 1030, 1041, 1047, 1085, 1100, 1107, 1116, 1131, 1139, 1158, 1166, 1167, 1168, 1169, 1170, 1179, 1180, 1182, 1183, 1185, 1186, 1213, 1214, 1215, 1250, 1257, 1259, 1289, 1298, 1329, 1330, 1382, 1483, 1495, 1496, 1501, 1502, 1503, 1504, 1506, 1508, 1509, 1590, 1646, 1739, 1741, 1751, 1761, 1762, 1780, 1785, 1791, 1793, 1798], "realli": [2, 8, 60, 1741, 1759, 1781], "y": [2, 12, 14, 20, 29, 31, 34, 35, 38, 45, 53, 57, 58, 60, 589, 592, 695, 732, 734, 735, 736, 742, 743, 746, 748, 749, 750, 751, 752, 753, 777, 783, 800, 807, 850, 851, 888, 899, 905, 909, 961, 963, 966, 967, 968, 970, 971, 1005, 1036, 1041, 1045, 1098, 1107, 1108, 1131, 1166, 1167, 1168, 1169, 1170, 1171, 1184, 1186, 1205, 1210, 1211, 1213, 1214, 1215, 1217, 1222, 1237, 1241, 1242, 1253, 1254, 1255, 1257, 1259, 1281, 1282, 1289, 1292, 1298, 1299, 1318, 1347, 1364, 1387, 1418, 1437, 1468, 1592, 1610, 1612, 1613, 1634, 1665, 1679, 1703, 1707, 1708, 1728, 1731, 1738, 1739, 1740, 1741, 1752, 1753, 1757, 1759, 1760, 1761, 1762, 1765, 1767, 1768, 1771, 1777, 1781, 1784, 1789, 1791, 1794, 1798, 1801, 1802, 1803], "column": [2, 4, 21, 168, 236, 556, 559, 793, 803, 807, 888, 918, 946, 947, 995, 1065, 1066, 1069, 1085, 1088, 1093, 1097, 1102, 1140, 1259, 1301, 1338, 1339, 1432, 1513, 1523, 1668, 1670, 1671, 1672, 1674, 1675, 1688, 1707, 1711, 1713, 1722, 1757, 1767, 1793], "remov": [2, 4, 21, 23, 29, 33, 34, 49, 51, 53, 60, 460, 517, 528, 613, 706, 707, 708, 785, 786, 853, 962, 976, 1027, 1030, 1034, 1119, 1120, 1124, 1250, 1251, 1260, 1349, 1419, 1420, 1421, 1422, 1423, 1433, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1451, 1452, 1453, 1454, 1456, 1457, 1470, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1523, 1529, 1584, 1604, 1626, 1679, 1688, 1694, 1709, 1716, 1735, 1736, 1748, 1759, 1770, 1775, 1777, 1779, 1781, 1791, 1795, 1800], "breviti": [2, 60, 1777], "print": [2, 4, 17, 20, 23, 31, 33, 35, 38, 39, 40, 45, 46, 49, 53, 57, 59, 636, 644, 645, 659, 660, 670, 678, 961, 962, 969, 1030, 1034, 1036, 1037, 1041, 1119, 1171, 1174, 1212, 1237, 1250, 1262, 1263, 1329, 1385, 1388, 1389, 1427, 1437, 1447, 1448, 1449, 1450, 1453, 1465, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1509, 1637, 1735, 1738, 1739, 1759, 1761, 1762, 1764, 1770, 1771, 1777, 1778, 1779, 1781, 1783, 1789, 1798, 1799, 1802, 1803], "tabl": [2, 4, 23, 38, 60, 1193, 1338, 1739, 1741, 1764, 1781, 1783, 1784, 1789, 1793, 1800], "sort_bi": [2, 1783], "self_cpu_time_tot": [2, 1783], "avg": [2, 23, 1478], "mul": [2, 17, 31, 60, 394, 661, 662, 671, 1007, 1141, 1737, 1738, 1739, 1741, 1752, 1754, 1764, 1777, 1779, 1786, 1790, 1793, 1796, 1802], "32": [2, 3, 21, 23, 32, 35, 660, 958, 1027, 1039, 1119, 1164, 1189, 1190, 1191, 1195, 1196, 1198, 1199, 1219, 1238, 1244, 1255, 1293, 1294, 1295, 1296, 1297, 1312, 1342, 1343, 1349, 1753, 1754, 1770, 1774, 1777, 1787, 1793, 1796, 1798, 1799], "048m": 2, "200": [2, 27, 38, 1030, 1107, 1250, 1590, 1741, 1793], "27": [2, 589, 1097, 1498, 1520, 1722, 1777], "041m": 2, "powbackward0": 2, "9": [2, 8, 20, 21, 23, 30, 32, 60, 64, 289, 291, 293, 297, 444, 485, 531, 553, 555, 613, 659, 660, 710, 779, 785, 789, 793, 807, 888, 903, 906, 927, 928, 937, 938, 948, 951, 952, 955, 956, 983, 993, 1059, 1061, 1082, 1084, 1086, 1097, 1099, 1149, 1150, 1156, 1157, 1160, 1161, 1174, 1193, 1194, 1246, 1247, 1262, 1263, 1272, 1275, 1338, 1339, 1385, 1388, 1389, 1470, 1471, 1478, 1480, 1481, 1482, 1483, 1484, 1490, 1493, 1494, 1495, 1499, 1505, 1507, 1508, 1512, 1516, 1617, 1624, 1633, 1637, 1647, 1652, 1662, 1668, 1676, 1700, 1701, 1705, 1707, 1716, 1722, 1729, 1738, 1742, 1747, 1766, 1770, 1775, 1776, 1777, 1779, 1780, 1781, 1789, 1793, 1794, 1796, 1800], "727m": 2, "55": [2, 1204, 1777], "483m": 2, "accumulategrad": [2, 1759], "148m": 2, "graphroot": 2, "691": 2, "816u": 2, "emit": [2, 14, 40, 45, 60, 1045, 1639, 1741, 1778, 1788, 1793], "nvtx": [2, 5, 1736], "off": [2, 8, 9, 14, 23, 35, 39, 53, 60, 762, 764, 773, 868, 962, 987, 988, 1027, 1045, 1093, 1163, 1164, 1165, 1167, 1243, 1244, 1245, 1347, 1385, 1634, 1761, 1762, 1763, 1766, 1769, 1773, 1783, 1784, 1785, 1789, 1790], "o": [2, 29, 1030, 1221, 1250, 1256, 1742, 1762, 1766, 1776, 1781], "trace_nam": 2, "regular": [2, 4, 5, 23, 35, 39, 49, 53, 56, 60, 850, 851, 961, 1077, 1078, 1173, 1188, 1189, 1190, 1191, 1195, 1235, 1249, 1250, 1251, 1252, 1260, 1261, 1340, 1377, 1418, 1425, 1426, 1465, 1481, 1741, 1753, 1754, 1764, 1765, 1769, 1770, 1777, 1781, 1784, 1787, 1789, 1793, 1794, 1803], "command": [2, 5, 23, 37, 39, 46, 49, 60, 1762, 1768, 1776, 1782, 1783, 1790], "unfortun": [2, 6, 10, 20, 32, 1423, 1759], "wai": [2, 4, 6, 8, 9, 10, 14, 20, 21, 23, 27, 29, 33, 35, 38, 41, 45, 53, 55, 56, 59, 60, 127, 552, 705, 738, 740, 749, 751, 752, 753, 754, 755, 926, 928, 962, 983, 1030, 1059, 1060, 1075, 1090, 1166, 1194, 1213, 1214, 1215, 1220, 1232, 1233, 1234, 1250, 1278, 1295, 1297, 1339, 1391, 1423, 1435, 1463, 1498, 1505, 1547, 1550, 1553, 1586, 1587, 1738, 1740, 1741, 1745, 1747, 1750, 1751, 1752, 1753, 1759, 1761, 1764, 1765, 1766, 1767, 1770, 1772, 1773, 1776, 1777, 1778, 1780, 1781, 1784, 1789, 1790, 1793, 1797, 1799, 1803], "disk": [2, 20, 1620, 1759, 1770, 1781, 1798], "annot": [2, 34, 35, 41, 46, 60, 757, 1028, 1041, 1738, 1740, 1742, 1777, 1789], "wait": [2, 17, 23, 33, 39, 46, 48, 59, 811, 812, 814, 882, 1033, 1507, 1552, 1739, 1741, 1751, 1761, 1762, 1763, 1779, 1783, 1789], "nvidia": [2, 14, 23, 34, 38, 832, 860, 866, 883, 1721, 1736, 1762, 1766, 1768, 1774, 1776, 1784, 1801], "visual": [2, 33, 38, 60, 1131, 1178, 1179, 1180, 1181, 1182, 1183, 1197, 1243, 1244, 1245, 1301, 1770, 1776, 1783, 1798], "nvvp": 2, "timelin": [2, 5], "load_nvprof": 2, "repl": [2, 34], "append": [2, 23, 35, 59, 60, 206, 230, 579, 675, 677, 679, 853, 895, 897, 1124, 1203, 1221, 1252, 1261, 1267, 1278, 1423, 1739, 1740, 1741, 1759, 1761, 1772, 1776, 1777, 1779, 1798], "size": [2, 3, 4, 8, 17, 20, 21, 23, 29, 32, 33, 38, 39, 48, 53, 56, 60, 115, 185, 198, 218, 230, 231, 289, 291, 297, 315, 418, 419, 420, 422, 460, 465, 470, 471, 472, 485, 487, 489, 492, 515, 516, 517, 537, 553, 555, 578, 579, 589, 590, 606, 607, 609, 611, 612, 613, 615, 636, 644, 645, 655, 656, 657, 659, 660, 670, 678, 680, 681, 682, 683, 693, 699, 700, 701, 713, 725, 726, 728, 748, 749, 750, 751, 752, 753, 759, 763, 764, 766, 773, 775, 776, 777, 778, 779, 786, 787, 788, 789, 807, 808, 810, 816, 821, 822, 824, 864, 886, 887, 893, 896, 903, 905, 906, 907, 908, 911, 922, 923, 924, 926, 927, 928, 930, 931, 934, 935, 936, 937, 938, 940, 941, 942, 958, 959, 960, 967, 968, 971, 972, 987, 988, 992, 993, 1004, 1007, 1027, 1030, 1051, 1060, 1069, 1074, 1082, 1086, 1090, 1093, 1095, 1096, 1097, 1099, 1100, 1102, 1110, 1116, 1117, 1119, 1120, 1124, 1127, 1129, 1130, 1131, 1132, 1135, 1136, 1137, 1140, 1142, 1145, 1148, 1150, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1173, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1193, 1194, 1196, 1197, 1198, 1199, 1202, 1204, 1205, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1237, 1238, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1253, 1254, 1255, 1256, 1257, 1262, 1263, 1265, 1271, 1272, 1273, 1274, 1275, 1276, 1281, 1289, 1293, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1314, 1315, 1316, 1325, 1326, 1327, 1330, 1331, 1338, 1339, 1342, 1343, 1347, 1358, 1365, 1371, 1372, 1373, 1382, 1383, 1385, 1388, 1389, 1391, 1415, 1416, 1417, 1418, 1423, 1428, 1448, 1458, 1459, 1460, 1461, 1462, 1464, 1467, 1469, 1471, 1474, 1475, 1483, 1492, 1511, 1512, 1513, 1514, 1516, 1521, 1522, 1523, 1524, 1583, 1590, 1591, 1592, 1593, 1594, 1595, 1597, 1598, 1599, 1600, 1601, 1602, 1604, 1610, 1615, 1624, 1627, 1646, 1665, 1666, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1679, 1681, 1682, 1683, 1684, 1687, 1688, 1689, 1694, 1700, 1701, 1702, 1707, 1709, 1717, 1718, 1719, 1720, 1723, 1724, 1726, 1727, 1728, 1729, 1733, 1734, 1736, 1737, 1738, 1739, 1741, 1748, 1750, 1752, 1753, 1758, 1759, 1760, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1774, 1775, 1777, 1779, 1782, 1784, 1786, 1793, 1795, 1796, 1798, 1799], "format": [2, 18, 21, 38, 41, 50, 60, 132, 147, 149, 152, 155, 156, 157, 172, 183, 186, 216, 243, 273, 301, 307, 368, 471, 472, 496, 552, 555, 556, 557, 558, 559, 560, 674, 702, 703, 792, 853, 905, 906, 907, 960, 1027, 1030, 1043, 1072, 1173, 1194, 1202, 1220, 1250, 1265, 1423, 1428, 1459, 1461, 1475, 1598, 1600, 1602, 1620, 1663, 1665, 1670, 1671, 1672, 1673, 1674, 1675, 1684, 1734, 1735, 1738, 1741, 1742, 1762, 1764, 1770, 1775, 1777, 1778, 1779, 1783, 1784, 1789, 1790, 1793, 1796, 1798, 1800], "arg0": [2, 23], "arg1": [2, 23, 46, 47, 49], "repres": [2, 9, 12, 20, 21, 29, 30, 35, 39, 41, 42, 48, 50, 53, 60, 674, 702, 703, 705, 737, 803, 807, 809, 840, 843, 905, 926, 928, 933, 935, 936, 937, 938, 962, 983, 990, 1019, 1020, 1023, 1026, 1029, 1045, 1046, 1077, 1119, 1158, 1173, 1250, 1256, 1297, 1299, 1301, 1423, 1431, 1434, 1439, 1442, 1443, 1444, 1445, 1446, 1448, 1451, 1452, 1453, 1454, 1458, 1466, 1499, 1505, 1511, 1513, 1524, 1670, 1671, 1672, 1674, 1675, 1684, 1688, 1694, 1718, 1719, 1726, 1727, 1738, 1740, 1741, 1747, 1750, 1754, 1759, 1764, 1765, 1767, 1769, 1770, 1773, 1777, 1778, 1782, 1784, 1785, 1787, 1789, 1793, 1796, 1805], "order": [2, 4, 6, 23, 24, 27, 29, 31, 33, 36, 38, 49, 53, 54, 58, 59, 60, 127, 168, 185, 289, 291, 293, 297, 307, 702, 710, 724, 740, 741, 754, 774, 785, 812, 853, 893, 896, 897, 905, 923, 925, 926, 932, 944, 945, 946, 947, 963, 971, 983, 1030, 1049, 1060, 1066, 1068, 1075, 1082, 1085, 1086, 1093, 1094, 1097, 1099, 1102, 1131, 1137, 1138, 1140, 1158, 1173, 1187, 1250, 1251, 1260, 1277, 1278, 1312, 1347, 1371, 1372, 1373, 1418, 1423, 1434, 1444, 1458, 1459, 1460, 1461, 1470, 1483, 1505, 1511, 1514, 1524, 1534, 1624, 1627, 1652, 1662, 1688, 1694, 1704, 1711, 1713, 1718, 1721, 1722, 1728, 1735, 1736, 1738, 1739, 1741, 1742, 1751, 1752, 1753, 1754, 1757, 1759, 1760, 1762, 1763, 1764, 1765, 1767, 1770, 1773, 1777, 1780, 1781, 1782, 1784, 1786, 1789, 1790, 1791, 1793, 1794, 1796, 1800, 1803], "side": [2, 14, 23, 35, 48, 50, 57, 60, 682, 683, 686, 687, 688, 842, 899, 921, 922, 924, 927, 928, 933, 935, 936, 937, 938, 941, 1027, 1028, 1074, 1079, 1090, 1092, 1163, 1164, 1165, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1197, 1226, 1227, 1228, 1229, 1230, 1231, 1243, 1244, 1245, 1271, 1272, 1274, 1275, 1276, 1301, 1305, 1314, 1315, 1316, 1322, 1323, 1324, 1325, 1326, 1327, 1371, 1372, 1373, 1385, 1499, 1593, 1594, 1624, 1684, 1709, 1735, 1738, 1739, 1741, 1758, 1759, 1762, 1764, 1767, 1789], "creation": [2, 3, 20, 35, 60, 659, 660, 670, 678, 811, 962, 1423, 1439, 1552, 1738, 1742, 1750, 1751, 1759, 1762, 1778, 1789, 1791, 1799], "warmup": [2, 4, 33, 853, 1762, 1783], "correl": [2, 29, 49, 803, 1178, 1179, 1180, 1181, 1182, 1183, 1189, 1190, 1191, 1195], "view": [2, 8, 9, 12, 17, 20, 21, 27, 38, 39, 53, 60, 199, 230, 469, 470, 471, 579, 590, 608, 613, 674, 726, 734, 735, 736, 743, 777, 789, 800, 801, 895, 896, 903, 944, 945, 946, 947, 962, 993, 1005, 1030, 1085, 1096, 1194, 1202, 1220, 1250, 1265, 1301, 1302, 1303, 1304, 1339, 1384, 1422, 1423, 1429, 1514, 1611, 1615, 1616, 1620, 1626, 1627, 1658, 1676, 1687, 1696, 1701, 1705, 1717, 1726, 1727, 1729, 1736, 1737, 1738, 1739, 1751, 1753, 1754, 1760, 1764, 1779, 1786, 1791, 1793, 1795, 1796, 1799], "difficult": [2, 8, 10, 33, 38, 57, 971, 1728], "eas": [2, 60, 1761, 1764, 1768], "sequenc": [2, 20, 27, 29, 33, 36, 38, 127, 537, 674, 728, 740, 754, 779, 781, 782, 785, 793, 814, 820, 821, 824, 890, 904, 906, 971, 991, 992, 995, 1045, 1085, 1131, 1158, 1168, 1173, 1178, 1187, 1194, 1202, 1220, 1256, 1265, 1278, 1293, 1294, 1295, 1296, 1297, 1339, 1428, 1434, 1437, 1444, 1458, 1459, 1460, 1461, 1462, 1471, 1474, 1491, 1546, 1595, 1597, 1601, 1624, 1681, 1684, 1728, 1730, 1733, 1738, 1739, 1740, 1754, 1762, 1766, 1777, 1781, 1782, 1789, 1799, 1800], "seq": [2, 577, 674, 782, 794, 1131, 1202, 1220, 1256, 1265, 1293, 1295, 1297, 1461, 1716], "n": [2, 4, 23, 29, 35, 39, 41, 46, 49, 60, 206, 236, 381, 438, 439, 602, 605, 606, 607, 672, 674, 695, 725, 759, 763, 764, 766, 773, 775, 779, 785, 786, 787, 807, 886, 887, 897, 918, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 945, 965, 968, 971, 983, 987, 988, 992, 1027, 1030, 1041, 1045, 1046, 1049, 1050, 1059, 1060, 1061, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1102, 1110, 1119, 1124, 1126, 1131, 1134, 1142, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1173, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1189, 1190, 1191, 1193, 1194, 1195, 1197, 1198, 1199, 1201, 1202, 1203, 1204, 1205, 1210, 1211, 1213, 1214, 1215, 1217, 1218, 1219, 1220, 1222, 1232, 1233, 1234, 1238, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1253, 1254, 1255, 1256, 1257, 1259, 1265, 1267, 1271, 1272, 1273, 1274, 1275, 1276, 1281, 1283, 1284, 1285, 1289, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1312, 1318, 1330, 1331, 1339, 1343, 1347, 1382, 1385, 1387, 1423, 1428, 1432, 1443, 1452, 1469, 1511, 1512, 1513, 1518, 1523, 1524, 1595, 1601, 1603, 1616, 1624, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1665, 1666, 1682, 1683, 1684, 1688, 1689, 1694, 1701, 1702, 1707, 1711, 1713, 1722, 1723, 1724, 1725, 1728, 1737, 1739, 1741, 1752, 1753, 1757, 1759, 1762, 1764, 1766, 1767, 1781, 1783, 1784, 1793, 1794, 1798, 1799, 1800, 1803], "counter": [2, 23, 846, 864, 1005, 1187, 1750, 1751, 1759], "increment": [2, 23, 48, 958, 992, 1034, 1187, 1738, 1740, 1759, 1789], "stash": [2, 6, 1762, 1764, 1782], "tell": [2, 8, 60, 468, 1031, 1037, 1101, 1738, 1747, 1759, 1764, 1765, 1781], "top": [2, 4, 8, 9, 20, 29, 32, 41, 53, 60, 661, 759, 1166, 1167, 1186, 1210, 1217, 1241, 1257, 1299, 1302, 1347, 1439, 1443, 1445, 1653, 1704, 1742, 1747, 1751, 1764], "m": [2, 5, 9, 21, 23, 29, 49, 60, 602, 605, 606, 607, 636, 644, 645, 652, 653, 654, 655, 656, 657, 659, 660, 670, 672, 678, 763, 775, 779, 783, 788, 918, 969, 992, 1028, 1030, 1035, 1036, 1040, 1041, 1047, 1050, 1061, 1069, 1075, 1076, 1077, 1078, 1082, 1083, 1084, 1086, 1087, 1088, 1093, 1094, 1095, 1096, 1102, 1119, 1120, 1124, 1134, 1140, 1142, 1155, 1156, 1157, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1168, 1169, 1170, 1171, 1172, 1175, 1176, 1177, 1178, 1179, 1180, 1182, 1183, 1188, 1189, 1190, 1191, 1192, 1193, 1195, 1196, 1198, 1199, 1200, 1201, 1205, 1206, 1207, 1208, 1209, 1212, 1213, 1214, 1215, 1218, 1219, 1236, 1237, 1239, 1240, 1243, 1244, 1245, 1249, 1250, 1257, 1258, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1279, 1280, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1300, 1302, 1303, 1304, 1305, 1385, 1387, 1423, 1432, 1437, 1447, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1463, 1464, 1467, 1511, 1512, 1513, 1523, 1546, 1585, 1586, 1587, 1595, 1624, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1665, 1666, 1684, 1688, 1689, 1694, 1702, 1709, 1738, 1739, 1740, 1741, 1762, 1764, 1766, 1767, 1770, 1775, 1784, 1793, 1803], "By": [2, 3, 4, 6, 14, 20, 23, 32, 33, 38, 40, 45, 60, 418, 419, 420, 421, 422, 807, 814, 856, 858, 888, 900, 923, 925, 926, 927, 928, 936, 937, 938, 963, 964, 966, 967, 971, 983, 991, 992, 1034, 1082, 1093, 1101, 1130, 1135, 1144, 1166, 1167, 1168, 1169, 1170, 1184, 1186, 1204, 1210, 1213, 1214, 1215, 1216, 1217, 1241, 1242, 1253, 1254, 1255, 1257, 1264, 1281, 1282, 1289, 1298, 1319, 1320, 1330, 1359, 1382, 1390, 1467, 1513, 1524, 1610, 1707, 1728, 1735, 1740, 1745, 1747, 1759, 1762, 1764, 1766, 1770, 1773, 1775, 1777, 1780, 1788, 1789, 1793, 1800], "compar": [2, 4, 6, 14, 20, 53, 60, 610, 713, 724, 754, 909, 910, 933, 934, 935, 939, 940, 941, 942, 951, 952, 974, 986, 1005, 1019, 1054, 1118, 1128, 1133, 1151, 1256, 1423, 1468, 1634, 1741, 1750, 1762, 1764, 1767, 1773, 1776, 1784, 1785, 1789, 1793, 1798, 1800, 1802, 1803], "down": [2, 8, 14, 20, 29, 38, 39, 46, 47, 49, 53, 60, 693, 864, 900, 947, 953, 1039, 1075, 1358, 1524, 1617, 1769, 1772, 1777, 1789, 1791, 1798], "irrelev": [2, 4, 1742], "simpli": [2, 4, 14, 20, 29, 33, 41, 49, 59, 60, 962, 1017, 1028, 1162, 1188, 1423, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1588, 1738, 1740, 1759, 1765, 1767, 1770, 1771, 1783, 1793], "hand": [2, 5, 23, 35, 57, 60, 899, 905, 1028, 1074, 1079, 1090, 1092, 1162, 1260, 1278, 1709, 1721, 1738, 1740, 1741, 1759, 1767, 1770, 1775, 1781, 1793], "underwai": [2, 848, 1762], "up": [2, 7, 8, 9, 10, 14, 20, 21, 23, 27, 29, 32, 34, 35, 38, 39, 41, 45, 47, 48, 50, 51, 56, 60, 693, 699, 738, 850, 851, 853, 888, 905, 934, 935, 940, 942, 947, 962, 1021, 1034, 1039, 1042, 1043, 1088, 1158, 1173, 1197, 1295, 1297, 1301, 1302, 1312, 1338, 1347, 1358, 1415, 1423, 1494, 1595, 1617, 1718, 1719, 1735, 1738, 1740, 1745, 1747, 1750, 1751, 1752, 1753, 1759, 1760, 1761, 1762, 1766, 1767, 1768, 1770, 1773, 1777, 1781, 1783, 1784, 1789, 1790, 1800], "nonzero": [2, 53, 1027, 1111, 1113, 1114, 1119, 1731, 1737, 1739, 1779], "themselv": [2, 10, 29, 48, 53, 703, 1569, 1704, 1762, 1781, 1804], "did": [2, 8, 9, 23, 34, 35, 48, 1147, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1740, 1741, 1767, 1775, 1781], "relationship": [2, 10, 35, 45, 60, 792, 983, 1299, 1759, 1762, 1775, 1781], "conceptu": [2, 4, 1759, 1765, 1791], "tag": [2, 4, 8, 23, 1101, 1735, 1736, 1769, 1781, 1798], "eventu": [2, 8, 48, 53, 1735, 1782], "itt": [2, 1783], "intel": [2, 5, 1736, 1776], "r": [2, 29, 35, 38, 58, 127, 737, 739, 740, 754, 755, 756, 783, 794, 803, 905, 963, 965, 968, 971, 972, 975, 983, 1041, 1059, 1061, 1065, 1066, 1067, 1068, 1069, 1070, 1075, 1076, 1079, 1081, 1088, 1090, 1092, 1093, 1102, 1193, 1194, 1203, 1262, 1263, 1281, 1338, 1339, 1388, 1389, 1432, 1492, 1523, 1728, 1738, 1739, 1740, 1759, 1761, 1764, 1767, 1776, 1796, 1798], "vtune_flag": 2, "instrument": [2, 4, 21, 1736, 1769, 1803], "technolog": [2, 1736], "applic": [2, 3, 10, 29, 33, 48, 746, 832, 967, 1186, 1187, 1295, 1297, 1330, 1423, 1531, 1542, 1543, 1544, 1545, 1721, 1736, 1747, 1754, 1759, 1761, 1762, 1763, 1764, 1768, 1769, 1770, 1774, 1777, 1784, 1789, 1790, 1791, 1793, 1799], "across": [2, 9, 14, 20, 21, 23, 27, 35, 39, 49, 53, 57, 60, 589, 722, 760, 824, 863, 864, 905, 919, 971, 1040, 1045, 1131, 1187, 1197, 1238, 1256, 1258, 1289, 1301, 1317, 1349, 1365, 1411, 1423, 1428, 1444, 1448, 1470, 1547, 1620, 1728, 1736, 1738, 1750, 1752, 1754, 1759, 1763, 1766, 1769, 1770, 1772, 1773, 1774, 1782, 1785, 1789, 1790, 1795, 1798, 1803], "tool": [2, 5, 9, 10, 17, 23, 33, 34, 37, 38, 49, 60, 758, 1586, 1735, 1736, 1738, 1740, 1761, 1762, 1776, 1781, 1783, 1803], "With": [2, 17, 20, 23, 29, 33, 35, 38, 53, 59, 653, 654, 655, 656, 657, 699, 864, 926, 927, 928, 936, 937, 938, 1046, 1168, 1169, 1170, 1179, 1180, 1182, 1183, 1196, 1213, 1214, 1215, 1289, 1300, 1302, 1323, 1326, 1358, 1383, 1415, 1491, 1599, 1742, 1759, 1762, 1764, 1789, 1793, 1798], "abl": [2, 3, 8, 9, 17, 23, 31, 33, 38, 48, 57, 962, 1028, 1040, 1293, 1423, 1738, 1745, 1752, 1759, 1764, 1765, 1775, 1777, 1781, 1784, 1789, 1793, 1800], "labl": 2, "gui": 2, "detect_anomali": 2, "check_nan": 2, "engin": [2, 9, 10, 12, 15, 33, 311, 655, 656, 657, 744, 754, 971, 1595, 1728, 1736, 1759, 1762, 1763, 1764, 1778, 1789, 1790], "traceback": [2, 17, 38, 41, 49, 59, 60, 1005, 1015, 1740, 1741, 1742, 1751, 1754, 1764, 1774, 1793, 1800], "fail": [2, 8, 23, 29, 31, 32, 33, 35, 38, 39, 40, 41, 46, 47, 48, 49, 51, 59, 60, 755, 756, 812, 864, 1031, 1037, 1040, 1059, 1088, 1093, 1101, 1102, 1119, 1476, 1741, 1743, 1751, 1759, 1762, 1764, 1772, 1773, 1776, 1777, 1781, 1789], "debug": [2, 3, 5, 9, 20, 33, 34, 45, 755, 756, 809, 841, 880, 978, 1059, 1420, 1421, 1422, 1555, 1631, 1639, 1736, 1740, 1759, 1761, 1762, 1763, 1768, 1769, 1770, 1774, 1776, 1778, 1781, 1802], "test": [2, 4, 14, 17, 23, 33, 37, 38, 46, 48, 49, 53, 60, 609, 615, 922, 924, 925, 930, 931, 936, 937, 938, 940, 942, 1016, 1017, 1021, 1022, 1024, 1025, 1654, 1736, 1738, 1742, 1750, 1751, 1759, 1762, 1767, 1774, 1777, 1780, 1798, 1803, 1804], "slow": [2, 755, 1039, 1043, 1059, 1060, 1463, 1718, 1767, 1772, 1798], "import": [2, 3, 4, 8, 10, 14, 16, 17, 20, 21, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 38, 40, 42, 45, 46, 50, 53, 56, 57, 58, 59, 60, 198, 655, 656, 657, 686, 687, 688, 702, 774, 781, 807, 956, 958, 961, 962, 963, 965, 966, 967, 968, 969, 1005, 1027, 1028, 1031, 1033, 1035, 1036, 1037, 1039, 1040, 1041, 1045, 1046, 1047, 1081, 1082, 1085, 1086, 1099, 1131, 1216, 1250, 1423, 1427, 1435, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1450, 1451, 1452, 1460, 1461, 1462, 1463, 1470, 1493, 1517, 1585, 1586, 1587, 1738, 1740, 1741, 1742, 1750, 1751, 1754, 1758, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1769, 1770, 1772, 1773, 1774, 1775, 1777, 1784, 1789, 1790, 1791, 1793, 1796, 1798, 1799, 1800, 1803, 1804], "myfunc": [2, 1765], "inp": [2, 20, 23, 60, 741, 742, 743, 1301, 1423, 1737, 1804], "clone": [2, 15, 20, 53, 230, 421, 744, 747, 777, 1034, 1193, 1414, 1700, 1709, 1737, 1739, 1751, 1754, 1775, 1779, 1783, 1793, 1795, 1796, 1800], "run_fn": [2, 6, 1582, 1588], "10": [2, 19, 20, 21, 23, 24, 29, 30, 31, 32, 33, 34, 35, 37, 38, 48, 50, 289, 297, 311, 444, 485, 531, 553, 555, 556, 557, 601, 602, 613, 659, 660, 674, 675, 676, 677, 679, 763, 775, 785, 787, 788, 789, 793, 807, 884, 885, 886, 887, 888, 903, 905, 922, 924, 927, 928, 930, 931, 934, 935, 937, 938, 940, 942, 948, 956, 973, 983, 993, 1019, 1035, 1040, 1041, 1047, 1052, 1055, 1082, 1084, 1085, 1100, 1102, 1104, 1109, 1111, 1112, 1113, 1114, 1116, 1124, 1135, 1140, 1156, 1157, 1158, 1160, 1161, 1167, 1170, 1173, 1174, 1177, 1180, 1183, 1193, 1194, 1202, 1203, 1204, 1205, 1215, 1220, 1221, 1222, 1247, 1251, 1252, 1257, 1260, 1261, 1265, 1267, 1289, 1293, 1294, 1295, 1296, 1297, 1301, 1324, 1327, 1331, 1338, 1339, 1349, 1418, 1423, 1427, 1448, 1456, 1471, 1479, 1499, 1505, 1507, 1590, 1591, 1599, 1624, 1637, 1643, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1653, 1662, 1676, 1688, 1689, 1697, 1701, 1702, 1705, 1707, 1721, 1729, 1735, 1738, 1739, 1740, 1741, 1742, 1747, 1759, 1762, 1763, 1770, 1773, 1774, 1775, 1776, 1777, 1779, 1793, 1794, 1796, 1798, 1799, 1800, 1805], "last": [2, 6, 7, 12, 20, 21, 24, 27, 29, 31, 38, 48, 59, 60, 291, 589, 608, 674, 725, 764, 773, 779, 789, 850, 888, 893, 897, 922, 924, 927, 928, 930, 931, 934, 935, 937, 938, 940, 942, 944, 987, 988, 992, 1005, 1007, 1015, 1027, 1051, 1085, 1088, 1093, 1130, 1135, 1158, 1171, 1186, 1194, 1196, 1202, 1220, 1222, 1237, 1257, 1260, 1264, 1265, 1278, 1294, 1295, 1301, 1318, 1339, 1348, 1361, 1384, 1385, 1423, 1424, 1469, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1615, 1624, 1662, 1670, 1671, 1672, 1674, 1675, 1676, 1684, 1688, 1702, 1704, 1707, 1726, 1727, 1740, 1741, 1750, 1752, 1754, 1759, 1762, 1764, 1767, 1774, 1777, 1781, 1782, 1793, 1799, 1800], "stdin": [2, 1005, 1754, 1764, 1774, 1793], "instal": [2, 4, 14, 15, 23, 35, 60, 1735, 1738, 1770, 1771, 1777, 1781, 1789, 1798], "_tensor": [2, 131], "py": [2, 5, 14, 17, 23, 27, 29, 31, 32, 33, 34, 35, 37, 38, 40, 47, 49, 53, 60, 1423, 1585, 1735, 1738, 1741, 1762, 1763, 1767, 1769, 1777, 1781, 1784, 1790], "93": [2, 589], "retain_graph": [2, 127, 740, 754, 971, 1728, 1739, 1758, 1759, 1789], "90": [2, 889, 1509, 1616], "allow_unreach": 2, "76": 2, "_forward_cl": 2, "tmp": [2, 4, 14, 23, 38, 46, 48, 1735, 1762, 1783], "53": [2, 454], "44": [2, 32, 297, 418, 908, 1165, 1245, 1463], "set_detect_anomali": 2, "behaviour": [2, 609, 610, 615, 808, 1347, 1385, 1505, 1639, 1735, 1773], "intermediari": [2, 14, 29, 746, 1759, 1767], "pack": [2, 27, 652, 653, 654, 655, 656, 657, 659, 660, 674, 695, 1045, 1046, 1121, 1187, 1202, 1220, 1265, 1458, 1459, 1460, 1461, 1739, 1748, 1754, 1759, 1766, 1776, 1784], "unpack": [2, 674, 743, 1045, 1077, 1121, 1187, 1461, 1468, 1741, 1742, 1759, 1764, 1766], "common": [2, 4, 9, 20, 35, 38, 39, 48, 57, 601, 703, 713, 768, 771, 776, 802, 900, 905, 950, 951, 952, 953, 973, 1052, 1101, 1139, 1168, 1169, 1170, 1173, 1289, 1329, 1419, 1421, 1422, 1608, 1620, 1685, 1736, 1741, 1746, 1753, 1759, 1762, 1764, 1765, 1766, 1770, 1772, 1775, 1777, 1781, 1793, 1794, 1797, 1800], "trade": [2, 6, 9, 53, 1093, 1167, 1761, 1766, 1785], "leav": [2, 9, 35, 39, 49, 127, 740, 1035, 1047, 1435, 1438, 1480, 1481, 1679, 1738, 1740, 1741, 1759, 1781, 1785], "especi": [2, 10, 12, 20, 23, 33, 34, 35, 60, 230, 777, 1414, 1740, 1759, 1764, 1765, 1773, 1775, 1784, 1789, 1793], "notic": [2, 23, 605, 925, 939, 1124, 1134, 1166, 1302, 1364, 1496, 1497, 1502, 1503, 1509, 1736, 1738, 1759, 1793], "fit": [2, 10, 38, 40, 57, 471, 759, 1027, 1483, 1610, 1782, 1800], "evalu": [2, 5, 9, 10, 27, 29, 36, 56, 60, 609, 615, 864, 968, 1030, 1158, 1162, 1168, 1169, 1170, 1188, 1205, 1213, 1214, 1215, 1222, 1250, 1264, 1268, 1289, 1390, 1411, 1435, 1483, 1499, 1530, 1588, 1595, 1741, 1742, 1764, 1770, 1793], "saved_tensors_hook": [2, 746, 1759], "pack_hook": [2, 1759], "unpack_hook": [2, 1759], "pair": [2, 23, 29, 33, 48, 50, 589, 713, 783, 807, 939, 1043, 1093, 1131, 1242, 1251, 1256, 1260, 1387, 1428, 1492, 1604, 1740, 1741, 1752, 1759, 1762, 1782, 1789, 1790, 1791, 1798, 1800, 1803], "retriev": [2, 6, 20, 21, 23, 27, 35, 39, 48, 60, 508, 737, 738, 1193, 1197, 1301, 1338, 1423, 1459, 1754, 1759, 1769, 1777, 1781, 1782, 1789, 1790, 1791], "everytim": 2, "store": [2, 4, 6, 14, 17, 21, 34, 35, 39, 49, 53, 60, 302, 308, 373, 602, 738, 775, 820, 822, 824, 975, 1030, 1037, 1040, 1060, 1071, 1072, 1073, 1102, 1107, 1119, 1193, 1250, 1278, 1423, 1432, 1434, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1458, 1550, 1553, 1668, 1735, 1736, 1738, 1753, 1754, 1755, 1763, 1764, 1765, 1766, 1769, 1781, 1784, 1789, 1790, 1791, 1793, 1795, 1798, 1799, 1803], "access": [2, 10, 17, 20, 23, 33, 34, 37, 59, 528, 746, 818, 1030, 1033, 1045, 1092, 1158, 1250, 1418, 1425, 1426, 1427, 1433, 1437, 1459, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1736, 1738, 1739, 1741, 1742, 1745, 1748, 1751, 1753, 1754, 1759, 1762, 1766, 1767, 1769, 1770, 1789, 1793, 1796, 1797, 1799, 1805], "content": [2, 4, 8, 41, 60, 746, 1037, 1040, 1060, 1071, 1073, 1078, 1091, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1487, 1490, 1491, 1492, 1493, 1494, 1679, 1706, 1735, 1741, 1749, 1751, 1759, 1789, 1797, 1798, 1799], "equal": [2, 21, 23, 29, 48, 49, 50, 60, 236, 471, 516, 589, 610, 611, 612, 653, 654, 655, 656, 657, 674, 682, 683, 724, 764, 773, 784, 785, 797, 807, 822, 824, 876, 894, 910, 949, 963, 964, 974, 987, 988, 990, 991, 992, 1015, 1019, 1054, 1075, 1088, 1092, 1095, 1096, 1119, 1120, 1131, 1151, 1155, 1156, 1157, 1159, 1160, 1161, 1166, 1167, 1173, 1179, 1180, 1182, 1183, 1187, 1194, 1197, 1198, 1199, 1202, 1204, 1220, 1255, 1256, 1264, 1265, 1301, 1315, 1316, 1320, 1323, 1326, 1338, 1339, 1342, 1343, 1349, 1423, 1459, 1462, 1511, 1524, 1548, 1549, 1550, 1553, 1586, 1646, 1647, 1652, 1676, 1684, 1701, 1717, 1731, 1739, 1742, 1747, 1752, 1753, 1754, 1759, 1760, 1767, 1773, 1779, 1780, 1782, 1794, 1798, 1800], "term": [2, 9, 10, 29, 48, 60, 529, 677, 702, 785, 921, 922, 923, 924, 925, 926, 928, 936, 937, 938, 941, 953, 1061, 1158, 1166, 1204, 1211, 1220, 1221, 1255, 1264, 1281, 1344, 1356, 1390, 1400, 1423, 1427, 1432, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1477, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1494, 1608, 1653, 1736, 1741, 1758, 1759, 1764, 1765, 1766, 1767, 1777, 1781, 1784, 1790, 1793], "grad_fn": [2, 127, 311, 728, 740, 748, 749, 750, 751, 752, 753, 961, 1433, 1665, 1759, 1770, 1775], "mulbackward0": [2, 749, 752, 753], "inplac": [2, 56, 57, 60, 669, 672, 690, 692, 694, 744, 962, 1030, 1162, 1172, 1188, 1189, 1190, 1191, 1192, 1195, 1207, 1208, 1209, 1236, 1249, 1250, 1268, 1269, 1270, 1277, 1279, 1292, 1313, 1321, 1332, 1333, 1334, 1335, 1336, 1340, 1351, 1352, 1353, 1362, 1377, 1392, 1393, 1395, 1397, 1399, 1409, 1420, 1528, 1529, 1546, 1566, 1567, 1568, 1582, 1583, 1588, 1721, 1737, 1739, 1747, 1759, 1764, 1777, 1803], "lead": [2, 8, 19, 23, 30, 53, 58, 60, 744, 748, 750, 754, 756, 956, 971, 1060, 1220, 1265, 1281, 1679, 1728, 1741, 1753, 1754, 1759, 1761, 1763, 1764, 1765, 1773, 1776, 1780, 1781, 1784, 1793, 1798, 1799], "undefin": [2, 23, 30, 41, 53, 295, 444, 589, 726, 747, 755, 756, 779, 908, 957, 958, 1166, 1476, 1517, 1759, 1762, 1764, 1765], "inner": [2, 4, 53, 54, 58, 706, 708, 748, 888, 963, 967, 970, 1707, 1739, 1779, 1789, 1803], "save_on_cpu": 2, "pin_memori": [2, 20, 418, 419, 420, 421, 422, 906, 908, 1597, 1601, 1603, 1700, 1737, 1738, 1739, 1754, 1762, 1779, 1795], "within": [2, 6, 10, 20, 21, 23, 27, 29, 33, 34, 38, 48, 49, 50, 53, 59, 60, 65, 726, 755, 756, 815, 888, 1030, 1034, 1122, 1163, 1164, 1165, 1173, 1189, 1190, 1191, 1195, 1197, 1243, 1244, 1245, 1250, 1256, 1289, 1301, 1347, 1371, 1372, 1373, 1423, 1435, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1449, 1451, 1452, 1453, 1454, 1455, 1593, 1594, 1624, 1646, 1720, 1738, 1740, 1741, 1750, 1754, 1757, 1761, 1762, 1764, 1768, 1769, 1770, 1773, 1777, 1780, 1781, 1784, 1787, 1788, 1789, 1790, 1798], "move": [2, 6, 8, 9, 10, 14, 23, 35, 53, 60, 495, 561, 925, 1030, 1037, 1096, 1101, 1137, 1168, 1169, 1170, 1223, 1224, 1225, 1250, 1289, 1385, 1425, 1426, 1491, 1549, 1740, 1748, 1749, 1751, 1753, 1762, 1765, 1766, 1770, 1771, 1772, 1780, 1781, 1782, 1789, 1795, 1800], "copi": [2, 8, 12, 20, 21, 23, 34, 37, 39, 46, 53, 57, 60, 167, 173, 183, 186, 291, 377, 421, 431, 436, 444, 465, 471, 552, 553, 554, 555, 575, 589, 702, 727, 728, 742, 784, 792, 820, 821, 944, 945, 946, 947, 949, 962, 1030, 1041, 1102, 1150, 1187, 1197, 1250, 1260, 1301, 1423, 1458, 1546, 1566, 1567, 1605, 1611, 1617, 1700, 1709, 1715, 1738, 1739, 1751, 1754, 1759, 1760, 1762, 1764, 1772, 1779, 1781, 1782, 1783, 1784, 1789, 1793, 1795, 1796, 1797, 1799, 1803], "pin": [2, 186, 313, 418, 419, 420, 421, 422, 436, 552, 575, 906, 908, 1030, 1250, 1458, 1597, 1601, 1603, 1700, 1736, 1754, 1795], "asynchron": [2, 4, 5, 59, 173, 186, 552, 575, 833, 1030, 1033, 1048, 1250, 1736, 1742, 1761, 1763, 1789, 1795, 1798], "prod_1": 2, "prod_2": 2, "del": [2, 1742, 1751, 1764, 1766], "illustr": [2, 35, 1741, 1758, 1764, 1793], "aliv": [2, 20, 39, 48, 812, 1759, 1762, 1766, 1772, 1789, 1790, 1791], "live": [2, 27, 850, 853, 1030, 1250, 1738, 1762, 1766, 1789, 1791], "releas": [2, 8, 19, 23, 38, 48, 50, 60, 603, 785, 786, 808, 809, 810, 816, 832, 842, 843, 846, 850, 851, 853, 864, 976, 1030, 1060, 1071, 1073, 1074, 1075, 1078, 1091, 1119, 1120, 1190, 1216, 1220, 1250, 1265, 1359, 1371, 1372, 1373, 1470, 1523, 1604, 1620, 1684, 1688, 1694, 1709, 1735, 1736, 1740, 1750, 1751, 1759, 1761, 1762, 1768, 1773, 1774, 1775, 1776, 1777, 1784, 1789, 1799, 1800], "delet": [2, 23, 60, 741, 809, 817, 1735, 1748, 1751, 1759, 1779, 1788, 1789, 1791], "disable_saved_tensors_hook": 2, "error_messag": 2, "featur": [2, 9, 10, 12, 15, 17, 23, 27, 34, 49, 54, 59, 605, 674, 682, 683, 748, 750, 754, 880, 1041, 1124, 1134, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1168, 1183, 1188, 1189, 1190, 1191, 1195, 1198, 1199, 1202, 1203, 1213, 1220, 1221, 1256, 1265, 1267, 1284, 1293, 1295, 1297, 1298, 1299, 1300, 1315, 1316, 1333, 1334, 1335, 1340, 1342, 1343, 1364, 1423, 1513, 1721, 1736, 1738, 1740, 1741, 1742, 1745, 1753, 1754, 1759, 1764, 1766, 1767, 1774, 1777, 1778, 1783, 1784, 1789, 1793, 1798], "messag": [2, 3, 17, 23, 38, 41, 50, 57, 60, 596, 867, 869, 1059, 1060, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1509, 1735, 1738, 1739, 1741, 1742, 1766, 1777, 1782, 1783, 1789, 1791, 1800], "get": [2, 9, 12, 14, 20, 23, 24, 35, 36, 37, 38, 48, 49, 50, 51, 53, 57, 59, 60, 65, 127, 311, 602, 740, 743, 779, 835, 836, 837, 854, 892, 962, 965, 966, 967, 977, 1005, 1045, 1097, 1193, 1194, 1218, 1219, 1246, 1247, 1248, 1260, 1277, 1423, 1424, 1427, 1433, 1459, 1464, 1494, 1525, 1526, 1586, 1587, 1609, 1624, 1735, 1736, 1738, 1741, 1750, 1751, 1752, 1759, 1762, 1764, 1765, 1766, 1767, 1769, 1770, 1771, 1778, 1779, 1781, 1784, 1789, 1791, 1793, 1797, 1798, 1799, 1804], "variou": [3, 6, 14, 20, 23, 60, 1102, 1745, 1747, 1751, 1754, 1764, 1770, 1772, 1780, 1784, 1786, 1793, 1804], "is_built": [3, 1771], "built": [3, 4, 8, 9, 14, 21, 23, 31, 32, 35, 37, 38, 41, 56, 60, 796, 833, 1039, 1299, 1499, 1736, 1754, 1759, 1761, 1762, 1764, 1768, 1770, 1771, 1772, 1786, 1804], "necessarili": [3, 21, 23, 29, 39, 48, 444, 1066, 1088, 1099, 1130, 1186, 1257, 1762, 1764], "machin": [3, 23, 39, 48, 53, 54, 58, 1034, 1039, 1075, 1286, 1768, 1769, 1770, 1771, 1774, 1777, 1778, 1781, 1788, 1789, 1790], "driver": [3, 38, 975, 1075, 1093, 1094, 1739, 1762, 1773, 1789], "would": [3, 4, 6, 9, 10, 12, 14, 20, 23, 29, 33, 34, 38, 39, 41, 48, 49, 53, 55, 57, 60, 127, 418, 419, 420, 421, 422, 614, 674, 710, 740, 744, 754, 785, 906, 908, 926, 966, 967, 1028, 1030, 1031, 1035, 1037, 1045, 1046, 1163, 1164, 1165, 1166, 1167, 1202, 1216, 1220, 1243, 1244, 1245, 1250, 1260, 1265, 1347, 1358, 1418, 1423, 1424, 1458, 1468, 1597, 1601, 1603, 1614, 1624, 1700, 1701, 1706, 1738, 1740, 1741, 1752, 1753, 1754, 1755, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1767, 1775, 1777, 1781, 1782, 1784, 1789, 1790, 1791, 1793], "allow_tf32": [3, 1632, 1739, 1762, 1773], "tensorfloat": 3, "core": [3, 4, 8, 9, 35, 864, 1476, 1737, 1741, 1745, 1761, 1762, 1763, 1773, 1781], "amper": 3, "newer": [3, 14, 34, 1464, 1761, 1762, 1775, 1778, 1781, 1785], "tf32": 3, "allow_fp16_reduced_precision_reduct": [3, 1762, 1773], "precis": [3, 4, 9, 12, 14, 21, 29, 53, 602, 605, 755, 756, 763, 775, 853, 948, 979, 1075, 1093, 1099, 1124, 1134, 1163, 1164, 1165, 1167, 1178, 1179, 1180, 1181, 1182, 1183, 1203, 1221, 1237, 1243, 1244, 1245, 1302, 1358, 1423, 1617, 1632, 1637, 1736, 1741, 1750, 1755, 1759, 1770, 1781, 1784, 1785, 1787, 1794, 1796, 1798, 1799, 1805], "fp16": [3, 645, 1423, 1784, 1785], "gemm": [3, 33, 1761, 1777], "allow_bf16_reduced_precision_reduct": [3, 1762, 1773], "bf16": 3, "cufft_plan_cach": [3, 1762], "cufft": 3, "readonli": 3, "show": [3, 5, 8, 13, 17, 20, 21, 23, 30, 38, 60, 748, 754, 956, 1030, 1131, 1250, 1418, 1494, 1735, 1741, 1752, 1761, 1762, 1763, 1767, 1768, 1770, 1777, 1781, 1789, 1791], "max_siz": [3, 47, 49, 1762], "capac": [3, 876, 1762], "preferred_linalg_librari": 3, "algebra": [3, 10, 905, 1087, 1736, 1746], "cusolv": [3, 1093, 1094, 1688], "magma": [3, 787, 1075, 1119, 1523, 1688, 1776, 1793], "decid": [3, 5, 8, 23, 33, 48, 1448, 1747, 1777, 1793], "heurist": [3, 14, 20, 33, 38, 48, 49, 60, 905], "overrid": [3, 14, 21, 23, 24, 29, 41, 49, 53, 57, 60, 702, 703, 710, 850, 1166, 1167, 1184, 1186, 1210, 1217, 1241, 1242, 1253, 1254, 1255, 1257, 1264, 1281, 1282, 1298, 1319, 1320, 1330, 1359, 1382, 1390, 1439, 1620, 1637, 1736, 1741, 1745, 1780, 1781, 1784, 1789, 1798, 1803], "wherev": [3, 10, 35, 1752], "possibl": [3, 10, 14, 15, 17, 20, 23, 29, 33, 35, 38, 48, 53, 57, 60, 469, 470, 552, 589, 727, 728, 789, 818, 953, 965, 1030, 1043, 1045, 1070, 1072, 1077, 1083, 1086, 1087, 1090, 1095, 1101, 1167, 1173, 1250, 1338, 1339, 1358, 1391, 1415, 1423, 1437, 1438, 1480, 1583, 1608, 1611, 1626, 1676, 1684, 1700, 1738, 1740, 1741, 1751, 1752, 1757, 1759, 1761, 1762, 1763, 1764, 1767, 1772, 1773, 1774, 1776, 1781, 1784, 1789, 1791, 1796, 1800], "pick": [3, 23, 32, 47, 49, 485, 1759, 1789], "prefer": [3, 10, 20, 39, 53, 726, 750, 1028, 1070, 1083, 1087, 1095, 1102, 1257, 1587, 1624, 1684, 1700, 1738, 1762, 1781, 1793], "achiev": [3, 20, 21, 23, 29, 38, 49, 53, 905, 1030, 1173, 1250, 1257, 1349, 1423, 1762, 1769, 1781, 1789, 1791], "better": [3, 4, 8, 9, 10, 14, 20, 23, 31, 32, 33, 35, 38, 39, 875, 961, 965, 966, 1005, 1017, 1045, 1186, 1283, 1402, 1423, 1505, 1595, 1741, 1758, 1759, 1761, 1762, 1767, 1776, 1777, 1780, 1783, 1785, 1793, 1798, 1803], "select": [3, 12, 15, 18, 20, 23, 29, 35, 39, 289, 291, 293, 297, 674, 785, 815, 816, 826, 827, 828, 829, 831, 852, 856, 858, 859, 860, 862, 864, 865, 866, 870, 871, 872, 875, 876, 879, 881, 883, 925, 1102, 1131, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1202, 1220, 1265, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1453, 1454, 1627, 1697, 1731, 1738, 1739, 1741, 1751, 1752, 1753, 1754, 1759, 1761, 1762, 1767, 1774, 1779, 1784, 1793, 1797, 1800], "incorrect": [3, 5, 53, 60, 230, 485, 527, 746, 777, 1045, 1088, 1101, 1414, 1470, 1684, 1738, 1741, 1762, 1773, 1777], "linalg": [3, 381, 785, 786, 787, 788, 808, 891, 975, 1008, 1110, 1119, 1120, 1121, 1125, 1126, 1432, 1433, 1437, 1470, 1510, 1515, 1517, 1523, 1659, 1688, 1689, 1694, 1709, 1725, 1736], "inv": [3, 29, 787, 1008, 1061, 1065, 1071, 1087, 1091, 1095], "inv_ex": 3, "cholesky_ex": [3, 1059], "lu_factor": [3, 1078, 1079, 1119, 1120, 1121], "lu": [3, 11, 1071, 1077, 1078, 1079, 1120, 1121, 1739], "eigh": [3, 1059, 1065, 1068, 1087, 1093, 1694, 1773], "eighval": 3, "svdval": [3, 1061, 1075, 1084, 1093, 1688, 1773], "_linalgbackend": 3, "sdpbackend": 3, "enum": [3, 23, 35, 705, 1777, 1784, 1789], "scale": [3, 8, 20, 29, 33, 39, 47, 49, 74, 446, 448, 589, 601, 605, 606, 607, 652, 653, 654, 655, 656, 657, 658, 663, 664, 665, 666, 667, 668, 669, 670, 673, 684, 686, 687, 688, 689, 691, 694, 695, 763, 919, 920, 923, 941, 970, 971, 1116, 1162, 1188, 1193, 1194, 1195, 1211, 1222, 1277, 1296, 1302, 1303, 1304, 1338, 1339, 1340, 1356, 1358, 1397, 1402, 1478, 1499, 1531, 1534, 1547, 1548, 1549, 1550, 1553, 1590, 1591, 1592, 1593, 1594, 1666, 1667, 1685, 1728, 1736, 1739, 1753, 1757, 1762, 1766, 1770, 1784, 1785, 1787, 1794], "product": [3, 15, 23, 29, 48, 127, 602, 605, 606, 607, 674, 740, 742, 749, 751, 752, 753, 754, 763, 775, 781, 785, 803, 808, 866, 883, 886, 902, 905, 968, 970, 971, 1007, 1050, 1062, 1069, 1095, 1096, 1098, 1124, 1131, 1134, 1142, 1202, 1203, 1220, 1221, 1296, 1346, 1432, 1511, 1512, 1521, 1702, 1717, 1725, 1728, 1736, 1738, 1752, 1759, 1767, 1769, 1773, 1781, 1793], "attent": [3, 8, 1256, 1293, 1295, 1296, 1297, 1428, 1776, 1797], "stai": [3, 8, 27, 116, 1187, 1762, 1772, 1784, 1789, 1793], "inlin": [3, 14, 59, 850, 1030, 1034, 1045, 1761], "src": [3, 4, 23, 60, 173, 205, 289, 297, 444, 484, 485, 486, 487, 488, 489, 491, 509, 896, 962, 1140, 1293, 1296, 1297, 1476, 1621, 1622, 1623, 1627, 1658, 1696, 1737, 1739, 1781], "transform": [3, 4, 20, 34, 35, 57, 695, 786, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 961, 962, 963, 967, 970, 1027, 1039, 1171, 1205, 1213, 1214, 1215, 1222, 1237, 1278, 1294, 1295, 1296, 1297, 1312, 1318, 1347, 1364, 1383, 1418, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1529, 1566, 1567, 1582, 1583, 1653, 1684, 1736, 1765, 1782, 1784, 1798, 1803], "sdp_utils_cpp": 3, "h": [3, 5, 11, 14, 29, 460, 655, 656, 657, 674, 1059, 1066, 1069, 1079, 1093, 1156, 1157, 1164, 1165, 1169, 1170, 1174, 1179, 1180, 1182, 1190, 1191, 1193, 1195, 1202, 1203, 1214, 1215, 1220, 1221, 1222, 1233, 1234, 1244, 1245, 1262, 1263, 1265, 1267, 1284, 1300, 1303, 1304, 1312, 1347, 1382, 1388, 1389, 1432, 1433, 1464, 1476, 1688, 1739, 1752, 1753, 1759, 1762, 1763, 1766, 1767, 1777, 1797, 1798, 1799], "flash_sdp_en": 3, "flash": 3, "sdp": 3, "enable_mem_efficient_sdp": 3, "mem_efficient_sdp_en": 3, "enable_flash_sdp": 3, "math_sdp_en": 3, "math": [3, 20, 38, 60, 915, 1079, 1081, 1359, 1513, 1595, 1689, 1736, 1738, 1740, 1741, 1773, 1793, 1794, 1800], "enable_math_sdp": 3, "sdp_kernel": 3, "enable_flash": 3, "enable_math": 3, "enable_mem_effici": 3, "temporarili": [3, 39, 1628, 1759, 1777, 1783], "upon": [3, 20, 24, 39, 41, 60, 1423, 1434, 1437, 1751, 1759, 1762, 1777, 1784, 1791], "previou": [3, 17, 23, 33, 48, 60, 527, 674, 842, 950, 983, 1040, 1100, 1116, 1202, 1220, 1265, 1423, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1595, 1684, 1748, 1759, 1762, 1764, 1770, 1776, 1784, 1791], "version": [3, 6, 9, 14, 19, 21, 23, 29, 37, 38, 49, 53, 56, 60, 67, 69, 71, 73, 75, 77, 79, 81, 83, 85, 87, 98, 100, 102, 104, 107, 108, 110, 118, 120, 123, 124, 126, 129, 135, 137, 139, 141, 143, 145, 154, 163, 171, 175, 178, 180, 190, 192, 208, 212, 214, 220, 223, 225, 227, 229, 233, 238, 245, 247, 249, 253, 255, 259, 261, 268, 270, 272, 280, 282, 284, 286, 288, 290, 292, 294, 331, 333, 335, 337, 339, 341, 343, 346, 348, 350, 351, 358, 360, 362, 364, 366, 370, 374, 376, 394, 397, 400, 402, 412, 414, 416, 424, 429, 439, 442, 458, 462, 464, 480, 483, 484, 486, 488, 494, 498, 500, 503, 505, 507, 520, 522, 524, 527, 533, 535, 543, 547, 549, 565, 568, 570, 572, 574, 584, 594, 650, 651, 663, 664, 665, 666, 667, 668, 689, 690, 691, 692, 694, 698, 699, 711, 712, 814, 853, 987, 1005, 1027, 1030, 1033, 1034, 1037, 1040, 1059, 1072, 1073, 1077, 1078, 1091, 1124, 1149, 1167, 1220, 1250, 1251, 1265, 1302, 1312, 1337, 1347, 1354, 1363, 1394, 1396, 1410, 1411, 1415, 1419, 1428, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1464, 1491, 1493, 1494, 1567, 1583, 1621, 1622, 1623, 1682, 1683, 1684, 1688, 1706, 1721, 1723, 1724, 1735, 1752, 1753, 1759, 1760, 1762, 1764, 1765, 1767, 1768, 1769, 1770, 1771, 1774, 1776, 1777, 1778, 1780, 1781, 1783, 1787, 1793, 1801], "is_avail": [3, 16, 23, 1736, 1762, 1768, 1771, 1783], "determinist": [3, 4, 6, 19, 23, 29, 60, 65, 485, 721, 978, 1011, 1033, 1045, 1046, 1127, 1130, 1132, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1220, 1265, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1625, 1631, 1721, 1739, 1759, 1774, 1780, 1788], "algorithm": [3, 4, 8, 12, 18, 21, 24, 27, 29, 39, 53, 65, 674, 693, 699, 785, 1027, 1070, 1077, 1083, 1087, 1093, 1102, 1119, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1197, 1200, 1202, 1220, 1265, 1301, 1302, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1347, 1358, 1415, 1423, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1494, 1513, 1617, 1632, 1688, 1689, 1721, 1736, 1759, 1762, 1773, 1789, 1793], "are_deterministic_algorithms_en": 3, "use_deterministic_algorithm": [3, 721, 1011, 1631, 1774], "benchmark": [3, 33, 1736, 1739, 1762, 1768], "fastest": [3, 725, 1423, 1469, 1767, 1774], "benchmark_limit": 3, "specifi": [3, 4, 6, 9, 14, 20, 21, 23, 27, 29, 39, 41, 46, 47, 48, 49, 53, 60, 74, 127, 172, 235, 295, 307, 444, 454, 465, 469, 471, 472, 485, 487, 489, 508, 516, 517, 531, 552, 555, 575, 655, 656, 657, 682, 683, 703, 710, 726, 728, 740, 754, 766, 789, 795, 806, 807, 808, 811, 812, 820, 821, 822, 824, 839, 842, 853, 877, 886, 887, 888, 892, 893, 895, 905, 908, 919, 922, 924, 925, 927, 928, 930, 931, 932, 934, 935, 936, 937, 938, 940, 942, 963, 964, 967, 971, 972, 983, 991, 992, 1030, 1034, 1045, 1046, 1072, 1082, 1084, 1086, 1087, 1096, 1099, 1101, 1102, 1112, 1129, 1131, 1137, 1144, 1145, 1148, 1164, 1165, 1166, 1167, 1173, 1182, 1184, 1186, 1187, 1193, 1194, 1197, 1204, 1210, 1211, 1216, 1217, 1220, 1241, 1242, 1247, 1250, 1253, 1254, 1255, 1256, 1257, 1264, 1281, 1282, 1293, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1303, 1304, 1315, 1316, 1319, 1320, 1330, 1331, 1338, 1339, 1344, 1347, 1359, 1366, 1382, 1383, 1390, 1402, 1403, 1423, 1428, 1430, 1432, 1433, 1436, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1448, 1451, 1452, 1453, 1454, 1467, 1470, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1488, 1490, 1491, 1492, 1493, 1494, 1499, 1504, 1505, 1513, 1521, 1531, 1546, 1551, 1554, 1568, 1583, 1584, 1586, 1595, 1611, 1616, 1617, 1620, 1637, 1664, 1666, 1667, 1668, 1670, 1671, 1672, 1673, 1674, 1675, 1682, 1683, 1687, 1701, 1703, 1707, 1717, 1718, 1719, 1720, 1722, 1723, 1724, 1728, 1735, 1738, 1740, 1741, 1745, 1747, 1749, 1750, 1752, 1753, 1762, 1764, 1768, 1770, 1776, 1777, 1780, 1781, 1782, 1783, 1784, 1788, 1789, 1793, 1794, 1795, 1796, 1798, 1800], "maximum": [3, 29, 48, 49, 611, 613, 685, 722, 821, 856, 858, 864, 870, 871, 884, 885, 951, 967, 990, 991, 992, 1102, 1127, 1209, 1338, 1339, 1430, 1497, 1505, 1548, 1549, 1550, 1553, 1554, 1595, 1609, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1737, 1739, 1757, 1758, 1762, 1779, 1787, 1800], "try": [3, 4, 5, 8, 9, 23, 31, 33, 34, 40, 41, 45, 48, 53, 57, 876, 958, 967, 971, 1035, 1036, 1045, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1302, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1423, 1480, 1483, 1728, 1735, 1738, 1741, 1742, 1759, 1762, 1764, 1766, 1767, 1772, 1777, 1781, 1784, 1785, 1789, 1793], "dispatch": [3, 23, 33, 53, 60, 1035, 1741, 1745, 1762, 1764, 1777, 1804], "via": [3, 8, 12, 14, 15, 20, 23, 29, 33, 35, 46, 53, 60, 489, 589, 755, 756, 782, 809, 844, 864, 909, 965, 1102, 1168, 1169, 1170, 1187, 1205, 1213, 1214, 1215, 1222, 1289, 1432, 1464, 1467, 1505, 1738, 1740, 1741, 1750, 1751, 1754, 1757, 1759, 1762, 1764, 1765, 1766, 1768, 1770, 1772, 1773, 1777, 1781, 1784, 1789, 1790, 1793, 1796, 1797, 1804], "v8": 3, "verbos": [3, 14, 23, 33, 38, 60, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1735, 1753, 1777, 1778, 1798], "On": [3, 14, 19, 20, 23, 24, 29, 49, 57, 60, 602, 605, 763, 775, 1077, 1124, 1134, 1178, 1179, 1180, 1181, 1182, 1183, 1203, 1218, 1219, 1220, 1221, 1237, 1260, 1265, 1278, 1423, 1480, 1481, 1490, 1493, 1736, 1738, 1747, 1761, 1762, 1773, 1781, 1789, 1790, 1791, 1793], "demand": [3, 20, 844, 1740, 1769, 1789], "onemkl": 3, "easier": [3, 8, 20, 33, 38, 60, 1738, 1740, 1754, 1759, 1760, 1764, 1765], "dump": [3, 33, 35, 38, 60, 809, 1763, 1776], "durat": [3, 23, 33, 38, 45, 48, 1750, 1783], "kernel": [3, 4, 5, 12, 14, 17, 23, 33, 34, 53, 59, 653, 654, 655, 656, 657, 686, 687, 688, 812, 814, 815, 850, 851, 882, 883, 1163, 1164, 1165, 1178, 1179, 1180, 1181, 1182, 1183, 1197, 1198, 1199, 1218, 1219, 1226, 1227, 1228, 1229, 1230, 1231, 1243, 1244, 1245, 1246, 1247, 1248, 1301, 1322, 1323, 1324, 1325, 1326, 1327, 1342, 1343, 1435, 1738, 1745, 1748, 1754, 1762, 1764, 1765, 1771, 1773, 1777, 1783, 1785, 1793], "environ": [3, 4, 8, 14, 15, 17, 19, 21, 29, 33, 37, 38, 39, 41, 46, 51, 60, 1039, 1045, 1220, 1265, 1721, 1735, 1738, 1759, 1761, 1763, 1768, 1773, 1774, 1776, 1782, 1789], "variabl": [3, 4, 6, 14, 17, 19, 21, 29, 33, 34, 38, 39, 41, 46, 51, 53, 57, 60, 421, 628, 629, 630, 631, 632, 633, 634, 635, 636, 639, 640, 641, 642, 644, 645, 646, 647, 648, 652, 653, 654, 655, 656, 657, 659, 660, 670, 674, 678, 744, 803, 807, 875, 906, 971, 1043, 1045, 1102, 1171, 1178, 1179, 1180, 1181, 1182, 1183, 1187, 1193, 1194, 1202, 1203, 1220, 1221, 1222, 1235, 1237, 1250, 1253, 1258, 1265, 1267, 1423, 1427, 1458, 1459, 1460, 1461, 1462, 1474, 1478, 1495, 1496, 1497, 1498, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1531, 1597, 1599, 1601, 1721, 1728, 1733, 1735, 1736, 1747, 1753, 1754, 1759, 1761, 1763, 1766, 1767, 1773, 1774, 1776, 1777, 1780, 1784, 1789, 1798], "mkl_verbos": 3, "methodolog": 3, "larg": [3, 4, 8, 9, 20, 23, 33, 38, 60, 65, 805, 807, 864, 1075, 1093, 1158, 1197, 1301, 1341, 1423, 1505, 1583, 1657, 1668, 1736, 1751, 1753, 1754, 1761, 1762, 1766, 1770, 1773, 1775, 1777, 1781, 1782, 1785, 1789, 1793, 1796, 1799], "moreov": [3, 485, 1423], "investig": [3, 8, 23, 57], "enough": [3, 9, 21, 60, 1041, 1140, 1299, 1670, 1671, 1672, 1673, 1674, 1675, 1721, 1740, 1751, 1754, 1764, 1767, 1780, 1781, 1796, 1804], "scope": [3, 8, 50, 60, 958, 1289, 1448, 1738, 1740, 1741, 1762, 1766, 1777, 1781, 1791], "second": [3, 6, 14, 17, 23, 27, 35, 39, 41, 48, 50, 58, 60, 602, 605, 607, 610, 674, 722, 723, 724, 732, 755, 756, 763, 767, 768, 770, 771, 772, 775, 808, 866, 883, 893, 895, 896, 902, 910, 951, 952, 963, 966, 967, 968, 970, 971, 973, 974, 983, 986, 994, 995, 996, 1007, 1019, 1052, 1054, 1062, 1098, 1101, 1107, 1108, 1118, 1124, 1128, 1130, 1131, 1133, 1134, 1146, 1151, 1154, 1158, 1164, 1165, 1171, 1179, 1180, 1182, 1183, 1193, 1194, 1201, 1202, 1216, 1219, 1220, 1238, 1242, 1244, 1245, 1265, 1278, 1329, 1331, 1365, 1418, 1448, 1480, 1481, 1484, 1490, 1505, 1616, 1665, 1673, 1706, 1711, 1713, 1722, 1725, 1728, 1740, 1741, 1759, 1762, 1764, 1765, 1766, 1767, 1770, 1774, 1777, 1783, 1789, 1794, 1798], "verbose_on": 3, "level": [3, 4, 8, 9, 10, 15, 17, 20, 23, 33, 35, 36, 38, 39, 40, 41, 45, 53, 60, 471, 661, 741, 742, 743, 751, 814, 962, 975, 1187, 1423, 1736, 1737, 1738, 1741, 1742, 1750, 1751, 1754, 1757, 1759, 1761, 1764, 1767, 1778, 1781, 1783, 1784, 1785, 1789, 1793, 1798, 1802, 1803, 1804], "verbose_off": 3, "dnn": [3, 1761], "onednn": [3, 711, 712, 1032, 1038, 1584, 1784], "former": [3, 53, 1220, 1250], "dnnl_verbos": 3, "verbose_on_cr": 3, "get_opt_einsum": 3, "packag": [3, 8, 9, 12, 16, 21, 29, 59, 1347, 1423, 1735, 1736, 1764, 1770, 1780, 1789, 1798, 1801], "els": [3, 8, 20, 23, 29, 31, 39, 40, 48, 60, 575, 674, 766, 1041, 1047, 1216, 1289, 1384, 1423, 1480, 1481, 1490, 1491, 1492, 1493, 1612, 1613, 1646, 1652, 1694, 1738, 1740, 1742, 1743, 1747, 1751, 1754, 1762, 1764, 1765, 1770, 1771, 1777, 1780, 1781, 1795], "einsum": [3, 1739, 1779], "readthedoc": [3, 905], "io": [3, 8, 20, 37, 905, 1037, 1040, 1101, 1220, 1221, 1620, 1776, 1784], "en": [3, 21, 905, 1768, 1798, 1805], "path_find": [3, 905], "html": [3, 4, 5, 8, 15, 49, 646, 647, 648, 649, 659, 660, 670, 675, 676, 677, 678, 679, 905, 1299, 1721, 1760, 1768, 1770, 1774, 1781, 1798], "calcul": [3, 6, 20, 23, 45, 682, 683, 783, 807, 893, 897, 905, 909, 1021, 1027, 1085, 1107, 1108, 1110, 1163, 1164, 1165, 1168, 1169, 1170, 1173, 1181, 1182, 1183, 1197, 1204, 1205, 1213, 1214, 1215, 1222, 1289, 1301, 1302, 1314, 1315, 1316, 1344, 1347, 1358, 1387, 1433, 1444, 1464, 1468, 1470, 1499, 1531, 1534, 1547, 1548, 1552, 1610, 1634, 1682, 1683, 1694, 1711, 1713, 1723, 1724, 1759, 1760, 1763, 1767, 1773, 1776, 1784, 1803], "path": [3, 4, 5, 9, 14, 23, 33, 35, 46, 48, 50, 51, 53, 60, 757, 758, 809, 810, 905, 1030, 1250, 1266, 1297, 1427, 1735, 1739, 1740, 1759, 1762, 1764, 1768, 1775, 1781, 1783, 1793, 1802], "contract": [3, 35, 905, 1702, 1736, 1753, 1781], "fall": [3, 8, 14, 20, 755, 992, 1043, 1101, 1211, 1281, 1356, 1400, 1735, 1777, 1784], "left": [3, 20, 60, 433, 471, 713, 764, 768, 773, 774, 779, 784, 905, 925, 932, 946, 949, 950, 954, 987, 988, 992, 1027, 1028, 1035, 1049, 1070, 1079, 1083, 1087, 1090, 1091, 1092, 1093, 1095, 1107, 1108, 1140, 1158, 1163, 1164, 1165, 1166, 1167, 1178, 1179, 1180, 1197, 1204, 1217, 1218, 1219, 1238, 1239, 1240, 1241, 1243, 1244, 1245, 1253, 1254, 1255, 1259, 1260, 1298, 1301, 1302, 1303, 1304, 1347, 1367, 1385, 1430, 1497, 1498, 1511, 1546, 1548, 1604, 1617, 1624, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1684, 1702, 1707, 1722, 1738, 1739, 1741, 1764, 1770, 1787, 1794], "strategi": [3, 4, 8, 20, 21, 23, 27, 33, 41, 53, 748, 750, 905, 965, 1043, 1158, 1423, 1505, 1740, 1765, 1767, 1785], "auto": [3, 23, 54, 905, 1166, 1167, 1741, 1777, 1798], "greedi": [3, 27, 905], "doc": [3, 4, 5, 10, 15, 48, 49, 646, 647, 648, 649, 659, 660, 670, 675, 676, 677, 678, 679, 971, 1048, 1294, 1295, 1296, 1297, 1568, 1721, 1728, 1742, 1751, 1760, 1763, 1764, 1770, 1774, 1777, 1781, 1798], "timer": [4, 26], "stmt": [4, 1761], "setup": [4, 14, 21, 48, 49, 971, 1423, 1548, 1549, 1550, 1553, 1728, 1761, 1762, 1771, 1789, 1790], "global_setup": 4, "perf_count": 4, "global": [4, 6, 9, 20, 23, 27, 29, 32, 33, 38, 39, 49, 53, 57, 59, 60, 710, 713, 721, 764, 773, 859, 866, 906, 908, 918, 923, 941, 959, 962, 987, 988, 1011, 1018, 1030, 1033, 1045, 1049, 1100, 1116, 1250, 1420, 1421, 1422, 1423, 1444, 1448, 1474, 1586, 1597, 1599, 1601, 1604, 1628, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1733, 1738, 1741, 1742, 1755, 1758, 1764, 1769, 1770, 1772, 1774, 1784, 1789, 1790, 1791, 1796, 1798], "label": [4, 7, 8, 20, 27, 905, 1158, 1167, 1173, 1184, 1186, 1210, 1242, 1253, 1254, 1331, 1459, 1498, 1763, 1772, 1774, 1798], "sub_label": 4, "descript": [4, 8, 13, 14, 20, 38, 41, 48, 60, 1001, 1002, 1003, 1075, 1102, 1312, 1427, 1523, 1740, 1741, 1762, 1764, 1767, 1769, 1770, 1777, 1805], "env": [4, 23, 29, 33, 38, 41, 46, 48, 51, 60, 864, 1763, 1773, 1789], "num_thread": 4, "languag": [4, 14, 41, 1041, 1158, 1293, 1346, 1766], "measur": [4, 29, 45, 811, 856, 858, 1061, 1166, 1167, 1184, 1210, 1217, 1241, 1242, 1298, 1299, 1319, 1320, 1378, 1507, 1762, 1769, 1770, 1780, 1793], "statement": [4, 29, 35, 57, 60, 1031, 1045, 1742, 1759, 1764, 1772, 1775, 1777, 1781, 1784, 1789], "full": [4, 8, 9, 15, 20, 21, 23, 27, 29, 32, 33, 35, 38, 48, 51, 53, 54, 57, 60, 485, 747, 764, 773, 933, 934, 935, 939, 940, 942, 960, 970, 971, 987, 988, 1034, 1067, 1068, 1075, 1076, 1077, 1088, 1093, 1094, 1102, 1119, 1167, 1173, 1204, 1264, 1293, 1322, 1323, 1324, 1331, 1344, 1390, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1637, 1688, 1689, 1728, 1735, 1737, 1738, 1739, 1740, 1741, 1743, 1753, 1758, 1762, 1763, 1764, 1767, 1770, 1773, 1774, 1779, 1781, 1784, 1787, 1790, 1797], "org": [4, 5, 8, 10, 11, 15, 21, 29, 37, 49, 646, 647, 648, 649, 659, 660, 670, 675, 676, 677, 678, 679, 1102, 1220, 1268, 1269, 1296, 1299, 1467, 1513, 1653, 1735, 1742, 1759, 1760, 1770, 1774, 1776, 1777, 1781, 1798, 1805], "timeit": [4, 1761], "sever": [4, 15, 20, 23, 29, 53, 60, 652, 653, 654, 655, 656, 657, 680, 681, 686, 687, 688, 696, 697, 795, 853, 909, 1005, 1030, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1163, 1164, 1165, 1166, 1178, 1179, 1180, 1181, 1182, 1183, 1198, 1199, 1218, 1219, 1238, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1303, 1304, 1306, 1307, 1308, 1309, 1310, 1311, 1314, 1322, 1323, 1324, 1325, 1326, 1327, 1342, 1343, 1365, 1368, 1369, 1371, 1372, 1373, 1423, 1434, 1435, 1437, 1438, 1468, 1476, 1593, 1594, 1634, 1717, 1738, 1758, 1759, 1761, 1762, 1769, 1770, 1777, 1780, 1784, 1789], "kei": [4, 20, 34, 35, 39, 46, 48, 49, 53, 60, 575, 710, 759, 872, 961, 969, 1030, 1045, 1046, 1101, 1250, 1251, 1256, 1260, 1293, 1294, 1295, 1296, 1297, 1428, 1451, 1465, 1584, 1736, 1739, 1740, 1741, 1745, 1762, 1764, 1769, 1770, 1775, 1777, 1779, 1780, 1783, 1784, 1787, 1789, 1790, 1795, 1798, 1800, 1802], "awar": [4, 8, 459, 628, 629, 630, 631, 632, 633, 634, 635, 636, 646, 647, 648, 649, 711, 1423, 1566, 1567, 1587, 1588, 1692, 1693, 1753, 1759, 1762, 1781, 1787, 1790, 1793], "element": [4, 20, 23, 29, 34, 57, 58, 60, 74, 96, 127, 131, 173, 193, 218, 230, 234, 262, 289, 291, 293, 295, 297, 328, 373, 375, 377, 427, 444, 446, 447, 469, 471, 485, 487, 489, 492, 516, 517, 529, 531, 581, 582, 589, 597, 599, 600, 603, 604, 609, 610, 614, 615, 672, 674, 684, 685, 686, 687, 688, 694, 698, 703, 722, 724, 725, 726, 729, 730, 731, 732, 733, 740, 748, 749, 751, 752, 753, 765, 774, 777, 784, 790, 794, 801, 803, 804, 805, 850, 884, 885, 886, 887, 888, 889, 892, 894, 895, 896, 900, 902, 905, 908, 910, 911, 915, 935, 939, 940, 942, 944, 949, 951, 952, 954, 958, 963, 964, 966, 967, 968, 970, 971, 972, 973, 974, 975, 983, 986, 989, 990, 991, 992, 1007, 1015, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1049, 1051, 1052, 1054, 1071, 1073, 1077, 1088, 1092, 1103, 1104, 1106, 1109, 1111, 1112, 1113, 1114, 1118, 1119, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1138, 1140, 1145, 1146, 1148, 1149, 1150, 1151, 1152, 1162, 1163, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1188, 1189, 1190, 1191, 1192, 1194, 1195, 1197, 1202, 1203, 1206, 1207, 1208, 1209, 1210, 1211, 1216, 1217, 1220, 1222, 1226, 1227, 1228, 1229, 1230, 1231, 1236, 1239, 1241, 1242, 1243, 1244, 1245, 1249, 1251, 1253, 1254, 1255, 1256, 1257, 1258, 1260, 1261, 1262, 1263, 1264, 1265, 1267, 1268, 1269, 1270, 1277, 1279, 1280, 1281, 1282, 1283, 1285, 1286, 1288, 1289, 1290, 1291, 1292, 1293, 1298, 1299, 1301, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1330, 1332, 1336, 1339, 1340, 1345, 1346, 1350, 1351, 1352, 1353, 1356, 1359, 1360, 1362, 1367, 1371, 1372, 1373, 1377, 1378, 1382, 1383, 1385, 1388, 1389, 1390, 1391, 1392, 1393, 1397, 1398, 1399, 1400, 1402, 1404, 1406, 1407, 1408, 1409, 1414, 1428, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1451, 1452, 1458, 1459, 1461, 1462, 1469, 1470, 1471, 1473, 1516, 1517, 1520, 1521, 1593, 1594, 1596, 1607, 1610, 1611, 1615, 1617, 1619, 1637, 1640, 1642, 1654, 1655, 1657, 1658, 1662, 1667, 1670, 1671, 1672, 1673, 1674, 1675, 1677, 1678, 1682, 1683, 1687, 1696, 1698, 1699, 1703, 1704, 1705, 1707, 1709, 1710, 1711, 1712, 1713, 1715, 1717, 1718, 1719, 1723, 1724, 1725, 1728, 1731, 1739, 1741, 1747, 1754, 1757, 1760, 1761, 1764, 1767, 1773, 1775, 1777, 1780, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1804], "lazili": [4, 16, 811, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1418, 1738], "threadpool": 4, "comparison": [4, 21, 23, 36, 60, 1030, 1045, 1046, 1250, 1742, 1764, 1800, 1803], "appl": 4, "synchron": [4, 5, 16, 17, 21, 27, 33, 39, 48, 53, 59, 725, 811, 812, 814, 821, 841, 880, 1059, 1060, 1061, 1065, 1066, 1067, 1068, 1070, 1071, 1072, 1073, 1077, 1078, 1084, 1087, 1090, 1091, 1093, 1094, 1102, 1289, 1423, 1469, 1471, 1610, 1736, 1761, 1762, 1763, 1768, 1772, 1782, 1789], "focu": [4, 33, 35, 1507], "replic": [4, 20, 53, 983, 1040, 1178, 1179, 1180, 1187, 1197, 1226, 1227, 1228, 1274, 1275, 1276, 1301, 1385, 1411, 1782], "particularli": [4, 20, 21, 50, 1186, 1187, 1257, 1738, 1762], "variat": [4, 29, 38, 1741, 1764, 1785], "confound": 4, "quantifi": [4, 1299], "nois": [4, 38, 1739, 1774], "median": [4, 29, 150, 1146, 1721, 1739, 1752, 1779], "robust": [4, 1102, 1751, 1770], "deviat": [4, 29, 352, 1162, 1168, 1169, 1170, 1205, 1213, 1214, 1215, 1222, 1289, 1471, 1647, 1652, 1682, 1683, 1757], "merg": [4, 7, 8, 10, 20, 23, 49, 1251, 1256, 1260], "repeat": [4, 29, 57, 466, 807, 905, 1093, 1119, 1319, 1320, 1513, 1610, 1668, 1688, 1689, 1703, 1737, 1739, 1741, 1779, 1783, 1786, 1793], "autorang": 4, "exact": [4, 14, 20, 33, 38, 39, 50, 315, 655, 656, 657, 722, 723, 724, 755, 756, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 1130, 1182, 1220, 1358, 1423, 1508, 1663, 1757, 1763, 1772, 1793, 1804], "discuss": [4, 9, 10, 11, 29, 33, 36, 60, 1211, 1747, 1759, 1764, 1770, 1774, 1789, 1791, 1793], "docstr": [4, 14, 60, 1030, 1250, 1586, 1587, 1735, 1762], "adapt": [4, 680, 681, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1188, 1306, 1307, 1308, 1309, 1310, 1311, 1478, 1479, 1490, 1492, 1499, 1762], "metadata": [4, 41, 42, 1101, 1620, 1754, 1759, 1764, 1765, 1775, 1781, 1783, 1789, 1790, 1798], "field": [4, 8, 23, 27, 35, 39, 41, 45, 46, 60, 740, 1028, 1030, 1158, 1166, 1167, 1184, 1186, 1210, 1216, 1217, 1241, 1242, 1250, 1253, 1254, 1255, 1257, 1264, 1281, 1282, 1298, 1312, 1319, 1320, 1330, 1347, 1359, 1382, 1390, 1458, 1488, 1554, 1750, 1759, 1763, 1772, 1777, 1789, 1790, 1798], "displai": [4, 17, 33, 38, 852, 865, 1358, 1415, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1735, 1742, 1749, 1777, 1798, 1800], "instruct": [4, 5, 12, 14, 33, 35, 38, 50, 59, 1738, 1741, 1773, 1777, 1800], "count": [4, 20, 29, 35, 45, 60, 766, 806, 846, 958, 991, 992, 1028, 1067, 1068, 1458, 1718, 1719, 1739, 1750, 1779, 1783, 1789, 1791, 1793], "wall": 4, "callgrind": 4, "analog": [4, 35, 60, 610, 888, 926, 928, 1005, 1079, 1220, 1493, 1688, 1703, 1770], "constructor": [4, 14, 20, 21, 27, 53, 60, 1158, 1255, 1260, 1261, 1278, 1303, 1304, 1423, 1463, 1552, 1586, 1587, 1736, 1738, 1741, 1742, 1762, 1763, 1770, 1789, 1793, 1795, 1796, 1799, 1805], "specif": [4, 6, 8, 9, 10, 14, 23, 27, 29, 34, 35, 38, 39, 46, 48, 50, 53, 57, 60, 65, 485, 710, 759, 814, 896, 925, 992, 1027, 1034, 1039, 1043, 1045, 1046, 1130, 1197, 1222, 1420, 1421, 1439, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1490, 1491, 1492, 1493, 1494, 1586, 1627, 1735, 1738, 1740, 1741, 1743, 1745, 1750, 1753, 1755, 1759, 1762, 1768, 1772, 1774, 1777, 1780, 1781, 1783, 1784, 1785, 1787, 1789, 1791, 1798, 1799], "snippet": [4, 35, 49, 1735, 1770, 1775], "loop": [4, 21, 35, 50, 54, 57, 58, 60, 754, 853, 856, 858, 967, 971, 1045, 1423, 1435, 1480, 1587, 1588, 1728, 1738, 1739, 1741, 1750, 1761, 1762, 1766, 1767, 1770, 1773, 1777, 1783, 1784, 1798], "present": [4, 10, 20, 23, 48, 1028, 1119, 1158, 1220, 1260, 1458, 1476, 1735, 1749, 1751, 1752, 1753, 1758, 1759, 1762, 1764, 1767, 1770, 1777, 1781, 1790, 1793, 1796], "default_tim": 4, "summar": [4, 5, 35, 38, 49, 1637, 1741, 1754, 1793], "relu": [4, 21, 31, 34, 38, 57, 58, 60, 616, 617, 621, 622, 623, 624, 625, 626, 627, 631, 632, 633, 634, 635, 636, 639, 640, 641, 642, 643, 644, 645, 679, 702, 703, 710, 850, 963, 971, 1041, 1250, 1265, 1267, 1278, 1286, 1293, 1295, 1297, 1394, 1395, 1418, 1546, 1585, 1728, 1737, 1738, 1739, 1748, 1753, 1754, 1757, 1759, 1770, 1775, 1777, 1779, 1784, 1786, 1787], "readabl": [4, 13, 20, 46, 60, 852, 865, 1700, 1777, 1804], "supplement": 4, "disambigu": [4, 38, 46, 60, 1107], "ident": [4, 14, 20, 23, 29, 38, 60, 755, 756, 893, 1067, 1068, 1069, 1070, 1083, 1095, 1098, 1102, 1119, 1145, 1146, 1162, 1188, 1387, 1432, 1434, 1525, 1546, 1570, 1577, 1725, 1731, 1742, 1757, 1773, 1774, 1781, 1786, 1793], "our": [4, 8, 9, 23, 33, 34, 35, 38, 44, 47, 48, 49, 51, 57, 58, 60, 744, 925, 962, 1166, 1759, 1764, 1767, 1772, 1777, 1784, 1790, 1793], "easi": [4, 20, 31, 35, 36, 38, 48, 1738, 1759, 1766, 1769, 1770, 1772, 1781, 1784, 1789, 1790, 1793], "differenti": [4, 29, 54, 58, 127, 328, 561, 737, 739, 740, 742, 743, 745, 748, 749, 750, 751, 752, 753, 754, 755, 756, 792, 853, 966, 967, 968, 970, 1044, 1076, 1077, 1088, 1119, 1172, 1173, 1193, 1349, 1383, 1423, 1437, 1477, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493, 1534, 1721, 1736, 1747, 1764, 1766, 1767, 1777, 1789, 1799, 1801], "distinguish": [4, 1784, 1793], "princip": [4, 1076, 1513], "signal": [4, 12, 39, 48, 50, 652, 653, 654, 680, 681, 696, 697, 921, 922, 923, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 1027, 1092, 1155, 1156, 1157, 1159, 1160, 1161, 1163, 1164, 1165, 1178, 1179, 1180, 1198, 1199, 1218, 1219, 1238, 1243, 1244, 1245, 1303, 1304, 1306, 1307, 1308, 1309, 1310, 1311, 1314, 1322, 1325, 1342, 1343, 1365, 1368, 1369, 1371, 1372, 1373, 1684, 1736, 1751, 1772, 1783, 1789], "form": [4, 8, 10, 12, 20, 23, 29, 32, 47, 48, 49, 57, 60, 674, 693, 699, 786, 893, 933, 935, 1030, 1069, 1072, 1077, 1088, 1093, 1156, 1157, 1160, 1161, 1173, 1198, 1199, 1202, 1220, 1250, 1265, 1301, 1302, 1331, 1342, 1343, 1346, 1358, 1385, 1415, 1437, 1493, 1511, 1702, 1735, 1738, 1742, 1754, 1759, 1764, 1770, 1777, 1781, 1784, 1798], "treat": [4, 29, 47, 56, 60, 297, 444, 703, 755, 756, 850, 1082, 1085, 1087, 1099, 1101, 1111, 1112, 1113, 1114, 1131, 1148, 1194, 1204, 1222, 1254, 1255, 1256, 1257, 1260, 1278, 1283, 1339, 1423, 1469, 1499, 1617, 1684, 1696, 1703, 1740, 1741, 1752, 1759, 1789, 1793, 1796, 1803], "distinct": [4, 961, 1065, 1066, 1110, 1694, 1741, 1764, 1775, 1789, 1790], "workload": [4, 9, 20, 23, 53, 853, 1762, 1769, 1773, 1789], "good": [4, 8, 9, 14, 35, 53, 60, 65, 965, 1258, 1653, 1735, 1745, 1751, 1764, 1769, 1770, 1777, 1781, 1782, 1784], "intrins": [4, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 702, 703, 1785, 1786], "contrast": [4, 29, 39, 1493, 1737, 1757, 1759, 1765, 1793], "blocked_autorang": 4, "callback": [4, 21, 48, 50, 59, 60, 1423, 1750, 1769, 1783, 1789], "min_run_tim": 4, "minimum": [4, 14, 21, 39, 48, 49, 612, 613, 685, 723, 766, 885, 952, 990, 991, 992, 1132, 1173, 1209, 1299, 1497, 1498, 1505, 1548, 1549, 1550, 1553, 1554, 1653, 1670, 1671, 1672, 1673, 1674, 1675, 1737, 1739, 1757, 1759, 1767, 1778, 1779, 1787, 1796], "At": [4, 6, 7, 8, 15, 20, 32, 33, 35, 38, 939, 1178, 1179, 1180, 1181, 1182, 1183, 1218, 1219, 1748, 1754, 1761, 1767, 1784, 1789, 1794], "high": [4, 5, 8, 9, 10, 11, 15, 21, 23, 29, 33, 35, 38, 39, 45, 47, 49, 60, 96, 814, 1173, 1296, 1599, 1600, 1632, 1737, 1739, 1750, 1751, 1767, 1768, 1770, 1771, 1780, 1784, 1785, 1789, 1793, 1798, 1799, 1800, 1803], "pseudo": [4, 65], "total_tim": 4, "block_siz": 4, "choic": [4, 9, 10, 23, 33, 38, 1045, 1093, 1251, 1260, 1595, 1761, 1777, 1787, 1793], "block": [4, 8, 9, 20, 23, 27, 48, 50, 59, 60, 555, 556, 557, 774, 811, 864, 1050, 1102, 1178, 1179, 1180, 1181, 1182, 1183, 1197, 1226, 1227, 1228, 1229, 1230, 1231, 1253, 1301, 1341, 1414, 1423, 1670, 1671, 1672, 1738, 1740, 1741, 1750, 1751, 1755, 1759, 1762, 1763, 1767, 1777, 1784, 1789, 1793], "qualiti": [4, 8, 21], "balanc": [4, 65], "compet": 4, "statist": [4, 21, 23, 29, 33, 38, 856, 858, 859, 860, 862, 864, 865, 866, 870, 871, 872, 883, 1107, 1168, 1169, 1170, 1205, 1213, 1214, 1215, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1289, 1531, 1532, 1548, 1549, 1550, 1552, 1553, 1750, 1759, 1766, 1780, 1782, 1784, 1787], "amort": 4, "invoc": [4, 6, 35, 60, 1033, 1045, 1569, 1738, 1741, 1762, 1764, 1769, 1777, 1789, 1791], "less": [4, 7, 8, 14, 20, 21, 23, 29, 33, 39, 50, 339, 748, 750, 755, 756, 807, 860, 876, 905, 949, 953, 958, 961, 1054, 1066, 1102, 1118, 1119, 1158, 1211, 1264, 1281, 1287, 1461, 1608, 1694, 1711, 1713, 1735, 1739, 1741, 1754, 1762, 1764, 1772, 1773, 1779, 1782, 1784], "bias": [4, 21, 674, 1168, 1169, 1170, 1202, 1203, 1205, 1213, 1214, 1215, 1220, 1221, 1222, 1265, 1267, 1289, 1427], "trivial": [4, 39, 41, 785, 1428, 1432, 1777, 1791], "low": [4, 8, 17, 21, 29, 53, 471, 751, 814, 975, 1173, 1513, 1595, 1599, 1600, 1617, 1689, 1737, 1739, 1750, 1751, 1762, 1783, 1800, 1804], "digit": [4, 1637, 1735, 1749, 1769, 1773], "microsecond": [4, 1762], "bia": [4, 10, 23, 628, 629, 630, 631, 632, 633, 634, 635, 636, 641, 642, 643, 644, 645, 646, 647, 648, 649, 652, 653, 654, 655, 656, 657, 663, 665, 666, 667, 668, 670, 674, 675, 678, 679, 686, 687, 688, 695, 702, 703, 704, 969, 1030, 1039, 1158, 1171, 1178, 1179, 1180, 1181, 1182, 1183, 1202, 1203, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1237, 1250, 1256, 1265, 1266, 1267, 1317, 1318, 1322, 1323, 1324, 1325, 1326, 1327, 1348, 1357, 1361, 1364, 1418, 1423, 1427, 1428, 1432, 1433, 1447, 1449, 1451, 1464, 1467, 1592, 1737, 1739, 1748, 1764, 1770, 1775, 1784, 1786, 1798], "period": [4, 10, 27, 48, 764, 773, 852, 865, 866, 883, 925, 987, 988, 1049, 1509, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1739, 1750, 1772], "until": [4, 8, 20, 21, 23, 27, 33, 39, 48, 53, 59, 60, 459, 811, 812, 814, 844, 958, 1050, 1102, 1347, 1418, 1423, 1496, 1502, 1703, 1751, 1757, 1762, 1766, 1777, 1783, 1789, 1791], "overal": [4, 10, 20, 23, 48, 755, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 1296, 1759, 1761, 1762, 1772, 1785], "repetit": [4, 1610, 1703], "collect_callgrind": 4, "collect_baselin": 4, "retain_out_fil": 4, "callgrindstat": 4, "tupl": [4, 6, 14, 20, 35, 39, 45, 46, 48, 53, 60, 295, 418, 420, 422, 469, 492, 508, 531, 555, 611, 612, 613, 680, 681, 682, 683, 686, 687, 688, 693, 699, 700, 701, 703, 708, 709, 710, 726, 727, 734, 735, 736, 737, 738, 748, 749, 750, 751, 752, 753, 754, 755, 756, 778, 806, 820, 821, 824, 835, 853, 859, 884, 885, 903, 906, 908, 922, 924, 925, 927, 928, 930, 931, 932, 934, 935, 937, 938, 940, 942, 945, 955, 959, 961, 963, 964, 965, 966, 967, 968, 969, 970, 971, 975, 991, 993, 1030, 1036, 1041, 1045, 1046, 1051, 1060, 1065, 1066, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1082, 1086, 1088, 1089, 1091, 1093, 1096, 1099, 1117, 1119, 1121, 1127, 1129, 1131, 1132, 1135, 1137, 1145, 1148, 1155, 1156, 1157, 1159, 1160, 1161, 1163, 1164, 1165, 1173, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1187, 1197, 1198, 1199, 1218, 1219, 1226, 1227, 1228, 1229, 1230, 1231, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1251, 1256, 1260, 1271, 1272, 1273, 1274, 1275, 1276, 1300, 1301, 1302, 1303, 1304, 1305, 1307, 1308, 1310, 1311, 1314, 1315, 1316, 1322, 1323, 1324, 1325, 1326, 1327, 1342, 1343, 1358, 1371, 1372, 1373, 1385, 1415, 1416, 1417, 1421, 1422, 1428, 1437, 1448, 1461, 1465, 1469, 1470, 1474, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1513, 1514, 1523, 1586, 1587, 1597, 1599, 1601, 1611, 1615, 1616, 1662, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1682, 1683, 1687, 1688, 1689, 1694, 1700, 1701, 1702, 1703, 1704, 1709, 1716, 1717, 1718, 1719, 1723, 1724, 1728, 1729, 1731, 1733, 1738, 1739, 1742, 1751, 1754, 1759, 1762, 1764, 1765, 1770, 1775, 1777, 1781, 1784, 1789, 1793, 1798, 1800, 1803, 1804], "modulo": [4, 29, 953, 1608], "determin": [4, 9, 12, 14, 16, 17, 19, 20, 21, 23, 29, 33, 38, 39, 46, 48, 53, 57, 60, 748, 750, 755, 756, 764, 773, 780, 785, 854, 907, 926, 936, 960, 987, 988, 991, 992, 1043, 1063, 1075, 1086, 1089, 1110, 1124, 1194, 1198, 1199, 1220, 1256, 1259, 1265, 1339, 1342, 1343, 1358, 1391, 1415, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1475, 1505, 1551, 1554, 1598, 1600, 1602, 1629, 1670, 1671, 1672, 1673, 1674, 1675, 1684, 1734, 1741, 1742, 1753, 1762, 1763, 1764, 1770, 1777, 1781, 1784, 1789, 1791, 1796, 1798, 1800], "itself": [4, 6, 8, 9, 23, 24, 35, 38, 53, 58, 60, 609, 615, 727, 807, 966, 967, 1030, 1041, 1045, 1250, 1283, 1402, 1423, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1455, 1738, 1751, 1770, 1774, 1777, 1781, 1789, 1793, 1797], "jitter": 4, "interpret": [4, 20, 23, 27, 29, 35, 39, 48, 50, 693, 699, 728, 754, 863, 926, 927, 928, 933, 935, 936, 937, 938, 958, 980, 992, 1030, 1035, 1041, 1045, 1082, 1102, 1190, 1347, 1358, 1359, 1415, 1629, 1635, 1735, 1740, 1741, 1751, 1761, 1762, 1777, 1793, 1795, 1797], "ideal": [4, 33, 47, 49, 1045, 1753], "analysi": [4, 21, 29, 31, 36, 60, 1049, 1513, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1742, 1770, 1778, 1803], "valgrind": 4, "degrad": [4, 14, 1761, 1763, 1764, 1793], "due": [4, 5, 6, 8, 21, 23, 29, 33, 35, 38, 47, 53, 57, 60, 459, 728, 748, 749, 754, 803, 1042, 1065, 1066, 1093, 1119, 1190, 1204, 1293, 1302, 1358, 1463, 1689, 1738, 1754, 1762, 1763, 1767, 1768, 1774, 1777, 1784, 1785, 1789, 1791], "amelior": 4, "suffici": [4, 14, 21, 29, 33, 38, 40, 48, 53, 1735, 1793, 1796], "obtain": [4, 20, 23, 29, 41, 59, 60, 468, 760, 975, 1173, 1257, 1331, 1423, 1513, 1595, 1689, 1741, 1751, 1752, 1761, 1774, 1777, 1780, 1783, 1784], "callgrind_control": 4, "callgrind_annot": 4, "boundari": [4, 33, 60, 693, 699, 779, 983, 1175, 1176, 1177, 1271, 1272, 1273, 1274, 1275, 1276, 1302, 1305, 1358, 1415, 1499, 1505, 1624, 1739, 1763, 1781, 1782, 1789], "caller": [4, 39, 48, 60, 710, 1030, 1250, 1297, 1422, 1759, 1762, 1789, 1791], "structur": [4, 6, 10, 20, 21, 23, 30, 39, 41, 49, 60, 956, 968, 971, 1045, 1250, 1444, 1448, 1513, 1689, 1728, 1740, 1742, 1747, 1750, 1762, 1763, 1764, 1765, 1772, 1775, 1776, 1777, 1778, 1780, 1781, 1789, 1793, 1798, 1799, 1800, 1801, 1803], "restrict": [4, 9, 20, 29, 53, 57, 58, 1101, 1124, 1186, 1256, 1740, 1741, 1742, 1753, 1759, 1762, 1767, 1782, 1784], "builtin": [4, 23, 33, 38, 60, 1042, 1101, 1604, 1738, 1740, 1742, 1789, 1791], "surpris": [4, 9, 53, 1735, 1767, 1773], "serial": [4, 15, 20, 23, 27, 48, 1030, 1039, 1040, 1101, 1250, 1418, 1620, 1735, 1736, 1739, 1749, 1753, 1759, 1762, 1769, 1770, 1772, 1781, 1784, 1790], "subsequ": [4, 8, 14, 15, 23, 33, 35, 60, 812, 1030, 1041, 1045, 1178, 1179, 1180, 1181, 1182, 1183, 1250, 1278, 1422, 1762, 1774, 1777, 1789, 1793], "deseri": [4, 1101, 1418, 1735, 1749], "globalsbridg": 4, "care": [4, 8, 14, 23, 29, 33, 38, 53, 59, 60, 926, 928, 1250, 1694, 1751, 1761, 1762, 1763, 1764, 1766, 1770, 1772, 1775, 1777, 1789, 1793], "reli": [4, 10, 14, 20, 21, 33, 39, 41, 60, 127, 740, 755, 905, 1187, 1759, 1761, 1763, 1764, 1774, 1775, 1793, 1797], "pickl": [4, 20, 21, 23, 1030, 1101, 1250, 1620, 1751, 1775, 1781], "transfer": [4, 20, 23, 1748, 1751, 1762, 1768, 1770, 1781, 1789], "properli": [4, 8, 20, 21, 27, 39, 48, 53, 59, 926, 927, 928, 936, 937, 938, 1131, 1251, 1252, 1260, 1261, 1423, 1735, 1747, 1764, 1767, 1770, 1772, 1775, 1789, 1790, 1796], "profil": [4, 5, 33, 45, 60, 1043, 1420, 1421, 1422, 1637, 1736, 1779, 1789], "drive": [4, 10, 23, 35, 1759], "facil": [4, 1101, 1751], "analyz": [4, 5, 17, 38, 60, 1763, 1764, 1773], "manipul": [4, 59, 1034, 1736, 1758, 1766, 1770, 1782, 1787], "1000000": [4, 1477], "mirror": [4, 116], "semant": [4, 10, 16, 23, 48, 49, 53, 60, 127, 722, 723, 724, 740, 754, 777, 814, 864, 962, 971, 1034, 1040, 1099, 1391, 1719, 1728, 1736, 1740, 1741, 1745, 1747, 1754, 1765, 1770, 1777, 1793], "number_per_run": 4, "raw_tim": 4, "task_spec": 4, "serializ": [4, 21, 1738], "__repr__": [4, 1764], "consum": [4, 20, 30, 35, 50, 59, 905, 1751, 1762, 1772, 1777, 1778, 1798], "extrapol": 4, "sinc": [4, 8, 20, 21, 23, 29, 33, 35, 38, 41, 50, 53, 60, 291, 505, 661, 699, 703, 785, 856, 858, 860, 905, 945, 946, 947, 1027, 1030, 1035, 1040, 1043, 1119, 1166, 1193, 1246, 1247, 1248, 1250, 1302, 1312, 1347, 1349, 1415, 1418, 1420, 1448, 1470, 1480, 1497, 1498, 1499, 1505, 1684, 1694, 1738, 1739, 1740, 1741, 1748, 1750, 1754, 1758, 1759, 1762, 1764, 1765, 1766, 1767, 1769, 1770, 1775, 1776, 1777, 1779, 1781, 1782, 1783, 1784, 1788, 1789, 1790, 1791, 1793, 1794, 1796, 1797, 1799, 1800], "properti": [4, 20, 23, 24, 29, 32, 40, 45, 48, 53, 60, 702, 728, 760, 837, 921, 922, 924, 926, 927, 928, 936, 937, 938, 1028, 1030, 1162, 1283, 1402, 1418, 1424, 1425, 1426, 1458, 1736, 1741, 1745, 1750, 1759, 1762, 1767, 1780, 1783, 1789, 1793, 1795, 1796, 1799, 1801, 1804, 1805], "significant_figur": 4, "figur": [4, 8, 9, 33, 60, 1761, 1763, 1777, 1782, 1791, 1798, 1803], "intend": [4, 48, 60, 738, 746, 816, 1049, 1312, 1420, 1421, 1422, 1480, 1481, 1741, 1754, 1757, 1759, 1770, 1781], "interquartil": 4, "mitig": 4, "tail": [4, 20, 46], "z": [4, 11, 29, 38, 53, 57, 589, 725, 746, 786, 787, 797, 905, 909, 1131, 1203, 1347, 1437, 1468, 1469, 1517, 1548, 1612, 1613, 1738, 1739, 1740, 1753, 1759, 1761, 1762, 1767, 1768, 1777, 1781, 1787, 1789, 1791], "645": 4, "conjunct": [4, 20, 23, 27, 53, 1312, 1347, 1423, 1552, 1787], "trim_sigfig": 4, "human": [4, 13, 46, 852, 865, 1757, 1777, 1804], "raw": [4, 60, 958, 1088, 1762, 1781], "built_with_debug_symbol": 4, "baseline_inclusive_stat": 4, "baseline_exclusive_stat": 4, "stmt_inclusive_stat": 4, "stmt_exclusive_stat": 4, "stmt_callgrind_out": 4, "done": [4, 15, 20, 23, 29, 35, 39, 46, 53, 59, 60, 468, 755, 922, 924, 927, 928, 930, 931, 934, 935, 937, 938, 940, 942, 1045, 1119, 1168, 1169, 1170, 1187, 1190, 1213, 1214, 1215, 1232, 1233, 1234, 1235, 1260, 1289, 1295, 1297, 1423, 1679, 1741, 1745, 1748, 1751, 1761, 1762, 1763, 1765, 1766, 1770, 1773, 1777, 1782, 1784, 1785, 1789, 1791], "functioncount": 4, "stat": [4, 33, 38, 56, 864, 870, 871, 872, 1289, 1423, 1554, 1564, 1565, 1750, 1762, 1802], "as_standard": 4, "strip": [4, 1349, 1423, 1738, 1779], "prefix": [4, 23, 48, 53, 662, 671, 1030, 1250, 1423, 1735, 1759, 1777, 1781, 1802], "stumbl": 4, "filepath": 4, "dif": 4, "compon": [4, 8, 10, 15, 17, 23, 29, 35, 38, 60, 755, 925, 926, 928, 936, 937, 938, 1069, 1293, 1294, 1295, 1296, 1297, 1418, 1513, 1684, 1726, 1727, 1742, 1759, 1763, 1769, 1770, 1782, 1793], "locat": [4, 10, 14, 23, 29, 33, 45, 127, 131, 230, 485, 777, 779, 822, 884, 885, 1051, 1101, 1127, 1132, 1135, 1140, 1187, 1197, 1284, 1301, 1312, 1347, 1411, 1414, 1423, 1437, 1524, 1624, 1646, 1666, 1669, 1721, 1735, 1738, 1749, 1762, 1777, 1781, 1783, 1789, 1791, 1793, 1798, 1802], "someth": [4, 8, 31, 33, 34, 35, 38, 55, 60, 748, 750, 905, 1030, 1045, 1250, 1743, 1750, 1751, 1752, 1759, 1768, 1776, 1777, 1789, 1804], "resembl": [4, 15], "23234231": 4, "first_build_dir": 4, "9823794": 4, "bar": [4, 8, 35, 45, 60, 710, 807, 961, 1033, 1040, 1584, 1682, 1683, 1723, 1724, 1735, 1738, 1740, 1749, 1770, 1777, 1781, 1800], "53453": 4, "function_that_actually_chang": 4, "second_build_dir": 4, "cancel": [4, 1027], "site": [4, 8], "denois": 4, "explan": [4, 10, 33, 38, 41, 1030, 1250, 1587, 1736, 1763, 1764, 1770], "delta": [4, 29, 674, 1202, 1210, 1211, 1220, 1281, 1356, 1478, 1682, 1683, 1707, 1723, 1724, 1739, 1757], "inclus": [4, 29, 65, 485, 990, 992, 1100, 1116, 1122, 1599, 1600, 1681, 1788, 1800], "diff": [4, 8, 1738, 1739, 1779], "reason": [4, 9, 10, 20, 23, 33, 35, 38, 57, 926, 928, 1030, 1045, 1046, 1065, 1066, 1093, 1130, 1166, 1190, 1250, 1349, 1422, 1437, 1569, 1620, 1738, 1740, 1741, 1759, 1763, 1765, 1773, 1775, 1777, 1789, 1796, 1804], "unit": [4, 12, 14, 29, 39, 49, 53, 60, 674, 675, 923, 941, 1162, 1172, 1192, 1195, 1200, 1201, 1202, 1203, 1268, 1269, 1279, 1312, 1336, 1340, 1345, 1346, 1392, 1399, 1441, 1442, 1446, 1449, 1451, 1454, 1709, 1761, 1767, 1781], "next": [4, 20, 23, 29, 32, 33, 34, 35, 48, 53, 60, 531, 674, 1034, 1154, 1203, 1221, 1267, 1359, 1423, 1460, 1751, 1758, 1759, 1761, 1765, 1770, 1772, 1782, 1783, 1789, 1790, 1793, 1796, 1798], "logic": [4, 6, 14, 20, 35, 51, 53, 60, 767, 769, 770, 772, 922, 924, 927, 928, 930, 931, 934, 935, 937, 938, 940, 942, 962, 1034, 1111, 1112, 1113, 1114, 1124, 1256, 1423, 1522, 1614, 1741, 1742, 1762, 1763, 1764, 1765, 1767, 1784], "question": [4, 11, 20, 60, 1736, 1759], "why": [4, 8, 20, 53, 57, 60, 905, 1034, 1736, 1747, 1765], "involv": [4, 8, 10, 12, 20, 23, 53, 56, 57, 60, 1423, 1741, 1752, 1754, 1759, 1762, 1763, 1766, 1770, 1777, 1789, 1790, 1791, 1793], "look": [4, 5, 8, 9, 10, 15, 23, 29, 31, 33, 35, 38, 47, 48, 55, 57, 60, 748, 750, 1030, 1124, 1158, 1250, 1338, 1450, 1587, 1670, 1671, 1672, 1674, 1675, 1738, 1740, 1752, 1758, 1759, 1762, 1765, 1769, 1770, 1772, 1776, 1777, 1781, 1784, 1789, 1790, 1803], "autom": [4, 9, 33, 38, 60, 1738, 1784], "easili": [4, 8, 9, 12, 21, 23, 34, 38, 962, 1257, 1347, 1385, 1617, 1765, 1767, 1770, 1775, 1780, 1788, 1791, 1798], "exclus": [4, 20, 23, 29, 39, 48, 60, 992, 1256, 1295, 1297, 1423, 1428, 1599, 1600, 1603, 1759, 1800], "basi": [4, 10, 11, 29, 1102, 1499, 1762, 1769, 1784, 1789], "thought": [4, 45, 60, 923, 925, 941], "path_and_function_nam": 4, "children": [4, 41, 53, 60, 1030, 1250, 1528, 1751, 1770, 1781, 1791], "identifi": [4, 8, 10, 23, 35, 39, 42, 45, 48, 49, 50, 60, 708, 992, 1101, 1289, 1742, 1751, 1760, 1769, 1770, 1781, 1789, 1790, 1791, 1798], "hot": [4, 29, 35, 1349, 1384, 1767], "spot": 4, "_data": 4, "truncate_row": 4, "_linewidth": 4, "subtract": [4, 289, 535, 958, 1349, 1670, 1671, 1672, 1674, 1675, 1685, 1739, 1779, 1793], "index": [4, 15, 20, 21, 29, 37, 38, 46, 60, 168, 185, 257, 288, 289, 290, 291, 292, 293, 295, 297, 298, 444, 445, 484, 485, 486, 487, 488, 489, 490, 491, 611, 612, 708, 710, 725, 779, 826, 829, 884, 885, 925, 965, 966, 967, 969, 971, 972, 1001, 1002, 1003, 1004, 1028, 1046, 1051, 1059, 1077, 1095, 1109, 1117, 1119, 1123, 1127, 1130, 1131, 1132, 1135, 1140, 1146, 1149, 1150, 1158, 1173, 1186, 1193, 1194, 1251, 1252, 1257, 1260, 1261, 1299, 1301, 1338, 1339, 1384, 1443, 1445, 1452, 1453, 1458, 1469, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1508, 1509, 1524, 1621, 1622, 1623, 1624, 1626, 1627, 1628, 1658, 1667, 1668, 1670, 1671, 1672, 1674, 1675, 1684, 1696, 1717, 1720, 1721, 1728, 1736, 1737, 1738, 1739, 1741, 1747, 1751, 1752, 1753, 1754, 1759, 1762, 1763, 1765, 1768, 1774, 1779, 1791, 1793, 1796, 1797, 1798, 1799, 1800], "cpython": [4, 36, 60], "known": [4, 8, 10, 19, 23, 27, 38, 42, 54, 58, 968, 1045, 1046, 1101, 1178, 1179, 1180, 1181, 1182, 1183, 1197, 1220, 1265, 1279, 1281, 1301, 1358, 1399, 1418, 1645, 1646, 1700, 1736, 1739, 1743, 1750, 1751, 1754, 1757, 1759, 1761, 1774, 1777, 1791, 1794], "quit": [4, 8, 34, 60, 1741, 1764, 1766, 1781, 1789], "noisi": 4, "higher": [4, 8, 9, 21, 23, 53, 54, 58, 127, 740, 741, 754, 853, 897, 963, 971, 990, 1007, 1147, 1186, 1242, 1257, 1524, 1689, 1728, 1736, 1762, 1764, 1765, 1767, 1769, 1784, 1785, 1789, 1796], "filter": [4, 38, 515, 686, 687, 688, 1027, 1049, 1178, 1179, 1180, 1181, 1182, 1183, 1322, 1323, 1324, 1325, 1326, 1327, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1684, 1741, 1781], "rather": [4, 6, 9, 10, 14, 23, 34, 35, 39, 41, 50, 60, 693, 699, 759, 785, 1028, 1031, 1150, 1312, 1347, 1358, 1415, 1433, 1637, 1738, 1741, 1753, 1754, 1760, 1762, 1764, 1765, 1777, 1781, 1784, 1789, 1793, 1798], "unicod": [4, 1742], "dictionari": [4, 14, 20, 21, 29, 60, 702, 703, 704, 706, 707, 708, 710, 795, 864, 961, 969, 1030, 1031, 1037, 1041, 1045, 1046, 1101, 1102, 1193, 1194, 1250, 1251, 1260, 1338, 1448, 1529, 1566, 1567, 1568, 1583, 1589, 1740, 1742, 1764, 1770, 1777, 1780, 1789, 1798, 1802, 1804], "lookup": [4, 29, 35, 1193, 1338, 1738, 1742, 1761, 1790], "map": [4, 14, 23, 29, 35, 39, 45, 46, 48, 49, 53, 57, 58, 60, 600, 702, 706, 708, 710, 711, 712, 733, 776, 962, 971, 983, 992, 1037, 1040, 1101, 1102, 1181, 1182, 1183, 1189, 1190, 1191, 1195, 1197, 1246, 1247, 1248, 1251, 1260, 1333, 1334, 1335, 1340, 1428, 1432, 1448, 1524, 1529, 1531, 1546, 1567, 1568, 1582, 1583, 1589, 1591, 1718, 1719, 1728, 1742, 1753, 1755, 1759, 1763, 1764, 1765, 1771, 1776, 1781, 1784, 1787, 1789, 1790, 1791, 1795, 1800, 1804], "agnost": [4, 48, 1347, 1753], "reliabl": 4, "warrant": 4, "except": [4, 6, 8, 10, 14, 23, 24, 29, 39, 40, 41, 45, 49, 53, 59, 60, 555, 589, 600, 609, 611, 612, 615, 674, 733, 755, 756, 782, 789, 793, 813, 822, 824, 852, 865, 897, 903, 905, 951, 952, 969, 971, 993, 1037, 1045, 1047, 1051, 1085, 1101, 1117, 1127, 1129, 1130, 1132, 1135, 1145, 1148, 1150, 1202, 1220, 1265, 1302, 1384, 1423, 1433, 1458, 1463, 1464, 1470, 1521, 1610, 1626, 1663, 1680, 1682, 1683, 1687, 1707, 1723, 1724, 1728, 1729, 1736, 1738, 1740, 1741, 1742, 1743, 1747, 1751, 1754, 1762, 1764, 1770, 1773, 1776, 1781, 1782, 1789, 1791, 1793, 1795, 1796, 1800], "filter_fn": 4, "map_fn": 4, "coalesc": [4, 33, 35, 299, 304, 515, 586, 821, 1669, 1717, 1739, 1763, 1779, 1793], "finit": [5, 29, 755, 756, 1019, 1020, 1065, 1066, 1076, 1077, 1093, 1119, 1140, 1144, 1166, 1688, 1764, 1767, 1800], "natur": [5, 8, 9, 12, 23, 29, 755, 756, 1058, 1063, 1089, 1103, 1105, 1110, 1158, 1297, 1767, 1793, 1794], "against": [5, 14, 23, 39, 48, 713, 755, 756, 933, 934, 935, 939, 940, 942, 972, 1021, 1030, 1045, 1046, 1250, 1256, 1735, 1741, 1781, 1803], "cprofil": 5, "mode": [5, 9, 20, 21, 23, 29, 32, 33, 34, 38, 48, 50, 57, 58, 60, 198, 199, 660, 661, 686, 687, 688, 693, 699, 700, 701, 706, 708, 737, 739, 741, 742, 743, 748, 749, 750, 751, 755, 762, 795, 809, 841, 880, 881, 909, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 962, 965, 966, 967, 968, 969, 970, 978, 1005, 1013, 1014, 1028, 1030, 1031, 1034, 1045, 1047, 1088, 1101, 1131, 1168, 1169, 1170, 1178, 1179, 1180, 1194, 1205, 1213, 1214, 1215, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1250, 1266, 1289, 1302, 1303, 1322, 1323, 1324, 1339, 1347, 1358, 1385, 1415, 1416, 1417, 1433, 1437, 1468, 1499, 1507, 1523, 1551, 1554, 1584, 1585, 1631, 1633, 1634, 1721, 1736, 1739, 1748, 1752, 1757, 1762, 1763, 1765, 1766, 1770, 1778, 1779, 1783, 1785, 1786, 1787, 1789, 1804], "correct": [5, 7, 8, 21, 23, 24, 29, 48, 182, 183, 186, 198, 526, 552, 575, 576, 587, 744, 756, 807, 926, 928, 936, 937, 938, 1004, 1028, 1031, 1045, 1046, 1065, 1187, 1204, 1216, 1418, 1423, 1458, 1636, 1682, 1683, 1723, 1724, 1737, 1738, 1739, 1740, 1752, 1753, 1762, 1764, 1767, 1795], "launch": [5, 14, 20, 26, 34, 39, 40, 41, 46, 47, 48, 51, 59, 812, 1423, 1736, 1759, 1761, 1762, 1763, 1789], "spent": [5, 23, 33, 38, 760, 1505, 1761, 1770], "appear": [5, 21, 23, 29, 60, 710, 853, 905, 946, 947, 971, 1101, 1135, 1137, 1422, 1424, 1610, 1639, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1728, 1738, 1741, 1752, 1753, 1764, 1765, 1770, 1777, 1781], "extrem": [5, 35, 1423, 1759, 1777], "expens": [5, 20, 29, 33, 38, 53, 1432, 1762, 1767, 1769, 1783, 1789, 1799], "bound": [5, 15, 21, 38, 53, 454, 779, 790, 919, 920, 1030, 1163, 1164, 1165, 1243, 1244, 1245, 1250, 1268, 1347, 1507, 1603, 1624, 1741, 1742, 1757, 1781, 1784, 1794], "greater": [5, 23, 48, 268, 589, 784, 785, 790, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 974, 986, 1084, 1166, 1298, 1347, 1358, 1384, 1415, 1433, 1464, 1721, 1739, 1759, 1762, 1774, 1779, 1794], "spend": [5, 8, 1102], "sens": [5, 29, 48, 60, 1448, 1718, 1719, 1741, 1759], "respons": [5, 8, 10, 23, 27, 29, 39, 45, 50, 53, 59, 812, 1238, 1365, 1423, 1759, 1762, 1764, 1765, 1770, 1789], "Of": [5, 1469, 1735, 1763, 1764], "cours": [5, 33, 35, 60, 1735, 1763, 1764, 1789], "realiti": 5, "complic": [5, 21, 60, 1745, 1753, 1760, 1781, 1789, 1791], "depend": [5, 6, 14, 20, 23, 27, 29, 31, 33, 34, 35, 37, 39, 48, 49, 50, 53, 60, 291, 699, 726, 866, 883, 926, 928, 936, 937, 938, 963, 967, 970, 1041, 1045, 1065, 1066, 1093, 1119, 1124, 1166, 1167, 1184, 1186, 1194, 1197, 1210, 1216, 1217, 1241, 1242, 1253, 1254, 1255, 1257, 1264, 1281, 1282, 1298, 1301, 1302, 1312, 1319, 1320, 1330, 1339, 1347, 1359, 1382, 1390, 1415, 1418, 1423, 1437, 1438, 1444, 1499, 1511, 1513, 1595, 1611, 1670, 1671, 1672, 1674, 1675, 1688, 1709, 1731, 1735, 1738, 1740, 1741, 1747, 1751, 1759, 1761, 1762, 1764, 1765, 1767, 1770, 1777, 1783, 1784, 1789, 1793, 1799, 1800], "could": [5, 8, 9, 20, 23, 29, 33, 38, 39, 48, 53, 57, 59, 60, 846, 926, 928, 936, 937, 938, 1027, 1060, 1101, 1119, 1498, 1665, 1718, 1740, 1741, 1747, 1751, 1759, 1762, 1763, 1776, 1777, 1781, 1784, 1785, 1789, 1790, 1791, 1793, 1797, 1798], "account": [5, 46, 60, 1423, 1757, 1761, 1793], "heavili": [5, 1483, 1761, 1764, 1781], "similarli": [5, 8, 34, 59, 60, 674, 786, 925, 1030, 1085, 1250, 1422, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1455, 1527, 1583, 1710, 1711, 1712, 1713, 1740, 1764, 1766, 1767, 1773, 1793], "platform": [5, 9, 10, 14, 23, 40, 41, 45, 1076, 1077, 1088, 1523, 1688, 1748, 1768, 1773, 1774, 1784], "startup": 5, "slower": [5, 14, 23, 724, 749, 945, 946, 947, 1059, 1066, 1366, 1432, 1764, 1774, 1794], "multi": [5, 39, 48, 674, 812, 854, 873, 905, 925, 992, 1030, 1167, 1187, 1202, 1220, 1250, 1253, 1254, 1255, 1256, 1265, 1293, 1295, 1302, 1423, 1736, 1738, 1741, 1761, 1762, 1770, 1774, 1789, 1793, 1796, 1799, 1801], "rerun": [6, 23, 1762], "segment": [6, 33, 864, 958, 1281, 1781], "persist": [6, 18, 53, 674, 706, 707, 708, 1030, 1202, 1220, 1250, 1265, 1762, 1770, 1775, 1776], "rng": [6, 20, 839, 877, 1625, 1762, 1774, 1788], "advanc": [6, 15, 20, 21, 33, 39, 1293, 1295, 1297, 1469, 1745, 1747, 1753, 1762, 1768, 1772, 1797, 1798], "juggl": 6, "dropout": [6, 60, 674, 1030, 1162, 1189, 1190, 1191, 1195, 1202, 1220, 1250, 1256, 1265, 1266, 1293, 1295, 1297, 1313, 1333, 1334, 1335, 1340, 1427, 1428, 1736, 1739, 1748, 1753, 1754, 1759, 1762, 1779, 1786], "moder": 6, "hit": [6, 9, 14, 33, 38, 1423, 1735, 1762], "preserve_rng_st": 6, "checkpoint_sequenti": 6, "omit": [6, 14, 23, 49, 939, 940, 942, 1204, 1264, 1776, 1777, 1789, 1800], "save": [6, 8, 12, 15, 21, 23, 27, 33, 53, 468, 737, 738, 746, 1029, 1030, 1035, 1037, 1045, 1047, 1101, 1250, 1423, 1495, 1501, 1504, 1508, 1565, 1736, 1738, 1739, 1749, 1753, 1764, 1765, 1770, 1772, 1774, 1779, 1781, 1783, 1793, 1798, 1802], "anticip": 6, "belong": [6, 23, 27, 29, 35, 45, 60, 779, 814, 1495, 1735, 1762, 1780, 1804], "use_reentr": 6, "intermedi": [6, 14, 30, 57, 60, 776, 956, 962, 1119, 1194, 1293, 1295, 1297, 1339, 1738, 1741, 1762, 1764, 1765, 1766, 1773, 1803], "entir": [6, 8, 14, 20, 23, 32, 33, 35, 38, 39, 49, 60, 613, 755, 756, 962, 983, 1189, 1190, 1191, 1195, 1213, 1214, 1215, 1222, 1333, 1334, 1335, 1340, 1423, 1443, 1445, 1467, 1741, 1754, 1759, 1762, 1764, 1765, 1766, 1769, 1770, 1777, 1781, 1784, 1789, 1791, 1793], "recomput": [6, 746, 1302, 1358, 1467, 1780], "no_grad": [6, 909, 963, 967, 970, 1005, 1030, 1193, 1250, 1256, 1297, 1586, 1757, 1759, 1770, 1801], "manner": [6, 9, 39, 485, 748, 750, 1753, 1755, 1760], "gradient": [6, 12, 20, 21, 23, 27, 29, 33, 53, 54, 127, 198, 199, 266, 311, 460, 467, 485, 611, 612, 728, 737, 739, 740, 742, 743, 744, 745, 746, 748, 749, 750, 751, 752, 753, 754, 755, 756, 766, 792, 909, 961, 962, 963, 964, 968, 971, 972, 1005, 1030, 1065, 1066, 1069, 1076, 1077, 1093, 1102, 1119, 1121, 1127, 1130, 1132, 1166, 1173, 1181, 1182, 1183, 1186, 1187, 1193, 1194, 1204, 1218, 1219, 1250, 1257, 1281, 1330, 1331, 1338, 1339, 1349, 1358, 1366, 1368, 1369, 1382, 1415, 1416, 1417, 1422, 1423, 1424, 1429, 1430, 1432, 1437, 1468, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1497, 1498, 1511, 1634, 1669, 1688, 1728, 1736, 1738, 1739, 1747, 1753, 1754, 1757, 1762, 1763, 1764, 1766, 1767, 1770, 1773, 1779, 1780, 1789, 1790, 1793], "consist": [6, 20, 23, 29, 33, 38, 48, 49, 60, 755, 786, 787, 1030, 1059, 1065, 1066, 1068, 1070, 1071, 1072, 1073, 1097, 1099, 1250, 1297, 1434, 1437, 1523, 1688, 1694, 1738, 1741, 1747, 1753, 1754, 1765, 1770, 1774, 1777, 1780, 1793], "ex": [6, 40, 1423, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493, 1750], "anyth": [6, 8, 30, 41, 59, 1041, 1551, 1554, 1738, 1745, 1754, 1770, 1781], "detect": [6, 14, 16, 17, 20, 23, 24, 33, 38, 39, 41, 53, 748, 749, 750, 751, 752, 753, 962, 1034, 1423, 1721, 1736, 1751, 1754, 1762, 1767, 1773, 1777, 1781, 1789], "circumv": 6, "least": [6, 7, 9, 21, 29, 33, 38, 47, 48, 53, 236, 377, 613, 766, 893, 895, 896, 905, 946, 947, 983, 991, 992, 1027, 1052, 1075, 1102, 1124, 1144, 1158, 1423, 1459, 1735, 1741, 1753, 1757, 1759, 1760, 1762, 1766, 1782, 1785, 1791, 1793, 1794, 1795, 1800], "know": [6, 8, 9, 14, 24, 30, 33, 35, 60, 459, 744, 749, 956, 962, 1040, 1423, 1738, 1741, 1747, 1758, 1759, 1762, 1767, 1777, 1781, 1789, 1790, 1791, 1793], "lstm": [6, 677, 1221, 1739, 1762, 1777, 1779, 1784, 1786, 1787, 1798], "hidden": [6, 674, 969, 1202, 1203, 1220, 1221, 1265, 1267, 1424, 1762, 1798], "correctli": [6, 20, 23, 34, 37, 48, 459, 962, 1030, 1045, 1250, 1366, 1738, 1740, 1741, 1750, 1753, 1758, 1759, 1763, 1764, 1765, 1772, 1774, 1784, 1789], "entrant": 6, "futur": [6, 9, 10, 21, 23, 33, 39, 48, 49, 57, 60, 266, 297, 489, 528, 603, 703, 706, 707, 708, 746, 785, 786, 800, 801, 808, 809, 811, 812, 814, 842, 843, 850, 851, 853, 976, 1030, 1033, 1039, 1040, 1043, 1048, 1060, 1071, 1073, 1074, 1075, 1078, 1091, 1119, 1120, 1131, 1190, 1216, 1250, 1256, 1349, 1371, 1372, 1373, 1419, 1423, 1429, 1464, 1470, 1483, 1523, 1554, 1586, 1604, 1684, 1688, 1694, 1709, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1747, 1748, 1750, 1753, 1754, 1761, 1762, 1764, 1775, 1777, 1778, 1780, 1781, 1782, 1783, 1784, 1786, 1789, 1793, 1795, 1799, 1800, 1803], "sequenti": [6, 20, 27, 33, 38, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 703, 971, 1030, 1039, 1196, 1250, 1289, 1300, 1434, 1448, 1508, 1728, 1738, 1751, 1754, 1762, 1770, 1777, 1782, 1784, 1803], "compris": [6, 49], "chunk": [6, 20, 23, 53, 782, 824, 967, 1187, 1423, 1676, 1738, 1739, 1752, 1779, 1782, 1789, 1797], "input_var": [6, 1187], "person": [7, 8, 10], "land": [7, 10, 11], "six": [7, 1180], "commit": [7, 8, 10, 14, 54, 1735, 1736, 1773, 1774], "repositori": [7, 10, 37, 60, 1735, 1764, 1772], "submit": [7, 10, 811, 812, 814, 1762, 1774], "month": [7, 10], "qualifi": [7, 23, 45, 60, 1030, 1250, 1781], "pr": [7, 8, 1513, 1689, 1803], "interest": [7, 8, 10, 32, 34, 1759, 1765, 1767, 1770], "merge_rul": 7, "vote": [7, 10], "decis": [7, 39, 48, 50, 60, 1045, 1747, 1758], "criteria": [7, 10, 1102], "approv": [7, 10], "Not": [7, 35, 49, 1148, 1738, 1740, 1741, 1742, 1764, 1779, 1784, 1789], "busi": [7, 10], "dai": [7, 8], "contributor": [7, 8, 9, 10], "seen": [7, 17, 29, 35, 60, 198, 782, 1131, 1181, 1182, 1183, 1281, 1371, 1372, 1373, 1507, 1738, 1747, 1759, 1762, 1777, 1793], "thumb": [7, 23], "acceler": [8, 21, 33, 1168, 1169, 1170, 1289, 1477, 1768], "deep": [8, 10, 33, 36, 38, 60, 1168, 1169, 1170, 1192, 1289, 1493, 1736, 1757, 1770, 1784], "neural": [8, 9, 15, 60, 1162, 1173, 1188, 1195, 1204, 1216, 1249, 1250, 1257, 1262, 1263, 1277, 1279, 1293, 1295, 1297, 1377, 1399, 1435, 1491, 1499, 1505, 1738, 1740, 1741, 1757, 1762, 1773, 1777], "tape": 8, "system": [8, 9, 14, 15, 16, 49, 57, 60, 788, 1037, 1061, 1072, 1073, 1074, 1075, 1076, 1077, 1079, 1090, 1091, 1092, 1096, 1101, 1120, 1293, 1295, 1297, 1423, 1435, 1437, 1633, 1709, 1742, 1750, 1759, 1761, 1762, 1769, 1770, 1776, 1781, 1789], "organ": [8, 33, 35, 1763, 1769, 1781], "govern": [8, 9, 1736, 1784], "technic": [8, 10, 48, 60, 1030, 1250, 1422, 1759, 1766, 1781], "md": [8, 60, 702, 1781], "healthi": [8, 39, 48], "team": [8, 23, 54, 1775, 1782], "commun": [8, 9, 10, 24, 27, 33, 34, 39, 48, 50, 53, 1423, 1759, 1763, 1789, 1790], "project": [8, 1131, 1220, 1256, 1437, 1513, 1735, 1768], "ve": [8, 33, 35, 56, 57, 60, 1034, 1747, 1751, 1759, 1765, 1790, 1798], "come": [8, 9, 10, 20, 29, 30, 35, 45, 48, 54, 57, 905, 956, 962, 1101, 1189, 1190, 1191, 1195, 1216, 1476, 1745, 1748, 1763, 1765, 1769, 1781, 1789, 1791, 1793], "peopl": [8, 34, 1759, 1784], "scratch": [8, 38, 1759], "itch": 8, "acquaint": 8, "tip": [8, 33, 1762], "tracker": [8, 1102], "confirm": [8, 33, 1735, 1738, 1764, 1777, 1789, 1791], "tend": [8, 750, 1721], "bootcamp": 8, "1hr": 8, "although": [8, 9, 29, 57, 60, 814, 1181, 1182, 1183, 1250, 1258, 1423, 1736, 1741, 1758, 1764, 1773, 1782, 1784], "join": [8, 21, 23, 27, 48, 49, 59, 60, 1423, 1735, 1736, 1742, 1751, 1759, 1763, 1772, 1779, 1799], "dev": [8, 11, 36, 38, 40, 45], "happi": 8, "research": [8, 9, 10, 1423, 1735, 1759, 1767, 1775], "partner": 8, "speed": [8, 9, 14, 27, 35, 905, 961, 1021, 1034, 1039, 1093, 1158, 1688, 1759, 1761, 1762, 1763, 1764, 1766, 1768, 1773, 1784, 1789], "reach": [8, 9, 10, 20, 21, 23, 24, 32, 39, 48, 54, 1102, 1423, 1496, 1499, 1502, 1503, 1772, 1782, 1784, 1785, 1789], "design": [8, 10, 20, 29, 33, 34, 36, 38, 45, 48, 54, 57, 58, 755, 756, 1030, 1049, 1250, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1697, 1735, 1736, 1737, 1750, 1762, 1764, 1768, 1770, 1781], "comment": [8, 60, 1741, 1742, 1764, 1798], "crack": 8, "usual": [8, 14, 20, 21, 48, 49, 53, 60, 61, 454, 740, 748, 750, 754, 971, 1189, 1190, 1191, 1195, 1210, 1213, 1214, 1215, 1216, 1418, 1423, 1480, 1569, 1728, 1738, 1741, 1754, 1758, 1761, 1762, 1766, 1769, 1785, 1787, 1789, 1798, 1804], "idea": [8, 33, 38, 54, 905, 1158, 1423, 1762, 1769, 1777, 1790], "rfc": [8, 1759, 1784, 1790], "big": [8, 1480, 1481, 1484, 1490, 1491, 1670, 1671, 1672, 1673, 1674, 1675, 1784], "post": [8, 9, 24, 27, 36, 53, 712, 1030, 1250, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1582, 1586, 1736, 1745, 1763, 1766, 1776], "standard": [8, 14, 17, 21, 29, 41, 42, 46, 57, 60, 61, 328, 352, 561, 925, 1162, 1168, 1169, 1170, 1205, 1213, 1214, 1215, 1216, 1222, 1289, 1295, 1297, 1471, 1513, 1601, 1647, 1652, 1682, 1683, 1740, 1742, 1757, 1761, 1762, 1772, 1773, 1777, 1778, 1781, 1794], "lot": [8, 14, 20, 34, 35, 1751, 1759, 1762, 1767, 1772, 1781, 1782, 1788, 1790, 1798], "boil": 8, "mostli": [8, 29, 1028, 1423, 1762, 1793, 1804], "evid": 8, "peer": [8, 23, 27, 48, 53, 818, 1423, 1762, 1789], "paper": [8, 10, 21, 29, 1158, 1162, 1168, 1169, 1170, 1172, 1181, 1182, 1183, 1188, 1189, 1190, 1191, 1192, 1195, 1198, 1199, 1205, 1208, 1213, 1214, 1215, 1222, 1256, 1262, 1263, 1268, 1277, 1281, 1289, 1293, 1295, 1297, 1298, 1299, 1342, 1343, 1352, 1480, 1481, 1492, 1499, 1505, 1767, 1782], "framework": [8, 9, 10, 29, 45, 54, 59, 816, 1423, 1432, 1493, 1637, 1736, 1771, 1782, 1784, 1790, 1791], "bit": [8, 34, 35, 60, 65, 306, 431, 675, 677, 679, 768, 771, 800, 801, 958, 1010, 1547, 1548, 1549, 1550, 1553, 1555, 1583, 1612, 1613, 1625, 1654, 1762, 1770, 1773, 1776, 1784, 1787, 1788, 1793, 1796, 1799, 1805], "accept": [8, 10, 23, 38, 54, 55, 58, 127, 485, 737, 738, 739, 740, 745, 754, 785, 850, 853, 957, 971, 992, 1030, 1034, 1186, 1250, 1257, 1278, 1444, 1458, 1459, 1463, 1534, 1629, 1728, 1741, 1753, 1762, 1764, 1765, 1777, 1780, 1789, 1796, 1798], "overwhelm": [8, 33, 38, 1789], "newli": [8, 35, 53, 60, 919, 920, 1193, 1194, 1590, 1591, 1745], "publish": [8, 10, 40, 45, 48, 1102, 1736], "ground": [8, 10, 1186, 1330, 1798], "becom": [8, 9, 10, 20, 23, 29, 33, 35, 38, 60, 266, 674, 724, 983, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1202, 1220, 1235, 1255, 1265, 1278, 1330, 1347, 1418, 1497, 1662, 1694, 1707, 1747, 1763, 1777, 1781, 1783, 1789], "refactor": [8, 60, 1776, 1784], "coordin": [8, 23, 29, 33, 38, 39, 555, 558, 732, 983, 992, 1131, 1517, 1673, 1711, 1713, 1759, 1793, 1798], "pace": 8, "master": [8, 51, 702, 962, 1293, 1735, 1770, 1789], "fast": [8, 9, 20, 23, 34, 755, 1192, 1213, 1214, 1215, 1281, 1297, 1505, 1511, 1595, 1617, 1632, 1736, 1761, 1762, 1764, 1768, 1789, 1793, 1796, 1797], "definit": [8, 9, 20, 23, 24, 29, 35, 44, 60, 786, 787, 788, 807, 850, 953, 1050, 1059, 1060, 1102, 1216, 1359, 1403, 1470, 1608, 1707, 1735, 1738, 1740, 1742, 1758, 1759, 1764, 1767, 1781, 1784, 1798, 1800], "fundament": [8, 57, 1740, 1770, 1789, 1793], "cut": [8, 33], "guidanc": [8, 10, 15, 55, 1782], "stage": [8, 17, 21, 27, 38, 45, 53, 59, 1736, 1747, 1754, 1782, 1791], "piec": [8, 35, 1754, 1790], "advic": 8, "readi": [8, 14, 59, 764, 773, 987, 988, 1423, 1586, 1587, 1738, 1763, 1789, 1790], "draft": 8, "convert": [8, 20, 23, 29, 30, 35, 38, 60, 127, 552, 556, 557, 558, 559, 560, 702, 703, 704, 706, 707, 708, 710, 727, 728, 781, 794, 889, 925, 956, 1030, 1099, 1250, 1260, 1261, 1289, 1296, 1418, 1425, 1426, 1428, 1431, 1466, 1476, 1525, 1526, 1527, 1566, 1567, 1582, 1583, 1584, 1590, 1591, 1596, 1670, 1671, 1672, 1673, 1674, 1675, 1738, 1739, 1740, 1741, 1754, 1764, 1768, 1777, 1784, 1787, 1793, 1798, 1800, 1803], "press": [8, 60], "button": 8, "prepend": [8, 14, 20, 23, 27, 60, 206, 897, 1030, 1124, 1250, 1703, 1739, 1760], "titl": [8, 1779, 1783], "wip": 8, "progress": [8, 23, 27, 39, 49, 51, 811, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1490, 1491, 1492, 1493, 1494, 1722, 1735, 1749], "ignor": [8, 23, 27, 40, 46, 53, 60, 127, 471, 515, 602, 605, 606, 607, 722, 740, 754, 763, 785, 807, 854, 855, 873, 874, 926, 928, 936, 937, 938, 975, 990, 1030, 1041, 1047, 1050, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1076, 1077, 1078, 1079, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1098, 1099, 1121, 1145, 1146, 1147, 1163, 1164, 1165, 1166, 1167, 1184, 1186, 1194, 1202, 1204, 1210, 1216, 1217, 1220, 1241, 1242, 1243, 1244, 1245, 1250, 1253, 1254, 1255, 1256, 1257, 1264, 1265, 1281, 1282, 1293, 1296, 1298, 1319, 1320, 1330, 1339, 1359, 1382, 1390, 1423, 1428, 1470, 1499, 1507, 1511, 1583, 1586, 1587, 1637, 1666, 1667, 1684, 1688, 1709, 1738, 1741, 1742, 1747, 1753, 1759, 1762, 1764, 1777, 1793, 1800], "ci": [8, 1736, 1762], "folk": 8, "who": [8, 9, 10, 12, 35, 48, 1781], "regularli": 8, "queue": [8, 39, 50, 1751, 1798], "everyth": [8, 20, 29, 33, 35, 38, 1738, 1751, 1781], "happen": [8, 10, 23, 27, 29, 35, 39, 41, 48, 53, 57, 60, 61, 579, 962, 1289, 1423, 1432, 1496, 1502, 1503, 1509, 1528, 1546, 1688, 1736, 1750, 1751, 1759, 1762, 1763, 1764, 1765, 1766, 1771, 1772, 1776, 1777, 1784, 1789, 1797], "subsystem": [8, 12, 54, 58, 1736, 1764], "feel": [8, 1754, 1777, 1793], "ll": [8, 31, 57, 60, 674, 786, 853, 1059, 1202, 1203, 1220, 1221, 1548, 1549, 1586, 1587, 1747, 1759, 1762, 1764, 1765, 1772, 1777, 1784, 1790], "round": [8, 20, 23, 480, 713, 803, 805, 900, 926, 927, 928, 932, 936, 937, 938, 953, 1075, 1088, 1302, 1358, 1523, 1524, 1531, 1534, 1548, 1608, 1657, 1737, 1739, 1741, 1752, 1762, 1779, 1784, 1787, 1793, 1794], "trip": [8, 60, 926, 927, 928, 932, 936, 937, 938], "noth": [8, 14, 39, 60, 844, 1437, 1508, 1738, 1740, 1791], "accompani": 8, "solut": [8, 9, 57, 1074, 1075, 1079, 1087, 1090, 1092, 1096, 1166, 1423, 1709, 1738, 1739, 1757, 1758, 1766, 1772], "think": [8, 10, 33, 60, 1738, 1740, 1759, 1781, 1791], "confid": [8, 1798], "ahead": [8, 33, 1736, 1784], "search": [8, 12, 21, 38, 779, 1208, 1352, 1423, 1547, 1595, 1624, 1738, 1752, 1753, 1781, 1793], "repo": [8, 37, 1499, 1735, 1776], "unabl": [8, 38, 57, 1777, 1780], "reproduc": [8, 20, 33, 38, 57, 289, 297, 487, 489, 766, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1339, 1347, 1358, 1385, 1415, 1416, 1417, 1418, 1721, 1735, 1736, 1780, 1781], "problemat": [8, 20, 60, 1738, 1773, 1785], "insight": [8, 17], "individu": [8, 10, 14, 20, 21, 23, 27, 34, 53, 60, 218, 702, 786, 872, 923, 941, 1030, 1173, 1250, 1289, 1423, 1566, 1567, 1741, 1752, 1758, 1762, 1764, 1769, 1773, 1774, 1777, 1787, 1789, 1800], "intent": [8, 46, 48, 57, 1629, 1747, 1781], "lock": [8, 20, 23, 27, 29, 1759, 1762, 1772, 1781, 1790], "strike": 8, "convers": [8, 431, 552, 555, 780, 1015, 1458, 1736, 1742, 1768, 1777, 1784, 1785, 1793], "medium": [8, 53, 1632], "prioriti": [8, 10, 11, 23, 710, 814, 1740], "entranc": [8, 1762], "great": [8, 1759, 1767], "deal": [8, 9, 20, 35, 39, 50, 1702, 1751, 1766, 1789], "welcom": [8, 1754, 1793], "aim": [8, 1765, 1793], "rare": [8, 1758, 1777, 1804], "typo": 8, "send": [8, 20, 23, 34, 39, 50, 846, 1418, 1423, 1751, 1763, 1772, 1776, 1779, 1783, 1789, 1790, 1791, 1801, 1803], "consider": [8, 732, 1027, 1194, 1423, 1741, 1761], "forum": [8, 10, 1766, 1772], "share": [8, 11, 14, 20, 24, 27, 29, 30, 48, 49, 53, 57, 198, 287, 316, 431, 456, 492, 495, 589, 727, 728, 744, 755, 756, 809, 811, 842, 846, 956, 957, 958, 1000, 1077, 1149, 1150, 1187, 1423, 1435, 1471, 1584, 1606, 1620, 1679, 1700, 1706, 1720, 1739, 1758, 1759, 1761, 1772, 1775, 1776, 1777, 1789, 1793, 1795, 1797, 1802], "resolv": [8, 9, 10, 29, 60, 1030, 1181, 1182, 1183, 1197, 1247, 1250, 1740, 1741, 1742, 1776, 1781, 1795, 1804], "challeng": [8, 23, 33, 1790], "feedback": [8, 17, 21, 38, 53, 54, 1423, 1736], "direct": [8, 10, 12, 23, 35, 674, 702, 946, 947, 1030, 1202, 1220, 1250, 1265, 1467, 1492, 1513, 1595, 1616, 1759, 1762, 1764, 1770, 1789], "yourself": [8, 33, 56, 809, 1764, 1770, 1772, 1804], "problem": [8, 20, 23, 33, 38, 48, 57, 905, 1045, 1075, 1087, 1102, 1186, 1257, 1312, 1751, 1759, 1762, 1766, 1767, 1772, 1776, 1782, 1784, 1785, 1791], "area": [8, 10, 1358, 1770, 1784, 1794], "appreci": 8, "strive": 8, "respond": [8, 23], "quickli": [8, 9, 21, 34, 48], "ey": [8, 29, 168, 185, 787, 971, 1050, 1059, 1070, 1081, 1084, 1087, 1088, 1095, 1096, 1432, 1523, 1666, 1728, 1739, 1743, 1764, 1779], "everyon": [8, 39, 48], "touch": [8, 46, 60], "versu": [8, 1254], "write": [8, 9, 10, 17, 20, 23, 33, 34, 38, 39, 41, 45, 46, 47, 48, 53, 57, 58, 230, 485, 613, 777, 957, 971, 1007, 1040, 1060, 1071, 1072, 1073, 1077, 1078, 1091, 1414, 1620, 1709, 1721, 1728, 1736, 1740, 1750, 1753, 1762, 1765, 1766, 1767, 1780, 1781, 1793, 1798], "blog": [8, 9, 1745, 1763, 1784], "around": [8, 10, 12, 23, 29, 35, 38, 57, 59, 60, 127, 596, 740, 754, 809, 811, 812, 814, 881, 951, 952, 962, 1030, 1423, 1617, 1738, 1751, 1759, 1762, 1777, 1789], "internet": 8, "grow": [8, 9, 34, 60, 1793], "market": [8, 10], "benefit": [8, 9, 23, 38, 60, 1507, 1751, 1762, 1784, 1793], "opinion": [8, 9, 1793], "isn": [8, 20, 60, 431, 1027, 1759, 1762, 1764, 1789, 1800], "categor": [8, 41, 1349, 1736, 1742, 1785, 1789], "aspect": [8, 23, 60, 1764, 1770], "seem": [8, 1777], "unusu": 8, "claim": [8, 1505, 1767], "wast": [8, 1762], "someon": [8, 10, 1028, 1753], "too": [8, 10, 14, 21, 38, 48, 53, 57, 60, 1075, 1093, 1146, 1173, 1186, 1250, 1331, 1424, 1741, 1761, 1766, 1767, 1772, 1773, 1774, 1776, 1781, 1782, 1791, 1793], "advisori": 8, "fashion": [8, 20, 23, 50, 487, 1107, 1448, 1738], "rough": [8, 10], "consensu": [8, 10], "corpor": [8, 38], "wrote": [8, 9], "implicitli": [8, 23, 41, 53, 60, 888, 975, 983, 1045, 1046, 1101, 1163, 1164, 1165, 1243, 1244, 1245, 1629, 1707, 1738, 1740, 1741, 1759, 1768], "lifetim": [8, 1762, 1789], "immedi": [8, 9, 10, 48, 49, 53, 59, 1030, 1033, 1250, 1741, 1770, 1775, 1789, 1791], "sai": [8, 35, 60, 468, 965, 966, 967, 1030, 1250, 1738, 1758, 1759, 1766, 1781, 1790, 1791, 1793], "bugfix": 8, "motiv": [8, 9, 33, 38, 60, 1428, 1770, 1790], "ye": [8, 1777, 1793], "knuth": 8, "bewar": 8, "mere": 8, "proven": [8, 1188, 1423], "ok": [8, 41, 46, 795, 1035, 1791], "sometim": [8, 60, 751, 1045, 1197, 1301, 1325, 1326, 1327, 1437, 1736, 1741, 1751, 1759, 1762, 1765, 1766, 1770, 1772, 1781, 1796, 1799, 1804], "obvious": [8, 34], "broken": [8, 20, 864, 1777], "contrari": [8, 1761], "accident": 8, "put": [8, 10, 20, 23, 39, 53, 59, 60, 295, 925, 1101, 1205, 1499, 1735, 1739, 1751, 1762, 1772, 1779, 1781, 1790, 1791], "Is": [8, 35, 200, 308, 312, 314, 318, 319, 467, 476, 1256, 1293, 1295, 1297, 1428], "difficulti": [8, 1757], "nonlinearli": 8, "sign": [8, 29, 317, 500, 732, 802, 893, 941, 953, 958, 1063, 1088, 1089, 1110, 1242, 1492, 1608, 1640, 1654, 1737, 1739, 1752, 1779, 1787, 1793, 1796, 1799, 1800], "split": [8, 20, 23, 60, 589, 686, 687, 688, 782, 789, 864, 903, 993, 1187, 1201, 1202, 1220, 1256, 1265, 1322, 1323, 1324, 1325, 1326, 1327, 1346, 1584, 1586, 1587, 1701, 1729, 1738, 1739, 1752, 1762, 1779, 1781, 1782, 1784, 1789, 1793, 1797], "shippabl": 8, "complet": [8, 14, 20, 23, 35, 39, 40, 46, 48, 50, 57, 59, 459, 811, 812, 814, 882, 961, 962, 1033, 1041, 1043, 1048, 1060, 1088, 1312, 1423, 1434, 1465, 1523, 1586, 1736, 1740, 1741, 1742, 1751, 1758, 1759, 1762, 1765, 1768, 1774, 1781, 1782, 1789, 1790], "subtl": [8, 33, 38, 1213, 1214, 1215, 1764], "nuanc": [8, 35], "extra": [8, 14, 20, 21, 23, 27, 29, 35, 37, 53, 60, 905, 962, 971, 1030, 1037, 1040, 1075, 1101, 1250, 1257, 1432, 1684, 1694, 1728, 1740, 1753, 1759, 1761, 1763, 1764, 1766, 1769, 1781, 1783, 1793, 1800], "understand": [8, 9, 10, 23, 31, 32, 33, 34, 35, 38, 39, 40, 962, 1087, 1745, 1757, 1759, 1762, 1768, 1775, 1783, 1798], "hack": 8, "answer": [8, 11, 60, 1167, 1450, 1552], "regress": [8, 1166, 1774], "scrutini": 8, "undertak": 8, "rest": [8, 20, 21, 35, 49, 60, 703, 958, 1095, 1096, 1546, 1701, 1753, 1770, 1774, 1781, 1782, 1784, 1789], "chanc": [8, 29], "unrel": [8, 1758, 1764, 1781], "aid": [8, 38, 60, 1759], "troubleshoot": [8, 23], "mayb": 8, "rebas": 8, "latest": [8, 23, 27, 29, 37, 1444, 1735, 1768, 1777], "statu": [8, 10, 39, 1119, 1736, 1742, 1751, 1784], "hud": 8, "risk": [8, 9, 53, 1434, 1437], "configur": [8, 13, 20, 21, 23, 33, 38, 39, 40, 45, 48, 49, 50, 53, 702, 703, 706, 707, 708, 864, 1423, 1458, 1525, 1526, 1529, 1546, 1551, 1554, 1566, 1567, 1568, 1583, 1584, 1585, 1586, 1587, 1633, 1721, 1736, 1750, 1762, 1763, 1774, 1776, 1781, 1787, 1789, 1798, 1800], "riski": 8, "had": [8, 34, 60, 1045, 1418, 1703, 1759, 1765], "beforehand": [8, 33, 59], "hei": 8, "my": [8, 20, 1187, 1769, 1777, 1784], "branch": [8, 60, 1735, 1740, 1741, 1762], "member": [8, 10, 20, 23, 39, 48, 49, 60, 1030, 1204, 1250, 1344, 1738, 1740, 1741, 1750, 1766, 1783, 1789, 1800, 1801], "sphinx": 8, "folder": [8, 10, 14, 20, 60, 1735, 1798], "tree": [8, 41, 1250, 1293, 1781, 1791], "doxygen": 8, "special": [8, 12, 32, 35, 41, 50, 57, 60, 655, 656, 657, 755, 898, 912, 913, 914, 916, 917, 926, 928, 997, 998, 999, 1043, 1101, 1115, 1143, 1187, 1256, 1297, 1424, 1425, 1426, 1469, 1518, 1551, 1554, 1641, 1652, 1656, 1732, 1736, 1742, 1753, 1759, 1762, 1764, 1767, 1769, 1777, 1781, 1784, 1797, 1798], "server": [8, 20, 23, 49, 1034, 1762, 1781, 1784, 1789], "cppdoc": [8, 15], "cpp": [8, 14, 23, 1140, 1763], "accomplish": [8, 33, 1770], "holist": 8, "concept": [8, 57, 60, 1745, 1765, 1770, 1796], "galleri": 8, "restructur": [8, 1781], "text": [8, 29, 34, 130, 131, 150, 580, 589, 597, 599, 600, 601, 602, 603, 604, 605, 606, 607, 610, 614, 659, 660, 670, 672, 674, 678, 682, 683, 684, 686, 687, 688, 694, 698, 713, 729, 730, 731, 732, 733, 763, 764, 765, 768, 771, 773, 775, 784, 790, 801, 802, 804, 805, 807, 900, 919, 920, 949, 950, 954, 955, 974, 986, 987, 988, 989, 996, 1019, 1027, 1050, 1053, 1054, 1055, 1058, 1059, 1066, 1069, 1075, 1079, 1084, 1087, 1093, 1100, 1109, 1116, 1117, 1118, 1119, 1139, 1140, 1151, 1152, 1155, 1156, 1157, 1159, 1160, 1161, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1189, 1190, 1191, 1192, 1193, 1195, 1196, 1197, 1198, 1199, 1200, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1235, 1236, 1237, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1253, 1254, 1255, 1256, 1257, 1258, 1262, 1263, 1264, 1265, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1279, 1280, 1281, 1282, 1283, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1314, 1315, 1316, 1318, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1329, 1330, 1333, 1334, 1335, 1340, 1343, 1345, 1346, 1347, 1351, 1352, 1362, 1367, 1371, 1372, 1373, 1377, 1382, 1385, 1390, 1391, 1393, 1397, 1398, 1399, 1402, 1403, 1404, 1406, 1407, 1408, 1430, 1432, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493, 1499, 1516, 1517, 1520, 1523, 1548, 1549, 1601, 1604, 1607, 1619, 1640, 1642, 1643, 1655, 1657, 1666, 1667, 1677, 1684, 1685, 1688, 1694, 1698, 1699, 1731, 1754, 1757, 1767, 1777, 1781, 1787, 1794, 1798, 1800], "rst": 8, "rebuild": [8, 21], "circleci": 8, "shard": [8, 20, 27, 33, 53, 1423], "worker": [8, 14, 20, 21, 23, 24, 27, 39, 40, 41, 42, 48, 50, 51, 53, 1423, 1741, 1774, 1782, 1783, 1789, 1790, 1791], "40": [8, 32, 983, 1102, 1171, 1213, 1432, 1433, 1456, 1457, 1464, 1467, 1697], "minut": [8, 11, 23, 1798], "netlifi": 8, "noplot": 8, "render": [8, 23, 1798], "notebook": 8, "rebuilt": [8, 21, 27], "deploi": [8, 39, 48, 1736, 1769, 1775, 1781], "action": [8, 23, 29, 39, 42, 60, 1762, 1781, 1783, 1791], "document": [9, 10, 11, 16, 20, 23, 33, 35, 53, 54, 60, 646, 647, 648, 649, 659, 660, 670, 675, 676, 677, 678, 679, 721, 722, 723, 724, 780, 811, 812, 814, 864, 905, 975, 978, 979, 1011, 1018, 1030, 1147, 1158, 1193, 1194, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1250, 1434, 1443, 1452, 1470, 1522, 1614, 1631, 1721, 1735, 1738, 1740, 1741, 1751, 1752, 1753, 1755, 1758, 1764, 1766, 1770, 1774, 1775, 1777, 1780, 1781, 1784, 1785, 1786, 1789, 1793, 1797, 1801], "develop": [9, 10, 11, 14, 21, 23, 37, 38, 60, 1737, 1740, 1741, 1747, 1759, 1764, 1769, 1770, 1774, 1781, 1784, 1785, 1789, 1793], "meant": [9, 24, 48, 50, 1458, 1758, 1789], "rule": [9, 10, 14, 23, 29, 60, 127, 740, 779, 780, 888, 1079, 1090, 1168, 1169, 1170, 1213, 1214, 1215, 1289, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493, 1585, 1624, 1707, 1736, 1738, 1740, 1752, 1754, 1759, 1760, 1764, 1767, 1796, 1800], "concern": [9, 20, 1751, 1762, 1777], "disagr": 9, "contribut": [9, 10, 759, 991, 992, 1186, 1193, 1194, 1257, 1330, 1338, 1339, 1382, 1423, 1736, 1754, 1764, 1765, 1782], "maintainership": [9, 10], "escal": [9, 10], "hacker": 9, "poster": 9, "amaz": 9, "ml": [9, 34], "obsess": 9, "soumith": [9, 11], "goe": [9, 35, 60, 958, 1162, 1766], "depth": [9, 10, 693, 699, 868, 869, 1043, 1165, 1180, 1183, 1245, 1302, 1358, 1415, 1747, 1763, 1770, 1783], "primari": [9, 10, 23, 60, 1039, 1742, 1747, 1793], "goal": [9, 34, 45, 60, 1131, 1747, 1759, 1763, 1767, 1778, 1791], "secondari": 9, "abil": [9, 1620, 1747, 1769, 1781], "flexibl": [9, 21, 35, 53, 1086, 1423, 1747, 1762, 1764, 1770], "abstract": [9, 20, 21, 24, 29, 35, 39, 48, 50, 1439, 1741, 1763, 1784, 1789], "remain": [9, 29, 48, 60, 1137, 1193, 1194, 1338, 1339, 1418, 1423, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1455, 1524, 1611, 1750, 1751, 1758, 1766, 1770], "critic": [9, 33, 35, 48, 1433, 1464, 1750, 1761, 1762], "concret": [9, 29, 35, 51, 60, 699, 1302, 1385, 1415, 1532, 1552, 1569, 1738, 1741, 1762, 1764, 1772], "jump": [9, 531, 1796], "regim": 9, "ei": 9, "tradeoff": [9, 21, 33, 1784, 1790], "temptat": 9, "impos": [9, 50, 58, 1751, 1758], "strict": [9, 748, 749, 750, 751, 752, 753, 968, 1030, 1045, 1046, 1250, 1781, 1798, 1800], "upfront": 9, "simplifi": [9, 21, 59, 1037, 1240, 1433, 1747, 1759, 1767, 1770, 1780, 1790], "worth": [9, 10, 20, 21, 35, 51, 962, 1735, 1797], "friction": 9, "compel": 9, "rel": [9, 10, 14, 21, 23, 29, 35, 53, 60, 610, 724, 755, 756, 807, 1019, 1084, 1087, 1298, 1299, 1312, 1347, 1507, 1747, 1750, 1761, 1762, 1769, 1781, 1800], "narrow": [9, 33, 38, 1099, 1150, 1647, 1739, 1741, 1752, 1779, 1797], "subproblem": 9, "fragment": [9, 38, 832, 864, 1762], "ecosystem": [9, 34, 1769, 1771], "limit": [9, 10, 20, 33, 34, 35, 38, 53, 54, 58, 876, 962, 1043, 1173, 1193, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1423, 1448, 1637, 1736, 1741, 1751, 1753, 1754, 1759, 1762, 1763, 1770, 1773, 1774, 1775, 1781, 1784, 1787, 1789, 1790, 1800], "incomprehens": 9, "seamlessli": [9, 1754], "softwar": [9, 1065, 1066, 1093, 1721, 1762, 1768], "experi": [9, 10, 12, 21, 36, 37, 38, 58, 971, 1279, 1399, 1423, 1728, 1747, 1764, 1798], "rich": [9, 1741], "denomin": [9, 603, 1168, 1169, 1170, 1205, 1213, 1214, 1215, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1289, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1494, 1592], "subset": [9, 20, 23, 27, 49, 1041, 1737, 1738, 1740, 1741, 1764, 1777, 1787], "borrow": 9, "zen": 9, "implicit": [9, 682, 683, 686, 687, 688, 975, 983, 1163, 1164, 1165, 1178, 1179, 1180, 1181, 1182, 1183, 1197, 1243, 1244, 1245, 1301, 1314, 1315, 1316, 1322, 1323, 1324, 1371, 1372, 1373, 1511, 1737, 1739, 1741, 1742, 1777, 1781, 1797], "concis": [9, 41, 1789], "interchang": [9, 29, 1491, 1706, 1740, 1768, 1778], "everydai": 9, "english": 9, "movement": [9, 1797], "worri": [9, 1789], "placement": [9, 33, 39, 1418, 1584, 1784, 1789], "favor": [9, 23, 35, 699, 700, 701, 786, 875, 879, 1030, 1084, 1087, 1119, 1120, 1209, 1250, 1303, 1304, 1415, 1416, 1417, 1419, 1523, 1688, 1694, 1709], "practition": 9, "debugg": [9, 33, 38, 1035, 1767], "plug": 9, "ir": [9, 33, 38, 60, 674, 1033, 1034, 1202, 1203, 1738, 1741, 1777], "classic": [9, 1759], "sort": [9, 27, 35, 39, 60, 562, 581, 724, 725, 745, 905, 990, 1138, 1158, 1459, 1460, 1469, 1524, 1624, 1704, 1718, 1739, 1741, 1764, 1766, 1779, 1793], "distribut": [9, 12, 20, 21, 24, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 59, 150, 234, 262, 352, 427, 454, 580, 611, 612, 765, 880, 1140, 1158, 1162, 1186, 1187, 1188, 1189, 1190, 1191, 1195, 1200, 1204, 1216, 1264, 1268, 1289, 1330, 1332, 1333, 1334, 1335, 1340, 1344, 1345, 1349, 1359, 1390, 1423, 1471, 1516, 1547, 1595, 1597, 1598, 1599, 1600, 1601, 1602, 1736, 1741, 1753, 1757, 1758, 1762, 1782, 1783, 1785, 1791, 1794, 1798, 1801], "tldr": 9, "resourc": [9, 14, 20, 33, 39, 44, 48, 60, 1741, 1751, 1793], "characterist": [9, 1689, 1765, 1770], "uniformli": [9, 29, 1599, 1600, 1800], "leak": [9, 740, 746, 1741, 1751, 1759], "smart": [9, 1764, 1781, 1789], "anywai": [9, 1759], "obviou": [9, 1766, 1791], "extens": [9, 14, 17, 23, 29, 33, 38, 1101, 1102, 1620, 1640, 1736, 1747, 1754, 1758, 1775, 1781, 1793], "unavoid": 9, "latenc": [9, 33, 45, 1761, 1762], "caveat": [9, 38, 1418, 1463, 1747, 1751, 1762, 1770, 1775], "valuabl": 9, "certainli": [9, 1747], "heterogen": [9, 1740], "cluster": [9, 47, 48, 49, 1158, 1798], "focus": [9, 38, 1740, 1741, 1764], "beaten": 9, "space": [9, 10, 20, 29, 686, 687, 688, 888, 923, 925, 927, 928, 934, 941, 983, 992, 1045, 1046, 1100, 1116, 1158, 1178, 1179, 1180, 1181, 1182, 1183, 1197, 1216, 1226, 1227, 1228, 1229, 1230, 1231, 1244, 1245, 1301, 1322, 1323, 1324, 1325, 1326, 1327, 1359, 1707, 1739, 1755, 1759, 1767, 1770, 1775], "innov": 9, "ultim": [9, 10, 14, 41, 50, 1763], "evidenc": 9, "potenti": [9, 23, 33, 35, 48, 50, 168, 185, 1039, 1075, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1423, 1721, 1740, 1747, 1751, 1759, 1762, 1781, 1793, 1797], "began": 9, "bind": [9, 14, 60, 844, 1741, 1742, 1781], "monolith": 9, "deepli": 9, "integr": [9, 20, 31, 42, 131, 765, 767, 768, 769, 770, 771, 772, 807, 888, 991, 1030, 1053, 1097, 1098, 1149, 1250, 1595, 1607, 1707, 1754, 1764, 1769, 1770, 1780, 1782, 1784, 1794, 1796, 1800], "numpi": [9, 20, 37, 57, 421, 465, 609, 610, 615, 725, 727, 728, 744, 900, 902, 903, 905, 923, 944, 945, 946, 947, 951, 952, 957, 971, 993, 1060, 1061, 1071, 1082, 1084, 1085, 1086, 1087, 1088, 1093, 1094, 1097, 1099, 1131, 1136, 1517, 1607, 1610, 1617, 1629, 1637, 1670, 1671, 1672, 1673, 1674, 1675, 1688, 1690, 1691, 1697, 1700, 1701, 1703, 1725, 1728, 1729, 1747, 1760, 1764, 1765, 1773, 1774, 1776, 1781, 1796, 1797, 1798, 1799, 1800, 1805], "scipi": [9, 783, 1076, 1077, 1387, 1517, 1781, 1792, 1794, 1798], "scikit": [9, 1358], "favorit": 9, "cython": 9, "numba": 9, "reinvent": 9, "wheel": [9, 12, 1776], "year": [9, 1793], "rewrot": 9, "frontend": [9, 15, 33, 60], "familiar": [9, 15, 33, 60, 863, 1738, 1759, 1765, 1781, 1784, 1790, 1791], "perhap": [9, 35, 1765], "importantli": [9, 35], "huge": [9, 1689, 1750], "scientif": [9, 1637], "pareto": [9, 1736], "close": [9, 15, 23, 48, 60, 779, 846, 1019, 1065, 1066, 1092, 1093, 1119, 1281, 1299, 1624, 1688, 1709, 1750, 1759, 1764, 1773, 1781, 1784, 1789, 1798, 1800], "curv": [9, 1798], "capabl": [9, 14, 15, 23, 835, 1595, 1745, 1762, 1768, 1769, 1771, 1801], "torch_funct": [9, 1764], "torch_dispatch": 9, "torch": [9, 10, 12, 15, 17, 18, 21, 24, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 48, 50, 51, 53, 64, 65, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 741, 762, 809, 810, 811, 812, 814, 815, 829, 831, 842, 909, 1005, 1028, 1029, 1030, 1044, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1418, 1423, 1424, 1425, 1426, 1427, 1428, 1434, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1458, 1468, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1595, 1634, 1736, 1738, 1739, 1740, 1752, 1753, 1758, 1759, 1760, 1761, 1763, 1766, 1767, 1769, 1770, 1771, 1772, 1774, 1776, 1782, 1784, 1785, 1786, 1789, 1790, 1791, 1797], "tracer": [9, 35, 1045, 1777, 1798, 1803], "functorch": [9, 54, 58, 741, 748, 750, 751], "anchor": [9, 60, 1298, 1299, 1412, 1413, 1739], "hackabl": 9, "todai": [9, 54, 58, 1784], "open": [9, 10, 14, 20, 29, 33, 48, 54, 605, 757, 955, 1037, 1101, 1124, 1134, 1364, 1738, 1747, 1751, 1754, 1768, 1776, 1777, 1781, 1784, 1789, 1793, 1794], "evolv": [9, 1763], "ai": [9, 1777, 1794], "adopt": [10, 23, 636, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 659, 660, 670, 675, 676, 677, 678, 679], "hierarch": [10, 1798], "pull": [10, 11, 15, 37, 60, 127, 740, 1781], "request": [10, 11, 12, 23, 50, 605, 727, 728, 864, 1102, 1124, 1134, 1364, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1586, 1735, 1754, 1758, 1759, 1761, 1762, 1777, 1781, 1789, 1790, 1791, 1793, 1794], "overseen": 10, "catch": [10, 41, 1738, 1759, 1765, 1767], "maker": 10, "strong": 10, "toward": [10, 900, 991, 992, 1102, 1154, 1423, 1502, 1608, 1616, 1617, 1782], "philosophi": [10, 1736], "beyond": [10, 21, 1186, 1480, 1481, 1490, 1615, 1766, 1770], "encourag": [10, 39, 1754, 1784, 1793, 1800], "propos": [10, 1477, 1497, 1498, 1747, 1767, 1780, 1790], "review": [10, 11, 21, 35, 1781], "willing": 10, "invest": 10, "anyon": 10, "ownership": [10, 60], "codebas": 10, "strictli": [10, 20, 127, 168, 185, 740, 779, 992, 1030, 1034, 1250, 1759, 1794], "compani": 10, "bui": 10, "addition": [10, 20, 21, 23, 29, 53, 127, 485, 589, 740, 962, 966, 967, 1034, 1093, 1158, 1213, 1214, 1215, 1766, 1801], "membership": [10, 39, 47, 48, 1742], "That": [10, 39, 46, 49, 55, 60, 1027, 1100, 1116, 1721, 1748, 1764, 1765, 1766, 1775, 1781, 1789], "seat": 10, "reserv": [10, 45, 864, 1742, 1762, 1770], "emploi": [10, 1493, 1770, 1781, 1782], "directori": [10, 14, 23, 33, 37, 38, 46, 1735, 1749, 1769, 1781, 1783, 1798], "procedur": [10, 29, 38, 1045, 1046, 1102, 1584, 1789], "disput": 10, "made": [10, 27, 35, 38, 49, 60, 746, 756, 1030, 1250, 1295, 1297, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1490, 1491, 1492, 1493, 1494, 1605, 1740, 1747, 1776, 1781, 1798, 1800, 1804], "public": [10, 11, 962, 1764, 1804], "relev": [10, 24, 34, 35, 39, 48, 59, 1093, 1742, 1758, 1759, 1781, 1784], "resolut": [10, 1262, 1263, 1312, 1347, 1388, 1389, 1707, 1742, 1781, 1805], "conclus": 10, "publicli": [10, 1804], "vision": [10, 34, 1039, 1186, 1330, 1735, 1736], "roadmap": [10, 11], "parti": [10, 48, 1735, 1736, 1738, 1762, 1765, 1770, 1781], "particip": [10, 20, 23, 24, 27, 48, 49, 1423, 1790], "triag": [10, 11], "meet": [10, 11, 47, 1059, 1762], "Their": [10, 897], "articul": 10, "cohes": 10, "negoti": [10, 1789], "contenti": 10, "broad": [10, 1770], "stakehold": 10, "power": [10, 47, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 948, 1053, 1083, 1097, 1218, 1219, 1368, 1369, 1433, 1464, 1477, 1506, 1520, 1609, 1722, 1742, 1762, 1793], "veto": 10, "admin": 10, "amongst": 10, "commonli": [10, 29, 34, 53, 1131, 1741, 1743, 1758, 1759, 1780, 1784, 1796], "merit": 10, "demonstr": [10, 34, 49, 60, 1173, 1738, 1770, 1775, 1782, 1789], "expertis": 10, "align": [10, 21, 693, 699, 905, 983, 1085, 1165, 1173, 1186, 1202, 1216, 1220, 1244, 1245, 1265, 1302, 1330, 1331, 1358, 1359, 1415, 1432, 1470, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493, 1497, 1548, 1554, 1707, 1736, 1752, 1759, 1767, 1777, 1787, 1794], "continu": [10, 20, 23, 29, 32, 35, 51, 53, 60, 580, 749, 983, 1065, 1066, 1093, 1172, 1173, 1423, 1480, 1547, 1742, 1747, 1759, 1775, 1783, 1801], "light": [10, 1798], "mainten": [10, 48, 49], "emeritu": [10, 11], "inact": [10, 864, 1762], "contact": 10, "item": [10, 20, 35, 555, 561, 702, 703, 704, 706, 707, 708, 1186, 1251, 1260, 1437, 1546, 1637, 1735, 1737, 1738, 1739, 1740, 1741, 1752, 1762, 1777, 1779, 1781, 1789, 1798, 1799], "nomine": 10, "breadth": 10, "testimoni": 10, "posit": [10, 20, 29, 60, 65, 377, 444, 516, 755, 764, 766, 773, 786, 787, 788, 921, 922, 923, 924, 925, 933, 935, 939, 941, 958, 968, 970, 987, 988, 1022, 1025, 1030, 1033, 1059, 1060, 1071, 1073, 1084, 1087, 1088, 1102, 1122, 1137, 1144, 1149, 1150, 1167, 1178, 1179, 1180, 1185, 1186, 1187, 1194, 1204, 1211, 1250, 1256, 1286, 1293, 1298, 1299, 1312, 1320, 1339, 1344, 1347, 1412, 1413, 1420, 1421, 1422, 1428, 1582, 1586, 1588, 1615, 1617, 1666, 1668, 1710, 1711, 1712, 1713, 1720, 1735, 1739, 1752, 1753, 1764, 1765, 1767, 1777, 1779, 1782, 1788, 1793, 1794, 1800, 1804, 1805], "neg": [10, 12, 14, 20, 23, 29, 50, 60, 65, 414, 416, 431, 614, 669, 694, 766, 802, 805, 814, 829, 835, 836, 864, 875, 921, 922, 923, 924, 925, 926, 940, 941, 942, 948, 958, 1020, 1022, 1024, 1083, 1110, 1122, 1140, 1144, 1149, 1150, 1158, 1167, 1195, 1204, 1236, 1243, 1244, 1245, 1253, 1257, 1259, 1264, 1281, 1298, 1299, 1340, 1344, 1347, 1349, 1358, 1362, 1371, 1372, 1373, 1382, 1390, 1412, 1413, 1415, 1516, 1517, 1613, 1617, 1652, 1654, 1657, 1667, 1702, 1710, 1711, 1712, 1713, 1720, 1737, 1738, 1739, 1752, 1754, 1757, 1759, 1765, 1777, 1779, 1788, 1793, 1794], "interact": [10, 15, 20, 33, 60, 812, 844, 1005, 1587, 1742, 1763, 1781, 1798], "final": [10, 23, 27, 29, 32, 38, 39, 48, 57, 602, 605, 606, 674, 763, 781, 794, 905, 944, 962, 983, 1101, 1119, 1124, 1202, 1204, 1220, 1265, 1278, 1418, 1666, 1707, 1738, 1740, 1741, 1742, 1752, 1764, 1767, 1770, 1773, 1775, 1777, 1781, 1790, 1791], "declin": 10, "conflict": [10, 21, 49, 1781], "lack": [10, 12, 1065, 1066, 1093], "unfit": 10, "conduct": [10, 1423, 1513, 1689, 1789], "filial": 10, "romant": 10, "strength": 10, "candid": [10, 759, 1739, 1781], "letter": [10, 905], "befit": 10, "candidaci": 10, "behind": [10, 1736, 1775, 1790], "75": [10, 991, 1238, 1347, 1365, 1477, 1524, 1739, 1794], "choos": [10, 15, 60, 759, 833, 1075, 1088, 1093, 1166, 1757, 1758, 1761, 1781, 1785, 1798], "unforeseen": 10, "circumst": [10, 48, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1762], "perman": [10, 60, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1455, 1791], "unavail": [10, 1740], "rank": [10, 20, 21, 23, 24, 27, 29, 38, 39, 46, 48, 49, 51, 53, 1075, 1076, 1077, 1084, 1119, 1242, 1289, 1423, 1437, 1513, 1689, 1739, 1763, 1772, 1777, 1782, 1789, 1790], "elect": 10, "invit": [10, 1735], "convinc": 10, "approach": [10, 21, 23, 33, 60, 783, 971, 1728, 1738, 1751, 1754, 1762, 1764, 1767, 1784, 1789], "interview": 10, "talk": [10, 50, 1769], "gather": [10, 23, 48, 53, 485, 1697, 1721, 1737, 1739, 1764, 1766, 1769, 1779, 1781], "read": [10, 17, 20, 23, 30, 33, 34, 35, 36, 38, 39, 41, 48, 49, 53, 60, 421, 866, 888, 956, 957, 958, 1037, 1101, 1507, 1736, 1752, 1753, 1759, 1760, 1762, 1763, 1765, 1769, 1773, 1781, 1784, 1789], "attend": [10, 1256, 1293, 1428], "confer": [10, 1204], "pipelin": [10, 33, 60, 1736, 1789], "world": [10, 23, 27, 36, 39, 46, 48, 49, 53, 1289, 1423, 1759, 1781, 1784], "cover": [10, 32, 35, 54, 60, 880, 905, 1243, 1371, 1372, 1373, 1741, 1743, 1753, 1764, 1767, 1769, 1770, 1789], "push": [10, 35, 40, 869, 971, 1095, 1728, 1783], "codeown": 10, "notifi": [10, 24, 49, 1791], "expert": 10, "strongli": [10, 23, 39, 49, 1189, 1190, 1191, 1195, 1684, 1735], "failur": [10, 23, 29, 33, 35, 38, 39, 40, 41, 45, 46, 47, 48, 51, 755, 756, 962, 1045, 1046, 1741, 1751, 1782, 1789, 1791, 1800], "revert": [10, 29, 53, 1286, 1404, 1791], "substanti": [10, 21, 1762], "syntact": [10, 41, 60], "incompat": [10, 14, 57, 776, 1027, 1760, 1781, 1800], "establish": [10, 23, 48, 1759], "seri": [10, 60, 1173, 1213, 1774, 1777, 1804], "lf": 10, "llc": 10, "guidelin": [10, 1448, 1781, 1784, 1785], "trademark": 10, "www": [10, 1173, 1299, 1798], "lfproject": 10, "acknowledg": [10, 23, 1736, 1791, 1793], "copyright": [10, 38], "holder": 10, "independ": [10, 20, 23, 48, 53, 59, 130, 131, 693, 699, 748, 749, 750, 751, 752, 753, 814, 983, 992, 1088, 1188, 1189, 1190, 1191, 1195, 1333, 1334, 1335, 1340, 1358, 1415, 1467, 1523, 1736, 1738, 1758, 1759, 1762, 1775, 1781], "authorship": 10, "claus": [10, 1766], "bsd": 10, "licens": 10, "opensourc": 10, "outbound": 10, "inbound": 10, "q": [10, 21, 29, 405, 452, 672, 975, 1050, 1066, 1069, 1088, 1130, 1147, 1216, 1256, 1432, 1511, 1513, 1523, 1524, 1689, 1738, 1739, 1767, 1774, 1777, 1793, 1794], "partli": [10, 1741], "domain": [10, 29, 41, 600, 733, 919, 920, 921, 922, 924, 925, 926, 927, 928, 933, 935, 936, 937, 938, 983, 1554, 1754, 1777, 1784], "absolut": [10, 12, 14, 60, 69, 597, 610, 755, 756, 953, 1019, 1058, 1063, 1084, 1087, 1089, 1110, 1211, 1217, 1281, 1356, 1360, 1400, 1442, 1443, 1445, 1446, 1448, 1451, 1452, 1453, 1454, 1470, 1517, 1608, 1640, 1739, 1770, 1779, 1794, 1799, 1800], "health": 10, "success": [10, 29, 38, 39, 45, 60, 1060, 1071, 1073, 1119, 1444, 1670, 1671, 1672, 1674, 1675, 1762, 1770, 1777, 1793], "am": 10, "grant": 10, "purchas": 10, "board": 10, "driven": [10, 1777], "clearli": [10, 1747, 1781], "sponsorship": 10, "foundat": [10, 1778], "ptf": 10, "minor": [10, 835, 1060, 1076], "committ": 10, "facebook": 10, "infrastructur": [10, 40, 1781], "employe": 10, "expand": [10, 29, 231, 465, 726, 747, 755, 756, 778, 1082, 1083, 1131, 1256, 1300, 1391, 1717, 1735, 1737, 1739, 1752, 1753, 1760, 1765, 1777, 1779, 1781, 1782, 1797], "deliv": [10, 1783], "offici": [10, 23, 1158, 1784], "showcas": [10, 1246, 1762, 1772], "whenev": [10, 35, 728, 1432, 1433, 1480, 1750, 1751, 1787, 1790, 1791, 1804], "fix": [11, 17, 20, 23, 29, 33, 38, 39, 48, 53, 55, 57, 60, 238, 962, 1043, 1075, 1193, 1194, 1338, 1339, 1358, 1423, 1533, 1738, 1739, 1750, 1757, 1758, 1762, 1763, 1766, 1772, 1776, 1777, 1779, 1780], "plu": [11, 14, 748, 958, 1076, 1793], "quarterli": 11, "chintala": 11, "edward": 11, "yang": [11, 1102], "ezyang": [11, 1797], "greg": 11, "chanan": 11, "gchanan": 11, "dmytro": 11, "dzhulgakov": 11, "joel": [11, 1513, 1689], "schlosser": 11, "jbschlosser": 11, "alban": 11, "desmaison": 11, "alband": 11, "sam": 11, "gross": 11, "colesburi": 11, "adam": [11, 24, 27, 29, 53, 1481, 1482, 1484, 1490, 1494, 1780], "paszk": 11, "apaszk": 11, "ilqar": 11, "ramazanli": 11, "iramazanli": 11, "vincent": 11, "quennevil": 11, "belair": 11, "vincentqb": 11, "jeffrei": 11, "wan": 11, "soulitz": 11, "elia": 11, "ellison": 11, "eellison": 11, "michael": [11, 38], "suo": 11, "yanan": 11, "cao": 11, "gmagogsfm": 11, "jame": 11, "reed": 11, "jamesr66a": 11, "jason": [11, 32], "ansel": [11, 32], "jansel": 11, "zach": 11, "devito": 11, "zdevito": 11, "fritz": 11, "obermey": 11, "fritzo": 11, "neeraj": 11, "pradhan": 11, "neerajprad": 11, "alican": 11, "bozkurt": 11, "alicanb": 11, "vishwak": 11, "srinivasan": 11, "vishwakftw": 11, "shen": 11, "li": [11, 1147, 1524, 1762], "mrshenli": 11, "pritam": 11, "damania": 11, "pritamdamania87": 11, "yanli": 11, "zhao": 11, "zhaojuanmao": 11, "rohan": 11, "varma": 11, "wanchao": 11, "liang": 11, "wanchaol": 11, "junji": 11, "wang": [11, 29], "fduwjj": 11, "howard": 11, "huang": 11, "tristan": 11, "rice": 11, "d4l3k": 11, "alisson": 11, "azzolini": 11, "aazzolini": 11, "ke": 11, "wen": 11, "kwen2501": 11, "kiuk": 11, "chung": 11, "kiukchung": 11, "pieter": 11, "noordhui": 11, "pietern": 11, "mingzh": 11, "mingzhe09088": 11, "omkar": 11, "salpekar": 11, "osalpekar": 11, "vitali": 11, "fedyunin": 11, "vitalyfedyunin": 11, "simon": 11, "ssnl": 11, "mike": 11, "ruberri": 11, "mruberri": 11, "mario": 11, "lezcano": 11, "ivan": 11, "yashchuk": 11, "ivanyashchuk": 11, "pearu": 11, "peterson": 11, "nikita": 11, "vedeneev": 11, "nikitav": 11, "christian": 11, "puhrsch": 11, "cpuhrsch": 11, "andrew": [11, 1102], "amjam": 11, "driss": 11, "guessou": 11, "drisspg": 11, "mikayla": 11, "gawarecki": 11, "mikaylagawarecki": 11, "natalia": 11, "gimelshein": 11, "ngimel": 11, "georg": 11, "qi": 11, "peter": 11, "bell": 11, "peterbell10": 11, "mingfei": 11, "ma": 11, "mingfeima": 11, "xiaoqiang": 11, "zheng": 11, "xq": 11, "ilia": 11, "cherniavskii": 11, "cher": 11, "piotr": 11, "bialecki": 11, "ptrblck": 11, "sarofeen": 11, "csarofeen": 11, "tulloch": 11, "ajtulloch": 11, "alex": 11, "jann": 11, "jjsjann123": 11, "jianhui": 11, "bai": 11, "bddppq": 11, "yinghai": 11, "peng": 11, "sun": 11, "sunway513": 11, "jithun": 11, "nair": 11, "jithunnair": 11, "jeff": 11, "daili": 11, "jeffdaili": 11, "shulga": 11, "malfet": 11, "eli": 11, "uriega": 11, "seemether": 11, "mikei": 11, "dagits": 11, "zain": 11, "rizvi": 11, "zainrizvi": 11, "nirav": 11, "mehta": 11, "mehtanirav": 11, "andrei": 11, "talman": 11, "atalman": 11, "zhuoji": 11, "zhou": 11, "zhouzhuoji": 11, "karl": 11, "ostmo": 11, "kostmo": 11, "adnan": 11, "aziz": 11, "adnanaziz": 11, "ck": 11, "luk": 11, "ckluk": 11, "taylor": [11, 983], "robi": 11, "robieta": 11, "xu": [11, 53], "xuzhao9": 11, "geeta": 11, "chauhan": 11, "chauhang": 11, "victor": 11, "bittorf": 11, "bitfort": 11, "gisl": 11, "dankel": 11, "gdankel": 11, "feng": 11, "yf225": 11, "brian": 11, "hirsh": 11, "bdhirsh": 11, "sebastian": 11, "messmer": 11, "smessmer": 11, "bowen": 11, "bao": 11, "bowenbao": 11, "aaron": 11, "bockov": 11, "abock": 11, "gari": 11, "miguel": 11, "garymm": 11, "lara": 11, "haidar": 11, "hdr": 11, "fang": 11, "houseroad": 11, "negin": 11, "raoof": 11, "neginraoof": 11, "spandan": 11, "tiwari": 11, "spandantiwari": 11, "david": [11, 1158], "reiss": 11, "dreiss": 11, "raziel": 11, "guevara": 11, "linbin": 11, "yu": 11, "linbinyu": 11, "kobzarev": 11, "ivankobzarev": 11, "tao": 11, "xta0": 11, "vasilii": 11, "kuznetsov": 11, "vkuzo": 11, "jerri": 11, "zhang": 11, "jerryzh168": 11, "zafar": 11, "takhirov": 11, "supriya": 11, "rao": 11, "supriyar": 11, "raghuraman": 11, "krishnamoorthi": 11, "raghuramank100": 11, "guoliang": 11, "hua": 11, "nbcsm": 11, "teng": 11, "gao": 11, "gaoteng": 11, "git": [11, 33, 38, 1783], "johnson": 11, "peterjc123": [11, 1776], "kulin": 11, "seth": 11, "kulinseth": 11, "ramin": 11, "azarmehr": 11, "razarmehr": 11, "alfredo": 11, "mendoza": 11, "avmgithub": 11, "svetlana": 11, "karslioglu": 11, "svekar": 11, "jack": 11, "jackcaog": 11, "daniel": [11, 29], "sohn": 11, "jysohn23": 11, "cain": 11, "zcain117": 11, "hirsch": 11, "gregori": 11, "ail": 11, "ailzhang": 11, "libenzi": 11, "dlibenzi": 11, "suhan": 11, "asuhan": 11, "manoj": 11, "mycpuorg": 11, "vamshi": 11, "dantu": 11, "vdantu": 11, "dhanasekar": 11, "karuppasami": 11, "dhanainm": 11, "francisco": 11, "massa": 11, "fmassa": 11, "vasili": 11, "vrynioti": 11, "datumbox": 11, "nicola": 11, "hug": 11, "nicolashug": 11, "yosua": 11, "maranatha": 11, "yosuamichael": 11, "joao": 11, "gome": 11, "jdsgome": 11, "philip": 11, "meier": 11, "pmeier": 11, "fomin": 11, "vfdev": 11, "nayef": 11, "ahm": 11, "nayef211": 11, "parmeet": 11, "singh": 11, "bhatia": 11, "guanheng": 11, "zhangguanheng66": 11, "moto": 11, "hira": 11, "mthrok": 11, "hwang": 11, "hwangjeff": 11, "carolin": 11, "chen": 11, "carolineechen": 11, "xiaohui": 11, "zhaoheng": 11, "ni": 11, "nateanl": 11, "qb": 11, "ivchenko": 11, "divchenko": 11, "colin": 11, "colin2328": 11, "wenlei": 11, "xie": 11, "wenleix": 11, "11": [12, 14, 23, 32, 37, 38, 297, 485, 785, 789, 814, 853, 903, 993, 1050, 1086, 1100, 1116, 1158, 1174, 1199, 1247, 1343, 1470, 1471, 1662, 1701, 1729, 1738, 1742, 1747, 1753, 1762, 1776, 1777, 1779, 1793, 1794], "6": [12, 14, 17, 20, 21, 23, 29, 32, 33, 38, 46, 60, 289, 291, 293, 297, 444, 460, 471, 485, 489, 531, 579, 601, 602, 607, 613, 655, 656, 657, 659, 660, 672, 675, 677, 679, 748, 749, 751, 752, 753, 766, 774, 779, 785, 788, 789, 793, 807, 866, 883, 884, 888, 889, 900, 903, 904, 921, 929, 934, 935, 939, 940, 942, 944, 945, 948, 955, 983, 993, 995, 996, 1019, 1040, 1051, 1055, 1066, 1082, 1086, 1087, 1088, 1095, 1096, 1100, 1102, 1131, 1135, 1148, 1149, 1150, 1163, 1174, 1177, 1182, 1185, 1193, 1194, 1203, 1204, 1205, 1207, 1208, 1246, 1247, 1251, 1259, 1267, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1293, 1294, 1296, 1301, 1314, 1344, 1351, 1352, 1384, 1393, 1418, 1460, 1461, 1463, 1469, 1470, 1471, 1478, 1492, 1512, 1513, 1516, 1523, 1524, 1595, 1596, 1599, 1605, 1615, 1616, 1620, 1624, 1637, 1658, 1662, 1665, 1668, 1670, 1671, 1676, 1687, 1689, 1690, 1691, 1696, 1701, 1702, 1703, 1704, 1705, 1707, 1710, 1712, 1716, 1721, 1729, 1730, 1738, 1741, 1742, 1747, 1754, 1757, 1759, 1764, 1765, 1770, 1775, 1777, 1789, 1790, 1793, 1794, 1796, 1799, 1800, 1804], "download": [12, 34, 37, 1749, 1776, 1798], "pip": [12, 1776, 1777, 1798], "express": [12, 33, 38, 54, 57, 58, 60, 295, 1028, 1031, 1684, 1742, 1748, 1754, 1759, 1764, 1804], "bj": 12, "j": [12, 23, 29, 289, 291, 297, 485, 487, 489, 608, 742, 748, 750, 797, 905, 921, 922, 929, 935, 939, 940, 972, 1027, 1030, 1065, 1066, 1077, 1093, 1102, 1109, 1117, 1119, 1124, 1189, 1190, 1191, 1195, 1250, 1253, 1333, 1334, 1335, 1340, 1517, 1524, 1667, 1684, 1688, 1694, 1725, 1740, 1757, 1759, 1764, 1767, 1775], "imaginari": [12, 287, 755, 797, 803, 926, 928, 936, 937, 938, 1000, 1020, 1022, 1023, 1026, 1684, 1726, 1727, 1742, 1759, 1767, 1800], "satisfi": [12, 18, 21, 29, 589, 610, 674, 749, 755, 756, 779, 921, 922, 924, 926, 928, 936, 937, 938, 953, 1043, 1069, 1095, 1096, 1158, 1173, 1197, 1202, 1220, 1265, 1448, 1463, 1608, 1624, 1684, 1741, 1759, 1762, 1767, 1780, 1782, 1793, 1796], "equat": [12, 788, 905, 975, 987, 1073, 1074, 1075, 1076, 1077, 1079, 1090, 1092, 1166, 1650, 1709, 1739, 1759, 1767, 1794], "frequent": [12, 34, 1158, 1736, 1773, 1775], "mathemat": [12, 60, 748, 749, 750, 751, 752, 753, 953, 983, 1166, 1168, 1169, 1170, 1213, 1214, 1215, 1216, 1289, 1366, 1403, 1423, 1470, 1608, 1666, 1741, 1759, 1773, 1794, 1801], "topic": [12, 36, 1769, 1770], "tradition": 12, "torchaudio": [12, 1736], "mimick": 12, "vector": [12, 21, 29, 34, 53, 54, 57, 230, 289, 291, 297, 605, 606, 607, 732, 740, 742, 748, 749, 750, 751, 752, 753, 754, 776, 777, 783, 794, 803, 807, 808, 886, 887, 892, 894, 968, 970, 971, 975, 1062, 1069, 1077, 1085, 1086, 1090, 1093, 1097, 1098, 1099, 1119, 1124, 1131, 1140, 1142, 1167, 1168, 1169, 1170, 1173, 1187, 1193, 1194, 1197, 1205, 1213, 1214, 1215, 1259, 1289, 1298, 1301, 1320, 1338, 1339, 1347, 1349, 1383, 1387, 1414, 1429, 1431, 1433, 1437, 1466, 1470, 1512, 1513, 1668, 1688, 1694, 1722, 1725, 1728, 1759, 1767, 1784, 1793, 1798], "assembl": [12, 20], "lapack": [12, 787, 975, 1060, 1071, 1072, 1073, 1075, 1078, 1091, 1523, 1688], "cubla": [12, 825, 1721, 1774], "spectral": [12, 1049, 1065, 1093, 1433, 1456, 1464, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1773], "fft": [12, 1736, 1762], "4621": 12, "0303j": 12, "2438": [12, 1075, 1338], "5874j": 12, "7706": 12, "1421j": 12, "2110": 12, "1918j": 12, "complex128": [12, 152, 797, 948, 957, 1009, 1030, 1059, 1060, 1065, 1066, 1067, 1068, 1069, 1070, 1178, 1179, 1180, 1250, 1322, 1323, 1324, 1476, 1517, 1629, 1795, 1796, 1799, 1800], "complex64": [12, 155, 797, 922, 924, 925, 930, 931, 957, 1009, 1061, 1084, 1087, 1178, 1179, 1180, 1322, 1323, 1324, 1476, 1517, 1629, 1795, 1796, 1799, 1800], "apart": [12, 1741, 1759], "linspac": [12, 766, 790, 926, 936, 1131, 1739, 1743, 1779], "logspac": [12, 1739, 1743, 1779], "arang": [12, 20, 23, 30, 34, 485, 579, 607, 608, 609, 613, 615, 734, 735, 736, 777, 789, 793, 888, 903, 921, 925, 933, 939, 941, 945, 946, 947, 948, 955, 956, 993, 1050, 1051, 1055, 1058, 1082, 1085, 1086, 1099, 1150, 1271, 1272, 1273, 1274, 1275, 1302, 1303, 1304, 1384, 1470, 1471, 1512, 1520, 1524, 1604, 1611, 1616, 1637, 1668, 1676, 1687, 1701, 1702, 1704, 1705, 1707, 1729, 1737, 1739, 1747, 1754, 1775, 1779, 1794, 1798, 1799], "switch": [12, 20, 56, 59, 60, 1072, 1073, 1074, 1190, 1347, 1385, 1429, 1620, 1721, 1751, 1759, 1762, 1770, 1780], "view_as_r": [12, 1684, 1739, 1779, 1797], "6125": 12, "1681": 12, "3773": 12, "3487": 12, "0861": 12, "7981": 12, "1681j": 12, "3487j": 12, "7981j": 12, "mul_": [12, 1739, 1752, 1754, 1793], "2250": [12, 1086, 1470], "7546": [12, 788], "1722": 12, "x1": [12, 783, 1077, 1185, 1242, 1298, 1299, 1329, 1386, 1739], "3j": [12, 23, 614, 800, 801, 1612, 1613, 1629], "4j": [12, 23, 1640], "0000": [12, 29, 485, 713, 748, 750, 766, 786, 790, 803, 886, 892, 893, 894, 919, 920, 923, 925, 926, 932, 933, 936, 941, 953, 954, 955, 983, 989, 992, 996, 1055, 1058, 1059, 1060, 1072, 1073, 1076, 1081, 1082, 1086, 1088, 1100, 1116, 1145, 1193, 1194, 1302, 1303, 1305, 1338, 1339, 1470, 1517, 1523, 1593, 1594, 1595, 1604, 1608, 1609, 1633, 1640, 1642, 1643, 1645, 1648, 1649, 1650, 1651, 1666, 1709, 1710, 1712, 1731, 1747, 1754, 1762, 1793, 1794, 1799], "6569": [12, 996], "5708": [12, 889], "7854": 12, "complex_tensor": 12, "pt": [12, 21, 34, 1035, 1037, 1040, 1047, 1101, 1620, 1738, 1770, 1775, 1781], "conjug": [12, 306, 431, 608, 755, 788, 800, 801, 1010, 1059, 1060, 1066, 1069, 1072, 1079, 1093, 1098, 1102, 1432, 1511, 1612, 1684, 1688, 1725, 1767, 1780, 1799], "wirting": [12, 755, 1767], "deriv": [12, 23, 53, 127, 652, 653, 654, 655, 656, 657, 695, 740, 754, 755, 756, 968, 970, 983, 1027, 1087, 1119, 1418, 1532, 1552, 1736, 1740, 1764, 1767, 1789, 1793, 1794], "steepest": [12, 1759], "descent": [12, 29, 1477, 1493, 1497, 1498, 1759, 1770], "box": [12, 23, 34, 49, 971, 1728, 1753, 1759, 1763], "fulli": [12, 14, 20, 23, 27, 35, 60, 1030, 1246, 1247, 1248, 1250, 1737, 1741, 1764, 1781, 1784], "quantiz": [12, 60, 196, 302, 314, 445, 446, 447, 448, 449, 451, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 759, 890, 919, 920, 1427, 1428, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1736, 1779, 1796, 1799, 1800, 1802, 1803], "parallel_info": [13, 1761], "cppextens": 14, "setuptool": 14, "bare": 14, "buildextens": 14, "ext_modul": 14, "extra_compile_arg": [14, 1776], "cmdclass": 14, "build_ext": 14, "cudaextens": 14, "cuda_extens": 14, "extension_kernel": 14, "cu": 14, "cxx": 14, "nvcc": [14, 38, 838], "o2": 14, "arch": 14, "card": [14, 1776], "visibl": [14, 23, 33, 45, 832, 876, 1251, 1252, 1260, 1261], "ptx": 14, "road": 14, "recompil": [14, 32, 35, 60, 1043, 1768], "cc": [14, 23, 1762], "newest": 14, "torch_cuda_arch_list": 14, "build_my_extens": 14, "7": [14, 20, 21, 23, 29, 34, 37, 60, 236, 289, 291, 293, 297, 444, 485, 531, 579, 589, 601, 613, 659, 660, 751, 753, 771, 774, 779, 785, 789, 793, 888, 900, 902, 903, 906, 921, 944, 945, 948, 951, 955, 983, 993, 1007, 1051, 1055, 1065, 1070, 1072, 1073, 1076, 1077, 1081, 1082, 1086, 1093, 1148, 1149, 1150, 1156, 1157, 1160, 1161, 1163, 1174, 1193, 1238, 1246, 1247, 1271, 1272, 1273, 1274, 1275, 1301, 1314, 1385, 1450, 1455, 1463, 1470, 1595, 1599, 1605, 1615, 1616, 1617, 1624, 1637, 1640, 1642, 1653, 1654, 1662, 1668, 1670, 1671, 1676, 1688, 1690, 1691, 1694, 1696, 1701, 1702, 1705, 1707, 1716, 1725, 1729, 1738, 1742, 1747, 1753, 1754, 1760, 1762, 1764, 1773, 1775, 1777, 1779, 1784, 1793, 1796, 1797, 1798, 1799, 1800], "older": [14, 1762, 1775, 1781], "modestli": [14, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494], "imag": [14, 20, 33, 38, 655, 656, 657, 797, 1156, 1160, 1161, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1197, 1198, 1199, 1214, 1222, 1257, 1262, 1263, 1284, 1301, 1303, 1304, 1312, 1323, 1324, 1326, 1327, 1341, 1342, 1347, 1358, 1414, 1415, 1586, 1587, 1613, 1736, 1737, 1739, 1754, 1767, 1779, 1782, 1797, 1798], "pars": [14, 23, 51, 757, 1741, 1781, 1789], "window": [14, 20, 23, 60, 327, 527, 764, 773, 987, 988, 1027, 1049, 1163, 1164, 1165, 1198, 1199, 1218, 1219, 1243, 1244, 1245, 1246, 1247, 1248, 1314, 1342, 1343, 1371, 1372, 1373, 1593, 1594, 1684, 1736, 1739, 1750, 1762], "workaround": [14, 20, 60, 1034, 1735, 1774, 1777, 1784], "pure": [14, 15, 57, 1033, 1738], "sigmoidalphablendforwardcuda": 14, "69460": 14, "facebookresearch": 14, "pytorch3d": 14, "cb170ac024a949f1f9614ffe6af1c38d972f7d48": 14, "relocat": 14, "link": [14, 15, 29, 60, 1178, 1179, 1180, 1181, 1182, 1183, 1197, 1243, 1244, 1245, 1301, 1349, 1753, 1769, 1770, 1793], "refer": [14, 20, 21, 23, 24, 27, 29, 31, 35, 38, 40, 43, 44, 48, 49, 53, 54, 59, 230, 670, 678, 702, 703, 721, 726, 740, 777, 846, 851, 908, 958, 978, 979, 1011, 1018, 1030, 1033, 1041, 1048, 1061, 1082, 1086, 1099, 1102, 1173, 1204, 1250, 1299, 1312, 1320, 1329, 1347, 1414, 1423, 1427, 1428, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1513, 1547, 1548, 1549, 1552, 1553, 1554, 1584, 1595, 1631, 1653, 1689, 1721, 1735, 1736, 1739, 1751, 1752, 1754, 1755, 1758, 1759, 1762, 1763, 1764, 1765, 1766, 1767, 1770, 1772, 1774, 1780, 1785, 1786, 1789, 1790, 1793, 1796, 1797, 1798, 1801], "symbol": [14, 19, 596, 708, 1044, 1098, 1220, 1265, 1709, 1725, 1736, 1741, 1778], "rdc": 14, "dc": 14, "anymor": [14, 23, 53, 198], "dlto": 14, "dlink": 14, "protent": 14, "perf": [14, 35, 1784], "lib": [14, 1776], "nvshmem": 14, "ninja": [14, 1776], "dlink_librari": 14, "dlink_lib": 14, "std": [14, 39, 46, 65, 352, 427, 919, 920, 951, 952, 953, 1471, 1517, 1608, 1647, 1652, 1683, 1719, 1737, 1739, 1752, 1757, 1762, 1769, 1776, 1779], "17": [14, 23, 33, 38, 601, 1027, 1082, 1247, 1662, 1738, 1777, 1793], "mix": [14, 21, 29, 36, 53, 853, 1423, 1736, 1759, 1761, 1784, 1793], "use_ninja": 14, "greatli": [14, 60, 1762], "fallback": [14, 23, 33, 38, 48, 56, 1043, 1093, 1758, 1762], "distutil": 14, "max_job": 14, "extra_cflag": 14, "extra_cuda_cflag": 14, "extra_ldflag": 14, "extra_include_path": 14, "build_directori": 14, "with_cuda": [14, 1776], "is_python_modul": 14, "is_standalon": 14, "keep_intermedi": 14, "torch_extens": 14, "temporari": [14, 34, 60, 1424, 1551, 1554, 1759, 1766], "overridden": [14, 60, 737, 738, 739, 850, 1250, 1741, 1759, 1764, 1773, 1782, 1804], "torch_extensions_dir": 14, "subfold": 14, "o3": 14, "cuh": 14, "Such": [14, 20, 21, 59, 1694, 1722, 1793], "lib64": 14, "cudart": [14, 1776], "fine": [14, 23, 27, 30, 33, 956, 1045, 1423, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1490, 1491, 1492, 1493, 1494, 1583, 1586, 1735, 1751, 1759, 1762, 1764, 1777, 1781, 1782, 1784], "cuda_hom": 14, "safest": 14, "pybind11": [14, 15, 1740], "union": [14, 20, 39, 42, 46, 49, 53, 60, 1041, 1101, 1155, 1156, 1157, 1159, 1160, 1161, 1163, 1164, 1165, 1198, 1199, 1218, 1219, 1243, 1244, 1245, 1250, 1293, 1295, 1297, 1300, 1437, 1476, 1620, 1739, 1740, 1741, 1777, 1781, 1795, 1800, 1803], "linker": 14, "workspac": 14, "header": [14, 46, 1776, 1800], "automat": [14, 21, 23, 33, 34, 38, 48, 49, 60, 127, 561, 737, 739, 844, 853, 992, 1039, 1045, 1131, 1296, 1424, 1607, 1637, 1735, 1736, 1740, 1741, 1748, 1749, 1752, 1753, 1759, 1760, 1762, 1764, 1770, 1772, 1777, 1781, 1782, 1784, 1785, 1789, 1798, 1799, 1801], "construct": [14, 15, 20, 23, 27, 29, 35, 48, 53, 55, 57, 60, 127, 421, 702, 726, 727, 740, 754, 797, 892, 908, 971, 992, 1030, 1041, 1045, 1046, 1053, 1060, 1100, 1101, 1116, 1131, 1193, 1194, 1250, 1418, 1423, 1425, 1426, 1458, 1463, 1513, 1517, 1552, 1629, 1670, 1671, 1672, 1673, 1674, 1675, 1689, 1700, 1703, 1728, 1736, 1738, 1750, 1762, 1763, 1770, 1772, 1775, 1781, 1784, 1789, 1791, 1796, 1798, 1799, 1800], "plain": [14, 1167, 1251, 1260, 1432, 1672, 1764, 1793], "standalon": [14, 47, 48, 49, 708, 1041, 1045, 1738], "torch_lib_path": 14, "load_inlin": 14, "cpp_sourc": 14, "cuda_sourc": 14, "with_pytorch_error_handl": 14, "behav": [14, 15, 23, 59, 60, 289, 297, 465, 487, 489, 970, 1045, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1569, 1740, 1741, 1747, 1759, 1765, 1770, 1774, 1781, 1789, 1793], "exactli": [14, 21, 23, 29, 35, 50, 755, 756, 789, 820, 824, 905, 951, 952, 1027, 1030, 1071, 1194, 1197, 1250, 1278, 1281, 1339, 1349, 1423, 1470, 1747, 1752, 1759, 1762, 1763, 1764, 1767, 1768, 1777, 1781, 1782], "filenam": [14, 20, 34, 60, 1029, 1037, 1040, 1735, 1739, 1749, 1759, 1781, 1795, 1798], "typic": [14, 20, 21, 23, 29, 30, 38, 39, 41, 48, 49, 50, 53, 60, 807, 809, 948, 956, 1030, 1050, 1053, 1184, 1210, 1250, 1418, 1423, 1670, 1671, 1672, 1674, 1675, 1735, 1736, 1738, 1741, 1759, 1761, 1762, 1773, 1774, 1775, 1777, 1780, 1782, 1784, 1789, 1797, 1805], "concaten": [14, 20, 23, 750, 782, 793, 822, 904, 995, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1194, 1220, 1331, 1339, 1429, 1437, 1681, 1730, 1739, 1742, 1777, 1779, 1793], "furthermor": [14, 46, 1065, 1066, 1093, 1119, 1188, 1752, 1753, 1774, 1787, 1789], "cuda_runtim": 14, "se": 14, "warn": [14, 17, 21, 23, 27, 33, 35, 38, 53, 748, 754, 785, 866, 880, 883, 971, 1011, 1045, 1087, 1131, 1434, 1437, 1631, 1639, 1721, 1728, 1735, 1750, 1760, 1764, 1779, 1781, 1788], "macro": [14, 1768], "pybind": 14, "_safe_foo": 14, "redirect": [14, 39, 46], "obscur": 14, "sin_add": 14, "sin": [14, 31, 34, 57, 58, 503, 729, 795, 850, 963, 965, 966, 967, 970, 988, 1081, 1131, 1517, 1645, 1651, 1737, 1739, 1752, 1779, 1793, 1794, 1798], "inline_extens": 14, "include_path": 14, "get_compiler_abi_compatibility_and_vers": 14, "abi": [14, 15], "alongsid": [14, 35, 1030, 1250], "shell": 14, "torchvers": 14, "verify_ninja_avail": 14, "is_ninja_avail": 14, "embed": [15, 60, 660, 742, 896, 1158, 1184, 1194, 1210, 1222, 1256, 1299, 1339, 1428, 1627, 1739, 1761, 1779, 1784, 1786, 1789, 1793, 1798], "modif": [15, 33, 34, 53, 60, 198, 694, 744, 957, 958, 1030, 1250, 1423, 1764, 1770, 1781, 1784], "submodul": [15, 53, 60, 969, 1030, 1034, 1040, 1041, 1187, 1250, 1251, 1252, 1278, 1528, 1529, 1546, 1566, 1567, 1568, 1583, 1586, 1587, 1738, 1740, 1741, 1748, 1770, 1775, 1781, 1784, 1789, 1803], "preprocess": [15, 468, 1030], "augment": [15, 1742, 1800], "walk": [15, 38, 60, 1745, 1764, 1781, 1790, 1791, 1797], "interfac": [15, 21, 30, 40, 45, 48, 628, 629, 630, 631, 632, 633, 634, 635, 636, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 659, 660, 670, 675, 676, 677, 678, 679, 958, 1418, 1631, 1684, 1721, 1737, 1741, 1750, 1764, 1769, 1778, 1780, 1787, 1793, 1798], "opencv": [15, 1347, 1358], "struct": [15, 970, 971, 1728, 1748, 1769], "explain": [15, 23, 33, 38, 1735, 1741, 1758, 1762, 1765], "reshap": [15, 23, 29, 34, 470, 471, 485, 515, 589, 608, 793, 888, 903, 904, 944, 993, 1050, 1082, 1086, 1095, 1096, 1099, 1150, 1197, 1271, 1272, 1273, 1274, 1275, 1301, 1433, 1464, 1470, 1668, 1669, 1676, 1701, 1702, 1707, 1729, 1730, 1737, 1739, 1747, 1753, 1754, 1777, 1779, 1786, 1797, 1798], "classat_1_1_tensor": 15, "tensor_index": 15, "crucial": [15, 34, 35, 1745], "cpp_autograd": 15, "workflow": [15, 1735, 1764, 1784, 1785], "undesir": [15, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1764], "overview": [15, 23, 45, 1423, 1736, 1747, 1751, 1759, 1767, 1770, 1782, 1784, 1789], "cpp_frontend": 15, "library_root": 15, "libtorch": 15, "linux": [15, 23, 37, 1735], "gcc": 15, "pre": [15, 23, 27, 37, 53, 60, 754, 1030, 1250, 1421, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1490, 1491, 1492, 1493, 1494, 1496, 1502, 1735, 1738, 1741, 1748, 1761, 1770, 1777, 1782, 1799], "cxx11": 15, "introduc": [17, 29, 33, 38, 57, 674, 1102, 1202, 1220, 1265, 1358, 1615, 1735, 1741, 1760, 1763, 1771, 1777, 1781, 1782, 1783, 1789, 1799], "ran": [17, 33, 38], "race": [17, 1759], "enable_cuda_sanit": 17, "torch_cuda_sanit": 17, "concurr": [17, 23, 27, 1761, 1762, 1789, 1790], "uniniti": [17, 418, 471, 906, 907, 1418, 1425, 1426, 1463, 1779], "overwrit": [17, 20, 23, 60, 1251, 1260, 1741, 1759], "commandlin": 17, "example_error": 17, "csan": 17, "pointer": [17, 116, 825, 1266, 1762, 1763, 1769, 1789, 1791], "139719969079296": 17, "94646435460352": 17, "_sanit": 17, "364": 17, "_handle_kernel_launch": 17, "stack_trac": [17, 60], "stacksummari": 17, "10000": [17, 21, 34, 610, 1505, 1617, 1766, 1770, 1793, 1798], "420": 17, "_handle_memory_alloc": 17, "incorrectli": [17, 812, 950], "id": [17, 20, 23, 27, 35, 39, 48, 49, 53, 60, 688, 809, 843, 1289, 1373, 1411, 1423, 1552, 1741, 1769, 1778, 1779, 1781, 1788, 1789, 1790, 1795], "faulti": [17, 23], "schema": [17, 23, 1737, 1738, 1739, 1741, 1745, 1777], "current_stream": [17, 811, 1736, 1762], "wait_stream": [17, 23, 812, 814, 1762], "default_stream": [17, 23, 1736], "begin": [17, 20, 21, 23, 24, 38, 40, 48, 53, 60, 468, 674, 698, 713, 764, 802, 809, 856, 858, 925, 983, 989, 1050, 1085, 1097, 1165, 1166, 1167, 1184, 1186, 1192, 1202, 1203, 1206, 1207, 1208, 1209, 1210, 1211, 1217, 1220, 1221, 1236, 1241, 1244, 1245, 1257, 1258, 1265, 1268, 1281, 1287, 1292, 1299, 1330, 1351, 1352, 1423, 1432, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493, 1497, 1499, 1505, 1548, 1549, 1637, 1640, 1643, 1684, 1707, 1718, 1731, 1741, 1758, 1759, 1762, 1764, 1767, 1769, 1774, 1777, 1787, 1794], "suspect": [17, 1762], "condit": [18, 20, 57, 60, 589, 592, 596, 610, 674, 749, 755, 756, 1027, 1045, 1059, 1061, 1069, 1075, 1076, 1077, 1088, 1093, 1202, 1220, 1256, 1265, 1297, 1460, 1463, 1709, 1731, 1737, 1738, 1739, 1740, 1742, 1754, 1759, 1764, 1773, 1782, 1798], "cudnn": [18, 19, 674, 1039, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1202, 1220, 1265, 1266, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1632, 1736, 1739, 1762, 1773, 1774], "float16": [18, 21, 53, 273, 602, 605, 674, 763, 775, 957, 1012, 1030, 1124, 1134, 1178, 1179, 1180, 1181, 1182, 1183, 1202, 1203, 1220, 1221, 1237, 1250, 1265, 1480, 1551, 1554, 1578, 1579, 1583, 1617, 1758, 1770, 1784, 1786, 1795, 1796, 1799, 1800, 1805], "v100": [18, 674, 1202, 1220, 1265, 1762], "packedsequ": [18, 674, 1202, 1220, 1265, 1459, 1460, 1461], "rnn": [19, 674, 675, 676, 677, 679, 1202, 1203, 1220, 1221, 1267, 1424, 1427, 1435, 1458, 1583, 1743, 1766, 1770, 1786, 1798], "enforc": [19, 21, 59, 738, 1030, 1220, 1250, 1265, 1741, 1770, 1797], "cuda_launch_block": [19, 1220, 1265, 1762], "colon": [19, 1220, 1265, 1789], "cublas_workspace_config": [19, 1220, 1265, 1721, 1774], "16": [19, 23, 32, 33, 38, 297, 589, 652, 653, 654, 655, 656, 657, 686, 903, 921, 948, 983, 993, 1030, 1041, 1053, 1059, 1065, 1066, 1070, 1086, 1150, 1162, 1164, 1165, 1173, 1174, 1177, 1178, 1179, 1180, 1182, 1183, 1188, 1189, 1190, 1191, 1195, 1198, 1199, 1218, 1219, 1220, 1238, 1243, 1244, 1245, 1247, 1248, 1250, 1257, 1265, 1276, 1293, 1322, 1324, 1325, 1327, 1331, 1342, 1343, 1473, 1520, 1662, 1721, 1725, 1729, 1738, 1742, 1757, 1770, 1773, 1775, 1777, 1779, 1782, 1789, 1793, 1794, 1796, 1798, 1799], "4096": [19, 1220, 1265, 1721, 1762, 1777], "heart": [20, 35], "dataload": [20, 468, 1423, 1498, 1499, 1505, 1762, 1766, 1776, 1780, 1798], "batch_siz": [20, 29, 58, 963, 969, 971, 1256, 1458, 1460, 1461, 1728, 1739, 1765, 1766, 1774, 1777, 1798], "shuffl": [20, 1736, 1798], "batch_sampl": 20, "num_work": [20, 39, 1774, 1776], "drop_last": 20, "timeout": [20, 23, 48, 1751, 1789], "worker_init_fn": [20, 1766, 1774], "prefetch_factor": 20, "persistent_work": 20, "__getitem__": [20, 1721], "__len__": [20, 60, 1739], "protocol": [20, 30, 48, 50, 728, 956, 958, 1620, 1764, 1776, 1777, 1789, 1804], "sampl": [20, 29, 38, 54, 58, 60, 65, 130, 131, 352, 427, 454, 580, 693, 765, 807, 853, 866, 883, 923, 941, 963, 971, 983, 1046, 1119, 1140, 1162, 1166, 1167, 1171, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1186, 1188, 1189, 1190, 1191, 1193, 1194, 1195, 1204, 1210, 1213, 1214, 1215, 1216, 1217, 1235, 1237, 1241, 1242, 1253, 1254, 1255, 1257, 1264, 1268, 1281, 1282, 1289, 1298, 1312, 1319, 1320, 1330, 1332, 1333, 1334, 1335, 1338, 1339, 1340, 1344, 1347, 1349, 1357, 1358, 1359, 1382, 1390, 1423, 1433, 1471, 1498, 1513, 1516, 1595, 1597, 1599, 1601, 1603, 1666, 1682, 1683, 1723, 1724, 1728, 1736, 1750, 1757, 1758, 1762, 1769, 1770, 1781, 1784, 1785, 1798], "idx": [20, 60, 745, 1030, 1158, 1193, 1250, 1433, 1739, 1753], "th": [20, 131, 289, 291, 297, 674, 748, 750, 765, 785, 892, 897, 1004, 1027, 1051, 1069, 1077, 1083, 1119, 1140, 1189, 1190, 1191, 1195, 1202, 1210, 1220, 1265, 1333, 1334, 1335, 1340, 1524, 1684, 1764, 1776, 1794, 1796], "iterabledataset": [20, 1769], "__iter__": [20, 1742], "suitabl": [20, 29, 779, 1049, 1494, 1624, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1773, 1783, 1785, 1798], "improb": 20, "fetch": [20, 59, 60, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1476, 1789], "stream": [20, 23, 33, 39, 46, 53, 59, 127, 459, 740, 754, 809, 810, 811, 812, 815, 816, 817, 824, 827, 828, 842, 848, 879, 882, 1610, 1736, 1739, 1741, 1789], "databas": 20, "remot": [20, 23, 27, 39, 1423, 1782, 1789, 1790], "real": [20, 29, 31, 34, 35, 60, 602, 603, 604, 605, 606, 608, 614, 755, 763, 788, 797, 803, 853, 921, 922, 924, 926, 927, 928, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 1020, 1022, 1023, 1026, 1027, 1050, 1059, 1060, 1061, 1065, 1066, 1067, 1068, 1069, 1072, 1073, 1074, 1079, 1082, 1084, 1086, 1087, 1088, 1089, 1093, 1094, 1098, 1099, 1100, 1110, 1116, 1217, 1259, 1262, 1263, 1299, 1432, 1684, 1688, 1694, 1725, 1726, 1727, 1735, 1736, 1737, 1739, 1741, 1759, 1762, 1779, 1781, 1784, 1789, 1791, 1797, 1799, 1800, 1804], "replica": [20, 21, 23, 27, 46, 1187, 1423, 1763], "duplic": [20, 291, 295, 444, 764, 773, 794, 987, 988, 1030, 1250, 1718, 1719, 1793], "yield": [20, 21, 53, 60, 893, 895, 1030, 1076, 1077, 1250, 1731, 1741, 1742, 1747, 1782, 1784, 1794], "stochast": [20, 29, 1198, 1199, 1342, 1343, 1477, 1479, 1480, 1482, 1493, 1497, 1498, 1736, 1770], "decent": 20, "randomli": [20, 659, 660, 670, 678, 756, 1162, 1188, 1189, 1190, 1191, 1195, 1268, 1332, 1333, 1334, 1335, 1340, 1445, 1769, 1770], "permut": [20, 905, 1076, 1077, 1096, 1119, 1121, 1603, 1736, 1737, 1739, 1753, 1779, 1786, 1797, 1799], "mini": [20, 693, 699, 1168, 1169, 1170, 1193, 1194, 1205, 1210, 1213, 1214, 1215, 1222, 1242, 1253, 1255, 1289, 1298, 1338, 1339, 1358, 1415, 1782], "neither": [20, 23, 743, 746, 888, 948, 1256, 1297, 1470, 1707, 1764, 1773, 1789], "nor": [20, 23, 39, 53, 746, 1065, 1066, 1093, 1256, 1297, 1423, 1470, 1522, 1688, 1764, 1777], "notion": [20, 35, 755, 1168, 1169, 1170, 1213, 1214, 1215, 1289], "collat": 20, "minibatch": [20, 682, 683, 686, 687, 688, 1119, 1158, 1166, 1167, 1184, 1186, 1210, 1216, 1217, 1241, 1242, 1253, 1254, 1255, 1257, 1264, 1281, 1282, 1298, 1302, 1314, 1315, 1316, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1330, 1359, 1371, 1372, 1373, 1382, 1390, 1782], "loader": [20, 1780], "essenti": [20, 23, 39, 60, 1119, 1753, 1762, 1776, 1793], "dummi": [20, 27, 38, 1764, 1804], "infinit": [20, 1022, 1102, 1166, 1173, 1331, 1517, 1764, 1773, 1789], "drop": [20, 35, 58, 60, 853, 1035, 1088, 1093, 1162, 1684, 1738, 1753, 1772], "roughli": [20, 1216, 1763], "dataset_it": 20, "pad": [20, 21, 628, 629, 630, 631, 632, 633, 634, 635, 641, 642, 643, 646, 647, 652, 653, 654, 655, 656, 657, 682, 683, 686, 687, 688, 693, 696, 697, 699, 795, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 1027, 1163, 1164, 1165, 1173, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1193, 1194, 1197, 1226, 1227, 1228, 1229, 1230, 1231, 1243, 1244, 1245, 1246, 1247, 1248, 1253, 1254, 1256, 1271, 1272, 1273, 1274, 1275, 1276, 1296, 1297, 1301, 1305, 1314, 1315, 1316, 1322, 1323, 1324, 1325, 1326, 1327, 1338, 1339, 1341, 1347, 1358, 1371, 1372, 1373, 1374, 1375, 1376, 1414, 1415, 1428, 1459, 1461, 1462, 1593, 1594, 1684, 1736, 1737, 1739, 1754, 1766, 1777, 1779, 1784, 1798], "max": [20, 23, 39, 41, 48, 50, 53, 60, 93, 162, 163, 164, 165, 276, 611, 612, 613, 672, 684, 685, 694, 696, 697, 722, 766, 783, 790, 791, 795, 884, 919, 920, 990, 1041, 1061, 1075, 1082, 1084, 1086, 1087, 1099, 1159, 1160, 1161, 1172, 1173, 1184, 1185, 1194, 1198, 1199, 1204, 1209, 1210, 1218, 1219, 1236, 1238, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1253, 1254, 1255, 1258, 1269, 1270, 1277, 1298, 1299, 1301, 1309, 1310, 1311, 1321, 1329, 1339, 1342, 1343, 1358, 1362, 1371, 1372, 1373, 1383, 1387, 1391, 1393, 1397, 1415, 1429, 1461, 1480, 1481, 1482, 1492, 1497, 1498, 1507, 1534, 1547, 1548, 1549, 1550, 1553, 1593, 1594, 1721, 1737, 1738, 1739, 1747, 1750, 1754, 1760, 1762, 1766, 1779, 1784, 1787, 1805], "length": [20, 21, 23, 29, 33, 38, 236, 289, 291, 297, 327, 407, 408, 555, 674, 740, 754, 794, 824, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 958, 971, 1004, 1027, 1045, 1049, 1149, 1150, 1167, 1168, 1173, 1178, 1187, 1194, 1197, 1202, 1218, 1220, 1256, 1265, 1293, 1301, 1320, 1322, 1323, 1324, 1331, 1339, 1358, 1428, 1458, 1459, 1460, 1461, 1462, 1546, 1595, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1668, 1670, 1671, 1672, 1674, 1675, 1684, 1707, 1728, 1739, 1741, 1747, 1753, 1754, 1760, 1766, 1793, 1800], "certain": [20, 21, 23, 33, 35, 38, 45, 46, 57, 59, 60, 602, 605, 763, 775, 832, 893, 1005, 1027, 1030, 1037, 1101, 1124, 1134, 1178, 1179, 1180, 1181, 1182, 1183, 1203, 1221, 1237, 1250, 1256, 1301, 1348, 1359, 1361, 1428, 1469, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1741, 1747, 1753, 1759, 1760, 1762, 1764, 1769, 1770, 1773, 1777, 1782, 1783, 1789, 1790, 1793], "cheaper": [20, 59], "bulk": 20, "arrai": [20, 39, 421, 674, 727, 728, 766, 784, 803, 807, 905, 949, 957, 958, 966, 967, 1101, 1131, 1197, 1202, 1203, 1220, 1221, 1341, 1548, 1549, 1610, 1617, 1637, 1670, 1671, 1672, 1674, 1675, 1700, 1707, 1715, 1722, 1738, 1742, 1762, 1770, 1793, 1795, 1799, 1800], "untouch": 20, "slightli": [20, 23, 29, 53, 1470, 1513, 1689, 1735, 1762, 1767, 1773, 1781], "default_col": 20, "channel": [20, 56, 445, 446, 447, 693, 699, 919, 1027, 1168, 1169, 1170, 1174, 1178, 1179, 1180, 1181, 1182, 1183, 1188, 1189, 1190, 1191, 1195, 1197, 1205, 1213, 1214, 1215, 1222, 1226, 1227, 1228, 1229, 1230, 1231, 1238, 1258, 1284, 1289, 1301, 1302, 1303, 1304, 1317, 1333, 1334, 1335, 1340, 1357, 1358, 1365, 1391, 1415, 1443, 1444, 1445, 1452, 1453, 1467, 1550, 1553, 1590, 1753, 1755, 1757, 1759, 1784, 1785, 1787, 1798], "class_index": 20, "namedtupl": [20, 60, 743, 884, 885, 975, 1030, 1041, 1051, 1071, 1121, 1127, 1130, 1132, 1135, 1146, 1158, 1250, 1513, 1523, 1662, 1688, 1694, 1704, 1709, 1738, 1740, 1741, 1784], "situat": [20, 29, 33, 34, 50, 60, 803, 1437, 1751, 1764, 1765, 1772, 1773, 1781, 1784, 1791, 1804], "gil": [20, 23, 27, 1759, 1762, 1789], "integ": [20, 23, 29, 48, 265, 418, 420, 422, 516, 531, 537, 601, 602, 603, 604, 605, 606, 680, 681, 699, 701, 713, 763, 764, 773, 784, 802, 812, 814, 829, 835, 836, 864, 900, 903, 905, 906, 948, 949, 950, 951, 952, 953, 958, 959, 963, 964, 965, 966, 967, 973, 987, 988, 991, 992, 993, 1040, 1043, 1052, 1053, 1060, 1071, 1073, 1083, 1102, 1139, 1158, 1173, 1178, 1179, 1180, 1222, 1306, 1307, 1308, 1309, 1310, 1311, 1417, 1458, 1471, 1474, 1501, 1504, 1508, 1513, 1590, 1591, 1597, 1599, 1600, 1601, 1603, 1608, 1617, 1629, 1676, 1685, 1689, 1701, 1702, 1715, 1729, 1733, 1740, 1741, 1742, 1752, 1765, 1767, 1782, 1785, 1787, 1793, 1794, 1796, 1799, 1800, 1805], "among": [20, 21, 23, 27, 29, 48, 820, 821, 824, 992, 1187, 1471, 1741], "descriptor": [20, 1298, 1299, 1742, 1777], "parent": [20, 41, 46, 50, 708, 1250, 1525, 1526, 1751, 1776, 1781, 1791, 1798], "simplest": [20, 33, 35, 39, 60, 1163, 1164, 1165, 1178, 1179, 1180, 1243, 1244, 1245, 1435, 1583, 1763, 1764, 1770, 1784, 1791, 1793], "refcount": [20, 1751, 1772], "panda": 20, "pyarrow": 20, "13246": 20, "enumer": [20, 29, 60, 1030, 1250, 1252, 1261, 1498, 1739, 1740, 1758, 1762, 1776, 1798], "get_worker_info": [20, 1789], "seed": [20, 65, 845, 854, 855, 874, 1006, 1122, 1513, 1595, 1689, 1739, 1766, 1774, 1788], "naiv": [20, 33, 1782], "shut": [20, 1789], "garbag": [20, 1791], "subtleti": [20, 1187, 1764, 1766], "multiprocess": [20, 23, 24, 26, 39, 41, 49, 50, 1187, 1423, 1736, 1753, 1763, 1790], "unix": [20, 46, 810, 1751], "fork": [20, 46, 1048, 1423, 1741, 1761, 1762, 1766, 1769, 1772, 1776, 1788, 1789, 1791], "child": [20, 39, 41, 53, 1030, 1250, 1444, 1528, 1751, 1770, 1776, 1791], "address": [20, 23, 48, 51, 57, 193, 755, 756, 817, 1747, 1751, 1762, 1789, 1790], "maco": [20, 23, 37, 1751, 1771], "spawn": [20, 21, 24, 39, 40, 46, 50, 1033, 1423, 1736, 1758, 1763, 1772, 1776, 1790], "__name__": [20, 21, 23, 40, 41, 49, 1763, 1764, 1772, 1776, 1781, 1790], "__main__": [20, 21, 23, 40, 41, 49, 1760, 1763, 1772, 1776, 1790], "bytecod": [20, 31, 32, 33, 35, 36, 38, 1781], "base_se": 20, "worker_id": [20, 50, 1774], "therebi": [20, 29, 1784], "mandatorili": 20, "faq": [20, 1187, 1461, 1736], "initial_se": [20, 65, 1774, 1788], "host": [20, 23, 39, 41, 47, 48, 49, 50, 173, 186, 552, 575, 725, 1030, 1250, 1423, 1437, 1469, 1762, 1782, 1789, 1790, 1795], "recogn": [20, 795, 1741, 1789, 1793], "simplecustombatch": 20, "transposed_data": 20, "zip": [20, 1735, 1739, 1740, 1749, 1762, 1769, 1793], "tgt": [20, 1293, 1294, 1295], "collate_wrapp": 20, "float32": [20, 21, 38, 243, 552, 589, 728, 797, 919, 920, 957, 977, 979, 1012, 1154, 1167, 1302, 1303, 1304, 1314, 1480, 1517, 1522, 1547, 1548, 1549, 1550, 1553, 1554, 1595, 1599, 1614, 1629, 1630, 1632, 1673, 1726, 1754, 1758, 1762, 1773, 1777, 1786, 1794, 1795, 1796, 1799, 1800, 1805], "tensordataset": 20, "batch_ndx": 20, "is_pin": [20, 1458, 1739, 1752, 1779, 1795], "multiprocessing_context": 20, "pin_memory_devic": 20, "reshuffl": 20, "draw": [20, 131, 765, 1140, 1595, 1798], "mutual": [20, 23, 39, 1256, 1295, 1297, 1428], "subprocess": [20, 23, 46, 48, 50, 1766, 1772], "incomplet": [20, 748, 1743, 1794], "divis": [20, 555, 589, 603, 686, 687, 688, 789, 900, 950, 953, 1040, 1073, 1178, 1179, 1180, 1181, 1182, 1183, 1185, 1205, 1217, 1241, 1259, 1322, 1323, 1324, 1325, 1326, 1327, 1329, 1383, 1608, 1676, 1701, 1741, 1758, 1762], "smaller": [20, 60, 471, 516, 807, 1423, 1507, 1522, 1676, 1694, 1762, 1775, 1781, 1805], "randomsampl": 20, "prefetch": [20, 53], "shutdown": [20, 48, 1789, 1790], "unpickl": [20, 23, 1101, 1781], "practic": [20, 23, 29, 33, 53, 1736, 1738, 1747, 1751, 1753, 1759, 1764, 1767, 1770, 1775, 1781, 1789], "len": [20, 23, 60, 195, 516, 611, 612, 924, 928, 931, 935, 938, 942, 970, 1034, 1096, 1117, 1129, 1145, 1148, 1187, 1385, 1443, 1445, 1461, 1498, 1505, 1673, 1676, 1682, 1683, 1687, 1722, 1723, 1724, 1738, 1739, 1741, 1764, 1779, 1793, 1798], "proper": [20, 39, 59, 60, 896, 1627, 1740, 1759, 1762, 1764, 1776], "guess": 20, "trust": [20, 23, 1101, 1735, 1781], "inaccur": [20, 21], "kwd": 20, "myiterabledataset": 20, "assert": [20, 21, 29, 38, 55, 57, 58, 60, 596, 963, 965, 966, 967, 968, 969, 970, 971, 1028, 1033, 1034, 1039, 1476, 1728, 1740, 1742, 1764, 1765, 1770, 1781, 1784, 1800], "worker_info": 20, "iter_start": 20, "iter_end": 20, "per_work": 20, "ceil": [20, 154, 682, 683, 1163, 1164, 1165, 1218, 1219, 1243, 1244, 1245, 1314, 1315, 1316, 1371, 1372, 1373, 1593, 1594, 1617, 1737, 1739, 1752, 1762, 1779, 1793], "min": [20, 23, 33, 41, 48, 60, 93, 162, 163, 164, 165, 276, 611, 612, 613, 672, 684, 685, 694, 723, 790, 791, 850, 885, 919, 920, 990, 1061, 1075, 1076, 1082, 1086, 1088, 1093, 1099, 1119, 1140, 1172, 1209, 1236, 1238, 1258, 1270, 1277, 1321, 1358, 1362, 1391, 1393, 1397, 1415, 1492, 1497, 1498, 1507, 1511, 1513, 1523, 1534, 1547, 1548, 1549, 1550, 1553, 1688, 1710, 1711, 1712, 1713, 1737, 1739, 1750, 1752, 1777, 1779, 1784, 1787, 1789, 1805], "ds": 20, "mult": 20, "12": [20, 21, 23, 32, 53, 297, 489, 589, 602, 655, 656, 657, 659, 660, 785, 789, 903, 921, 993, 1034, 1049, 1088, 1158, 1174, 1182, 1197, 1198, 1199, 1247, 1262, 1263, 1284, 1293, 1301, 1342, 1343, 1383, 1388, 1389, 1433, 1464, 1512, 1523, 1637, 1652, 1662, 1701, 1717, 1729, 1735, 1738, 1739, 1742, 1747, 1762, 1771, 1775, 1777, 1779, 1793, 1800], "overall_start": 20, "overall_end": 20, "concatdataset": 20, "chaindataset": 20, "chain": [20, 21, 29, 59, 60, 127, 740, 785, 1085, 1194, 1278, 1495, 1508, 1741, 1759, 1762, 1764, 1767, 1770, 1780], "fly": [20, 850, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1759], "_util": 20, "collate_fn_map": 20, "registri": [20, 1736, 1777], "default_collate_fn_map": 20, "insert": [20, 23, 29, 53, 59, 60, 661, 702, 703, 1251, 1252, 1260, 1423, 1586, 1587, 1624, 1627, 1637, 1658, 1681, 1720, 1738, 1748, 1762, 1779, 1784], "collate_tensor_fn": 20, "custom_col": 20, "collate_map": 20, "outer": [20, 607, 748, 905, 963, 967, 970, 976, 1739, 1741, 1779], "unchang": [20, 471, 485, 487, 944, 1030, 1250, 1293, 1428, 1546, 1609, 1679, 1758, 1773, 1784], "byte": [20, 23, 29, 48, 218, 529, 728, 816, 856, 858, 860, 862, 958, 1029, 1101, 1256, 1428, 1476, 1483, 1620, 1740, 1741, 1742, 1752, 1781, 1793, 1795], "k": [20, 23, 29, 35, 38, 49, 60, 262, 329, 478, 485, 487, 489, 562, 589, 674, 788, 892, 905, 961, 972, 992, 1051, 1059, 1061, 1065, 1066, 1067, 1068, 1069, 1070, 1074, 1075, 1076, 1079, 1081, 1088, 1090, 1092, 1093, 1102, 1120, 1124, 1163, 1165, 1171, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1198, 1199, 1202, 1203, 1220, 1221, 1235, 1237, 1238, 1243, 1245, 1256, 1257, 1265, 1267, 1330, 1342, 1343, 1365, 1382, 1432, 1511, 1513, 1523, 1616, 1666, 1667, 1668, 1670, 1671, 1672, 1674, 1675, 1684, 1704, 1709, 1739, 1740, 1757, 1762, 1764, 1776, 1793, 1794, 1796], "v_i": [20, 1069], "v_1": 20, "v_2": 20, "v1_i": 20, "v2_i": 20, "v1_1": 20, "v1_2": 20, "v2_1": 20, "v2_2": 20, "elem": [20, 1739], "isinst": [20, 29, 38, 60, 1017, 1028, 1739, 1741, 1759, 1764, 1770, 1781, 1793], "customtyp": 20, "collate_customtype_fn": 20, "custotyp": 20, "default_convert": 20, "NOT": [20, 23, 39, 48, 49, 50, 60, 769, 1112, 1190, 1423, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1455, 1476, 1759, 1791, 1793], "np": [20, 783, 900, 905, 945, 946, 947, 1387, 1517, 1765, 1774, 1777, 1798, 1799, 1800], "fraction": [20, 29, 33, 876, 948, 954, 1181, 1182, 1183, 1198, 1199, 1256, 1297, 1342, 1343, 1442, 1443, 1445, 1446, 1448, 1451, 1452, 1453, 1454, 1524, 1757], "workerinfo": [20, 1789], "random_split": 20, "floor": [20, 247, 682, 683, 900, 950, 1040, 1163, 1164, 1165, 1218, 1219, 1243, 1244, 1245, 1314, 1315, 1316, 1371, 1372, 1373, 1593, 1594, 1608, 1617, 1684, 1737, 1739, 1741, 1752, 1775, 1779, 1793], "frac": [20, 29, 255, 352, 603, 674, 686, 687, 688, 713, 764, 773, 803, 807, 900, 950, 983, 987, 988, 1049, 1061, 1065, 1066, 1069, 1081, 1093, 1100, 1116, 1158, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1174, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1188, 1197, 1202, 1203, 1204, 1205, 1213, 1214, 1215, 1216, 1218, 1219, 1220, 1221, 1222, 1235, 1237, 1238, 1239, 1240, 1243, 1244, 1245, 1253, 1254, 1255, 1257, 1265, 1267, 1268, 1280, 1282, 1283, 1285, 1286, 1288, 1289, 1290, 1301, 1316, 1322, 1323, 1324, 1325, 1326, 1327, 1367, 1383, 1385, 1387, 1398, 1402, 1404, 1406, 1407, 1478, 1479, 1482, 1484, 1490, 1497, 1498, 1592, 1604, 1607, 1619, 1640, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1667, 1682, 1683, 1684, 1688, 1707, 1723, 1724, 1739, 1752, 1757, 1759, 1767, 1779, 1794], "remaind": [20, 32, 462, 953, 983, 1737, 1739, 1779], "robin": [20, 23], "generator1": 20, "manual_se": [20, 57, 65, 1739, 1752, 1770, 1774, 1779, 1788], "42": [20, 32, 773, 1139, 1552, 1644, 1762, 1770], "generator2": 20, "30": [20, 23, 29, 32, 39, 48, 418, 589, 636, 644, 645, 670, 678, 983, 1052, 1171, 1173, 1177, 1237, 1301, 1322, 1331, 1418, 1501, 1503, 1509, 1591, 1697, 1764, 1777, 1780, 1789], "data_sourc": 20, "sequentialsampl": 20, "num_sampl": [20, 395, 1140, 1739], "drawn": [20, 150, 234, 262, 1140, 1471, 1595, 1599, 1600, 1757, 1800, 1801], "subsetrandomsampl": 20, "weightedrandomsampl": 20, "probabl": [20, 33, 131, 674, 765, 991, 1107, 1140, 1158, 1162, 1166, 1173, 1186, 1188, 1189, 1190, 1191, 1195, 1202, 1204, 1220, 1256, 1257, 1265, 1319, 1330, 1331, 1332, 1333, 1334, 1335, 1340, 1349, 1359, 1382, 1523, 1751, 1764, 1776, 1777, 1794, 1798], "row": [20, 21, 29, 185, 289, 291, 297, 557, 560, 609, 615, 725, 748, 750, 783, 803, 807, 888, 918, 946, 947, 967, 971, 992, 1051, 1077, 1085, 1088, 1093, 1117, 1119, 1127, 1129, 1130, 1132, 1135, 1140, 1146, 1147, 1148, 1338, 1339, 1387, 1432, 1469, 1521, 1524, 1609, 1668, 1669, 1670, 1671, 1672, 1674, 1675, 1687, 1704, 1707, 1711, 1713, 1722, 1728, 1730, 1739, 1767, 1793, 1798], "05": [20, 27, 60, 90, 320, 610, 628, 629, 630, 631, 632, 633, 639, 640, 650, 651, 663, 665, 666, 667, 668, 755, 756, 787, 919, 1019, 1045, 1046, 1116, 1168, 1169, 1170, 1205, 1213, 1214, 1215, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1289, 1293, 1295, 1297, 1317, 1348, 1357, 1361, 1423, 1496, 1502, 1503, 1509, 1646, 1647, 1652, 1738, 1739, 1780, 1790, 1800], "batchsampl": 20, "distributedsampl": [20, 1423], "num_replica": 20, "world_siz": [20, 21, 23, 24, 27, 39, 48, 49, 51, 53, 1423, 1763, 1782, 1789, 1790], "evenli": [20, 555, 611, 612, 903, 993, 1100, 1116, 1729], "set_epoch": 20, "is_distribut": [20, 1739, 1779], "start_epoch": 20, "n_epoch": 20, "vanilla": [21, 1747], "allreduc": [21, 23, 1423, 1762, 1763, 1779], "besid": [21, 23, 1762, 1763, 1798], "register_comm_hook": [21, 27, 53, 1423], "mainli": [21, 29, 1173, 1331, 1555, 1802], "bucket": [21, 27, 33, 38, 1158, 1423, 1739, 1763, 1779], "gradbucket": [21, 1423], "flatten": [21, 53, 60, 722, 723, 894, 992, 1086, 1099, 1301, 1470, 1524, 1605, 1610, 1615, 1717, 1718, 1719, 1739, 1752, 1753, 1757, 1777, 1779, 1786, 1797], "decompos": [21, 60, 955, 962, 1074, 1737, 1759, 1777], "get_per_parameter_tensor": 21, "wise": [21, 23, 29, 603, 604, 614, 672, 684, 685, 694, 698, 732, 801, 905, 910, 951, 952, 973, 974, 986, 995, 1052, 1054, 1111, 1112, 1113, 1114, 1118, 1128, 1131, 1133, 1151, 1172, 1183, 1190, 1192, 1206, 1207, 1208, 1209, 1211, 1236, 1239, 1249, 1258, 1268, 1269, 1270, 1277, 1279, 1280, 1281, 1286, 1288, 1290, 1291, 1321, 1336, 1345, 1346, 1350, 1351, 1352, 1353, 1356, 1360, 1362, 1367, 1377, 1378, 1391, 1392, 1393, 1397, 1398, 1399, 1400, 1404, 1406, 1407, 1408, 1668, 1730, 1761, 1764, 1793, 1794, 1797], "_distributed_c10d": [21, 23], "1d": [21, 29, 618, 621, 652, 655, 686, 696, 794, 803, 807, 888, 902, 991, 992, 1007, 1085, 1086, 1131, 1147, 1155, 1159, 1163, 1173, 1178, 1181, 1186, 1189, 1190, 1194, 1218, 1242, 1243, 1255, 1257, 1302, 1306, 1309, 1312, 1314, 1322, 1325, 1333, 1339, 1368, 1371, 1524, 1590, 1593, 1707, 1725], "is_last": 21, "set_buff": 21, "stateless": [21, 57, 1755, 1770], "ddp_comm_hook": [21, 27], "default_hook": 21, "allreduce_hook": 21, "process_group": [21, 24, 27, 53, 1289, 1423], "aggreg": [21, 23, 33, 38, 41, 53, 1194, 1339, 1423, 1448, 1750, 1782], "henc": [21, 27, 39, 47, 48, 51, 53, 59, 765, 958, 1246, 1247, 1248, 1302, 1673, 1754, 1759, 1762, 1763, 1789, 1791], "purpos": [21, 23, 34, 35, 38, 60, 444, 471, 755, 1039, 1124, 1173, 1256, 1420, 1421, 1422, 1637, 1750, 1754, 1759, 1781, 1790], "unaffect": [21, 471, 472, 1204], "ddp_model": [21, 23, 1423, 1763], "fp16_compress_hook": 21, "compress": [21, 53, 185, 559, 560, 927, 928, 937, 938, 1423, 1670, 1671, 1672, 1674, 1675, 1706, 1736], "decompress": [21, 1735, 1749], "bf16_compress_hook": 21, "nccl": [21, 24, 49, 53, 1423, 1768], "brain": [21, 1796, 1799], "wrapper": [21, 23, 29, 53, 59, 60, 596, 671, 809, 811, 812, 814, 879, 881, 951, 952, 969, 1030, 1187, 1527, 1552, 1738, 1740, 1741, 1750, 1751, 1762, 1763, 1777, 1782], "fp16_compress_wrapp": 21, "powersgdst": 21, "matrix_approximation_rank": 21, "start_powersgd_it": 21, "powersgd_hook": 21, "bf16_compress_wrapp": 21, "wikipedia": [21, 1384, 1759, 1767, 1805], "wiki": [21, 1805], "bfloat16_float": 21, "point_format": 21, "vogel": 21, "et": [21, 29, 53, 1173, 1262, 1263, 1298, 1299, 1493, 1653, 1689, 1757], "al": [21, 29, 53, 1173, 1262, 1263, 1298, 1299, 1493, 1653, 1689, 1757], "neurip": [21, 29], "2019": [21, 29, 864], "bandwidth": [21, 23, 34, 47, 49, 1784, 1789], "hyperparamet": [21, 60, 1798], "1000": [21, 920, 925, 951, 952, 1158, 1193, 1299, 1590, 1617, 1637, 1700, 1759, 1775, 1777, 1798], "min_compression_r": 21, "use_error_feedback": 21, "warm_start": 21, "orthogonalization_epsilon": 21, "random_se": 21, "compression_stats_logging_frequ": 21, "batch_tensors_with_same_shap": 21, "tune": [21, 23, 27, 33, 38, 795, 864, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1490, 1491, 1492, 1493, 1494, 1759, 1762, 1771, 1784], "stronger": 21, "threshold": [21, 60, 795, 1084, 1087, 1211, 1281, 1286, 1404, 1410, 1507, 1637, 1739, 1758, 1762, 1779, 1798], "exponenti": [21, 234, 915, 1081, 1107, 1108, 1109, 1117, 1172, 1192, 1336, 1736, 1741, 1779, 1780, 1794, 1801], "grid": [21, 925, 1131, 1312, 1347, 1737, 1739, 1762, 1798], "satisfactori": 21, "nlp": [21, 33, 1213, 1214, 1215, 1222], "appendix": [21, 1736], "defer": [21, 53, 1762, 1782], "hybrid": [21, 53, 195, 514, 994], "scheme": [21, 48, 451, 1534, 1547, 1548, 1549, 1550, 1553, 1555, 1770], "sensit": [21, 1211, 1281, 1777, 1781, 1790], "suboptim": [21, 34], "trajectori": 21, "irrecover": 21, "impact": [21, 23, 33, 38, 864, 1632, 1748, 1750, 1759, 1784, 1797], "warm": [21, 27, 33, 853, 1497, 1498, 1762, 1783], "num_row": 21, "num_col": 21, "1e": [21, 60, 90, 320, 610, 628, 629, 630, 631, 632, 633, 639, 640, 650, 651, 663, 665, 666, 667, 668, 669, 755, 756, 786, 787, 1019, 1045, 1046, 1096, 1168, 1169, 1170, 1185, 1204, 1205, 1213, 1214, 1215, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1236, 1259, 1264, 1289, 1293, 1295, 1297, 1298, 1317, 1329, 1344, 1348, 1349, 1357, 1361, 1383, 1386, 1390, 1412, 1433, 1464, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1494, 1507, 1515, 1633, 1738, 1739, 1764, 1770, 1780, 1794, 1800], "orthogon": [21, 1066, 1069, 1088, 1093, 1102, 1511, 1523, 1757, 1759, 1770, 1793], "div": [21, 212, 901, 950, 953, 1158, 1262, 1263, 1608, 1714, 1737, 1739, 1745, 1752, 1779, 1793, 1796], "0s": [21, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494], "batch": [21, 23, 29, 33, 38, 49, 51, 54, 55, 57, 58, 60, 602, 618, 619, 620, 621, 622, 623, 674, 693, 699, 754, 755, 756, 763, 775, 776, 783, 786, 787, 788, 808, 893, 895, 905, 966, 967, 971, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1097, 1098, 1099, 1102, 1110, 1119, 1120, 1124, 1166, 1167, 1168, 1169, 1170, 1173, 1178, 1179, 1184, 1186, 1187, 1189, 1190, 1191, 1193, 1194, 1195, 1197, 1202, 1203, 1204, 1205, 1210, 1211, 1213, 1214, 1215, 1216, 1217, 1220, 1221, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1241, 1242, 1253, 1254, 1255, 1256, 1257, 1259, 1262, 1263, 1264, 1265, 1267, 1281, 1282, 1289, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1301, 1312, 1317, 1319, 1320, 1330, 1331, 1333, 1334, 1335, 1338, 1339, 1340, 1341, 1344, 1357, 1358, 1359, 1382, 1390, 1414, 1415, 1418, 1423, 1428, 1432, 1458, 1459, 1461, 1462, 1498, 1499, 1505, 1511, 1513, 1523, 1592, 1670, 1671, 1672, 1674, 1675, 1679, 1684, 1688, 1689, 1694, 1706, 1709, 1710, 1712, 1725, 1728, 1736, 1752, 1753, 1754, 1758, 1762, 1765, 1766, 1770, 1772, 1782, 1784, 1789, 1793, 1798, 1799], "epsilon": [21, 60, 713, 1084, 1087, 1168, 1169, 1170, 1185, 1205, 1213, 1214, 1215, 1222, 1259, 1289, 1329, 1383, 1433, 1464, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1547, 1548, 1549, 1550, 1553, 1592, 1739, 1794], "bucket_cap_mb": [21, 1423, 1763], "footprint": [21, 1423, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1762], "bottleneck": [21, 34, 1736, 1770], "memor": 21, "compens": 21, "apex": 21, "uncompress": [21, 1793], "p": [21, 29, 53, 60, 131, 210, 262, 399, 400, 426, 463, 464, 580, 602, 605, 763, 765, 775, 783, 899, 1050, 1061, 1067, 1068, 1076, 1077, 1119, 1121, 1124, 1134, 1143, 1162, 1188, 1189, 1190, 1191, 1193, 1194, 1195, 1216, 1218, 1219, 1255, 1259, 1261, 1298, 1299, 1313, 1332, 1333, 1334, 1335, 1338, 1339, 1340, 1368, 1369, 1379, 1383, 1386, 1387, 1412, 1429, 1435, 1437, 1443, 1452, 1470, 1493, 1609, 1665, 1737, 1739, 1740, 1758, 1759, 1762, 1767, 1772, 1783, 1793, 1794], "pq": 21, "ps": [21, 1766], "mq": [21, 1784, 1803], "qs": 21, "tp": 21, "speedup": [21, 34, 35, 1256, 1297], "awai": [21, 60, 1347, 1736, 1753, 1759, 1765], "config": [21, 32, 33, 34, 35, 38, 53, 60, 702, 703, 704, 1584, 1586, 1763, 1776, 1787], "comm": [21, 23, 1763], "handler": [21, 23, 41, 42, 1444, 1750, 1769, 1781, 1804], "batched_powersgd_hook": 21, "destroi": [21, 48, 1187, 1759, 1789], "squar": [21, 29, 522, 653, 654, 655, 656, 693, 699, 807, 892, 894, 1027, 1061, 1063, 1065, 1066, 1067, 1070, 1071, 1075, 1077, 1079, 1081, 1083, 1087, 1089, 1090, 1092, 1093, 1097, 1110, 1119, 1156, 1160, 1164, 1165, 1179, 1180, 1182, 1183, 1198, 1199, 1211, 1219, 1241, 1244, 1245, 1248, 1281, 1293, 1314, 1323, 1326, 1342, 1343, 1347, 1356, 1358, 1378, 1400, 1415, 1432, 1478, 1480, 1481, 1482, 1484, 1490, 1491, 1494, 1619, 1677, 1709, 1722, 1739, 1779, 1793], "truncat": [21, 950, 1715, 1754, 1757, 1766, 1773], "impli": [21, 48, 1751, 1759, 1777, 1782, 1787, 1789], "debugging_hook": 21, "noop_hook": 21, "noop": [21, 1423], "headroom": 21, "desynchron": [21, 23], "trainer": [21, 39, 41, 46, 49, 50, 1423, 1789], "restart": [21, 32, 39, 47, 49, 51, 1497, 1498, 1751, 1798], "__setstate__": 21, "__getstate__": 21, "reload": [21, 27, 1735], "os": [21, 23, 24, 38, 49, 50, 51, 60, 1101, 1423, 1620, 1735, 1751, 1759, 1762, 1763, 1776, 1781, 1782, 1789], "sy": [21, 40, 49, 51, 1735, 1762, 1781], "tempfil": 21, "simplemodel": 21, "24": [21, 23, 29, 32, 768, 1088, 1238, 1312, 1463, 1523, 1702, 1738, 1757, 1761, 1794], "fc2": [21, 1418, 1782], "master_addr": [21, 23, 39, 49, 51, 1763, 1782, 1789, 1790], "localhost": [21, 23, 48, 49, 1763, 1782, 1789, 1790], "master_port": [21, 23, 39, 49, 51, 1763, 1782, 1789, 1790], "12355": 21, "init_process_group": [21, 23, 24, 27, 39, 49, 51, 1423, 1762, 1763, 1789], "cleanup": 21, "destroy_process_group": 21, "run_demo": 21, "demo_fn": 21, "mp": [21, 23, 24, 50, 1423, 1736, 1763, 1772, 1784, 1790, 1795, 1796, 1803], "nproc": [21, 23, 46, 1751, 1763, 1790], "demo_seri": 21, "gettempdir": 21, "device_id": [21, 23, 24, 27, 49, 53, 1101, 1187, 1289, 1411, 1423, 1763], "powersgd_st": 21, "lr": [21, 24, 27, 53, 1418, 1423, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1762, 1763, 1770, 1780, 1790, 1798], "001": [21, 755, 756, 1039, 1480, 1481, 1490, 1494, 1506, 1763], "comm_hook": 21, "comm_hook_st": 21, "hook_stat": 21, "barrier": [21, 39, 48, 1779], "map_loc": [21, 1034, 1037, 1101, 1423, 1735, 1749, 1781], "n_gpu": 21, "device_count": [21, 23, 1736], "got": [21, 23, 739, 1764], "thank": [21, 29, 1764, 1782], "author": [21, 32, 34, 38, 48, 49, 971, 1490, 1595, 1728, 1758], "thij": 21, "par": 21, "home": [22, 1762], "brief": [23, 1423, 1751, 1789], "introduct": [23, 29, 842, 1423, 1736, 1738, 1742, 1752, 1760, 1770, 1777, 1789, 1793, 1798], "mpi": [23, 1423], "gloo": [23, 49, 1423, 1763, 1768, 1789], "recv": [23, 1423, 1779, 1790], "broadcast": [23, 27, 29, 33, 53, 57, 74, 173, 373, 375, 377, 485, 487, 489, 537, 601, 602, 603, 604, 605, 606, 607, 613, 732, 763, 768, 771, 775, 776, 777, 778, 802, 821, 899, 900, 905, 910, 950, 951, 952, 953, 972, 974, 986, 996, 1054, 1055, 1062, 1075, 1079, 1084, 1085, 1087, 1090, 1098, 1118, 1123, 1124, 1134, 1139, 1142, 1151, 1154, 1185, 1204, 1256, 1329, 1391, 1423, 1428, 1512, 1520, 1608, 1610, 1685, 1702, 1707, 1731, 1736, 1737, 1741, 1752, 1753, 1754, 1763, 1777, 1779, 1794], "all_reduc": [23, 50, 1423], "all_gath": 23, "scatter": [23, 27, 53, 485, 487, 489, 1187, 1739, 1766, 1779, 1789], "reduce_scatt": [23, 1779], "all_to_al": 23, "v1": [23, 53, 1098, 1512, 1735, 1763, 1789], "init_method": [23, 1423, 1789], "adher": [23, 1741], "some_fil": 23, "machine_nam": 23, "share_folder_nam": 23, "tcpstore": [23, 48], "past": [23, 34, 60, 866, 883, 1423, 1766], "ask": [23, 57, 1735, 1736, 1765, 1767], "infiniband": [23, 1423, 1789], "interconnect": 23, "gpudirect": 23, "ethernet": 23, "node": [23, 27, 33, 38, 39, 41, 47, 48, 53, 60, 62, 63, 853, 1044, 1173, 1187, 1423, 1547, 1548, 1549, 1552, 1553, 1554, 1748, 1762, 1777, 1778, 1781, 1782, 1789, 1790, 1791, 1803], "encount": [23, 31, 33, 35, 38, 57, 59, 60, 1423, 1738, 1741, 1743, 1761, 1773, 1781, 1784], "ip": [23, 48], "ib": 23, "upcom": [23, 33, 38, 53, 1758], "nccl_socket_ifnam": 23, "eth0": 23, "gloo_socket_ifnam": 23, "comma": [23, 905, 1741], "eth1": 23, "eth2": 23, "eth3": 23, "imper": 23, "nccl_debug": 23, "info": [23, 32, 33, 38, 39, 42, 46, 811, 812, 814, 1060, 1071, 1073, 1074, 1078, 1091, 1119, 1476, 1736, 1739, 1763, 1764, 1765, 1781], "nccl_debug_subsi": 23, "coll": 23, "hang": [23, 24, 27, 1423, 1763], "topolog": [23, 39, 60, 1777], "effort": [23, 1789], "socket": [23, 1751, 1789], "nccl_socket_nthread": 23, "nccl_nsocks_perthread": 23, "cloud": [23, 1793, 1798], "aw": [23, 40, 807], "gcp": 23, "primit": [23, 27, 48, 1101, 1737, 1738, 1740, 1742, 1761, 1771, 1777, 1789], "kind": [23, 35, 42, 60, 1049, 1424, 1522, 1652, 1735, 1745, 1764, 1772, 1781, 1784, 1794, 1796], "connect": [23, 39, 48, 1178, 1179, 1180, 1181, 1182, 1183, 1226, 1227, 1228, 1229, 1230, 1231, 1278, 1751, 1789], "advantag": [23, 48, 49, 1167, 1211, 1763, 1766, 1789, 1793], "redund": [23, 53, 921, 922, 924, 926, 940, 942, 1684], "averag": [23, 27, 680, 681, 682, 683, 759, 761, 807, 1030, 1155, 1156, 1157, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1184, 1186, 1194, 1204, 1210, 1216, 1217, 1218, 1219, 1223, 1224, 1225, 1241, 1242, 1250, 1253, 1254, 1255, 1256, 1257, 1264, 1281, 1282, 1289, 1298, 1306, 1307, 1308, 1314, 1315, 1316, 1319, 1320, 1330, 1344, 1359, 1368, 1369, 1382, 1390, 1423, 1428, 1477, 1478, 1480, 1481, 1482, 1484, 1490, 1491, 1494, 1549, 1550, 1707, 1736, 1763, 1783], "elimin": [23, 34, 60, 582, 1718, 1719, 1774], "thrash": 23, "recurr": [23, 674, 675, 1045, 1173, 1187, 1202, 1203, 1220, 1265, 1435, 1461, 1491, 1736, 1762], "use_distribut": 23, "datetim": [23, 1750], "timedelta": [23, 48, 1750], "1800": 23, "group_nam": [23, 45], "pg_option": 23, "url": [23, 37, 48, 758, 1735, 1749, 1789], "discov": [23, 1789], "encod": [23, 39, 45, 48, 60, 1077, 1101, 1166, 1167, 1293, 1294, 1295, 1296, 1297, 1423, 1670, 1671, 1672, 1674, 1675, 1738, 1741, 1742, 1764, 1775, 1781, 1790, 1793], "ucc": 23, "lowercas": 23, "deadlock": [23, 1423], "job": [23, 39, 41, 42, 44, 45, 47, 48, 49, 50, 1423, 1499, 1505, 1769, 1783, 1798], "exchang": [23, 48, 812, 893, 1762, 1777], "nccl_blocking_wait": 23, "nccl_async_error_handl": [23, 1762], "throw": [23, 24, 33, 34, 38, 53, 59, 60, 167, 299, 304, 516, 586, 1015, 1030, 1070, 1119, 1250, 1423, 1425, 1426, 1461, 1470, 1519, 1721, 1754, 1759, 1774, 1789, 1799], "abort": [23, 1762], "crash": [23, 41, 48, 1751, 1759, 1789, 1791, 1798], "caught": [23, 1423, 1751], "littl": [23, 35, 1764, 1791], "watch": 23, "dog": 23, "deprec": [23, 39, 48, 49, 53, 381, 528, 575, 699, 700, 701, 703, 754, 785, 786, 857, 861, 976, 1030, 1084, 1087, 1119, 1120, 1166, 1167, 1184, 1186, 1209, 1210, 1216, 1217, 1241, 1242, 1250, 1253, 1254, 1255, 1257, 1264, 1281, 1282, 1298, 1303, 1304, 1319, 1320, 1330, 1359, 1382, 1390, 1415, 1416, 1417, 1419, 1423, 1464, 1470, 1523, 1554, 1604, 1684, 1688, 1694, 1709, 1736, 1738, 1743, 1751, 1760, 1783, 1795, 1799, 1800], "processgroupopt": 23, "processgroupnccl": [23, 1763], "is_high_priority_stream": 23, "is_initi": [23, 1736], "is_mpi_avail": 23, "is_nccl_avail": 23, "is_gloo_avail": 23, "is_torchelastic_launch": 23, "elast": [23, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 1736], "aka": [23, 759, 1211, 1759, 1796], "torchelast": [23, 26, 39, 40, 41, 42, 45, 47, 48, 49, 50, 51], "torchelastic_run_id": [23, 49], "proxi": [23, 35, 1784], "rendezv": [23, 26, 39, 45, 47, 51, 1763, 1789], "null": [23, 40, 42, 45], "discoveri": [23, 48, 1762, 1781], "reachabl": 23, "multicast": 23, "20": [23, 27, 29, 32, 35, 297, 601, 636, 644, 645, 652, 653, 654, 655, 656, 657, 660, 670, 674, 675, 676, 677, 678, 679, 686, 983, 1028, 1031, 1041, 1052, 1086, 1139, 1162, 1164, 1165, 1167, 1168, 1169, 1170, 1171, 1173, 1177, 1178, 1179, 1180, 1182, 1183, 1188, 1189, 1190, 1191, 1195, 1198, 1199, 1202, 1203, 1205, 1212, 1213, 1214, 1215, 1218, 1219, 1220, 1221, 1222, 1237, 1243, 1244, 1245, 1247, 1248, 1250, 1265, 1267, 1278, 1286, 1289, 1292, 1293, 1294, 1295, 1322, 1324, 1325, 1327, 1331, 1342, 1343, 1349, 1404, 1427, 1432, 1433, 1457, 1464, 1467, 1483, 1498, 1591, 1697, 1738, 1739, 1754, 1763, 1764, 1773, 1780, 1789, 1793], "23456": 23, "clean": [23, 39, 60, 846, 1735, 1751, 1781], "fcntl": 23, "nf": 23, "init": [23, 39, 41, 53, 1030, 1250, 1258, 1277, 1463, 1736, 1741, 1743, 1759, 1764, 1769, 1770], "brand": 23, "succe": [23, 38, 48, 57, 1762, 1764, 1776], "unexpect": [23, 30, 33, 35, 60, 808, 956, 958, 1030, 1250, 1679, 1738, 1759, 1764, 1773], "unsuccess": 23, "mnt": 23, "sharedfil": 23, "port": [23, 39, 47, 48, 49, 1768], "backend_str": 23, "uppercas": 23, "classmethod": [23, 48, 648, 652, 653, 654, 659, 660, 670, 678, 702, 703, 704, 706, 707, 708, 710, 811, 1193, 1194, 1289, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1476, 1552, 1741, 1742, 1764, 1784, 1789, 1795, 1804], "register_backend": [23, 1789], "func": [23, 57, 60, 745, 746, 747, 748, 749, 750, 751, 752, 753, 755, 756, 1005, 1033, 1045, 1046, 1347, 1587, 1728, 1736, 1741, 1758, 1789, 1791, 1804], "extended_api": 23, "instanti": [23, 27, 47, 48, 49, 60, 909, 1005, 1194, 1339, 1434, 1458, 1463, 1468, 1569, 1735, 1738, 1740, 1741, 1762, 1764, 1770, 1795], "3rd": [23, 29, 48, 589, 1507, 1760], "processgroup": [23, 27, 53, 1423], "four": [23, 1075, 1179, 1764, 1767, 1789, 1791], "c10d": [23, 39, 47, 49, 51, 1423, 1763, 1779], "distributedbackendopt": 23, "get_backend": [23, 48], "get_rank": [23, 1289], "uniqu": [23, 39, 45, 48, 49, 50, 485, 489, 1021, 1065, 1066, 1070, 1076, 1077, 1079, 1088, 1090, 1092, 1093, 1130, 1137, 1688, 1719, 1735, 1738, 1749, 1764, 1781, 1783, 1789, 1790, 1791, 1793, 1798], "get_world_s": 23, "filestor": [23, 48], "hashstor": 23, "client": [23, 27, 33, 48, 1781], "host_nam": 23, "hostnam": [23, 39, 48, 1783], "listen": 23, "is_mast": 23, "300": [23, 39, 1107, 1167, 1462, 1780], "wait_for_work": 23, "server_stor": 23, "127": [23, 704, 1537, 1538, 1540, 1541, 1559, 1560, 1573, 1574, 1575, 1576, 1577, 1753, 1784, 1798], "1234": [23, 48, 1007], "client_stor": 23, "first_kei": 23, "first_valu": 23, "underli": [23, 27, 29, 35, 39, 57, 60, 74, 287, 302, 352, 375, 377, 446, 447, 448, 449, 456, 471, 492, 495, 528, 529, 530, 585, 662, 671, 726, 811, 1000, 1004, 1030, 1101, 1149, 1390, 1606, 1706, 1720, 1738, 1741, 1754, 1762, 1766, 1768, 1782, 1789, 1797], "hashmap": 23, "file_nam": [23, 1735, 1749, 1781], "store1": 23, "store2": 23, "prefixstor": 23, "old": [23, 30, 35, 60, 710, 956, 1190, 1475, 1507, 1620, 1734, 1736, 1738, 1759, 1762, 1764, 1776, 1784, 1798], "whose": [23, 29, 38, 53, 60, 515, 742, 785, 802, 893, 905, 910, 958, 974, 983, 986, 992, 1030, 1046, 1054, 1100, 1116, 1118, 1151, 1250, 1423, 1471, 1517, 1584, 1640, 1703, 1741, 1759, 1764, 1767, 1781, 1793, 1798, 1800], "quantiti": [23, 54, 58, 1065, 1066, 1093, 1216, 1442, 1443, 1445, 1446, 1448, 1451, 1452, 1453, 1454, 1507, 1767], "compare_set": 23, "arg2": 23, "expected_valu": 23, "desired_valu": 23, "second_valu": 23, "overload": [23, 60, 589, 1740, 1741, 1745], "bad_kei": 23, "num_kei": 23, "written": [23, 34, 38, 41, 57, 758, 866, 1187, 1493, 1738, 1740, 1747, 1748, 1759, 1763, 1764, 1765, 1770, 1775, 1777, 1781, 1795, 1798], "destruct": [23, 1750, 1789, 1791], "delete_kei": 23, "successfulli": [23, 38, 39, 45, 1036, 1633, 1751, 1770, 1775, 1789], "set_timeout": 23, "grain": [23, 1583, 1586, 1759, 1777], "plai": 23, "new_group": [23, 53, 1289], "opaqu": [23, 30, 809, 842, 843, 956], "pattern": [23, 702, 703, 704, 705, 710, 850, 1187, 1461, 1586, 1666, 1738, 1741, 1759, 1762, 1764, 1766, 1768, 1775, 1785, 1786], "enqueu": [23, 59, 812, 814, 815, 1762, 1790], "get_group_rank": 23, "global_rank": [23, 39], "translat": [23, 35, 62, 63, 983, 1759, 1791], "queri": [23, 35, 48, 60, 811, 812, 814, 866, 883, 1030, 1250, 1256, 1428, 1436, 1739, 1762, 1781], "get_global_rank": 23, "group_rank": [23, 39, 49], "get_process_group_rank": 23, "dst": [23, 1735, 1781], "destin": [23, 42, 45, 53, 186, 390, 391, 575, 822, 823, 972, 1030, 1136, 1137, 1250, 1739, 1789, 1790, 1795], "unspecifi": [23, 454, 1283, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1448, 1451, 1452, 1548, 1549, 1550, 1553, 1667, 1747, 1793, 1798], "sender": [23, 1791], "isend": 23, "irecv": 23, "is_complet": 23, "finish": [23, 39, 45, 46, 48, 50, 59, 962, 1762, 1763, 1776, 1783, 1789, 1791], "batch_isend_irecv": 23, "p2p_op_list": 23, "p2pop": 23, "op_list": 23, "send_tensor": 23, "recv_tensor": 23, "send_op": 23, "recv_op": 23, "req": 23, "pg": [23, 1423], "set_devic": [23, 53, 1423, 1628, 1736, 1789, 1796], "p2p": [23, 48], "async_op": 23, "onto": [23, 35, 53, 60, 869, 1037, 1040, 1101, 1437, 1735, 1751, 1762, 1765, 1766, 1770, 1783], "get_futur": [23, 1423], "regard": [23, 1181, 1182, 1183, 1193, 1194, 1338, 1339, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1738, 1791, 1793], "add_": [23, 56, 57, 198, 962, 1739, 1752, 1760, 1793], "101": [23, 1158], "overwrot": 23, "sent": [23, 846, 1741, 1751, 1772, 1789, 1790, 1791], "broadcast_object_list": 23, "object_list": 23, "picklabl": [23, 1030, 1250, 1781], "current_devic": [23, 827, 828, 835, 836, 852, 856, 858, 859, 860, 862, 864, 865, 866, 870, 871, 872, 882, 883, 1736, 1796], "insecur": [23, 1101], "malici": [23, 1101, 1781], "redoptyp": 23, "bitwis": [23, 767, 769, 770, 772, 1742, 1773, 1785], "reduceop": 23, "int64": [23, 168, 185, 289, 297, 368, 713, 766, 779, 906, 919, 920, 957, 1330, 1458, 1599, 1603, 1604, 1624, 1670, 1671, 1672, 1674, 1675, 1762, 1793, 1795, 1796, 1799, 1805], "1j": [23, 614, 800, 801, 1026, 1612, 1613, 1725, 1759, 1767, 1775], "2j": [23, 614, 800, 801, 1612, 1613, 1640, 1725, 1759], "tensor_list": [23, 1754], "all_gather_into_tensor": 23, "output_tensor": 23, "input_tensor": [23, 34], "accommod": [23, 1246, 1247, 1248], "ii": [23, 803, 905, 1220, 1221], "tensor_in": 23, "tensor_out": 23, "tensor_out2": 23, "all_gather_object": 23, "obj": [23, 60, 728, 831, 1016, 1017, 1036, 1041, 1620, 1739, 1776, 1781], "pickabl": 23, "popul": [23, 29, 46, 53, 59, 60, 311, 467, 475, 476, 1130, 1146, 1762], "responsibl": 23, "gather_object": 23, "gather_list": 23, "object_gather_list": 23, "scatter_list": 23, "tensor_s": 23, "t_one": 23, "t_five": 23, "scatter_object_list": 23, "scatter_object_output_list": 23, "scatter_object_input_list": 23, "output_list": 23, "input_list": 23, "reduce_scatter_tensor": 23, "Its": [23, 34, 60, 807, 822, 1030, 1077, 1095, 1096, 1121, 1250, 1470, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1487, 1490, 1491, 1492, 1493, 1494, 1725, 1741, 1763], "all_to_all_singl": 23, "output_split_s": 23, "input_split_s": 23, "cancaten": 23, "dim": [23, 29, 57, 58, 60, 89, 91, 92, 93, 95, 111, 112, 113, 161, 181, 184, 187, 188, 189, 190, 191, 192, 206, 236, 240, 257, 288, 289, 290, 291, 292, 293, 297, 298, 329, 355, 367, 382, 384, 385, 386, 389, 403, 404, 405, 406, 409, 410, 426, 435, 443, 452, 463, 464, 466, 477, 478, 484, 485, 486, 487, 488, 489, 490, 491, 508, 509, 512, 513, 515, 518, 523, 524, 526, 531, 536, 545, 550, 562, 577, 578, 581, 582, 583, 584, 587, 589, 609, 611, 612, 613, 615, 722, 723, 724, 750, 751, 753, 782, 789, 798, 806, 808, 822, 824, 884, 885, 886, 887, 888, 897, 903, 921, 922, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 942, 944, 945, 963, 971, 972, 983, 993, 1001, 1002, 1003, 1004, 1007, 1051, 1061, 1062, 1082, 1086, 1096, 1098, 1099, 1109, 1117, 1127, 1129, 1130, 1132, 1135, 1137, 1138, 1145, 1146, 1147, 1148, 1149, 1150, 1158, 1185, 1186, 1187, 1190, 1194, 1196, 1201, 1216, 1221, 1240, 1256, 1257, 1258, 1283, 1285, 1297, 1299, 1300, 1329, 1330, 1346, 1349, 1358, 1366, 1371, 1372, 1373, 1382, 1383, 1385, 1387, 1391, 1402, 1403, 1411, 1423, 1433, 1439, 1443, 1445, 1452, 1453, 1464, 1467, 1470, 1514, 1521, 1524, 1609, 1610, 1615, 1616, 1621, 1622, 1623, 1626, 1627, 1658, 1661, 1662, 1664, 1667, 1669, 1676, 1679, 1681, 1682, 1683, 1684, 1687, 1697, 1701, 1702, 1703, 1704, 1707, 1708, 1716, 1717, 1718, 1719, 1720, 1723, 1724, 1728, 1729, 1736, 1737, 1738, 1739, 1753, 1754, 1765, 1766, 1775, 1777, 1779, 1793, 1794, 1796, 1802], "13": [23, 32, 38, 723, 789, 903, 906, 950, 983, 993, 1034, 1119, 1174, 1198, 1199, 1247, 1284, 1342, 1343, 1662, 1694, 1701, 1729, 1738, 1742, 1779, 1793], "14": [23, 32, 297, 489, 788, 850, 851, 888, 903, 993, 1082, 1088, 1144, 1174, 1247, 1523, 1595, 1662, 1701, 1702, 1707, 1729, 1738, 1742, 1777, 1779, 1793, 1797, 1798], "15": [23, 60, 589, 903, 973, 983, 993, 1052, 1066, 1174, 1247, 1248, 1462, 1515, 1653, 1662, 1705, 1729, 1738, 1739, 1742, 1777, 1793], "uneven": [23, 24, 27, 1423], "18": [23, 32, 297, 418, 601, 906, 983, 1027, 1102, 1247, 1738, 1777, 1793], "21": [23, 29, 601, 785, 888, 1088, 1523, 1707, 1738, 1793], "22": [23, 29, 32, 297, 589, 1102, 1418, 1462, 1738, 1774, 1793], "23": [23, 38, 485, 1102, 1648, 1738, 1793], "31": [23, 771, 1165, 1245, 1418, 1648, 1777], "33": [23, 652, 653, 654, 655, 656, 657, 686, 1030, 1178, 1179, 1180, 1182, 1183, 1248, 1250, 1322, 1324, 1325, 1327, 1738, 1777], "34": [23, 32, 35, 38], "35": [23, 1088, 1169, 1170, 1214, 1215, 1289, 1523], "36": [23, 32, 35, 297, 948, 983], "input_split": 23, "output_split": 23, "5j": 23, "6j": 23, "7j": 23, "8j": 23, "9j": 23, "10j": 23, "11j": 23, "12j": 23, "13j": 23, "14j": 23, "15j": 23, "16j": 23, "output_tensor_list": 23, "input_tensor_list": 23, "monitored_barri": [23, 1779], "wait_all_rank": 23, "band": 23, "bor": 23, "bxor": 23, "premul_sum": 23, "suppos": [23, 60, 1027, 1508, 1694, 1747, 1793], "_make_nccl_premul_sum": 23, "all_reduce_multigpu": 23, "__members__": 23, "reduce_op": 23, "mention": [23, 35, 38, 53, 1735, 1740, 1741, 1753, 1762, 1770, 1777, 1793, 1797], "revisit": 23, "broadcast_multigpu": 23, "reduce_multigpu": 23, "all_gather_multigpu": 23, "reduce_scatter_multigpu": 23, "distributed_test": 23, "dev_idx": 23, "src_tensor": 23, "resid": [23, 53, 59, 173, 265, 313, 1101, 1423, 1762, 1782, 1789], "dst_tensor": 23, "cpp_extens": [23, 1736, 1764], "cpp_c10d_extens": 23, "torchrun": [23, 26, 40, 47, 51], "benefiti": 23, "nproc_per_nod": [23, 40, 47, 49], "num_gpus_you_hav": 23, "your_training_script": [23, 47, 49], "arg3": 23, "192": [23, 589, 1777], "168": 23, "nnode": [23, 47, 49], "node_rank": 23, "offer": [23, 31, 33, 53, 56, 1423, 1721, 1737, 1762, 1768, 1781, 1793], "local_rank": [23, 39, 41, 46, 49, 51, 1289], "local_process_rank": 23, "argpars": [23, 49, 1762], "parser": [23, 49, 1762], "argumentpars": [23, 49, 1762], "add_argu": [23, 49, 1762], "parse_arg": [23, 40, 49, 51, 1762, 1777], "output_devic": [23, 27, 49, 1187, 1289, 1411, 1423], "use_env": [23, 49, 51], "adjust": [23, 27, 29, 53, 1736, 1761, 1785], "launcher": [23, 49], "filesystem": [23, 810, 1735, 1781], "12042": 23, "wrong": [23, 34, 60, 744, 1028, 1031, 1763, 1772, 1776, 1777, 1780], "imagenet": [23, 1757], "inconsist": [23, 53, 713, 1604, 1764], "suit": [23, 1738, 1740, 1741, 1777, 1785, 1789], "group_gloo": 23, "29501": 23, "monitoredbarri": 23, "ms": [23, 45], "transport": [23, 1789], "598": 23, "2401": 23, "db00": 23, "eef0": 23, "1100": 23, "3560": 23, "1c05": 23, "25d": 23, "8594": 23, "torch_cpp_log_level": 23, "twolinlayernet": 23, "ddp": [23, 24, 27, 33, 53, 1289, 1423, 1736, 1762, 1763, 1789], "i0607": 23, "739390": 23, "515217": 23, "logger": [23, 1802, 1803], "173": 23, "broadcast_buff": [23, 1423], "bucket_cap_byt": 23, "26214400": 23, "find_unused_paramet": [23, 1423, 1763], "gradient_as_bucket_view": [23, 1423], "is_multi_device_modul": 23, "num_parameter_tensor": 23, "total_parameter_size_byt": 23, "440": 23, "backend_nam": 23, "bucket_s": 23, "cuda_visible_devic": [23, 875, 1423, 1762], "module_nam": [23, 60, 708, 710, 1781], "nccl_ib_timeout": 23, "nccl_nthread": 23, "58": 23, "085681": 23, "544067": 23, "344": 23, "unused_parameter_s": 23, "40838608": 23, "5983335": 23, "4326421": 23, "comp": [23, 29], "4207652": 23, "085693": 23, "544066": 23, "42850427": 23, "3885553": 23, "2357981": 23, "2234674": 23, "enhanc": [23, 53, 1423], "unus": [23, 27, 60, 846, 860, 1035, 1041, 1212, 1423, 1738, 1740, 1741, 1762, 1763, 1768, 1781], "constraint": [23, 749, 842, 853, 967, 1423, 1433, 1458, 1736, 1741, 1754, 1765, 1767, 1770, 1793], "went": [23, 33, 60], "wasn": [23, 1101, 1738], "va": 23, "lue": 23, "indirectli": 23, "outstand": [23, 1789], "stuck": [23, 39, 50], "uninform": 23, "root": [23, 33, 37, 41, 48, 49, 53, 60, 703, 1067, 1068, 1491, 1619, 1677, 1748, 1759, 1781, 1789, 1790, 1793], "nontrivi": [23, 1762], "reveal": [23, 1763], "default_pg": 23, "opt": [23, 27, 1041, 1495, 1496, 1502, 1506, 1508, 1738, 1767], "verifi": [23, 34, 60, 755, 888, 1707, 1735, 1738, 1749, 1764, 1767, 1777, 1782], "longtensor": [23, 111, 112, 113, 291, 293, 295, 425, 444, 485, 487, 489, 722, 723, 972, 1004, 1051, 1140, 1193, 1194, 1253, 1338, 1339, 1384, 1469, 1624, 1662, 1673, 1696, 1704, 1731, 1796, 1799], "set_debug_level": 23, "set_debug_level_from_env": 23, "get_debug_level": 23, "torch_show_cpp_stacktrac": 23, "distbackenderror": 23, "thrown": [23, 35, 53, 59, 589, 726, 728, 864, 903, 993, 1030, 1060, 1069, 1071, 1073, 1076, 1077, 1088, 1250, 1429, 1729, 1781], "facilit": [24, 29, 57, 812, 893, 1629, 1735, 1738, 1741, 1774], "outlin": [24, 33, 1782, 1790], "joinabl": [24, 27, 1423], "joinhook": 24, "throw_on_early_termin": [24, 1423], "shadow": [24, 27, 1423, 1802, 1803], "notify_join_context": 24, "zeroredundancyoptim": [24, 27, 1423], "01": [24, 27, 50, 669, 694, 906, 948, 1236, 1362, 1363, 1418, 1477, 1479, 1481, 1491, 1492, 1499, 1505, 1549, 1550, 1590, 1644, 1646, 1647, 1652, 1653, 1737, 1739, 1757, 1769, 1780], "yet": [24, 33, 35, 38, 39, 57, 59, 60, 811, 880, 1033, 1035, 1047, 1135, 1423, 1439, 1443, 1445, 1736, 1740, 1741, 1753, 1754, 1762, 1777, 1779, 1784, 1789, 1791, 1793, 1794, 1796], "vacuou": 24, "inherit": [24, 1450, 1738, 1740, 1754, 1764, 1770, 1772], "join_hook": [24, 27, 1423], "join_devic": 24, "join_process_group": 24, "repeatedli": [24, 1762, 1793], "main_hook": 24, "post_hook": 24, "is_last_join": 24, "fault": [26, 39, 47, 48, 958], "toler": [26, 39, 47, 48, 60, 610, 755, 756, 1019, 1045, 1046, 1084, 1087, 1102, 1483, 1738, 1800], "quickstart": 26, "agent": [26, 40, 41, 42, 45, 47, 49, 50, 1789], "expir": 26, "metric": [26, 33, 856, 858, 864, 1507, 1750, 1770, 1783, 1798], "kubernet": 26, "distributedoptim": [27, 1423, 1789, 1790], "rref": [27, 1423, 1736, 1741, 1782, 1790], "optimizer_class": 27, "params_rref": 27, "get_gradi": [27, 1779, 1789, 1790], "multithread": [27, 762, 1762], "dist_autograd": [27, 1423, 1789, 1790], "rpc": [27, 59, 1423, 1736, 1741, 1782, 1790, 1791], "context_id": [27, 1423, 1789, 1790], "rref1": [27, 1789, 1790], "worker1": [27, 59, 1423, 1789, 1790], "rref2": [27, 1789, 1790], "to_her": [27, 1423, 1779, 1789, 1790, 1791], "dist_optim": [27, 1423, 1790], "postlocalsgdoptim": 27, "afer": 27, "modelaverag": 27, "localsgd": 27, "model_averag": 27, "post_localsgd_hook": 27, "postlocalsgdst": 27, "subgroup": 27, "start_localsgd_it": 27, "warmup_step": 27, "local_optim": 27, "periodicmodelaverag": 27, "intra": [27, 1761, 1763, 1782], "unnecessari": [27, 1463, 1741, 1762, 1764, 1775, 1781, 1797], "parameters_as_bucket_view": 27, "overlap_with_ddp": 27, "peak": [27, 53, 856, 858, 864, 870, 871, 872, 1423, 1499, 1505, 1782], "consumpt": [27, 1468, 1793, 1798], "partit": [27, 33, 1158, 1707, 1779, 1782, 1790, 1791], "registr": [27, 59, 850, 1423, 1434, 1437, 1745, 1781], "offset": [27, 32, 35, 39, 202, 203, 204, 205, 315, 492, 529, 660, 726, 893, 894, 895, 896, 958, 1064, 1194, 1339, 1423, 1590, 1591, 1668, 1711, 1713, 1739, 1741], "intact": [27, 1789], "ddp_zero_hook": 27, "disjointli": 27, "trail": [27, 1460, 1462, 1754, 1757, 1760, 1764], "wari": 27, "static_graph": [27, 1423, 1763], "third": [27, 29, 904, 905, 1119, 1158, 1165, 1180, 1183, 1245, 1505, 1736, 1738, 1762, 1765, 1770, 1781, 1783], "add_param_group": [27, 1437, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494], "param_group": [27, 53, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1487, 1490, 1491, 1492, 1493, 1494, 1501, 1504], "frozen": [27, 1034, 1039, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1490, 1491, 1492, 1493, 1494, 1742, 1776], "trainabl": [27, 853, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1490, 1491, 1492, 1493, 1494, 1764], "consolidate_state_dict": 27, "consolid": [27, 53, 1782], "pertain": 27, "preced": [27, 39, 53, 1421, 1505, 1706, 1742, 1761, 1780, 1784], "parameteriz": 29, "tensorflow": [29, 1491, 1759, 1798], "backpropag": [29, 756, 1492, 1523, 1766], "random": [29, 39, 48, 49, 54, 60, 65, 131, 674, 765, 839, 840, 845, 854, 855, 873, 874, 877, 878, 966, 971, 982, 1006, 1102, 1122, 1162, 1173, 1195, 1202, 1220, 1268, 1340, 1390, 1395, 1418, 1433, 1439, 1445, 1446, 1453, 1454, 1471, 1513, 1595, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1625, 1638, 1689, 1728, 1735, 1736, 1739, 1757, 1765, 1767, 1773, 1777, 1779, 1798], "surrog": 29, "likelihood": [29, 1158, 1204, 1257, 1264, 1344, 1382, 1390], "ratio": [29, 39, 589, 1198, 1199, 1342, 1343, 1739], "reinforc": [29, 1279, 1399], "polici": [29, 39, 41, 53, 1499, 1505], "reparameter": [29, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1455, 1456, 1457, 1467], "trick": [29, 751, 1167, 1349, 1759, 1767, 1769], "autoencod": 29, "whilst": [29, 1762], "densiti": [29, 277, 991, 992, 1653, 1739, 1794], "log_prob": [29, 1158, 1173, 1331, 1739], "theta": [29, 1312, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493, 1739], "alpha": [29, 33, 74, 75, 76, 77, 82, 83, 84, 85, 86, 87, 128, 129, 288, 289, 525, 532, 533, 534, 535, 601, 602, 605, 606, 607, 658, 684, 689, 763, 850, 851, 987, 1001, 1162, 1172, 1192, 1238, 1277, 1313, 1321, 1336, 1337, 1347, 1365, 1397, 1477, 1491, 1649, 1650, 1663, 1666, 1680, 1685, 1686, 1737, 1739, 1759, 1764, 1777], "partial": [29, 34, 39, 48, 53, 56, 60, 853, 895, 970, 983, 1076, 1077, 1078, 1120, 1246, 1247, 1248, 1374, 1375, 1376, 1423, 1444, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1557, 1558, 1559, 1560, 1561, 1563, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1668, 1741, 1742, 1753, 1759, 1764, 1767, 1777, 1791, 1800], "pi": [29, 150, 352, 614, 773, 987, 988, 1081, 1200, 1264, 1345, 1390, 1497, 1498, 1517, 1644, 1645, 1648, 1649, 1650, 1651, 1684, 1740, 1741, 1781, 1794], "reward": 29, "ascent": 29, "prob": [29, 1739], "policy_network": 29, "next_stat": 29, "rsampl": 29, "parameter": [29, 352, 427, 1036, 1755, 1793], "has_rsampl": 29, "batch_shap": 29, "event_shap": 29, "validate_arg": 29, "arg_constraint": 29, "cdf": 29, "cumul": [29, 884, 885, 886, 887, 888, 1109, 1168, 1169, 1170, 1200, 1223, 1224, 1225, 1289, 1345], "mass": 29, "enumerate_support": 29, "discret": [29, 52, 454, 921, 922, 923, 924, 926, 927, 928, 929, 930, 931, 934, 935, 940, 942, 1349, 1653, 1798, 1801], "cardin": [29, 1131], "univari": 29, "singleton": [29, 230, 1222, 1720, 1760], "cartesian": [29, 781, 1131, 1517], "itertool": [29, 781, 794], "_instanc": 29, "icdf": 29, "perplex": 29, "sample_shap": 29, "sample_n": 29, "set_default_validate_arg": 29, "mimic": [29, 1505], "stddev": 29, "varianc": [29, 807, 1168, 1169, 1170, 1195, 1204, 1213, 1214, 1215, 1223, 1224, 1225, 1232, 1233, 1234, 1289, 1340, 1344, 1490, 1491, 1592, 1601, 1602, 1723, 1724, 1757, 1770], "exp_famili": 29, "famili": 29, "p_": [29, 785, 1121, 1493], "langl": 29, "rangl": 29, "denot": [29, 60, 807, 1050, 1069, 1075, 1088, 1098, 1178, 1179, 1216, 1434, 1437, 1493, 1670, 1671, 1672, 1674, 1675, 1725, 1767, 1787, 1790, 1793], "carrier": 29, "analyt": [29, 755, 756, 1793], "bregman": 29, "courtesi": 29, "frank": 29, "nielsen": 29, "richard": 29, "nock": 29, "logit": [29, 366, 1167, 1186, 1320, 1330, 1349, 1739, 1779, 1794], "70": [29, 1088, 1523, 1754], "odd": [29, 926, 927, 928, 936, 937, 938, 1322, 1323, 1324], "lower_bound": 29, "upper_bound": 29, "has_enumerate_support": 29, "param_shap": 29, "concentration1": 29, "concentration0": 29, "concentr": 29, "1046": 29, "1st": [29, 1760], "2nd": [29, 589, 1258, 1284, 1385, 1760], "greaterthan": 29, "total_count": 29, "71": 29, "trial": 29, "integergreaterthan": 29, "ldot": [29, 1061, 1069, 1100, 1116, 1131, 1222, 1243, 1244, 1245, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493], "dimension": [29, 485, 487, 734, 735, 736, 774, 781, 793, 893, 895, 896, 905, 921, 922, 924, 925, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 939, 940, 942, 944, 946, 947, 958, 983, 992, 993, 994, 1062, 1067, 1068, 1069, 1070, 1095, 1100, 1116, 1124, 1131, 1158, 1175, 1176, 1177, 1186, 1187, 1193, 1194, 1222, 1240, 1257, 1271, 1272, 1273, 1274, 1275, 1276, 1283, 1285, 1289, 1305, 1330, 1382, 1385, 1416, 1417, 1432, 1469, 1595, 1670, 1671, 1672, 1673, 1674, 1675, 1684, 1697, 1700, 1701, 1707, 1741, 1754, 1757, 1760, 1767, 1773, 1793, 1795, 1796, 1799, 1801], "unnorm": [29, 1186, 1320, 1330, 1349], "likewis": [29, 1706], "25": [29, 468, 558, 559, 560, 783, 991, 1097, 1102, 1196, 1253, 1255, 1258, 1418, 1423, 1462, 1483, 1505, 1524, 1722, 1738, 1794], "independentconstraint": 29, "simplex": 29, "loc": [29, 1101], "lorentz": 29, "3214": 29, "width": [29, 693, 699, 990, 991, 992, 1164, 1165, 1179, 1180, 1182, 1183, 1219, 1244, 1245, 1257, 1284, 1302, 1358, 1415, 1583, 1753], "df": 29, "chi": 29, "continuous_bernoulli": 29, "lim": [29, 1027], "499": 29, "501": 29, "2538": [29, 1061], "pervas": 29, "loaiza": 29, "ganem": 29, "cunningham": 29, "jp": 29, "arxiv": [29, 1220, 1268, 1269, 1296, 1467, 1513, 1689, 1759], "ab": [29, 31, 32, 33, 35, 38, 67, 68, 598, 783, 905, 1061, 1082, 1083, 1085, 1086, 1099, 1102, 1220, 1269, 1296, 1299, 1301, 1387, 1467, 1470, 1507, 1513, 1517, 1736, 1737, 1739, 1741, 1752, 1753, 1762, 1770, 1779, 1793, 1799], "1907": 29, "06845": 29, "8954": 29, "greaterthaneq": 29, "df1": 29, "df2": 29, "fisher": 29, "snedecor": 29, "2453": 29, "degre": [29, 807, 889, 1030, 1067, 1068, 1250, 1259, 1298, 1423, 1596, 1616, 1682, 1683, 1723, 1724, 1739, 1767, 1779, 1793], "freedom": [29, 807, 1682, 1683, 1723, 1724, 1767], "0124": 29, "half_cauchi": 29, "half_norm": 29, "base_distribut": 29, "reinterpreted_batch_ndim": 29, "reinterpret": [29, 471], "diagon": [29, 57, 201, 236, 567, 568, 569, 570, 774, 803, 807, 892, 893, 894, 896, 905, 918, 966, 967, 975, 1059, 1071, 1073, 1076, 1088, 1092, 1387, 1668, 1705, 1709, 1710, 1711, 1712, 1713, 1739, 1764, 1779, 1797], "multivari": [29, 1794], "multivariate_norm": 29, "mvn": 29, "scale_tril": 29, "diag": [29, 58, 965, 966, 967, 1065, 1066, 1093, 1513, 1668, 1688, 1689, 1694, 1739, 1779], "diagn": 29, "1729": [29, 1770], "lkj_choleski": 29, "lkj": 29, "matric": [29, 236, 602, 605, 763, 775, 776, 785, 786, 787, 788, 893, 975, 1050, 1059, 1060, 1061, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1079, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1092, 1093, 1094, 1102, 1110, 1119, 1121, 1134, 1201, 1259, 1312, 1346, 1432, 1437, 1511, 1513, 1523, 1637, 1663, 1665, 1666, 1688, 1689, 1694, 1709, 1710, 1712, 1739, 1752, 1767, 1773, 1793, 1799], "eta": [29, 1477, 1479, 1492], "proport": [29, 1218, 1219, 1256, 1297], "det": [29, 1067, 1068, 1089, 1110, 1739, 1779], "l": [29, 674, 764, 773, 779, 786, 787, 905, 987, 988, 1030, 1049, 1059, 1060, 1065, 1066, 1067, 1068, 1072, 1076, 1077, 1119, 1121, 1163, 1166, 1167, 1168, 1178, 1186, 1189, 1190, 1197, 1202, 1210, 1211, 1213, 1216, 1217, 1220, 1232, 1241, 1243, 1250, 1252, 1256, 1257, 1265, 1281, 1298, 1299, 1301, 1428, 1443, 1452, 1460, 1462, 1483, 1624, 1694, 1739, 1741, 1759, 1798], "lkjcorr": 29, "onion": 29, "3x3": [29, 888, 1707], "3516": 29, "9361": 29, "1899": [29, 1132], "4748": 29, "8593": 29, "vine": 29, "2009": [29, 1513, 1689], "lewandowski": 29, "dorota": 29, "kurowicka": 29, "harri": [29, 1653], "joe": 29, "journal": [29, 1595], "1016": 29, "jmva": 29, "04": [29, 948, 1107, 1646, 1653], "008": 29, "corrcholeski": 29, "log_norm": [29, 1779], "lowrank_multivariate_norm": 29, "cov_factor": 29, "cov_diag": 29, "covari": [29, 776, 803, 807, 1168, 1169, 1170, 1289, 1513], "covariance_matrix": 29, "2102": 29, "5429": [29, 1709], "woodburi": 29, "lemma": 29, "formula": [29, 65, 682, 683, 737, 739, 764, 773, 987, 988, 1055, 1121, 1122, 1264, 1315, 1316, 1403, 1493, 1591, 1764, 1767, 1783, 1788], "capacit": 29, "precision_matrix": 29, "mixture_same_famili": 29, "mixture_distribut": 29, "component_distribut": 29, "rightmost": [29, 776, 991, 992, 1741], "gaussian": [29, 1200, 1204, 1279, 1344, 1345, 1399, 1652, 1794], "gmm": 29, "modl": 29, "bivari": 29, "categori": [29, 41, 1140, 1741, 1743, 1777, 1785, 1796], "innermost": [29, 983, 992, 1624], "1338": 29, "mathbf": [29, 1050, 1433, 1464, 1467, 1492], "sigma": [29, 150, 352, 674, 1167, 1201, 1202, 1203, 1220, 1221, 1279, 1280, 1346, 1399, 1433, 1464, 1647, 1682, 1683, 1723, 1724, 1739], "triangular": [29, 786, 787, 788, 1059, 1060, 1066, 1068, 1076, 1077, 1084, 1087, 1088, 1090, 1092, 1387, 1499, 1523, 1694, 1709, 1710, 1711, 1712, 1713], "decomposit": [29, 60, 786, 975, 1059, 1060, 1065, 1066, 1067, 1068, 1069, 1071, 1076, 1077, 1078, 1079, 1084, 1088, 1089, 1093, 1094, 1119, 1121, 1432, 1511, 1513, 1517, 1523, 1688, 1689, 1736, 1773], "positivedefinit": 29, "lowercholeski": 29, "negative_binomi": 29, "stop": [29, 39, 48, 49, 50, 713, 846, 1028, 1102, 1173, 1458, 1507, 1604, 1738, 1741, 1789], "halfopeninterv": 29, "mu": [29, 352, 1491, 1493], "one_hot_categor": 29, "onehot": 29, "5623": 29, "nonneg": [29, 1299, 1513, 1689, 1794], "pmf": 29, "mathrm": [29, 765, 1067, 1068, 1069, 1070, 1081, 1168, 1169, 1170, 1205, 1213, 1214, 1215, 1222, 1259, 1264, 1289, 1432, 1480, 1481, 1482, 1492, 1592, 1794], "relaxed_bernoulli": 29, "temperatur": [29, 1349], "parametr": [29, 961, 1434, 1441, 1464, 1465, 1755, 1764], "relax": [29, 1045, 1046, 1437, 1784], "reparametriz": 29, "99": [29, 1041, 1491, 1738], "2951": [29, 1129], "3442": 29, "8918": 29, "9021": 29, "maddison": 29, "2017": [29, 1293, 1295, 1297, 1669, 1776], "reparametr": [29, 1349, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1449], "jang": 29, "relaxed_categor": 29, "1294": [29, 786], "2324": [29, 1030, 1250], "3859": 29, "2523": 29, "student": 29, "transformed_distribut": 29, "composit": [29, 57, 965, 1077, 1432, 1738, 1741, 1765, 1770, 1777], "basedistribut": 29, "dx": [29, 888, 1166, 1707, 1739, 1764, 1765, 1794], "dy": 29, "logist": [29, 1279, 1282, 1399, 1794], "sigmoidtransform": 29, "affinetransform": 29, "invert": [29, 60, 788, 1021, 1061, 1070, 1071, 1077, 1083, 1090, 1092, 1095, 1096, 1110, 1246, 1247, 1248, 1709, 1739, 1773, 1789], "3418": 29, "upper": [29, 158, 159, 160, 541, 566, 774, 779, 786, 787, 788, 790, 919, 920, 990, 991, 1059, 1060, 1066, 1068, 1076, 1077, 1088, 1092, 1268, 1387, 1395, 1396, 1499, 1505, 1523, 1603, 1624, 1694, 1709, 1712, 1713, 1739, 1757, 1779, 1794, 1800], "von_mis": 29, "circular": [29, 1178, 1179, 1180, 1226, 1227, 1228, 1385], "von": 29, "mise": [29, 1778], "unconstrain": [29, 1437], "angl": [29, 669, 732, 889, 1110, 1236, 1517, 1596, 1640, 1736, 1739, 1779, 1793], "9777": 29, "radian": [29, 614, 732, 889, 1596, 1739, 1779], "nichola": 29, "simul": [29, 1531, 1533, 1784, 1787], "1979": 29, "152": [29, 589], "157": 29, "4784": [29, 1134], "symmetr": [29, 764, 773, 786, 787, 788, 926, 927, 928, 933, 935, 939, 940, 942, 987, 988, 1049, 1059, 1060, 1065, 1066, 1068, 1072, 1073, 1074, 1081, 1084, 1087, 1093, 1102, 1432, 1437, 1505, 1534, 1548, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1694, 1784, 1787], "x_ij": 29, "wu": [29, 1102], "chu": 29, "2018": [29, 1102, 1521], "sawyer": 29, "2007": 29, "anderson": 29, "w": [29, 58, 127, 737, 739, 740, 746, 754, 755, 756, 764, 773, 807, 963, 972, 987, 988, 1027, 1069, 1156, 1157, 1164, 1165, 1169, 1170, 1174, 1179, 1180, 1186, 1190, 1191, 1193, 1194, 1195, 1214, 1215, 1222, 1233, 1234, 1244, 1245, 1255, 1256, 1257, 1262, 1263, 1284, 1300, 1301, 1303, 1304, 1312, 1338, 1339, 1347, 1382, 1388, 1389, 1433, 1464, 1467, 1739, 1752, 1753, 1757, 1759, 1764, 1767, 1781, 1798], "2003": 29, "ed": [29, 57, 1189, 1190, 1759, 1781, 1804], "odel": 29, "feiveson": 29, "1966": 29, "samplecovari": 29, "jasa": 29, "61": 29, "313": 29, "199": 29, "203": [29, 589], "ku": 29, "bloomfield": 29, "2010": [29, 1757], "ox": 29, "max_try_correct": 29, "bartlett": [29, 764], "singular": [29, 1061, 1075, 1076, 1082, 1084, 1086, 1087, 1093, 1094, 1102, 1110, 1119, 1433, 1437, 1513, 1688, 1689, 1773], "accordingli": [29, 60, 1039, 1220, 1437, 1754, 1789], "kl_diverg": 29, "kullback": [29, 1216, 1359], "leibler": [29, 1216, 1359], "notimplementederror": [29, 35, 1781], "register_kl": 29, "type_p": 29, "type_q": 29, "pairwis": [29, 1210, 1259, 1298], "kl_normal_norm": 29, "ambigu": [29, 60, 1015, 1181, 1182, 1183, 1197, 1246, 1247, 1248, 1302, 1741], "runtimewarn": 29, "basep": 29, "derivedq": 29, "kl_version1": 29, "derivedp": 29, "baseq": 29, "kl_version2": 29, "tie": 29, "abstransform": 29, "cache_s": [29, 35], "event_dim": 29, "pointwis": [29, 34, 966, 967, 1107, 1108, 1216, 1752, 1760], "affin": [29, 445, 446, 447, 448, 449, 663, 665, 666, 667, 1168, 1169, 1170, 1205, 1213, 1214, 1215, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1289, 1312, 1534, 1762, 1770], "cattransform": 29, "tseq": 29, "functor": [29, 850, 851], "submatrix": 29, "x0": [29, 34], "t0": [29, 983, 1477, 1740], "exptransform": 29, "identity_transform": 29, "composetransform": 29, "compos": [29, 35, 60, 652, 653, 654, 655, 656, 657, 680, 681, 686, 687, 688, 696, 697, 786, 788, 963, 965, 966, 967, 971, 1030, 1155, 1156, 1157, 1159, 1160, 1161, 1163, 1164, 1165, 1178, 1179, 1180, 1181, 1182, 1183, 1198, 1199, 1218, 1219, 1238, 1243, 1244, 1245, 1250, 1298, 1303, 1304, 1306, 1307, 1308, 1309, 1310, 1311, 1314, 1322, 1323, 1324, 1325, 1326, 1327, 1342, 1343, 1365, 1368, 1369, 1371, 1372, 1373, 1593, 1594, 1728, 1736, 1737, 1738, 1741, 1752, 1764, 1765, 1770, 1777, 1781, 1798], "corrcholeskytransform": 29, "uncontrain": 29, "euclidean": [29, 783, 1383], "x_i": [29, 57, 790, 884, 885, 886, 887, 1098, 1105, 1240, 1259, 1283, 1285, 1298, 1367, 1402, 1520, 1667, 1682, 1683, 1707, 1723, 1724, 1725, 1794], "stickbreakingtransform": 29, "r_i": 29, "tanh": [29, 549, 674, 679, 733, 1200, 1202, 1203, 1220, 1221, 1249, 1265, 1267, 1291, 1345, 1377, 1408, 1737, 1739, 1752, 1753, 1757, 1779, 1786, 1793], "unsign": [29, 1787, 1796, 1799, 1800], "z_i": 29, "s_i": 29, "y_i": [29, 790, 884, 885, 886, 887, 1098, 1105, 1298, 1707, 1725, 1767], "sqrt": [29, 60, 352, 520, 674, 803, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 996, 1049, 1131, 1168, 1169, 1170, 1171, 1178, 1179, 1180, 1181, 1182, 1183, 1200, 1202, 1203, 1205, 1213, 1214, 1215, 1218, 1219, 1220, 1221, 1222, 1235, 1237, 1265, 1267, 1289, 1345, 1437, 1478, 1479, 1480, 1481, 1484, 1490, 1491, 1592, 1619, 1652, 1682, 1683, 1737, 1739, 1752, 1757, 1758, 1759, 1779, 1793, 1794, 1800], "cumulativedistributiontransform": 29, "copula": 29, "base_dist": 29, "independenttransform": 29, "base_transform": 29, "log_abs_det_jacobian": 29, "lowercholeskytransform": 29, "positivedefinitetransform": 29, "powertransform": 29, "expon": [29, 244, 245, 256, 441, 442, 948, 955, 1053, 1083, 1158, 1238, 1383, 1520, 1595, 1737, 1739, 1796, 1799], "reshapetransform": 29, "in_shap": 29, "out_shap": 29, "softplustransform": 29, "tanhtransform": 29, "softmaxtransform": 29, "biject": 29, "hmc": 29, "act": [29, 35, 39, 46, 57, 1167, 1251, 1252, 1261, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1449, 1451, 1452, 1453, 1454, 1455, 1583, 1721, 1762, 1770, 1774], "stacktransform": 29, "stick": 29, "aris": [29, 60, 1759], "primarili": [29, 59, 706, 707, 708, 1150, 1551, 1750, 1784], "taken": [29, 38, 53, 59, 60, 713, 926, 928, 951, 952, 1173, 1186, 1194, 1257, 1331, 1339, 1637, 1668, 1694, 1757, 1761, 1762, 1764, 1766, 1769, 1775, 1777, 1781, 1783], "memoiz": 29, "_call": 29, "_invers": 29, "codomain": [29, 1759], "iff": 29, "weaker": [29, 1762], "pseudoinvers": [29, 1070, 1087, 1095], "monoton": [29, 1249, 1377, 1624], "decreas": [29, 864, 1075, 1189, 1190, 1191, 1195, 1263, 1459, 1460, 1492, 1499, 1507, 1748, 1774, 1793, 1796], "forward_shap": 29, "inverse_shap": 29, "corr_choleski": 29, "greater_than": 29, "greater_than_eq": 29, "integer_interv": 29, "less_than": 29, "lower_choleski": 29, "lower_triangular": 29, "nonnegative_integ": 29, "one_hot": [29, 1739, 1779], "positive_integ": 29, "positive_semidefinit": 29, "positive_definit": 29, "real_vector": 29, "unit_interv": 29, "is_discret": 29, "constrain": [29, 1286, 1741, 1770], "alia": [29, 42, 68, 69, 88, 164, 165, 381, 409, 410, 417, 512, 598, 714, 715, 716, 717, 718, 719, 720, 737, 791, 798, 799, 891, 898, 901, 912, 913, 914, 916, 917, 943, 976, 984, 985, 997, 998, 999, 1008, 1028, 1030, 1056, 1057, 1064, 1080, 1084, 1087, 1115, 1125, 1126, 1136, 1141, 1143, 1153, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1250, 1358, 1426, 1458, 1472, 1510, 1515, 1518, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1618, 1641, 1656, 1659, 1661, 1686, 1690, 1691, 1708, 1714, 1732, 1741, 1764, 1779, 1794, 1795, 1799], "_cat": 29, "dependent_properti": 29, "_dependentproperti": 29, "_greaterthan": 29, "_greaterthaneq": 29, "_independentconstraint": 29, "_integerinterv": 29, "_interv": 29, "half_open_interv": 29, "_halfopeninterv": 29, "_lessthan": 29, "_multinomi": 29, "_stack": [29, 1779], "constraintregistri": 29, "biject_to": 29, "transform_to": 29, "overparameter": 29, "rotat": [29, 1616, 1688], "hamiltonian": 29, "mont": 29, "carlo": 29, "invari": [29, 1458, 1673, 1791, 1793], "potential_energi": 29, "cheap": [29, 1158], "svi": 29, "fewer": [29, 57, 609, 611, 612, 615, 789, 1050, 1051, 1117, 1127, 1129, 1130, 1132, 1135, 1145, 1148, 1204, 1329, 1521, 1669, 1682, 1683, 1687, 1703, 1723, 1724, 1760, 1775, 1800], "my_constraint": 29, "my_transform": 29, "myconstraintclass": 29, "my_factori": 29, "mytransform": 29, "param1": [29, 1770], "param2": [29, 1770], "constraint_registri": 29, "my_registri": 29, "construct_transform": 29, "myconstraint": 29, "from_dlpack": [30, 728], "ext_tensor": [30, 956], "extern": [30, 812, 956, 1045, 1750, 1761, 1762, 1773, 1777], "immut": [30, 956, 1741], "__dlpack__": [30, 956], "capsul": [30, 728, 956], "ndarrai": [30, 431, 727, 956, 957, 1670, 1671, 1672, 1673, 1674, 1675, 1700, 1777, 1798, 1800], "pycapsul": [30, 956], "to_dlpack": [30, 956], "t2": [30, 33, 38, 603, 604, 728, 956, 983, 1423, 1789, 1790], "style": [30, 60, 725, 900, 956, 1469, 1738, 1740, 1741, 1777, 1781, 1798], "dltensor": [30, 956], "t3": [30, 956, 1790], "legaci": [30, 49, 1349, 1783, 1796], "idiomat": 30, "inde": [30, 35, 1738, 1747, 1781, 1791], "pretti": [31, 35, 1030, 1637, 1738, 1778], "dynamo": [31, 34, 35, 37, 38, 795], "_dynamo": [31, 32, 33, 34, 36, 38, 1736, 1763], "my_compil": [31, 32, 35], "gm": [31, 35, 38, 60], "print_tabular": [31, 35, 60], "co": [31, 34, 58, 178, 599, 773, 795, 850, 963, 966, 967, 970, 987, 988, 1081, 1184, 1185, 1188, 1497, 1498, 1505, 1517, 1644, 1645, 1648, 1649, 1650, 1651, 1653, 1670, 1671, 1672, 1674, 1675, 1737, 1739, 1752, 1779, 1780, 1793, 1798, 1800], "opcod": [31, 32, 35, 60, 1781], "placehold": [31, 32, 60, 1212, 1762], "call_funct": [31, 32, 33, 35, 38, 60], "0x7f1a894649a8": 31, "mockmodul": 31, "optimized_mod": 31, "abs_1": [31, 32], "0x7f8d259298a0": 31, "truediv": [31, 32, 60], "call_method": [31, 32, 35, 60], "sum_1": [31, 32, 60], "lt": [31, 32, 338, 370, 1056, 1737, 1738, 1739, 1752, 1779], "mul_1": 31, "nondeterminist": [31, 60, 289, 291, 297, 487, 489, 766, 1051, 1173, 1178, 1179, 1180, 1181, 1182, 1183, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1339, 1347, 1358, 1385, 1415, 1416, 1417, 1631, 1721], "superior": 31, "optimize_for_infer": [31, 34, 1034], "optimize_for_inference_compil": 31, "And": [31, 34, 35, 37, 884, 885, 961, 1030, 1051, 1127, 1132, 1173, 1250, 1529, 1552, 1759, 1764, 1765, 1776, 1777, 1784, 1803], "code_to_acceler": 31, "trt_compil": 31, "tensorrt": [31, 33, 34, 1784], "cudagraphs_compil": 31, "cudagraph": [31, 33, 34, 842, 1762], "tensor_match": 32, "function_match": 32, "recaptur": 32, "dispatch_kei": [32, 1745], "ndim": [32, 1095, 1096, 1752, 1754, 1793, 1799], "dynamic_shap": 32, "log_level": [32, 33, 38, 1763], "output_cod": 32, "spammi": 32, "printout": [32, 60, 852, 865], "__compiled_fn_0": 32, "eval_with_kei": 32, "0x7f9ca082f8a0": 32, "load_fast": [32, 35], "load_glob": 32, "load_method": 32, "load_const": [32, 35], "binary_add": 32, "binary_true_divid": 32, "store_fast": 32, "26": [32, 38, 1085, 1498], "compare_op": 32, "28": [32, 589, 660, 888, 1707, 1777], "pop_jump_if_fals": 32, "38": [32, 1144], "binary_multipli": [32, 35], "return_valu": [32, 39, 40, 46], "unpack_sequ": 32, "__resume_at_30_1": 32, "__resume_at_38_2": 32, "__resume_at_": 32, "jump_absolut": 32, "resume_at": 32, "aotautograd": [33, 34, 38, 1763], "evalfram": 33, "usercod": 33, "unrol": [33, 1740, 1741, 1777], "fsdp": [33, 53, 1736], "mutat": [33, 60, 962, 1034, 1529, 1566, 1567, 1582, 1583, 1781, 1799], "delai": [33, 1791], "rob": 33, "fusion": [33, 34, 60, 702, 1032, 1038, 1043, 1044, 1045, 1046, 1546, 1585, 1586, 1748, 1770, 1784], "opportun": [33, 1060, 1738, 1790], "diminish": 33, "vast": 33, "250k": 33, "aitempl": 33, "fuse": [33, 34, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 639, 640, 641, 642, 643, 644, 645, 702, 703, 1043, 1044, 1480, 1534, 1546, 1584, 1585, 1748, 1752, 1777, 1784, 1785, 1786, 1787], "mobil": [33, 1748, 1784], "succeed": [33, 39, 48, 1119], "aot_eag": [33, 34, 38], "torchdynamo_debug_funct": [33, 38], "desired_function_nam": 33, "replay_record_en": [33, 38], "replai": [33, 38, 809, 842, 1762], "hundr": [33, 38, 1758, 1769], "thousand": [33, 38], "highli": [33, 48, 1158, 1423, 1735, 1771, 1777, 1793, 1800], "minifi": 33, "tini": [33, 1799, 1800, 1805], "torchdynamo_repro_aft": [33, 38], "aot": [33, 38], "your_model": 33, "quickest": 33, "repro": [33, 38], "torchdynamo_repro_dir": 33, "nvfuser": [33, 34, 38, 1738], "leverag": [33, 34, 1789], "compile_tim": [33, 38], "torch_compile_debug": [33, 34, 38], "_inductor": [33, 38], "diagram": [33, 38, 39, 48, 1030, 1250, 1784, 1791], "assumpt": [33, 38, 45, 49, 755, 1173, 1204, 1759, 1763, 1767, 1789, 1790, 1793], "guard": [33, 38, 39, 1772, 1779, 1781, 1804], "cache_size_limit": [33, 35, 38], "troubl": [33, 38], "compilationprofil": [33, 38], "my_model": [33, 38, 1423, 1738], "traffic": 33, "frozen_toy_exampl": 33, "accelerat": 33, "vertic": [33, 1729, 1730, 1782, 1798], "cosin": [33, 599, 600, 804, 805, 1184, 1185, 1329, 1497, 1498, 1505, 1648, 1780], "horizont": [33, 793, 993, 995, 1782], "schedul": [33, 39, 41, 47, 53, 59, 1491, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1763, 1769, 1783], "physic": [33, 49, 923, 941, 1742, 1761, 1793], "principl": [33, 1762], "whatev": [33, 50, 60, 421, 1423, 1628, 1709, 1741, 1765], "triton": [33, 34, 36, 37, 38, 795, 1765], "multiprocessor": 33, "tile": [33, 465, 1739, 1779], "some_fun": [33, 38], "insurmount": [33, 38], "invis": [33, 38, 1762], "maxim": [33, 38, 722, 1127, 1246, 1247, 1248, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1491, 1492, 1493, 1494, 1793], "woo": [33, 38], "out_guard": [33, 38], "ops_per_graph": [33, 38], "builtinvari": [33, 38], "constantvari": [33, 35, 38], "generic_jump": [33, 38], "torchdynamo_dynamic_shap": 33, "vari": [33, 38, 1281, 1458, 1547, 1646, 1750, 1773, 1780, 1784, 1785, 1793], "cv": 33, "app": 33, "unnecessarili": 33, "cold": 33, "torchdynamo_repro_level": [33, 38], "bisect": [33, 38], "codegen": [33, 34, 38, 60], "dramat": [33, 38], "allevi": [33, 1782], "new_fn": 34, "famou": 34, "crunch": 34, "trig": 34, "size_hint": 34, "16384": [34, 1762], "__file__": [34, 1735, 1776, 1781], "meta": [34, 53, 60, 312, 1745, 1789, 1798, 1800], "fp32": [34, 53, 695, 708, 890, 1423, 1762, 1773, 1784, 1785, 1787], "i32": 34, "instance_descriptor": 34, "divisible_by_16": 34, "equal_to_1": 34, "in_ptr0": 34, "out_ptr0": 34, "xnumel": 34, "xblock": 34, "tl": 34, "constexpr": 34, "xoffset": 34, "program_id": 34, "xindex": 34, "xmask": 34, "tmp0": 34, "tmp1": 34, "tmp2": 34, "int32": [34, 168, 185, 289, 297, 301, 420, 589, 779, 907, 919, 920, 955, 957, 958, 1060, 1071, 1072, 1073, 1091, 1119, 1173, 1522, 1624, 1784, 1793, 1795, 1796, 1799, 1805], "held": [34, 59, 809, 832, 860, 1758], "resnet50": [34, 1735, 1798], "hub": [34, 1736, 1749], "v0": 34, "resnet18": [34, 56, 60, 1735, 1738, 1740, 1749, 1781], "pretrain": [34, 1193, 1194, 1587, 1735, 1759, 1777], "opt_model": 34, "64": [34, 56, 58, 966, 967, 969, 1155, 1156, 1157, 1159, 1160, 1161, 1167, 1278, 1625, 1754, 1776, 1777, 1784, 1788, 1793, 1796, 1798, 1799], "aot_cudagraph": 34, "inspir": [34, 53, 1483, 1764], "timm": 34, "huggingfac": 34, "berttoken": 34, "bertmodel": 34, "bert": [34, 1296], "uncas": 34, "token": [34, 48, 809, 842, 843, 1735, 1742], "from_pretrain": [34, 1193, 1194], "me": 34, "encoded_input": 34, "return_tensor": 34, "trigonometri": 34, "skim": 34, "create_model": 34, "resnext101_32x8d": 34, "highest": [34, 1158, 1599, 1600, 1632, 1785, 1800], "torchinductor": [34, 36], "aot_nvfus": 34, "ofi": 34, "fx2trt": [34, 1784], "onnxrt": 34, "ipex": 34, "silent": [34, 854, 855, 873, 874, 1004, 1045, 1250, 1762, 1773, 1777], "symbolic_trac": [34, 60], "traceabl": [34, 60, 596, 708, 1738, 1784], "smoother": [34, 1735, 1747], "transit": [34, 35, 1030, 1131, 1250, 1684, 1736, 1738], "ux": [35, 54, 58], "perspect": [35, 1763, 1773, 1790], "fn_foo": 35, "grab": 35, "dig": 35, "hole": 35, "neutral": 35, "referenc": [35, 60, 812, 1030, 1250, 1709, 1740, 1759, 1777, 1789], "previous": [35, 48, 53, 54, 57, 58, 60, 198, 614, 702, 703, 971, 1037, 1682, 1683, 1723, 1724, 1728, 1738, 1760, 1762, 1770, 1781, 1782, 1788, 1789, 1794], "invalid": [35, 41, 46, 1030, 1140, 1250, 1758, 1759, 1777, 1781, 1782], "lifecycl": 35, "check_fn": 35, "_pyinterpreterstate_setevalframefunc": 35, "convert_fram": [35, 38], "convert_frame_assert": 35, "gloss": 35, "compiler_fn": 35, "one_graph": 35, "_convert_frame_assert": 35, "frametyp": 35, "f_code": 35, "unsupport": [35, 57, 1738, 1742, 1753, 1789, 1793], "needless": 35, "evict": 35, "transform_code_object": 35, "output_instruct": 35, "rememb": [35, 1766, 1772], "guardedcod": 35, "symbolic_loc": 35, "f_local": 35, "travers": [35, 53, 1423, 1564, 1763, 1764, 1790, 1802, 1803], "ordereddict": [35, 1030, 1250, 1251, 1260, 1278, 1418, 1448, 1739, 1770, 1775, 1800], "variablebuild": 35, "localsourc": 35, "_wrap": 35, "variabletrack": 35, "make_guard": 35, "outputgraph": 35, "recal": [35, 1167, 1764, 1798], "pump": 35, "cool": 35, "di": [35, 1751], "get_instruct": 35, "124": 35, "opnam": 35, "argval": 35, "starts_lin": 35, "is_jump_target": 35, "hasattr": [35, 60, 1739, 1764, 1784], "inst": 35, "unimpl": 35, "miss": [35, 46, 53, 605, 1030, 1124, 1134, 1184, 1213, 1214, 1215, 1250, 1364, 1776, 1777, 1778, 1793], "getattr": [35, 60, 1739], "straightforward": [35, 60, 1747, 1754, 1770, 1793], "dozen": 35, "symbolic_convert": [35, 38], "spoken": 35, "quiet": 35, "closer": [35, 983, 1299, 1524, 1764, 1770], "mind": [35, 1075, 1093, 1193, 1759, 1765, 1767], "replace_guard": 35, "add_guard": 35, "visit": [35, 51, 1777], "behalf": 35, "python_typ": 35, "as_proxi": 35, "as_python_proxi": 35, "bookeep": 35, "came": 35, "somewher": [35, 1753, 1769], "flesh": 35, "relianc": 35, "fulfil": [35, 1759, 1765, 1781], "build_tupl": 35, "gist": [35, 1767], "bookkeep": 35, "popn": 35, "tuplevari": 35, "pydoc": 35, "tensorvari": 35, "hint": [35, 809, 842, 1031, 1738, 1740, 1741, 1762], "sybmolic_convert": 35, "instructiontranslatorbas": 35, "pop": [35, 57, 868, 1251, 1260, 1779, 1782, 1783], "techniqu": [35, 38, 60, 1188, 1439, 1707, 1755, 1770, 1782, 1784], "dataclass": 35, "ctor": 35, "guardsourc": 35, "create_fn": 35, "guard_sourc": 35, "elif": [35, 60, 1036, 1216, 1740, 1741, 1768], "istyp": 35, "guardbuild": 35, "equals_match": 35, "rangevari": 35, "appar": 35, "checkfunctionmanag": 35, "compile_check_fn": 35, "cacheentri": 35, "create_cache_entri": 35, "pyobject": 35, "guarded_cod": 35, "malloc": [35, 53], "sizeof": [35, 1795], "debug_null_check": 35, "pyobject_getattrstr": 35, "null_check": 35, "pycodeobject": 35, "sort_kei": 35, "guard_nn_modul": 35, "is_nn_modul": 35, "local_build": 35, "global_build": 35, "ref": [35, 38, 1735], "val": [35, 850, 1036, 1739, 1741, 1757], "___guarded_cod": 35, "___check_type_id": 35, "94367738391392": 35, "___check_tensor": 35, "deeper": [35, 1770, 1781], "dive": [35, 36, 1763, 1767, 1781], "_eval_fram": 35, "anew": 35, "massiv": 35, "role": [35, 39, 40, 48, 49], "weak": 35, "soon": [35, 38, 48, 53, 703, 1759, 1784, 1789, 1791], "moduleinvalid": 35, "pep": [36, 1738, 1740, 1777], "523": 36, "rewrit": [36, 57, 1748, 1759, 1767, 1777], "customiz": [36, 1742, 1802], "usabl": [36, 38, 59, 1741, 1777], "openmp": [36, 1736, 1761, 1776], "dashboard": 36, "video": [36, 1262, 1263, 1753, 1798], "nightli": 37, "prerequisit": [37, 1763], "pip3": 37, "reinstal": 37, "whl": 37, "cu117": 37, "cd": [37, 1776, 1781, 1783], "verify_dynamo": 37, "ghcr": 37, "hoc": 37, "bin": [37, 39, 46, 48, 276, 277, 766, 990, 991, 992, 1547, 1739, 1741, 1779, 1798], "bash": 37, "lazo": 38, "meantim": [38, 1166, 1167, 1184, 1186, 1210, 1217, 1241, 1242, 1253, 1254, 1255, 1257, 1264, 1281, 1282, 1298, 1319, 1320, 1330, 1359, 1382, 1390], "infra": [38, 41, 1778], "smallest": [38, 41, 784, 1051, 1061, 1082, 1086, 1102, 1522, 1704, 1800, 1805], "subgraph": [38, 795, 1759, 1763, 1777, 1781, 1803], "wich": 38, "insuffici": [38, 854], "proce": [38, 1758, 1762, 1789], "test_assertion_error": 38, "mlazo": 38, "837": 38, "build_map": 38, "assertionerror": [38, 60, 1427, 1800], "anexecut": 38, "portion": [38, 53, 954, 1187, 1281, 1387, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1494, 1694, 1785], "fortun": [38, 1766], "isol": [38, 60, 1418, 1751, 1782], "test_backend_error": 38, "_foobar": [38, 1779], "246": [38, 589], "185": [38, 589], "decomp_fn": 38, "810": 38, "repro_aft": 38, "nearli": [38, 127, 740, 754, 1513, 1772, 1789], "minifier_launch": 38, "base_dir": 38, "runnabl": [38, 60, 1758, 1777, 1798], "rand_strid": 38, "proxy_tensor": [38, 962], "make_fx": [38, 962], "0a0": 38, "gitfddfc44": 38, "fddfc4488afb207971c54ad4bf58130fdc8a4dc5": 38, "2005": [38, 599, 1724], "2022": 38, "thu_feb_10_18": 38, "41_pst_2022": 38, "v11": 38, "112": [38, 589], "cuda_11": 38, "r11": 38, "30978841_0": 38, "a100": 38, "sxm4": 38, "40gb": 38, "compile_fx": 38, "compile_fx_inn": 38, "toi": [38, 45], "toy_compil": 38, "debug_util": 38, "run_fwd_maybe_bwd": 38, "opt_mod": 38, "sh": [38, 682, 683, 687, 688, 1315, 1316, 1323, 1324, 1326, 1327, 1372, 1373], "st": [38, 1316, 1324, 1327, 1373], "dt": [38, 1324, 1327, 1794], "requires_grad_": [38, 311, 421, 1030, 1173, 1250, 1331, 1665, 1700, 1739, 1752, 1759, 1799], "rg": 38, "amp": [38, 853, 1736, 1758], "autocast": [38, 853, 1256, 1736, 1762], "torhinductor": 38, "model_forward_0": 38, "torchinductor_jansel": 38, "rh": [38, 1075, 1120], "crhwqgmbqtchqt3v3wdeeszjb352m4vbjbvdovaaeqpzi7tdjxqr": 38, "layernorm": [38, 1205, 1213, 1214, 1215, 1293, 1297, 1361, 1786], "buf1": 38, "schedulernod": 38, "computedbuff": 38, "memorydep": 38, "s0": 38, "unmet_depend": 38, "buf0": 38, "c0": [38, 676, 1220, 1427], "met_depend": 38, "primals_2": 38, "buf1_loop_bodi": 38, "var_rang": 38, "z0": 38, "index0": 38, "index1": 38, "bodi": [38, 60, 1041, 1738, 1740, 1741, 1742], "get_index": 38, "get_index_1": 38, "load_1": 38, "get_index_2": 38, "hinder": 38, "sublist": [38, 905], "exhibit": 38, "outweigh": 38, "readm": [38, 43, 44, 702, 1754], "verify_instal": 38, "log_fil": 38, "plane": [39, 48, 652, 653, 654, 655, 656, 657, 680, 681, 682, 683, 686, 687, 688, 696, 697, 893, 1155, 1156, 1157, 1159, 1160, 1161, 1163, 1164, 1165, 1178, 1179, 1180, 1181, 1182, 1183, 1198, 1199, 1218, 1219, 1222, 1238, 1243, 1244, 1245, 1306, 1307, 1308, 1309, 1310, 1311, 1314, 1315, 1316, 1322, 1323, 1324, 1325, 1326, 1327, 1342, 1343, 1365, 1368, 1369, 1371, 1372, 1373, 1467, 1593, 1594, 1616], "monitor": [39, 49, 50, 811, 1507, 1736, 1762, 1768], "unhealthi": 39, "tear": 39, "react": 39, "decentr": 39, "elasticag": 39, "deploy": [39, 48, 1736], "quad": [39, 1166, 1167, 1186, 1217, 1241, 1257, 1299], "group_result": 39, "is_fail": [39, 40], "exit_cod": 39, "get_worker_group": 39, "workergroup": [39, 49], "mutabl": [39, 1045, 1738, 1781, 1798], "implementor": 39, "defens": 39, "retri": [39, 41, 50, 53, 864, 1789, 1791], "max_restart": [39, 40, 47, 49], "runresult": 39, "workerspec": [39, 40, 49, 50], "local_world_s": [39, 40, 49], "rdzv_handler": [39, 40, 48], "monitor_interv": [39, 40], "local_addr": [39, 48], "tee": [39, 46], "blueprint": 39, "spec": [39, 40, 50, 61, 1547, 1548, 1549, 1552, 1553, 1554, 1786], "homogen": [39, 49], "rendezvoushandl": [39, 40, 48, 49], "rdzv": 39, "chose": [39, 1758], "consol": [39, 42, 45, 46, 49, 1798], "get_entrypoint_nam": 39, "__qualname__": 39, "workerst": 39, "unknown": [39, 1425, 1426, 1791], "unrecover": 39, "interrupt": [39, 1751], "termin": [39, 48, 50, 60, 1483, 1751, 1789], "uncaught": [39, 41], "unhandl": 39, "recov": [39, 742, 926, 1089, 1121, 1423, 1458, 1684, 1758, 1766, 1767, 1785], "is_run": 39, "role_rank": [39, 49], "role_world_s": [39, 49], "pid": [39, 41, 49, 50, 1289, 1766, 1783], "local_elastic_ag": 39, "localelasticag": [39, 40, 50], "start_method": [39, 40, 46, 50, 1751], "exit_barrier_timeout": 39, "log_dir": [39, 46, 1750, 1798], "inter": [39, 41, 980, 1635, 1761, 1763, 1782, 1789], "safeti": [39, 60, 1738, 1741, 1753], "advis": [39, 589, 713, 1772], "pipe": [39, 50, 1736, 1789], "torchelastic_enable_file_tim": 39, "torchelastic_timer_fil": 39, "shared_queu": 39, "get_context": [39, 50, 1772], "nproc_per_process": 39, "foobar": [39, 41, 45, 46], "other_param": [39, 50], "usr": [39, 46, 48, 1762], "trainer_arg": 39, "simpleelasticag": 39, "scaffold": 39, "_assign_worker_rank": 39, "group_world_s": 39, "_exit_barri": 39, "_initialize_work": 39, "worker_group": 39, "fresh": [39, 896, 1627, 1658, 1735], "start_work": 39, "_stop_work": 39, "optimist": 39, "deleg": 39, "_monitor_work": 39, "_rendezv": 39, "_restart_work": 39, "_shutdown": 39, "death_sig": 39, "sigterm": 39, "_start_work": 39, "gracefulli": [39, 49, 57, 1060, 1765], "meaning": [39, 41, 42, 864, 1762], "canon": [39, 41, 1738, 1801], "meaningless": 39, "intention": [39, 902, 1725, 1768, 1789], "ship": [40, 962, 1761, 1789], "programmat": [40, 60, 1770], "my_launch": 40, "argv": [40, 51], "trainer_entrypoint_fn": 40, "fn_arg": 40, "run_result": 40, "tricki": [40, 54, 58, 1759, 1770, 1791], "myrendezvoushandl": 40, "elastic_ag": 40, "servic": [40, 1763], "metrichandl": [40, 45], "mymetrichandl": 40, "metric_data": [40, 45], "metricdata": 40, "sink": [40, 45, 1750], "eventhandl": 40, "cloudwatch": 40, "nulleventhandl": 40, "myeventhandl": 40, "start_process": [41, 46, 1751], "torchelastic_error_fil": 41, "timestamp": [41, 42, 45, 49, 1750, 1798], "error_handl": 41, "sugar": [41, 1740], "get_error_handl": 41, "childfailederror": 41, "get_first_failur": 41, "dump_error_fil": 41, "error_fil": [41, 46], "exitcod": [41, 49], "nanni": 41, "accur": [41, 811, 983, 1105, 1192, 1595, 1707, 1762, 1790], "diagnost": [41, 1736, 1738], "torchelastic_ag": 41, "trainer_0": 41, "trainer_1": 41, "json": [41, 46, 50, 1769, 1783], "trainer_n": 41, "errorhandl": 41, "record_except": 41, "processfailur": 41, "test_ev": 42, "eventsourc": 42, "get_logging_handl": 42, "millisecond": [42, 45, 811, 1750], "eventmetadatavalu": 42, "telemetri": 45, "timeseri": 45, "metric_group": 45, "metric_nam": 45, "sensibl": 45, "vs": [45, 60, 969, 1027, 1043, 1611, 1736, 1738, 1740, 1776], "my_modul": [45, 53, 60, 1738, 1781], "nullmetricshandl": 45, "consolemetricshandl": 45, "my_method": 45, "put_metr": 45, "calculate_lat": 45, "succinctli": 45, "baz": [45, 60, 710, 1781, 1800], "leaf_modul": 45, "classnam": [45, 1741], "threw": 45, "my_app": 45, "consolemetrichandl": 45, "stdout": [45, 46, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1509, 1777], "stdoutmetrichandl": 45, "ts": 45, "1574213883": 45, "4182858": 45, "my_metr": 45, "1574213940": 45, "5237644": 45, "nullmetrichandl": 45, "class_nam": [45, 60], "def_nam": 45, "leaf": [45, 127, 199, 311, 421, 475, 476, 727, 740, 1528, 1566, 1568, 1700, 1754, 1758, 1759, 1803], "metric_valu": 45, "metric_group_nam": 45, "popen": 46, "stderr": [46, 1735, 1749], "err": 46, "echo": 46, "hello": [46, 57, 1740, 1781], "pcontext": 46, "multiprocesscontext": 46, "subprocesscontext": 46, "keyset": 46, "bitmask": 46, "mask": [46, 374, 375, 376, 377, 378, 515, 1123, 1162, 1173, 1195, 1256, 1293, 1294, 1295, 1296, 1297, 1340, 1428, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1736, 1739, 1752, 1753, 1793], "bar0": 46, "bar1": 46, "file1": 46, "file2": 46, "caution": 46, "short": [46, 60, 677, 905, 1027, 1173, 1220, 1221, 1331, 1427, 1476, 1637, 1684, 1740, 1752, 1759, 1760, 1770, 1789, 1795, 1796, 1799], "ing": 46, "cmd": [46, 49], "forkserv": [46, 1423, 1751, 1772], "tee_stdout": 46, "tee_stderr": 46, "processcontext": [46, 1751], "superset": [46, 49], "runprocsresult": 46, "num_nod": [47, 49], "trainers_per_nod": 47, "num_allowed_failur": 47, "rdzv_id": [47, 49], "job_id": [47, 48, 49], "rdzv_backend": [47, 49, 51], "rdzv_endpoint": [47, 49, 51], "host_node_addr": [47, 49], "min_siz": [47, 49], "num_allowed_failures_or_membership_chang": 47, "node1": [47, 49], "29400": [47, 49], "sidecar": [47, 48], "agre": [48, 1088, 1791], "resum": [48, 1499, 1505, 1507, 1789, 1791, 1798], "retryabl": 48, "late": 48, "announc": 48, "lose": [48, 51, 168, 185, 1753], "train_loop": [48, 1587], "arriv": [48, 49, 1789, 1791], "dynamicrendezvoushandl": 48, "rendezvousbackend": 48, "c10drendezvousbackend": 48, "etcdrendezvousbackend": 48, "supersed": 48, "etcdrendezvoushandl": 48, "my_run_id": 48, "from_backend": 48, "run_id": [48, 49], "min_nod": 48, "max_nod": 48, "rendezvousparamet": 48, "endpoint": [48, 49], "admit": [48, 49, 1762], "get_as_bool": 48, "get_as_int": 48, "rendezvoushandlerregistri": 48, "create_handl": 48, "creator": [48, 1759, 1789, 1791], "get_run_id": 48, "is_clos": 48, "set_clos": 48, "next_rendezv": 48, "mark": [48, 59, 60, 744, 745, 1423, 1554, 1738, 1740, 1759, 1763, 1764, 1770, 1781, 1783, 1790, 1799], "rendezvousclosederror": 48, "rendezvousconnectionerror": 48, "rendezvousstateerror": 48, "rendezvoustimeouterror": 48, "num_nodes_wait": 48, "rendezvouserror": 48, "dynamic_rendezv": 48, "join_timeout": 48, "600": 48, "last_call_timeout": 48, "close_timeout": 48, "adress": 48, "rendezvoustimeout": 48, "get_stat": [48, 65], "fenc": 48, "set_stat": [48, 65], "condition": [48, 1634], "last_cal": 48, "heartbeat": 48, "keep_al": 48, "c10d_rendezvous_backend": 48, "create_backend": 48, "store_typ": 48, "tcp": [48, 49, 1789], "read_timeout": 48, "60": [48, 50, 1204, 1509, 1697, 1702, 1750, 1789], "is_host": 48, "cname": 48, "fqdn": [48, 49], "etcd_rendezvous_backend": 48, "ssl_cert": 48, "ssl": 48, "certif": 48, "ssl_cert_kei": 48, "privat": [48, 1762, 1764, 1781], "ca_cert": 48, "rool": 48, "key_prefix": 48, "ttl": 48, "hour": 48, "etcd_rendezv": 48, "rdzv_impl": 48, "etcdrendezv": 48, "etcd_address": 48, "min_work": 48, "max_work": 48, "noqa": 48, "w605": 48, "2379": [48, 1127], "etcd_prefix": 48, "etcdstor": 48, "etcd_stor": 48, "etcd_client": 48, "etcd_store_prefix": 48, "c10": [48, 1769], "piggyback": 48, "num": [48, 659, 660, 674, 1140, 1202, 1205, 1220, 1256, 1265, 1293], "atom": [48, 60, 1742], "lookuperror": 48, "override_timeout": 48, "etcdserv": 48, "cumbersom": [48, 1741], "etcd_serv": 48, "data_dir": 48, "v3": [48, 49], "substitut": [48, 60, 1042, 1759, 1796], "torchelastic_etcd_binary_path": 48, "get_client": 48, "etcd_binary_path": 48, "entry_point": 49, "migrat": [49, 1131, 1784], "train_script": 49, "aforment": 49, "suffic": [49, 60], "compliant": [49, 51], "num_train": 49, "wors": [49, 1721], "port_k": 49, "assgin": 49, "etcd": 49, "v2": [49, 1098, 1512, 1735], "revis": 49, "localworkergroup": 49, "max_nnod": 49, "torchelastic_restart_count": 49, "far": [49, 1039, 1347], "torchelastic_max_restart": 49, "python_exec": 49, "gang": 49, "departur": 49, "surviv": 49, "kill": [49, 50, 1751, 1766], "frequenc": [49, 766, 807, 921, 922, 923, 924, 925, 926, 927, 928, 933, 935, 936, 937, 938, 939, 940, 941, 942, 1158, 1193, 1194, 1338, 1339, 1499, 1684], "ness": 49, "load_checkpoint": [49, 51], "checkpoint_path": [49, 51], "dataset": [49, 51, 1158, 1167, 1216, 1530, 1736, 1766, 1769, 1776, 1780, 1784, 1785, 1798], "train_step": 49, "should_checkpoint": 49, "save_checkpoint": [49, 51], "acquir": [50, 60, 1770, 1791, 1793], "deadlin": 50, "message_queu": 50, "localtimerserv": 50, "max_interv": 50, "trainer_func": 50, "localtimercli": 50, "expiri": 50, "timer_cli": 50, "countdown": 50, "timefram": [50, 1789], "elig": [50, 1791], "reap": 50, "timerserv": 50, "mp_queue": 50, "daemon": [50, 1751], "filetimerserv": 50, "file_path": 50, "log_ev": [50, 1750], "filetimercli": 50, "fifo": 50, "watchdog": 50, "filetimerrequest": 50, "sigkil": 50, "named_pip": 50, "mkfifo": 50, "timercli": 50, "timerrequest": 50, "scope_id": 50, "expiration_tim": 50, "acquisit": 50, "request_queu": 50, "entiti": [50, 60], "clear_tim": 50, "get_expired_tim": 50, "register_tim": 50, "timer_request": 50, "expositori": 51, "worst": [51, 1764], "total_num_epoch": 51, "sharding_strategi": 53, "cpu_offload": 53, "auto_wrap_polici": 53, "backward_prefetch": 53, "backwardprefetch": 53, "backward_pr": [53, 1030, 1250], "mixed_precis": 53, "ignored_modul": 53, "param_init_fn": 53, "sync_module_st": 53, "forward_prefetch": 53, "limit_all_gath": 53, "use_orig_param": 53, "ignored_paramet": 53, "deepspe": 53, "shorten": 53, "sharded_modul": 53, "0001": [53, 60, 886, 1074, 1238, 1365, 1477, 1507, 1739, 1780], "dev_id": 53, "no_sync": [53, 1423], "offload": 53, "ping": 53, "77724": 53, "shardingstrategi": 53, "hybrid_shard": 53, "full_shard": 53, "cpuoffload": 53, "_fsdppolici": 53, "modulewrappolici": 53, "nonwrapped_numel": 53, "subtre": 53, "size_based_auto_wrap_polici": 53, "exce": [53, 1107, 1762], "100m": 53, "numel": [53, 417, 793, 807, 936, 1015, 1739, 1752, 1759, 1779, 1793], "custom_auto_wrap_polici": 53, "min_num_param": 53, "1e8": 53, "my_auto_wrap_polici": 53, "functool": [53, 56, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1557, 1558, 1559, 1560, 1561, 1563, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1764, 1800], "1e5": 53, "mixedprecis": 53, "granular": [53, 1043, 1758], "is_meta": [53, 1779], "reset_paramet": 53, "torchdistx": 53, "deferred_init": 53, "materialize_modul": 53, "mymodul": [53, 60, 1034, 1035, 1036, 1040, 1041, 1047, 1251, 1252, 1260, 1261, 1738, 1740, 1741, 1766, 1775, 1789], "my_init_fn": 53, "fsdp_model": 53, "fullstatedictconfig": 53, "flight": 53, "compatiabl": 53, "kept": [53, 60, 613, 693, 699, 1168, 1169, 1170, 1213, 1214, 1215, 1289, 1358, 1415, 1741, 1751, 1784], "summon_full_param": 53, "norm_typ": [53, 659, 660, 1193, 1194, 1218, 1219, 1338, 1339, 1368, 1369, 1429, 1739], "infin": [53, 805, 1020, 1022, 1024, 1025, 1144, 1166, 1243, 1244, 1245, 1371, 1372, 1373, 1429, 1482, 1657, 1667, 1793, 1794], "no_shard": 53, "largest": [53, 562, 766, 949, 1061, 1082, 1084, 1086, 1087, 1102, 1384, 1433, 1704, 1739, 1740, 1741, 1805], "promot": [53, 601, 768, 771, 780, 850, 900, 948, 950, 951, 952, 953, 1139, 1189, 1190, 1191, 1195, 1329, 1522, 1607, 1608, 1614, 1629, 1685, 1737, 1741, 1796, 1800], "flatten_sharded_optim_state_dict": 53, "sharded_optim_state_dict": 53, "shard_full_optim_state_dict": 53, "shardedtensor": 53, "unflatten": [53, 1739, 1752, 1753, 1779, 1797], "meth": [53, 1789], "fsdp_modul": 53, "root_onli": 53, "full_optim_state_dict": 53, "optim_input": 53, "rank0_onli": 53, "convent": [53, 60, 311, 784, 905, 923, 925, 949, 969, 1168, 1169, 1170, 1213, 1214, 1215, 1289, 1617, 1620, 1715, 1735, 1749, 1754, 1759, 1767, 1770, 1775], "alias": [53, 742, 962, 971, 1358, 1728, 1740, 1741, 1745, 1764], "named_buff": [53, 1030, 1250, 1770, 1775], "intercept": [53, 60], "occurr": [53, 1028, 1130, 1458, 1718, 1719], "named_paramet": [53, 55, 961, 1030, 1034, 1250, 1770, 1775], "gossipgrad": [53, 1423], "unshard": 53, "latter": [53, 603, 1030, 1220, 1250, 1257, 1528, 1765, 1770, 1772, 1774], "rekey_optim_state_dict": 53, "optim_state_dict": 53, "optim_state_key_typ": 53, "loadabl": [53, 1735], "wrapped_model": 53, "wrapped_optim": 53, "full_osd": 53, "nonwrapped_model": 53, "nonwrapped_optim": 53, "rekeyed_osd": 53, "optimstatekeytyp": 53, "param_id": 53, "osd": 53, "param_nam": 53, "sharded_osd": 53, "scatter_full_optim_state_dict": 53, "new_model": 53, "new_optim": 53, "remap": [53, 65, 1034, 1037, 1101, 1122, 1735, 1749, 1788], "set_state_dict_typ": 53, "state_dict_typ": 53, "state_dict_config": 53, "descend": [53, 60, 113, 513, 724, 1030, 1093, 1094, 1250, 1662, 1688, 1739], "transpar": [53, 1763, 1782, 1789, 1791], "sharded_state_dict": 53, "statedicttyp": 53, "shardedstatedictconfig": 53, "offload_to_cpu": 53, "statedictconfig": 53, "writeback": 53, "with_grad": 53, "summon": 53, "storag": [53, 198, 287, 315, 318, 319, 431, 456, 471, 492, 495, 529, 530, 556, 557, 559, 560, 726, 742, 744, 831, 896, 1000, 1004, 1016, 1030, 1037, 1101, 1123, 1149, 1150, 1187, 1250, 1606, 1620, 1627, 1658, 1663, 1665, 1679, 1700, 1706, 1735, 1736, 1739, 1749, 1751, 1759, 1762, 1772, 1775, 1781, 1789, 1793, 1796, 1797, 1799], "discard": [53, 1027, 1087, 1435, 1735, 1740, 1750], "redundantli": [53, 1758], "oom": [53, 1766], "materi": [53, 747, 800, 1425, 1426, 1612, 1613, 1764], "throughput": [53, 1738, 1761], "contend": 53, "backward_post": 53, "reorder": [53, 925, 1085], "reshard": 53, "shard_grad_op": 53, "volum": [53, 992], "_hybrid_shard_zero2": 53, "freed": [53, 127, 740, 754, 817, 864, 1751, 1762, 1768, 1789], "param_dtyp": 53, "reduce_dtyp": 53, "buffer_dtyp": 53, "keep_low_precision_grad": 53, "cast_forward_input": 53, "cast_root_forward_input": 53, "permit": [53, 1793], "thereaft": 53, "upcast": 53, "full_state_dict": 53, "batchnorm": [53, 616, 617, 1030, 1039, 1250, 1289, 1423, 1748, 1759, 1770, 1780, 1782, 1784, 1786, 1787], "isntanc": 53, "c2": 53, "c1": 53, "test_submodules_with_different_precis": 53, "test_submodules_with_different_precisions_error": 53, "offload_param": 53, "jax": [54, 57, 58, 1759, 1765], "bring": [54, 60, 926, 1312, 1347, 1782], "love": 54, "hear": 54, "vmap": [54, 56, 60, 748, 750, 754, 755, 756, 963, 966, 967, 969], "arbitrarili": [54, 58, 485, 1033, 1312, 1741, 1759, 1765], "stock": [54, 58], "ensembl": [54, 58, 969], "maml": [54, 58], "vjp": [54, 57, 737, 738, 967, 971, 1728, 1764, 1765], "whirlwind": 54, "tour": 54, "jacrev": [55, 57, 750, 965, 966, 1765], "functional_cal": [55, 969], "running_mean": [56, 1030, 1168, 1169, 1170, 1213, 1214, 1215, 1223, 1224, 1225, 1232, 1233, 1234, 1250, 1289, 1317, 1357, 1737, 1739, 1770, 1775], "running_var": [56, 1030, 1168, 1169, 1170, 1213, 1214, 1215, 1223, 1224, 1225, 1232, 1233, 1234, 1250, 1289, 1317, 1357, 1737, 1739, 1775], "vmape": 56, "groupnorm": [56, 1348], "anywher": [56, 1758], "batchnorm2d": [56, 629, 632, 634, 639, 1039, 1187, 1224, 1317, 1546, 1748, 1759, 1770, 1784, 1786], "track_running_stat": [56, 665, 666, 667, 1168, 1169, 1170, 1213, 1214, 1215, 1223, 1224, 1225, 1232, 1233, 1234, 1289, 1775], "resnet": [56, 1735, 1738, 1740, 1770, 1781, 1798, 1802], "regnet": 56, "norm_lay": 56, "num_group": [56, 663, 1205, 1348, 1739], "attach": [56, 59, 60, 116, 628, 629, 630, 631, 632, 633, 634, 635, 636, 646, 647, 648, 649, 703, 1418, 1566, 1568, 1589, 1735, 1738, 1740, 1752, 1764, 1784, 1790, 1802], "fragil": 56, "replace_all_batch_norm_modules_": 56, "grad_x": [57, 1765], "has_aux": [57, 963, 964, 966, 967, 968, 970], "jvp": [57, 738, 741, 742, 743, 747, 1764], "jacfwd": [57, 750, 965, 1765], "mental": [57, 962], "absenc": 57, "unbind": [57, 971, 1728, 1736, 1739, 1752, 1779, 1797], "presenc": [57, 60, 1039, 1145, 1781, 1793], "lst": 57, "in_dim": [57, 58, 963, 971, 1728, 1765], "consequ": [57, 1093, 1220, 1688, 1741, 1759, 1762, 1774], "batchedtensor": 57, "batched_tensor_input": 57, "allclos": [57, 58, 60, 755, 756, 850, 927, 928, 934, 935, 962, 963, 965, 966, 967, 968, 970, 971, 1077, 1079, 1090, 1092, 1095, 1096, 1121, 1437, 1523, 1694, 1728, 1739, 1765, 1779], "new_": [57, 1762, 1799], "new_zero": [57, 1739, 1779], "new_empti": [57, 1739, 1779], "diag_emb": [57, 895, 1065, 1066, 1093, 1688, 1694, 1739, 1779], "vec": [57, 84, 85, 398, 606, 1142, 1466, 1737, 1739, 1793], "copy_": [57, 198, 962, 1302, 1738, 1739, 1752, 1762, 1795], "arithmet": [57, 768, 771, 785, 1085, 1614, 1742, 1750, 1752, 1753, 1773, 1784, 1796], "extra_arg": 57, "theoret": 57, "custom_dot": 57, "lax": 57, "cond": [57, 1773], "while_loop": 57, "is_nonzero": [57, 1739, 1779, 1793], "xs": [57, 1131, 1435], "rag": [57, 1754], "unclear": [57, 589], "add_nois": 57, "prng": 57, "cos_x": [58, 963], "neg_sin_x": [58, 963], "hide": [58, 971, 1728, 1765], "lift": [58, 971, 1728, 1753, 1779], "simpler": [58, 971, 1728, 1738, 1759, 1764, 1767, 1770], "feature_s": [58, 963, 971, 1728], "feature_vec": [58, 963, 971, 1728], "compute_loss": [58, 961, 963], "mseloss": [58, 963, 1211, 1281, 1378, 1762, 1763], "grad_weight_per_exampl": [58, 963], "cotang": [58, 970], "vjp_fn": [58, 970], "out_tang": 58, "hessian0": 58, "hessian1": 58, "hess": [58, 965], "encapsul": [59, 60, 1789], "rpc_async": [59, 1741, 1779, 1789, 1791], "add_done_callback": 59, "fut": [59, 1033, 1423, 1761, 1789], "carefulli": [59, 1765, 1781], "set_result": [59, 1423, 1789], "haven": [59, 1770], "set_except": 59, "baseexcept": 59, "valueerror": [59, 1028, 1437, 1438, 1458, 1461, 1764, 1782, 1800], "slow_set_futur": 59, "sleep": 59, "cb1": 59, "cb2": 59, "dedic": [59, 1762], "pool": [59, 680, 681, 682, 683, 696, 697, 809, 842, 843, 853, 864, 1155, 1156, 1157, 1159, 1160, 1161, 1163, 1164, 1165, 1198, 1199, 1218, 1219, 1243, 1244, 1245, 1246, 1247, 1248, 1251, 1306, 1307, 1308, 1309, 1310, 1311, 1314, 1315, 1316, 1342, 1343, 1368, 1369, 1371, 1372, 1373, 1593, 1594, 1736, 1761, 1762, 1764, 1770, 1772, 1786, 1789], "didn": [59, 1764, 1776, 1780], "cb_fut": 59, "chain_cb_fut": 59, "cb": [59, 1789], "collect_al": 59, "fut0": 59, "fut1": [59, 1789], "fut_list": 59, "wait_al": 59, "toolkit": 60, "clamp": [60, 163, 164, 791, 1036, 1166, 1204, 1347, 1358, 1415, 1531, 1534, 1737, 1739, 1748, 1752, 1777, 1779, 1784, 1786, 1787, 1794, 1800], "get_attr": 60, "call_modul": 60, "feed": [60, 1738, 1766, 1770, 1802], "fake": [60, 628, 629, 630, 631, 632, 633, 634, 635, 636, 646, 647, 648, 703, 919, 920, 1531, 1532, 1542, 1544, 1566, 1586, 1587, 1781, 1784, 1787], "theses": 60, "callsit": 60, "constitut": 60, "tracer_class": 60, "treatment": 60, "topk": [60, 1739, 1752, 1779], "linear_weight": 60, "add_1": [60, 962], "linear_1": 60, "relu_1": 60, "topk_1": 60, "pose": [60, 1790], "explor": [60, 1735, 1759, 1770, 1781], "edit": [60, 1781, 1797], "lint": 60, "inserting_aft": 60, "new_nod": 60, "replace_all_uses_with": 60, "tediou": 60, "unwieldi": 60, "conv": [60, 618, 619, 620, 621, 622, 623, 624, 625, 626, 702, 705, 710, 1030, 1039, 1045, 1046, 1178, 1179, 1180, 1181, 1182, 1183, 1250, 1251, 1257, 1546, 1585, 1748, 1757, 1762, 1773, 1777, 1784, 1785, 1786, 1787], "machineri": [60, 1764], "imagin": [60, 1789], "requisit": 60, "relu_decomposit": 60, "decomposition_rul": 60, "constitu": [60, 1754], "new_graph": 60, "graphappendingtrac": 60, "proxy_arg": 60, "output_proxi": 60, "node_copi": 60, "ari": [60, 1777], "unari": [60, 966, 967, 1293, 1295, 1297, 1742, 1752], "organiz": 60, "shapeprop": 60, "named_modul": [60, 1030, 1250, 1770], "args_it": 60, "load_arg": 60, "map_arg": 60, "fetch_attr": 60, "target_atom": 60, "attr_itr": 60, "nonexist": [60, 1740, 1741], "self_obj": 60, "encompass": 60, "prove": [60, 1751], "disprov": 60, "led": 60, "auxiliari": [60, 963, 964, 966, 967, 968, 970, 1735, 1769], "unord": [60, 1251, 1260], "nondetermin": [60, 756, 1774], "dedupl": [60, 1803], "torchvis": [60, 1735, 1736, 1738, 1740, 1777, 1781, 1784, 1798, 1802], "transformed_resnet18": 60, "input_imag": 60, "224": [60, 1586, 1587, 1738, 1740, 1777], "margin": [60, 1184, 1210, 1242, 1253, 1255, 1298, 1299, 1328, 1355, 1370, 1379, 1412, 1413, 1739, 1798], "commut": 60, "toolbox": 60, "tradit": 60, "luckili": 60, "my_pass": 60, "my_module_transform": 60, "input_valu": 60, "prompt": [60, 1735, 1776], "set_trac": [60, 1035, 1041, 1047, 1738], "examin": [60, 1770, 1777, 1783], "undergon": 60, "subclassm": 60, "untrac": 60, "pre_trac": 60, "post_trac": 60, "sake": 60, "tabular": 60, "transform_graph": 60, "session": 60, "luck": 60, "input_nod": 60, "stepwis": 60, "breakpoint": [60, 1741], "excel": 60, "onlin": [60, 1479], "realpython": 60, "pycharm": 60, "vscode": 60, "graphic": [60, 1776], "parlanc": 60, "func_to_trac": 60, "dyn": 60, "155": 60, "__bool__": [60, 1739, 1741], "to_bool": 60, "85": [60, 1253, 1505], "traceerror": [60, 1784], "architectur": [60, 834, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 1186, 1293, 1330, 1633, 1762, 1773, 1784], "hyper": [60, 1281, 1740, 1798], "do_activ": 60, "512": [60, 1293, 1294, 1295, 1296, 1297, 1762], "without_activ": 60, "with_activ": 60, "traced_without_activ": 60, "traced_with_activ": 60, "concrete_arg": 60, "truli": [60, 1777], "__torch_function__": [60, 1804], "161": 60, "len_1": 60, "sqrt_1": 60, "mycustomtrac": 60, "traced_graph": 60, "myspecialsubmodul": 60, "submod": 60, "neg_1": 60, "is_leaf_modul": [60, 1803], "sparse_coo_tensor": [60, 515, 553, 1669, 1739, 1743, 1779, 1793], "ones_lik": [60, 966, 967, 970, 1739, 1754, 1762, 1765, 1770, 1779], "zeros_lik": [60, 745, 747, 1739, 1743, 1754, 1762, 1779, 1793], "viabl": [60, 1762], "torch_randn": 60, "gotcha": 60, "bake": [60, 1034, 1039], "dropoutrepro": 60, "assert_clos": [60, 922, 924, 925, 930, 931, 936, 937, 938, 940, 942, 1738, 1800], "greatest": [60, 973, 1144, 1800], "6207983493804932": 60, "dropoutrepro2": 60, "pytre": [60, 1765], "overspeci": 60, "ph": 60, "shouldn": [60, 809, 1781, 1793, 1797], "v": [60, 460, 515, 742, 749, 751, 752, 753, 779, 961, 971, 1065, 1069, 1093, 1097, 1102, 1256, 1298, 1299, 1338, 1383, 1467, 1491, 1493, 1513, 1669, 1673, 1688, 1689, 1694, 1728, 1739, 1740, 1741, 1750, 1759, 1767, 1777, 1781, 1793, 1798], "fn_or_nam": 60, "callfunct": 60, "fn_to_be_trac": 60, "reassign": [60, 1762], "regener": 60, "unset": [60, 1773], "add_submodul": 60, "subpath": 60, "get_submodul": [60, 1030, 1250], "delete_all_unused_submodul": 60, "delete_submodul": 60, "print_read": 60, "print_output": 60, "date": [60, 1781], "pythoncod": 60, "fxmodul": 60, "pathlik": [60, 1101, 1620, 1781], "owning_modul": 60, "tracer_cl": 60, "tracer_extra": 60, "the_funct": 60, "type_expr": 60, "create_nod": 60, "method_nam": 60, "0th": [60, 971, 1728], "inserting_befor": 60, "influenc": [60, 1793], "eliminate_dead_cod": 60, "dead": 60, "attr_1": 60, "is_impur": 60, "bad": [60, 1751, 1777, 1781, 1784], "sound": [60, 1278, 1745, 1798], "erase_nod": 60, "to_eras": 60, "eras": 60, "qualified_nam": 60, "graph_copi": 60, "val_map": 60, "return_output_nod": 60, "slice": [60, 579, 611, 612, 1168, 1169, 1170, 1283, 1285, 1289, 1402, 1403, 1609, 1626, 1627, 1658, 1667, 1716, 1737, 1738, 1742, 1754, 1777, 1779, 1793, 1794, 1797, 1799], "memory_format": [60, 132, 147, 149, 152, 155, 156, 157, 166, 172, 183, 186, 216, 243, 273, 301, 307, 368, 471, 472, 496, 552, 792, 906, 907, 960, 1030, 1250, 1423, 1475, 1598, 1600, 1602, 1734, 1736, 1737, 1739, 1800], "layout": [60, 127, 168, 185, 318, 319, 418, 419, 420, 421, 422, 431, 515, 554, 555, 589, 605, 713, 740, 742, 764, 773, 823, 906, 907, 908, 918, 923, 941, 959, 960, 987, 988, 1049, 1100, 1116, 1124, 1134, 1150, 1364, 1474, 1475, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1665, 1666, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1706, 1711, 1713, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1743, 1754, 1762, 1779, 1781, 1793, 1798, 1799, 1800], "companion": 60, "__exit__": [60, 1741, 1742, 1781], "arg_transform": 60, "value_remap": 60, "_node_list": 60, "doubli": 60, "on_generate_cod": 60, "make_transform": 60, "transformcodefunc": 60, "insert_pdb": 60, "current_tran": 60, "stuff": 60, "default_valu": 60, "_not_": 60, "tabul": 60, "process_input": 60, "process_output": 60, "python_cod": 60, "root_modul": [60, 703, 1786], "set_codegen": 60, "return_typ": [60, 613, 884, 885, 992, 1051, 1089, 1127, 1130, 1132, 1135, 1146, 1662, 1704, 1709], "all_input_nod": 60, "format_nod": 60, "placeholder_nam": 60, "maybe_return_typenam": 60, "__str__": [60, 1739, 1741], "autogener": [60, 1765], "impur": 60, "normalized_argu": 60, "arg_typ": 60, "kwarg_typ": 60, "normalize_to_only_use_kwarg": 60, "vararg": 60, "argskwargspair": 60, "bx": 60, "ax": [60, 1061, 1075, 1079, 1090, 1091, 1092, 1120, 1131, 1258, 1268, 1709, 1777], "prev": [60, 1492], "replace_with": 60, "delete_user_cb": 60, "propagate_meta": 60, "replace_input_with": 60, "old_input": 60, "new_input": 60, "create_proxi": 60, "record_stack_trac": 60, "update_arg": 60, "update_kwarg": 60, "autowrap_modul": 60, "autowrap_funct": 60, "create_arg": 60, "prepar": [60, 969, 1039, 1529, 1567, 1569, 1582, 1584, 1586, 1587, 1588, 1742, 1777, 1802, 1803], "create_args_for_root": 60, "root_fn": 60, "is_modul": 60, "introspect": 60, "disallow": [60, 1781, 1789, 1796], "proxy_factory_fn": 60, "attr": [60, 127, 740, 1131, 1617], "attr_val": 60, "parameter_proxy_cach": 60, "module_qualified_nam": [60, 1803], "path_of_modul": 60, "some_hyperparamet": 60, "indexed_item": 60, "proxied_valu": 60, "garbage_collect_valu": 60, "run_nod": 60, "swap": [60, 589, 1119, 1298, 1299, 1412, 1413, 1525, 1526, 1527, 1529, 1589, 1706, 1739, 1742, 1762, 1784, 1793, 1802], "vice": [60, 431, 575, 957, 958, 1242, 1759, 1787, 1795], "versa": [60, 431, 575, 957, 958, 1242, 1759, 1787, 1795], "negsigmswapinterpret": 60, "call_self": 60, "args_tail": 60, "fetch_args_kwargs_from_env": 60, "map_nodes_to_valu": 60, "initial_env": 60, "enable_io_process": 60, "negsigmswapxform": 60, "nodes_map": 60, "subgraph_rewrit": 60, "w1": 60, "w2": 60, "m1": [60, 1726, 1727], "m2": [60, 1463, 1726, 1727, 1784], "traced_modul": [60, 1775], "despit": [60, 1045, 1046, 1767], "stack_1": 60, "stack_2": 60, "sum_2": 60, "max_1": 60, "max_2": 60, "add_2": 60, "onnx": [62, 63, 64, 1459, 1460, 1476, 1736, 1753, 1784], "opset_vers": [64, 1777, 1779], "g_cpu": 65, "g_cuda": 65, "bytetensor": [65, 839, 840, 877, 878, 982, 1293, 1428, 1638, 1788, 1796, 1799], "2147483647": 65, "0x8000_0000_0000_0000": [65, 1122, 1788], "0xffff_ffff_ffff_ffff": [65, 1122, 1788], "random_devic": 65, "1516516984916": 65, "new_stat": [65, 877, 878, 1638, 1788], "void": [65, 810, 851, 1762, 1769], "g_cpu_oth": 65, "abs_": [69, 1739, 1752, 1799], "acosh": [73, 99, 715, 1737, 1739, 1752, 1779], "batch1": [76, 77, 128, 129, 602, 763, 1739], "batch2": [76, 77, 128, 129, 146, 602, 763, 1739], "tensor1": [78, 79, 80, 81, 603, 604, 1124, 1614, 1739], "tensor2": [78, 79, 80, 81, 290, 379, 603, 604, 1124, 1614, 1739], "mat1": [82, 83, 525, 605, 994, 1050, 1134, 1663, 1665, 1666, 1680, 1737, 1739], "mat2": [82, 83, 388, 525, 605, 775, 994, 1050, 1134, 1663, 1665, 1666, 1680, 1737, 1739], "mat": [84, 85, 511, 606, 1142, 1595, 1660, 1663, 1680, 1739, 1798], "vec1": [86, 87, 607, 1739], "vec2": [86, 87, 264, 434, 607, 976, 1512, 1739], "keepdim": [89, 91, 92, 93, 95, 111, 112, 329, 367, 382, 384, 385, 386, 389, 403, 404, 405, 406, 426, 443, 452, 526, 536, 587, 609, 611, 612, 613, 615, 722, 723, 1051, 1082, 1086, 1099, 1117, 1127, 1129, 1130, 1132, 1135, 1145, 1146, 1147, 1148, 1259, 1386, 1470, 1521, 1524, 1682, 1683, 1687, 1723, 1724, 1737, 1739, 1752, 1794], "rtol": [90, 320, 610, 755, 756, 1019, 1084, 1087, 1738, 1739, 1800], "atol": [90, 320, 610, 755, 756, 1019, 1084, 1087, 1096, 1738, 1739, 1764, 1800], "08": [90, 320, 610, 773, 1019, 1076, 1185, 1264, 1329, 1390, 1480, 1481, 1482, 1484, 1490, 1491, 1494, 1507, 1644, 1739], "equal_nan": [90, 320, 610, 1019, 1739, 1800], "arcco": [98, 1739, 1779, 1800], "acosh_": [100, 1739, 1752], "arccosh": [100, 1739, 1779], "arcsin": [102, 729, 1739, 1779, 1793], "arcsinh": [104, 1739, 1779], "atan2_": [107, 1739, 1752], "arctan2": [107, 1739, 1779], "arctan": [108, 1739, 1779], "arctanh": [110, 1739, 1779], "storage_offset": [115, 492, 589, 726, 1737, 1739, 1779], "cl": [116, 1764, 1784, 1789, 1804], "asinh": [120, 717, 1737, 1739, 1752, 1779, 1793], "atan": [124, 718, 1737, 1739, 1752, 1779, 1793], "atanh": [126, 720, 1737, 1739, 1752, 1779, 1793], "60521": [127, 740], "issuecom": [127, 740], "867061780": [127, 740], "texttt": [130, 131, 610, 1019, 1158, 1800], "bernoulli": [131, 674, 1162, 1188, 1189, 1190, 1191, 1195, 1202, 1220, 1332, 1333, 1334, 1335, 1340, 1736, 1739, 1752, 1779, 1801], "preserve_format": [132, 147, 149, 152, 155, 156, 157, 166, 183, 186, 216, 243, 273, 301, 368, 496, 552, 792, 907, 960, 1475, 1598, 1600, 1602, 1734, 1796], "minlength": [133, 766, 1739], "bitwise_and": [135, 1737, 1739, 1779], "bitwise_left_shift": [137, 1739, 1779], "bitwise_not": [139, 1737, 1739, 1752, 1779], "bitwise_or": [141, 1737, 1739, 1779], "bitwise_right_shift": [143, 1739, 1779], "bitwise_xor": [145, 1737, 1739, 1779], "uint8": [149, 218, 589, 609, 615, 957, 1522, 1590, 1591, 1614, 1784, 1795, 1796, 1798, 1799, 1805], "cauchi": [150, 1736, 1759, 1767, 1779, 1801], "dfrac": [150, 352, 580, 1185, 1329, 1433, 1464, 1467], "complex32": [156, 1178, 1179, 1180, 1322, 1323, 1324, 1476, 1799, 1800], "int8": [157, 421, 645, 767, 768, 769, 770, 771, 772, 957, 1111, 1112, 1113, 1114, 1784, 1787, 1795, 1796, 1799, 1805], "input2": [160, 432, 433, 489, 674, 788, 1171, 1184, 1185, 1242, 1259, 1318, 1328, 1329, 1370, 1739, 1758, 1777], "clamp_": [165, 1739, 1752], "uncoalesc": [167, 304, 1673], "coo": [167, 299, 304, 586, 994, 1663, 1665, 1670, 1671, 1672, 1673, 1674, 1675, 1736, 1747, 1796, 1800], "inttensor": [168, 185, 1004, 1119, 1120, 1193, 1796, 1799], "csr": [168, 185, 319, 556, 557, 560, 1194, 1663, 1665, 1666, 1672, 1675, 1747, 1800], "sparse_csr": [168, 185, 555, 1666, 1668, 1672, 1675, 1793], "nnz": [168, 515, 555, 755, 1150, 1665, 1666, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1793], "mkl": [168, 185, 1736, 1761, 1776, 1779, 1793], "routin": [168, 185, 724, 787, 1102, 1662, 1688, 1793], "downcast": [168, 185], "to_sparse_csr": [168, 185, 556, 557, 1666, 1739, 1779, 1793], "conj_phys": [171, 800, 1737, 1739, 1779, 1793], "contiguous_format": [172, 307, 471, 472, 906, 1423, 1796], "non_block": [173, 186, 552, 575, 1030, 1250, 1458, 1737, 1739, 1762, 1795], "copysign": [175, 1739, 1779], "fweight": [182, 807, 1739], "aweight": [182, 807, 1739], "sparse_dim": [195, 516, 517, 1663, 1665, 1669, 1673, 1739, 1779, 1793], "resize_": [198, 472, 962, 1051, 1738, 1739, 1740, 1752, 1786, 1795], "resize_as_": [198, 1739, 1752, 1793], "set_": [198, 471, 1739], "transpose_": [198, 1739, 1793], "zero_": [198, 1075, 1338, 1739, 1752, 1753, 1770, 1793], "dim1": [202, 204, 205, 540, 564, 565, 893, 895, 896, 1064, 1691, 1706, 1739], "dim2": [202, 204, 205, 893, 895, 896, 1064, 1739], "digamma": [208, 1737, 1739, 1752, 1779, 1794], "rounding_mod": [211, 212, 213, 214, 900, 901, 950, 953, 1608, 1714, 1739], "split_size_or_sect": [217, 278, 591, 1676], "eq": [220, 1737, 1739, 1752, 1779], "erf": [223, 1737, 1739, 1752, 1779, 1793, 1794], "erfc": [225, 1737, 1739, 1752, 1779, 1794], "front": [230, 1102, 1253, 1753, 1765], "lambd": [234, 274, 1206, 1287, 1350, 1405, 1477, 1739], "fill_valu": [236, 419, 959, 960, 1173, 1737, 1739, 1762], "tall": [236, 1088, 1093, 1764], "start_dim": [239, 944, 1196, 1739], "end_dim": [239, 944, 1196, 1739], "float_pow": [245, 1739, 1779], "floor_divid": [249, 900, 1739, 1779, 1793], "divisor": [252, 253, 461, 462, 682, 683, 900, 950, 953, 973, 1164, 1165, 1197, 1301, 1315, 1316, 1608, 1714], "fmod": [253, 1608, 1737, 1739, 1779], "mantissa": [256, 454, 955, 1053, 1739, 1762, 1773], "gcd": [259, 1737, 1739, 1779], "ge": [261, 985, 1123, 1207, 1208, 1351, 1352, 1737, 1739, 1752, 1779], "geometr": [262, 693, 699, 1347, 1358, 1415, 1722, 1736, 1779, 1801], "ordin": [265, 1670, 1671, 1672, 1674, 1675, 1796], "greater_equ": [270, 1739, 1779], "gt": [272, 984, 1737, 1739, 1752, 1767, 1779], "hypot": [280, 1737, 1739, 1779], "i0": [282, 1049, 1652, 1739, 1779, 1794], "igamma": [284, 1737, 1739, 1779], "igammac": [286, 1737, 1739, 1779], "3100": [287, 456, 1000, 1606], "3553j": [287, 456, 1000, 1606], "5445": [287, 456, 1000, 1606], "7896j": [287, 456, 1000, 1606], "6492": [287, 456, 1000, 1606], "0633j": [287, 456, 1000, 1606], "0638": [287, 456, 1000, 1606], "8119j": [287, 456, 1000, 1606], "3553": [287, 1000], "7896": [287, 1000], "0633": [287, 1000, 1076, 1754], "8119": [287, 1000], "index_add_": [288, 745, 1001, 1002, 1739, 1774], "index_copy_": [290, 1739], "index_fill_": [292, 1739, 1752], "index_put_": [294, 1739], "include_self": [297, 488, 489, 1003, 1623, 1737, 1739], "identit": 297, "amax": [297, 489, 612, 613, 1737, 1739, 1779], "amin": [297, 489, 611, 613, 1737, 1739, 1779], "fill_": [297, 1030, 1055, 1250, 1609, 1739, 1752, 1770, 1795], "72": [297, 589, 983], "uint8_t": [302, 1476], "retain_grad": [311, 1739, 1779], "n_fft": [327, 527, 1027, 1684, 1739], "hop_length": [327, 527, 1027, 1684, 1739], "win_length": [327, 527, 1027, 1684, 1739], "center": [327, 527, 693, 699, 925, 1027, 1312, 1347, 1358, 1415, 1491, 1513, 1646, 1684, 1739, 1759, 1779, 1798], "onesid": [327, 527, 1027, 1684, 1737, 1739], "return_complex": [327, 527, 1027, 1684, 1739], "tolist": [328, 1741, 1779, 1795], "lcm": [331, 1739, 1779], "ldexp": [333, 955, 1739, 1779], "le": [335, 1057, 1207, 1208, 1351, 1352, 1737, 1739, 1752, 1779, 1800], "lerp": [337, 1739, 1779], "less_equ": [341, 1739, 1779], "lgamma": [343, 1737, 1739, 1779], "ln": [352, 1058, 1794], "logical_and": [358, 1737, 1739, 1779], "logical_not": [360, 1737, 1739, 1752, 1779], "logical_or": [362, 1737, 1739, 1779], "logical_xor": [364, 1739, 1779], "pivot": [371, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1119, 1120, 1121, 1523, 1739], "get_info": [371, 1119], "lu_data": [372, 1120, 1121, 1739], "lu_pivot": [372, 1120, 1121, 1739], "masked_fill_": [374, 1739, 1752, 1753], "booltensor": [375, 377, 1123, 1293, 1428, 1731, 1796, 1799], "masked_scatter_": [376, 1739], "mvlgamma": [400, 1739, 1779], "posinf": [401, 402, 1144, 1739], "neginf": [401, 402, 1144, 1739], "nan_to_num": [402, 1739, 1779], "interpol": [405, 452, 699, 700, 701, 1055, 1147, 1302, 1303, 1304, 1312, 1347, 1415, 1416, 1417, 1524, 1547, 1721, 1739, 1786], "ne": [412, 1433, 1464, 1472, 1737, 1739, 1752, 1779], "8182e": 418, "5765e": 418, "41": [418, 908, 1088, 1418, 1463, 1523], "0545e": 418, "0949e": 418, "4842e": [418, 908], "0000e": [418, 908, 948, 1107, 1116, 1144, 1463, 1644, 1646, 1647, 1652, 1653], "00": [418, 908, 948, 1107, 1116, 1144, 1463, 1644, 1646, 1647, 1652, 1653, 1738], "141592": [419, 959], "1416": [419, 889, 959, 1700], "from_numpi": [421, 727, 728, 1700], "array_lik": [421, 727, 1670, 1671, 1672, 1673, 1674, 1675, 1700, 1754], "nextaft": [424, 1737, 1739, 1779], "fro": [426, 1061, 1082, 1086, 1099, 1443, 1452, 1470, 1739], "not_equ": [429, 1739, 1779], "reflect": [431, 492, 527, 957, 958, 961, 1027, 1178, 1179, 1180, 1226, 1227, 1228, 1271, 1272, 1273, 1347, 1385, 1465, 1508, 1684, 1738, 1739, 1766, 1797], "resolve_conj": [431, 800, 1739, 1779], "resolve_neg": [431, 1739, 1779], "shorthand": [431, 1049], "input3": [433, 1739], "transpos": [433, 565, 566, 589, 608, 655, 656, 657, 788, 905, 970, 1059, 1060, 1066, 1069, 1072, 1079, 1090, 1093, 1181, 1182, 1183, 1301, 1325, 1326, 1327, 1432, 1461, 1511, 1688, 1690, 1691, 1694, 1695, 1709, 1737, 1739, 1752, 1754, 1759, 1773, 1777, 1779, 1786, 1793, 1797, 1799], "polygamma": [439, 1739, 1779, 1794], "q_per_channel_axi": [446, 447, 1739, 1779], "zero_point": [447, 449, 652, 653, 654, 655, 656, 657, 658, 663, 664, 665, 666, 667, 668, 669, 670, 672, 673, 684, 686, 687, 688, 689, 691, 694, 695, 919, 920, 1531, 1534, 1547, 1548, 1549, 1550, 1553, 1590, 1591, 1592, 1593, 1594, 1739, 1784, 1785], "qtensor": [451, 1739], "uniform": [454, 580, 765, 1186, 1268, 1330, 1597, 1598, 1646, 1736, 1737, 1757, 1779, 1801], "queu": [459, 815, 1762], "life": [459, 812], "cycl": [459, 740, 812, 1499, 1505, 1759, 1783], "unexpectedli": [459, 1799], "maxnorm": [463, 464, 1609, 1739], "repeat_interleav": [465, 1721, 1739, 1779, 1786], "output_s": [466, 655, 656, 657, 680, 681, 1155, 1156, 1157, 1159, 1160, 1161, 1182, 1197, 1198, 1199, 1246, 1247, 1248, 1301, 1306, 1307, 1308, 1309, 1310, 1311, 1341, 1342, 1343, 1374, 1375, 1376, 1610, 1737, 1739, 1754], "is_leaf": [467, 1739, 1752, 1754, 1779], "saved_weight": 468, "loaded_weight": 468, "5503": 468, "4926": [468, 1770], "1158": 468, "8303": 468, "1007": 468, "9853": 468, "2316": 468, "6606": 468, "resiz": [471, 472, 495, 516, 517, 957, 958, 962, 1302, 1347, 1358, 1737, 1739, 1752, 1779, 1795], "shift": [477, 768, 771, 925, 932, 1162, 1168, 1169, 1170, 1195, 1289, 1340, 1615, 1739, 1742], "decim": [479, 480, 1617, 1739, 1773, 1805], "scatter_": [484, 487, 1621, 1739], "scatter_add_": [485, 486, 1622, 1721, 1739], "axi": [485, 487, 489, 799, 904, 919, 945, 972, 995, 1550, 1553, 1590, 1610, 1615, 1616, 1730, 1737, 1739, 1765, 1777, 1782, 1784], "4600": 485, "2300": 485, "scatter_reduce_": [488, 1623, 1739], "scatter_reduc": [489, 1737, 1739, 1779], "sgn": [494, 954, 1642, 1739, 1752, 1779, 1793], "int16": [496, 957, 1112, 1795, 1796, 1799, 1805], "dense_dim": [514, 516, 517, 1673, 1739, 1779, 1793], "nse": [515, 1793], "randint": [515, 766, 807, 948, 1135, 1173, 1299, 1330, 1331, 1669, 1739, 1743, 1753, 1779, 1798, 1801], "6550": 515, "2397": 515, "1611": 515, "0779": [515, 1066, 1520, 1731], "2326": 515, "0558": 515, "4711": 515, "9678": 515, "5138": 515, "0411": 515, "9417": 515, "5158": 515, "0793": 515, "0036": [515, 1127], "2569": 515, "1055": 515, "sparse_coo": [515, 555, 1150, 1665, 1668, 1669, 1673, 1793, 1796], "split_siz": [518, 1676, 1739], "squeez": [524, 609, 611, 612, 613, 615, 1051, 1117, 1127, 1129, 1130, 1132, 1135, 1145, 1148, 1329, 1521, 1669, 1682, 1683, 1687, 1723, 1724, 1737, 1739, 1752, 1777, 1779, 1786, 1797], "pad_mod": [527, 1684, 1739], "typedstorag": [528, 1795], "untypedstorag": [528, 585, 1795], "untyped_storag": 528, "compute_uv": [538, 1093, 1094, 1688, 1739], "axis0": [539, 1690, 1739], "axis1": [539, 1690, 1739], "dim0": [540, 564, 565, 1691, 1706, 1739], "eigenvector": [541, 1065, 1066, 1102, 1694, 1739], "indices_or_sect": [550, 903, 993, 1701, 1729], "rep": 551, "5044": 552, "0005": [552, 1503, 1509], "3310": 552, "0584": [552, 1688], "cuda0": [552, 1762, 1768, 1799], "mkldnn": [554, 1039, 1736, 1779], "sparsedim": 555, "blocksiz": [555, 556, 557, 1670, 1671, 1672, 1739, 1793], "sparse_csc": [555, 1668, 1672, 1674, 1793], "sparse_bsr": [555, 557, 1671, 1672, 1793], "sparse_bsc": [555, 556, 1670, 1672, 1793], "bsr": [555, 557, 1671, 1672, 1800], "bsc": [555, 556, 1670, 1672, 1800], "crow_indic": [555, 1666, 1668, 1671, 1672, 1675, 1739, 1779, 1793, 1800], "col_indic": [555, 557, 1666, 1668, 1671, 1672, 1675, 1739, 1779, 1793, 1800], "sparsecsr": [555, 1706, 1793], "row_indic": [556, 1670, 1674, 1739, 1779, 1793, 1800], "_nnz": [558, 559, 560, 1779], "csc": [559, 1672, 1674, 1800], "012766935862600803": 561, "5415473580360413": 561, "08909505605697632": 561, "7729271650314331": 561, "unitriangular": [566, 1092, 1709, 1739], "tril": [568, 1739, 1779], "triu": [570, 1437, 1709, 1739, 1777, 1779], "trunc": [574, 603, 900, 943, 950, 953, 1617, 1737, 1739, 1752, 1779, 1793], "sizedim": 579, "return_invers": [581, 582, 1718, 1719, 1739], "return_count": [581, 582, 1718, 1719, 1739], "unsqueez": [584, 925, 1050, 1090, 1193, 1269, 1437, 1703, 1737, 1739, 1764, 1779, 1786, 1793, 1797, 1798], "subspac": [589, 1093, 1256, 1513, 1688, 1689], "span": [589, 868, 869, 1186, 1688, 1783, 1789], "foral": 589, "proportion": [589, 699, 1302, 1415], "met": [589, 1069, 1076, 1077, 1088, 1102, 1256, 1297], "9482": [589, 1007], "0310": 589, "4999": 589, "5316": 589, "1520": 589, "7472": 589, "5617": 589, "8649": 589, "4724": [589, 1770], "0334": 589, "2976": 589, "8499": 589, "2109": 589, "9913": 589, "9607": 589, "6123": 589, "1064483442": 589, "1124191867": 589, "1069546515": 589, "1089989247": 589, "1105482831": 589, "1061112040": 589, "1057999968": 589, "1084397505": 589, "1071760287": 589, "1123489973": 589, "1097310419": 589, "1084649136": 589, "1101533110": 589, "1073668768": 589, "1082790149": 589, "1088634448": 589, "1000000000": 589, "0047": 589, "0310j": 589, "5316j": 589, "7472j": 589, "8649j": 589, "0334j": 589, "8499j": 589, "9913j": 589, "6123j": 589, "202": 589, "154": [589, 1776], "59": [589, 1711, 1713], "182": 589, "243": [589, 1027, 1688], "253": 589, "188": 589, "252": [589, 1776], "191": 589, "63": [589, 1776, 1784], "240": 589, "227": 589, "165": 589, "190": 589, "128": [589, 636, 644, 645, 670, 678, 704, 1171, 1185, 1212, 1237, 1259, 1298, 1299, 1329, 1537, 1538, 1540, 1541, 1547, 1548, 1574, 1575, 1577, 1753, 1754, 1784, 1786, 1787, 1789, 1796, 1799], "146": 589, "106": 589, "205": 589, "206": 589, "189": 589, "95": [589, 1501, 1504, 1505], "147": 589, "89": [589, 1596], "43": 589, "87": 589, "235": 589, "226": 589, "254": [589, 1776], "111": 589, "117": 589, "177": 589, "xlogi": [594, 1739, 1779, 1794], "3348": 599, "5889": 599, "1584": 599, "2294": [599, 1129], "2004": 599, "3690": 599, "7298": [599, 1607], "hyperbol": [600, 730, 733, 805, 1290, 1657, 1699], "uniform_": [600, 733, 765, 1739, 1752, 1757, 1764, 1794, 1801], "3192": 600, "9915": 600, "9674": 600, "7151": 600, "7791": 600, "3120": [600, 802], "2979": 600, "1341": 600, "_i": [601, 602, 603, 604, 605, 763, 765, 768, 771, 775, 790, 900, 950, 1053, 1055, 1139, 1298, 1516, 1520, 1604, 1640, 1685, 1731, 1794], "0202": 601, "0985": 601, "3506": [601, 1119], "6056": 601, "19": [601, 660, 788, 1247, 1738, 1777, 1793], "3944": 601, "9732": 601, "3497": 601, "6245": [601, 1061], "4022": [601, 887, 1688], "3743": 601, "7724": 601, "5811": 601, "8017": 601, "7695": 601, "3930": 601, "3672": [601, 808, 1062], "1450": [601, 1669], "6971": 601, "0736": [601, 1770], "0994": 601, "3216": 601, "7845": 601, "1610": 601, "1868": 601, "4090": 601, "9902": [601, 808, 1062], "3667": [601, 802], "3925": 601, "6147": 601, "sum_": [602, 1027, 1081, 1098, 1163, 1164, 1165, 1178, 1179, 1180, 1186, 1218, 1219, 1238, 1253, 1257, 1259, 1682, 1683, 1684, 1702, 1707, 1723, 1724, 1725, 1794], "mathbin": [602, 605, 606, 763, 775, 1666], "doubletensor": [602, 603, 604, 605, 606, 763, 1630, 1796, 1799], "tensorfloat32": [602, 605, 763, 775, 1124, 1134, 1178, 1179, 1180, 1181, 1182, 1183, 1237, 1322, 1323, 1324, 1325, 1326, 1327, 1364, 1632, 1762, 1773], "rocm": [602, 605, 763, 775, 1124, 1134, 1178, 1179, 1180, 1181, 1182, 1183, 1203, 1221, 1237, 1736], "6311": 602, "0503": 602, "9768": [602, 1770], "0362": 602, "1653": 602, "8185": 602, "4255": [602, 1139], "6760": 602, "9453": 602, "5743": 602, "8202": 602, "3691": 602, "0943": 602, "1109": [602, 1204, 1653], "4730": [602, 1702], "histor": [603, 864, 1190, 1761, 1770, 1775], "t1": [603, 604, 728, 983, 1423, 1740, 1789, 1790], "2312": [603, 1669], "6496": 603, "1312": 603, "0428": 603, "4292": 603, "1030": 603, "5369": 603, "9829": 603, "0430": 603, "8635": 604, "6391": 604, "6174": 604, "7617": 604, "5879": 604, "7388": 604, "8353": 604, "6249": 604, "6511": 604, "8716": 605, "4671": 605, "3746": 605, "7573": 605, "9555": 605, "8681": 605, "3768": 606, "5565": 606, "otim": [607, 1050, 1201, 1346], "conj": [608, 801, 921, 922, 924, 926, 933, 935, 939, 940, 942, 1059, 1060, 1066, 1068, 1087, 1612, 1613, 1737, 1739, 1767, 1779, 1799], "mh": [608, 786, 1066, 1688, 1739, 1779, 1797, 1799], "lvert": [610, 1019, 1298, 1383, 1800], "rvert": [610, 1019, 1800], "leq": [610, 764, 765, 802, 923, 925, 1019, 1050, 1054, 1069, 1075, 1173, 1192, 1253, 1255, 1257, 1331, 1382, 1385, 1643, 1684, 1757, 1794], "elementwis": [610, 802, 823, 850, 851, 948, 950, 1154, 1213, 1214, 1215, 1287, 1405, 1722, 1741, 1754, 1767, 1794], "07": [610, 786, 787, 908, 1067, 1070, 1075, 1087, 1088, 1094, 1117, 1120, 1432, 1483, 1547, 1548, 1549, 1550, 1553, 1647, 1652, 1688], "09": [610, 1483, 1495], "8177": 611, "4878": 611, "2491": 611, "9130": 611, "7158": 611, "1775": 611, "0992": 611, "4817": 611, "0053": 611, "0164": 611, "3738": 611, "0507": [611, 1777], "9700": 611, "1106": 611, "0318": 611, "0816": [611, 1119], "6451": 612, "4866": 612, "2987": 612, "3312": 612, "5744": 612, "2980": [612, 1754], "8397": 612, "2713": 612, "9128": 612, "9214": 612, "7268": 612, "2995": 612, "9023": [612, 1060], "4853": 612, "9075": 612, "6165": 612, "180": [614, 889, 1596], "14159": [614, 1700], "135": 614, "45": [614, 1169, 1170, 1214, 1215, 1289, 1463, 1777], "ao": [616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 1531, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1557, 1558, 1559, 1560, 1561, 1563, 1565, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1585, 1586, 1587, 1784, 1785, 1786], "batch_norm": [616, 617, 1039, 1739, 1779], "3d": [617, 620, 623, 654, 657, 681, 683, 688, 693, 1131, 1157, 1161, 1165, 1168, 1170, 1180, 1183, 1190, 1191, 1197, 1199, 1213, 1215, 1245, 1256, 1302, 1308, 1311, 1312, 1316, 1324, 1327, 1335, 1341, 1343, 1358, 1373, 1385, 1415, 1428, 1754, 1773, 1784, 1793, 1798], "bn": [618, 619, 620, 621, 622, 623, 905, 1039, 1546, 1585, 1775, 1780, 1784, 1785], "qat": [628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 646, 647, 648, 649, 702, 703, 1784, 1785, 1786], "in_channel": [628, 629, 630, 631, 632, 633, 634, 635, 641, 642, 643, 646, 647, 652, 653, 654, 655, 656, 657, 1039, 1178, 1179, 1180, 1181, 1182, 1183, 1226, 1227, 1228, 1229, 1230, 1231], "out_channel": [628, 629, 630, 631, 632, 633, 634, 635, 641, 642, 643, 646, 647, 652, 653, 654, 655, 656, 657, 1039, 1178, 1179, 1180, 1181, 1182, 1183, 1226, 1227, 1228, 1229, 1230, 1231], "kernel_s": [628, 629, 630, 631, 632, 633, 634, 635, 641, 642, 643, 646, 647, 652, 653, 654, 655, 656, 657, 682, 683, 696, 697, 1030, 1039, 1163, 1164, 1165, 1178, 1179, 1180, 1181, 1182, 1183, 1197, 1198, 1199, 1218, 1219, 1226, 1227, 1228, 1229, 1230, 1231, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1301, 1314, 1315, 1316, 1325, 1326, 1327, 1341, 1342, 1343, 1368, 1369, 1371, 1372, 1373, 1374, 1375, 1376, 1414, 1593, 1594, 1737, 1739, 1798], "dilat": [628, 629, 630, 631, 632, 633, 634, 635, 641, 642, 643, 646, 647, 652, 653, 654, 655, 656, 657, 686, 687, 688, 696, 697, 1178, 1179, 1180, 1181, 1182, 1183, 1197, 1226, 1227, 1228, 1229, 1230, 1231, 1243, 1244, 1245, 1301, 1322, 1323, 1324, 1325, 1326, 1327, 1341, 1371, 1372, 1373, 1414, 1593, 1594, 1737, 1739, 1777], "padding_mod": [628, 629, 630, 631, 632, 633, 634, 635, 641, 642, 643, 646, 647, 652, 653, 654, 655, 656, 657, 686, 687, 688, 1178, 1179, 1180, 1181, 1182, 1183, 1226, 1227, 1228, 1229, 1230, 1231, 1347, 1737, 1739], "ep": [628, 629, 630, 631, 632, 633, 639, 640, 650, 651, 663, 665, 666, 667, 668, 755, 756, 1039, 1115, 1154, 1168, 1169, 1170, 1185, 1204, 1205, 1213, 1214, 1215, 1222, 1223, 1224, 1225, 1232, 1233, 1234, 1259, 1264, 1289, 1293, 1295, 1297, 1298, 1317, 1329, 1344, 1348, 1349, 1357, 1361, 1383, 1386, 1390, 1412, 1433, 1464, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1494, 1507, 1547, 1548, 1549, 1550, 1553, 1592, 1737, 1739, 1764, 1767, 1794, 1805], "momentum": [628, 629, 630, 631, 632, 633, 639, 640, 650, 651, 665, 666, 667, 1168, 1169, 1170, 1213, 1214, 1215, 1223, 1224, 1225, 1232, 1233, 1234, 1289, 1317, 1357, 1484, 1491, 1493, 1499, 1505, 1507, 1737, 1739, 1770, 1780], "freeze_bn": [628, 629, 630, 631, 632, 633], "qconfig": [628, 629, 630, 631, 632, 633, 634, 635, 636, 646, 647, 648, 649, 705, 710, 711, 712, 1525, 1526, 1528, 1529, 1566, 1567, 1568, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1583, 1584, 1586, 1587, 1803], "batchnorm1d": [628, 631, 1223, 1289, 1317, 1775, 1786], "fakequant": [628, 629, 630, 631, 632, 633, 634, 635, 636, 646, 647, 648, 649, 1534, 1535, 1539, 1540, 1541, 1570, 1574, 1577, 1587], "weight_fake_qu": [628, 629, 630, 631, 632, 633, 634, 635, 646, 647], "quant": [628, 629, 630, 631, 632, 633, 634, 635, 636, 646, 647, 648, 702, 919, 920, 1527, 1566, 1586, 1587, 1784, 1785], "batchnorm3d": [630, 633, 635, 640, 1225, 1289, 1317, 1786], "in_featur": [636, 644, 645, 648, 649, 670, 678, 969, 1030, 1158, 1235, 1237, 1250, 1418, 1432, 1433, 1463, 1464, 1467, 1770], "out_featur": [636, 644, 645, 648, 649, 670, 678, 969, 1030, 1171, 1235, 1237, 1250, 1418, 1432, 1433, 1463, 1464, 1467, 1770], "num_featur": [639, 640, 650, 651, 665, 666, 667, 1030, 1168, 1169, 1170, 1213, 1214, 1215, 1223, 1224, 1225, 1232, 1233, 1234, 1250, 1289, 1349, 1770], "qint8": [644, 645, 670, 675, 678, 679, 686, 687, 688, 695, 702, 704, 1476, 1531, 1537, 1538, 1540, 1541, 1548, 1561, 1563, 1569, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1581, 1583, 1584, 1586, 1587, 1590, 1591, 1784, 1786, 1787, 1795, 1799, 1800], "highlight": [646, 647, 1741], "from_float": [648, 652, 653, 654, 659, 660, 670, 678, 708, 1529, 1551, 1554, 1566, 1784], "qparams_dict": [648, 652, 653, 654, 678], "quint8": [652, 653, 654, 655, 656, 657, 659, 660, 670, 686, 687, 688, 695, 702, 704, 1476, 1531, 1535, 1536, 1539, 1547, 1548, 1549, 1550, 1553, 1555, 1557, 1558, 1570, 1572, 1574, 1575, 1580, 1581, 1584, 1586, 1590, 1591, 1592, 1593, 1594, 1784, 1786, 1787, 1795, 1799, 1800], "learnabl": [652, 653, 654, 655, 656, 657, 659, 660, 670, 674, 678, 1168, 1169, 1170, 1171, 1178, 1179, 1180, 1181, 1182, 1183, 1193, 1194, 1202, 1203, 1205, 1213, 1214, 1215, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1237, 1258, 1265, 1267, 1289, 1339, 1391, 1770], "q_input": [652, 653, 654, 655, 656, 657, 686, 687, 688], "quantize_per_tensor": [652, 653, 654, 655, 656, 657, 670, 671, 672, 686, 687, 688, 1592, 1593, 1594, 1739, 1779, 1784], "unequ": [653, 654, 655, 656, 657, 1179, 1180, 1182, 1183], "50": [653, 655, 656, 657, 686, 1085, 1135, 1164, 1165, 1173, 1178, 1179, 1180, 1182, 1183, 1198, 1199, 1218, 1219, 1243, 1244, 1245, 1300, 1324, 1325, 1327, 1331, 1342, 1343, 1492, 1552, 1697, 1754], "56": 654, "output_pad": [655, 656, 657, 1181, 1182, 1183, 1229, 1230, 1231, 1325, 1326, 1327, 1737, 1739], "qnnpack": [655, 656, 670, 678, 711, 712, 1584, 1586, 1587, 1784, 1786], "convtranspose2d": [655, 1230, 1326, 1721, 1786], "nnq": [655, 656, 657, 1525, 1526, 1527, 1589, 1784], "downsampl": [655, 656, 657, 1182, 1302, 1312, 1347, 1358], "upsampl": [655, 656, 657, 693, 700, 701, 1182, 1303, 1304, 1312, 1347, 1358, 1416, 1417, 1547], "fbgemm": [656, 657, 670, 678, 711, 712, 1584, 1586, 1587, 1784, 1785], "cubic": [657, 1199, 1343, 1347], "num_embed": [659, 660, 1193, 1194, 1339], "embedding_dim": [659, 660, 1193, 1194, 1222, 1338, 1339], "padding_idx": [659, 1193, 1194, 1338, 1339, 1737, 1739], "scale_grad_by_freq": [659, 660, 1193, 1194, 1338, 1339, 1737, 1739], "_weight": [659, 660, 1193, 1194], "overwritten": [659, 660, 670, 678, 1529, 1569, 1586, 1759, 1800], "_embed": [659, 660], "_dim": [659, 660, 1193], "include_last_offset": [660, 1194, 1339, 1739], "embedding_bag": [660, 1739, 1779], "floatfunct": [661, 1784], "activation_post_process": [661, 1531, 1784], "add_relu": [661, 662, 671, 1779, 1802], "add_scalar": [661, 662, 671, 1779, 1798, 1802], "mul_scalar": [661, 662, 671, 1779, 1802], "collector": 662, "f_add": 662, "num_channel": [663, 1205, 1753], "normalized_shap": [668, 1222, 1361, 1737, 1739], "elementwise_affin": [668, 1222], "negative_slop": [669, 694, 1236, 1362, 1363, 1737, 1739, 1757], "slope": [669, 694, 1236, 1281, 1757], "bias_": [670, 678], "_featur": [670, 678, 695, 1158, 1171, 1235, 1237, 1318, 1364], "from_refer": [670, 678], "ref_qlinear": [670, 678], "output_scal": [670, 673, 1592, 1739], "output_zero_point": [670, 673, 1592, 1739], "q_add": 671, "qint32": [671, 672, 1476, 1590, 1591, 1784, 1787, 1795, 1799, 1800], "x_0": [672, 1707], "gate": [674, 675, 1201, 1202, 1203, 1220, 1279, 1346, 1399], "r_t": [674, 1202, 1490], "w_": [674, 1156, 1157, 1160, 1161, 1164, 1165, 1167, 1175, 1176, 1177, 1179, 1180, 1182, 1183, 1186, 1198, 1199, 1202, 1203, 1219, 1220, 1221, 1244, 1245, 1247, 1248, 1257, 1262, 1263, 1265, 1267, 1271, 1272, 1273, 1274, 1275, 1276, 1302, 1303, 1304, 1305, 1343, 1347], "x_t": [674, 741, 743, 1168, 1169, 1170, 1202, 1213, 1214, 1215, 1220, 1265, 1289, 1478], "b_": [674, 1202, 1203, 1220, 1221, 1238, 1265, 1267, 1702, 1793], "hr": [674, 1202, 1203, 1220, 1767], "h_": [674, 1156, 1157, 1160, 1161, 1164, 1165, 1171, 1176, 1177, 1179, 1180, 1182, 1183, 1198, 1199, 1202, 1203, 1219, 1220, 1237, 1244, 1245, 1246, 1247, 1248, 1262, 1263, 1265, 1267, 1272, 1273, 1275, 1276, 1302, 1303, 1304, 1305, 1318, 1343, 1347], "z_t": [674, 1202], "iz": [674, 1202, 1203], "hz": [674, 1202, 1203, 1798], "n_t": [674, 1202], "hn": [674, 676, 1202, 1203, 1220, 1265, 1427], "h_t": [674, 1202, 1220, 1265], "hadamard": [674, 1202, 1203, 1220, 1221], "multilay": [674, 1202, 1220], "_t": [674, 1202, 1220, 1491, 1493, 1764], "hidden_s": [674, 675, 679, 1202, 1203, 1220, 1221, 1265, 1266, 1267, 1427, 1739], "num_lay": [674, 1202, 1220, 1265, 1266, 1294, 1296, 1427, 1739, 1770], "b_ih": [674, 1202, 1203, 1220, 1221, 1265, 1267, 1739], "b_hh": [674, 1202, 1203, 1220, 1221, 1265, 1267, 1739], "batch_first": [674, 1202, 1220, 1256, 1265, 1266, 1293, 1295, 1297, 1427, 1428, 1459, 1461, 1462, 1739, 1766], "bidirect": [674, 1202, 1220, 1265, 1266, 1427, 1739], "h_0": [674, 1202, 1220, 1221, 1265], "seq_len": [674, 1202, 1220, 1256, 1265], "pack_padded_sequ": [674, 1202, 1220, 1265, 1458, 1460, 1461, 1766], "num_direct": [674, 1202, 1220, 1265], "h_n": [674, 1202, 1220, 1265], "input1": [674, 1171, 1184, 1185, 1242, 1259, 1318, 1328, 1329, 1370, 1739, 1758, 1777], "_size": [674, 1155, 1156, 1157, 1159, 1160, 1161, 1163, 1164, 1165, 1178, 1179, 1180, 1181, 1182, 1183, 1197, 1198, 1199, 1202, 1203, 1218, 1219, 1220, 1221, 1243, 1244, 1245, 1246, 1247, 1248, 1265, 1267, 1301, 1343], "_layer": [674, 1202, 1220, 1265], "_direct": 674, "output1": [674, 1158, 1758, 1777], "output2": [674, 1158], "weight_ih_l": [674, 1202, 1220, 1265], "w_ir": [674, 1202], "w_iz": [674, 1202], "w_in": [674, 1202], "weight_hh_l": [674, 1202, 1220, 1265], "w_hr": [674, 1202], "w_hz": [674, 1202], "w_hn": [674, 1202], "bias_ih_l": [674, 1202, 1220, 1265], "b_ir": [674, 1202], "b_iz": [674, 1202], "b_in": [674, 1202], "bias_hh_l": [674, 1202, 1220, 1265], "b_hr": [674, 1202], "b_hz": [674, 1202], "b_hn": [674, 1202], "mathcal": [674, 1171, 1178, 1179, 1180, 1181, 1182, 1183, 1193, 1194, 1202, 1203, 1220, 1221, 1235, 1237, 1265, 1267, 1268, 1289, 1601, 1757, 1767], "u": [674, 786, 787, 788, 1066, 1068, 1072, 1076, 1077, 1093, 1119, 1121, 1171, 1178, 1179, 1180, 1181, 1182, 1183, 1202, 1203, 1220, 1221, 1235, 1237, 1265, 1267, 1268, 1289, 1300, 1437, 1513, 1688, 1689, 1694, 1737, 1739, 1757, 1759, 1781], "h0": [674, 676, 1202, 1220, 1265, 1427], "gru": [675, 1203, 1739, 1762, 1779, 1784], "cell": [675, 677, 679, 1202, 1203, 1220, 1221, 1265, 1267], "hx": [675, 677, 679, 1203, 1221, 1267, 1739], "cn": [676, 1030, 1220, 1427], "cx": [677, 1221, 1739], "nonlinear": [679, 1166, 1184, 1210, 1265, 1267, 1277, 1736, 1757, 1793], "elman": [679, 1265, 1267], "adaptiveavgpool2d": [680, 1307, 1721, 1786], "adaptiveavgpool3d": [681, 1308, 1721, 1786], "ceil_mod": [682, 683, 696, 697, 1163, 1164, 1165, 1218, 1219, 1243, 1244, 1245, 1314, 1315, 1316, 1368, 1369, 1371, 1372, 1373, 1593, 1594, 1737, 1739], "count_include_pad": [682, 683, 1163, 1164, 1165, 1314, 1315, 1316, 1737, 1739], "divisor_overrid": [682, 683, 1164, 1165, 1315, 1316, 1737, 1739], "kh": [682, 683, 687, 688, 1164, 1165, 1198, 1199, 1244, 1245, 1315, 1316, 1323, 1324, 1326, 1327, 1342, 1343, 1372, 1373], "kw": [682, 683, 687, 688, 1164, 1165, 1198, 1199, 1244, 1245, 1314, 1315, 1316, 1322, 1323, 1324, 1325, 1326, 1327, 1342, 1343, 1371, 1372, 1373], "sw": [682, 683, 686, 687, 688, 1314, 1315, 1316, 1322, 1323, 1324, 1325, 1326, 1327, 1371, 1372, 1373], "avgpool2d": [682, 1315, 1786], "_channel": [682, 683, 686, 687, 688, 1178, 1179, 1180, 1181, 1182, 1183, 1205, 1314, 1315, 1316, 1322, 1323, 1324, 1325, 1326, 1327, 1371, 1372, 1373, 1789], "ih": [682, 683, 687, 688, 1265, 1267, 1315, 1316, 1323, 1324, 1326, 1327, 1372, 1373], "iw": [682, 683, 686, 687, 688, 1314, 1315, 1316, 1322, 1323, 1324, 1325, 1326, 1327, 1371, 1372, 1373], "padh": [682, 683, 687, 688, 1315, 1316, 1323, 1324, 1326, 1327], "padw": [682, 683, 686, 687, 688, 1314, 1315, 1316, 1322, 1323, 1324, 1325, 1326, 1327], "kd": [683, 688, 1165, 1245], "sd": [683, 688], "padd": [683, 688], "formul": [684, 1172, 1192, 1206, 1240, 1286, 1287, 1366, 1383, 1767, 1793], "min_": [685, 1065, 1066, 1075, 1093, 1688, 1694], "max_": [685, 1243, 1244, 1245, 1433, 1464], "convolv": [686, 687, 688, 1178, 1179, 1180, 1181, 1182, 1183, 1226, 1227, 1228, 1229, 1230, 1231, 1322, 1323, 1324, 1325, 1326, 1327], "dw": [686, 687, 688, 1322, 1323, 1324, 1325, 1326, 1327], "qf": [686, 687, 688], "dtype_input": [686, 687, 688], "dtype_filt": [686, 687, 688], "q_filter": [686, 687, 688], "dh": [687, 688, 1323, 1324, 1326, 1327], "dd": 688, "min_val": [692, 1209, 1353, 1354, 1737, 1739], "max_val": [692, 1209, 1353, 1354, 1737, 1739], "scale_factor": [693, 699, 700, 701, 1302, 1303, 1304, 1358, 1415, 1416, 1417, 1737, 1739], "nearest": [693, 699, 701, 1147, 1302, 1304, 1347, 1358, 1415, 1417, 1524, 1617, 1762], "align_corn": [693, 699, 700, 1302, 1303, 1312, 1347, 1358, 1415, 1416, 1737, 1739], "height": [693, 699, 1164, 1165, 1179, 1180, 1182, 1183, 1219, 1244, 1245, 1257, 1284, 1302, 1358, 1415, 1753], "spatial": [693, 699, 700, 701, 783, 925, 1169, 1197, 1222, 1262, 1263, 1284, 1301, 1302, 1303, 1304, 1312, 1347, 1358, 1387, 1388, 1389, 1415, 1416, 1417], "pixel": [693, 699, 701, 1179, 1186, 1189, 1190, 1191, 1195, 1257, 1262, 1263, 1302, 1312, 1347, 1358, 1415, 1417], "corner": [693, 699, 774, 1302, 1312, 1347, 1358, 1415], "edg": [693, 699, 983, 991, 992, 1358, 1415, 1746, 1765, 1790], "leakyrelu": [694, 1251, 1362, 1770, 1786], "_slope": [694, 1236, 1362, 1757], "xa": [695, 1079, 1090, 1091, 1092, 1237, 1364], "return_indic": [696, 697, 1159, 1160, 1161, 1198, 1199, 1243, 1244, 1245, 1246, 1247, 1248, 1309, 1310, 1311, 1342, 1343, 1371, 1372, 1373, 1739], "maxpool1d": [696, 1246, 1371, 1374, 1786], "maxpool2d": [697, 1247, 1251, 1372, 1375, 1777, 1786], "linearli": [699, 1088, 1302, 1415, 1502, 1523, 1766, 1780, 1787], "neighbour": [701, 1238, 1358, 1417], "backend_config": [702, 703, 704, 705, 708, 709, 1584, 1585, 1586, 1587, 1803], "acycl": [702, 1759], "backendpatternconfig": [702, 1586], "dequant": [702, 1428, 1525, 1527, 1531, 1533, 1586, 1739, 1779, 1785, 1787, 1800, 1802], "blob": [702, 962, 1767, 1769, 1798], "dtypeconfig": [702, 703, 1586], "observationtyp": [702, 703, 1586, 1786], "weighted_int8_dtype_config": [702, 1586], "input_dtyp": [702, 704, 1586, 1786], "output_dtyp": [702, 704, 1586, 1737, 1786], "weight_dtyp": [702, 704, 1586, 1786], "bias_dtyp": [702, 704, 1786], "fuse_conv2d_relu": 702, "is_qat": [702, 703], "convrelu2d": [702, 1786], "linear_config": 702, "set_observation_typ": [702, 703, 1586], "output_use_different_observer_as_input": [702, 703, 705, 1586, 1786], "add_dtype_config": [702, 703, 1586], "set_root_modul": [702, 703], "set_qat_modul": [702, 703], "set_reference_quantized_modul": [702, 703], "conv_relu_config": 702, "set_fused_modul": [702, 703], "set_fuser_method": [702, 703], "fused_conv_relu_config": 702, "my_backend": 702, "set_backend_pattern_config": [702, 1586], "from_dict": [702, 703, 704, 706, 707, 708, 710], "backend_config_dict": [702, 1784], "set_nam": 702, "to_dict": [702, 703, 704, 706, 707, 708, 710], "backendconfig": [703, 704, 709, 1584, 1586, 1787], "dtype_config": [703, 1786], "backend_pattern_config_dict": 703, "observation_typ": [703, 1786], "qat_modul": [703, 1786], "reference_quantized_modul": 703, "fused_modul": [703, 1786], "fuser_method": [703, 1546, 1786], "pattern_complex_format": 703, "set_dtype_config": 703, "fuse_linear_relu": 703, "linearrelu": [703, 1786], "output_share_observer_with_input": [703, 705, 1786], "renam": [703, 1739, 1752, 1753, 1779], "quantdequantstub": 703, "set_pattern": 703, "is_dynam": [704, 1554, 1557, 1572, 1578, 1581, 1786], "dtype_config1": 704, "dtype_config2": 704, "dtypewithconstraint": [704, 1786], "quant_min_lower_bound": [704, 1786], "quant_max_upper_bound": [704, 1786], "255": [704, 919, 920, 958, 1347, 1358, 1415, 1534, 1535, 1536, 1539, 1557, 1570, 1572, 1574, 1575, 1581, 1784, 1786, 1798], "input_dtype_with_constraint": 704, "scale_min_lower_bound": [704, 1786], "scale_max_upper_bound": [704, 1786], "dtype_config_dict": 704, "bias_typ": [704, 1586], "maxpool": [705, 1198, 1199, 1342, 1343, 1777], "custom_config": [706, 707, 708, 709], "convert_fx": [706, 1784, 1803], "convert_custom_config": [706, 1584, 1784], "set_observed_to_quantized_map": 706, "observedcustommodul": [706, 708, 1529, 1566, 1784], "quantizedcustommodul": [706, 1529], "set_preserved_attribut": [706, 707, 708], "attr1": [706, 707, 708, 1777], "attr2": [706, 707, 708, 1777], "convert_custom_config_dict": [706, 1529, 1784], "observed_to_quantized_custom_module_class": [706, 1529, 1784], "floatcustommodul": [706, 708], "weight_onli": [706, 1584, 1784], "preserved_attribut": [706, 707, 708], "observed_class": [706, 708], "quantized_class": 706, "quant_typ": [706, 708], "quanttyp": [706, 708], "from_observ": [706, 1529, 1784], "fuse_fx": [707, 1784], "fuse_custom_config": [707, 1585], "fuse_custom_config_dict": [707, 1546], "convertcustomconfig": [707, 1584], "prepare_fx": [708, 1568, 1584, 1587, 1784, 1803], "prepare_qat_fx": [708, 1584, 1784], "prepare_custom_config": [708, 709, 1586, 1587, 1784], "set_standalone_module_nam": 708, "module1": [708, 710, 1762], "qconfig_map": [708, 709, 710, 711, 712, 1584, 1586, 1587, 1784], "child_prepare_custom_config": 708, "set_standalone_module_class": 708, "mystandalonemodul": 708, "set_float_to_observed_map": 708, "set_non_traceable_module_nam": 708, "module2": [708, 710, 1762], "module3": [708, 1762], "set_non_traceable_module_class": 708, "nontraceablemodule1": 708, "nontraceablemodule2": 708, "set_input_quantized_index": 708, "set_output_quantized_index": 708, "prepare_custom_config_dict": [708, 1566, 1568, 1784], "standalone_module_nam": 708, "standalone_module_class": 708, "module_class": 708, "float_to_observed_custom_module_class": [708, 1566, 1784], "non_traceable_module_nam": 708, "non_traceable_module_class": 708, "input_quantized_idx": 708, "output_quantized_idx": 708, "float_class": 708, "qconfigmap": [709, 711, 712, 1584, 1586, 1784, 1787], "preparecustomconfig": [709, 1586], "set_glob": [710, 1584, 1586, 1784], "set_object_typ": [710, 1584, 1586], "set_module_name_regex": 710, "regex": 710, "set_module_nam": [710, 1584, 1586], "set_module_name_object_type_ord": 710, "global_qconfig": 710, "qconfig1": 710, "qconfig2": 710, "qconfig3": 710, "qconfig_dict": [710, 1568], "object_typ": 710, "module_name_regex": 710, "module_name_object_type_ord": 710, "conv0": 710, "x86": [711, 712, 1633, 1784, 1786], "lceil": [713, 784], "rceil": [713, 784], "gap": [713, 1604, 1736, 1784], "adjac": [713, 774, 1189, 1190, 1191, 1195, 1604, 1793], "set_default_tensor_typ": [713, 764, 773, 906, 908, 918, 923, 941, 959, 977, 987, 988, 1049, 1100, 1116, 1474, 1597, 1599, 1601, 1603, 1604, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1670, 1671, 1672, 1673, 1674, 1675, 1711, 1713, 1733], "get_default_dtyp": [713, 1100, 1116, 1476, 1604, 1795, 1796, 1805], "5000": [713, 734, 735, 736, 766, 790, 923, 925, 926, 933, 936, 941, 951, 953, 954, 955, 983, 989, 992, 1055, 1081, 1100, 1145, 1147, 1175, 1176, 1194, 1302, 1524, 1593, 1594, 1595, 1604, 1608, 1794, 1799], "3398": 722, "2663": [722, 1762], "2686": 722, "2450": 722, "7401": 722, "8805": 722, "3402": 722, "1936": 722, "4907": [722, 1117], "3948": [722, 802], "0691": 722, "3132": 722, "6092": 722, "5419": 722, "2993": [722, 1687], "3195": 722, "1139": 723, "2254": 723, "1381": [723, 1687], "3687": 723, "0100": [723, 1083, 1590], "1975": [723, 1754], "0102": 723, "4732": 723, "9240": 723, "1207": [723, 1139], "7506": 723, "0213": 723, "7809": 723, "2960": 723, "9384": 723, "1438": 723, "ascend": [724, 925, 1066, 1068, 1097, 1138, 1624, 1662, 1694, 1718], "0785": 724, "5267": 724, "8521": 724, "4065": 724, "1598": 724, "0788": 724, "0745": 724, "2700": 724, "2208": 724, "0722": 724, "7064": 724, "2564": 724, "0669": 724, "2318": 724, "8229": 724, "9280": 724, "lexicograph": [725, 1469, 1741, 1793], "9039": 726, "6291": 726, "0795": [726, 1524, 1770], "1586": 726, "1939": 726, "4900": 726, "1909": 726, "7503": 726, "9355": 726, "histori": [727, 728, 1483, 1700, 1747, 1754, 1764, 1766, 1790], "dlpack": [728, 956, 1736], "frombuff": 728, "data_ptr": [728, 1752, 1795, 1797], "addbackward0": [728, 1770, 1775], "__array_interface__": 728, "5962": 729, "4985": 729, "4396": 729, "4525": [729, 1754], "6387": 729, "4552": 729, "sine": [730, 1645, 1655, 1657], "1606": 730, "4267": 730, "0899": 730, "0250": 730, "1599": 730, "1534": 730, "9435": 730, "8990": [730, 900], "arctang": [731, 732], "2341": 731, "2539": 731, "6256": 731, "6448": 731, "2299": 731, "2487": 731, "5591": [731, 752], "5727": 731, "quadrant": 732, "9041": [732, 783], "0196": [732, 783], "3108": [732, 783], "4423": [732, 783], "9833": 732, "0811": 732, "9743": 732, "4151": 732, "tangent": [733, 742, 743, 968, 1290, 1698, 1699], "9385": 733, "2968": 733, "8591": 733, "1871": 733, "7253": 733, "3060": 733, "2899": 733, "1893": 733, "needs_input_grad": [737, 1764], "setup_context": [738, 1765], "save_for_forward": [738, 1765], "grad_input": [739, 745, 747, 1030, 1250, 1422, 1764, 1770], "grad_tensor": [740, 754, 1739, 1762], "grad_vari": 740, "forward_ad": 741, "dual": [741, 742, 743, 1468, 1765], "make_du": [741, 743], "your_fn": 741, "unpack_du": [741, 742], "grad_aft": 741, "dual_level": [742, 743], "primal": [743, 964, 968, 970], "x_npy": 744, "once_differenti": [744, 745, 746, 747, 1764], "g1": [745, 747, 1762, 1791], "g2": [745, 747, 1762, 1791], "oppos": [746, 1765], "weren": 746, "grad_out": [746, 1737, 1739, 1767], "gx": 746, "gy": 746, "gz": 746, "simplefunc": 747, "induc": [747, 1347, 1385, 1757], "outer_jacobian_strategi": 748, "disconnect": [748, 749, 750, 751, 752, 753], "said": [748, 749, 750, 751, 752, 753, 1747, 1773], "cliff": [748, 750, 754], "_debug_only_display_vmap_fallback_warn": [748, 754], "pow_reduc": [748, 749, 752], "2265": 748, "8221": 748, "9456": [748, 765], "2550": 748, "viewbackward": [748, 750], "pow_adder_reduc": [748, 749, 752], "func_output": [749, 751, 752, 753], "1448": 749, "0239": 749, "6456": 749, "4988": 749, "4310": 749, "sumbackward0": [749, 752], "3030": 749, "significantli": [749, 1423, 1480, 1632, 1793], "vhp": 749, "batched_grad": 750, "exp_reduc": [750, 751, 753], "4917": 750, "4352": 750, "4369": 750, "3799": 750, "exp_add": 750, "8052": 750, "3963": 750, "3090": 751, "6742": 751, "9114": 751, "2106": 751, "sumbackward1": [751, 753], "squeezebackward1": 751, "adder": [751, 753], "2399": 751, "5005": 751, "0689": 752, "2431": 752, "0989": 752, "4456": 752, "8053": [752, 1619], "7817": 753, "2458": 753, "7830": 753, "7782": 753, "4458": 753, "3962": 753, "3042": [753, 1087], "6354": 753, "1288": [753, 1648], "0652": 753, "5483": 753, "5035": 753, "2046": [753, 802], "1292": 753, "1432": 753, "3059": 753, "3225": 753, "6652": 753, "7753": 753, "0152": 753, "4225": 753, "3340": 753, "only_input": 754, "allow_unus": [754, 1739], "is_grads_batch": 754, "require_grad": [754, 1741, 1759], "06": [755, 756, 1070, 1075, 1076, 1087, 1088, 1093, 1204, 1259, 1298, 1301, 1344, 1386, 1412, 1478, 1492, 1688, 1739, 1800], "raise_except": [755, 756], "check_sparse_nnz": 755, "nondet_tol": [755, 756], "check_undefined_grad": [755, 756], "check_grad_dtyp": [755, 756], "check_batched_grad": [755, 756], "check_batched_forward_grad": 755, "check_forward_ad": 755, "check_backward_ad": 755, "fast_mod": [755, 756, 1767], "perturb": [755, 756, 1767], "sparsetensor": [755, 1673], "gradgradcheck": [755, 1764], "gen_non_contig_grad_output": 756, "check_fwd_over_rev": 756, "check_rev_over_rev": 756, "noncontigu": [756, 850, 1800], "inaccuraci": 756, "eventlist": [758, 759], "chrome": [758, 1783], "group_by_stack_n": [759, 1783], "roof": 759, "functioneventavg": [759, 761], "window_length": [764, 773, 987, 988, 1049, 1739], "2n": [764, 1643], "trim": [764, 773, 921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 987, 988, 1027], "_length": [764, 773, 987, 988, 1027, 1173, 1684], "sim": [765, 1264, 1390, 1516, 1601], "pseudorandom": [765, 1140, 1471, 1513, 1516, 1597, 1599, 1601, 1603, 1689], "1737": 765, "0950": [765, 1666], "3609": 765, "7148": 765, "0289": [765, 1710], "2676": 765, "8937": 765, "7202": 765, "2500": [766, 923, 925, 926, 936, 941, 1100, 1302, 1595], "7500": [766, 926, 936, 955, 983, 1085, 1100, 1302, 1595, 1651], "AND": [767, 1111, 1741, 1759], "OR": [770, 1113, 1741], "xor": [772, 1114, 1741], "blackman": [773, 1653], "arrang": 774, "broadcast_tensor": [776, 1739, 1779], "out_int32": [779, 1624, 1739], "formal": [779, 1624, 1747, 1753], "eg": [779, 1617, 1624], "tensor_a": [781, 794], "tensor_b": 781, "understood": 782, "6580": 782, "0969": 782, "4614": 782, "1034": [782, 905], "5790": 782, "1497": 782, "x2": [783, 1077, 1242, 1298, 1299, 1329, 1386, 1739], "compute_mod": 783, "use_mm_for_euclid_dist_if_necessari": 783, "distanc": [783, 1027, 1065, 1066, 1093, 1210, 1259, 1298, 1299, 1387, 1499, 1684, 1688, 1736], "infti": [783, 1027, 1081, 1166, 1218, 1219, 1281, 1387, 1490, 1794], "use_mm_for_euclid_dist": 783, "donot_use_mm_for_euclid_dist": 783, "minkowski": [783, 1387], "ham": [783, 987, 1387, 1649], "closest": [783, 1387], "xn": [783, 1387], "4821": [783, 786], "059": 783, "0590": 783, "1763": [783, 1607], "4713": [783, 1607], "6986": [783, 1607], "3702": [783, 1607], "1193": [783, 1119], "0959": 783, "7138": 783, "8322": 783, "2830": [783, 1712], "3791": 783, "6341": 784, "4208": 784, "0900": 784, "5826": 784, "lowest": [785, 1144, 1442, 1443, 1451, 1452, 1599, 1600, 1764, 1800], "clr": [785, 1499], "3375": 785, "9790": 785, "1119": 785, "6577": 785, "5609": [785, 1338], "5095": 785, "2614": 785, "4038": 785, "3378": [785, 1712], "4982": 785, "2457": [785, 1132], "2561": 785, "4684": 785, "7163": 785, "9647": 785, "8917": [785, 1110], "3213": [785, 1106], "2284": [785, 885], "8615": 785, "2816": 785, "tu": 786, "mt": [786, 787, 1059, 1066, 1068, 1072, 1073, 1074, 1079, 1088, 1523, 1688, 1694, 1739, 1747, 1779, 1797, 1799], "4112": 786, "7486": 786, "4551": 786, "3544": 786, "6724": 786, "5528": 786, "0592": [786, 1770], "9371": 786, "5487": 786, "7023": 786, "03": [786, 787, 1107, 1646, 1647, 1652], "3842e": [786, 1075], "dpotri": 787, "spotri": 787, "uu": 787, "9935": 787, "6353": 787, "5806": 787, "8769": 787, "7183": [787, 1081, 1770], "6618": 787, "9314": 787, "2251": [787, 808, 1062, 1104], "0889": 787, "4439": 787, "2122": 787, "1412": 787, "5894e": 787, "semidefinit": 788, "7747": 788, "9549": 788, "3086": 788, "4114": 788, "8733": 788, "6355": 788, "9891": 788, "1974": 788, "4706": 788, "4115": 788, "6225": 788, "1625": 788, "6097": 788, "8398": 788, "2387": [788, 803], "3771": [788, 1076], "4173": 788, "1626": [788, 808, 1062], "tensor_split": [789, 903, 993, 1729, 1739, 1779, 1797], "min_valu": [790, 1209], "max_valu": [790, 1209, 1739], "_valu": [790, 1158, 1430, 1673, 1764, 1779, 1793], "7120": 790, "1734": [790, 1004], "0478": [790, 1731], "0922": 790, "3333": [790, 983, 992, 1302, 1303, 1700], "hstack": [793, 1739, 1779, 1793], "with_replac": [794, 1739], "combinations_with_replac": 794, "fullgraph": 795, "autotun": 795, "remateri": 795, "acc": 795, "_glibcxx_use_cxx11_abi": 796, "flip": [800, 946, 947, 1097, 1739, 1779], "lazi": [800, 1042, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1418, 1494, 1736], "writeabl": [800, 801], "is_conj": [800, 1612, 1739, 1779], "geq": [802, 974, 1061, 1069, 1186, 1236, 1257, 1258, 1268, 1330, 1382, 1432, 1757, 1794], "signbit": [802, 1737, 1739, 1779, 1793], "2557": 802, "0026": 802, "5387": 802, "4740": 802, "9244": 802, "7079": 802, "2778": 802, "0249": [802, 1105], "5719": 802, "0059": 802, "2600": 802, "4475": 802, "9567": [802, 1065, 1687], "5757": 802, "1751": 802, "0742": 802, "2998": 802, "1054": 802, "2373": 802, "3190": [802, 1762], "1128": [802, 1087, 1220], "pearson": 803, "coeffici": [803, 987, 1478, 1480, 1481, 1482, 1484, 1490, 1494, 1648, 1649, 1650, 1709], "r_": [803, 1702], "ij": [803, 905, 1109, 1117, 1131, 1253], "c_": [803, 1178, 1179, 1180, 1181, 1182, 1183, 1220, 1262, 1263], "jj": 803, "hermitian": [803, 921, 922, 924, 926, 927, 928, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 1059, 1060, 1065, 1066, 1068, 1072, 1073, 1074, 1084, 1087, 1093, 1694, 1739], "cov": [803, 1739, 1779], "2678": [803, 1193], "0908": 803, "3766": 803, "2780": 803, "5812": 803, "1535": [803, 1193], "2350": 803, "3582": 803, "4309": 804, "2706": 804, "8562": 804, "9796": [804, 1075], "1395": 804, "2957": 804, "6553": 804, "5574": 804, "1632": 805, "1835": 805, "6979": 805, "7325": [805, 895], "0133": 805, "7860": 805, "2536": 805, "2805": 805, "sleef": [805, 1657], "unbias": [807, 1168, 1169, 1170, 1205, 1213, 1214, 1215, 1222, 1289, 1682, 1683, 1723, 1724, 1737, 1739], "_w": 807, "x_": [807, 915, 1103, 1104, 1106, 1109, 1117, 1167, 1186, 1240, 1257, 1283, 1285, 1402, 1548, 1549, 1667, 1707, 1759, 1787, 1794], "y_": [807, 915, 1103, 1104, 1106, 1167, 1186, 1216, 1707, 1759, 1794], "w_i": [807, 1069], "mu_x": 807, "mu_i": [807, 1484], "whichev": [807, 971, 1347, 1524, 1728, 1762], "w_ix_": 807, "bessel": [807, 1049, 1652, 1682, 1683, 1723, 1724, 1794], "corrcoef": [807, 1739, 1779], "6667": [807, 992, 1302, 1303, 1609, 1643, 1775], "fw": 807, "4282": 807, "0255": [807, 892], "4144": [807, 1762], "4169": 807, "3956": [808, 1062], "1455": [808, 1062, 1776], "6895": [808, 1062], "5849": [808, 1062], "3599": [808, 1062], "7180": [808, 1062], "0521": [808, 1062], "1339": [808, 1062], "0225": [808, 1062, 1075], "0257": [808, 1062], "4725": [808, 1062], "1479": [808, 1062], "7005": [808, 1062], "9757": [808, 1062], "3904": [808, 1062], "3726": [808, 1062], "1836": [808, 1062], "9688": [808, 1062], "7153": [808, 1062, 1794], "2159": [808, 1062], "0844": [808, 1062], "5281": [808, 1062], "6120": [808, 1062], "4490": [808, 1062], "5687": [808, 1062], "9792": [808, 886, 1062], "8304": [808, 1062], "3037": [808, 1062, 1770], "5650": [808, 1062], "2329": [808, 1062], "9883": [808, 1062], "0551": [808, 1062], "capture_begin": [809, 1762], "make_graphed_cal": [809, 1762], "graph_pool_handl": [809, 842], "other_graph_inst": [809, 842], "capture_end": [809, 1762], "debug_dump": 809, "debug_path": 809, "enable_debug_mod": 809, "path_to_so_fil": 810, "alloc_fn_nam": 810, "free_fn_nam": 810, "ctype": 810, "change_current_alloc": [810, 1762], "ssize_t": [810, 1762], "cudastream_t": [810, 812, 1762], "ptr": [810, 1762], "size_t": 810, "oss": 810, "enable_tim": [811, 1762], "interprocess": 811, "marker": 811, "elapsed_tim": [811, 1762], "end_ev": [811, 1762], "elaps": [811, 1750], "from_ipc_handl": 811, "reconstruct": [811, 1119, 1166, 1167, 1767, 1775, 1781], "ipc": [811, 846], "ipc_handl": 811, "proceed": [811, 1204, 1790, 1791], "cudaeventsynchron": 811, "cudastreamwaitev": [811, 812, 814], "stream_ptr": 812, "record_ev": [812, 814], "cudastreamsynchron": [812, 814], "wait_ev": [812, 814], "interoper": 816, "caching_allocator_delet": 816, "mem_ptr": 817, "caching_allocator_alloc": 817, "peer_devic": 818, "_cudaalloc": 819, "buffer_s": 821, "10485760": 821, "chunk_siz": [824, 967, 971, 1728], "cublashandle_t": 825, "unoccupi": 832, "smi": [832, 860, 866, 883, 1762, 1766, 1768], "pytorch_cuda_alloc_conf": [833, 1762], "cudamallocasync": [833, 864, 1762], "_cudadeviceproperti": 837, "gencod": 838, "eagerli": [839, 845, 1762], "cuda_graph": 842, "ordinari": [844, 1423, 1758], "code_str": [850, 851], "templat": [850, 851, 1780], "temp": 850, "dir": [850, 1735, 1741, 1781], "boardcast": 850, "typenam": [850, 851], "my_kernel": [850, 851], "jitted_fn": [850, 851], "create_jit_fn": [850, 851], "util_fn": 850, "gelu": [850, 1279, 1293, 1295, 1297, 1399, 1737, 1739, 1754, 1779], "my_gelu": 850, "my_lib": [850, 1745, 1776], "impl": [850, 1745], "num_output": 851, "sample_arg": 853, "num_warmup_it": 853, "allow_unused_input": 853, "datadistributedparallel": 853, "manual_seed_al": 854, "occupi": [856, 859, 860, 870, 1238, 1365, 1762, 1768, 1805], "reset_peak_memory_stat": [856, 858, 870, 871], "max_memory_reserv": [857, 1762, 1768], "cudamemgetinfo": 859, "memory_reserv": [861, 1762, 1768], "snapshot": [863, 1741, 1762, 1768], "large_pool": 864, "small_pool": 864, "allocated_byt": 864, "cudamalloc": [864, 1762], "reserved_byt": 864, "active_byt": 864, "inactive_split": 864, "inactive_split_byt": 864, "octob": 864, "1mb": 864, "num_alloc_retri": 864, "num_oom": 864, "assist": [864, 1763], "max_split_s": 864, "oversize_alloc": 864, "oversize_seg": 864, "abbrevi": 865, "percent": [866, 883], "msg": [867, 869, 1783, 1800], "instantan": [867, 1783], "ascii": [867, 869, 1101, 1741, 1783], "max_memory_alloc": [870, 1762, 1768], "max_memory_cach": 871, "memory_stat": [872, 1762, 1768], "seed_al": 873, "environment": 875, "total_memori": 876, "debug_mod": [880, 1631], "streamcontext": [881, 1736], "x_1": [884, 885, 886, 887, 1097, 1171, 1184, 1185, 1318, 1329, 1707], "x_2": [884, 885, 886, 887, 1097, 1171, 1184, 1185, 1318, 1329], "x_3": [884, 885, 886, 887, 1097], "3449": 884, "5447": 884, "0685": 884, "5104": [884, 1762], "1706": 884, "2259": 884, "4696": 884, "3284": 884, "9946": 884, "8209": [884, 887], "6628": 885, "0975": 885, "2680": [885, 1761], "3298": [885, 892], "4220": 885, "3885": 885, "1762": 885, "9165": 885, "6684": [885, 1007], "overflow": [886, 887, 1129, 1145, 1148, 1366, 1402, 1403, 1521, 1617, 1664, 1667, 1687, 1711, 1713, 1762, 1773, 1794], "6001": 886, "2069": 886, "1919": 886, "6727": [886, 899], "0062": 886, "4126": 886, "2129": 886, "4206": 886, "1968": [886, 1794], "1241": 886, "0238": 886, "0233": [886, 1596], "0157": 886, "0158": [886, 1688], "0065": 886, "0014": [886, 1794], "0006": 886, "8286": 887, "4890": 887, "5155": 887, "8443": 887, "1865": 887, "1752": [887, 895], "0595": 887, "1850": 887, "1571": [887, 1770, 1775], "4243": 887, "3175": 887, "8020": [887, 1521], "0423": 887, "2289": 887, "0537": 887, "0058": 887, "9780": 887, "trapezoid": [888, 1708, 1739, 1779], "360": 889, "2832": 889, "diagflat": [892, 1739, 1779], "5950": 892, "0872": 892, "4264": 892, "1064": [892, 1770], "8795": 892, "2429": 892, "1374": 892, "1029": 892, "6482": 892, "6300": 892, "5410": 893, "2934": 893, "1788": [893, 1794], "5684": 893, "0845": [893, 1657, 1770], "3986": 893, "2956": [894, 1062], "9068": 894, "1695": 894, "2094": [894, 1762], "3018": 894, "1516": 894, "9342": 894, "0854": 895, "1431": 895, "8536": 895, "0905": 895, "0360": [895, 1139], "6927": 895, "3735": 895, "4945": 895, "2631": [895, 1138, 1762], "3755": 895, "5977": 895, "8172": 895, "1065": [895, 1770], "0401": 895, "2235": [895, 1687], "7938": 895, "3081": 895, "6166": 895, "2335": 895, "0500": 895, "7336": 895, "3836": 895, "1015": 895, "emb": [896, 1627, 1658], "5393": 899, "8675": 899, "5916": 899, "6321": 899, "0967": 899, "0511": 899, "6295": 899, "8360": 899, "6973": 899, "6537": 899, "dividend": [900, 950, 953, 1608, 1714], "true_divid": [900, 1739, 1779], "3810": [900, 991], "2774": 900, "2972": 900, "3719": 900, "4637": 900, "7620": 900, "5548": 900, "5944": 900, "7438": 900, "9274": 900, "3711": 900, "9353": 900, "4605": 900, "2917": 900, "1815": [900, 1110], "0111": [900, 1646], "9805": 900, "5923": 900, "1062": 900, "4581": [900, 1069], "7759": 900, "2344": [900, 1694], "1830": 900, "0313": 900, "1908": 900, "4757": 900, "8032": 900, "2930": 900, "8113": 900, "2308": 900, "4620": [900, 1731], "6051": 900, "5676": 900, "2639": 900, "2260": 900, "4509": [900, 1083], "2086": 900, "1322": 900, "9764": 900, "9564": 900, "3484": 900, "2278": 900, "1068": [900, 1004], "4678": 900, "3938": [900, 1695], "depthwis": [903, 904, 1178, 1179, 1180], "atleast_3d": [904, 1739, 1779], "operand": [905, 1741, 1742, 1764, 1793, 1796], "notat": [905, 1216, 1637, 1742, 1770, 1799], "einstein": 905, "summat": [905, 1027, 1109, 1117, 1793], "subscript": [905, 1742], "jk": 905, "ik": [905, 1102], "za": 905, "alphabet": [905, 1331, 1789], "arrow": [905, 1791], "ki": 905, "ellipsi": [905, 1741, 1742, 1753], "fourth": 905, "whitespac": [905, 1742], "opt_einsum": [905, 1736], "_the_": 905, "bypass": [905, 1754, 1762], "disclaim": 905, "52": 905, "op1": [905, 1741], "sublist1": 905, "op2": [905, 1741], "sublist2": 905, "subslist_out": 905, "2104": 905, "7952": 905, "2433": 905, "4545": 905, "1156": 905, "2897": [905, 1770], "3918": 905, "4963": 905, "3744": 905, "9381": 905, "2685": 905, "6070": 905, "7208": 905, "8058": 905, "4419": 905, "0936": 905, "1713": 905, "4291": 905, "5802": 905, "7350": [905, 1794], "5704": 905, "4290": 905, "9323": 905, "4480": 905, "bs": 905, "bij": 905, "bjk": 905, "bik": 905, "0564": 905, "5904": 905, "2023": 905, "1271": 905, "6706": [905, 1524], "8097": 905, "8025": 905, "1183": 905, "2239": [905, 1089], "3107": 905, "5756": 905, "2354": 905, "4558": 905, "3460": 905, "5087": 905, "8530": [905, 1175], "8153": 905, "8787": 905, "3839": [905, 1727], "2112": [905, 1710], "3728": 905, "1131": [905, 1521], "0921": 905, "8305": 905, "ji": 905, "anm": 905, "bm": 905, "ba": 905, "3430": [905, 1110], "2405": 905, "4494": 905, "3311": 905, "5201": 905, "0356": 905, "4064e": 906, "8000e": 906, "3493e": 906, "5751e": 906, "1428e": 906, "5955e": 906, "9683e": 908, "1239e": 908, "0705e": 908, "set_grad_en": [909, 1739, 1779, 1801], "parenthesi": [909, 1005, 1468], "doubler": [909, 1468], "elsewher": [910, 918, 974, 986, 1020, 1022, 1023, 1026, 1054, 1118, 1151, 1666, 1735], "quant_min": [919, 920, 1531, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1547, 1548, 1549, 1550, 1553, 1554, 1557, 1559, 1560, 1570, 1572, 1573, 1574, 1575, 1576, 1577, 1581, 1739, 1784], "quant_max": [919, 920, 1531, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1547, 1548, 1549, 1550, 1553, 1554, 1557, 1559, 1560, 1570, 1572, 1573, 1574, 1575, 1576, 1577, 1581, 1739, 1784], "_max": [919, 920, 1784], "_min": [919, 920, 1784], "nearbi": [919, 920], "_int": [919, 920], "_point": [919, 920], "fake_quant": [919, 920, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1570, 1574, 1575, 1577, 1587, 1803], "2525": 919, "0466": 919, "3491": [919, 1083], "2168": [919, 1702], "5906": [919, 1794], "6258": 919, "6444": 919, "0542": 919, "0475": [919, 1794], "0486": 919, "3405": 919, "6134": [919, 1132], "6323": 919, "0552": 920, "9730": 920, "3973": 920, "0780": 920, "4000": [920, 923, 932, 941, 1302, 1592, 1643], "6000": [920, 1293, 1295, 1297, 1302, 1592, 1640, 1643], "fourier": [921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 1027, 1653, 1684, 1736], "rfft": [921, 926, 936, 940, 941, 942], "compact": [921, 922, 924, 1072, 1074, 1077, 1764, 1777, 1784], "chalf": [921, 922, 924, 926, 927, 928, 929, 930, 931, 936, 937, 938, 1739, 1779, 1799], "sm53": [921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942], "ortho": [921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 1102], "orthonorm": [921, 922, 924, 926, 927, 928, 929, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 942, 1093, 1432, 1688, 1694], "ifft": [921, 925, 926, 930, 931, 933, 934, 935, 936, 937, 938], "fftn": [922, 925, 931, 934, 942], "rfft2": [922, 937], "ifft2": [922, 934], "two_fft": [922, 924, 934, 940, 942], "check_strid": [922, 924, 925, 930, 931, 936, 937, 938, 940, 942, 1800], "nyquist": [923, 925, 933, 935, 939, 940, 941, 942], "i_1": [924, 942, 1050], "i_n": [924, 942, 971, 1050, 1702, 1728], "rfftn": [924, 928, 934, 938, 940], "ifftn": [924, 930, 935], "rearrang": [925, 932, 1174, 1262, 1263, 1388, 1389, 1753], "fftfreq": [925, 932, 941], "9000": [925, 1700], "8000": [925, 1145, 1302, 1524, 1643], "uncent": 925, "ifftshift": 925, "x_center": 925, "x_uncent": 925, "fft_uncent": 925, "fft_center": 925, "x_centered_2": 925, "ihfft": [926, 934, 935], "irfft": [926, 938, 939], "symmetri": [926, 928, 1684], "opposit": [926, 928, 1688, 1706], "transformed_dim_s": [926, 936], "0000j": [926, 933, 936, 1059, 1060, 1065, 1066, 1068, 1517, 1640], "1250": [926, 1138], "1720j": 926, "0406j": 926, "2809": 926, "6250": [926, 936, 955, 1302], "9691": 926, "hfftn": [927, 935], "last_dim_s": [927, 928, 937, 938, 1737], "ihfft2": 927, "roundtrip": [927, 928, 936, 937, 938], "ihfftn": [928, 934], "irfftn": [928, 937, 942], "fft2": [930, 940], "two_ifft": [930, 931, 935], "fftshift": 932, "hfft": 933, "6882j": 933, "1625j": 933, "hfft2": 934, "8602j": 936, "2031j": 936, "1562": 936, "3511": 936, "7812": 936, "2114": 936, "irfft2": 940, "wider": [948, 1738, 1741, 1780, 1793], "49": [948, 1085, 1761], "2500e": 948, "1000e": 948, "7656e": 948, "lfloor": [949, 954, 1158, 1163, 1164, 1165, 1178, 1179, 1180, 1197, 1218, 1219, 1243, 1244, 1245, 1301, 1302, 1303, 1304, 1316, 1385, 1604, 1684], "rfloor": [949, 954, 1158, 1163, 1164, 1165, 1178, 1179, 1180, 1197, 1218, 1219, 1243, 1244, 1245, 1301, 1302, 1303, 1304, 1316, 1385, 1604, 1684], "8166": 949, "5308": 949, "2530": 949, "2091": 949, "7000": [951, 1194, 1642], "3000": [952, 1193, 1642, 1762], "entrywis": [953, 1608], "modulu": [953, 1089, 1608], "operatornam": [954, 1065, 1066, 1067, 1068, 1085, 1093, 1166, 1167, 1173, 1210, 1211, 1217, 1241, 1281, 1299, 1642], "8750": [955, 1302], "char": [958, 1476, 1752, 1795], "parameter_and_buffer_dict": 961, "parameters_and_buff": [961, 1465], "submodule_nam": [961, 1465], "parameter_nam": [961, 1465], "mutlipl": 961, "grad_weight": [961, 1764], "detached_param": 961, "foo_": 962, "intermediate_upd": 962, "mutations_and_view": 962, "intermeid": 962, "inpt": 962, "out1": [962, 1739], "out2": [962, 1739], "f_trace": 962, "f_no_mutations_trac": 962, "f_no_mutations_and_views_trac": 962, "a_1": [962, 1050], "view_1": 962, "view_copi": [962, 1739, 1779, 1801], "view_copy_1": 962, "as_strid": [962, 1737, 1739, 1779, 1797], "writ": 962, "native_funct": [962, 1737], "yaml": [962, 1737], "argnum": [963, 964, 965, 966, 967], "aux": [963, 964, 966, 967, 968, 970], "my_loss_func": 963, "y_pred": [963, 1762], "loss_per_sampl": 963, "y_true": 963, "priorit": [965, 966, 968, 1793], "autodiff": [966, 967, 968, 1088], "jacobian_f": [966, 967], "f_x": [966, 967], "jacboian": [966, 967], "expectedx": [966, 967], "expectedi": [966, 967], "_preallocate_and_copi": 967, "stand": [968, 970, 1740, 1781, 1791], "jvp_out": 968, "num_model": 969, "l1": [969, 1210, 1211, 1281, 1356, 1400, 1442, 1451, 1770, 1775], "l2": [969, 1211, 1241, 1281, 1477, 1478, 1479, 1480, 1482, 1484, 1490, 1491, 1493, 1758], "vjpfunc": 970, "out_dim": [971, 1728, 1739, 1753, 1765], "unsuccessfulli": [971, 1728], "rummag": [971, 1728], "batched_dot": [971, 1728], "imposs": [971, 1728, 1758], "jacobian_row": [971, 1728], "get_vjp": [971, 1728], "n1": [971, 1610, 1728], "n0": [971, 1728], "batched_pow": [971, 1728], "autobatch": [971, 1728], "sparse_grad": [972, 1737, 1739], "tau": [975, 1069, 1349, 1479, 1493, 1510, 1511, 1646, 1739], "elementari": [975, 1759, 1767], "reflector": [975, 1432, 1511], "household": [975, 1069, 1432, 1511], "householder_product": [975, 1432, 1510], "gel": [975, 1075], "set_default_dtyp": 977, "set_deterministic_debug_mod": [978, 1721], "set_float32_matmul_precis": 979, "edge_ord": [983, 1739], "mathbb": [983, 1059, 1061, 1065, 1066, 1067, 1068, 1069, 1070, 1075, 1076, 1079, 1081, 1088, 1090, 1092, 1093, 1186, 1257, 1432], "rightarrow": 983, "central": [983, 1767, 1769], "interior": 983, "theorem": 983, "h_r": 983, "neighbor": [983, 1027, 1302, 1304, 1684], "x_r": 983, "approx": [983, 1689, 1767], "h_l": 983, "outermost": 983, "80": [983, 1085, 1503, 1637, 1762, 1780], "halv": 983, "coord": 983, "54": [987, 1212, 1649], "46": [987, 1648], "hann_window": [987, 1684, 1739, 1743, 1779], "hann": [988, 1649], "histogram": [990, 992, 1547, 1739, 1779, 1798], "hist": [991, 992, 1739], "bin_edg": [991, 992, 1739], "9524": 991, "leftmost": [992, 1754], "leg": 996, "triangl": [996, 1798], "hypotenus": 996, "4031": 996, "gammainc": [998, 1794], "gammaincc": [999, 1794], "index_reduce_": [1003, 1739], "realloc": 1004, "1427": 1004, "0231": 1004, "5414": 1004, "0009": 1004, "4664": [1004, 1702], "2647": 1004, "1228": 1004, "6571": 1004, "7230": 1004, "6004": 1004, "inferencemod": [1005, 1759], "bump": 1005, "_version": [1005, 1779], "multidimension": [1007, 1099, 1213], "8173": 1007, "0874": 1007, "1784": 1007, "3279": 1007, "7894": 1007, "4682": 1007, "7159": 1007, "1506": 1007, "4034": 1007, "3657": 1007, "0387": 1007, "9892": 1007, "1774": 1007, "3261": 1007, "3917": 1007, "4537": [1007, 1418], "7493": 1007, "1724": 1007, "2291": 1007, "5749": 1007, "2267": 1007, "7920": 1007, "3607": 1007, "3701": 1007, "3666": 1007, "5850": [1007, 1060], "7242": 1007, "9837": 1007, "1560": 1007, "2907": 1007, "6785": 1007, "5671": [1007, 1061], "5452": 1007, "6912": 1007, "5509": 1007, "1782": 1007, "9843": 1007, "7366": 1007, "5672": [1007, 1471], "5115": 1007, "4864": 1007, "2476": 1007, "4337": 1007, "6347": 1007, "1748": 1007, "3567": [1007, 1060], "6558": 1007, "2469": [1007, 1770], "5787": [1007, 1110], "typecheck": [1017, 1779], "mypi": [1017, 1740, 1741], "warn_alwai": 1018, "set_warn_alwai": 1018, "nonfinit": 1019, "test_el": [1021, 1739], "assume_uniqu": [1021, 1739], "0j": [1026, 1725], "nola": 1027, "envelop": 1027, "hop": [1027, 1684], "shorter": [1027, 1777, 1789], "griffin": 1027, "ieee": [1027, 1204, 1653, 1773], "tran": 1027, "assp": 1027, "vol": [1027, 1204, 1653], "pp": [1027, 1204, 1653], "236": 1027, "apr": 1027, "1984": 1027, "fft_size": 1027, "n_frame": 1027, "slide": [1027, 1163, 1164, 1165, 1197, 1243, 1244, 1245, 1301, 1341, 1371, 1372, 1373, 1414, 1593, 1594, 1684], "signal_length": 1027, "scriptmodul": [1028, 1029, 1034, 1037, 1039, 1040, 1041, 1045, 1046, 1738, 1740, 1748, 1777], "implic": [1028, 1045, 1789, 1793], "attributemodul": 1028, "names_ag": 1028, "9223372036854775807": [1028, 1458, 1750], "get_debug_st": 1029, "graphexecutorst": 1029, "_extra_fil": [1029, 1030, 1037, 1040, 1769], "save_to_buff": 1029, "add_modul": [1030, 1250], "init_weight": [1030, 1250, 1770], "buf": [1030, 1250], "20l": [1030, 1250], "1l": [1030, 1250], "5l": [1030, 1250], "syntax": [1030, 1738, 1741, 1781], "code_with_const": 1030, "constmap": 1030, "extra_repr": [1030, 1250, 1764], "get_buff": [1030, 1250], "attributeerror": [1030, 1250, 1764, 1784], "get_extra_st": [1030, 1250], "set_extra_st": [1030, 1250], "get_paramet": [1030, 1250], "net_b": [1030, 1250], "net_c": [1030, 1250], "inlined_graph": 1030, "ipu": [1030, 1250], "missing_kei": [1030, 1250], "unexpected_kei": [1030, 1250], "remove_dupl": [1030, 1250], "named_children": [1030, 1250, 1770], "conv4": [1030, 1250], "conv5": [1030, 1250], "memo": [1030, 1250], "register_backward_hook": [1030, 1250, 1422], "register_full_backward_hook": [1030, 1250, 1770], "removablehandl": [1030, 1250, 1419, 1420, 1421, 1422, 1781], "register_buff": [1030, 1250, 1738, 1740, 1764, 1770], "register_forward_hook": [1030, 1250, 1420, 1770], "with_kwarg": [1030, 1250], "fire": [1030, 1250, 1763, 1769], "register_module_forward_hook": [1030, 1250, 1770], "register_forward_pre_hook": [1030, 1187, 1250, 1421, 1770], "forward_pr": [1030, 1250], "register_module_forward_pre_hook": [1030, 1250, 1770], "register_module_full_backward_hook": [1030, 1250, 1419, 1770], "register_full_backward_pre_hook": [1030, 1250, 1770], "register_module_full_backward_pre_hook": [1030, 1250, 1770], "register_load_state_dict_post_hook": [1030, 1250], "incompatible_kei": [1030, 1250], "register_modul": [1030, 1250], "register_paramet": [1030, 1250, 1764, 1770], "register_state_dict_pre_hook": [1030, 1250], "keep_var": [1030, 1250], "finetun": [1030, 1250], "gan": [1030, 1250, 1433, 1464], "share_memori": [1030, 1250, 1772], "share_memory_": [1030, 1250, 1751, 1795], "shallow": [1030, 1187, 1250, 1298, 1299], "channels_last": [1030, 1250, 1423, 1796], "4d": [1030, 1169, 1197, 1214, 1250, 1302, 1341, 1358, 1385, 1415, 1592], "1913": [1030, 1250], "3420": [1030, 1250], "5113": [1030, 1250, 1702], "2325": [1030, 1062, 1250], "gpu1": [1030, 1250], "1914": [1030, 1250], "5112": [1030, 1250, 1762], "3741": [1030, 1250], "2382": [1030, 1139, 1250], "5593": [1030, 1250], "4443": [1030, 1250], "6122": [1030, 1250], "1150": [1030, 1250], "to_empti": [1030, 1250], "dst_type": [1030, 1250], "xpu": [1030, 1250], "set_to_non": [1030, 1250, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1762], "the_typ": 1031, "the_valu": 1031, "script_bar": 1033, "addmod": 1033, "preserved_attr": 1034, "optimize_numer": 1034, "run_frozen_optim": 1034, "scripted_modul": [1034, 1041, 1775], "frozen_modul": 1034, "modified_tensor": 1034, "mymodule2": 1034, "dump_alias_db": 1034, "pdb": [1035, 1041, 1047, 1738, 1740], "training_method": 1035, "target_typ": 1036, "refin": [1036, 1753], "testcod": [1036, 1740], "key1": 1036, "val1": 1036, "key2": 1036, "val2": 1036, "scriptfunct": [1037, 1041, 1042, 1045, 1777], "readlin": [1037, 1101, 1781], "seek": [1037, 1101, 1781, 1784], "bytesio": [1037, 1040, 1101, 1620, 1777, 1784], "rb": [1037, 1101], "extra_fil": [1037, 1040], "txt": [1037, 1040, 1781], "other_method": 1039, "lesser": [1039, 1759, 1761], "extent": [1039, 1761, 1793], "frozen_mod": 1039, "offlin": 1040, "_frames_up": 1041, "_rcb": 1041, "scriptdict": 1041, "scriptlist": 1041, "test_sum": 1041, "scripted_fn": [1041, 1738], "conv1": [1041, 1250, 1278, 1546, 1738, 1784, 1798], "conv2": [1041, 1250, 1278, 1738, 1784], "some_entry_point": 1041, "python_only_fn": 1041, "testnnmodul": 1041, "pdt_model": 1041, "scripted_model": [1041, 1781], "un": [1043, 1173, 1784], "unfus": 1043, "nb": 1043, "check_trac": [1045, 1046], "check_input": [1045, 1046, 1738], "check_toler": [1045, 1046], "_force_outplac": [1045, 1046], "_module_class": [1045, 1046], "_compilation_unit": [1045, 1046], "compilationunit": [1045, 1046], "example_kwarg_input": 1045, "trace_modul": [1045, 1738, 1741], "untrack": 1045, "checker": [1045, 1046, 1741, 1777], "diverg": [1045, 1046, 1216, 1359, 1736, 1741], "traced_foo": [1045, 1738], "example_weight": [1045, 1046], "example_forward_input": [1045, 1046], "example_inputs_is_kwarg": 1046, "method2": 1046, "example_method2_input": 1046, "weighted_kernel_sum": 1046, "use_memory_effici": 1047, "memory_effici": 1047, "scriptabl": 1047, "kaiser": [1049, 1293, 1295, 1297], "i_0": [1049, 1050, 1652, 1702, 1794], "zeroth": [1049, 1652, 1794], "out_i": 1049, "kroneck": 1050, "a_0": 1050, "a_n": 1050, "b_0": 1050, "b_1": 1050, "b_n": 1050, "k_0": [1050, 1702], "k_1": 1050, "k_n": 1050, "j_0": 1050, "j_1": 1050, "j_n": 1050, "k_t": 1050, "i_t": [1050, 1220, 1492], "b_t": 1050, "j_t": 1050, "bmatrix": 1050, "a_": [1050, 1121, 1238, 1702], "cdot": [1050, 1075, 1087, 1166, 1167, 1185, 1186, 1208, 1216, 1253, 1254, 1255, 1256, 1257, 1293, 1329, 1352, 1517, 1684, 1794, 1800], "vdot": [1050, 1097, 1098, 1739, 1779], "ddot": [1050, 1097], "kth": 1051, "full_lik": [1055, 1739, 1743, 1779], "logarithm": [1058, 1063, 1089, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1116, 1173, 1331, 1366, 1664, 1794], "gamma": [1058, 1168, 1169, 1170, 1205, 1213, 1214, 1215, 1222, 1289, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1493, 1495, 1499, 1500, 1503, 1508, 1509, 1592, 1736, 1739, 1777, 1779, 1780, 1794], "5724": [1058, 1794], "1208": [1058, 1794], "mathrlap": [1059, 1065, 1066, 1067, 1068, 1076, 1079, 1088, 1090, 1092, 1093, 1432], "qquad": [1059, 1061, 1065, 1066, 1067, 1068, 1069, 1076, 1079, 1088, 1090, 1092, 1093, 1432], "eigenvalu": [1059, 1065, 1066, 1067, 1068, 1081, 1084, 1087, 1092, 1093, 1102, 1513, 1694, 1739], "resp": [1059, 1066, 1068, 1092, 1093, 1110], "5266": 1059, "9586": 1059, "0626j": 1059, "4160": 1059, "5895": 1059, "2322": 1059, "2976j": 1059, "4928": [1059, 1702], "4692e": 1059, "8747e": 1059, "check_error": [1060, 1071, 1073, 1078, 1091, 1739], "performantli": 1060, "3792": 1060, "9831j": 1060, "8757": 1060, "5425": 1060, "6374j": 1060, "kappa": 1061, "_p": [1061, 1259], "frobeniu": [1061, 1075, 1082, 1086, 1470], "nuc": [1061, 1082, 1086, 1099, 1443, 1452, 1470], "nuclear": [1061, 1082, 1086, 1470], "sigma_1": [1061, 1075, 1084, 1087], "sigma_n": 1061, "kappa_2": 1061, "kappa_": 1061, "4142": [1061, 1086, 1470, 1517], "1623": [1061, 1082], "2426": [1061, 1086, 1470], "7071": [1061, 1645], "5917": 1061, "9941": 1062, "5132": 1062, "5681": 1062, "4653": 1062, "4507": 1062, "4119": 1062, "6163": 1062, "1073": 1062, "3957": 1062, "9666": [1062, 1338], "0840": 1062, "3357": 1062, "2139": 1062, "slogdet": [1063, 1110, 1739, 1779], "0934": 1063, "1990": [1063, 1110], "4099": [1063, 1110], "7386": [1063, 1110], "diagonaliz": [1065, 1067], "neq": [1065, 1066, 1069, 1093, 1151, 1253, 1255, 1478, 1479, 1480, 1482, 1484, 1490, 1491, 1493, 1497, 1688, 1694], "phi": [1065, 1066, 1093, 1200, 1345, 1688], "shall": [1065, 1066, 1093, 1434, 1438], "lambda_i": [1065, 1066, 1081, 1694], "lambda_j": [1065, 1066, 1694], "eigval": [1065, 1739], "9828": [1065, 1710, 1770], "3889j": 1065, "4617": 1065, "3010j": 1065, "1662": 1065, "7435j": 1065, "6139": 1065, "0562j": 1065, "1226": [1065, 1067], "5738j": [1065, 1067], "7537": [1065, 1067], "1286j": [1065, 1067], "9218": 1065, "1882": 1065, "2220j": 1065, "0270": 1065, "3867j": 1065, "7119e": 1065, "2841e": 1065, "uplo": [1066, 1068, 1694, 1739], "unitari": [1066, 1069, 1088, 1093, 1432, 1511], "eigvalsh": [1066, 1084, 1694], "9228": [1066, 1068], "2029": [1066, 1068], "0862j": [1066, 1068], "3464": [1066, 1068], "3277": [1066, 1068], "9415": [1066, 1068], "0846": 1066, "9964": 1066, "9170": 1066, "3898j": 1066, "0331j": 1066, "1062e": 1066, "5423e": 1066, "polynomi": [1067, 1068, 1506], "_n": [1067, 1068, 1070, 1432, 1764], "4576e": [1067, 1094], "5797": 1068, "4629": 1068, "1605": 1068, "3780": 1068, "1113": [1068, 1770], "7381": 1068, "h_1h_2": 1069, "h_k": 1069, "h_i": [1069, 1284], "_m": [1069, 1432], "tau_i": 1069, "8034": 1069, "4184j": 1069, "2588": 1069, "0174j": 1069, "6853": 1069, "7953j": 1069, "0790": 1069, "5620j": 1069, "6989j": 1069, "5360": 1069, "1193j": 1069, "3877": 1069, "6691j": 1069, "3512": 1069, "3024j": 1069, "4766": 1069, "5783j": 1069, "0361": [1069, 1770], "6587j": 1069, "6396": [1069, 1770], "1612j": 1069, "3693": 1069, "4481j": 1069, "aa": 1070, "pinv": [1070, 1075, 1515], "moor": [1070, 1087], "penros": [1070, 1087], "ainv": [1070, 1071, 1091, 1095], "1921e": 1070, "9073e": [1070, 1301], "5107e": 1070, "ldl": [1072, 1074], "indefinit": 1072, "ld": [1072, 1073, 1074, 1739], "sytrf": [1072, 1073], "ldl_solv": 1072, "ldl_factor_ex": [1072, 1074], "2079": [1072, 1073, 1794], "2414": [1072, 1073], "9428": [1072, 1073], "4554": [1072, 1073], "3264": [1072, 1073], "3823": [1072, 1073], "5884": [1072, 1073], "9595": [1072, 1073, 1645], "2695": [1072, 1073, 1694], "8513": [1072, 1073], "1633": [1072, 1073], "ldl_factor": 1073, "rcond": [1075, 1087, 1515, 1739], "_f": 1075, "gelsi": 1075, "gelsd": 1075, "gelss": 1075, "tridiagon": 1075, "sigma_i": [1075, 1093, 1688], "residu": [1075, 1102, 1739, 1770], "singular_valu": [1075, 1739], "lh": 1075, "0838": [1075, 1770], "2275": [1075, 1138], "3844": 1075, "5499": 1075, "1175": 1075, "9102": 1075, "0870": 1075, "6772": 1075, "7758": 1075, "5109": 1075, "4382": 1075, "3769": 1075, "1818": 1075, "3450": 1075, "0806": [1075, 1770], "3967": 1075, "3994": 1075, "1521": 1075, "1473": 1075, "9194": 1075, "0458": 1075, "6705": [1075, 1134], "1802": 1075, "4086": 1075, "5152e": 1075, "almost": [1076, 1077, 1776], "5007": 1076, "9755": 1076, "0489": 1076, "9644": [1076, 1129], "9605e": 1076, "0376e": 1076, "lu_factor_ex": [1077, 1119], "lu_unpack": [1077, 1119, 1739, 1779], "b1": 1077, "b2": [1077, 1762, 1768], "a_factor": 1077, "getrf": [1078, 1091], "adjoint": [1079, 1739, 1779, 1797, 1799], "3891": 1081, "8660": 1081, "ord": [1082, 1086, 1099, 1470, 1739, 1741, 1779], "la": [1082, 1086, 1099, 1770], "2829": 1082, "2627": 1082, "0756": 1083, "4980": 1083, "6617": 1083, "4994": 1083, "9980": 1083, "2731": 1083, "8001": 1083, "2640": 1083, "4571": 1083, "5511": 1083, "0163": [1083, 1129], "5292": 1083, "4899": 1083, "0822": 1083, "2773": [1083, 1754], "varepsilon": [1084, 1087], "finfo": [1084, 1087, 1154, 1547, 1548, 1549, 1550, 1553, 1736, 1800], "tol": [1084, 1102, 1739], "fewest": 1085, "wherea": [1085, 1145, 1688, 1741, 1800], "nd": [1085, 1773], "bc": [1085, 1780], "75000": 1085, "148": 1085, "vector_norm": [1086, 1470], "matrix_norm": [1086, 1099, 1433, 1470], "clearer": [1086, 1764, 1778], "7460": [1086, 1470], "3485": 1086, "8570e": 1086, "8480": 1086, "2361": [1086, 1470, 1471], "7417": [1086, 1470], "computation": [1087, 1767], "5495": [1087, 1138], "0979": 1087, "4092": 1087, "4132": [1087, 1651], "1143": 1087, "3662": 1087, "6374": 1087, "9294": 1087, "3269": [1087, 1770], "5745": [1087, 1682, 1683, 1723, 1724], "0382": [1087, 1139], "5922": 1087, "6759": 1087, "0600": 1087, "1933": 1087, "2090": 1087, "0903": 1087, "0817": 1087, "4752": [1087, 1687], "7124": 1087, "1631": 1087, "2272": 1087, "1356": 1087, "3933": 1087, "5023": 1087, "0308": 1087, "1725": 1087, "5216": 1087, "apinv": 1087, "5633e": 1087, "0830e": 1087, "wide": [1088, 1093, 1432, 1647, 1761, 1764, 1770], "51": [1088, 1248, 1523], "167": [1088, 1523], "68": [1088, 1523, 1738, 1740], "8571": [1088, 1523], "3943": [1088, 1523], "3314": [1088, 1523], "4286": [1088, 1523], "9029": [1088, 1523], "0343": [1088, 1523], "2857": [1088, 1523], "1714": [1088, 1523, 1770], "9429": [1088, 1523], "175": [1088, 1523], "q2": 1088, "r2": [1088, 1289], "6099e": 1088, "2158e": 1088, "logabsdet": [1089, 1739], "0032": 1089, "1219": [1089, 1607], "6690": 1089, "1161": 1089, "4053": 1089, "6218": [1089, 1699], "9273": 1089, "0082": 1089, "7576": 1089, "logdet": [1089, 1739, 1779], "linalg_slogdet": [1089, 1739, 1779], "2776": 1089, "solve_triangular": [1090, 1709], "expand_a": [1090, 1739, 1764, 1779, 1797], "rectangular": [1092, 1093, 1121, 1757], "triu_": [1092, 1739], "tril_": [1092, 1739], "full_matric": [1093, 1094, 1437, 1688, 1737, 1739], "vh": [1093, 1437, 1688, 1737, 1739], "gesvdj": [1093, 1094, 1688], "jacobi": 1093, "gesvda": [1093, 1094], "gesvd": [1093, 1094, 1688], "u_k": 1093, "v_k": 1093, "sigma_j": [1093, 1688], "eigendecomposit": 1093, "0486e": 1093, "0957e": 1093, "5139": 1094, "1087": 1094, "1066": 1094, "ind": [1095, 1096, 1739, 1765], "tensorsolv": 1095, "atensorinv": 1095, "movedim": [1096, 1136, 1739, 1765, 1779, 1797], "tensorinv": 1096, "vandermond": [1097, 1722], "pmatrix": 1097, "x_n": [1097, 1166, 1167, 1210, 1211, 1217, 1241, 1281, 1707, 1759], "125": [1097, 1268, 1722, 1739], "overlin": [1098, 1725], "3223": 1098, "2815": 1098, "1944": [1098, 1770], "counterpart": [1099, 1423, 1582, 1589, 1741, 1748, 1801, 1802], "4345": 1099, "pickle_modul": [1101, 1620], "weights_onli": 1101, "pickle_load_arg": 1101, "register_packag": 1101, "binaryio": [1101, 1620, 1781], "untrust": [1101, 1781], "unsaf": [1101, 1434, 1437, 1739, 1762, 1781], "tamper": [1101, 1781], "ram": [1101, 1762], "surg": 1101, "decod": [1101, 1293, 1294, 1295, 1423, 1781], "utf": [1101, 1777, 1781], "unicodedecodeerror": 1101, "codec": 1101, "0x": 1101, "latin1": 1101, "byte_arrai": 1101, "niter": [1102, 1513, 1689], "ortho_iparam": 1102, "ortho_fparam": 1102, "ortho_bparam": 1102, "knyazev": 1102, "knyazev2001": 1102, "stathopoulosetal2002": 1102, "converg": [1102, 1281, 1432, 1480, 1481, 1505, 1758, 1770, 1773], "promptli": 1102, "precondition": 1102, "eigenpair": 1102, "criterion": [1102, 1166, 1167, 1184, 1186, 1211, 1217, 1241, 1242, 1253, 1254, 1255, 1281, 1282, 1298, 1299, 1330, 1498, 1595, 1766], "fep": 1102, "eigenproblem": 1102, "iparam": 1102, "fparam": 1102, "bparam": 1102, "ivar": 1102, "fvar": 1102, "bvar": 1102, "tvar": 1102, "istep": 1102, "converged_count": 1102, "rerr": 1102, "force_stop": 1102, "2001": 1102, "precondit": 1102, "eigensolv": 1102, "siam": 1102, "sci": 1102, "517": 1102, "541": 1102, "epub": 1102, "doi": [1102, 1204, 1653], "1137": 1102, "s1064827500366124": 1102, "andrea": 1102, "stathopoulo": 1102, "kesheng": 1102, "2002": [1102, 1653], "2165": 1102, "2182": 1102, "s1064827500370883": 1102, "duerschetal2018": 1102, "jed": 1102, "duersch": 1102, "meiyu": 1102, "shao": 1102, "chao": 1102, "ming": 1102, "gu": 1102, "c655": 1102, "c676": 1102, "17m1129830": 1102, "log_": [1103, 1104, 1105, 1106, 1739, 1752], "7767": 1103, "3234": 1103, "2156": 1103, "2411": 1103, "5739": 1103, "5637": 1103, "4640": 1103, "1952": 1103, "4226": 1103, "5204": [1103, 1597], "5224": 1104, "9354": 1104, "7257": 1104, "1301": 1104, "2820": 1104, "0290": 1104, "1392": 1104, "8857": 1104, "6476": 1104, "0090": [1105, 1152, 1519, 1794], "9923": [1105, 1665], "5372": 1105, "2492": 1105, "8653": 1105, "7055": 1105, "7705": 1105, "2225": 1105, "8419": 1106, "8003": [1106, 1774], "9971": 1106, "5287": 1106, "0490": 1106, "2483": 1106, "0042": 1106, "9196": 1106, "3504": [1106, 1702], "logsumexp": [1107, 1739, 1752, 1779, 1794], "3069": 1107, "6867": 1107, "8731": 1107, "30000": 1107, "1269e": 1107, "log_2": 1108, "logaddexp": [1108, 1739, 1779], "limits_": 1109, "42296738": 1109, "04462666": 1109, "86278635": 1109, "94622083": 1109, "05277811": 1109, "39202815": 1109, "83525007": 1109, "84492621": 1109, "06084887": 1109, "06844475": 1109, "2611": [1110, 1699], "9254": 1110, "6213": [1110, 1770], "6843": 1110, "3242": 1110, "9665": 1110, "4539": 1110, "0887": [1110, 1794], "1336": 1110, "4025": 1110, "7089": [1110, 1193], "9032": 1110, "3031": 1110, "2589": 1116, "1135": 1116, "5481": [1116, 1129, 1770], "9566": 1116, "sum_j": [1117, 1240, 1283, 1285, 1402, 1667, 1794], "0593": [1117, 1770], "5696": 1117, "6859e": 1117, "compute_pivot": 1119, "transposit": [1119, 1706, 1793], "perm": 1119, "a_lu": 1119, "5558": 1119, "1684": 1119, "1551": 1119, "1940": 1119, "6189": 1119, "5497": 1119, "4526": 1119, "2526": 1119, "3285": 1119, "7988": 1119, "7175": 1119, "9701": 1119, "2634": 1119, "9255": 1119, "3459": 1119, "00000e": 1120, "8312": 1120, "unpack_data": [1121, 1739], "unpack_pivot": [1121, 1739], "l_": [1121, 1155, 1159, 1163, 1167, 1178, 1179, 1180, 1181, 1218, 1243], "u_": [1121, 1478, 1482], "3552": [1123, 1339], "3825": 1123, "8297": 1123, "3477": 1123, "2035": [1123, 1682, 1683, 1723, 1724], "2252": [1123, 1794], "5002": 1123, "6248": [1123, 1132], "1307": 1123, "0608": [1123, 1662], "1244": 1123, "0139": 1123, "6763": 1127, "7445": 1127, "2369": 1127, "argmax": [1127, 1158, 1243, 1371, 1372, 1373, 1697, 1737, 1739, 1779], "max_indic": 1127, "2360": 1127, "2942": 1127, "1222": [1127, 1770], "8475": 1127, "1949": 1127, "1127": 1127, "6702": 1127, "5717": 1127, "9207": 1127, "1297": 1127, "8768": 1127, "6172": 1127, "6060": 1127, "2432": 1127, "3288": 1129, "3367": 1129, "nanmean": [1129, 1739, 1779], "3841": 1129, "6320": 1129, "4254": 1129, "7384": 1129, "0131": 1129, "6549": [1129, 1645], "4279": 1129, "3350": 1129, "7694": 1129, "5600": [1129, 1302], "0842": 1129, "9580": 1129, "3623": 1129, "2343": [1129, 1754], "5085": 1129, "4599": 1129, "1807": 1129, "5219": 1130, "5212": 1130, "2202": 1130, "2505": 1130, "3982": 1130, "9948": 1130, "3518": 1130, "3131": 1130, "3180": [1130, 1793], "6993": 1130, "0436": 1130, "0438": 1130, "2270": 1130, "2751": 1130, "7303": 1130, "2192": 1130, "3321": 1130, "2488": 1130, "0778": 1130, "9510": 1130, "7048": 1130, "4742": [1130, 1715, 1794], "7125": [1130, 1669], "plot": [1131, 1761, 1798], "t_0": [1131, 1498], "t_": [1131, 1199, 1343, 1497, 1498, 1739, 1793], "s_0": 1131, "s_": [1131, 1156, 1157, 1196, 1300], "g_0": 1131, "g_": [1131, 1482, 1492, 1493], "g_i": 1131, "t_i": 1131, "0d": [1131, 1242], "xy": 1131, "50276": 1131, "cartesian_prod": [1131, 1739, 1779], "grid_x": 1131, "grid_i": 1131, "dstack": [1131, 1739, 1779, 1793], "matplotlib": [1131, 1798], "pyplot": [1131, 1798], "plt": 1131, "ys": 1131, "plot_surfac": 1131, "6750": 1132, "0857": [1132, 1712], "7197": [1132, 1731], "argmin": [1132, 1737, 1739, 1779], "min_indic": [1132, 1739], "1334": 1132, "2803": 1132, "4644": [1132, 1682, 1683, 1723, 1724], "2635": [1132, 1770], "3651": 1132, "0384": 1132, "0128": 1132, "7015": 1132, "1153": 1132, "9849": 1132, "1458": [1132, 1794], "5788": 1132, "deduc": [1134, 1793], "4851": 1134, "5037": 1134, "3633": 1134, "0760": 1134, "3362": [1136, 1137], "8437": [1136, 1137], "9627": [1136, 1137], "1727": [1136, 1137], "5173": [1136, 1137], "1398": [1136, 1137], "1321": 1138, "4370": 1138, "1289": 1138, "0527": 1138, "3077": [1138, 1678], "0881": 1138, "1259": 1138, "0284": 1138, "2015": [1139, 1757, 1770], "6087": 1139, "1494": 1139, "5491": 1139, "260": 1139, "8663": 1139, "3137": 1139, "0700": 1139, "8378": 1139, "5146": 1139, "1216": 1139, "5244": 1139, "5767": 1139, "1363": 1139, "5877": 1139, "5083": 1139, "1614": 1139, "1645": 1139, "7021": 1139, "0085": 1139, "0367": 1139, "1567": 1139, "4312": 1139, "1019": 1139, "4394": 1139, "8753": 1139, "_sampl": 1140, "thtensorrandom": 1140, "320": [1140, 1276], "0404": 1142, "6361": 1142, "multigammaln": [1143, 1794], "4028e": 1144, "1400e": 1144, "isnan": [1145, 1737, 1739, 1779, 1793], "midpoint": [1147, 1524], "weakli": [1149, 1150, 1794], "to_spars": [1150, 1665, 1739, 1774, 1779, 1793], "2262": [1152, 1519], "0682": [1152, 1519], "2866": [1152, 1519], "3940": [1152, 1519], "5x7": [1156, 1160], "7x7": [1156, 1160], "10x7": [1156, 1160], "cube": [1157, 1161, 1595], "d_": [1157, 1161, 1165, 1177, 1180, 1183, 1245, 1248, 1273, 1276, 1302, 1347, 1710, 1711, 1712, 1713], "5x7x9": [1157, 1161], "7x7x7": [1157, 1161], "7x9x8": [1157, 1161], "n_class": 1158, "cutoff": [1158, 1757], "div_valu": 1158, "head_bia": 1158, "edouard": 1158, "grave": [1158, 1173], "armand": 1158, "joulin": 1158, "moustapha": 1158, "ciss\u00e9": 1158, "grangier": 1158, "herv\u00e9": 1158, "j\u00e9gou": 1158, "imbalanc": 1158, "zipf": 1158, "law": 1158, "head": [1158, 1256, 1293, 1295, 1297, 1428], "102": 1158, "1001": 1158, "1002": 1158, "_class": 1158, "predict": [1158, 1167, 1204, 1330, 1780, 1798], "maxunpool1d": [1159, 1243, 1374, 1721], "maxunpool2d": [1160, 1198, 1244, 1375, 1721], "maxunpool3d": [1161, 1199, 1245, 1376, 1721], "selu": [1162, 1195, 1340, 1739, 1757, 1777, 1779], "n_i": [1163, 1164, 1165, 1178, 1179, 1180, 1243, 1244, 1245, 1298, 1299], "c_j": [1163, 1164, 1165, 1243, 1244, 1245], "size_averag": [1166, 1167, 1184, 1186, 1210, 1216, 1217, 1241, 1242, 1253, 1254, 1255, 1257, 1264, 1281, 1282, 1298, 1319, 1320, 1328, 1330, 1355, 1359, 1360, 1370, 1378, 1379, 1380, 1381, 1382, 1390, 1400, 1401, 1412, 1739], "unreduc": [1166, 1167, 1186, 1211, 1217, 1241, 1257, 1281, 1299], "ell": [1166, 1167, 1186, 1210, 1211, 1217, 1241, 1257, 1281, 1299], "l_1": [1166, 1167, 1186, 1210, 1211, 1217, 1241, 1257, 1281, 1299], "l_n": [1166, 1167, 1186, 1210, 1211, 1217, 1241, 1257, 1281, 1299], "w_n": [1166, 1167, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653], "y_n": [1166, 1167, 1186, 1210, 1211, 1217, 1241, 1257, 1281, 1707, 1759], "lim_": [1166, 1759], "secondli": 1166, "straight": [1166, 1349], "rescal": [1166, 1167, 1186, 1254, 1255, 1257, 1283, 1285, 1319, 1320, 1330, 1382, 1437, 1464], "nbatch": [1166, 1167], "random_": [1166, 1167, 1186, 1257, 1320, 1739, 1752, 1801], "pos_weight": [1167, 1320, 1739], "classif": [1167, 1173, 1186, 1253, 1255, 1257, 1282, 1331, 1736, 1757, 1785], "ell_c": 1167, "l_c": 1167, "p_c": 1167, "hat": [1168, 1169, 1170, 1213, 1214, 1215, 1289], "terminolog": [1168, 1169, 1170, 1289], "tempor": [1168, 1170, 1173, 1289, 1302, 1331, 1358, 1415], "5d": [1170, 1215, 1302, 1347, 1358, 1385, 1415], "volumetr": [1170, 1289, 1302, 1347, 1358, 1415, 1416, 1417], "spatio": [1170, 1289], "in1_featur": 1171, "in2_featur": 1171, "in1": [1171, 1318], "in2": [1171, 1318], "blank": [1173, 1331, 1739, 1742], "zero_infin": [1173, 1331, 1739], "connectionist": [1173, 1331], "unseg": 1173, "longest": [1173, 1459, 1461, 1462, 1766], "input_length": [1173, 1331, 1739, 1766], "target_length": [1173, 1331, 1739], "s_n": 1173, "target_n": 1173, "unbatch": [1173, 1186, 1197, 1202, 1213, 1220, 1256, 1265, 1293, 1341], "s_min": 1173, "cs": 1173, "toronto": 1173, "edu": [1173, 1595], "icml_2006": 1173, "pdf": [1173, 1268, 1653, 1759], "256": [1173, 1520, 1762, 1777], "background": [1173, 1181, 1347, 1385, 1772, 1789], "channel_shuffl": [1174, 1739, 1779], "_left": [1175, 1176, 1177, 1271, 1272, 1273, 1274, 1275, 1276, 1305, 1385], "_right": [1175, 1176, 1177, 1271, 1272, 1273, 1274, 1275, 1276, 1305, 1385], "0491": 1175, "7152": 1175, "0749": 1175, "3287": 1175, "8966": 1175, "1466": 1175, "2771": 1175, "6616": 1175, "4523": 1175, "1255": 1175, "6372": [1175, 1688], "1182": 1175, "8652": 1175, "_top": [1176, 1177, 1272, 1273, 1275, 1276, 1305, 1385], "_bottom": [1176, 1177, 1272, 1273, 1275, 1276, 1305, 1385], "6585": 1176, "4320": [1176, 1695], "8701": 1176, "4649": 1176, "_front": [1177, 1273, 1276, 1385], "_back": [1177, 1273, 1276, 1385], "_j": [1178, 1179], "star": [1178, 1179, 1180, 1741], "\u00e0": [1178, 1179, 1180, 1181, 1182, 1183, 1197, 1301], "trou": [1178, 1179, 1180, 1181, 1182, 1183, 1197, 1301], "harder": [1178, 1179, 1180, 1181, 1182, 1183, 1197, 1244, 1245, 1301], "nice": [1178, 1179, 1180, 1181, 1182, 1183, 1197, 1243, 1244, 1245, 1301, 1753, 1759, 1781], "prod_": [1179, 1180, 1182, 1183, 1196, 1300, 1484], "out_j": 1180, "deconvolut": [1181, 1182, 1183, 1325, 1326, 1327], "_pad": [1181, 1182, 1183], "dissimilar": [1184, 1210], "semi": [1184, 1210, 1757], "supervis": [1184, 1210], "vert": [1185, 1259, 1329], "_2": [1185, 1329, 1433, 1464], "ast_1": [1185, 1201], "ast_2": [1185, 1201], "ignore_index": [1186, 1257, 1330, 1382, 1739], "label_smooth": [1186, 1330, 1739], "unbalanc": [1186, 1257], "d_1": [1186, 1257, 1330, 1382], "d_2": [1186, 1257, 1330, 1382], "d_k": [1186, 1257, 1330, 1382], "_index": [1186, 1257], "logsoftmax": [1186, 1257, 1283, 1366], "nllloss": [1186, 1283, 1382, 1402, 1721], "blend": 1186, "smooth": [1186, 1211, 1281, 1286, 1330, 1491], "w_c": 1186, "truth": [1186, 1330, 1747, 1798], "rethink": [1186, 1330], "incept": [1186, 1330], "spectral_norm": [1187, 1456], "neuron": 1188, "detector": 1188, "dropout1d": [1190, 1739], "_freez": 1193, "sparseadam": 1193, "adagrad": [1193, 1747, 1789], "0251": 1193, "6902": [1193, 1521], "7172": 1193, "6431": 1193, "0748": 1193, "6969": 1193, "4970": 1193, "3448": 1193, "9685": 1193, "3677": 1193, "7265": 1193, "1685": 1193, "4362": 1193, "4004": [1193, 1669], "9400": 1193, "9124": 1193, "3616": 1193, "1151": 1193, "0309": 1193, "9315": 1193, "1655": [1193, 1762], "9897": 1193, "0635": 1193, "7895": 1193, "0364": 1193, "6778": 1193, "5803": 1193, "bag": [1194, 1339], "per_sample_weight": [1194, 1339, 1739], "embedding_sum": 1194, "8861": 1194, "4350": 1194, "0523": 1194, "1306": 1194, "5798": 1194, "0044": 1194, "7082": [1194, 1339], "2145": [1194, 1339], "6251": [1194, 1339], "6500": 1194, "satur": [1195, 1340], "alphadropout": [1195, 1313], "160": [1196, 1780], "unfold": [1197, 1739, 1779, 1797], "prod_d": [1197, 1301], "neighborhood": [1197, 1301], "col2im": [1197, 1737, 1739, 1779], "fold_param": [1197, 1301], "input_on": [1197, 1301], "output_ratio": [1198, 1199, 1342, 1343, 1739], "_random_sampl": [1198, 1199, 1739], "ben": [1198, 1199, 1342, 1343], "graham": [1198, 1199, 1342, 1343], "oh": [1198, 1199, 1342, 1343], "ow": [1198, 1199, 1342, 1343], "_ratio": [1198, 1199, 1343], "13x12": [1198, 1342], "kt": [1199, 1316, 1324, 1327, 1343, 1373], "ot": [1199, 1343], "13x12x11": [1199, 1343], "044715": [1200, 1345], "pack_sequ": [1202, 1220, 1265, 1461], "weight_ih": [1203, 1221, 1267, 1427], "weight_hh": [1203, 1221, 1267, 1427], "bias_ih": [1203, 1221, 1267], "bias_hh": [1203, 1221, 1267], "const": [1204, 1769], "homoscedast": [1204, 1344], "heteroscedast": [1204, 1344], "nix": 1204, "weigend": 1204, "1994": 1204, "icnn": 1204, "94": 1204, "orlando": 1204, "fl": 1204, "usa": [1204, 1798], "374138": 1204, "instancenorm": [1205, 1786], "shrinkag": [1206, 1287, 1350, 1405], "mobilenetv3": [1208, 1352], "_val": 1209, "l1loss": [1211, 1281, 1360], "outlier": [1211, 1281, 1784, 1785], "huber": [1211, 1281], "smoothl1loss": [1211, 1400], "insensit": 1212, "unused_argument1": 1212, "unused_argument2": 1212, "ingredi": [1213, 1214, 1215], "styliz": [1213, 1214, 1215], "rgb": [1214, 1215, 1798], "color": [1215, 1740, 1741, 1798], "log_target": [1216, 1359, 1739], "pred": [1216, 1423, 1737, 1771, 1780, 1789], "kl": [1216, 1359, 1736], "summaris": 1216, "loss_pointwis": 1216, "batchmean": [1216, 1359], "kl_loss": 1216, "mae": 1217, "hi": [1220, 1221, 1738, 1740, 1767], "f_t": [1220, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493], "hf": [1220, 1221], "g_t": [1220, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493], "ig": [1220, 1221], "hg": [1220, 1221], "o_t": 1220, "ho": [1220, 1221], "c_t": 1220, "odot": 1220, "forget": [1220, 1740, 1741], "proj_siz": [1220, 1266], "1402": 1220, "c_0": [1220, 1221], "proj": 1220, "c_n": 1220, "w_ii": 1220, "w_if": 1220, "w_ig": 1220, "w_io": 1220, "w_hi": 1220, "w_hf": 1220, "w_hg": 1220, "w_ho": 1220, "b_ii": 1220, "b_if": 1220, "b_ig": 1220, "b_io": 1220, "b_hi": 1220, "b_hf": 1220, "b_hg": 1220, "b_ho": 1220, "weight_hr_l": 1220, "_revers": 1220, "h_1": 1221, "c_1": 1221, "time_step": 1221, "_shape": 1222, "sentence_length": 1222, "lazymodulemixin": [1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235], "cls_to_becom": [1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1426], "convtranspose1d": [1229, 1325, 1721, 1786], "convtranspose3d": [1231, 1327, 1721, 1786], "instancenorm1d": [1232, 1357, 1786], "instancenorm2d": [1233, 1357, 1786], "instancenorm3d": [1234, 1357, 1786], "uninitializedparamet": [1235, 1418, 1736], "lrn": 1238, "signal_2d": 1238, "signal_4d": 1238, "output_2d": 1238, "output_4d": 1238, "x_j": [1240, 1283, 1285, 1402, 1667, 1767, 1794], "unpool": [1246, 1247, 1248], "maxpool3d": [1248, 1373, 1376, 1721, 1786], "unpooled_output": 1248, "t_destin": 1250, "lrelu": [1251, 1770], "hing": [1253, 1255], "sum_i": [1254, 1255, 1282], "nelement": [1254, 1282], "embed_dim": [1256, 1428], "num_head": [1256, 1428, 1739], "add_bias_kv": [1256, 1428], "add_zero_attn": [1256, 1428, 1739], "kdim": [1256, 1428], "vdim": [1256, 1428], "jointli": 1256, "multihead": [1256, 1295], "concat": [1256, 1739, 1779], "head_1": 1256, "head_h": 1256, "head_i": 1256, "qw_i": 1256, "kw_i": 1256, "vw_i": 1256, "loosen": 1256, "inference_mod": [1256, 1297], "nestedtensor": [1256, 1297, 1754], "key_padding_mask": [1256, 1428, 1739], "attn_mask": [1256, 1296, 1428, 1739], "attn_output_weight": [1256, 1428], "multihead_attn": 1256, "attn_output": [1256, 1428], "need_weight": [1256, 1428, 1739], "average_attn_weight": [1256, 1428, 1739], "is_caus": [1256, 1296, 1297, 1428, 1739], "e_q": 1256, "e_k": 1256, "e_v": 1256, "_head": [1256, 1293], "causal": [1256, 1295, 1296, 1297, 1428], "attn_weight": [1256, 1428], "merge_mask": 1256, "mask_typ": 1256, "merged_mask": 1256, "nll": 1257, "crossentropyloss": [1257, 1330], "num_paramet": 1258, "nchannel": 1258, "decai": [1258, 1477, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1493, 1496, 1500, 1502, 1503, 1506, 1507, 1509, 1646, 1780], "legitim": [1258, 1347, 1765], "vert_p": 1259, "fromkei": 1260, "popitem": [1260, 1779], "setdefault": [1260, 1779], "upscale_factor": [1262, 1388, 1739], "upscal": 1262, "shi": [1262, 1263], "2016": [1262, 1263, 1299], "_factor": [1262, 1263, 1302, 1303, 1304], "pixel_shuffl": [1262, 1739, 1779], "downscale_factor": [1263, 1389, 1739], "pixelshuffl": [1263, 1388, 1389], "downscal": 1263, "pixel_unshuffl": [1263, 1739, 1779], "log_input": [1264, 1390, 1739], "poisson": [1264, 1390, 1646, 1736, 1739, 1779], "stirl": [1264, 1390], "hh": [1265, 1267], "flatten_paramet": 1266, "3333333333333333": [1268, 1496, 1502, 1739], "leaki": [1268, 1395, 1757], "rectifi": [1268, 1269, 1392, 1757], "liner": 1268, "empir": 1268, "1505": 1268, "00853": 1268, "crelu": 1269, "1603": 1269, "05201": 1269, "480": 1276, "6732632423543772848170429916717": [1277, 1397], "0507009873554804934193349852946": [1277, 1397], "kaiming_norm": 1277, "kaiming_normal_": [1277, 1743, 1757], "initialis": 1277, "calculate_gain": [1277, 1743, 1757], "modulelist": [1278, 1770], "cascad": 1278, "relu1": [1278, 1418, 1546], "relu2": [1278, 1418], "swish": [1279, 1399], "coin": [1279, 1399], "explod": 1281, "cnn": [1281, 1784], "ross": 1281, "girshick": 1281, "quadrat": [1281, 1766], "huberloss": [1281, 1356], "lie": [1283, 1285, 1402, 1667, 1794, 1798], "w_j": 1284, "soft": [1287, 1349, 1405], "softshrinkag": 1287, "convert_sync_batchnorm": 1289, "r1": [1289, 1778], "sync_bn_network": 1289, "ddp_sync_bn_network": 1289, "sync_bn_modul": 1289, "d_model": [1293, 1294, 1295, 1296, 1297], "nhead": [1293, 1294, 1295, 1296, 1297], "num_encoder_lay": 1293, "num_decoder_lay": 1293, "dim_feedforward": [1293, 1295, 1297], "2048": [1293, 1295, 1297, 1547, 1762], "custom_encod": 1293, "custom_decod": 1293, "layer_norm_ep": [1293, 1295, 1297], "norm_first": [1293, 1295, 1297], "ashish": [1293, 1295, 1297], "vaswani": [1293, 1295, 1297], "noam": [1293, 1295, 1297], "shazeer": [1293, 1295, 1297], "niki": [1293, 1295, 1297], "parmar": [1293, 1295, 1297], "jakob": [1293, 1295, 1297], "uszkoreit": [1293, 1295, 1297], "llion": [1293, 1295, 1297], "jone": [1293, 1295, 1297], "aidan": [1293, 1295, 1297], "gomez": [1293, 1295, 1297], "lukasz": [1293, 1295, 1297], "illia": [1293, 1295, 1297], "polosukhin": [1293, 1295, 1297], "6010": [1293, 1295, 1297], "multiheadattent": [1293, 1295, 1297, 1784], "feedforward": [1293, 1295, 1297, 1757], "transformer_model": 1293, "word_language_model": 1293, "src_mask": [1293, 1297], "tgt_mask": [1293, 1294, 1295], "memory_mask": [1293, 1294, 1295], "src_key_padding_mask": [1293, 1296, 1297], "tgt_key_padding_mask": [1293, 1294, 1295], "memory_key_padding_mask": [1293, 1294, 1295], "_mask": [1293, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1455], "unmask": [1293, 1428], "_key_padding_mask": 1293, "generate_square_subsequent_mask": 1293, "sz": 1293, "decoder_lay": [1294, 1295], "transformerdecoderlay": 1294, "transformer_decod": 1294, "attn": [1295, 1297], "tgt_is_caus": 1295, "memory_is_caus": 1295, "encoder_lay": [1296, 1297], "enable_nested_tensor": 1296, "mask_check": 1296, "1810": 1296, "04805": 1296, "transformerencoderlay": 1296, "transformer_encod": 1296, "triplet": [1298, 1299], "x3": 1298, "balnta": [1298, 1299], "riba": [1298, 1299], "a_i": [1298, 1299, 1648], "p_i": [1298, 1299], "rm": [1298, 1299], "bf": [1298, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493], "rvert_p": [1298, 1383], "tripletmarginwithdistanceloss": [1298, 1413], "triplet_loss": [1298, 1299], "distance_funct": [1299, 1413], "l_i": 1299, "tripletmarginloss": [1299, 1412], "l_p": [1299, 1383], "pairwisedist": [1299, 1386], "penal": [1299, 1770], "distant": 1299, "anchor_id": 1299, "positive_id": 1299, "negative_id": 1299, "l_infin": 1299, "bmva": 1299, "bmvc": 1299, "paper119": 1299, "unflattened_s": 1300, "namedtensor": 1300, "namedshap": 1300, "u_1": 1300, "u_n": 1300, "u_i": 1300, "im2col": [1301, 1739, 1779], "fold": [1301, 1689, 1739, 1748, 1777, 1787, 1793], "2x3": 1301, "3x4": 1301, "inp_unf": 1301, "out_unf": 1301, "recompute_scale_factor": [1302, 1358], "bicub": [1302, 1347, 1358, 1415, 1721], "trilinear": [1302, 1347, 1358, 1415, 1721], "input_3x3": 1302, "4375": 1302, "8125": 1302, "9375": 1302, "2400": [1302, 1702], "1200": [1302, 1617, 1762], "8800": 1302, "4400": [1302, 1702], "7200": 1302, "0400": 1302, "2800": [1302, 1640], "3600": 1302, "5200": 1302, "6400": 1302, "1678": 1305, "4418": 1305, "9466": [1305, 1794], "9604": 1305, "4219": 1305, "5241": 1305, "9162": 1305, "5436": [1305, 1702], "6446": 1305, "adaptiveavgpool1d": [1306, 1786], "tripl": [1308, 1311], "adaptivemaxpool1d": 1309, "adaptivemaxpool2d": [1310, 1721], "adaptivemaxpool3d": 1311, "ill": [1312, 1773], "avgpool1d": [1314, 1786], "avgpool3d": [1316, 1721, 1786], "iT": [1316, 1324, 1327], "padt": [1316, 1324, 1327], "score": [1320, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1448, 1451, 1452, 1736], "out_padw": [1325, 1326, 1327], "out_padh": [1326, 1327], "out_padt": 1327, "cosineembeddingloss": 1328, "ctcloss": [1331, 1721], "charact": [1331, 1637, 1738, 1741, 1753, 1789], "elu": [1337, 1739, 1777, 1779, 1786], "embedding_matrix": [1338, 1339], "8490": 1338, "9625": 1338, "6753": 1338, "7761": 1338, "6108": 1338, "6246": 1338, "9751": 1338, "3618": 1338, "4161": [1338, 1793], "2419": 1338, "7383": 1338, "0237": 1338, "7794": 1338, "0528": 1338, "3385": 1338, "8612": 1338, "1867": 1338, "5384": 1338, "8720": 1338, "6262": 1338, "7471": 1338, "embeddingbag": [1339, 1721, 1784, 1786, 1799], "3397": 1339, "5545": 1339, "5893": 1339, "4386": 1339, "5882": 1339, "featurealphadropout": 1340, "gaussiannllloss": 1344, "border": 1347, "affine_grid": [1347, 1739], "extrema": 1347, "pil": [1347, 1358], "overshoot": [1347, 1358, 1415], "gumbel": [1349, 1736], "y_hard": 1349, "y_soft": 1349, "hardtanh": [1354, 1737, 1739, 1748, 1779, 1786], "hingeembeddingloss": 1355, "use_input_stat": [1357, 1739], "antialia": 1358, "anti": 1358, "pillow": [1358, 1798], "buggi": 1358, "inter_nearest": 1358, "kldivloss": 1359, "batchsiz": [1359, 1670, 1671, 1672, 1674, 1675, 1793], "leaky_relu": [1363, 1737, 1739, 1757, 1779, 1786], "localresponsenorm": 1365, "_stacklevel": [1366, 1402, 1403, 1739], "lppool1d": 1368, "lppool2d": 1369, "marginrankingloss": 1370, "max_unpool1d": [1371, 1739], "multimarginloss": 1379, "multilabelmarginloss": 1380, "multilabelsoftmarginloss": 1381, "n_0": 1383, "n_": 1383, "n_k": 1383, "everywher": [1384, 1684], "constantpad2d": 1385, "reflectionpad2d": [1385, 1721], "replicationpad2d": [1385, 1721], "t4d": 1385, "p1d": 1385, "p2d": 1385, "p3d": 1385, "pixelunshuffl": 1389, "poissonnllloss": 1390, "rrelu": [1396, 1739, 1779], "softmarginloss": 1401, "module_kwarg": 1411, "upsample_trilinear": 1416, "fo": 1416, "spatia": 1417, "mixin": [1418, 1736], "dry": 1418, "lazymlp": 1418, "lazylinear": 1418, "lazy_mlp": 1418, "mlp": [1418, 1784], "8832e": 1418, "5636e": 1418, "1598e": 1418, "5637e": 1418, "8788e": 1418, "0042e": 1418, "0019": 1418, "lazymodul": 1418, "full_mlp": 1418, "3837": [1418, 1521], "0907": 1418, "6708": 1418, "5223": 1418, "9028": 1418, "2851": 1418, "6813": 1418, "5766": 1418, "8678": 1418, "1320": 1418, "2938": 1418, "0679": [1418, 1712], "2793": [1418, 1471], "1088": 1418, "1795": 1418, "2301": 1418, "2807": 1418, "2479": 1418, "1091": 1418, "has_uninitialized_param": 1418, "initialize_paramet": 1418, "check_reduct": 1423, "optimizer_param": 1423, "loss_func": [1423, 1789], "consume_prefix_in_state_dict_if_pres": 1423, "nccl2": 1423, "dictat": [1423, 1741], "megabyt": 1423, "mb": [1423, 1762], "preemptiv": [1423, 1566, 1567], "detach_": [1423, 1739, 1752, 1786, 1793], "reentrant": 1423, "ddp_logging_data": 1423, "can_set_static_graph": 1423, "model_ddp": 1423, "_get_ddp_logging_data": 1423, "divide_by_initial_world_s": 1423, "syncbatchnorm": 1423, "exhaust": 1423, "deplet": 1423, "pariti": 1423, "discrep": [1423, 1595, 1767], "another_input": 1423, "predivid": 1423, "encode_and_decod": 1423, "encoded_tensor": 1423, "decoded_tensor": 1423, "_lstmlayer": 1427, "nnqa": 1427, "mha": 1428, "conver": 1428, "error_if_nonfinit": 1429, "clip_valu": 1430, "orthogonal_map": 1432, "use_trivi": 1432, "qq": 1432, "matrix_exp": [1432, 1739, 1779], "caylei": 1432, "thin": [1432, 1523], "manifold": 1432, "register_parametr": [1432, 1433, 1434, 1435, 1464, 1755], "orth_linear": 1432, "parametrizedlinear": [1432, 1433], "moduledict": [1432, 1433, 1740, 1770], "parametrizationlist": [1432, 1433, 1437], "_orthogon": 1432, "9332e": 1432, "n_power_iter": [1433, 1464], "sn": [1433, 1464], "discrimin": [1433, 1464], "adversari": [1433, 1464], "lipschitz": 1433, "reimplement": [1433, 1464], "_spectralnorm": 1433, "convtranspos": [1433, 1464], "snm": 1433, "0081": 1433, "amaxbackward0": 1433, "original0": [1434, 1437], "original1": [1434, 1437], "tensor_nam": [1434, 1436, 1437, 1438], "right_invers": [1434, 1437], "out_rnn": 1435, "rnn_cell": 1435, "simplic": [1437, 1790], "inbuilt": 1437, "unparametr": 1437, "rankon": 1437, "surject": 1437, "s0_sqrt": 1437, "linear_rank_on": 1437, "matrix_rank": 1437, "leave_parametr": 1438, "unparametris": 1438, "prune": [1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1793], "skeleton": 1439, "compute_mask": [1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446], "importance_scor": [1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1448, 1451, 1452], "apply_mask": [1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446], "pruned_tensor": [1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446], "default_mask": [1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446], "_orig": [1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1455], "undon": [1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1455], "unprun": [1442, 1443, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454], "indexerror": [1443, 1445], "basepruningmethod": [1444, 1450], "add_pruning_method": 1444, "pruning_typ": [1444, 1448], "unstructur": [1444, 1448], "ravel": [1444, 1739, 1779], "nonmask": 1444, "bias_mask": [1447, 1449], "pruning_method": 1448, "typeerror": [1448, 1764, 1782, 1800, 1804], "parameters_to_prun": 1448, "l1unstructur": 1448, "parameters_to_vector": 1448, "forward_pre_hook": [1450, 1770], "random_unstructur": [1450, 1455], "odict_kei": 1451, "weight_orig": 1451, "weight_mask": [1451, 1454], "columns_prun": 1453, "t_modul": [1456, 1457, 1464, 1467], "weight_norm": 1457, "sorted_indic": [1458, 1460, 1461], "unsorted_indic": [1458, 1460, 1461], "abc": [1458, 1741], "axbc": 1458, "throughout": [1458, 1767, 1770, 1784], "conform": [1458, 1770], "is_cuda": [1458, 1752, 1779, 1795], "enforce_sort": [1459, 1460, 1461], "unsort": [1459, 1460, 1624], "shortest": 1459, "uncondition": [1459, 1735, 1764, 1804], "pad_sequ": [1460, 1739, 1779], "padding_valu": [1461, 1462, 1739], "total_length": [1461, 1766], "seq_unpack": 1461, "lens_unpack": 1461, "module_cl": [1463, 1789], "5846e": 1463, "29": [1463, 1653, 1777], "8307e": 1463, "5250e": 1463, "1210e": 1463, "4677e": 1463, "5915e": 1463, "4013e": 1463, "weight_u": 1464, "decoupl": [1467, 1481], "weight_g": [1467, 1739], "weight_v": 1467, "1602": 1467, "07868": 1467, "as_tupl": [1469, 1731], "complexfloat": [1470, 1476], "0425": 1471, "7969": 1471, "2925": 1471, "7229": 1471, "2134": 1471, "0505": 1471, "1408": 1471, "0563": 1471, "0566": 1471, "0732": [1471, 1702], "0687": 1471, "1177": 1471, "2303": 1471, "1552": 1471, "6148": 1471, "6535": 1471, "8318": 1471, "3987": 1471, "9544": [1471, 1596], "6048": 1471, "7909": 1471, "120": [1473, 1798], "from_valu": 1476, "onnx_typ": 1476, "tensorprotodatatyp": 1476, "torch_c_value_with_type_float": 1476, "from_dtyp": 1476, "jit_type_bas": 1476, "safer": [1476, 1747], "onnxexportererror": [1476, 1777], "symbolicvalueerror": 1476, "onnx_compat": 1476, "scalar_nam": 1476, "typing_extens": [1476, 1738, 1740], "liter": [1476, 1739, 1742, 1753, 1781], "complexhalf": 1476, "complexdoubl": 1476, "torch_nam": 1476, "int8_t": 1476, "int64_t": 1476, "int16_t": 1476, "weight_decai": [1477, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1493, 1770], "foreach": [1477, 1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493], "1e6": 1477, "register_step_post_hook": [1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494], "removeablehandl": [1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494], "register_step_pre_hook": [1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494], "new_arg": [1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494], "new_kwarg": [1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1490, 1491, 1492, 1493, 1494], "altogeth": [1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1489, 1490, 1491, 1492, 1493, 1494], "rho": 1478, "110mm": [1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493], "4pt": [1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493], "textbf": [1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493], "theta_0": [1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493], "v_0": [1478, 1480, 1481, 1484, 1490, 1491], "leftarrow": [1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493], "u_0": [1478, 1482], "hspace": [1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493], "5mm": [1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493], "nabla_": [1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493], "theta_": [1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493], "10mm": [1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493], "v_t": [1478, 1480, 1481, 1484, 1490, 1491], "v_": [1478, 1480, 1481, 1484, 1490, 1491, 1493], "2_t": [1478, 1479, 1480, 1481, 1484, 1490, 1491], "21mm": 1478, "u_t": [1478, 1482], "theta_t": [1478, 1479, 1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493], "lr_decai": 1479, "initial_accumulator_valu": 1479, "12mm": [1479, 1490], "_sum_0": 1479, "tild": [1479, 1491], "_sum_t": 1479, "_sum_": 1479, "subgradi": 1479, "999": [1480, 1481, 1482, 1484, 1490, 1494, 1775], "amsgrad": [1480, 1481], "beta_1": [1480, 1481, 1482, 1484, 1490], "beta_2": [1480, 1481, 1482, 1484, 1490], "13mm": [1480, 1481, 1482, 1484, 1490, 1491, 1492, 1493], "textit": [1480, 1481, 1493], "m_0": [1480, 1481, 1482, 1484, 1490], "widehat": [1480, 1481, 1484, 1490], "m_t": [1480, 1481, 1482, 1484, 1490], "m_": [1480, 1481, 1482, 1484, 1490], "impair": [1480, 1481], "ungraph": [1480, 1481], "002": [1482, 1484], "t_1": 1482, "2e": [1482, 1484], "max_it": 1483, "max_ev": 1483, "tolerance_grad": 1483, "tolerance_chang": 1483, "history_s": 1483, "line_search_fn": 1483, "bfg": 1483, "minfunc": 1483, "intens": [1483, 1773], "param_byt": 1483, "strong_wolf": 1483, "reevalu": [1483, 1488, 1494, 1780], "momentum_decai": 1484, "004": 1484, "gamma_t": 1484, "psi": [1484, 1794], "mu_t": 1484, "96": 1484, "mu_": 1484, "11mm": 1484, "incorpor": [1484, 1784], "nesterov": [1484, 1493], "4e": 1484, "weightdecai": 1490, "18mm": 1490, "rho_": 1490, "6mm": 1490, "rho_t": 1490, "t_2": 1490, "l_t": 1490, "adamw": 1490, "_0": [1491, 1765, 1781], "av": 1491, "8mm": 1491, "3mm": 1491, "lectur": 1491, "hinton": 1491, "step_siz": [1492, 1509], "resili": [1492, 1773], "eta_": [1492, 1497, 1498], "etaplu": 1492, "etaminu": 1492, "gamma_": [1492, 1794], "0_": 1492, "eta_0": 1492, "i_": [1492, 1702], "15mm": [1492, 1493], "eta_t": [1492, 1497, 1498], "dampen": 1493, "subtli": 1493, "sutskev": 1493, "veloc": 1493, "lr_schedul": [1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1780], "chainabl": [1495, 1505], "081": 1495, "729": [1495, 1508], "6561": [1495, 1726], "59049": 1495, "scheduler1": [1495, 1508, 1780], "constantlr": [1495, 1508], "total_it": [1495, 1496, 1502, 1506, 1508], "scheduler2": [1495, 1508, 1780], "exponentiallr": [1495, 1508, 1780], "get_last_lr": [1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509], "print_lr": [1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509], "is_verbos": [1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509], "__dict__": [1495, 1496, 1497, 1498, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509], "last_epoch": [1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509], "mileston": [1496, 1502, 1503, 1508, 1780], "simultan": [1496, 1497, 1502, 1503, 1509, 1759, 1789], "025": [1496, 1502], "t_max": [1497, 1780], "eta_min": [1497, 1498], "anneal": [1497, 1498, 1505, 1780], "cur": [1497, 1498], "sgdr": [1497, 1498], "2k": 1497, "sole": 1497, "t_mult": 1498, "interleav": 1498, "base_lr": [1499, 1505], "max_lr": [1499, 1505], "step_size_up": 1499, "step_size_down": 1499, "scale_fn": 1499, "scale_mod": 1499, "cycle_momentum": [1499, 1505], "base_momentum": [1499, 1505], "max_momentum": [1499, 1505], "cyclic": 1499, "forth": [1499, 1722, 1735, 1783], "amplitud": [1499, 1505], "triangular2": 1499, "exp_rang": 1499, "bckenstler": 1499, "data_load": [1499, 1505, 1586, 1587, 1772], "train_batch": [1499, 1505], "get_lr": 1499, "lr_lambda": [1501, 1504], "lambda1": 1501, "lambda2": 1501, "start_factor": 1502, "end_factor": 1502, "03125": 1502, "0375": 1502, "04375": 1502, "005": [1503, 1509], "lmbda": 1504, "total_step": 1505, "steps_per_epoch": 1505, "pct_start": 1505, "anneal_strategi": [1505, 1780], "div_factor": 1505, "final_div_factor": 1505, "three_phas": 1505, "1cycl": 1505, "fastai": 1505, "unpublish": 1505, "percentag": [1505, 1646], "initial_lr": 1505, "min_lr": [1505, 1507], "1e4": 1505, "annihil": 1505, "00075": 1506, "00050": 1506, "00025": 1506, "patienc": 1507, "threshold_mod": 1507, "cooldown": 1507, "stagnat": 1507, "new_lr": 1507, "hasn": [1507, 1750, 1781], "optimum": 1507, "dynamic_threshold": 1507, "val_loss": 1507, "81": 1508, "mn": 1511, "pca": [1513, 1793], "overestim": [1513, 1689], "nathan": [1513, 1689], "halko": [1513, 1689], "gunnar": [1513, 1689], "martinsson": [1513, 1689], "tropp": [1513, 1689], "probabilist": [1513, 1689], "0909": [1513, 1689], "4061": [1513, 1689], "na": [1513, 1689], "cmath": [1517, 1739], "4142j": 1517, "4331": 1520, "2475": [1520, 1687], "6834": 1520, "2791": 1520, "1875": 1520, "5561": 1520, "4670": 1520, "5428": 1521, "5854": 1521, "5261": [1521, 1688], "1857": 1521, "2498": 1521, "1646": [1521, 1762], "0705": 1521, "0629": 1521, "2962": 1521, "0821": [1521, 1646], "1831": 1521, "type1": [1522, 1739], "type2": [1522, 1739], "2117": 1524, "9765": 1524, "1707": 1524, "4884": 1524, "5661": 1524, "5795": 1524, "5280": 1524, "9206": 1524, "stub": [1525, 1526, 1781], "calibr": [1525, 1526, 1529, 1566, 1567, 1582, 1584, 1586, 1758, 1784, 1785, 1787, 1803], "quantstub": [1527, 1784], "dequantstub": [1527, 1784], "quantwrapp": 1528, "remove_qconfig": 1529, "is_refer": 1529, "calib_data": 1530, "movingaverageminmaxobserv": [1531, 1534, 1535, 1536, 1538, 1541, 1550, 1570, 1574, 1575, 1577], "observer_kwarg": [1531, 1534], "x_out": [1531, 1534], "fake_quant_en": 1531, "observer_en": 1531, "emul": [1531, 1742, 1764], "calculate_qparam": [1532, 1547, 1548, 1552], "qscheme": [1534, 1535, 1537, 1538, 1539, 1540, 1541, 1547, 1548, 1549, 1550, 1553, 1555, 1558, 1561, 1563, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1580, 1581, 1739, 1779, 1784, 1787, 1800], "per_tensor_affin": [1535, 1539, 1547, 1548, 1549, 1570, 1574, 1591, 1592, 1593, 1594, 1784, 1787], "reduce_rang": [1535, 1539, 1540, 1541, 1547, 1548, 1549, 1550, 1553, 1555, 1570, 1574, 1577, 1739, 1784, 1785], "fusedmovingavgobsfakequant": [1536, 1537, 1538, 1575], "movingaverageperchannelminmaxobserv": [1537, 1540], "per_channel_symmetr": [1537, 1540, 1561, 1573, 1581, 1784, 1787], "per_tensor_symmetr": [1538, 1541, 1563, 1571, 1572, 1574, 1575, 1576, 1577, 1784, 1787], "histogramobserv": [1539, 1559], "ch_axi": [1540, 1550, 1553, 1558, 1580, 1739], "modules_to_fus": 1546, "fuser_func": 1546, "fuse_known_modul": 1546, "convmodul": 1546, "bnmodul": 1546, "convbnmodul": 1546, "additional_fuser_method_map": 1546, "fuse_conv_bn": [1546, 1786], "bn1": 1546, "fused_m": 1546, "upsample_r": 1547, "factory_kwarg": [1547, 1548, 1553], "1920928955078125e": [1547, 1548, 1549, 1550, 1553], "minmaxobserv": [1547, 1549, 1553, 1560, 1563, 1569, 1571, 1572, 1573, 1576, 1586, 1587, 1787], "q_": [1548, 1787], "x_orig": 1548, "reset_min_max_v": [1548, 1553], "averaging_const": [1549, 1550, 1739], "per_channel_affin": [1550, 1553, 1590, 1784, 1787], "custom_op_nam": [1551, 1554], "with_arg": [1552, 1569, 1586, 1587], "_callable_arg": 1552, "_with_arg": 1552, "foo_build": 1552, "foo_instance1": 1552, "foo_instance2": 1552, "with_callable_arg": 1552, "_with_callable_arg": 1552, "cur_tim": 1552, "get_time_func": 1552, "dan": 1552, "creation_tim": 1552, "compute_dtyp": 1554, "todo": [1554, 1584, 1586, 1587, 1803], "recordingobserv": [1556, 1571], "placeholderobserv": [1557, 1562, 1572, 1578, 1579, 1580, 1581], "perchannelminmaxobserv": [1558, 1561, 1573, 1580, 1581], "per_channel_affine_float_qparam": [1558, 1580], "obs_dict": 1565, "get_observer_state_dict": 1565, "allow_list": [1566, 1802], "observer_non_leaf_module_list": 1566, "custommodul": [1566, 1784], "propagate_qconfig_": 1568, "my_qconfig": 1569, "default_observ": 1569, "run_arg": [1582, 1588], "qconfig_spec": 1583, "quantize_fx": [1584, 1585, 1586, 1587, 1784, 1803], "graph_modul": 1584, "_remove_qconfig": 1584, "qconfig_from_prepar": 1584, "prepared_model": [1584, 1586, 1587], "xnnpack": [1584, 1748, 1784], "get_default_backend_config": [1584, 1586, 1587], "quantized_model": 1584, "fusion_pattern": 1585, "fusecustomconfig": 1585, "_equalization_config": 1586, "observedgraphmodul": [1586, 1587], "get_default_qconfig_map": [1586, 1784], "float_model": [1586, 1587, 1802], "get_default_qconfig": [1586, 1587, 1784], "linear_pattern_config": 1586, "suer": 1586, "sample_inference_data": 1586, "get_default_qat_qconfig_map": [1587, 1784], "load_weight": 1587, "train_data": 1587, "get_default_qat_qconfig": [1587, 1784], "custom_module_class_map": 1589, "quantization_schem": [1590, 1591, 1592, 1593, 1594], "int_repr": [1590, 1591, 1739, 1779], "nchw": [1592, 1798], "qx": [1592, 1593, 1594], "00001": 1592, "max_pool1d": [1593, 1739, 1779, 1786], "max_pool2d": [1594, 1739, 1779, 1786], "quasirandom": 1595, "scrambl": 1595, "sobol": 1595, "quasi": 1595, "21201": 1595, "web": 1595, "unsw": 1595, "au": [1595, 1781], "fkuo": 1595, "art": 1595, "owen": 1595, "niederreit": 1595, "xing": 1595, "466": 1595, "489": 1595, "decemb": 1595, "1998": 1595, "zh": 1595, "vychisl": 1595, "phy": 1595, "784": 1595, "802": 1595, "1967": 1595, "soboleng": 1595, "draw_base2": 1595, "base2": 1595, "fast_forward": 1595, "142": 1596, "283": 1596, "570": 1596, "359": 1596, "9894": 1596, "2503": 1597, "3525": 1597, "5673": 1597, "8237": 1597, "5781": 1597, "6879": 1597, "3816": 1597, "7249": 1597, "0998": 1597, "1436": 1601, "9966": 1601, "3426": 1601, "6366": 1601, "5954": 1601, "8929": 1601, "0923": 1601, "1719": 1601, "4709": 1601, "1996": 1601, "4595": 1607, "4314": 1607, "flat": [1610, 1653, 1739, 1754, 1777], "n2": 1610, "n3": 1610, "negat": [1613, 1741], "is_neg": [1613, 1739, 1779], "ti": 1617, "equidist": 1617, "inexact": 1617, "1234567": 1617, "1230": 1617, "vstack": [1618, 1739, 1779, 1793], "0370": 1619, "2970": 1619, "5420": 1619, "9105": 1619, "8351": 1619, "pickle_protocol": [1620, 1781], "default_protocol": 1620, "_use_new_zipfile_seri": 1620, "zipfil": [1620, 1781], "sorted_sequ": [1624, 1739], "sorter": [1624, 1739], "sorted_sequence_1d": 1624, "select_copi": [1626, 1739, 1779], "complaint": 1629, "bfloat16_3x": 1632, "denorm": [1633, 1773], "sse3": 1633, "323": 1633, "88131e": 1633, "324": 1633, "is_train": [1634, 1801], "interop": 1635, "intraop": 1636, "edgeitem": 1637, "linewidth": 1637, "sci_mod": 1637, "shamelessli": 1637, "repr": [1637, 1741], "sane": 1637, "_tensor_str": 1637, "_formatt": 1637, "12345": 1637, "1235": 1637, "excess": 1639, "24j": 1640, "8000j": 1640, "9600j": 1640, "4472": [1640, 1770], "8944j": 1640, "expit": [1641, 1794], "sym": [1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653], "2222": [1643, 1700], "4444": 1643, "8889": 1643, "4901e": 1644, "4000e": 1644, "0077e": 1644, "4923e": 1644, "waveform": [1645, 1646, 1647], "1564": 1645, "4540": 1645, "8910": 1645, "9877": 1645, "1423": [1645, 1666], "4154": 1645, "8413": [1645, 1794], "0302": 1646, "2231": 1646, "6065": 1646, "5400e": 1646, "3546e": 1646, "4788e": 1646, "8316e": 1646, "02": [1646, 1647, 1652], "3534e": 1646, "0065e": [1647, 1652], "1875e": [1647, 1652], "3937e": [1647, 1652], "2465e": [1647, 1652], "8250e": [1647, 1652], "9858e": [1647, 1652], "1365e": [1647, 1652], "8659e": [1647, 1652], "4658e": [1647, 1652], "3941e": [1647, 1652], "5400": 1648, "3376": 1648, "4200": 1648, "9136": 1648, "wit": [1648, 1738], "0955": [1648, 1649, 1651], "3455": [1648, 1649, 1651], "6545": [1648, 1649, 1651], "9045": [1648, 1649, 1651], "0800": [1649, 1650], "1876": [1649, 1650], "4601": [1649, 1650], "7700": [1649, 1650], "9723": [1649, 1650], "1679": 1650, "3979": 1650, "6821": 1650, "9121": 1650, "1170": 1651, "9698": 1651, "36358": 1653, "z_n": [1653, 1759], "48917": 1653, "2z_n": 1653, "13659": 1653, "3z_n": 1653, "01064": 1653, "4z_n": 1653, "\u03c0": 1653, "sidelob": 1653, "transact": 1653, "acoust": 1653, "speech": 1653, "84": 1653, "91": 1653, "feb": 1653, "1981": 1653, "tassp": 1653, "1163506": 1653, "heinzel": 1653, "spectrum": [1653, 1773], "dft": 1653, "comprehens": [1653, 1741, 1742, 1753, 1762, 1768, 1784], "februari": 1653, "holomet": 1653, "fnal": 1653, "gov": 1653, "gh_fft": 1653, "nutal": 1653, "general_ham": 1653, "6280e": 1653, "2698e": 1653, "1052e": 1653, "9826e": 1653, "5461": [1655, 1770], "1347": 1655, "7266": 1655, "2746": 1655, "5194": 1655, "1343": 1655, "4032": 1655, "2711": 1655, "5380": 1657, "8632": 1657, "1265": 1657, "9399": 1657, "5644": 1657, "9744": 1657, "1268": 1657, "2162": 1662, "6719": 1662, "3332": 1662, "5793": [1662, 1770], "0061": 1662, "6058": 1662, "9497": 1662, "5071": 1662, "3343": 1662, "9553": 1662, "0960": 1662, "derivati": [1663, 1665], "5901": 1665, "0183": 1665, "6146": 1665, "8061": 1665, "0112": [1665, 1677], "6302": 1665, "6479": 1665, "7874": 1665, "2056": 1665, "5641": 1665, "1716": 1665, "3323": 1665, "8723": 1665, "8951": 1665, "7904": 1665, "sparseaddmmbackward": 1665, "1394": 1665, "6415": [1665, 1694], "1639": [1665, 1762], "sparsiti": [1666, 1736, 1747, 1757], "spy": 1666, "2847": 1666, "7805": 1666, "1900": [1666, 1774], "to_dens": [1666, 1668, 1739, 1779, 1793], "3903": 1666, "x_k": 1667, "6438": 1669, "6467": 1669, "3411": 1669, "0918": 1669, "5348": 1669, "0634": 1669, "0494": 1669, "0646": 1669, "1844": 1669, "1276": 1669, "1874": 1669, "6334": 1669, "9682": 1669, "5340": 1669, "7483": 1669, "4512": 1669, "4073": 1669, "8901": 1669, "3183": 1669, "7539": 1669, "6596": 1669, "ccol_indic": [1670, 1674, 1739, 1779, 1793, 1800], "ncolblock": [1670, 1793], "array_list": [1670, 1671, 1672, 1674, 1675], "nrow": [1670, 1671, 1672, 1674, 1675, 1793], "ncol": [1670, 1671, 1672, 1674, 1675, 1793], "denses": [1670, 1671, 1672, 1674, 1675, 1793], "nrowblock": [1671, 1793], "compressed_indic": [1672, 1739, 1793], "plain_indic": [1672, 1739, 1793], "compressed_dim_s": [1672, 1793], "rdinat": 1673, "_indic": [1673, 1779, 1793], "0755": [1677, 1678], "0226": [1677, 1678], "0831": [1677, 1678], "4806": [1677, 1678], "2883": 1677, "6933": 1677, "0457": 1678, "0069": 1678, "2310": 1678, "2959": [1682, 1683, 1723, 1724], "8101": [1682, 1683, 1723, 1724], "5027": [1682, 1683, 1723, 1724], "3270": [1682, 1683, 1723, 1724], "5905": [1682, 1683, 1723, 1724], "6538": [1682, 1683, 1723, 1724, 1770], "3330": [1682, 1683, 1723, 1724], "5596": [1682, 1683, 1723, 1724], "6548": [1682, 1683, 1723, 1724], "1264": [1682, 1683, 1723, 1724], "5080": [1682, 1683, 1688, 1723, 1724, 1770], "6420": [1682, 1683, 1723, 1724], "1992": [1682, 1683, 1723, 1724], "0311": [1682, 1794], "7477": 1682, "2204": 1682, "9087": 1682, "2620": 1683, "0028": [1683, 1706], "0957": 1683, "6038": 1683, "0645": [1683, 1724], "4485": [1683, 1724], "8707": [1683, 1724], "0665": [1683, 1724], "librosa": 1684, "omega": 1684, "win": [1684, 1759], "_fft": [1684, 1739], "1133": 1687, "2958": 1687, "5475": 1687, "0569": 1687, "0737": 1687, "3429": 1687, "9138": 1687, "9337": 1687, "6864": [1687, 1710], "1132": 1687, "7892": 1687, "1003": 1687, "5688": 1687, "3637": 1687, "9906": 1687, "5197": 1687, "4598": 1687, "3708": 1687, "6217": 1687, "435": 1687, "1335": 1687, "3135": 1687, "gesdd": 1688, "conquer": 1688, "gesvdjbatch": 1688, "fortran": 1688, "\u00b9": 1688, "2364": 1688, "7752": 1688, "7201": 1688, "7394": 1688, "0504": 1688, "3371": 1688, "5296": 1688, "3550": 1688, "5569": 1688, "2445": 1688, "1414": 1688, "4027": 1688, "0287": 1688, "5434": 1688, "1946": 1688, "8833": 1688, "3679": 1688, "4296": 1688, "2890": 1688, "6604": 1688, "2717": 1688, "2618": 1688, "4234": 1688, "2481": 1688, "4733": 1688, "3289": [1688, 1775], "0315": 1688, "7806": 1688, "0199": 1688, "8766": 1688, "4809": 1688, "4054": 1688, "7600": 1688, "8611": 1688, "2594": 1688, "4373": 1688, "6531e": 1688, "a_big": [1688, 1694], "6503e": 1688, "swapax": [1691, 1739, 1779, 1797], "symint": [1692, 1693, 1737], "symfloat": [1692, 1693], "thereof": 1694, "irrespect": [1694, 1762], "7827": [1694, 1754], "4559": 1694, "7123": 1694, "8330": 1694, "4250": 1694, "8636": 1694, "2100": 1694, "1798": 1694, "7112": 1694, "5785": 1694, "1988": 1694, "6227": 1694, "1036": 1694, "1453": 1694, "7012": 1694, "7497": [1694, 1726], "3163": 1694, "2477": 1694, "1050": 1694, "1643": 1694, "9034": 1694, "0291": 1694, "3508": [1694, 1770], "1817": 1694, "2417": 1694, "3071": 1694, "5081": 1694, "6534": 1694, "4026": 1694, "5176": 1694, "1223": 1694, "0220": 1694, "3295": 1694, "7798": 1694, "4850": 1694, "5773": 1694, "5840": 1694, "1337": 1694, "0447": 1694, "6381": 1694, "0193": 1694, "4230": 1694, "1995": 1695, "4608": 1695, "7702": 1695, "4875": 1695, "9158": 1695, "5872": 1695, "6929": 1695, "6932": 1695, "argsort": [1697, 1739, 1765, 1779], "take_along_axi": [1697, 1765], "max_idx": 1697, "sorted_idx": 1697, "2027": 1698, "7687": 1698, "4412": 1698, "3856": 1698, "5930": 1698, "9859": 1698, "4722": 1698, "3366": 1698, "8986": 1699, "7279": 1699, "1745": 1699, "7156": 1699, "8257": 1699, "2553": 1699, "as_tensor": [1700, 1739, 1754, 1764, 1779, 1798, 1799, 1800], "11111": 1700, "222222": 1700, "3333333": 1700, "1111": 1700, "array_split": 1701, "i_d": 1702, "k_": 1702, "4532": 1702, "4874": 1702, "5018": 1702, "4796": [1702, 1774], "5162": 1702, "5306": 1702, "2922": 1702, "7556": 1702, "2741": 1702, "3161": 1702, "0704": 1702, "0187": 1702, "4079": 1702, "3126": 1702, "8744": 1702, "8223": 1702, "9445": 1702, "4117": 1702, "7780": 1702, "7193": 1702, "4867": 1702, "3204": 1702, "5513": 1702, "4737": [1702, 1727], "2850": 1702, "2573": 1702, "5997": 1702, "sparsebsr": 1706, "sparsecsc": 1706, "sparsebsc": 1706, "9893": 1706, "5809": 1706, "1669": 1706, "7299": 1706, "4942": [1706, 1770], "y_0": 1707, "y_1": 1707, "x_diff": 1707, "y_diff": 1707, "riemann": [1707, 1759, 1767, 1794], "badli": 1709, "cloned_coeffici": 1709, "1527": 1709, "0753": 1709, "7986": 1709, "0210": 1709, "3513": 1709, "5492": 1709, "7403": 1709, "0243": 1709, "7841": 1709, "9046": 1709, "5405": 1709, "9320": 1709, "9270": 1709, "2826": 1709, "lbrace": [1710, 1711, 1712, 1713], "rbrace": [1710, 1711, 1712, 1713], "0813": 1710, "8619": 1710, "7105": 1710, "0935": 1710, "1380": 1710, "3409": [1710, 1774], "2219": 1710, "5653": 1710, "2521": 1710, "2345": 1710, "2544": 1710, "3461": 1710, "4785": 1710, "4477": 1710, "6049": 1710, "6368": 1710, "8775": 1710, "7145": 1710, "1502": 1710, "2716": 1710, "1243": 1710, "5413": 1710, "3615": 1710, "0614": 1710, "7344": 1710, "3164": 1710, "7648": 1710, "4024": 1710, "0978": 1710, "col": [1711, 1713, 1739], "2309": 1712, "5207": 1712, "0049": 1712, "2072": 1712, "0680": 1712, "6602": 1712, "3480": 1712, "5211": 1712, "4573": 1712, "5876": 1712, "0794": [1712, 1794], "8373": 1712, "6654": 1712, "2604": 1712, "5235": 1712, "2447": 1712, "9556": 1712, "2919": 1712, "1768": 1712, "4333": 1712, "3146": [1712, 1770], "6576": 1712, "0432": 1712, "9348": [1712, 1794], "4410": 1712, "9888": 1712, "3337": 1712, "6556": 1712, "4798": 1712, "5466": 1715, "8008": 1715, "9079": 1715, "unique_consecut": [1718, 1739, 1779], "inverse_indic": [1718, 1719], "warn_onli": 1721, "alon": [1721, 1740, 1781], "put_": [1721, 1739], "index_add": [1721, 1739, 1779], "index_select": [1721, 1737, 1739, 1779, 1793], "fractionalmaxpool2d": 1721, "fractionalmaxpool3d": 1721, "reflectionpad1d": 1721, "reflectionpad3d": 1721, "replicationpad1d": 1721, "replicationpad3d": 1721, "histc": [1721, 1739, 1779], "bincount": [1721, 1739, 1779], "kthvalu": [1721, 1739, 1752, 1779], "cublasapi_reproduc": [1721, 1774], "avg_pool3d_backward_cuda": 1721, "alexandr": 1722, "theophil": 1722, "0631": 1723, "5590": 1723, "4893": 1723, "8258": 1723, "5926": 1724, "0056": 1724, "3646": 1724, "vecdot": 1725, "mi": [1726, 1727], "6116": 1726, "5772": [1726, 1794], "4606": 1726, "9120": 1726, "0786": 1726, "6623": 1726, "5772j": 1726, "9120j": 1726, "7497j": 1726, "6623j": 1726, "3839j": 1727, "2098": 1727, "6699j": 1727, "3470": 1727, "9451j": 1727, "5174": 1727, "3136j": 1727, "6699": 1727, "9451": 1727, "3136": 1727, "atleast_2d": [1730, 1739, 1779], "3139": 1731, "3898": 1731, "1657": 1731, "0383": 1731, "8785": 1731, "1089": 1731, "hubconf": 1735, "entrypoint_nam": 1735, "_resnet18": 1735, "underscor": [1735, 1753, 1789, 1799], "load_state_dict_from_url": [1735, 1749], "2gb": 1735, "relative_path_to_checkpoint": 1735, "pth": [1735, 1749, 1775], "dirnam": 1735, "5c106cde": [1735, 1749], "force_reload": 1735, "skip_valid": 1735, "trust_repo": 1735, "repo_own": 1735, "repo_nam": 1735, "torchhub": 1735, "owner": [1735, 1764, 1779, 1789, 1790], "github_token": 1735, "repo_or_dir": 1735, "mute": 1735, "resnet50_weight": 1735, "imagenet1k_v1": 1735, "download_url_to_fil": 1735, "hash_prefix": 1735, "temporary_fil": 1735, "sha256": [1735, 1749], "s3": [1735, 1749, 1776], "amazonaw": [1735, 1749, 1776], "model_dir": [1735, 1749], "check_hash": [1735, 1749], "hub_dir": [1735, 1749], "get_dir": [1735, 1749], "ext": [1735, 1749], "eight": [1735, 1749], "hash": [1735, 1739, 1741, 1749, 1779], "succinct": 1735, "set_dir": 1735, "path_to_hub_dir": 1735, "torch_hom": 1735, "xdg_cache_hom": [1735, 1762], "reiniti": 1735, "path_importer_cach": 1735, "subpackag": [1735, 1781], "offend": 1735, "classifi": [1736, 1741, 1777, 1780, 1784, 1798], "pypi": 1736, "conda": [1736, 1776], "hip": 1736, "javadoc": 1736, "uninitializedbuff": 1736, "anomali": 1736, "can_device_access_p": 1736, "current_blas_handl": 1736, "device_of": 1736, "get_arch_list": 1736, "get_device_cap": 1736, "get_device_nam": 1736, "get_device_properti": 1736, "get_gencode_flag": 1736, "get_sync_debug_mod": 1736, "ipc_collect": 1736, "memory_usag": 1736, "set_stream": 1736, "set_sync_debug_mod": 1736, "outofmemoryerror": 1736, "jiter": 1736, "sanit": 1736, "xeon": [1736, 1761], "pathwis": 1736, "exponentialfamili": 1736, "binomi": [1736, 1739, 1779], "chi2": 1736, "continuousbernoulli": 1736, "dirichlet": 1736, "fishersnedecor": 1736, "halfcauchi": 1736, "halfnorm": 1736, "kumaraswami": 1736, "lkjcholeski": 1736, "laplac": 1736, "lognorm": 1736, "lowrankmultivariatenorm": 1736, "mixturesamefamili": 1736, "multinomi": [1736, 1739, 1779], "multivariatenorm": 1736, "negativebinomi": 1736, "onehotcategor": 1736, "relaxedbernoulli": 1736, "logitrelaxedbernoulli": 1736, "relaxedonehotcategor": 1736, "studentt": 1736, "transformeddistribut": 1736, "vonmis": 1736, "weibul": 1736, "wishart": 1736, "solver": [1736, 1773], "misc": 1736, "alexnet": 1736, "pitfal": 1736, "powersgd": 1736, "remotemodul": 1736, "sampler": 1736, "mobile_optim": 1736, "model_zoo": 1736, "tensorboard": [1736, 1750, 1783], "iinfo": 1736, "unifi": [1736, 1753], "__config__": [1736, 1761], "torchdata": 1736, "torchrec": 1736, "torchserv": 1736, "torchtext": 1736, "xla": 1736, "_out": [1737, 1757, 1759, 1767], "opset": [1737, 1777, 1778, 1779], "_adaptive_avg_pool2d": [1737, 1779], "_adaptive_avg_pool2d_backward": 1737, "_log_softmax": [1737, 1779], "half_to_float": 1737, "_native_batch_norm_legit": [1737, 1779], "no_stat": 1737, "_softmax": [1737, 1779, 1794], "_to_copi": [1737, 1779], "scalartyp": 1737, "memoryformat": 1737, "start_step": 1737, "avg_pool2d": [1737, 1739, 1779, 1786], "avg_pool2d_backward": 1737, "constant_pad_nd": [1737, 1739, 1779], "convolution_backward": 1737, "bias_siz": 1737, "output_mask": 1737, "embedding_dense_backward": 1737, "num_weight": 1737, "empty_strid": [1737, 1739, 1743, 1779], "interpolation_mod": [1737, 1739], "isinf": [1737, 1739, 1779, 1793], "max_pool2d_with_indic": [1737, 1739, 1779], "max_pool2d_with_indices_backward": 1737, "native_batch_norm": [1737, 1739, 1779], "native_dropout": [1737, 1739, 1779], "native_group_norm": [1737, 1739, 1779], "hxw": [1737, 1739], "native_group_norm_backward": 1737, "rstd": 1737, "native_layer_norm": [1737, 1739, 1779], "native_layer_norm_backward": 1737, "tensor_scalar": 1737, "tensor_tensor": 1737, "scalar_tensor": [1737, 1739, 1779], "slice_scatt": [1737, 1739, 1779], "dim_intlist": 1737, "upsample_bilinear2d": [1737, 1739, 1779], "upsample_nearest2d": [1737, 1739, 1779], "convert_element_typ": [1737, 1779], "broadcast_in_dim": [1737, 1779], "bessel_i0": [1737, 1779], "bessel_i1": [1737, 1779], "bessel_j0": [1737, 1779, 1794], "bessel_j1": [1737, 1779, 1794], "cbrt": [1737, 1779], "erf_inv": [1737, 1779], "erfcx": [1737, 1779, 1794], "exp2": [1737, 1739, 1779, 1794, 1798], "isfinit": [1737, 1739, 1773, 1779], "ndtri": [1737, 1779, 1794], "spherical_bessel_j0": [1737, 1779, 1794], "fmax": [1737, 1739, 1779], "fmin": [1737, 1739, 1779], "shift_left": [1737, 1779], "shift_right_arithmet": [1737, 1779], "zeta": [1737, 1762, 1779, 1794], "broadcast_dimens": 1737, "collapse_view": [1737, 1779], "start_indic": 1737, "limit_indic": 1737, "slice_in_dim": [1737, 1779], "start_index": 1737, "limit_index": 1737, "split_dim": [1737, 1779], "outer_length": 1737, "view_of": [1737, 1779], "as_strided_scatt": [1737, 1739, 1779], "rev": [1737, 1779], "device_put": [1737, 1779], "maximum_valu": [1737, 1779], "minium_valu": [1737, 1779], "to_dtyp": [1737, 1779], "copy_to": [1737, 1779], "fft_r2c": [1737, 1779], "fft_c2c": [1737, 1779], "fft_c2r": [1737, 1779], "optimiz": 1738, "disadvantag": 1738, "gentl": 1738, "beam": 1738, "traced_bar": 1738, "myscriptmodul": 1738, "103": [1738, 1740], "939": [1738, 1740], "116": [1738, 1740], "779": [1738, 1740], "123": [1738, 1740], "my_script_modul": [1738, 1740], "ins": 1738, "pytorch_jit": 1738, "traced_fn": 1738, "disable_jit_exampl": 1738, "printer": 1738, "rv": 1738, "rv0": 1738, "rv1": 1738, "ssa": 1738, "prim": [1738, 1777, 1779], "listconstruct": 1738, "block0": 1738, "block1": 1738, "loop_in_traced_fn": 1738, "input_tupl": 1738, "fill_row_zero": 1738, "tracerwarn": 1738, "disjoint": 1738, "nr": 1738, "09115803241729736": 1738, "6782537698745728": 1738, "cpu_model": 1738, "gpu_model": 1738, "sample_input_cpu": 1738, "sample_input_gpu": 1738, "traced_cpu": 1738, "traced_gpu": 1738, "use_gpu": 1738, "__constants__": [1738, 1740], "my_module_inst": 1738, "redeclar": 1738, "nn_module_inst": 1738, "my_scripted_model": 1738, "526": [1738, 1740, 1777], "script_method": 1738, "implicitly_compiled_method": 1738, "another_forward": 1738, "unused_method": 1738, "some_fn": 1738, "ever": [1738, 1795], "some_fn2": 1738, "some_fn3": 1738, "some_fn4": 1738, "my_dict": [1738, 1740], "my_int": [1738, 1740], "my_const": 1738, "polyfil": 1738, "make_dict": 1738, "coupl": [1738, 1769, 1790], "nnc": 1738, "__and__": 1739, "__iand__": 1739, "__ilshift__": 1739, "__ior__": 1739, "__irshift__": 1739, "__ixor__": 1739, "__lshift__": 1739, "__or__": 1739, "__rshift__": 1739, "__xor__": 1739, "absolute_": 1739, "acos_": [1739, 1752], "addbmm_": 1739, "addcdiv_": 1739, "addcmul_": 1739, "addmv_": [1739, 1752], "addr_": 1739, "align_a": [1739, 1752, 1753, 1779], "align_to": [1739, 1752, 1753, 1779], "ellipsis_idx": 1739, "aminmax": [1739, 1779], "arccos_": 1739, "arccosh_": 1739, "arcsin_": [1739, 1793], "arcsinh_": 1739, "arctan2_": 1739, "arctan_": 1739, "arctanh_": 1739, "argwher": [1739, 1779], "as_strided_": 1739, "asin_": [1739, 1752, 1793], "asinh_": [1739, 1752], "atan_": [1739, 1752], "atanh_": [1739, 1752], "baddbmm_": 1739, "bernoulli_": [1739, 1752, 1801], "bitwise_and_": 1739, "bitwise_left_shift_": 1739, "bitwise_not_": [1739, 1752], "bitwise_or_": 1739, "bitwise_right_shift_": 1739, "bitwise_xor_": 1739, "broadcast_to": [1739, 1779], "cauchy_": [1739, 1752, 1801], "ceil_": [1739, 1752], "clamp_max": [1739, 1779], "clamp_max_": 1739, "clamp_min": [1739, 1779], "clamp_min_": 1739, "clip_": 1739, "conj_physical_": 1739, "copysign_": 1739, "cos_": [1739, 1752], "cosh_": [1739, 1752], "count_nonzero": [1739, 1779], "cummax": [1739, 1779], "cummin": [1739, 1779], "cumprod_": 1739, "cumsum_": 1739, "deg2rad": [1739, 1752, 1779, 1793], "deg2rad_": [1739, 1752, 1793], "outdim": 1739, "diagonal_scatt": [1739, 1779], "digamma_": [1739, 1752], "div_": [1739, 1752, 1793], "divide_": 1739, "dsplit": [1739, 1779], "element_s": [1739, 1752, 1779, 1795], "eq_": 1739, "erf_": [1739, 1752], "erfc_": [1739, 1752], "erfinv_": [1739, 1752], "exp2_": 1739, "exp_": [1739, 1752], "expm1_": [1739, 1752], "exponential_": [1739, 1752, 1801], "fill_diagonal_": 1739, "fix_": 1739, "fliplr": [1739, 1779], "flipud": [1739, 1779], "float_power_": 1739, "floor_": [1739, 1752], "floor_divide_": [1739, 1793], "fmod_": 1739, "frac_": [1739, 1752], "frexp": [1739, 1779], "gcd_": 1739, "ge_": 1739, "geometric_": [1739, 1801], "ger": [1739, 1779], "get_devic": [1739, 1752, 1779, 1793, 1795, 1796], "greater_": 1739, "greater_equal_": 1739, "gt_": 1739, "hardshrink": [1739, 1779], "heavisid": [1739, 1779], "heaviside_": 1739, "hsplit": [1739, 1779, 1797], "hypot_": 1739, "i0_": 1739, "igamma_": 1739, "igammac_": 1739, "index_fil": [1739, 1752, 1779], "index_reduc": [1739, 1779], "is_coalesc": [1739, 1779, 1793], "is_complex": [1739, 1779, 1793, 1796], "is_contigu": [1739, 1752, 1779, 1797], "is_floating_point": [1739, 1752, 1779, 1793, 1796], "is_infer": [1739, 1779], "is_same_s": [1739, 1779, 1793], "is_set_to": [1739, 1779], "is_sign": [1739, 1752, 1779, 1793], "isclos": [1739, 1779], "isneginf": [1739, 1779, 1793], "isposinf": [1739, 1779, 1793], "isreal": [1739, 1779], "istft": [1739, 1779], "kron": [1739, 1779], "lcm_": 1739, "ldexp_": 1739, "le_": 1739, "lerp_": 1739, "less_": 1739, "less_equal_": 1739, "lgamma_": 1739, "log10_": [1739, 1752], "log1p_": [1739, 1752, 1793], "log2_": [1739, 1752], "log_normal_": [1739, 1752, 1801], "logaddexp2": [1739, 1779], "logcumsumexp": [1739, 1779], "logical_and_": 1739, "logical_not_": [1739, 1752], "logical_or_": 1739, "logical_xor_": 1739, "logit_": 1739, "lt_": 1739, "masked_fil": [1739, 1752, 1779], "masked_scatt": [1739, 1779], "masked_select": [1739, 1752, 1779], "matrix_pow": [1739, 1779], "moveaxi": [1739, 1779], "msort": [1739, 1779], "multiply_": 1739, "mvlgamma_": 1739, "nan_to_num_": 1739, "nanmedian": [1739, 1752, 1779], "nansum": [1739, 1779], "narrow_copi": [1739, 1779, 1793], "ne_": 1739, "neg_": [1739, 1752, 1793], "negative_": [1739, 1793], "new_empty_strid": [1739, 1779], "new_ful": [1739, 1762, 1779], "new_on": [1739, 1779], "nextafter_": 1739, "normal_": [1739, 1752, 1757, 1762, 1801], "not_equal_": 1739, "output_nr": [1739, 1779], "polygamma_": 1739, "pow_": [1739, 1752], "q_per_channel_scal": [1739, 1779], "q_per_channel_zero_point": [1739, 1779], "q_scale": [1739, 1779], "q_zero_point": [1739, 1779], "rad2deg": [1739, 1752, 1779, 1793], "rad2deg_": [1739, 1752, 1793], "reciprocal_": [1739, 1752], "record_stream": [1739, 1762, 1779], "refine_nam": [1739, 1752, 1753, 1779], "relu_": [1739, 1786], "remainder_": 1739, "rename_": [1739, 1752, 1753], "renorm_": 1739, "reshape_a": [1739, 1754, 1779, 1797], "resize_a": [1739, 1779], "the_templ": 1739, "resize_as_sparse_": 1739, "retains_grad": [1739, 1779], "roll": [1739, 1779], "rot90": [1739, 1779], "round_": [1739, 1752], "rsqrt_": [1739, 1752], "select_scatt": [1739, 1779], "sgn_": [1739, 1752], "sigmoid_": [1739, 1752, 1786], "sign_": [1739, 1752], "sin_": [1739, 1752], "sinc_": 1739, "sinh_": [1739, 1752], "smm": [1739, 1779, 1793], "sparse_mask": [1739, 1779], "sparse_resize_": 1739, "sparse_resize_and_clear_": 1739, "split_with_s": [1739, 1779, 1797], "sqrt_": [1739, 1752], "square_": 1739, "squeeze_": [1739, 1786], "sspaddmm": [1739, 1779, 1793], "sub_": [1739, 1752, 1793], "subtract_": 1739, "sum_to_s": [1739, 1779], "swapaxes_": 1739, "swapdim": [1739, 1779, 1797], "swapdims_": 1739, "take_along_dim": [1739, 1779], "tan_": [1739, 1752], "tanh_": [1739, 1752, 1786], "tensor_indices_or_sect": 1739, "to_mkldnn": [1739, 1779], "to_padded_tensor": [1739, 1754, 1779], "to_sparse_bsc": [1739, 1779], "to_sparse_bsr": [1739, 1779, 1793], "to_sparse_csc": [1739, 1779, 1793], "true_divide_": 1739, "trunc_": [1739, 1752], "type_a": [1739, 1752, 1779], "out0": [1739, 1775], "unsafe_chunk": [1739, 1779], "unsafe_split": [1739, 1779], "unsafe_split_with_s": [1739, 1779], "unsqueeze_": [1739, 1786], "view_a": [1739, 1779, 1797], "vsplit": [1739, 1779, 1797], "xlogy_": 1739, "adaptive_avg_pool2d": [1739, 1764, 1779, 1786], "adaptive_max_pool1d_with_indic": [1739, 1764], "adaptive_max_pool2d_with_indic": 1739, "adaptive_max_pool3d_with_indic": 1739, "alpha_dropout": [1739, 1779], "assert_int_or_pair": 1739, "arg_nam": 1739, "nonetyp": [1739, 1741], "binary_cross_entropi": [1739, 1779], "binary_cross_entropy_with_logit": [1739, 1779], "celu": [1739, 1779], "dropout2d": 1739, "dropout3d": 1739, "feature_alpha_dropout": [1739, 1779], "fractional_max_pool2d_with_indic": 1739, "fractional_max_pool3d_with_indic": 1739, "gaussian_nll_loss": 1739, "glu": [1739, 1779], "gumbel_softmax": 1739, "hardsigmoid": [1739, 1779, 1786], "hardswish": [1739, 1779, 1786], "huber_loss": [1739, 1779], "instance_norm": [1739, 1779, 1786], "local_response_norm": 1739, "lp_pool1d": 1739, "lp_pool2d": 1739, "max_pool1d_with_indic": [1739, 1779], "max_pool3d_with_indic": [1739, 1779], "mish": [1739, 1779], "multi_head_attention_forward": 1739, "embed_dim_to_check": 1739, "in_proj_weight": 1739, "in_proj_bia": 1739, "bias_k": 1739, "bias_v": 1739, "dropout_p": 1739, "out_proj_weight": 1739, "out_proj_bia": 1739, "use_separate_proj_weight": 1739, "q_proj_weight": 1739, "k_proj_weight": 1739, "v_proj_weight": 1739, "static_k": 1739, "static_v": 1739, "multilabel_soft_margin_loss": 1739, "relu6": [1739, 1779, 1786], "silu": [1739, 1779], "softsign": 1739, "tanhshrink": 1739, "adaptive_avg_pool1d": [1739, 1764, 1779, 1786], "adaptive_max_pool1d": [1739, 1764, 1779], "affine_grid_gener": [1739, 1779], "alias_copi": [1739, 1779], "align_tensor": [1739, 1779], "alpha_dropout_": 1739, "as_strided_copi": [1739, 1779], "atleast_1d": [1739, 1779], "avg_pool1d": [1739, 1779, 1786], "bartlett_window": [1739, 1743, 1779], "cudnn_en": 1739, "batch_norm_backward_elemt": 1739, "invstd": 1739, "mean_di": 1739, "mean_dy_xmu": 1739, "batch_norm_backward_reduc": 1739, "input_g": 1739, "bias_g": 1739, "out3": 1739, "batch_norm_elemt": [1739, 1779], "batch_norm_gather_stat": [1739, 1779], "batch_norm_gather_stats_with_count": [1739, 1779], "batch_norm_stat": [1739, 1779], "batch_norm_update_stat": [1739, 1779], "blackman_window": [1739, 1743, 1779], "block_diag": [1739, 1779], "can_cast": [1739, 1779], "ccol_indices_copi": [1739, 1779], "celu_": 1739, "choose_qparams_optim": [1739, 1779], "n_bin": 1739, "bit_width": 1739, "col_indices_copi": [1739, 1779], "column_stack": [1739, 1779], "conv_tbc": [1739, 1779], "crow_indices_copi": [1739, 1779], "cudnn_affine_grid_gener": [1739, 1779], "cudnn_batch_norm": [1739, 1779], "exponential_average_factor": 1739, "cudnn_convolut": [1739, 1779], "cudnn_convolution_add_relu": [1739, 1779], "cudnn_convolution_relu": [1739, 1779], "cudnn_convolution_transpos": [1739, 1779], "cudnn_grid_sampl": [1739, 1779], "cudnn_is_accept": [1739, 1779], "cumulative_trapezoid": [1739, 1779], "detach_copi": [1739, 1779], "diagonal_copi": [1739, 1779], "dropout_": [1739, 1748], "embedding_renorm_": 1739, "empty_lik": [1739, 1743, 1752, 1779, 1793], "empty_quant": [1739, 1779], "anyenumtyp": 1739, "expand_copi": [1739, 1779], "fake_quantize_per_channel_affin": [1739, 1779], "fbgemm_linear_fp16_weight": [1739, 1779], "packed_weight": 1739, "fbgemm_linear_fp16_weight_fp32_activ": [1739, 1779], "fbgemm_linear_int8_weight": [1739, 1779], "col_offset": 1739, "weight_scal": 1739, "weight_zero_point": 1739, "fbgemm_linear_int8_weight_fp32_activ": [1739, 1779], "fbgemm_linear_quantize_weight": [1739, 1779], "fbgemm_pack_gemm_matrix_fp16": [1739, 1779], "fbgemm_pack_quantized_matrix": [1739, 1779], "feature_alpha_dropout_": 1739, "feature_dropout": [1739, 1779], "feature_dropout_": 1739, "frobenius_norm": [1739, 1779], "from_fil": [1739, 1779, 1795], "fused_moving_avg_obs_fake_qu": [1739, 1779], "observer_on": 1739, "fake_quant_on": 1739, "running_min": 1739, "running_max": 1739, "per_row_fake_qu": 1739, "symmetric_qu": 1739, "has_bias": 1739, "gru_cel": [1739, 1779], "w_ih": 1739, "w_hh": 1739, "hamming_window": [1739, 1743, 1779], "histogramdd": [1739, 1779], "hspmm": [1739, 1779, 1793], "indices_copi": [1739, 1779], "is_autocast_cpu_en": [1739, 1779], "is_autocast_en": [1739, 1779], "is_grad_en": [1739, 1779], "is_vulkan_avail": [1739, 1779], "isin": [1739, 1779], "kaiser_window": [1739, 1779], "lstm_cell": [1739, 1779], "meshgrid": [1739, 1779], "miopen_batch_norm": [1739, 1779], "miopen_convolut": [1739, 1779], "miopen_convolution_add_relu": [1739, 1779], "miopen_convolution_relu": [1739, 1779], "miopen_convolution_transpos": [1739, 1779], "miopen_depthwise_convolut": [1739, 1779], "miopen_rnn": [1739, 1779], "weight_stride0": 1739, "dropout_st": 1739, "out4": 1739, "mkldnn_adaptive_avg_pool2d": [1739, 1779], "mkldnn_convolut": [1739, 1779], "mkldnn_linear_backward_weight": 1739, "bias_defin": 1739, "mkldnn_max_pool2d": [1739, 1779], "mkldnn_max_pool3d": [1739, 1779], "save_mean": 1739, "save_invstd": 1739, "native_channel_shuffl": [1739, 1779], "native_norm": [1739, 1779, 1793], "norm_except_dim": [1739, 1779], "nuclear_norm": [1739, 1779], "pairwise_dist": [1739, 1779], "permute_copi": [1739, 1779], "promote_typ": [1739, 1779, 1800], "quantize_per_channel": [1739, 1779, 1784], "quantize_per_tensor_dynam": [1739, 1779, 1784], "quantized_batch_norm": [1739, 1779], "quantized_gru_cel": [1739, 1779], "packed_ih": 1739, "packed_hh": 1739, "col_offsets_ih": 1739, "col_offsets_hh": 1739, "scale_ih": 1739, "scale_hh": 1739, "zero_point_ih": 1739, "zero_point_hh": 1739, "quantized_lstm_cel": [1739, 1779], "quantized_max_pool1d": [1739, 1779], "quantized_max_pool2d": [1739, 1779], "quantized_rnn_relu_cel": [1739, 1779], "quantized_rnn_tanh_cel": [1739, 1779], "rand_lik": [1739, 1743, 1762, 1779, 1801], "randint_lik": [1739, 1743, 1779, 1801], "randn_lik": [1739, 1743, 1779, 1801], "randperm": [1739, 1743, 1779, 1801], "result_typ": [1739, 1779], "scalar1": 1739, "scalar2": 1739, "rnn_relu": [1739, 1779], "rnn_relu_cel": [1739, 1779], "rnn_tanh": [1739, 1779], "rnn_tanh_cel": [1739, 1779], "row_indices_copi": [1739, 1779], "row_stack": [1739, 1779], "rrelu_": 1739, "rsub": [1739, 1779], "searchsort": [1739, 1779], "segment_reduc": [1739, 1779], "selu_": 1739, "slice_copi": [1739, 1779], "sparse_bsc_tensor": [1739, 1779, 1793], "sparse_bsr_tensor": [1739, 1779, 1793], "sparse_compressed_tensor": [1739, 1779, 1793], "sparse_csc_tensor": [1739, 1779, 1793], "sparse_csr_tensor": [1739, 1779, 1793], "split_copi": [1739, 1779], "split_with_sizes_copi": [1739, 1779], "squeeze_copi": [1739, 1779], "std_mean": [1739, 1752, 1779], "t_copi": [1739, 1779], "threshold_": 1739, "transpose_copi": [1739, 1779], "trapz": [1739, 1779], "tril_indic": [1739, 1743, 1779], "triu_indic": [1739, 1743, 1779], "unbind_copi": [1739, 1779], "unfold_copi": [1739, 1779], "unsqueeze_copi": [1739, 1779], "values_copi": [1739, 1779], "vander": [1739, 1743, 1779], "var_mean": [1739, 1752, 1779], "view_as_complex_copi": [1739, 1779], "view_as_real_copi": [1739, 1779], "_nn": 1739, "adaptive_max_pool2d": [1739, 1779], "conv_depthwise3d": [1739, 1779], "cross_entropy_loss": [1739, 1779], "input_scal": 1739, "elu_": 1739, "flatten_dense_tensor": [1739, 1779], "random_sampl": 1739, "gelu_": 1739, "hardsigmoid_": [1739, 1786], "hardswish_": 1739, "hardtanh_": [1739, 1786], "leaky_relu_": 1739, "log_sigmoid": [1739, 1779], "mish_": 1739, "mkldnn_linear": [1739, 1779], "mkldnn_reorder_conv2d_weight": [1739, 1779], "mkldnn_reorder_conv3d_weight": [1739, 1779], "nll_loss2d": [1739, 1779], "nll_loss_nd": [1739, 1779], "reflection_pad3d": [1739, 1779], "relu6_": 1739, "rrelu_with_nois": [1739, 1779], "rrelu_with_noise_": 1739, "silu_": 1739, "slow_conv3d": [1739, 1779], "slow_conv_dilated2d": [1739, 1779], "slow_conv_dilated3d": [1739, 1779], "slow_conv_transpose2d": [1739, 1779], "slow_conv_transpose3d": [1739, 1779], "softshrink": [1739, 1779], "thnn_conv2d": [1739, 1779], "unflatten_dense_tensor": [1739, 1779], "upsample_bicubic2d": [1739, 1779], "scales_h": 1739, "scales_w": 1739, "upsample_linear1d": [1739, 1779], "upsample_nearest1d": [1739, 1779], "upsample_nearest3d": [1739, 1779], "scales_d": 1739, "upsample_trilinear3d": [1739, 1779], "fft_fftfreq": [1739, 1779], "fft_fftshift": [1739, 1779], "fft_hfft2": [1739, 1779], "fft_hfftn": [1739, 1779], "fft_ifftshift": [1739, 1779], "fft_ihfft2": [1739, 1779], "fft_ihfftn": [1739, 1779], "fft_rfftfreq": [1739, 1779], "_linalg": 1739, "linalg_cross": [1739, 1779], "linalg_det": [1739, 1779], "linalg_diagon": [1739, 1779], "eigvec": 1739, "linalg_ldl_factor": [1739, 1779], "linalg_ldl_factor_ex": [1739, 1779], "linalg_ldl_solv": [1739, 1779], "linalg_lu": [1739, 1779], "linalg_lu_factor": [1739, 1779], "linalg_lu_factor_ex": [1739, 1779], "linalg_lu_solv": [1739, 1779], "linalg_matmul": [1739, 1779], "linalg_matrix_exp": [1739, 1779], "linalg_matrix_pow": [1739, 1779], "linalg_multi_dot": [1739, 1779], "linalg_norm": [1739, 1779], "linalg_pinv": [1739, 1779], "linalg_solve_ex": [1739, 1779], "linalg_solve_triangular": [1739, 1779], "linalg_vand": [1739, 1779], "linalg_vecdot": [1739, 1779], "linalg_vector_norm": [1739, 1779], "_nest": 1739, "nested_to_padded_tensor": [1739, 1779], "_spars": 1739, "sparse_sampled_addmm": [1739, 1779], "_special": 1739, "special_airy_ai": [1739, 1779], "special_bessel_j0": [1739, 1779], "special_bessel_j1": [1739, 1779], "special_bessel_y0": [1739, 1779], "special_bessel_y1": [1739, 1779], "special_chebyshev_polynomial_t": [1739, 1779], "special_chebyshev_polynomial_u": [1739, 1779], "special_chebyshev_polynomial_v": [1739, 1779], "special_chebyshev_polynomial_w": [1739, 1779], "special_digamma": [1739, 1779], "special_entr": [1739, 1779], "special_erf": [1739, 1779], "special_erfc": [1739, 1779], "special_erfcx": [1739, 1779], "special_erfinv": [1739, 1779], "special_exp2": [1739, 1779], "special_expit": [1739, 1779], "special_expm1": [1739, 1779], "special_gammainc": [1739, 1779], "special_gammaincc": [1739, 1779], "special_gammaln": [1739, 1779], "special_hermite_polynomial_h": [1739, 1779], "special_i0": [1739, 1779], "special_i1": [1739, 1779], "special_laguerre_polynomial_l": [1739, 1779], "special_legendre_polynomial_p": [1739, 1779], "special_log1p": [1739, 1779], "special_log_ndtr": [1739, 1779], "special_log_softmax": [1739, 1779], "special_logit": [1739, 1779], "special_logsumexp": [1739, 1779], "special_modified_bessel_i0": [1739, 1779], "special_modified_bessel_i1": [1739, 1779], "special_modified_bessel_k0": [1739, 1779], "special_modified_bessel_k1": [1739, 1779], "special_multigammaln": [1739, 1779], "special_ndtr": [1739, 1779], "special_ndtri": [1739, 1779], "special_polygamma": [1739, 1779], "special_psi": [1739, 1779], "special_round": [1739, 1779], "special_scaled_modified_bessel_k0": [1739, 1779], "special_scaled_modified_bessel_k1": [1739, 1779], "special_shifted_chebyshev_polynomial_t": [1739, 1779], "special_shifted_chebyshev_polynomial_u": [1739, 1779], "special_shifted_chebyshev_polynomial_v": [1739, 1779], "special_shifted_chebyshev_polynomial_w": [1739, 1779], "special_sinc": [1739, 1779], "special_softmax": [1739, 1779], "special_spherical_bessel_j0": [1739, 1779], "special_xlog1pi": [1739, 1779], "special_xlog": [1739, 1779], "special_zeta": [1739, 1779], "tval": 1739, "is_accept": 1739, "rect": 1739, "grad_mod": 1739, "magic": [1739, 1742], "__complex__": 1739, "__float__": 1739, "__int__": 1739, "hex": [1739, 1741, 1779], "__hex__": 1739, "oct": [1739, 1779], "__oct__": 1739, "divmod": [1739, 1741, 1779], "chr": [1739, 1741, 1779], "int_float": 1739, "float_int": 1739, "fab": [1739, 1779], "int_int": 1739, "float_float": 1739, "complex_complex": 1739, "int_complex": 1739, "complex_int": 1739, "float_complex": 1739, "complex_float": [1739, 1795], "scalar_scalar": 1739, "int_to_int": 1739, "modf": [1739, 1779], "mathremaind": [1739, 1779], "programm": [1740, 1741], "tn": 1740, "subtyp": 1740, "an_error": 1740, "noreturn": [1740, 1741], "classvar": [1740, 1741], "anystr": [1740, 1741], "nomin": 1740, "newtyp": [1740, 1741], "tup": [1740, 1741], "emptydatastructur": 1740, "my_list": 1740, "aug_add_x": 1740, "inc": [1740, 1741], "__new__": [1740, 1742], "assign_x": [1740, 1741], "polymorph": 1740, "sum_pair": 1740, "red": [1740, 1741], "green": [1740, 1741], "enum_fn": [1740, 1741], "my_variable_nam": 1740, "top_level_method": 1740, "told": 1740, "other_help": 1740, "ten": [1740, 1798], "my_paramet": 1740, "my_submodul": 1740, "tuple_or_list": 1740, "a_tupl": 1740, "de": [1740, 1781, 1784], "is_script": [1740, 1741, 1779], "unsupported_linear_op": 1740, "is_trac": [1740, 1741], "univers": 1740, "a_dict": 1740, "some_dict": 1740, "delimit": [1741, 1742], "tstype": 1741, "tsmoduletyp": 1741, "tsalltyp": 1741, "tsmetatyp": 1741, "tsprimitivetyp": 1741, "tsstructuraltyp": 1741, "tsnominaltyp": 1741, "myclass": [1741, 1781], "printabl": [1741, 1781], "sortabl": 1741, "nevertheless": [1741, 1791], "inc_first_el": 1741, "cpufloattyp": 1741, "tstupl": 1741, "tsnamedtupl": 1741, "tslist": 1741, "tsdict": 1741, "tsoption": 1741, "tsunion": 1741, "tsfutur": 1741, "tsrref": 1741, "keytyp": 1741, "tensortyp": 1741, "mytupl": 1741, "scripted_inc": 1741, "_annotatednamedtupl": 1741, "_namedtupleannot": 1741, "_unannotatednamedtupl": 1741, "mistak": [1741, 1766], "nameerror": 1741, "remedi": 1741, "tsbuiltinclass": 1741, "tscustomclass": 1741, "tsenum": 1741, "tstensor": 1741, "subtensor": [1741, 1764, 1804], "subwithtorchfunct": 1741, "script_g": 1741, "tsclassdef": 1741, "methoddefinit": 1741, "__torch__": [1741, 1777], "class2": 1741, "tsenumdef": 1741, "tsenumtyp": 1741, "memberidentifi": 1741, "intenum": 1741, "intflag": 1741, "basecolor": 1741, "compli": [1741, 1781], "classbodydefinit": 1741, "notabl": 1741, "moduleobj": 1741, "testmodul": 1741, "mymodel": [1741, 1758, 1772], "dosometh": 1741, "strateg": 1741, "congruent": 1741, "python3": 1741, "unannot": 1741, "python3annot": 1741, "paramannot": 1741, "returnannot": 1741, "funcormethodbodi": 1741, "mypyannot": 1741, "localvarannot": 1741, "setval": 1741, "moduletyp": [1741, 1781], "classidentifi": 1741, "instanceattridentifi": 1741, "offset_": 1741, "tsstructualtyp": 1741, "grammar": 1741, "chapter": [1741, 1767], "floattyp": 1741, "inttyp": 1741, "stringtyp": 1741, "devicetyp": 1741, "bullet": 1741, "tupletyp": 1741, "listtyp": 1741, "enclosur": 1741, "parenth_form": 1741, "list_displai": 1741, "dict_displai": 1741, "legal": 1741, "stringliter": 1741, "floatnumb": 1741, "expression_list": 1741, "list_comprehens": 1741, "comp_for": 1741, "target_list": 1741, "or_expr": 1741, "key_datum_list": 1741, "dict_comprehens": 1741, "key_datum": 1741, "ongo": [1741, 1777, 1784, 1789], "enclos": 1741, "datum": [1741, 1803], "attributeref": 1741, "slice_list": 1741, "slice_item": 1741, "proper_slic": 1741, "argument_list": 1741, "desugar": 1741, "u_expr": 1741, "tightli": [1741, 1770], "m_expr": 1741, "a_expr": 1741, "shift_expr": 1741, "and_expr": 1741, "xor_expr": 1741, "comp_oper": 1741, "__lt__": 1741, "__contains__": 1741, "or_test": 1741, "and_test": 1741, "not_test": 1741, "conditional_express": 1741, "starred_item": 1741, "expression_stmt": 1741, "starred_express": 1741, "assignment_express": 1741, "assignment_stmt": 1741, "augmented_assignment_stmt": 1741, "augtarget": 1741, "augop": 1741, "annotated_assignment_stmt": 1741, "raise_stmt": 1741, "assert_stmt": 1741, "return_stmt": 1741, "del_stmt": 1741, "pass_stmt": 1741, "print_stmt": 1741, "break_stmt": 1741, "continue_stmt": 1741, "if_stmt": 1741, "while_stmt": 1741, "for_stmt": 1741, "with_stmt": 1741, "with_item": 1741, "__enter__": 1741, "suppress": [1741, 1788], "tuple_stmt": 1741, "getattr_stmt": 1741, "hasattr_stmt": 1741, "zip_stmt": 1741, "iterable1": 1741, "iterable2": 1741, "enumerate_stmt": 1741, "_log": 1741, "add_stat_valu": 1741, "sugaredvalu": 1741, "unrecogn": 1741, "honor": 1741, "__abs__": 1741, "bytearrai": 1741, "delattr": 1741, "exec": 1741, "__index__": 1741, "frozenset": 1741, "isint": 1741, "issubclass": [1741, 1764], "ndigit": 1741, "setattr": 1741, "__import__": [1741, 1781], "notimpl": [1741, 1742, 1764], "rpc_sync": [1741, 1779, 1789, 1790, 1791], "synonym": 1741, "_fork": [1741, 1761], "deatil": 1741, "_wait": [1741, 1761], "lexic": 1742, "indent": 1742, "coroutin": 1742, "__del__": [1742, 1759], "__bytes__": 1742, "__format__": 1742, "__hash__": 1742, "__slots__": 1742, "metaclass": 1742, "mro": 1742, "__r": 1742, "__": 1742, "await": [1742, 1789], "nonloc": 1742, "bytesliter": 1742, "imagnumb": 1742, "parenthes": 1742, "ifs": 1742, "compound": 1742, "exc_typ": 1742, "exc_valu": 1742, "eye_": [1743, 1757], "dirac_": [1743, 1757], "orthogonal_": [1743, 1757, 1770], "adaptivelogsoftmaxwithloss": 1743, "enable_grad": [1743, 1801], "overload_nam": 1745, "handi": [1745, 1759, 1762], "spotti": 1745, "googl": 1745, "colab": [1745, 1781], "ns": [1745, 1785], "keynam": 1745, "alias_analysi": 1745, "conserv": [1745, 1747, 1762], "op_nam": 1745, "opoverload": 1745, "div_cpu": 1745, "born": 1747, "citizen": 1747, "afterthought": 1747, "unlock": 1747, "intuit": 1747, "alik": 1747, "grai": 1747, "systemat": 1747, "onboard": 1747, "maskedarrai": 1747, "masked_tensor": 1747, "optimize_for_mobil": 1748, "blocklist": [1748, 1781], "mobileoptimizertyp": 1748, "conv_bn_fus": 1748, "correspondingli": 1748, "prepack": [1748, 1779], "insert_fold_prepack_op": 1748, "arm": [1748, 1784], "remove_dropout": 1748, "hoist": 1748, "hoist_conv_packed_param": 1748, "vulkan": 1748, "vulkan_automatic_gpu_transf": 1748, "freeze_modul": 1748, "script_modul": 1748, "optimization_blocklist": 1748, "preserved_method": 1748, "metal": [1748, 1771], "recursivescriptmodul": [1748, 1775], "load_url": 1749, "infrequ": 1750, "window_s": 1750, "max_sampl": 1750, "cap": 1750, "_monitor": 1750, "data_value_t": 1750, "eventhandlerhandl": 1750, "register_event_handl": 1750, "unregist": [1750, 1777], "unregister_event_handl": 1750, "tensorboardeventhandl": 1750, "writer": [1750, 1770, 1798], "summarywrit": [1750, 1798], "shared_memori": 1751, "abruptli": 1751, "get_all_sharing_strategi": 1751, "get_sharing_strategi": 1751, "set_sharing_strategi": 1751, "new_strategi": 1751, "abnorm": [1751, 1772], "fatal": [1751, 1772], "forev": [1751, 1763], "asap": 1751, "queue_2": 1751, "x_clone": 1751, "segfault": [1751, 1773], "shm_open": 1751, "mmap": 1751, "prone": [1751, 1772], "destructor": [1751, 1791], "seriou": [1751, 1762], "torch_shm_manag": 1751, "unnot": 1751, "spawncontext": 1751, "has_nam": 1752, "is_shar": [1752, 1795], "is_spars": [1752, 1779, 1793, 1795], "is_sparse_csr": [1752, 1779, 1795], "is_tensor": [1752, 1793], "unifies_names_from_input_tensor": 1752, "ndimens": 1752, "position": [1752, 1753], "unnam": [1752, 1753], "misalign": 1752, "inher": 1752, "collaps": 1752, "disappear": 1752, "img": [1753, 1798], "renamed_img": 1753, "coexist": 1753, "wildcard": [1753, 1781], "scale_channel": 1753, "more_img": 1753, "named_tensor": 1753, "named_img": 1753, "flat_img": 1753, "named_flat_img": 1753, "unflattened_img": 1753, "unflattened_named_img": 1753, "grad_loss": 1753, "8107": 1753, "6357": 1753, "0783": 1753, "untest": 1753, "rename_map": 1753, "greedili": 1753, "unment": 1753, "49152": 1753, "datastructur": 1754, "seamless": 1754, "nested_tensor": 1754, "nt": 1754, "vein": 1754, "as_nested_tensor": 1754, "irregular": 1754, "indistinguish": 1754, "2286": 1754, "4842": 1754, "6745": [1754, 1794], "0658": 1754, "1247": 1754, "4078": 1754, "8083": 1754, "2871": 1754, "5559": 1754, "9885": 1754, "4074": 1754, "4855": 1754, "0733": 1754, "8285": 1754, "6858": 1754, "7030": 1754, "3481": 1754, "0236": 1754, "fake_grad": 1754, "6862": 1754, "1282": 1754, "1031": 1754, "0464": 1754, "3276": 1754, "9967": 1754, "0054": 1754, "8972": 1754, "9174": 1754, "4995": 1754, "8546": 1754, "7194": 1754, "2918": 1754, "1846": 1754, "8793": 1754, "5183": 1754, "6447": 1754, "8009": 1754, "8468": 1754, "9832": 1754, "5272": 1754, "pt_infer": 1754, "pt_larg": 1754, "pt_small": 1754, "bitwidth": [1755, 1770, 1784], "asymmetr": [1755, 1784, 1787], "gain": 1757, "sacrific": [1757, 1762], "normalis": 1757, "constant_": 1757, "ones_": 1757, "zeros_": 1757, "dirac": 1757, "xavier_uniform_": 1757, "glorot": 1757, "bengio": 1757, "fan": 1757, "_in": 1757, "xavier_normal_": [1757, 1770], "kaiming_uniform_": 1757, "fan_in": 1757, "delv": 1757, "surpass": 1757, "he": 1757, "_mode": 1757, "fan_out": 1757, "trunc_normal_": 1757, "redrawn": 1757, "sax": 1757, "2013": 1757, "sparse_": 1757, "marten": 1757, "walkthrough": 1758, "clip_grad_value_": 1758, "optimizer2": 1758, "batch_per_it": 1758, "iters_to_accumul": 1758, "num_proc": 1758, "grad_param": 1758, "grad_norm": 1758, "scaled_grad_param": 1758, "inv_scal": 1758, "optimizer0": 1758, "optimizer1": 1758, "output0": 1758, "model0": 1758, "model1": 1758, "loss0": 1758, "loss1": 1758, "imped": 1758, "poor": [1758, 1759], "dp_model": 1758, "alter": [1758, 1764], "imported_funct": 1758, "mymm": 1758, "myfloat32func": 1758, "fwd_output": 1758, "cleaner": 1759, "mapsto": 1759, "educ": 1759, "_save": 1759, "_saved_self": 1759, "_saved_result": 1759, "convex": 1759, "concav": 1759, "togglabl": 1759, "drawback": 1759, "0011": 1759, "dirti": 1759, "hogwild": 1759, "train_fn": 1759, "graphtask": 1759, "copyslic": 1759, "mutex": 1759, "gotten": 1759, "curiou": 1759, "\u2102": 1759, "yj": 1759, "holomorph": 1759, "theori": 1759, "homomorph": 1759, "mathematician": 1759, "im": 1759, "studi": [1759, 1783], "beauti": 1759, "somewhat": [1759, 1762, 1793], "counterintuit": 1759, "0906": 1759, "4835": 1759, "audio": [1759, 1798], "\u211d": 1759, "z_": [1759, 1794], "_output": 1759, "vj": 1759, "selfdeletingtempfil": 1759, "tmp_dir": 1759, "uuid": 1759, "uuid4": 1759, "temp_fil": 1759, "forbidden": 1759, "savedtensor": 1759, "_raw_saved_": 1759, "_raw_saved_self": 1759, "save_on_disk_threshold": 1759, "tensor_or_sctf": 1759, "_saved_oth": 1759, "4th": 1760, "backcompat": 1760, "broadcast_warn": 1760, "userwarn": 1760, "compute_z": 1761, "w_z": 1761, "w_y": 1761, "tbb": 1761, "aten_thread": 1761, "omp": 1761, "mkl_thread": 1761, "bla": 1761, "mkldnn_cpu_runtim": 1761, "use_mkldnn": 1761, "use_tbb": 1761, "use_openmp": 1761, "ON": [1761, 1768, 1769], "set_num_interop_thread": 1761, "get_num_interop_thread": 1761, "set_num_thread": 1761, "get_num_thread": 1761, "omp_num_thread": 1761, "mkl_num_thread": 1761, "1024": [1761, 1762], "e5": 1761, "oversubscript": 1761, "spread": 1762, "cuda2": [1762, 1768], "a_ful": 1762, "10240": 1762, "b_full": 1762, "ab_ful": 1762, "7277": 1762, "ab_tf32": 1762, "016": 1762, "ga100": 1762, "1747": 1762, "relative_error": 1762, "0022": 1762, "ab_fp32": 1762, "0031": 1762, "000039": 1762, "7x": 1762, "toggl": 1762, "globalcontext": 1762, "setallowtf32cubla": 1762, "setallowtf32cudnn": 1762, "bench_gemm_transform": 1762, "allow_fp16_reduc": 1762, "4048": 1762, "1634": 1762, "4056": 1762, "1670": 1762, "1661": 1762, "4080": 1762, "1664": 1762, "1658": 1762, "1651": 1762, "4104": 1762, "1677": 1762, "1674": 1762, "4128": 1762, "1796": [1762, 1770], "2519": 1762, "5096": 1762, "2144": 1762, "2149": 1762, "2766": 1762, "5120": 1762, "2142": 1762, "9728": 1762, "3875": 1762, "5779": 1762, "6182": 1762, "9656": 1762, "setallowfp16reductioncubla": 1762, "instabl": 1762, "test_matmul_cuda": 1762, "setallowbf16reductioncubla": 1762, "start_ev": 1762, "elapsed_time_m": 1762, "exploit": 1762, "paragraph": [1762, 1767], "initial_grad": 1762, "memory_alloc": [1762, 1768], "empty_cach": [1762, 1768], "memory_snapshot": [1762, 1768], "memcheck": 1762, "pytorch_no_cuda_memory_cach": [1762, 1768], "option2": 1762, "value2": 1762, "max_split_size_mb": 1762, "borderlin": 1762, "unlimit": 1762, "memory_summari": 1762, "resort": [1762, 1767, 1781], "roundup_power2_divis": 1762, "cudacachingalloc": 1762, "ineffici": [1762, 1784], "1280": 1762, "1536": 1762, "1792": 1762, "256mb": 1762, "512mb": 1762, "1gb": 1762, "knob": 1762, "roundup_bypass_threshold_mb": 1762, "garbage_collection_threshold": 1762, "reclaim": 1762, "release_cached_block": 1762, "unfavor": 1762, "cuda_runtime_api": 1762, "iostream": 1762, "fpic": 1762, "my_malloc": 1762, "cout": 1762, "endl": [1762, 1769], "my_fre": 1762, "cudafre": 1762, "cudapluggablealloc": 1762, "new_alloc": 1762, "lru": 1762, "geometri": 1762, "1023": 1762, "varieti": [1762, 1790], "use_pytorch_kernel_cach": 1762, "pytorch_kernel_cache_path": 1762, "store_tru": 1762, "disable_cuda": 1762, "assess": 1762, "cudagetdevicecount": 1762, "cuinit": 1762, "pytorch_nvml_based_cuda_check": 1762, "nvml": 1762, "nvmldevicegetcount_v2": 1762, "poison": 1762, "aforement": [1762, 1772], "train_load": 1762, "x_cpu": 1762, "x_gpu": 1762, "x_cpu_long": 1762, "y_cpu": 1762, "y_gpu": 1762, "y_cpu_long": 1762, "new_tensor": 1762, "overus": 1762, "cudagraphlaunch": 1762, "elid": 1762, "versatil": 1762, "static_input": 1762, "static_output": 1762, "realist": 1762, "sophist": [1762, 1780], "violat": [1762, 1765], "prohibit": [1762, 1775], "virtual": 1762, "d_in": 1762, "d_out": 1762, "640": 1762, "static_target": 1762, "static_y_pr": 1762, "static_loss": 1762, "real_input": 1762, "real_target": 1762, "refil": 1762, "dag": 1762, "rejoin": 1762, "cuda_work": 1762, "nsight": 1762, "reorgan": 1762, "graphabl": 1762, "illeg": 1762, "needlessli": 1762, "econom": 1762, "static_out_1": 1762, "g1_workload": 1762, "static_in_1": 1762, "static_out_2": 1762, "g2_workload": 1762, "static_in_2": 1762, "real_data_1": 1762, "real_data_2": 1762, "occasion": [1762, 1793], "29500": [1763, 1782, 1789, 1790], "grad0": 1763, "grad1": 1763, "bucket1": 1763, "bucket0": 1763, "hurt": 1763, "kick": [1763, 1789, 1790], "earliest": 1763, "unreadi": 1763, "absent": 1763, "hpp": 1763, "processgroupgloo": 1763, "processgroupmpi": 1763, "_sync_param": 1763, "autograd_hook": 1763, "prepare_for_backward": 1763, "_after_": 1763, "optimize_ddp": 1763, "mark_dirti": 1764, "mark_non_differenti": [1764, 1765], "set_materialize_grad": 1764, "differenc": 1764, "linearfunct": 1764, "grad_bia": 1764, "mulconst": 1764, "mycub": [1764, 1765], "grad_dx": [1764, 1765], "my_cub": [1764, 1765], "input_featur": 1764, "output_featur": 1764, "duck": [1764, 1781], "__array_function__": 1764, "nep": 1764, "0018": 1764, "scalartensor": 1764, "handled_funct": 1764, "mandat": 1764, "ensure_tensor": 1764, "metadatatensor": 1764, "__add__": 1764, "subtensor2": 1764, "othersubtensor": 1764, "loggingtensor": 1764, "permiss": 1764, "_metadata": 1764, "ndata": 1764, "ret": [1764, 1789], "ministri": 1764, "silli": 1764, "superclass": 1764, "troublesom": 1764, "face": [1764, 1781, 1798], "_get_overridable_funct": 1764, "overriden": 1764, "get_overridable_funct": [1764, 1804], "func_dict": 1764, "nn_func": 1764, "labori": 1764, "_get_testing_overrid": 1764, "get_testing_overrid": [1764, 1804], "override_dict": 1764, "dummy_add": 1764, "get_ignored_funct": [1764, 1804], "custom_vjp": 1765, "custom_jvp": 1765, "to_numpi": 1765, "numpysort": 1765, "ind_inv": 1765, "_1": [1765, 1781], "numpytak": 1765, "numpy_sort": 1765, "saniti": 1765, "ggx": 1765, "generate_vmap_rul": 1765, "vmappabl": 1765, "x_bdim": 1765, "ind_bdim": 1765, "ind_inv_bdim": 1765, "expanded_x": 1765, "expanded_ind": 1765, "expanded_ind_inv": 1765, "new_dim": 1765, "logical_dim": 1765, "maybe_expand_bdim_at_front": 1765, "pseudocod": 1765, "rapidli": 1766, "abridg": 1766, "total_loss": 1766, "extrud": 1766, "phenomenon": 1766, "plenti": 1766, "bptt": 1766, "repackag": 1766, "nm": 1766, "blow": 1766, "elf": 1766, "grep": 1766, "run_model": 1766, "recoveri": 1766, "data_parallel": 1766, "pad_packed_sequ": 1766, "padded_input": 1766, "packed_input": 1766, "packed_output": 1766, "my_lstm": 1766, "dp_m": 1766, "padding_input": 1766, "ur": 1767, "ui": [1767, 1798], "rewritten": 1767, "j_f": 1767, "stori": 1767, "calculu": 1767, "cw": 1767, "bigger": 1767, "articl": 1767, "58eb23378f2a376565a66ac32c93a316c45b6131": 1767, "l99": 1767, "l105": 1767, "ds_dx": 1767, "compute_gradi": 1767, "ds_dy": 1767, "conj_w_d": 1767, "w_d": 1767, "d_idx": 1767, "albeit": 1767, "wonder": 1767, "amd": 1768, "dialect": 1768, "portabl": 1768, "rocmdoc": 1768, "programming_guid": 1768, "hip_api_guid": 1768, "cuda_vers": 1768, "cudaruntimegetvers": 1768, "cudadrivergetvers": 1768, "hip_vers": 1768, "hipruntimegetvers": 1768, "hipdrivergetvers": 1768, "11000": 1768, "use_rocm": 1768, "rocm_vers": 1768, "40300": 1768, "cmake": [1768, 1776], "drocm_force_enable_gpu_assert": 1768, "addglobalcallback": 1769, "recordfunct": 1769, "ivalu": 1769, "threadlocaldebuginfo": 1769, "debuginfoguard": 1769, "recordfunctioncallback": 1769, "onfunctionent": 1769, "onfunctionexit": 1769, "needsinput": 1769, "samplingprob": 1769, "enablerecordfunct": 1769, "cerr": 1769, "broader": [1769, 1801], "inject": 1769, "setapiusagehandl": 1769, "setapiusagelogg": 1769, "event_nam": 1769, "c10_log_api_usage_onc": 1769, "my_api": 1769, "_log_api_usage_onc": 1769, "archiv": 1769, "bundl": 1769, "artifact": [1769, 1781], "akin": 1769, "jpeg": 1769, "camera": [1769, 1798], "setexportmoduleextrafileshook": 1769, "extrafilesmap": 1769, "producer_info": 1769, "getenv": 1769, "getsourc": 1769, "precompil": 1769, "pyc": 1769, "loos": 1769, "elabor": 1770, "tpu": 1770, "mylinear": 1770, "sample_input": 1770, "0413": 1770, "2057": 1770, "0597": 1770, "8247": 1770, "1045": 1770, "4299": 1770, "5457": 1770, "4793": 1770, "3634": 1770, "8525": 1770, "6749": 1770, "l0": [1770, 1775], "bignet": 1770, "big_net": 1770, "dynamicnet": 1770, "dynamic_net": 1770, "2051": 1770, "7601": 1770, "1963": 1770, "4354": 1770, "6598": 1770, "4446": 1770, "4628": 1770, "8774": 1770, "6848": 1770, "5458": 1770, "4647": 1770, "5310": 1770, "0609": 1770, "0940": 1770, "1266": 1770, "0623": 1770, "0550": 1770, "5317": 1770, "5562": 1770, "4028": 1770, "6942": 1770, "0140": 1770, "0329": 1770, "1160": 1770, "0434": 1770, "3889": 1770, "1613": 1770, "6340": 1770, "3887": 1770, "9979": 1770, "0767": 1770, "3526": 1770, "8756": 1770, "5847": 1770, "6016": 1770, "1608": 1770, "0829": 1770, "6338": 1770, "9239": 1770, "6943": 1770, "5034": 1770, "0268": 1770, "4489": 1770, "9403": 1770, "2509": 1770, "5052": 1770, "3088": 1770, "4951": 1770, "3381": 1770, "5166": 1770, "boilerpl": [1770, 1781], "beginn": 1770, "examples_nn": 1770, "polynomial_modul": 1770, "teach": 1770, "0013": [1770, 1794], "0030": 1770, "0008": 1770, "modalmodul": 1770, "6614": 1770, "2669": 1770, "0617": 1770, "4519": 1770, "two_layer_net_optim": 1770, "blitz": 1770, "neural_networks_tutori": 1770, "autograd_tutori": 1770, "new_net": 1770, "runningmean": 1770, "1041": 1770, "0647": 1770, "1515": 1770, "m_load": 1770, "unserialized_th": 1770, "statefulmodul": 1770, "param3": 1770, "param_list": 1770, "parameterlist": 1770, "param_dict": 1770, "parameterdict": 1770, "buffer1": 1770, "buffer2": 1770, "buffer3": 1770, "0322": 1770, "9066": 1770, "1409": 1770, "4852": 1770, "6949": 1770, "2911": 1770, "1044": 1770, "4202": 1770, "1953": 1770, "5299": 1770, "8747": 1770, "6289": 1770, "4898": 1770, "6434": 1770, "5187": 1770, "0346": 1770, "4077": 1770, "4324": 1770, "7022": 1770, "3915": 1770, "6176": 1770, "6062": 1770, "5992": 1770, "4452": 1770, "2843": 1770, "3710": 1770, "3947": 1770, "saving_loading_model": 1770, "what_is_state_dict": 1770, "skip_init": 1770, "skip_param_init": 1770, "forward_hook": 1770, "backward_hook": 1770, "new_grad_input": 1770, "gi": 1770, "5059": 1770, "8158": 1770, "2390": 1770, "0043": 1770, "addmmbackward": 1770, "forward_pre_hook_handl": 1770, "5752": 1770, "7421": 1770, "forward_hook_handl": 1770, "0980": 1770, "4666": 1770, "0256": 1770, "4497": 1770, "5046": 1770, "combat": 1770, "benefici": 1770, "shader": 1771, "mps_devic": 1771, "yourfavoritenet": 1771, "a3c": 1772, "set_start_method": 1772, "simplequeu": 1772, "cope": 1772, "eleg": 1772, "num_process": 1772, "modern": 1773, "754": 1773, "1e20": 1773, "4142e": 1773, "struggl": 1773, "benign": 1773, "v_dot2": 1773, "mfma": 1773, "fp64": 1773, "rocbla": 1773, "miopen": 1773, "rocblas_internal_fp16_alt_impl": 1773, "miopen_debug_convolution_attrib_fp16_alt_impl": 1773, "_convbackend": 1773, "slownd": 1773, "slownd_transpos": 1773, "slownd_dil": 1773, "slownd_dilated_transpos": 1773, "convbackend": 1773, "miopendepthwis": 1773, "miopentranspos": 1773, "svd_lowrank": [1774, 1793], "22modul": 1774, "20determin": 1774, "index_add_cuda_": 1774, "1509": 1774, "8027": 1774, "0333": 1774, "1444": 1774, "rese": 1774, "seed_work": 1774, "worker_se": 1774, "train_dataset": 1774, "tensor_dict": 1775, "loaded_numb": 1775, "loaded_even": 1775, "scene": [1775, 1798], "loaded_smal": 1775, "num_batches_track": 1775, "bn_state_dict": 1775, "new_bn": 1775, "out0_relu": 1775, "1400": 1775, "4563": 1775, "0271": 1775, "4406": 1775, "2827": 1775, "4588": 1775, "2031": 1775, "0300": 1775, "1316": 1775, "6533": 1775, "3413": 1775, "1112": 1775, "m_state_dict": 1775, "new_m": 1775, "original_nam": 1775, "controlflowmodul": 1775, "controlflowmodule_trac": 1775, "3793": 1775, "controlflowmodule_script": 1775, "rem": 1776, "7z": 1776, "curl": 1776, "ossci": 1776, "mkl_2020": 1776, "aoa": 1776, "omkl": 1776, "cuda_prefix": 1776, "cuda102": 1776, "magma_2": 1776, "4_": 1776, "omagma": 1776, "cmake_include_path": 1776, "magma_hom": 1776, "studio": 1776, "cmake_gener": 1776, "ffi": 1776, "create_extens": 1776, "_ext": 1776, "define_macro": 1776, "relative_to": 1776, "c99": 1776, "x86_x64": 1776, "packagesnotfounderror": 1776, "anaconda": 1776, "noarch": 1776, "continuum": 1776, "pkg": 1776, "pro": [1776, 1798], "msys2": 1776, "importerror": [1776, 1781], "dll": 1776, "vc2017": 1776, "redistribut": 1776, "vc": 1776, "vs2017_runtim": 1776, "mkl_fft": 1776, "intel_openmp": 1776, "vs2017": 1776, "pai": [1776, 1797], "openbla": 1776, "upstream": 1776, "forg": 1776, "emerg": 1776, "bootstrap": 1776, "forgotten": 1776, "idiom": 1776, "freeze_support": 1776, "forkingpickl": 1776, "brokenpipeerror": 1776, "errno": 1776, "couldn": [1776, 1777], "torch_14808_1591070686": 1776, "thalloc": 1776, "tdr": 1776, "thcudacheck": 1776, "csrc": 1776, "storageshar": 1776, "dummy_input": 1777, "input_nam": 1777, "actual_input_1": 1777, "learned_": 1777, "output_nam": 1777, "learned_0": 1777, "learned_1": 1777, "learned_2": 1777, "learned_3": 1777, "learned_14": 1777, "learned_15": 1777, "kernel_shap": 1777, "9216": 1777, "transb": 1777, "check_model": 1777, "printable_graph": 1777, "onnxruntim": 1777, "ort": 1777, "ort_sess": 1777, "inferencesess": 1777, "astyp": 1777, "seq_length": 1777, "real_seq_length": 1777, "experienc": 1777, "new_data": 1777, "hope": 1777, "input_0": 1777, "input_1": 1777, "symbolic_opset": 1777, "symbolic_opset9": 1777, "_variablefunct": 1777, "pyi": 1777, "checkout": 1777, "___torch_mangle_0": 1777, "alpha_f": 1777, "myrelu": 1777, "value_t": 1777, "pythonop": [1777, 1779], "mylogexp": 1777, "operator_export_typ": 1777, "onnx_fallthrough": 1777, "onnx_aten_fallback": 1777, "onnxscript": 1777, "onnx_opset": 1777, "opset15": 1777, "custom_opset": 1777, "67326": 1777, "alphax": 1777, "castlik": 1777, "gammax": 1777, "po": 1777, "settyp": 1777, "custom_selu": 1777, "jit_util": 1777, "graphcontext": 1777, "onnxscript_op": 1777, "register_custom_op_symbol": 1777, "symbolic_nam": 1777, "symbolic_fn": 1777, "Be": 1777, "symbolic_help": 1777, "symbolic_foo_forward": 1777, "custom_domain": 1777, "attr1_f": 1777, "attr2_i": 1777, "custom_op": 1777, "foo_forward": 1777, "foomodel": 1777, "example_input1": 1777, "caffe2": [1777, 1798], "torch_script_graph": 1777, "unconvertible_op": 1777, "dynamic_ax": 1777, "export_param": 1777, "trainingmod": 1777, "operatorexporttyp": 1777, "do_constant_fold": 1777, "keep_initializers_as_input": 1777, "export_modules_as_funct": 1777, "OF": 1777, "WITH": 1777, "input_i": 1777, "input_z": 1777, "pb": 1777, "fileno": 1777, "untrain": 1777, "doc_str": 1777, "onnx_aten": 1777, "build_caffe2": 1777, "summodul": 1777, "dim_valu": 1777, "my_custom_axis_nam": 1777, "dim_param": 1777, "sum_dynamic_axes_1": 1777, "predefin": 1777, "checkererror": 1777, "unsupportedoperatorerror": 1777, "export_to_pretty_str": 1777, "export_typ": 1777, "google_print": 1777, "add_node_nam": 1777, "nodeproto": 1777, "protobuf": 1777, "debugstr": 1777, "contrib": 1777, "test_aten_embedding_2": 1777, "test_oper": 1777, "unregister_custom_op_symbol": 1777, "select_model_mode_for_export": 1777, "is_in_onnx_export": 1777, "middl": 1777, "enable_log": 1777, "disable_log": 1777, "underdevelop": 1778, "parsabl": 1778, "sarif": 1778, "poe0001": 1778, "poe0002": 1778, "poe0003": 1778, "poe0004": 1778, "_intern": [1778, 1795], "exportdiagnost": 1778, "record_cpp_call_stack": 1778, "frames_to_skip": 1778, "record_python_call_stack": 1778, "diagnosticengin": 1778, "diagnosticcontext": 1778, "rulecollect": 1778, "custom_collection_from_list": 1778, "customrulecollect": 1778, "message_default_templ": 1778, "xxx": 1778, "create_diagnostic_context": 1778, "diagnos": 1778, "rule1": 1778, "sarif_log": 1778, "diagnostic_typ": 1778, "_infra": 1778, "diagnosticopt": 1778, "pretty_print": 1778, "constantchunk": 1779, "__and_": 1779, "__contains_": 1779, "__derive_index": 1779, "__getitem_": 1779, "__interpol": 1779, "__is_": 1779, "__isnot_": 1779, "__lshift_": 1779, "__not_": 1779, "__or_": 1779, "__range_length": 1779, "__rshift_": 1779, "__xor_": 1779, "_cast_byt": 1779, "_cast_char": 1779, "_cast_doubl": 1779, "_cast_float": 1779, "_cast_half": 1779, "_cast_int": 1779, "_cast_long": 1779, "_cast_short": 1779, "_conj": 1779, "_dim_arang": 1779, "_pack_padded_sequ": 1779, "_pad_packed_sequ": 1779, "_reshape_from_tensor": 1779, "_sample_dirichlet": 1779, "_set_item": 1779, "_shape_as_tensor": 1779, "_standard_gamma": 1779, "_uniqu": 1779, "_unique2": 1779, "_weight_norm": 1779, "conv1d_relu": 1779, "conv2d_relu": 1779, "embedding_renorm": 1779, "floordiv": [1779, 1786], "nonzero_numpi": 1779, "numpy_t": 1779, "unchecked_cast": 1779, "unique_dim": 1779, "_quantiz": 1779, "conv2d_prepack": 1779, "conv3d_prepack": 1779, "conv3d_relu": 1779, "conv_transpose1d_prepack": 1779, "conv_transpose2d_prepack": 1779, "conv_transpose3d_prepack": 1779, "linear_dynam": 1779, "linear_prepack": 1779, "linear_prepack_fp16": 1779, "linear_prepack_fp16_legaci": 1779, "linear_prepack_legaci": 1779, "_test": 1779, "get_first": 1779, "compleximplicit": 1779, "floatimplicit": 1779, "intimplicit": 1779, "scalarimplicit": 1779, "__iand_": 1779, "__ilshift_": 1779, "__ior_": 1779, "__irshift_": 1779, "__ixor_": 1779, "__round_to_zero_floordiv": 1779, "__upsampl": 1779, "__upsample_bilinear": 1779, "__upsample_nearest": 1779, "_adaptive_avg_pool3d": 1779, "_add_batch_dim": 1779, "_add_relu": 1779, "_addmm_activ": 1779, "_aminmax": 1779, "_amp_foreach_non_finite_check_and_unscal": 1779, "_amp_update_scal": 1779, "_assert_async": 1779, "_assert_tensor_metadata": 1779, "_autocast_to_full_precis": 1779, "_autocast_to_reduced_precis": 1779, "_batch_norm_impl_index": 1779, "_cdist_forward": 1779, "_cholesky_solve_help": 1779, "_choose_qparams_per_tensor": 1779, "_chunk_grad_outputs_efficient_attent": 1779, "_coalesc": 1779, "_compute_linear_combin": 1779, "_conj_copi": 1779, "_conj_phys": 1779, "_conv_depthwise2d": 1779, "_convert_indices_from_coo_to_csr": 1779, "_convert_indices_from_csr_to_coo": 1779, "_convolution_mod": 1779, "_copy_from": 1779, "_copy_from_and_res": 1779, "_ctc_loss": 1779, "_cudnn_ctc_loss": 1779, "_cudnn_init_dropout_st": 1779, "_cudnn_rnn": 1779, "_cudnn_rnn_flatten_weight": 1779, "_cufft_clear_plan_cach": 1779, "_cufft_get_plan_cache_max_s": 1779, "_cufft_get_plan_cache_s": 1779, "_cufft_set_plan_cache_max_s": 1779, "_cummax_help": 1779, "_cummin_help": 1779, "_debug_has_internal_overlap": 1779, "_dimi": 1779, "_dimv": 1779, "_dirichlet_grad": 1779, "_efficient_attention_forward": 1779, "_efficientzerotensor": 1779, "_embedding_bag": 1779, "_embedding_bag_forward_onli": 1779, "_empty_affine_quant": 1779, "_empty_per_channel_affine_quant": 1779, "_euclidean_dist": 1779, "_fake_quantize_learnable_per_channel_affin": 1779, "_fake_quantize_learnable_per_tensor_affin": 1779, "_fake_quantize_per_tensor_affine_cachemask_tensor_qparam": 1779, "_fft_c2c": 1779, "_fft_c2r": 1779, "_fft_r2c": 1779, "_flash_attention_forward": 1779, "_foreach_ab": 1779, "_foreach_aco": 1779, "_foreach_add": 1779, "_foreach_addcdiv": 1779, "_foreach_addcmul": 1779, "_foreach_asin": 1779, "_foreach_atan": 1779, "_foreach_ceil": 1779, "_foreach_clamp_max": 1779, "_foreach_clamp_min": 1779, "_foreach_co": 1779, "_foreach_cosh": 1779, "_foreach_div": 1779, "_foreach_erf": 1779, "_foreach_erfc": 1779, "_foreach_exp": 1779, "_foreach_expm1": 1779, "_foreach_floor": 1779, "_foreach_frac": 1779, "_foreach_lgamma": 1779, "_foreach_log": 1779, "_foreach_log10": 1779, "_foreach_log1p": 1779, "_foreach_log2": 1779, "_foreach_maximum": 1779, "_foreach_minimum": 1779, "_foreach_mul": 1779, "_foreach_neg": 1779, "_foreach_norm": 1779, "_foreach_reciproc": 1779, "_foreach_round": 1779, "_foreach_sigmoid": 1779, "_foreach_sin": 1779, "_foreach_sinh": 1779, "_foreach_sqrt": 1779, "_foreach_sub": 1779, "_foreach_tan": 1779, "_foreach_tanh": 1779, "_foreach_trunc": 1779, "_foreach_zero": 1779, "_fused_adam": 1779, "_fused_dropout": 1779, "_fused_moving_avg_obs_fq_help": 1779, "_fused_moving_avg_obs_fq_helper_funct": 1779, "_fused_sdp_choic": 1779, "_fw_primal": 1779, "_fw_primal_copi": 1779, "_get_tracing_st": 1779, "_grad_sum_to_s": 1779, "_has_compatible_shallow_copy_typ": 1779, "_has_same_storage_numel": 1779, "_histogramdd_bin_edg": 1779, "_histogramdd_from_bin_ct": 1779, "_histogramdd_from_bin_tensor": 1779, "_index_put_impl": 1779, "_indices_copi": 1779, "_infer_s": 1779, "_is_zerotensor": 1779, "_linalg_check_error": 1779, "_linalg_det": 1779, "_linalg_eigh": 1779, "_linalg_slogdet": 1779, "_linalg_solve_ex": 1779, "_linalg_svd": 1779, "_list_to_tensor": 1779, "_local_scalar_dens": 1779, "_logcumsumexp": 1779, "_lstm_mp": 1779, "_make_du": 1779, "_make_dual_copi": 1779, "_make_per_channel_quantized_tensor": 1779, "_make_per_tensor_quantized_tensor": 1779, "_masked_scal": 1779, "_masked_softmax": 1779, "_mkldnn_reshap": 1779, "_mkldnn_transpos": 1779, "_mps_convolut": 1779, "_mps_convolution_transpos": 1779, "_mps_max_pool2d": 1779, "_native_batch_norm_legit_funct": 1779, "_native_decoder_only_multi_head_attent": 1779, "_native_multi_head_attent": 1779, "_ncf_unsqueez": 1779, "_ncf_view": 1779, "_neg_view": 1779, "_neg_view_copi": 1779, "_nested_from_pad": 1779, "_nested_from_padded_and_nested_exampl": 1779, "_nested_tensor_from_mask": 1779, "_nested_tensor_from_mask_left_align": 1779, "_nested_tensor_from_tensor_list": 1779, "_nested_tensor_offset": 1779, "_nested_tensor_s": 1779, "_nested_tensor_softmax_with_shap": 1779, "_nested_tensor_strid": 1779, "_nested_view_from_buff": 1779, "_nested_view_from_buffer_copi": 1779, "_new_zeros_with_same_feature_meta": 1779, "_nnpack_avail": 1779, "_nnpack_spatial_convolut": 1779, "_no_grad_embedding_renorm": 1779, "_no_grad_fil": 1779, "_no_grad_norm": 1779, "_no_grad_uniform": 1779, "_no_grad_zero": 1779, "_pack_sequ": 1779, "_pad_circular": 1779, "_pad_enum": 1779, "_pdist_forward": 1779, "_pin_memori": 1779, "_prelu_kernel": 1779, "_remove_batch_dim": 1779, "_reshape_alia": 1779, "_reshape_alias_copi": 1779, "_reshape_copi": 1779, "_resize_output": 1779, "_rowwise_prun": 1779, "_saturate_weight_to_fp16": 1779, "_scaled_dot_product_attent": 1779, "_scaled_dot_product_attention_math": 1779, "_scaled_dot_product_efficient_attent": 1779, "_scaled_dot_product_flash_attent": 1779, "_size_if_not_equ": 1779, "_slow_conv2d_forward": 1779, "_sobol_engine_draw": 1779, "_sobol_engine_ff": 1779, "_sobol_engine_initialize_st": 1779, "_sobol_engine_scrambl": 1779, "_sparse_addmm": 1779, "_sparse_broadcast_to": 1779, "_sparse_broadcast_to_copi": 1779, "_sparse_bsc_tensor_unsaf": 1779, "_sparse_bsr_tensor_unsaf": 1779, "_sparse_compressed_tensor_unsaf": 1779, "_sparse_coo_tensor_unsaf": 1779, "_sparse_coo_tensor_with_dim": 1779, "_sparse_coo_tensor_with_dims_and_tensor": 1779, "_sparse_csc_tensor_unsaf": 1779, "_sparse_csr_prod": 1779, "_sparse_csr_sum": 1779, "_sparse_csr_tensor_unsaf": 1779, "_sparse_log_softmax": 1779, "_sparse_mask_help": 1779, "_sparse_mm": 1779, "_sparse_softmax": 1779, "_sparse_sparse_matmul": 1779, "_sparse_sum": 1779, "_spdiag": 1779, "_standard_gamma_grad": 1779, "_symeig_help": 1779, "_tensor_to_list": 1779, "_test_ambiguous_default": 1779, "_test_autograd_multiple_dispatch": 1779, "_test_autograd_multiple_dispatch_view": 1779, "_test_autograd_multiple_dispatch_view_copi": 1779, "_test_optional_filled_intlist": 1779, "_test_optional_floatlist": 1779, "_test_optional_intlist": 1779, "_test_serialization_subcmul": 1779, "_test_string_default": 1779, "_test_warn_in_autograd": 1779, "_thnn_fused_gru_cel": 1779, "_thnn_fused_lstm_cel": 1779, "_to_cpu": 1779, "_to_dens": 1779, "_transform_bias_rescale_qkv": 1779, "_transformer_decoder_only_layer_fwd": 1779, "_transformer_encoder_layer_fwd": 1779, "_trilinear": 1779, "_triton_multi_head_attent": 1779, "_triton_scaled_dot_attent": 1779, "_unpack_du": 1779, "_unsafe_view": 1779, "_unwrap_opt": 1779, "_upsample_bicubic2d_aa": 1779, "_upsample_bilinear2d_aa": 1779, "_upsample_nearest_exact1d": 1779, "_upsample_nearest_exact2d": 1779, "_upsample_nearest_exact3d": 1779, "_use_cudnn_ctc_loss": 1779, "_use_cudnn_rnn_flatten_weight": 1779, "_validate_compressed_sparse_indic": 1779, "_validate_sparse_bsc_tensor_arg": 1779, "_validate_sparse_bsr_tensor_arg": 1779, "_validate_sparse_compressed_tensor_arg": 1779, "_validate_sparse_coo_tensor_arg": 1779, "_validate_sparse_csc_tensor_arg": 1779, "_validate_sparse_csr_tensor_arg": 1779, "_values_copi": 1779, "_weight_norm_interfac": 1779, "capit": 1779, "confirmed_by_own": [1779, 1789], "convolution_overrid": 1779, "copy_sparse_to_spars": 1779, "endswith": 1779, "expandtab": 1779, "fake_quantize_per_channel_affine_cachemask": 1779, "fake_quantize_per_tensor_affine_cachemask": 1779, "fill_diagon": 1779, "glu_jvp": 1779, "has_torch_funct": [1779, 1804], "is_non_overlapping_and_dens": 1779, "is_own": 1779, "is_strides_like_format": 1779, "isalnum": 1779, "isalpha": 1779, "isdecim": 1779, "isdigit": 1779, "isidentifi": 1779, "islow": 1779, "isnumer": 1779, "isprint": 1779, "isspac": 1779, "istitl": 1779, "isupp": 1779, "lift_fresh": 1779, "lift_fresh_copi": 1779, "ljust": 1779, "local_valu": [1779, 1782], "log_sigmoid_forward": 1779, "lstrip": 1779, "matrix_h": 1779, "nll_loss2d_forward": 1779, "nll_loss_forward": 1779, "normal_funct": 1779, "owner_nam": 1779, "percentformat": 1779, "quantized_gru": 1779, "quantized_lstm": 1779, "resize_as_spars": 1779, "rfind": 1779, "rindex": 1779, "rjust": 1779, "rpartit": 1779, "rsplit": 1779, "rstrip": 1779, "set_data": 1779, "slow_conv3d_forward": 1779, "sparse_res": 1779, "sparse_resize_and_clear": 1779, "splitlin": 1779, "startswith": 1779, "swapcas": 1779, "sym_numel": 1779, "sym_siz": 1779, "sym_storage_offset": 1779, "sym_strid": 1779, "unique_dim_consecut": 1779, "zfill": 1779, "_allgather_bas": 1779, "_reduce_scatter_bas": 1779, "allgath": 1779, "allgather_coalesc": 1779, "allreduce_coalesc": 1779, "alltoal": 1779, "alltoall_bas": 1779, "recv_any_sourc": 1779, "_mkl_linear": 1779, "_mkl_reorder_linear_weight": 1779, "_convolution_pointwis": 1779, "_linear_pointwis": 1779, "mkldnn_prepack": 1779, "conv2d_run": 1779, "nvprim": 1779, "conv2d_clamp_prepack": 1779, "conv2d_clamp_run": 1779, "conv2d_transpose_clamp_prepack": 1779, "conv2d_transpose_clamp_run": 1779, "linear_clamp_prepack": 1779, "linear_clamp_run": 1779, "unpack_prepacked_sizes_conv2d": 1779, "unpack_prepacked_sizes_linear": 1779, "addstatvalu": 1779, "autogradadd": 1779, "autogradallnonzero": 1779, "autogradallzero": 1779, "autogradanynonzero": 1779, "autogradzero": 1779, "bailout": 1779, "bailouttempl": 1779, "broadcastmkldnntensor": 1779, "broadcasts": 1779, "chunksiz": 1779, "constantmkldnntensor": 1779, "cudafusiongroup": 1779, "cudafusionguard": 1779, "cudafusionivalguard": 1779, "cudafusionsizeeq": 1779, "cudafusionviewguard": 1779, "differentiablegraph": 1779, "enumnam": 1779, "enumvalu": 1779, "fallbackgraph": 1779, "fusedconcat": 1779, "fusiongroup": 1779, "ifthenels": 1779, "ignoredpythonop": 1779, "mkldnnclamp": 1779, "mkldnnhardsigmoid": 1779, "mkldnnhardswish": 1779, "mkldnnhardtanh": 1779, "mkldnnlayernorm": 1779, "mkldnnscalarmul": 1779, "mmbatchsid": 1779, "mmtreereduc": 1779, "modulecontainerindex": 1779, "numtotensor": 1779, "raiseexcept": 1779, "reductions": 1779, "requiresgradcheck": 1779, "staticruntimecopyout": 1779, "staticsubgraph": 1779, "stringindex": 1779, "tensorexprdynamicgroup": 1779, "tensorexprdynamicguard": 1779, "tensorexprgroup": 1779, "timepoint": 1779, "tupleindex": 1779, "tupleunpack": 1779, "varconcat": 1779, "varstack": 1779, "add_opt": 1779, "expand_as_copi": 1779, "flatten_copi": 1779, "infer_squeeze_s": 1779, "infer_unsqueeze_s": 1779, "is_cpu": 1779, "is_ipu": 1779, "is_mkldnn": 1779, "is_mp": 1779, "is_nest": 1779, "is_ort": 1779, "is_quant": 1779, "is_vulkan": 1779, "is_xpu": 1779, "onednnfusiongroup": 1779, "onednnfusionguard": 1779, "profile_ivalu": 1779, "rangelist": 1779, "reshape_copi": 1779, "rpc_remot": 1779, "unchecked_unwrap_opt": 1779, "_call_end_callbacks_on_jit_fut": 1779, "_record_function_ent": 1779, "_record_function_enter_new": 1779, "_record_function_exit": 1779, "_bfloat16quantizedtofloat": 1779, "_floattobfloat16quant": 1779, "add_out": 1779, "add_relu_out": 1779, "add_scalar_out": 1779, "add_scalar_relu": 1779, "add_scalar_relu_out": 1779, "batch_norm1d": 1779, "batch_norm1d_relu": 1779, "batch_norm2d": 1779, "batch_norm2d_relu": 1779, "batch_norm3d": 1779, "batch_norm3d_relu": 1779, "batch_norm_relu": 1779, "cat_out": 1779, "cat_relu": 1779, "cat_relu_out": 1779, "conv1d_dynam": 1779, "conv1d_prepack": 1779, "conv1d_unpack": 1779, "conv2d_dil": 1779, "conv2d_dynam": 1779, "conv2d_group": 1779, "conv2d_output_pad": 1779, "conv2d_pad": 1779, "conv2d_strid": 1779, "conv2d_transpos": 1779, "conv2d_unpack": 1779, "conv2d_unpack_s": 1779, "conv3d_dil": 1779, "conv3d_dynam": 1779, "conv3d_group": 1779, "conv3d_output_pad": 1779, "conv3d_pad": 1779, "conv3d_strid": 1779, "conv3d_transpos": 1779, "conv3d_unpack": 1779, "conv_prepack": 1779, "conv_transpose1d_dynam": 1779, "conv_transpose1d_unpack": 1779, "conv_transpose2d_dil": 1779, "conv_transpose2d_dynam": 1779, "conv_transpose2d_group": 1779, "conv_transpose2d_output_pad": 1779, "conv_transpose2d_pad": 1779, "conv_transpose2d_strid": 1779, "conv_transpose2d_transpos": 1779, "conv_transpose2d_unpack": 1779, "conv_transpose3d_dil": 1779, "conv_transpose3d_dynam": 1779, "conv_transpose3d_group": 1779, "conv_transpose3d_output_pad": 1779, "conv_transpose3d_pad": 1779, "conv_transpose3d_strid": 1779, "conv_transpose3d_transpos": 1779, "conv_transpose3d_unpack": 1779, "conv_unpack": 1779, "embedding_4bit": 1779, "embedding_bag_2bit_prepack": 1779, "embedding_bag_2bit_rowwise_offset": 1779, "embedding_bag_2bit_unpack": 1779, "embedding_bag_4bit": 1779, "embedding_bag_4bit_prepack": 1779, "embedding_bag_4bit_rowwise_offset": 1779, "embedding_bag_4bit_unpack": 1779, "embedding_bag_byt": 1779, "embedding_bag_byte_prepack": 1779, "embedding_bag_byte_rowwise_offset": 1779, "embedding_bag_byte_unpack": 1779, "embedding_bag_prepack": 1779, "embedding_bag_unpack": 1779, "embedding_byt": 1779, "linear_dynamic_fp16": 1779, "linear_leaky_relu": 1779, "linear_relu": [1779, 1786], "linear_relu_dynam": 1779, "linear_relu_dynamic_fp16": 1779, "linear_tanh": 1779, "linear_unpack": 1779, "linear_unpack_fp16": 1779, "linear_with_input_q_dq_qweight_dq_output_fp32": 1779, "linear_with_input_q_dq_qweight_dq_relu_output_fp32": 1779, "make_quantized_cell_param": 1779, "make_quantized_cell_params_dynam": 1779, "make_quantized_cell_params_fp16": 1779, "mul_out": 1779, "mul_relu": 1779, "mul_relu_out": 1779, "mul_scalar_out": 1779, "mul_scalar_relu": 1779, "mul_scalar_relu_out": 1779, "quantized_gru_cell_dynam": 1779, "quantized_lstm_cell_dynam": 1779, "quantized_rnn_relu_cell_dynam": 1779, "quantized_rnn_tanh_cell_dynam": 1779, "qlinear": 1779, "qlinear_dynam": 1779, "qlinear_prepack": 1779, "qlinear_relu": 1779, "qlinear_relu_dynam": 1779, "qlinear_unpack": 1779, "static_runtim": 1779, "vartupleunpack": 1779, "clamp_nan_to_num": 1779, "create_owned_ref": 1779, "dequantize_copi": 1779, "dict_unpack": 1779, "expand_dims_copi": 1779, "fused_equally_split": 1779, "select_tensor": 1779, "signed_log1p": 1779, "to_copi": 1779, "to_maybe_copy_out": 1779, "var1": 1780, "var2": 1780, "lbfg": 1780, "reducelronplateau": 1780, "multisteplr": 1780, "upgrad": [1780, 1800], "swa_util": 1780, "averagedmodel": 1780, "swalr": 1780, "update_bn": 1780, "optima": 1780, "swa_model": 1780, "update_paramet": 1780, "swa_schedul": 1780, "anneal_epoch": 1780, "swa_lr": 1780, "avg_fn": 1780, "ema_model": 1780, "ema_avg": 1780, "averaged_model_paramet": 1780, "model_paramet": 1780, "num_averag": 1780, "cosineannealinglr": 1780, "swa_start": 1780, "test_input": 1780, "secur": 1781, "unpackag": 1781, "exercis": 1781, "unzip": 1781, "my_packag": 1781, "freeli": 1781, "94304870911616": 1781, "94304900784016": 1781, "extern_modul": 1781, "model_1": 1781, "pkl": 1781, "myzip": 1781, "file_byt": 1781, "writestr": 1781, "new_file_byt": 1781, "vim": 1781, "vimrc": 1781, "bufreadcmd": 1781, "brows": 1781, "amatch": 1781, "vi": 1781, "packageimport": 1781, "queryabl": 1781, "glob": 1781, "packageexport": 1781, "pe": 1781, "save_pickl": 1781, "has_fil": 1781, "importer_file_structur": 1781, "package_a": 1781, "get_rdep": 1781, "all_path": 1781, "dependency_graph_str": 1781, "save_text": 1781, "save_binari": 1781, "my_resourc": 1781, "config_stuff": 1781, "raw_data": 1781, "my_byt": 1781, "complementari": [1781, 1794], "load_pickl": 1781, "load_text": 1781, "load_binari": 1781, "my_tensor": 1781, "__reduce_package__": 1781, "__reduce__": 1781, "my_str": 1781, "time_import": 1781, "time_export": 1781, "pickler": 1781, "persistent_id": 1781, "persistent_load": 1781, "generated_module_nam": 1781, "get_unique_id": 1781, "clock_gettim": 1781, "unpackage_foo": 1781, "depickl": 1781, "foo_1": 1781, "foo_2": 1781, "foo_packag": 1781, "foo_collect": 1781, "foo1": 1781, "foo2": 1781, "imported_foo": 1781, "9857706": 1781, "650140837": 1781, "652698385": 1781, "__torch_package__": 1781, "is_in_packag": 1781, "userexcept": 1781, "unpackageableexcept": 1781, "loaded_modul": 1781, "import_modul": 1781, "save_source_str": 1781, "save_modul": 1781, "textwrap": 1781, "dedent": 1781, "my_funct": 1781, "is_packag": 1781, "importlib": 1781, "my_pickl": 1781, "get_my_resourc": 1781, "read_text": 1781, "torch_package_import": 1781, "get_my_pickl": 1781, "is_from_packag": 1781, "stdlib": 1781, "my_test": 1781, "f2": [1781, 1782], "sys_import": 1781, "script_model": 1781, "mixed_model": 1781, "python_model_with_scripted_submodul": 1781, "loaded_script": 1781, "loaded_mix": 1781, "convention": 1781, "94286146172688": 1781, "94286146172784": 1781, "consult": 1781, "essai": 1781, "another_packag": 1781, "pickletool": 1781, "ast": 1781, "deni": 1781, "my_export": 1781, "my_interned_modul": 1781, "package_export": 1781, "my_externed_modul": 1781, "my_mocked_modul": 1781, "unwant": [1781, 1798], "hodg": 1781, "podg": 1781, "bazel": 1781, "buck": 1781, "my_class_inst": 1781, "imported_myclass": 1781, "okai": 1781, "torch_package_0": 1781, "handle_me_this_wai": 1781, "inadvert": 1781, "pun": 1781, "packagingerror": 1781, "dependency_graph": 1781, "emptymatcherror": 1781, "allow_empti": 1781, "_sysimport": 1781, "hermet": 1781, "scan": 1781, "orderedimport": 1781, "add_depend": 1781, "graphviz": 1781, "lang": 1781, "denied_modul": 1781, "my_subpackag": 1781, "digraph": 1781, "externed_modul": 1781, "interned_modul": 1781, "mocked_modul": 1781, "register_extern_hook": 1781, "register_intern_hook": 1781, "register_mock_hook": 1781, "myobject": 1781, "save_source_fil": 1781, "file_or_directori": 1781, "my_subsubpackag": 1781, "file_or_buff": 1781, "module_allow": 1781, "pytorchfileread": 1781, "python_vers": 1781, "is_dir": 1781, "gpipe": 1782, "suffer": 1782, "microbatch": 1782, "bubbl": 1782, "except_last": 1782, "deferred_batch_norm": 1782, "torchgpip": 1782, "withdevic": 1782, "micro": 1782, "fc": [1782, 1784], "init_rpc": [1782, 1789, 1790], "output_rref": 1782, "pipelinin": 1782, "fairli": 1782, "fed": [1782, 1798], "nochunk": 1782, "resnext": 1782, "till": 1782, "skippabl": 1782, "perfectli": 1782, "1to3": 1782, "layer1": 1782, "f1": 1782, "layer2": 1782, "layer3": 1782, "skip_1to3": 1782, "f3": 1782, "alic": 1782, "bob": 1782, "carol": 1782, "stashstashpop": 1782, "f_alic": 1782, "f_bob": 1782, "verify_skipp": 1782, "unmatch": [1782, 1803], "fairscal": 1782, "_kinetoprofil": 1783, "profileract": 1783, "add_metadata": 1783, "add_metadata_json": 1783, "unaggreg": 1783, "export_chrome_trac": 1783, "export_stack": 1783, "self_cuda_time_tot": 1783, "flamegraph": 1783, "brendangregg": 1783, "pl": 1783, "countnam": 1783, "perf_viz": 1783, "svg": 1783, "on_trace_readi": 1783, "record_and_sav": 1783, "tensorboard_trace_handl": 1783, "dir_nam": 1783, "logdir": [1783, 1798], "plugin": [1783, 1798], "code_to_profil": 1783, "row_limit": 1783, "trace_handl": 1783, "test_trace_": 1783, "step_num": 1783, "code_iteration_to_profil": 1783, "skip_first": 1783, "worker_nam": [1783, 1789], "use_gzip": 1783, "range_push": 1783, "range_pop": 1783, "4x": 1784, "broadli": 1784, "domin": 1784, "previous_layer_fp32": 1784, "linear_fp32": 1784, "activation_fp32": 1784, "next_layer_fp32": 1784, "linear_weight_fp32": 1784, "linear_int8_w_fp32_inp": 1784, "linear_weight_int8": 1784, "ptdq": 1784, "model_fp32": 1784, "model_int8": 1784, "quantize_dynam": 1784, "input_fp32": 1784, "ptq": [1784, 1785, 1787], "previous_layer_int8": 1784, "linear_with_activation_int8": 1784, "next_layer_int8": 1784, "ptsq": 1784, "assymetr": 1784, "minmax": 1784, "l2norm": 1784, "model_fp32_fus": 1784, "fuse_modul": [1784, 1785], "model_fp32_prepar": 1784, "fake_qu": 1784, "fq": 1784, "prepare_qat": 1784, "training_loop": 1784, "requant": 1784, "linear1": 1784, "custom_qconfig": 1784, "fxptq": 1784, "model_fp": 1784, "usermodel": 1784, "deepcopi": [1784, 1803], "model_to_quant": 1784, "default_dynamic_qconfig": 1784, "model_prepar": 1784, "model_quant": 1784, "model_fus": 1784, "per_channel_scal": 1784, "per_channel_zero_point": 1784, "quantized_tensor": 1784, "qengin": 1784, "in4": 1784, "avx2": 1784, "float_modul": [1784, 1802], "staticquantcustommodul": 1784, "observed_modul": 1784, "default_qconfig": [1784, 1803], "test_quantized_op": 1784, "testquantizedop": 1784, "test_custom_module_lstm": 1784, "test_quantize_fx": 1784, "testquantizefx": 1784, "test_static_lstm": 1784, "some_oper": 1784, "e2": 1784, "thnn_conv2d_forward": 1784, "quantizedcpu": 1784, "some_qconfig": 1784, "linearpackedparam": 1784, "_modul": 1784, "prepare_orig": 1784, "quantized_orig": 1784, "scripted_quant": 1784, "fp32_op": 1785, "int8_op": 1785, "cooperlak": 1785, "audit": 1785, "op_fp32": 1785, "op_int8": 1785, "_numeric_suit": 1785, "_numeric_suite_fx": 1785, "scale_exact_match": 1786, "zero_point_exact_match": 1786, "0x7f6cfb4526a0": 1786, "0x7f6ca9991560": 1786, "0x7f6ca99915f0": 1786, "num_tensor_args_to_observation_typ": 1786, "convbn1d": 1786, "0x7f6ca8a638c0": 1786, "reference_quantized_module_for_root": 1786, "fuse_convtranspose_bn": 1786, "0x7f6ca8a693b0": 1786, "linearbn1d": 1786, "fuse_linear_bn": 1786, "0x7f6ca8a69320": 1786, "convbn2d": 1786, "convbn3d": 1786, "bnrelu2d": 1786, "bnrelu3d": 1786, "input_type_to_index": 1786, "conv_fus": 1786, "convbnrelu1d": 1786, "convbnrelu2d": 1786, "convbnrelu3d": 1786, "convrelu1d": 1786, "convrelu3d": 1786, "0x7f6ca9991680": 1786, "0x7f6ca9991cb0": 1786, "quint4x2": [1786, 1795, 1799, 1800], "embedding_op": 1786, "input_output_observ": 1786, "0x7f6ca9994b90": 1786, "00390625": 1786, "0x7f6ca99944d0": 1786, "0x7f6ca9994680": 1786, "0x7f6ca9991b90": 1786, "0x7f6ca9994a70": 1786, "0x7f6ca990acb0": 1786, "0x7f6ca9994b00": 1786, "0x7f6ca9991e60": 1786, "linear_fus": 1786, "_sequential_wrapper2": 1786, "0x7f6d02a10d40": 1786, "0x7f6ca9991a70": 1786, "0x7f6ca6cec3b0": 1786, "fuse_conv_bn_relu": 1786, "0x7f6ca8a69290": 1786, "0x7f6ca6cecb90": 1786, "0x7f6ca6cecc20": 1786, "0x7f6ca6ceccb0": 1786, "0x7f6ca6cecd40": 1786, "0x7f6ca6cecdd0": 1786, "0x7f6ca6cece60": 1786, "0x7f6ca6cecef0": 1786, "0x7f6ca6cecf80": 1786, "0x7f6ca6d02050": 1786, "0x7f6ca6d020e0": 1786, "0x7f6ca9991c20": 1786, "0078125": 1786, "customconfig": 1787, "custom_module_config": 1787, "fork_rng": 1788, "_caller": 1788, "_devices_kw": 1788, "slowli": 1788, "unind": 1788, "get_rng_stat": 1788, "set_rng_stat": 1788, "shortcom": 1789, "stitch": 1789, "rpc_backend_opt": 1789, "trainer3": 1789, "parameterserver2": 1789, "dash": [1789, 1791], "backendtyp": 1789, "rpcbackendopt": 1789, "rpcagent": 1789, "transmit": 1789, "calle": [1789, 1791], "_set_rpc_timeout": 1789, "5678": 1789, "worker0": 1789, "my_script_add": 1789, "wire": 1789, "fut2": 1789, "grace": 1789, "pend": [1789, 1798], "userrref": [1789, 1791], "async_execut": 1789, "paus": 1789, "outmost": 1789, "async_add_chain": 1789, "worker2": 1789, "script_add": 1789, "async_add": 1789, "asyncexecutionclass": 1789, "static_async_add": 1789, "class_async_add": 1789, "ret_fut": 1789, "bound_async_add": 1789, "rpc_timeout": 1789, "incid": [1789, 1791], "nvlink": 1789, "multiplex": 1789, "tensorpiperpcbackendopt": 1789, "num_worker_thread": 1789, "device_map": 1789, "_transport": 1789, "tensorpipeag": 1789, "set_device_map": 1789, "idempot": [1789, 1791], "intermitt": 1789, "remote_modul": 1789, "forward_async": 1789, "remote_devic": 1789, "workernam": 1789, "trainer0": 1789, "ps0": 1789, "remote_linear_modul": 1789, "get_module_rref": 1789, "remote_paramet": 1789, "conjuct": 1789, "my_add": [1790, 1804], "t4": 1790, "t5": 1790, "autograd_message_id": 1790, "autograd_context_id": 1790, "bracket": 1790, "send1": 1790, "kickoff": 1790, "recv2": 1790, "heard": 1790, "send2": 1790, "recv1": 1790, "dist_autograd_simpl": 1790, "random_tensor": 1790, "_run_process": 1790, "dst_rank": 1790, "dst_name": 1790, "run_process": 1790, "rrefid": 1791, "ownerrref": 1791, "transient": 1791, "udf": 1791, "deliveri": 1791, "knowledg": 1791, "danger": 1791, "ancestor": 1791, "trickier": 1791, "wouldn": 1791, "forkid": 1791, "ack": 1791, "solid": 1791, "gc": 1791, "followup": 1791, "lil": 1793, "stark": 1793, "slight": 1793, "8415": 1793, "9093": 1793, "1411": 1793, "7568": 1793, "9589": 1793, "2794": 1793, "catastroph": 1793, "9900": 1793, "maskedtensor": 1793, "000": 1793, "400": 1793, "s2": 1793, "plain_dim_s": 1793, "lp64": 1793, "280": 1793, "310": 1793, "sp": 1793, "9078": 1793, "conception": 1793, "lobpcg": 1793, "geneig": 1793, "pca_lowrank": 1793, "kindli": 1793, "airy_ai": 1794, "airi": 1794, "onward": 1794, "9635": 1794, "entr": 1794, "3466": 1794, "int_": 1794, "8427": 1794, "0561": 1794, "4769": 1794, "9213": 1794, "8858": 1794, "7683": 1794, "7481": 1794, "2920": 1794, "minu": 1794, "int_0": 1794, "gammaln": 1794, "a1": 1794, "a2": 1794, "3528": 1794, "5665": 1794, "6472": 1794, "4335": 1794, "2650": 1794, "2661": 1794, "2796": 1794, "8808": 1794, "3019": 1794, "4658": 1794, "3085": 1794, "2430": 1794, "2070": 1794, "i1": 1794, "5652": 1794, "9534": 1794, "7595": 1794, "2153": 1794, "log_ndtr": 1794, "_ndtr": 1794, "6077": 1794, "7832": 1794, "841": 1794, "6931": 1794, "1728": 1794, "023": 1794, "9331": 1794, "6486": 1794, "1523": 1794, "6516": 1794, "6352": 1794, "6131": 1794, "7169": 1794, "6261": 1794, "displaystyl": 1794, "undefiend": 1794, "6835": 1794, "8474": 1794, "1929": 1794, "7162": 1794, "4180": 1794, "3928": 1794, "4007": 1794, "7586": 1794, "3901": 1794, "5049": 1794, "ndtr": 1794, "0228": 1794, "1587": 1794, "9772": 1794, "9987": 1794, "2p": 1794, "64493": 1794, "4041": 1794, "8288": 1794, "4939": 1794, "97": 1794, "4091": 1794, "8863": 1794, "771": 1794, "scaled_modified_bessel_k0": 1794, "scaled_modified_bessel_k1": 1794, "2948": 1794, "0267": 1794, "1566": 1794, "9186": 1794, "8631": 1794, "0259": 1794, "1300": 1794, "spheric": 1794, "xlog1pi": 1794, "3863": 1794, "1972": 1794, "6094": 1794, "2189": 1794, "8283": 1794, "7726": 1794, "0986": 1794, "1589": 1794, "hurwitz": 1794, "6449": 1794, "0823": 1794, "floatstorag": 1795, "intstorag": 1795, "untyp": 1795, "wrap_storag": 1795, "complex_doubl": 1795, "from_buff": 1795, "nbyte": 1795, "pickle_storage_typ": 1795, "coppi": 1795, "doublestorag": 1795, "halfstorag": 1795, "longstorag": 1795, "shortstorag": 1795, "charstorag": 1795, "bytestorag": 1795, "boolstorag": 1795, "bfloat16storag": 1795, "complexdoublestorag": 1795, "complexfloatstorag": 1795, "quint8storag": 1795, "qint8storag": 1795, "qint32storag": 1795, "quint4x2storag": 1795, "quint2x4storag": 1795, "quint2x4": [1795, 1800], "twelv": 1796, "halftensor": [1796, 1799], "bfloat16tensor": [1796, 1799], "chartensor": [1796, 1799], "shorttensor": [1796, 1799], "binary16": [1796, 1799], "significand": [1796, 1799], "float_tensor": 1796, "double_tensor": 1796, "complex_float_tensor": 1796, "complex_double_tensor": 1796, "int_tensor": 1796, "long_tensor": 1796, "uint_tensor": 1796, "bool_tensor": 1796, "long_zerodim": 1796, "int_zerodim": 1796, "set_default_devic": 1796, "cuda1": 1796, "nhwc": [1796, 1798], "channels_last_3d": 1796, "ndhwc": 1796, "blogpost": 1797, "totensor": 1798, "trainset": 1798, "mnist": 1798, "mnist_train": 1798, "trainload": 1798, "grayscal": 1798, "make_grid": 1798, "add_imag": 1798, "add_graph": 1798, "clutter": 1798, "n_iter": 1798, "purge_step": 1798, "max_queu": 1798, "flush_sec": 1798, "filename_suffix": 1798, "current_datetime_hostnam": 1798, "exp1": 1798, "suffix": [1798, 1799], "global_step": 1798, "purg": 1798, "event_file_writ": 1798, "eventfilewrit": 1798, "may04_22": 1798, "54_": 1798, "macbook": 1798, "my_experi": 1798, "lr_0": 1798, "1_batch_16": 1798, "locallr_0": 1798, "scalar_valu": 1798, "walltim": 1798, "new_styl": 1798, "double_precis": 1798, "blobnam": 1798, "simple_valu": 1798, "2x": 1798, "main_tag": 1798, "tag_scalar_dict": 1798, "run_14h": 1798, "xsinx": 1798, "xcosx": 1798, "tanx": 1798, "add_histogram": 1798, "max_bin": 1798, "fd": 1798, "img_tensor": 1798, "dataformat": 1798, "chw": 1798, "hwc": 1798, "hw": 1798, "wh": 1798, "3xhxw": 1798, "img_hwc": 1798, "my_imag": 1798, "my_image_hwc": 1798, "img_batch": 1798, "my_image_batch": 1798, "add_figur": 1798, "add_video": 1798, "vid_tensor": 1798, "fp": 1798, "moviepi": 1798, "add_audio": 1798, "snd_tensor": 1798, "sample_r": 1798, "44100": 1798, "add_text": 1798, "text_str": 1798, "input_to_model": 1798, "use_strict_trac": 1798, "add_embed": 1798, "label_img": 1798, "metadata_head": 1798, "projector": 1798, "kwlist": 1798, "add_pr_curv": 1798, "num_threshold": 1798, "pr_curv": 1798, "add_custom_scalar": 1798, "chart": 1798, "categorynam": 1798, "chartnam": 1798, "listofproperti": 1798, "multilin": 1798, "taiwan": 1798, "twse": 1798, "0050": 1798, "2330": 1798, "dow": 1798, "aaa": 1798, "bbb": 1798, "ccc": 1798, "nasdaq": 1798, "add_mesh": 1798, "config_dict": 1798, "mesh": 1798, "js": 1798, "threej": 1798, "vertex": 1798, "number_of_vertic": 1798, "vertices_tensor": 1798, "colors_tensor": 1798, "faces_tensor": 1798, "my_mesh": 1798, "add_hparam": 1798, "hparam_dict": 1798, "metric_dict": 1798, "hparam_domain_discret": 1798, "run_nam": 1798, "hparam": 1798, "bsize": 1798, "_like": 1799, "allow_subclass": 1800, "check_devic": 1800, "check_dtyp": 1800, "check_layout": 1800, "6e": 1800, "3e": 1800, "assert_equ": 1800, "000000000000001e": 1800, "1e0": 1800, "argh": 1800, "nfooter": 1800, "66": 1800, "footer": 1800, "make_tensor": 1800, "exclude_zero": 1800, "1205": 1800, "2282": 1800, "6380": 1800, "assert_allclos": 1800, "default_gener": 1801, "click": 1801, "inplace_view": 1801, "nondeterministic_seed": 1801, "nondeterministic_bitwis": 1801, "data_dependent_output": 1801, "dynamic_output_shap": 1801, "compare_weight": 1802, "float_dict": 1802, "quantized_dict": 1802, "wt_compare_dict": 1802, "qmodel": 1802, "compute_error": 1802, "weight_dict": 1802, "get_logger_dict": 1802, "shadowlogg": 1802, "outputlogg": [1802, 1803], "target_dict": 1802, "q_modul": 1802, "logger_cl": [1802, 1803], "prepare_model_with_stub": 1802, "module_swap_list": 1802, "q_model": 1802, "ob_dict": 1802, "compare_model_stub": 1802, "quantizablebasicblock": 1802, "get_matching_activ": 1802, "act_dict": 1802, "prepare_model_output": 1802, "compare_model_output": 1802, "act_compare_dict": 1802, "weight_comparison": 1803, "extract_weight": 1803, "sqnr": 1803, "extend_logger_results_with_comparison": 1803, "compute_sqnr": 1803, "mp_n": 1803, "mq_n": 1803, "add_logg": 1803, "act_comparison": 1803, "extract_logger_info": 1803, "mp_shadows_mq": 1803, "add_shadow_logg": 1803, "shadow_act_comparison": 1803, "extract_shadow_logger_info": 1803, "ref_node_nam": 1803, "prev_node_nam": 1803, "model_nam": 1803, "ref_nam": 1803, "prev_node_target_typ": 1803, "ref_node_target_typ": 1803, "results_typ": 1803, "index_within_arg": 1803, "index_of_arg": 1803, "fqn": 1803, "qconfig_str": 1803, "outputcomparisonlogg": 1803, "x_ref": 1803, "nstracer": 1803, "skipped_module_nam": 1803, "skipped_module_class": 1803, "model_name_a": 1803, "model_a": 1803, "model_name_b": 1803, "model_b": 1803, "base_name_to_sets_of_related_op": 1803, "unmatchable_types_map": 1803, "op_to_type_to_weight_extraction_fn": 1803, "nsresultstyp": 1803, "name_a": 1803, "name_b": 1803, "should_log_input": 1803, "model_a_with_logg": 1803, "model_b_with_logg": 1803, "model_name_to_use_for_layer_nam": 1803, "node_type_to_io_type_map": 1803, "model_a_shadows_b": 1803, "model_name_1": 1803, "model_name_2": 1803, "comparison_fn": 1803, "comparison_nam": 1803, "prepare_n_shadows_model": 1803, "qconfig_multi_map": 1803, "custom_prepare_fn": 1803, "custom_prepare_kwarg": 1803, "custom_trac": 1803, "args_kwargs_m": 1803, "op_m": 1803, "output_m": 1803, "mod_with_op_m_transformed_with_qconfig_n": 1803, "args_m": 1803, "op_m_prepared_with_qconfig_n": 1803, "output_m_n": 1803, "comparison_logg": 1803, "kwargs_m": 1803, "docblock": 1803, "loggers_set_en": 1803, "loggers_set_save_activ": 1803, "save_activ": 1803, "convert_n_shadows_model": 1803, "custom_convert_fn": 1803, "custom_convert_kwarg": 1803, "extract_results_n_shadows_model": 1803, "print_comparisons_n_shadows_model": 1803, "compute_normalized_l2_error": 1803, "compute_cosine_similar": 1803, "as_subclass": 1804, "resolve_nam": 1804, "handle_torch_funct": 1804, "public_api": 1804, "relevant_arg": 1804, "has_torch_function_unari": 1804, "is_tensor_lik": 1804, "notatensor": 1804, "tensorlik": 1804, "is_tensor_method_or_properti": 1804, "__get__": 1804, "__module__": 1804, "slot": 1804, "wrap_torch_funct": 1804, "smallest_norm": 1805, "subnorm": 1805, "denormal_numb": 1805}, "objects": {"": [[1801, 0, 0, "-", "torch"], [1738, 7, 1, "-", "PYTORCH_JIT"]], "torch": [[1795, 1, 1, "", "BFloat16Storage"], [1795, 1, 1, "", "BoolStorage"], [1795, 1, 1, "", "ByteStorage"], [1795, 1, 1, "", "CharStorage"], [1795, 1, 1, "", "ComplexDoubleStorage"], [1795, 1, 1, "", "ComplexFloatStorage"], [1795, 1, 1, "", "DoubleStorage"], [1795, 1, 1, "", "FloatStorage"], [65, 1, 1, "", "Generator"], [1795, 1, 1, "", "HalfStorage"], [1795, 1, 1, "", "IntStorage"], [1795, 1, 1, "", "LongStorage"], [1795, 1, 1, "", "QInt32Storage"], [1795, 1, 1, "", "QInt8Storage"], [1795, 1, 1, "", "QUInt2x4Storage"], [1795, 1, 1, "", "QUInt4x2Storage"], [1795, 1, 1, "", "QUInt8Storage"], [1795, 1, 1, "", "ShortStorage"], [1801, 1, 1, "", "Tag"], [1799, 1, 1, "", "Tensor"], [1795, 1, 1, "", "TypedStorage"], [1795, 1, 1, "", "UntypedStorage"], [13, 0, 0, "-", "__config__"], [596, 5, 1, "", "_assert"], [0, 0, 0, "-", "_dynamo"], [597, 5, 1, "", "abs"], [598, 5, 1, "", "absolute"], [599, 5, 1, "", "acos"], [600, 5, 1, "", "acosh"], [601, 5, 1, "", "add"], [602, 5, 1, "", "addbmm"], [603, 5, 1, "", "addcdiv"], [604, 5, 1, "", "addcmul"], [605, 5, 1, "", "addmm"], [606, 5, 1, "", "addmv"], [607, 5, 1, "", "addr"], [608, 5, 1, "", "adjoint"], [609, 5, 1, "", "all"], [610, 5, 1, "", "allclose"], [611, 5, 1, "", "amax"], [612, 5, 1, "", "amin"], [613, 5, 1, "", "aminmax"], [1, 0, 0, "-", "amp"], [614, 5, 1, "", "angle"], [615, 5, 1, "", "any"], [1784, 0, 0, "-", "ao"], [713, 5, 1, "", "arange"], [714, 5, 1, "", "arccos"], [715, 5, 1, "", "arccosh"], [716, 5, 1, "", "arcsin"], [717, 5, 1, "", "arcsinh"], [718, 5, 1, "", "arctan"], [719, 5, 1, "", "arctan2"], [720, 5, 1, "", "arctanh"], [721, 5, 1, "", "are_deterministic_algorithms_enabled"], [722, 5, 1, "", "argmax"], [723, 5, 1, "", "argmin"], [724, 5, 1, "", "argsort"], [725, 5, 1, "", "argwhere"], [726, 5, 1, "", "as_strided"], [727, 5, 1, "", "as_tensor"], [728, 5, 1, "", "asarray"], [729, 5, 1, "", "asin"], [730, 5, 1, "", "asinh"], [731, 5, 1, "", "atan"], [732, 5, 1, "", "atan2"], [733, 5, 1, "", "atanh"], [734, 5, 1, "", "atleast_1d"], [735, 5, 1, "", "atleast_2d"], [736, 5, 1, "", "atleast_3d"], [1, 1, 1, "", "autocast"], [1801, 0, 0, "-", "autograd"], [3, 0, 0, "-", "backends"], [763, 5, 1, "", "baddbmm"], [764, 5, 1, "", "bartlett_window"], [765, 5, 1, "", "bernoulli"], [766, 5, 1, "", "bincount"], [767, 5, 1, "", "bitwise_and"], [768, 5, 1, "", "bitwise_left_shift"], [769, 5, 1, "", "bitwise_not"], [770, 5, 1, "", "bitwise_or"], [771, 5, 1, "", "bitwise_right_shift"], [772, 5, 1, "", "bitwise_xor"], [773, 5, 1, "", "blackman_window"], [774, 5, 1, "", "block_diag"], [775, 5, 1, "", "bmm"], [776, 5, 1, "", "broadcast_shapes"], [777, 5, 1, "", "broadcast_tensors"], [778, 5, 1, "", "broadcast_to"], [779, 5, 1, "", "bucketize"], [780, 5, 1, "", "can_cast"], [781, 5, 1, "", "cartesian_prod"], [782, 5, 1, "", "cat"], [783, 5, 1, "", "cdist"], [784, 5, 1, "", "ceil"], [785, 5, 1, "", "chain_matmul"], [786, 5, 1, "", "cholesky"], [787, 5, 1, "", "cholesky_inverse"], [788, 5, 1, "", "cholesky_solve"], [789, 5, 1, "", "chunk"], [790, 5, 1, "", "clamp"], [791, 5, 1, "", "clip"], [792, 5, 1, "", "clone"], [793, 5, 1, "", "column_stack"], [794, 5, 1, "", "combinations"], [795, 5, 1, "", "compile"], [796, 5, 1, "", "compiled_with_cxx11_abi"], [797, 5, 1, "", "complex"], [798, 5, 1, "", "concat"], [799, 5, 1, "", "concatenate"], [800, 5, 1, "", "conj"], [801, 5, 1, "", "conj_physical"], [1801, 0, 0, "-", "contrib"], [802, 5, 1, "", "copysign"], [803, 5, 1, "", "corrcoef"], [804, 5, 1, "", "cos"], [805, 5, 1, "", "cosh"], [806, 5, 1, "", "count_nonzero"], [807, 5, 1, "", "cov"], [1, 0, 0, "-", "cpu"], [808, 5, 1, "", "cross"], [16, 0, 0, "-", "cuda"], [884, 5, 1, "", "cummax"], [885, 5, 1, "", "cummin"], [886, 5, 1, "", "cumprod"], [887, 5, 1, "", "cumsum"], [888, 5, 1, "", "cumulative_trapezoid"], [889, 5, 1, "", "deg2rad"], [890, 5, 1, "", "dequantize"], [891, 5, 1, "", "det"], [1796, 1, 1, "", "device"], [892, 5, 1, "", "diag"], [893, 5, 1, "", "diag_embed"], [894, 5, 1, "", "diagflat"], [895, 5, 1, "", "diagonal"], [896, 5, 1, "", "diagonal_scatter"], [897, 5, 1, "", "diff"], [898, 5, 1, "", "digamma"], [899, 5, 1, "", "dist"], [23, 0, 0, "-", "distributed"], [29, 0, 0, "-", "distributions"], [900, 5, 1, "", "div"], [901, 5, 1, "", "divide"], [902, 5, 1, "", "dot"], [903, 5, 1, "", "dsplit"], [904, 5, 1, "", "dstack"], [1796, 1, 1, "", "dtype"], [905, 5, 1, "", "einsum"], [906, 5, 1, "", "empty"], [907, 5, 1, "", "empty_like"], [908, 5, 1, "", "empty_strided"], [909, 1, 1, "", "enable_grad"], [910, 5, 1, "", "eq"], [911, 5, 1, "", "equal"], [912, 5, 1, "", "erf"], [913, 5, 1, "", "erfc"], [914, 5, 1, "", "erfinv"], [915, 5, 1, "", "exp"], [916, 5, 1, "", "exp2"], [917, 5, 1, "", "expm1"], [918, 5, 1, "", "eye"], [919, 5, 1, "", "fake_quantize_per_channel_affine"], [920, 5, 1, "", "fake_quantize_per_tensor_affine"], [52, 0, 0, "-", "fft"], [943, 5, 1, "", "fix"], [944, 5, 1, "", "flatten"], [945, 5, 1, "", "flip"], [946, 5, 1, "", "fliplr"], [947, 5, 1, "", "flipud"], [948, 5, 1, "", "float_power"], [949, 5, 1, "", "floor"], [950, 5, 1, "", "floor_divide"], [951, 5, 1, "", "fmax"], [952, 5, 1, "", "fmin"], [953, 5, 1, "", "fmod"], [954, 5, 1, "", "frac"], [955, 5, 1, "", "frexp"], [956, 5, 1, "", "from_dlpack"], [957, 5, 1, "", "from_numpy"], [958, 5, 1, "", "frombuffer"], [959, 5, 1, "", "full"], [960, 5, 1, "", "full_like"], [55, 0, 0, "-", "func"], [59, 0, 0, "-", "futures"], [60, 0, 0, "-", "fx"], [972, 5, 1, "", "gather"], [973, 5, 1, "", "gcd"], [974, 5, 1, "", "ge"], [975, 5, 1, "", "geqrf"], [976, 5, 1, "", "ger"], [977, 5, 1, "", "get_default_dtype"], [978, 5, 1, "", "get_deterministic_debug_mode"], [979, 5, 1, "", "get_float32_matmul_precision"], [980, 5, 1, "", "get_num_interop_threads"], [981, 5, 1, "", "get_num_threads"], [982, 5, 1, "", "get_rng_state"], [983, 5, 1, "", "gradient"], [984, 5, 1, "", "greater"], [985, 5, 1, "", "greater_equal"], [986, 5, 1, "", "gt"], [987, 5, 1, "", "hamming_window"], [988, 5, 1, "", "hann_window"], [989, 5, 1, "", "heaviside"], [990, 5, 1, "", "histc"], [991, 5, 1, "", "histogram"], [992, 5, 1, "", "histogramdd"], [993, 5, 1, "", "hsplit"], [994, 5, 1, "", "hspmm"], [995, 5, 1, "", "hstack"], [1735, 0, 0, "-", "hub"], [996, 5, 1, "", "hypot"], [997, 5, 1, "", "i0"], [998, 5, 1, "", "igamma"], [999, 5, 1, "", "igammac"], [1000, 5, 1, "", "imag"], [1001, 5, 1, "", "index_add"], [1002, 5, 1, "", "index_copy"], [1003, 5, 1, "", "index_reduce"], [1004, 5, 1, "", "index_select"], [1005, 1, 1, "", "inference_mode"], [1006, 5, 1, "", "initial_seed"], [1007, 5, 1, "", "inner"], [1008, 5, 1, "", "inverse"], [1009, 5, 1, "", "is_complex"], [1010, 5, 1, "", "is_conj"], [1011, 5, 1, "", "is_deterministic_algorithms_warn_only_enabled"], [1012, 5, 1, "", "is_floating_point"], [1013, 5, 1, "", "is_grad_enabled"], [1014, 5, 1, "", "is_inference_mode_enabled"], [1015, 5, 1, "", "is_nonzero"], [1016, 5, 1, "", "is_storage"], [1017, 5, 1, "", "is_tensor"], [1018, 5, 1, "", "is_warn_always_enabled"], [1019, 5, 1, "", "isclose"], [1020, 5, 1, "", "isfinite"], [1021, 5, 1, "", "isin"], [1022, 5, 1, "", "isinf"], [1023, 5, 1, "", "isnan"], [1024, 5, 1, "", "isneginf"], [1025, 5, 1, "", "isposinf"], [1026, 5, 1, "", "isreal"], [1027, 5, 1, "", "istft"], [1738, 0, 0, "-", "jit"], [1049, 5, 1, "", "kaiser_window"], [1050, 5, 1, "", "kron"], [1051, 5, 1, "", "kthvalue"], [1796, 1, 1, "", "layout"], [1052, 5, 1, "", "lcm"], [1053, 5, 1, "", "ldexp"], [1054, 5, 1, "", "le"], [1055, 5, 1, "", "lerp"], [1056, 5, 1, "", "less"], [1057, 5, 1, "", "less_equal"], [1058, 5, 1, "", "lgamma"], [1746, 0, 0, "-", "linalg"], [1100, 5, 1, "", "linspace"], [1101, 5, 1, "", "load"], [1102, 5, 1, "", "lobpcg"], [1103, 5, 1, "", "log"], [1104, 5, 1, "", "log10"], [1105, 5, 1, "", "log1p"], [1106, 5, 1, "", "log2"], [1107, 5, 1, "", "logaddexp"], [1108, 5, 1, "", "logaddexp2"], [1109, 5, 1, "", "logcumsumexp"], [1110, 5, 1, "", "logdet"], [1111, 5, 1, "", "logical_and"], [1112, 5, 1, "", "logical_not"], [1113, 5, 1, "", "logical_or"], [1114, 5, 1, "", "logical_xor"], [1115, 5, 1, "", "logit"], [1116, 5, 1, "", "logspace"], [1117, 5, 1, "", "logsumexp"], [1118, 5, 1, "", "lt"], [1119, 5, 1, "", "lu"], [1120, 5, 1, "", "lu_solve"], [1121, 5, 1, "", "lu_unpack"], [1122, 5, 1, "", "manual_seed"], [1747, 0, 0, "-", "masked"], [1123, 5, 1, "", "masked_select"], [1124, 5, 1, "", "matmul"], [1125, 5, 1, "", "matrix_exp"], [1126, 5, 1, "", "matrix_power"], [1127, 5, 1, "", "max"], [1128, 5, 1, "", "maximum"], [1129, 5, 1, "", "mean"], [1130, 5, 1, "", "median"], [1796, 1, 1, "", "memory_format"], [1131, 5, 1, "", "meshgrid"], [1132, 5, 1, "", "min"], [1133, 5, 1, "", "minimum"], [1134, 5, 1, "", "mm"], [1135, 5, 1, "", "mode"], [1750, 0, 0, "-", "monitor"], [1136, 5, 1, "", "moveaxis"], [1137, 5, 1, "", "movedim"], [1138, 5, 1, "", "msort"], [1139, 5, 1, "", "mul"], [1140, 5, 1, "", "multinomial"], [1141, 5, 1, "", "multiply"], [1751, 0, 0, "-", "multiprocessing"], [1142, 5, 1, "", "mv"], [1143, 5, 1, "", "mvlgamma"], [1144, 5, 1, "", "nan_to_num"], [1145, 5, 1, "", "nanmean"], [1146, 5, 1, "", "nanmedian"], [1147, 5, 1, "", "nanquantile"], [1148, 5, 1, "", "nansum"], [1149, 5, 1, "", "narrow"], [1150, 5, 1, "", "narrow_copy"], [1151, 5, 1, "", "ne"], [1152, 5, 1, "", "neg"], [1153, 5, 1, "", "negative"], [1754, 0, 0, "-", "nested"], [1154, 5, 1, "", "nextafter"], [1755, 0, 0, "-", "nn"], [1468, 1, 1, "", "no_grad"], [1469, 5, 1, "", "nonzero"], [1470, 5, 1, "", "norm"], [1471, 5, 1, "", "normal"], [1472, 5, 1, "", "not_equal"], [1473, 5, 1, "", "numel"], [1474, 5, 1, "", "ones"], [1475, 5, 1, "", "ones_like"], [1777, 0, 0, "-", "onnx"], [1780, 0, 0, "-", "optim"], [1510, 5, 1, "", "orgqr"], [1511, 5, 1, "", "ormqr"], [1512, 5, 1, "", "outer"], [1781, 0, 0, "-", "package"], [1513, 5, 1, "", "pca_lowrank"], [1514, 5, 1, "", "permute"], [1515, 5, 1, "", "pinverse"], [1516, 5, 1, "", "poisson"], [1517, 5, 1, "", "polar"], [1518, 5, 1, "", "polygamma"], [1519, 5, 1, "", "positive"], [1520, 5, 1, "", "pow"], [1521, 5, 1, "", "prod"], [1783, 0, 0, "-", "profiler"], [1522, 5, 1, "", "promote_types"], [1523, 5, 1, "", "qr"], [1524, 5, 1, "", "quantile"], [1784, 0, 0, "-", "quantization"], [1590, 5, 1, "", "quantize_per_channel"], [1591, 5, 1, "", "quantize_per_tensor"], [1592, 5, 1, "", "quantized_batch_norm"], [1593, 5, 1, "", "quantized_max_pool1d"], [1594, 5, 1, "", "quantized_max_pool2d"], [1596, 5, 1, "", "rad2deg"], [1597, 5, 1, "", "rand"], [1598, 5, 1, "", "rand_like"], [1599, 5, 1, "", "randint"], [1600, 5, 1, "", "randint_like"], [1601, 5, 1, "", "randn"], [1602, 5, 1, "", "randn_like"], [1788, 0, 0, "-", "random"], [1603, 5, 1, "", "randperm"], [1604, 5, 1, "", "range"], [1605, 5, 1, "", "ravel"], [1606, 5, 1, "", "real"], [1607, 5, 1, "", "reciprocal"], [1608, 5, 1, "", "remainder"], [1609, 5, 1, "", "renorm"], [1610, 5, 1, "", "repeat_interleave"], [1611, 5, 1, "", "reshape"], [1612, 5, 1, "", "resolve_conj"], [1613, 5, 1, "", "resolve_neg"], [1614, 5, 1, "", "result_type"], [1615, 5, 1, "", "roll"], [1616, 5, 1, "", "rot90"], [1617, 5, 1, "", "round"], [1618, 5, 1, "", "row_stack"], [1619, 5, 1, "", "rsqrt"], [1620, 5, 1, "", "save"], [1621, 5, 1, "", "scatter"], [1622, 5, 1, "", "scatter_add"], [1623, 5, 1, "", "scatter_reduce"], [1624, 5, 1, "", "searchsorted"], [1625, 5, 1, "", "seed"], [1626, 5, 1, "", "select"], [1627, 5, 1, "", "select_scatter"], [1628, 5, 1, "", "set_default_device"], [1629, 5, 1, "", "set_default_dtype"], [1630, 5, 1, "", "set_default_tensor_type"], [1631, 5, 1, "", "set_deterministic_debug_mode"], [1632, 5, 1, "", "set_float32_matmul_precision"], [1633, 5, 1, "", "set_flush_denormal"], [1634, 1, 1, "", "set_grad_enabled"], [1635, 5, 1, "", "set_num_interop_threads"], [1636, 5, 1, "", "set_num_threads"], [1637, 5, 1, "", "set_printoptions"], [1638, 5, 1, "", "set_rng_state"], [1639, 5, 1, "", "set_warn_always"], [1640, 5, 1, "", "sgn"], [1641, 5, 1, "", "sigmoid"], [1642, 5, 1, "", "sign"], [1792, 0, 0, "-", "signal"], [1654, 5, 1, "", "signbit"], [1655, 5, 1, "", "sin"], [1656, 5, 1, "", "sinc"], [1657, 5, 1, "", "sinh"], [1658, 5, 1, "", "slice_scatter"], [1659, 5, 1, "", "slogdet"], [1660, 5, 1, "", "smm"], [1661, 5, 1, "", "softmax"], [1662, 5, 1, "", "sort"], [1793, 0, 0, "-", "sparse"], [1670, 5, 1, "", "sparse_bsc_tensor"], [1671, 5, 1, "", "sparse_bsr_tensor"], [1672, 5, 1, "", "sparse_compressed_tensor"], [1673, 5, 1, "", "sparse_coo_tensor"], [1674, 5, 1, "", "sparse_csc_tensor"], [1675, 5, 1, "", "sparse_csr_tensor"], [1794, 0, 0, "-", "special"], [1676, 5, 1, "", "split"], [1677, 5, 1, "", "sqrt"], [1678, 5, 1, "", "square"], [1679, 5, 1, "", "squeeze"], [1680, 5, 1, "", "sspaddmm"], [1681, 5, 1, "", "stack"], [1682, 5, 1, "", "std"], [1683, 5, 1, "", "std_mean"], [1684, 5, 1, "", "stft"], [1685, 5, 1, "", "sub"], [1686, 5, 1, "", "subtract"], [1687, 5, 1, "", "sum"], [1688, 5, 1, "", "svd"], [1689, 5, 1, "", "svd_lowrank"], [1690, 5, 1, "", "swapaxes"], [1691, 5, 1, "", "swapdims"], [1692, 5, 1, "", "sym_float"], [1693, 5, 1, "", "sym_int"], [1694, 5, 1, "", "symeig"], [1695, 5, 1, "", "t"], [1696, 5, 1, "", "take"], [1697, 5, 1, "", "take_along_dim"], [1698, 5, 1, "", "tan"], [1699, 5, 1, "", "tanh"], [1700, 5, 1, "", "tensor"], [1701, 5, 1, "", "tensor_split"], [1702, 5, 1, "", "tensordot"], [1800, 0, 0, "-", "testing"], [1703, 5, 1, "", "tile"], [1704, 5, 1, "", "topk"], [1705, 5, 1, "", "trace"], [1706, 5, 1, "", "transpose"], [1707, 5, 1, "", "trapezoid"], [1708, 5, 1, "", "trapz"], [1709, 5, 1, "", "triangular_solve"], [1710, 5, 1, "", "tril"], [1711, 5, 1, "", "tril_indices"], [1712, 5, 1, "", "triu"], [1713, 5, 1, "", "triu_indices"], [1714, 5, 1, "", "true_divide"], [1715, 5, 1, "", "trunc"], [1716, 5, 1, "", "unbind"], [1717, 5, 1, "", "unflatten"], [1718, 5, 1, "", "unique"], [1719, 5, 1, "", "unique_consecutive"], [1720, 5, 1, "", "unsqueeze"], [1721, 5, 1, "", "use_deterministic_algorithms"], [1801, 0, 0, "-", "utils"], [1722, 5, 1, "", "vander"], [1723, 5, 1, "", "var"], [1724, 5, 1, "", "var_mean"], [1725, 5, 1, "", "vdot"], [1726, 5, 1, "", "view_as_complex"], [1727, 5, 1, "", "view_as_real"], [1728, 5, 1, "", "vmap"], [1729, 5, 1, "", "vsplit"], [1730, 5, 1, "", "vstack"], [1731, 5, 1, "", "where"], [1732, 5, 1, "", "xlogy"], [1733, 5, 1, "", "zeros"], [1734, 5, 1, "", "zeros_like"]], "torch.BFloat16Storage": [[1795, 2, 1, "", "dtype"]], "torch.BoolStorage": [[1795, 2, 1, "", "dtype"]], "torch.ByteStorage": [[1795, 2, 1, "", "dtype"]], "torch.CharStorage": [[1795, 2, 1, "", "dtype"]], "torch.ComplexDoubleStorage": [[1795, 2, 1, "", "dtype"]], "torch.ComplexFloatStorage": [[1795, 2, 1, "", "dtype"]], "torch.DoubleStorage": [[1795, 2, 1, "", "dtype"]], "torch.FloatStorage": [[1795, 2, 1, "", "dtype"]], "torch.Generator": [[65, 2, 1, "", "device"], [65, 3, 1, "", "get_state"], [65, 3, 1, "", "initial_seed"], [65, 3, 1, "", "manual_seed"], [65, 3, 1, "", "seed"], [65, 3, 1, "", "set_state"]], "torch.HalfStorage": [[1795, 2, 1, "", "dtype"]], "torch.IntStorage": [[1795, 2, 1, "", "dtype"]], "torch.LongStorage": [[1795, 2, 1, "", "dtype"]], "torch.QInt32Storage": [[1795, 2, 1, "", "dtype"]], "torch.QInt8Storage": [[1795, 2, 1, "", "dtype"]], "torch.QUInt2x4Storage": [[1795, 2, 1, "", "dtype"]], "torch.QUInt4x2Storage": [[1795, 2, 1, "", "dtype"]], "torch.QUInt8Storage": [[1795, 2, 1, "", "dtype"]], "torch.ShortStorage": [[1795, 2, 1, "", "dtype"]], "torch.Tag": [[1801, 4, 1, "", "name"]], "torch.Tensor": [[1799, 2, 1, "", "H"], [1799, 2, 1, "", "T"], [66, 3, 1, "", "abs"], [67, 3, 1, "", "abs_"], [68, 3, 1, "", "absolute"], [69, 3, 1, "", "absolute_"], [70, 3, 1, "", "acos"], [71, 3, 1, "", "acos_"], [72, 3, 1, "", "acosh"], [73, 3, 1, "", "acosh_"], [74, 3, 1, "", "add"], [75, 3, 1, "", "add_"], [76, 3, 1, "", "addbmm"], [77, 3, 1, "", "addbmm_"], [78, 3, 1, "", "addcdiv"], [79, 3, 1, "", "addcdiv_"], [80, 3, 1, "", "addcmul"], [81, 3, 1, "", "addcmul_"], [82, 3, 1, "", "addmm"], [83, 3, 1, "", "addmm_"], [84, 3, 1, "", "addmv"], [85, 3, 1, "", "addmv_"], [86, 3, 1, "", "addr"], [87, 3, 1, "", "addr_"], [88, 3, 1, "", "adjoint"], [1753, 3, 1, "", "align_as"], [1753, 3, 1, "", "align_to"], [89, 3, 1, "", "all"], [90, 3, 1, "", "allclose"], [91, 3, 1, "", "amax"], [92, 3, 1, "", "amin"], [93, 3, 1, "", "aminmax"], [94, 3, 1, "", "angle"], [95, 3, 1, "", "any"], [96, 3, 1, "", "apply_"], [97, 3, 1, "", "arccos"], [98, 3, 1, "", "arccos_"], [99, 3, 1, "", "arccosh"], [100, 3, 1, "", "arccosh_"], [101, 3, 1, "", "arcsin"], [102, 3, 1, "", "arcsin_"], [103, 3, 1, "", "arcsinh"], [104, 3, 1, "", "arcsinh_"], [105, 3, 1, "", "arctan"], [106, 3, 1, "", "arctan2"], [107, 3, 1, "", "arctan2_"], [108, 3, 1, "", "arctan_"], [109, 3, 1, "", "arctanh"], [110, 3, 1, "", "arctanh_"], [111, 3, 1, "", "argmax"], [112, 3, 1, "", "argmin"], [113, 3, 1, "", "argsort"], [114, 3, 1, "", "argwhere"], [115, 3, 1, "", "as_strided"], [116, 3, 1, "", "as_subclass"], [117, 3, 1, "", "asin"], [118, 3, 1, "", "asin_"], [119, 3, 1, "", "asinh"], [120, 3, 1, "", "asinh_"], [121, 3, 1, "", "atan"], [122, 3, 1, "", "atan2"], [123, 3, 1, "", "atan2_"], [124, 3, 1, "", "atan_"], [125, 3, 1, "", "atanh"], [126, 3, 1, "", "atanh_"], [127, 3, 1, "", "backward"], [128, 3, 1, "", "baddbmm"], [129, 3, 1, "", "baddbmm_"], [130, 3, 1, "", "bernoulli"], [131, 3, 1, "", "bernoulli_"], [132, 3, 1, "", "bfloat16"], [133, 3, 1, "", "bincount"], [134, 3, 1, "", "bitwise_and"], [135, 3, 1, "", "bitwise_and_"], [136, 3, 1, "", "bitwise_left_shift"], [137, 3, 1, "", "bitwise_left_shift_"], [138, 3, 1, "", "bitwise_not"], [139, 3, 1, "", "bitwise_not_"], [140, 3, 1, "", "bitwise_or"], [141, 3, 1, "", "bitwise_or_"], [142, 3, 1, "", "bitwise_right_shift"], [143, 3, 1, "", "bitwise_right_shift_"], [144, 3, 1, "", "bitwise_xor"], [145, 3, 1, "", "bitwise_xor_"], [146, 3, 1, "", "bmm"], [147, 3, 1, "", "bool"], [148, 3, 1, "", "broadcast_to"], [149, 3, 1, "", "byte"], [150, 3, 1, "", "cauchy_"], [151, 3, 1, "", "ccol_indices"], [152, 3, 1, "", "cdouble"], [153, 3, 1, "", "ceil"], [154, 3, 1, "", "ceil_"], [155, 3, 1, "", "cfloat"], [156, 3, 1, "", "chalf"], [157, 3, 1, "", "char"], [158, 3, 1, "", "cholesky"], [159, 3, 1, "", "cholesky_inverse"], [160, 3, 1, "", "cholesky_solve"], [161, 3, 1, "", "chunk"], [162, 3, 1, "", "clamp"], [163, 3, 1, "", "clamp_"], [164, 3, 1, "", "clip"], [165, 3, 1, "", "clip_"], [166, 3, 1, "", "clone"], [167, 3, 1, "", "coalesce"], [168, 3, 1, "", "col_indices"], [169, 3, 1, "", "conj"], [170, 3, 1, "", "conj_physical"], [171, 3, 1, "", "conj_physical_"], [172, 3, 1, "", "contiguous"], [173, 3, 1, "", "copy_"], [174, 3, 1, "", "copysign"], [175, 3, 1, "", "copysign_"], [176, 3, 1, "", "corrcoef"], [177, 3, 1, "", "cos"], [178, 3, 1, "", "cos_"], [179, 3, 1, "", "cosh"], [180, 3, 1, "", "cosh_"], [181, 3, 1, "", "count_nonzero"], [182, 3, 1, "", "cov"], [183, 3, 1, "", "cpu"], [184, 3, 1, "", "cross"], [185, 3, 1, "", "crow_indices"], [186, 3, 1, "", "cuda"], [187, 3, 1, "", "cummax"], [188, 3, 1, "", "cummin"], [189, 3, 1, "", "cumprod"], [190, 3, 1, "", "cumprod_"], [191, 3, 1, "", "cumsum"], [192, 3, 1, "", "cumsum_"], [193, 3, 1, "", "data_ptr"], [194, 3, 1, "", "deg2rad"], [195, 3, 1, "", "dense_dim"], [196, 3, 1, "", "dequantize"], [197, 3, 1, "", "det"], [198, 3, 1, "", "detach"], [199, 3, 1, "", "detach_"], [200, 2, 1, "", "device"], [201, 3, 1, "", "diag"], [202, 3, 1, "", "diag_embed"], [203, 3, 1, "", "diagflat"], [204, 3, 1, "", "diagonal"], [205, 3, 1, "", "diagonal_scatter"], [206, 3, 1, "", "diff"], [207, 3, 1, "", "digamma"], [208, 3, 1, "", "digamma_"], [209, 3, 1, "", "dim"], [210, 3, 1, "", "dist"], [211, 3, 1, "", "div"], [212, 3, 1, "", "div_"], [213, 3, 1, "", "divide"], [214, 3, 1, "", "divide_"], [215, 3, 1, "", "dot"], [216, 3, 1, "", "double"], [217, 3, 1, "", "dsplit"], [218, 3, 1, "", "element_size"], [219, 3, 1, "", "eq"], [220, 3, 1, "", "eq_"], [221, 3, 1, "", "equal"], [222, 3, 1, "", "erf"], [223, 3, 1, "", "erf_"], [224, 3, 1, "", "erfc"], [225, 3, 1, "", "erfc_"], [226, 3, 1, "", "erfinv"], [227, 3, 1, "", "erfinv_"], [228, 3, 1, "", "exp"], [229, 3, 1, "", "exp_"], [230, 3, 1, "", "expand"], [231, 3, 1, "", "expand_as"], [232, 3, 1, "", "expm1"], [233, 3, 1, "", "expm1_"], [234, 3, 1, "", "exponential_"], [235, 3, 1, "", "fill_"], [236, 3, 1, "", "fill_diagonal_"], [237, 3, 1, "", "fix"], [238, 3, 1, "", "fix_"], [239, 3, 1, "", "flatten"], [240, 3, 1, "", "flip"], [241, 3, 1, "", "fliplr"], [242, 3, 1, "", "flipud"], [243, 3, 1, "", "float"], [244, 3, 1, "", "float_power"], [245, 3, 1, "", "float_power_"], [246, 3, 1, "", "floor"], [247, 3, 1, "", "floor_"], [248, 3, 1, "", "floor_divide"], [249, 3, 1, "", "floor_divide_"], [250, 3, 1, "", "fmax"], [251, 3, 1, "", "fmin"], [252, 3, 1, "", "fmod"], [253, 3, 1, "", "fmod_"], [254, 3, 1, "", "frac"], [255, 3, 1, "", "frac_"], [256, 3, 1, "", "frexp"], [257, 3, 1, "", "gather"], [258, 3, 1, "", "gcd"], [259, 3, 1, "", "gcd_"], [260, 3, 1, "", "ge"], [261, 3, 1, "", "ge_"], [262, 3, 1, "", "geometric_"], [263, 3, 1, "", "geqrf"], [264, 3, 1, "", "ger"], [265, 3, 1, "", "get_device"], [266, 2, 1, "", "grad"], [267, 3, 1, "", "greater"], [268, 3, 1, "", "greater_"], [269, 3, 1, "", "greater_equal"], [270, 3, 1, "", "greater_equal_"], [271, 3, 1, "", "gt"], [272, 3, 1, "", "gt_"], [273, 3, 1, "", "half"], [274, 3, 1, "", "hardshrink"], [275, 3, 1, "", "heaviside"], [276, 3, 1, "", "histc"], [277, 3, 1, "", "histogram"], [278, 3, 1, "", "hsplit"], [279, 3, 1, "", "hypot"], [280, 3, 1, "", "hypot_"], [281, 3, 1, "", "i0"], [282, 3, 1, "", "i0_"], [283, 3, 1, "", "igamma"], [284, 3, 1, "", "igamma_"], [285, 3, 1, "", "igammac"], [286, 3, 1, "", "igammac_"], [287, 2, 1, "", "imag"], [288, 3, 1, "", "index_add"], [289, 3, 1, "", "index_add_"], [290, 3, 1, "", "index_copy"], [291, 3, 1, "", "index_copy_"], [292, 3, 1, "", "index_fill"], [293, 3, 1, "", "index_fill_"], [294, 3, 1, "", "index_put"], [295, 3, 1, "", "index_put_"], [296, 3, 1, "", "index_reduce"], [297, 3, 1, "", "index_reduce_"], [298, 3, 1, "", "index_select"], [299, 3, 1, "", "indices"], [300, 3, 1, "", "inner"], [301, 3, 1, "", "int"], [302, 3, 1, "", "int_repr"], [303, 3, 1, "", "inverse"], [304, 3, 1, "", "is_coalesced"], [305, 3, 1, "", "is_complex"], [306, 3, 1, "", "is_conj"], [307, 3, 1, "", "is_contiguous"], [308, 2, 1, "", "is_cuda"], [309, 3, 1, "", "is_floating_point"], [310, 3, 1, "", "is_inference"], [311, 2, 1, "", "is_leaf"], [312, 2, 1, "", "is_meta"], [313, 3, 1, "", "is_pinned"], [314, 2, 1, "", "is_quantized"], [315, 3, 1, "", "is_set_to"], [316, 3, 1, "", "is_shared"], [317, 3, 1, "", "is_signed"], [318, 2, 1, "", "is_sparse"], [319, 2, 1, "", "is_sparse_csr"], [320, 3, 1, "", "isclose"], [321, 3, 1, "", "isfinite"], [322, 3, 1, "", "isinf"], [323, 3, 1, "", "isnan"], [324, 3, 1, "", "isneginf"], [325, 3, 1, "", "isposinf"], [326, 3, 1, "", "isreal"], [327, 3, 1, "", "istft"], [328, 3, 1, "", "item"], [329, 3, 1, "", "kthvalue"], [330, 3, 1, "", "lcm"], [331, 3, 1, "", "lcm_"], [332, 3, 1, "", "ldexp"], [333, 3, 1, "", "ldexp_"], [334, 3, 1, "", "le"], [335, 3, 1, "", "le_"], [336, 3, 1, "", "lerp"], [337, 3, 1, "", "lerp_"], [338, 3, 1, "", "less"], [339, 3, 1, "", "less_"], [340, 3, 1, "", "less_equal"], [341, 3, 1, "", "less_equal_"], [342, 3, 1, "", "lgamma"], [343, 3, 1, "", "lgamma_"], [344, 3, 1, "", "log"], [345, 3, 1, "", "log10"], [346, 3, 1, "", "log10_"], [347, 3, 1, "", "log1p"], [348, 3, 1, "", "log1p_"], [349, 3, 1, "", "log2"], [350, 3, 1, "", "log2_"], [351, 3, 1, "", "log_"], [352, 3, 1, "", "log_normal_"], [353, 3, 1, "", "logaddexp"], [354, 3, 1, "", "logaddexp2"], [355, 3, 1, "", "logcumsumexp"], [356, 3, 1, "", "logdet"], [357, 3, 1, "", "logical_and"], [358, 3, 1, "", "logical_and_"], [359, 3, 1, "", "logical_not"], [360, 3, 1, "", "logical_not_"], [361, 3, 1, "", "logical_or"], [362, 3, 1, "", "logical_or_"], [363, 3, 1, "", "logical_xor"], [364, 3, 1, "", "logical_xor_"], [365, 3, 1, "", "logit"], [366, 3, 1, "", "logit_"], [367, 3, 1, "", "logsumexp"], [368, 3, 1, "", "long"], [369, 3, 1, "", "lt"], [370, 3, 1, "", "lt_"], [371, 3, 1, "", "lu"], [372, 3, 1, "", "lu_solve"], [1799, 2, 1, "", "mH"], [1799, 2, 1, "", "mT"], [373, 3, 1, "", "map_"], [374, 3, 1, "", "masked_fill"], [375, 3, 1, "", "masked_fill_"], [376, 3, 1, "", "masked_scatter"], [377, 3, 1, "", "masked_scatter_"], [378, 3, 1, "", "masked_select"], [379, 3, 1, "", "matmul"], [380, 3, 1, "", "matrix_exp"], [381, 3, 1, "", "matrix_power"], [382, 3, 1, "", "max"], [383, 3, 1, "", "maximum"], [384, 3, 1, "", "mean"], [385, 3, 1, "", "median"], [386, 3, 1, "", "min"], [387, 3, 1, "", "minimum"], [388, 3, 1, "", "mm"], [389, 3, 1, "", "mode"], [390, 3, 1, "", "moveaxis"], [391, 3, 1, "", "movedim"], [392, 3, 1, "", "msort"], [393, 3, 1, "", "mul"], [394, 3, 1, "", "mul_"], [395, 3, 1, "", "multinomial"], [396, 3, 1, "", "multiply"], [397, 3, 1, "", "multiply_"], [398, 3, 1, "", "mv"], [399, 3, 1, "", "mvlgamma"], [400, 3, 1, "", "mvlgamma_"], [1753, 2, 1, "", "names"], [401, 3, 1, "", "nan_to_num"], [402, 3, 1, "", "nan_to_num_"], [403, 3, 1, "", "nanmean"], [404, 3, 1, "", "nanmedian"], [405, 3, 1, "", "nanquantile"], [406, 3, 1, "", "nansum"], [407, 3, 1, "", "narrow"], [408, 3, 1, "", "narrow_copy"], [409, 2, 1, "", "ndim"], [410, 3, 1, "", "ndimension"], [411, 3, 1, "", "ne"], [412, 3, 1, "", "ne_"], [413, 3, 1, "", "neg"], [414, 3, 1, "", "neg_"], [415, 3, 1, "", "negative"], [416, 3, 1, "", "negative_"], [417, 3, 1, "", "nelement"], [418, 3, 1, "", "new_empty"], [419, 3, 1, "", "new_full"], [420, 3, 1, "", "new_ones"], [421, 3, 1, "", "new_tensor"], [422, 3, 1, "", "new_zeros"], [423, 3, 1, "", "nextafter"], [424, 3, 1, "", "nextafter_"], [425, 3, 1, "", "nonzero"], [426, 3, 1, "", "norm"], [427, 3, 1, "", "normal_"], [428, 3, 1, "", "not_equal"], [429, 3, 1, "", "not_equal_"], [430, 3, 1, "", "numel"], [431, 3, 1, "", "numpy"], [432, 3, 1, "", "orgqr"], [433, 3, 1, "", "ormqr"], [434, 3, 1, "", "outer"], [435, 3, 1, "", "permute"], [436, 3, 1, "", "pin_memory"], [437, 3, 1, "", "pinverse"], [438, 3, 1, "", "polygamma"], [439, 3, 1, "", "polygamma_"], [440, 3, 1, "", "positive"], [441, 3, 1, "", "pow"], [442, 3, 1, "", "pow_"], [443, 3, 1, "", "prod"], [444, 3, 1, "", "put_"], [445, 3, 1, "", "q_per_channel_axis"], [446, 3, 1, "", "q_per_channel_scales"], [447, 3, 1, "", "q_per_channel_zero_points"], [448, 3, 1, "", "q_scale"], [449, 3, 1, "", "q_zero_point"], [450, 3, 1, "", "qr"], [451, 3, 1, "", "qscheme"], [452, 3, 1, "", "quantile"], [453, 3, 1, "", "rad2deg"], [454, 3, 1, "", "random_"], [455, 3, 1, "", "ravel"], [456, 2, 1, "", "real"], [457, 3, 1, "", "reciprocal"], [458, 3, 1, "", "reciprocal_"], [459, 3, 1, "", "record_stream"], [1753, 3, 1, "", "refine_names"], [460, 3, 1, "", "register_hook"], [461, 3, 1, "", "remainder"], [462, 3, 1, "", "remainder_"], [1753, 3, 1, "", "rename"], [1753, 3, 1, "", "rename_"], [463, 3, 1, "", "renorm"], [464, 3, 1, "", "renorm_"], [465, 3, 1, "", "repeat"], [466, 3, 1, "", "repeat_interleave"], [467, 2, 1, "", "requires_grad"], [468, 3, 1, "", "requires_grad_"], [469, 3, 1, "", "reshape"], [470, 3, 1, "", "reshape_as"], [471, 3, 1, "", "resize_"], [472, 3, 1, "", "resize_as_"], [473, 3, 1, "", "resolve_conj"], [474, 3, 1, "", "resolve_neg"], [475, 3, 1, "", "retain_grad"], [476, 2, 1, "", "retains_grad"], [477, 3, 1, "", "roll"], [478, 3, 1, "", "rot90"], [479, 3, 1, "", "round"], [480, 3, 1, "", "round_"], [481, 3, 1, "", "row_indices"], [482, 3, 1, "", "rsqrt"], [483, 3, 1, "", "rsqrt_"], [484, 3, 1, "", "scatter"], [485, 3, 1, "", "scatter_"], [486, 3, 1, "", "scatter_add"], [487, 3, 1, "", "scatter_add_"], [488, 3, 1, "", "scatter_reduce"], [489, 3, 1, "", "scatter_reduce_"], [490, 3, 1, "", "select"], [491, 3, 1, "", "select_scatter"], [492, 3, 1, "", "set_"], [493, 3, 1, "", "sgn"], [494, 3, 1, "", "sgn_"], [495, 3, 1, "", "share_memory_"], [496, 3, 1, "", "short"], [497, 3, 1, "", "sigmoid"], [498, 3, 1, "", "sigmoid_"], [499, 3, 1, "", "sign"], [500, 3, 1, "", "sign_"], [501, 3, 1, "", "signbit"], [502, 3, 1, "", "sin"], [503, 3, 1, "", "sin_"], [504, 3, 1, "", "sinc"], [505, 3, 1, "", "sinc_"], [506, 3, 1, "", "sinh"], [507, 3, 1, "", "sinh_"], [508, 3, 1, "", "size"], [509, 3, 1, "", "slice_scatter"], [510, 3, 1, "", "slogdet"], [511, 3, 1, "", "smm"], [512, 3, 1, "", "softmax"], [513, 3, 1, "", "sort"], [514, 3, 1, "", "sparse_dim"], [515, 3, 1, "", "sparse_mask"], [516, 3, 1, "", "sparse_resize_"], [517, 3, 1, "", "sparse_resize_and_clear_"], [518, 3, 1, "", "split"], [519, 3, 1, "", "sqrt"], [520, 3, 1, "", "sqrt_"], [521, 3, 1, "", "square"], [522, 3, 1, "", "square_"], [523, 3, 1, "", "squeeze"], [524, 3, 1, "", "squeeze_"], [525, 3, 1, "", "sspaddmm"], [526, 3, 1, "", "std"], [527, 3, 1, "", "stft"], [528, 3, 1, "", "storage"], [529, 3, 1, "", "storage_offset"], [530, 3, 1, "", "storage_type"], [531, 3, 1, "", "stride"], [532, 3, 1, "", "sub"], [533, 3, 1, "", "sub_"], [534, 3, 1, "", "subtract"], [535, 3, 1, "", "subtract_"], [536, 3, 1, "", "sum"], [537, 3, 1, "", "sum_to_size"], [538, 3, 1, "", "svd"], [539, 3, 1, "", "swapaxes"], [540, 3, 1, "", "swapdims"], [541, 3, 1, "", "symeig"], [542, 3, 1, "", "t"], [543, 3, 1, "", "t_"], [544, 3, 1, "", "take"], [545, 3, 1, "", "take_along_dim"], [546, 3, 1, "", "tan"], [547, 3, 1, "", "tan_"], [548, 3, 1, "", "tanh"], [549, 3, 1, "", "tanh_"], [550, 3, 1, "", "tensor_split"], [551, 3, 1, "", "tile"], [552, 3, 1, "", "to"], [553, 3, 1, "", "to_dense"], [554, 3, 1, "", "to_mkldnn"], [555, 3, 1, "", "to_sparse"], [556, 3, 1, "", "to_sparse_bsc"], [557, 3, 1, "", "to_sparse_bsr"], [558, 3, 1, "", "to_sparse_coo"], [559, 3, 1, "", "to_sparse_csc"], [560, 3, 1, "", "to_sparse_csr"], [561, 3, 1, "", "tolist"], [562, 3, 1, "", "topk"], [563, 3, 1, "", "trace"], [564, 3, 1, "", "transpose"], [565, 3, 1, "", "transpose_"], [566, 3, 1, "", "triangular_solve"], [567, 3, 1, "", "tril"], [568, 3, 1, "", "tril_"], [569, 3, 1, "", "triu"], [570, 3, 1, "", "triu_"], [571, 3, 1, "", "true_divide"], [572, 3, 1, "", "true_divide_"], [573, 3, 1, "", "trunc"], [574, 3, 1, "", "trunc_"], [575, 3, 1, "", "type"], [576, 3, 1, "", "type_as"], [577, 3, 1, "", "unbind"], [578, 3, 1, "", "unflatten"], [579, 3, 1, "", "unfold"], [580, 3, 1, "", "uniform_"], [581, 3, 1, "", "unique"], [582, 3, 1, "", "unique_consecutive"], [583, 3, 1, "", "unsqueeze"], [584, 3, 1, "", "unsqueeze_"], [585, 3, 1, "", "untyped_storage"], [586, 3, 1, "", "values"], [587, 3, 1, "", "var"], [588, 3, 1, "", "vdot"], [589, 3, 1, "", "view"], [590, 3, 1, "", "view_as"], [591, 3, 1, "", "vsplit"], [592, 3, 1, "", "where"], [593, 3, 1, "", "xlogy"], [594, 3, 1, "", "xlogy_"], [595, 3, 1, "", "zero_"]], "torch.TypedStorage": [[1795, 3, 1, "", "bfloat16"], [1795, 3, 1, "", "bool"], [1795, 3, 1, "", "byte"], [1795, 3, 1, "", "char"], [1795, 3, 1, "", "clone"], [1795, 3, 1, "", "complex_double"], [1795, 3, 1, "", "complex_float"], [1795, 3, 1, "", "copy_"], [1795, 3, 1, "", "cpu"], [1795, 3, 1, "", "cuda"], [1795, 3, 1, "", "data_ptr"], [1795, 4, 1, "", "device"], [1795, 3, 1, "", "double"], [1795, 2, 1, "", "dtype"], [1795, 3, 1, "", "element_size"], [1795, 3, 1, "", "fill_"], [1795, 3, 1, "", "float"], [1795, 3, 1, "", "from_buffer"], [1795, 3, 1, "", "from_file"], [1795, 3, 1, "", "get_device"], [1795, 3, 1, "", "half"], [1795, 3, 1, "", "int"], [1795, 4, 1, "", "is_cuda"], [1795, 3, 1, "", "is_pinned"], [1795, 3, 1, "", "is_shared"], [1795, 2, 1, "", "is_sparse"], [1795, 3, 1, "", "long"], [1795, 3, 1, "", "nbytes"], [1795, 3, 1, "", "pickle_storage_type"], [1795, 3, 1, "", "pin_memory"], [1795, 3, 1, "", "resize_"], [1795, 3, 1, "", "share_memory_"], [1795, 3, 1, "", "short"], [1795, 3, 1, "", "size"], [1795, 3, 1, "", "tolist"], [1795, 3, 1, "", "type"], [1795, 3, 1, "", "untyped"]], "torch.UntypedStorage": [[1795, 3, 1, "", "bfloat16"], [1795, 3, 1, "", "bool"], [1795, 3, 1, "", "byte"], [1795, 3, 1, "", "char"], [1795, 3, 1, "", "clone"], [1795, 3, 1, "", "complex_double"], [1795, 3, 1, "", "complex_float"], [1795, 3, 1, "", "copy_"], [1795, 3, 1, "", "cpu"], [1795, 3, 1, "", "cuda"], [1795, 3, 1, "", "data_ptr"], [1795, 2, 1, "", "device"], [1795, 3, 1, "", "double"], [1795, 3, 1, "", "element_size"], [1795, 3, 1, "", "fill_"], [1795, 3, 1, "", "float"], [1795, 3, 1, "", "from_buffer"], [1795, 3, 1, "", "from_file"], [1795, 3, 1, "", "get_device"], [1795, 3, 1, "", "half"], [1795, 3, 1, "", "int"], [1795, 4, 1, "", "is_cuda"], [1795, 3, 1, "", "is_pinned"], [1795, 3, 1, "", "is_shared"], [1795, 2, 1, "", "is_sparse"], [1795, 2, 1, "", "is_sparse_csr"], [1795, 3, 1, "", "long"], [1795, 3, 1, "", "mps"], [1795, 3, 1, "", "nbytes"], [1795, 3, 1, "", "new"], [1795, 3, 1, "", "pin_memory"], [1795, 3, 1, "", "resize_"], [1795, 3, 1, "", "share_memory_"], [1795, 3, 1, "", "short"], [1795, 3, 1, "", "size"], [1795, 3, 1, "", "tolist"], [1795, 3, 1, "", "type"], [1795, 3, 1, "", "untyped"]], "torch.__config__": [[13, 5, 1, "", "parallel_info"], [13, 5, 1, "", "show"]], "torch._dynamo": [[0, 1, 1, "", "OptimizedModule"], [0, 5, 1, "", "allow_in_graph"], [0, 5, 1, "", "disable"], [0, 5, 1, "", "disallow_in_graph"], [0, 5, 1, "", "graph_break"], [0, 5, 1, "", "list_backends"], [0, 5, 1, "", "optimize"], [0, 5, 1, "", "optimize_assert"], [0, 5, 1, "", "reset"], [0, 5, 1, "", "run"], [0, 5, 1, "", "skip"]], "torch.ao": [[1784, 0, 0, "-", "nn"], [1784, 0, 0, "-", "ns"], [1784, 0, 0, "-", "pruning"], [1784, 0, 0, "-", "quantization"]], "torch.ao.nn": [[1787, 0, 0, "-", "intrinsic"], [1787, 0, 0, "-", "qat"], [1784, 0, 0, "-", "quantizable"], [1784, 0, 0, "-", "quantized"], [1784, 0, 0, "-", "sparse"]], "torch.ao.nn.intrinsic": [[616, 1, 1, "", "BNReLU2d"], [617, 1, 1, "", "BNReLU3d"], [618, 1, 1, "", "ConvBn1d"], [619, 1, 1, "", "ConvBn2d"], [620, 1, 1, "", "ConvBn3d"], [621, 1, 1, "", "ConvBnReLU1d"], [622, 1, 1, "", "ConvBnReLU2d"], [623, 1, 1, "", "ConvBnReLU3d"], [624, 1, 1, "", "ConvReLU1d"], [625, 1, 1, "", "ConvReLU2d"], [626, 1, 1, "", "ConvReLU3d"], [627, 1, 1, "", "LinearReLU"], [1787, 0, 0, "-", "modules"], [1787, 0, 0, "-", "qat"], [1787, 0, 0, "-", "quantized"]], "torch.ao.nn.intrinsic.qat": [[628, 1, 1, "", "ConvBn1d"], [629, 1, 1, "", "ConvBn2d"], [630, 1, 1, "", "ConvBn3d"], [631, 1, 1, "", "ConvBnReLU1d"], [632, 1, 1, "", "ConvBnReLU2d"], [633, 1, 1, "", "ConvBnReLU3d"], [634, 1, 1, "", "ConvReLU2d"], [635, 1, 1, "", "ConvReLU3d"], [636, 1, 1, "", "LinearReLU"], [637, 1, 1, "", "freeze_bn_stats"], [1787, 0, 0, "-", "modules"], [638, 1, 1, "", "update_bn_stats"]], "torch.ao.nn.intrinsic.quantized": [[639, 1, 1, "", "BNReLU2d"], [640, 1, 1, "", "BNReLU3d"], [641, 1, 1, "", "ConvReLU1d"], [642, 1, 1, "", "ConvReLU2d"], [643, 1, 1, "", "ConvReLU3d"], [644, 1, 1, "", "LinearReLU"], [1787, 0, 0, "-", "dynamic"], [1787, 0, 0, "-", "modules"]], "torch.ao.nn.intrinsic.quantized.dynamic": [[645, 1, 1, "", "LinearReLU"], [1787, 0, 0, "-", "modules"]], "torch.ao.nn.qat": [[646, 1, 1, "", "Conv2d"], [647, 1, 1, "", "Conv3d"], [648, 1, 1, "", "Linear"], [1787, 0, 0, "-", "dynamic"], [1787, 0, 0, "-", "modules"]], "torch.ao.nn.qat.Linear": [[648, 3, 1, "", "from_float"]], "torch.ao.nn.qat.dynamic": [[649, 1, 1, "", "Linear"], [1787, 0, 0, "-", "modules"]], "torch.ao.nn.quantizable": [[1784, 0, 0, "-", "modules"]], "torch.ao.nn.quantized": [[650, 1, 1, "", "BatchNorm2d"], [651, 1, 1, "", "BatchNorm3d"], [652, 1, 1, "", "Conv1d"], [653, 1, 1, "", "Conv2d"], [654, 1, 1, "", "Conv3d"], [655, 1, 1, "", "ConvTranspose1d"], [656, 1, 1, "", "ConvTranspose2d"], [657, 1, 1, "", "ConvTranspose3d"], [658, 1, 1, "", "ELU"], [659, 1, 1, "", "Embedding"], [660, 1, 1, "", "EmbeddingBag"], [661, 1, 1, "", "FXFloatFunctional"], [662, 1, 1, "", "FloatFunctional"], [663, 1, 1, "", "GroupNorm"], [664, 1, 1, "", "Hardswish"], [665, 1, 1, "", "InstanceNorm1d"], [666, 1, 1, "", "InstanceNorm2d"], [667, 1, 1, "", "InstanceNorm3d"], [668, 1, 1, "", "LayerNorm"], [669, 1, 1, "", "LeakyReLU"], [670, 1, 1, "", "Linear"], [671, 1, 1, "", "QFunctional"], [672, 1, 1, "", "ReLU6"], [673, 1, 1, "", "Sigmoid"], [1787, 0, 0, "-", "dynamic"], [1787, 0, 0, "-", "functional"], [1787, 0, 0, "-", "modules"], [1784, 0, 0, "-", "reference"]], "torch.ao.nn.quantized.Conv1d": [[652, 3, 1, "", "from_float"]], "torch.ao.nn.quantized.Conv2d": [[653, 3, 1, "", "from_float"]], "torch.ao.nn.quantized.Conv3d": [[654, 3, 1, "", "from_float"]], "torch.ao.nn.quantized.Embedding": [[659, 3, 1, "", "from_float"]], "torch.ao.nn.quantized.EmbeddingBag": [[660, 3, 1, "", "from_float"]], "torch.ao.nn.quantized.Linear": [[670, 3, 1, "", "from_float"], [670, 3, 1, "", "from_reference"]], "torch.ao.nn.quantized.dynamic": [[674, 1, 1, "", "GRU"], [675, 1, 1, "", "GRUCell"], [676, 1, 1, "", "LSTM"], [677, 1, 1, "", "LSTMCell"], [678, 1, 1, "", "Linear"], [679, 1, 1, "", "RNNCell"], [1787, 0, 0, "-", "modules"]], "torch.ao.nn.quantized.dynamic.Linear": [[678, 3, 1, "", "from_float"], [678, 3, 1, "", "from_reference"]], "torch.ao.nn.quantized.functional": [[680, 1, 1, "", "adaptive_avg_pool2d"], [681, 1, 1, "", "adaptive_avg_pool3d"], [682, 1, 1, "", "avg_pool2d"], [683, 1, 1, "", "avg_pool3d"], [684, 1, 1, "", "celu"], [685, 1, 1, "", "clamp"], [686, 1, 1, "", "conv1d"], [687, 1, 1, "", "conv2d"], [688, 1, 1, "", "conv3d"], [689, 1, 1, "", "elu"], [690, 1, 1, "", "hardsigmoid"], [691, 1, 1, "", "hardswish"], [692, 1, 1, "", "hardtanh"], [693, 1, 1, "", "interpolate"], [694, 1, 1, "", "leaky_relu"], [695, 1, 1, "", "linear"], [696, 1, 1, "", "max_pool1d"], [697, 1, 1, "", "max_pool2d"], [698, 1, 1, "", "threshold"], [699, 1, 1, "", "upsample"], [700, 1, 1, "", "upsample_bilinear"], [701, 1, 1, "", "upsample_nearest"]], "torch.ao.nn.quantized.reference": [[1784, 0, 0, "-", "modules"]], "torch.ao.nn.sparse": [[1784, 0, 0, "-", "quantized"]], "torch.ao.nn.sparse.quantized": [[1784, 0, 0, "-", "dynamic"]], "torch.ao.ns": [[1802, 0, 0, "-", "_numeric_suite"], [1803, 0, 0, "-", "_numeric_suite_fx"], [1784, 0, 0, "-", "fx"]], "torch.ao.ns._numeric_suite": [[1802, 1, 1, "", "Logger"], [1802, 1, 1, "", "OutputLogger"], [1802, 1, 1, "", "Shadow"], [1802, 1, 1, "", "ShadowLogger"], [1802, 5, 1, "", "compare_model_outputs"], [1802, 5, 1, "", "compare_model_stub"], [1802, 5, 1, "", "compare_weights"], [1802, 5, 1, "", "get_logger_dict"], [1802, 5, 1, "", "get_matching_activations"], [1802, 5, 1, "", "prepare_model_outputs"], [1802, 5, 1, "", "prepare_model_with_stubs"]], "torch.ao.ns._numeric_suite.Logger": [[1802, 3, 1, "", "forward"]], "torch.ao.ns._numeric_suite.OutputLogger": [[1802, 3, 1, "", "forward"]], "torch.ao.ns._numeric_suite.Shadow": [[1802, 3, 1, "", "add"], [1802, 3, 1, "", "add_relu"], [1802, 3, 1, "", "add_scalar"], [1802, 3, 1, "", "cat"], [1802, 3, 1, "", "forward"], [1802, 3, 1, "", "mul"], [1802, 3, 1, "", "mul_scalar"]], "torch.ao.ns._numeric_suite.ShadowLogger": [[1802, 3, 1, "", "forward"]], "torch.ao.ns._numeric_suite_fx": [[1803, 1, 1, "", "NSTracer"], [1803, 1, 1, "", "OutputComparisonLogger"], [1803, 1, 1, "", "OutputLogger"], [1803, 5, 1, "", "add_loggers"], [1803, 5, 1, "", "add_shadow_loggers"], [1803, 5, 1, "", "convert_n_shadows_model"], [1803, 5, 1, "", "extend_logger_results_with_comparison"], [1803, 5, 1, "", "extract_logger_info"], [1803, 5, 1, "", "extract_results_n_shadows_model"], [1803, 5, 1, "", "extract_shadow_logger_info"], [1803, 5, 1, "", "extract_weights"], [1803, 5, 1, "", "loggers_set_enabled"], [1803, 5, 1, "", "loggers_set_save_activations"], [1803, 5, 1, "", "prepare_n_shadows_model"], [1803, 5, 1, "", "print_comparisons_n_shadows_model"]], "torch.ao.ns._numeric_suite_fx.NSTracer": [[1803, 3, 1, "", "is_leaf_module"]], "torch.ao.ns._numeric_suite_fx.OutputComparisonLogger": [[1803, 3, 1, "", "forward"]], "torch.ao.ns._numeric_suite_fx.OutputLogger": [[1803, 3, 1, "", "forward"]], "torch.ao.ns.fx.utils": [[1803, 5, 1, "", "compute_cosine_similarity"], [1803, 5, 1, "", "compute_normalized_l2_error"], [1803, 5, 1, "", "compute_sqnr"]], "torch.ao.pruning": [[1784, 0, 0, "-", "scheduler"], [1784, 0, 0, "-", "sparsifier"]], "torch.ao.quantization": [[1784, 0, 0, "-", "backend_config"], [1784, 0, 0, "-", "fx"]], "torch.ao.quantization.backend_config": [[702, 1, 1, "", "BackendConfig"], [703, 1, 1, "", "BackendPatternConfig"], [704, 1, 1, "", "DTypeConfig"], [705, 1, 1, "", "ObservationType"]], "torch.ao.quantization.backend_config.BackendConfig": [[702, 4, 1, "", "configs"], [702, 3, 1, "", "from_dict"], [702, 3, 1, "", "set_backend_pattern_config"], [702, 3, 1, "", "set_backend_pattern_configs"], [702, 3, 1, "", "set_name"], [702, 3, 1, "", "to_dict"]], "torch.ao.quantization.backend_config.BackendPatternConfig": [[703, 3, 1, "", "add_dtype_config"], [703, 3, 1, "", "from_dict"], [703, 3, 1, "", "set_dtype_configs"], [703, 3, 1, "", "set_fused_module"], [703, 3, 1, "", "set_fuser_method"], [703, 3, 1, "", "set_observation_type"], [703, 3, 1, "", "set_pattern"], [703, 3, 1, "", "set_qat_module"], [703, 3, 1, "", "set_reference_quantized_module"], [703, 3, 1, "", "set_root_module"], [703, 3, 1, "", "to_dict"]], "torch.ao.quantization.backend_config.DTypeConfig": [[704, 3, 1, "", "from_dict"], [704, 3, 1, "", "to_dict"]], "torch.ao.quantization.backend_config.ObservationType": [[705, 2, 1, "", "OUTPUT_SHARE_OBSERVER_WITH_INPUT"], [705, 2, 1, "", "OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT"]], "torch.ao.quantization.fx.custom_config": [[706, 1, 1, "", "ConvertCustomConfig"], [707, 1, 1, "", "FuseCustomConfig"], [708, 1, 1, "", "PrepareCustomConfig"], [709, 1, 1, "", "StandaloneModuleConfigEntry"]], "torch.ao.quantization.fx.custom_config.ConvertCustomConfig": [[706, 3, 1, "", "from_dict"], [706, 3, 1, "", "set_observed_to_quantized_mapping"], [706, 3, 1, "", "set_preserved_attributes"], [706, 3, 1, "", "to_dict"]], "torch.ao.quantization.fx.custom_config.FuseCustomConfig": [[707, 3, 1, "", "from_dict"], [707, 3, 1, "", "set_preserved_attributes"], [707, 3, 1, "", "to_dict"]], "torch.ao.quantization.fx.custom_config.PrepareCustomConfig": [[708, 3, 1, "", "from_dict"], [708, 3, 1, "", "set_float_to_observed_mapping"], [708, 3, 1, "", "set_input_quantized_indexes"], [708, 3, 1, "", "set_non_traceable_module_classes"], [708, 3, 1, "", "set_non_traceable_module_names"], [708, 3, 1, "", "set_output_quantized_indexes"], [708, 3, 1, "", "set_preserved_attributes"], [708, 3, 1, "", "set_standalone_module_class"], [708, 3, 1, "", "set_standalone_module_name"], [708, 3, 1, "", "to_dict"]], "torch.ao.quantization.qconfig_mapping": [[710, 1, 1, "", "QConfigMapping"], [711, 1, 1, "", "get_default_qat_qconfig_mapping"], [712, 1, 1, "", "get_default_qconfig_mapping"]], "torch.ao.quantization.qconfig_mapping.QConfigMapping": [[710, 3, 1, "", "from_dict"], [710, 3, 1, "", "set_global"], [710, 3, 1, "", "set_module_name"], [710, 3, 1, "", "set_module_name_object_type_order"], [710, 3, 1, "", "set_module_name_regex"], [710, 3, 1, "", "set_object_type"], [710, 3, 1, "", "to_dict"]], "torch.autograd": [[2, 1, 1, "", "Function"], [740, 5, 1, "", "backward"], [2, 1, 1, "", "detect_anomaly"], [754, 5, 1, "", "grad"], [755, 5, 1, "", "gradcheck"], [756, 5, 1, "", "gradgradcheck"], [2, 1, 1, "", "set_detect_anomaly"], [762, 1, 1, "", "set_multithreading_enabled"]], "torch.autograd.Function": [[737, 3, 1, "", "backward"], [738, 3, 1, "", "forward"], [739, 3, 1, "", "jvp"]], "torch.autograd.forward_ad": [[741, 1, 1, "", "dual_level"], [742, 5, 1, "", "make_dual"], [743, 5, 1, "", "unpack_dual"]], "torch.autograd.function.FunctionCtx": [[744, 3, 1, "", "mark_dirty"], [745, 3, 1, "", "mark_non_differentiable"], [746, 3, 1, "", "save_for_backward"], [747, 3, 1, "", "set_materialize_grads"]], "torch.autograd.functional": [[748, 5, 1, "", "hessian"], [749, 5, 1, "", "hvp"], [750, 5, 1, "", "jacobian"], [751, 5, 1, "", "jvp"], [752, 5, 1, "", "vhp"], [753, 5, 1, "", "vjp"]], "torch.autograd.graph": [[2, 1, 1, "", "disable_saved_tensors_hooks"], [2, 1, 1, "", "save_on_cpu"], [2, 1, 1, "", "saved_tensors_hooks"]], "torch.autograd.profiler": [[2, 1, 1, "", "emit_itt"], [2, 1, 1, "", "emit_nvtx"], [757, 5, 1, "", "load_nvprof"], [2, 1, 1, "", "profile"]], "torch.autograd.profiler.profile": [[758, 3, 1, "", "export_chrome_trace"], [759, 3, 1, "", "key_averages"], [760, 4, 1, "", "self_cpu_time_total"], [761, 3, 1, "", "total_average"]], "torch.backends": [[3, 0, 0, "-", "cuda"], [3, 0, 0, "-", "cudnn"], [3, 0, 0, "-", "mkl"], [3, 0, 0, "-", "mkldnn"], [3, 0, 0, "-", "mps"], [3, 0, 0, "-", "openmp"], [3, 0, 0, "-", "opt_einsum"], [3, 0, 0, "-", "quantized"], [3, 0, 0, "-", "xeon"], [3, 0, 0, "-", "xnnpack"]], "torch.backends.cuda": [[3, 1, 1, "", "SDPBackend"], [3, 3, 1, "", "clear"], [3, 5, 1, "", "enable_flash_sdp"], [3, 5, 1, "", "enable_math_sdp"], [3, 5, 1, "", "enable_mem_efficient_sdp"], [3, 5, 1, "", "flash_sdp_enabled"], [3, 5, 1, "", "is_built"], [3, 5, 1, "", "math_sdp_enabled"], [3, 2, 1, "", "max_size"], [3, 5, 1, "", "mem_efficient_sdp_enabled"], [3, 5, 1, "", "preferred_linalg_library"], [3, 5, 1, "", "sdp_kernel"]], "torch.backends.cuda.torch.backends.cuda": [[3, 2, 1, "", "cufft_plan_cache"], [3, 2, 1, "", "size"]], "torch.backends.cuda.torch.backends.cuda.matmul": [[3, 2, 1, "", "allow_bf16_reduced_precision_reduction"], [3, 2, 1, "", "allow_fp16_reduced_precision_reduction"], [3, 2, 1, "", "allow_tf32"]], "torch.backends.cudnn": [[3, 5, 1, "", "is_available"], [3, 5, 1, "", "version"]], "torch.backends.cudnn.torch.backends.cudnn": [[3, 2, 1, "", "allow_tf32"], [3, 2, 1, "", "benchmark"], [3, 2, 1, "", "benchmark_limit"], [3, 2, 1, "", "deterministic"], [3, 2, 1, "", "enabled"]], "torch.backends.mkl": [[3, 5, 1, "", "is_available"], [3, 1, 1, "", "verbose"]], "torch.backends.mkldnn": [[3, 5, 1, "", "is_available"], [3, 1, 1, "", "verbose"]], "torch.backends.mps": [[3, 5, 1, "", "is_available"], [3, 5, 1, "", "is_built"]], "torch.backends.openmp": [[3, 5, 1, "", "is_available"]], "torch.backends.opt_einsum": [[3, 5, 1, "", "get_opt_einsum"], [3, 5, 1, "", "is_available"]], "torch.backends.opt_einsum.torch.backends.opt_einsum": [[3, 2, 1, "", "enabled"], [3, 2, 1, "", "strategy"]], "torch.cpu": [[1, 0, 0, "-", "amp"]], "torch.cpu.amp": [[1, 1, 1, "", "autocast"]], "torch.cuda": [[809, 1, 1, "", "CUDAGraph"], [810, 1, 1, "", "CUDAPluggableAllocator"], [811, 1, 1, "", "Event"], [812, 1, 1, "", "ExternalStream"], [813, 6, 1, "", "OutOfMemoryError"], [814, 1, 1, "", "Stream"], [815, 1, 1, "", "StreamContext"], [17, 0, 0, "-", "_sanitizer"], [1, 0, 0, "-", "amp"], [816, 5, 1, "", "caching_allocator_alloc"], [817, 5, 1, "", "caching_allocator_delete"], [818, 5, 1, "", "can_device_access_peer"], [819, 5, 1, "", "change_current_allocator"], [825, 5, 1, "", "current_blas_handle"], [826, 5, 1, "", "current_device"], [827, 5, 1, "", "current_stream"], [828, 5, 1, "", "default_stream"], [829, 1, 1, "", "device"], [830, 5, 1, "", "device_count"], [831, 1, 1, "", "device_of"], [832, 5, 1, "", "empty_cache"], [833, 5, 1, "", "get_allocator_backend"], [834, 5, 1, "", "get_arch_list"], [835, 5, 1, "", "get_device_capability"], [836, 5, 1, "", "get_device_name"], [837, 5, 1, "", "get_device_properties"], [838, 5, 1, "", "get_gencode_flags"], [839, 5, 1, "", "get_rng_state"], [840, 5, 1, "", "get_rng_state_all"], [841, 5, 1, "", "get_sync_debug_mode"], [842, 1, 1, "", "graph"], [843, 5, 1, "", "graph_pool_handle"], [844, 5, 1, "", "init"], [845, 5, 1, "", "initial_seed"], [846, 5, 1, "", "ipc_collect"], [847, 5, 1, "", "is_available"], [848, 5, 1, "", "is_current_stream_capturing"], [849, 5, 1, "", "is_initialized"], [852, 5, 1, "", "list_gpu_processes"], [853, 5, 1, "", "make_graphed_callables"], [854, 5, 1, "", "manual_seed"], [855, 5, 1, "", "manual_seed_all"], [856, 5, 1, "", "max_memory_allocated"], [857, 5, 1, "", "max_memory_cached"], [858, 5, 1, "", "max_memory_reserved"], [859, 5, 1, "", "mem_get_info"], [860, 5, 1, "", "memory_allocated"], [861, 5, 1, "", "memory_cached"], [862, 5, 1, "", "memory_reserved"], [863, 5, 1, "", "memory_snapshot"], [864, 5, 1, "", "memory_stats"], [865, 5, 1, "", "memory_summary"], [866, 5, 1, "", "memory_usage"], [870, 5, 1, "", "reset_max_memory_allocated"], [871, 5, 1, "", "reset_max_memory_cached"], [872, 5, 1, "", "reset_peak_memory_stats"], [873, 5, 1, "", "seed"], [874, 5, 1, "", "seed_all"], [875, 5, 1, "", "set_device"], [876, 5, 1, "", "set_per_process_memory_fraction"], [877, 5, 1, "", "set_rng_state"], [878, 5, 1, "", "set_rng_state_all"], [879, 5, 1, "", "set_stream"], [880, 5, 1, "", "set_sync_debug_mode"], [881, 5, 1, "", "stream"], [882, 5, 1, "", "synchronize"], [883, 5, 1, "", "utilization"]], "torch.cuda.CUDAGraph": [[809, 3, 1, "", "capture_begin"], [809, 3, 1, "", "capture_end"], [809, 3, 1, "", "debug_dump"], [809, 3, 1, "", "enable_debug_mode"], [809, 3, 1, "", "pool"], [809, 3, 1, "", "replay"], [809, 3, 1, "", "reset"]], "torch.cuda.Event": [[811, 3, 1, "", "elapsed_time"], [811, 3, 1, "", "from_ipc_handle"], [811, 3, 1, "", "ipc_handle"], [811, 3, 1, "", "query"], [811, 3, 1, "", "record"], [811, 3, 1, "", "synchronize"], [811, 3, 1, "", "wait"]], "torch.cuda.ExternalStream": [[812, 3, 1, "", "query"], [812, 3, 1, "", "record_event"], [812, 3, 1, "", "synchronize"], [812, 3, 1, "", "wait_event"], [812, 3, 1, "", "wait_stream"]], "torch.cuda.Stream": [[814, 3, 1, "", "query"], [814, 3, 1, "", "record_event"], [814, 3, 1, "", "synchronize"], [814, 3, 1, "", "wait_event"], [814, 3, 1, "", "wait_stream"]], "torch.cuda._sanitizer": [[17, 5, 1, "", "enable_cuda_sanitizer"]], "torch.cuda.amp": [[1, 1, 1, "", "GradScaler"], [1, 1, 1, "", "autocast"], [1, 5, 1, "", "custom_bwd"], [1, 5, 1, "", "custom_fwd"]], "torch.cuda.amp.GradScaler": [[1, 3, 1, "", "get_backoff_factor"], [1, 3, 1, "", "get_growth_factor"], [1, 3, 1, "", "get_growth_interval"], [1, 3, 1, "", "get_scale"], [1, 3, 1, "", "is_enabled"], [1, 3, 1, "", "load_state_dict"], [1, 3, 1, "", "scale"], [1, 3, 1, "", "set_backoff_factor"], [1, 3, 1, "", "set_growth_factor"], [1, 3, 1, "", "set_growth_interval"], [1, 3, 1, "", "state_dict"], [1, 3, 1, "", "step"], [1, 3, 1, "", "unscale_"], [1, 3, 1, "", "update"]], "torch.cuda.comm": [[820, 5, 1, "", "broadcast"], [821, 5, 1, "", "broadcast_coalesced"], [822, 5, 1, "", "gather"], [823, 5, 1, "", "reduce_add"], [824, 5, 1, "", "scatter"]], "torch.cuda.jiterator": [[850, 5, 1, "", "_create_jit_fn"], [851, 5, 1, "", "_create_multi_output_jit_fn"]], "torch.cuda.nvtx": [[867, 5, 1, "", "mark"], [868, 5, 1, "", "range_pop"], [869, 5, 1, "", "range_push"]], "torch.distributed": [[23, 1, 1, "", "Backend"], [23, 1, 1, "", "DistBackendError"], [23, 1, 1, "", "FileStore"], [21, 1, 1, "", "GradBucket"], [23, 1, 1, "", "HashStore"], [23, 1, 1, "", "P2POp"], [23, 1, 1, "", "PrefixStore"], [23, 1, 1, "", "ReduceOp"], [23, 1, 1, "", "Store"], [23, 1, 1, "", "TCPStore"], [23, 0, 0, "-", "algorithms"], [23, 5, 1, "", "all_gather"], [23, 5, 1, "", "all_gather_into_tensor"], [23, 5, 1, "", "all_gather_multigpu"], [23, 5, 1, "", "all_gather_object"], [23, 5, 1, "", "all_reduce"], [23, 5, 1, "", "all_reduce_multigpu"], [23, 5, 1, "", "all_to_all"], [23, 5, 1, "", "all_to_all_single"], [1789, 0, 0, "-", "autograd"], [23, 5, 1, "", "barrier"], [23, 5, 1, "", "batch_isend_irecv"], [23, 5, 1, "", "broadcast"], [23, 5, 1, "", "broadcast_multigpu"], [23, 5, 1, "", "broadcast_object_list"], [25, 0, 0, "-", "checkpoint"], [23, 0, 0, "-", "elastic"], [53, 0, 0, "-", "fsdp"], [23, 5, 1, "", "gather"], [23, 5, 1, "", "gather_object"], [23, 5, 1, "", "get_backend"], [23, 5, 1, "", "get_global_rank"], [23, 5, 1, "", "get_group_rank"], [23, 5, 1, "", "get_process_group_ranks"], [23, 5, 1, "", "get_rank"], [23, 5, 1, "", "get_world_size"], [23, 5, 1, "", "init_process_group"], [23, 5, 1, "", "irecv"], [23, 5, 1, "", "is_available"], [23, 5, 1, "", "is_gloo_available"], [23, 5, 1, "", "is_initialized"], [23, 5, 1, "", "is_mpi_available"], [23, 5, 1, "", "is_nccl_available"], [23, 5, 1, "", "is_torchelastic_launched"], [23, 5, 1, "", "isend"], [23, 0, 0, "-", "launch"], [23, 0, 0, "-", "launcher"], [23, 5, 1, "", "monitored_barrier"], [23, 5, 1, "", "new_group"], [23, 0, 0, "-", "nn"], [27, 0, 0, "-", "optim"], [23, 0, 0, "-", "pipeline"], [23, 5, 1, "", "recv"], [23, 5, 1, "", "reduce"], [23, 5, 1, "", "reduce_multigpu"], [23, 1, 1, "", "reduce_op"], [23, 5, 1, "", "reduce_scatter"], [23, 5, 1, "", "reduce_scatter_multigpu"], [23, 5, 1, "", "reduce_scatter_tensor"], [1789, 0, 0, "-", "rpc"], [49, 0, 0, "-", "run"], [23, 5, 1, "", "scatter"], [23, 5, 1, "", "scatter_object_list"], [23, 5, 1, "", "send"], [23, 0, 0, "-", "tensor"]], "torch.distributed.Backend": [[23, 3, 1, "", "register_backend"]], "torch.distributed.GradBucket": [[21, 5, 1, "", "buffer"], [21, 5, 1, "", "gradients"], [21, 5, 1, "", "index"], [21, 5, 1, "", "is_last"], [21, 5, 1, "", "parameters"], [21, 5, 1, "", "set_buffer"]], "torch.distributed.Store": [[23, 5, 1, "", "add"], [23, 5, 1, "", "compare_set"], [23, 5, 1, "", "delete_key"], [23, 5, 1, "", "get"], [23, 5, 1, "", "num_keys"], [23, 5, 1, "", "set"], [23, 5, 1, "", "set_timeout"], [23, 5, 1, "", "wait"]], "torch.distributed.algorithms": [[24, 1, 1, "", "Join"], [24, 1, 1, "", "JoinHook"], [24, 1, 1, "", "Joinable"], [23, 0, 0, "-", "ddp_comm_hooks"], [23, 0, 0, "-", "model_averaging"]], "torch.distributed.algorithms.Join": [[24, 3, 1, "", "notify_join_context"]], "torch.distributed.algorithms.JoinHook": [[24, 3, 1, "", "main_hook"], [24, 3, 1, "", "post_hook"]], "torch.distributed.algorithms.Joinable": [[24, 4, 1, "", "join_device"], [24, 3, 1, "", "join_hook"], [24, 4, 1, "", "join_process_group"]], "torch.distributed.algorithms.ddp_comm_hooks.debugging_hooks": [[21, 5, 1, "", "noop_hook"]], "torch.distributed.algorithms.ddp_comm_hooks.default_hooks": [[21, 5, 1, "", "allreduce_hook"], [21, 5, 1, "", "bf16_compress_hook"], [21, 5, 1, "", "bf16_compress_wrapper"], [21, 5, 1, "", "fp16_compress_hook"], [21, 5, 1, "", "fp16_compress_wrapper"]], "torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook": [[21, 1, 1, "", "PowerSGDState"], [21, 5, 1, "", "batched_powerSGD_hook"], [21, 5, 1, "", "powerSGD_hook"]], "torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState": [[21, 3, 1, "", "__getstate__"], [21, 3, 1, "", "__setstate__"]], "torch.distributed.autograd": [[1789, 5, 1, "", "backward"], [1789, 1, 1, "", "context"], [1789, 5, 1, "", "get_gradients"]], "torch.distributed.elastic": [[39, 0, 0, "-", "agent"], [42, 0, 0, "-", "events"], [45, 0, 0, "-", "metrics"], [46, 0, 0, "-", "multiprocessing"], [48, 0, 0, "-", "rendezvous"], [50, 0, 0, "-", "timer"], [23, 0, 0, "-", "utils"]], "torch.distributed.elastic.agent": [[39, 0, 0, "-", "server"]], "torch.distributed.elastic.agent.server": [[39, 1, 1, "", "ElasticAgent"], [39, 1, 1, "", "SimpleElasticAgent"], [39, 1, 1, "", "Worker"], [39, 1, 1, "", "WorkerGroup"], [39, 1, 1, "", "WorkerSpec"], [39, 1, 1, "", "WorkerState"]], "torch.distributed.elastic.agent.server.ElasticAgent": [[39, 3, 1, "", "get_worker_group"], [39, 3, 1, "", "run"]], "torch.distributed.elastic.agent.server.SimpleElasticAgent": [[39, 3, 1, "", "_assign_worker_ranks"], [39, 3, 1, "", "_exit_barrier"], [39, 3, 1, "", "_initialize_workers"], [39, 3, 1, "", "_monitor_workers"], [39, 3, 1, "", "_rendezvous"], [39, 3, 1, "", "_restart_workers"], [39, 3, 1, "", "_shutdown"], [39, 3, 1, "", "_start_workers"], [39, 3, 1, "", "_stop_workers"]], "torch.distributed.elastic.agent.server.WorkerSpec": [[39, 3, 1, "", "get_entrypoint_name"]], "torch.distributed.elastic.agent.server.WorkerState": [[39, 3, 1, "", "is_running"]], "torch.distributed.elastic.agent.server.api": [[39, 1, 1, "", "RunResult"]], "torch.distributed.elastic.agent.server.local_elastic_agent": [[39, 1, 1, "", "LocalElasticAgent"]], "torch.distributed.elastic.events.api": [[42, 1, 1, "", "Event"], [42, 2, 1, "", "EventMetadataValue"], [42, 1, 1, "", "EventSource"]], "torch.distributed.elastic.events": [[42, 5, 1, "", "get_logging_handler"], [42, 5, 1, "", "record"]], "torch.distributed.elastic.metrics.api": [[45, 1, 1, "", "ConsoleMetricHandler"], [45, 1, 1, "", "MetricHandler"], [45, 1, 1, "", "NullMetricHandler"]], "torch.distributed.elastic.metrics": [[45, 5, 1, "", "configure"], [45, 5, 1, "", "prof"], [45, 5, 1, "", "put_metric"]], "torch.distributed.elastic.multiprocessing.api": [[46, 1, 1, "", "MultiprocessContext"], [46, 1, 1, "", "PContext"], [46, 1, 1, "", "RunProcsResult"], [46, 1, 1, "", "SubprocessContext"]], "torch.distributed.elastic.multiprocessing": [[41, 0, 0, "-", "errors"], [46, 5, 1, "", "start_processes"]], "torch.distributed.elastic.multiprocessing.errors": [[41, 1, 1, "", "ChildFailedError"], [41, 1, 1, "", "ErrorHandler"], [41, 1, 1, "", "ProcessFailure"], [41, 5, 1, "", "record"]], "torch.distributed.elastic.rendezvous": [[48, 1, 1, "", "RendezvousClosedError"], [48, 1, 1, "", "RendezvousConnectionError"], [48, 1, 1, "", "RendezvousError"], [48, 1, 1, "", "RendezvousHandler"], [48, 1, 1, "", "RendezvousHandlerRegistry"], [48, 1, 1, "", "RendezvousParameters"], [48, 1, 1, "", "RendezvousStateError"], [48, 1, 1, "", "RendezvousTimeoutError"], [48, 0, 0, "-", "registry"]], "torch.distributed.elastic.rendezvous.RendezvousHandler": [[48, 3, 1, "", "get_backend"], [48, 3, 1, "", "get_run_id"], [48, 3, 1, "", "is_closed"], [48, 3, 1, "", "next_rendezvous"], [48, 3, 1, "", "num_nodes_waiting"], [48, 3, 1, "", "set_closed"], [48, 3, 1, "", "shutdown"]], "torch.distributed.elastic.rendezvous.RendezvousHandlerRegistry": [[48, 3, 1, "", "create_handler"], [48, 3, 1, "", "register"]], "torch.distributed.elastic.rendezvous.RendezvousParameters": [[48, 3, 1, "", "get"], [48, 3, 1, "", "get_as_bool"], [48, 3, 1, "", "get_as_int"]], "torch.distributed.elastic.rendezvous.c10d_rendezvous_backend": [[48, 1, 1, "", "C10dRendezvousBackend"], [48, 5, 1, "", "create_backend"]], "torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend": [[48, 3, 1, "", "get_state"], [48, 4, 1, "", "name"], [48, 3, 1, "", "set_state"]], "torch.distributed.elastic.rendezvous.dynamic_rendezvous": [[48, 1, 1, "", "DynamicRendezvousHandler"], [48, 1, 1, "", "RendezvousBackend"], [48, 1, 1, "", "RendezvousTimeout"], [48, 5, 1, "", "create_handler"]], "torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler": [[48, 3, 1, "", "from_backend"]], "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend": [[48, 3, 1, "", "get_state"], [48, 4, 1, "", "name"], [48, 3, 1, "", "set_state"]], "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout": [[48, 4, 1, "", "close"], [48, 4, 1, "", "heartbeat"], [48, 4, 1, "", "join"], [48, 4, 1, "", "last_call"]], "torch.distributed.elastic.rendezvous.etcd_rendezvous": [[48, 1, 1, "", "EtcdRendezvousHandler"]], "torch.distributed.elastic.rendezvous.etcd_rendezvous_backend": [[48, 1, 1, "", "EtcdRendezvousBackend"], [48, 5, 1, "", "create_backend"]], "torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend": [[48, 3, 1, "", "get_state"], [48, 4, 1, "", "name"], [48, 3, 1, "", "set_state"]], "torch.distributed.elastic.rendezvous.etcd_server": [[48, 1, 1, "", "EtcdServer"]], "torch.distributed.elastic.rendezvous.etcd_store": [[48, 1, 1, "", "EtcdStore"]], "torch.distributed.elastic.rendezvous.etcd_store.EtcdStore": [[48, 3, 1, "", "add"], [48, 3, 1, "", "check"], [48, 3, 1, "", "get"], [48, 3, 1, "", "set"], [48, 3, 1, "", "wait"]], "torch.distributed.elastic.timer": [[50, 1, 1, "", "FileTimerClient"], [50, 1, 1, "", "FileTimerServer"], [50, 1, 1, "", "LocalTimerClient"], [50, 1, 1, "", "LocalTimerServer"], [50, 1, 1, "", "TimerClient"], [50, 1, 1, "", "TimerRequest"], [50, 1, 1, "", "TimerServer"], [50, 5, 1, "", "configure"], [50, 5, 1, "", "expires"]], "torch.distributed.elastic.timer.TimerClient": [[50, 3, 1, "", "acquire"], [50, 3, 1, "", "release"]], "torch.distributed.elastic.timer.TimerServer": [[50, 3, 1, "", "clear_timers"], [50, 3, 1, "", "get_expired_timers"], [50, 3, 1, "", "register_timers"]], "torch.distributed.elastic.utils": [[23, 0, 0, "-", "data"]], "torch.distributed.fsdp": [[53, 1, 1, "", "BackwardPrefetch"], [53, 1, 1, "", "CPUOffload"], [53, 1, 1, "", "FullyShardedDataParallel"], [53, 1, 1, "", "MixedPrecision"], [53, 1, 1, "", "ShardingStrategy"]], "torch.distributed.fsdp.FullyShardedDataParallel": [[53, 3, 1, "", "apply"], [53, 3, 1, "", "clip_grad_norm_"], [53, 3, 1, "", "flatten_sharded_optim_state_dict"], [53, 3, 1, "", "forward"], [53, 3, 1, "", "fsdp_modules"], [53, 3, 1, "", "full_optim_state_dict"], [53, 4, 1, "", "module"], [53, 3, 1, "", "named_buffers"], [53, 3, 1, "", "named_parameters"], [53, 3, 1, "", "no_sync"], [53, 3, 1, "", "register_comm_hook"], [53, 3, 1, "", "rekey_optim_state_dict"], [53, 3, 1, "", "scatter_full_optim_state_dict"], [53, 3, 1, "", "set_state_dict_type"], [53, 3, 1, "", "shard_full_optim_state_dict"], [53, 3, 1, "", "sharded_optim_state_dict"], [53, 3, 1, "", "state_dict_type"], [53, 3, 1, "", "summon_full_params"]], "torch.distributed.nn": [[23, 0, 0, "-", "api"], [23, 0, 0, "-", "jit"]], "torch.distributed.nn.api.remote_module": [[1789, 1, 1, "", "RemoteModule"]], "torch.distributed.nn.api.remote_module.RemoteModule": [[1789, 3, 1, "", "get_module_rref"], [1789, 3, 1, "", "remote_parameters"]], "torch.distributed.nn.jit": [[23, 0, 0, "-", "templates"]], "torch.distributed.optim": [[27, 1, 1, "", "DistributedOptimizer"], [27, 1, 1, "", "PostLocalSGDOptimizer"], [27, 1, 1, "", "ZeroRedundancyOptimizer"]], "torch.distributed.optim.DistributedOptimizer": [[27, 3, 1, "", "step"]], "torch.distributed.optim.PostLocalSGDOptimizer": [[27, 3, 1, "", "load_state_dict"], [27, 3, 1, "", "state_dict"], [27, 3, 1, "", "step"]], "torch.distributed.optim.ZeroRedundancyOptimizer": [[27, 3, 1, "", "add_param_group"], [27, 3, 1, "", "consolidate_state_dict"], [27, 3, 1, "", "join_hook"], [27, 3, 1, "", "load_state_dict"], [27, 3, 1, "", "state_dict"], [27, 3, 1, "", "step"]], "torch.distributed.pipeline": [[23, 0, 0, "-", "sync"]], "torch.distributed.pipeline.sync": [[1782, 1, 1, "", "Pipe"], [23, 0, 0, "-", "skip"]], "torch.distributed.pipeline.sync.Pipe": [[1782, 3, 1, "", "forward"]], "torch.distributed.pipeline.sync.skip.skippable": [[1782, 1, 1, "", "pop"], [1782, 5, 1, "", "skippable"], [1782, 1, 1, "", "stash"], [1782, 5, 1, "", "verify_skippables"]], "torch.distributed.rpc": [[1789, 1, 1, "", "BackendType"], [1789, 1, 1, "", "RRef"], [1789, 1, 1, "", "RpcBackendOptions"], [1789, 1, 1, "", "TensorPipeRpcBackendOptions"], [1789, 1, 1, "", "WorkerInfo"], [1789, 5, 1, "", "get_worker_info"], [1789, 5, 1, "", "init_rpc"], [1789, 5, 1, "", "remote"], [1789, 5, 1, "", "rpc_async"], [1789, 5, 1, "", "rpc_sync"], [1789, 5, 1, "", "shutdown"]], "torch.distributed.rpc.RpcBackendOptions": [[1789, 4, 1, "", "init_method"], [1789, 4, 1, "", "rpc_timeout"]], "torch.distributed.rpc.TensorPipeRpcBackendOptions": [[1789, 4, 1, "", "device_maps"], [1789, 4, 1, "", "devices"], [1789, 4, 1, "", "init_method"], [1789, 4, 1, "", "num_worker_threads"], [1789, 4, 1, "", "rpc_timeout"], [1789, 3, 1, "", "set_device_map"], [1789, 3, 1, "", "set_devices"]], "torch.distributed.rpc.WorkerInfo": [[1789, 4, 1, "", "id"], [1789, 4, 1, "", "name"]], "torch.distributed.rpc.functions": [[1789, 5, 1, "", "async_execution"]], "torch.distributed.tensor": [[28, 0, 0, "-", "parallel"]], "torch.distributions.bernoulli": [[29, 1, 1, "", "Bernoulli"]], "torch.distributions.bernoulli.Bernoulli": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "enumerate_support"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_enumerate_support"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "logits"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 4, 1, "", "param_shape"], [29, 4, 1, "", "probs"], [29, 3, 1, "", "sample"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.beta": [[29, 1, 1, "", "Beta"]], "torch.distributions.beta.Beta": [[29, 2, 1, "", "arg_constraints"], [29, 4, 1, "", "concentration0"], [29, 4, 1, "", "concentration1"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 3, 1, "", "rsample"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.binomial": [[29, 1, 1, "", "Binomial"]], "torch.distributions.binomial.Binomial": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "enumerate_support"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_enumerate_support"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "logits"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 4, 1, "", "param_shape"], [29, 4, 1, "", "probs"], [29, 3, 1, "", "sample"], [29, 4, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.categorical": [[29, 1, 1, "", "Categorical"]], "torch.distributions.categorical.Categorical": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "enumerate_support"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_enumerate_support"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "logits"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 4, 1, "", "param_shape"], [29, 4, 1, "", "probs"], [29, 3, 1, "", "sample"], [29, 4, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.cauchy": [[29, 1, 1, "", "Cauchy"]], "torch.distributions.cauchy.Cauchy": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "cdf"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 3, 1, "", "icdf"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 3, 1, "", "rsample"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.chi2": [[29, 1, 1, "", "Chi2"]], "torch.distributions.chi2.Chi2": [[29, 2, 1, "", "arg_constraints"], [29, 4, 1, "", "df"], [29, 3, 1, "", "expand"]], "torch.distributions": [[29, 0, 0, "-", "constraint_registry"], [29, 0, 0, "-", "constraints"], [29, 0, 0, "-", "kl"], [29, 0, 0, "-", "transforms"]], "torch.distributions.constraint_registry": [[29, 1, 1, "", "ConstraintRegistry"]], "torch.distributions.constraint_registry.ConstraintRegistry": [[29, 3, 1, "", "register"]], "torch.distributions.constraints": [[29, 1, 1, "", "Constraint"], [29, 2, 1, "", "cat"], [29, 2, 1, "", "dependent_property"], [29, 2, 1, "", "greater_than"], [29, 2, 1, "", "greater_than_eq"], [29, 2, 1, "", "half_open_interval"], [29, 2, 1, "", "independent"], [29, 2, 1, "", "integer_interval"], [29, 2, 1, "", "interval"], [29, 2, 1, "", "less_than"], [29, 2, 1, "", "multinomial"], [29, 2, 1, "", "stack"]], "torch.distributions.constraints.Constraint": [[29, 3, 1, "", "check"]], "torch.distributions.continuous_bernoulli": [[29, 1, 1, "", "ContinuousBernoulli"]], "torch.distributions.continuous_bernoulli.ContinuousBernoulli": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "cdf"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 3, 1, "", "icdf"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "logits"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "param_shape"], [29, 4, 1, "", "probs"], [29, 3, 1, "", "rsample"], [29, 3, 1, "", "sample"], [29, 4, 1, "", "stddev"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.dirichlet": [[29, 1, 1, "", "Dirichlet"]], "torch.distributions.dirichlet.Dirichlet": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 3, 1, "", "rsample"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.distribution": [[29, 1, 1, "", "Distribution"]], "torch.distributions.distribution.Distribution": [[29, 4, 1, "", "arg_constraints"], [29, 4, 1, "", "batch_shape"], [29, 3, 1, "", "cdf"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "enumerate_support"], [29, 4, 1, "", "event_shape"], [29, 3, 1, "", "expand"], [29, 3, 1, "", "icdf"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 3, 1, "", "perplexity"], [29, 3, 1, "", "rsample"], [29, 3, 1, "", "sample"], [29, 3, 1, "", "sample_n"], [29, 3, 1, "", "set_default_validate_args"], [29, 4, 1, "", "stddev"], [29, 4, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.exp_family": [[29, 1, 1, "", "ExponentialFamily"]], "torch.distributions.exp_family.ExponentialFamily": [[29, 3, 1, "", "entropy"]], "torch.distributions.exponential": [[29, 1, 1, "", "Exponential"]], "torch.distributions.exponential.Exponential": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "cdf"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 3, 1, "", "icdf"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 3, 1, "", "rsample"], [29, 4, 1, "", "stddev"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.fishersnedecor": [[29, 1, 1, "", "FisherSnedecor"]], "torch.distributions.fishersnedecor.FisherSnedecor": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 3, 1, "", "rsample"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.gamma": [[29, 1, 1, "", "Gamma"]], "torch.distributions.gamma.Gamma": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "cdf"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 3, 1, "", "rsample"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.geometric": [[29, 1, 1, "", "Geometric"]], "torch.distributions.geometric.Geometric": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "logits"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 4, 1, "", "probs"], [29, 3, 1, "", "sample"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.gumbel": [[29, 1, 1, "", "Gumbel"]], "torch.distributions.gumbel.Gumbel": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 4, 1, "", "stddev"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.half_cauchy": [[29, 1, 1, "", "HalfCauchy"]], "torch.distributions.half_cauchy.HalfCauchy": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "cdf"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 3, 1, "", "icdf"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 4, 1, "", "scale"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.half_normal": [[29, 1, 1, "", "HalfNormal"]], "torch.distributions.half_normal.HalfNormal": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "cdf"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 3, 1, "", "icdf"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 4, 1, "", "scale"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.independent": [[29, 1, 1, "", "Independent"]], "torch.distributions.independent.Independent": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "enumerate_support"], [29, 3, 1, "", "expand"], [29, 4, 1, "", "has_enumerate_support"], [29, 4, 1, "", "has_rsample"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 3, 1, "", "rsample"], [29, 3, 1, "", "sample"], [29, 4, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.kl": [[29, 5, 1, "", "kl_divergence"], [29, 5, 1, "", "register_kl"]], "torch.distributions.kumaraswamy": [[29, 1, 1, "", "Kumaraswamy"]], "torch.distributions.kumaraswamy.Kumaraswamy": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.laplace": [[29, 1, 1, "", "Laplace"]], "torch.distributions.laplace.Laplace": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "cdf"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 3, 1, "", "icdf"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 3, 1, "", "rsample"], [29, 4, 1, "", "stddev"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.lkj_cholesky": [[29, 1, 1, "", "LKJCholesky"]], "torch.distributions.lkj_cholesky.LKJCholesky": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "expand"], [29, 3, 1, "", "log_prob"], [29, 3, 1, "", "sample"], [29, 2, 1, "", "support"]], "torch.distributions.log_normal": [[29, 1, 1, "", "LogNormal"]], "torch.distributions.log_normal.LogNormal": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 4, 1, "", "loc"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 4, 1, "", "scale"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.lowrank_multivariate_normal": [[29, 1, 1, "", "LowRankMultivariateNormal"]], "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal": [[29, 2, 1, "", "arg_constraints"], [29, 4, 1, "", "covariance_matrix"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 4, 1, "", "precision_matrix"], [29, 3, 1, "", "rsample"], [29, 4, 1, "", "scale_tril"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.mixture_same_family": [[29, 1, 1, "", "MixtureSameFamily"]], "torch.distributions.mixture_same_family.MixtureSameFamily": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "cdf"], [29, 4, 1, "", "component_distribution"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mixture_distribution"], [29, 3, 1, "", "sample"], [29, 4, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.multinomial": [[29, 1, 1, "", "Multinomial"]], "torch.distributions.multinomial.Multinomial": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "logits"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "param_shape"], [29, 4, 1, "", "probs"], [29, 3, 1, "", "sample"], [29, 4, 1, "", "support"], [29, 2, 1, "", "total_count"], [29, 4, 1, "", "variance"]], "torch.distributions.multivariate_normal": [[29, 1, 1, "", "MultivariateNormal"]], "torch.distributions.multivariate_normal.MultivariateNormal": [[29, 2, 1, "", "arg_constraints"], [29, 4, 1, "", "covariance_matrix"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 4, 1, "", "precision_matrix"], [29, 3, 1, "", "rsample"], [29, 4, 1, "", "scale_tril"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.negative_binomial": [[29, 1, 1, "", "NegativeBinomial"]], "torch.distributions.negative_binomial.NegativeBinomial": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "expand"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "logits"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 4, 1, "", "param_shape"], [29, 4, 1, "", "probs"], [29, 3, 1, "", "sample"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.normal": [[29, 1, 1, "", "Normal"]], "torch.distributions.normal.Normal": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "cdf"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 3, 1, "", "icdf"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 3, 1, "", "rsample"], [29, 3, 1, "", "sample"], [29, 4, 1, "", "stddev"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.one_hot_categorical": [[29, 1, 1, "", "OneHotCategorical"]], "torch.distributions.one_hot_categorical.OneHotCategorical": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "enumerate_support"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_enumerate_support"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "logits"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 4, 1, "", "param_shape"], [29, 4, 1, "", "probs"], [29, 3, 1, "", "sample"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.pareto": [[29, 1, 1, "", "Pareto"]], "torch.distributions.pareto.Pareto": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 4, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.poisson": [[29, 1, 1, "", "Poisson"]], "torch.distributions.poisson.Poisson": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "expand"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 3, 1, "", "sample"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.relaxed_bernoulli": [[29, 1, 1, "", "LogitRelaxedBernoulli"], [29, 1, 1, "", "RelaxedBernoulli"]], "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "expand"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "logits"], [29, 4, 1, "", "param_shape"], [29, 4, 1, "", "probs"], [29, 3, 1, "", "rsample"], [29, 2, 1, "", "support"]], "torch.distributions.relaxed_bernoulli.RelaxedBernoulli": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 4, 1, "", "logits"], [29, 4, 1, "", "probs"], [29, 2, 1, "", "support"], [29, 4, 1, "", "temperature"]], "torch.distributions.relaxed_categorical": [[29, 1, 1, "", "RelaxedOneHotCategorical"]], "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 4, 1, "", "logits"], [29, 4, 1, "", "probs"], [29, 2, 1, "", "support"], [29, 4, 1, "", "temperature"]], "torch.distributions.studentT": [[29, 1, 1, "", "StudentT"]], "torch.distributions.studentT.StudentT": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 3, 1, "", "rsample"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.transformed_distribution": [[29, 1, 1, "", "TransformedDistribution"]], "torch.distributions.transformed_distribution.TransformedDistribution": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "cdf"], [29, 3, 1, "", "expand"], [29, 4, 1, "", "has_rsample"], [29, 3, 1, "", "icdf"], [29, 3, 1, "", "log_prob"], [29, 3, 1, "", "rsample"], [29, 3, 1, "", "sample"], [29, 4, 1, "", "support"]], "torch.distributions.transforms": [[29, 1, 1, "", "AbsTransform"], [29, 1, 1, "", "AffineTransform"], [29, 1, 1, "", "CatTransform"], [29, 1, 1, "", "ComposeTransform"], [29, 1, 1, "", "CorrCholeskyTransform"], [29, 1, 1, "", "CumulativeDistributionTransform"], [29, 1, 1, "", "ExpTransform"], [29, 1, 1, "", "IndependentTransform"], [29, 1, 1, "", "LowerCholeskyTransform"], [29, 1, 1, "", "PositiveDefiniteTransform"], [29, 1, 1, "", "PowerTransform"], [29, 1, 1, "", "ReshapeTransform"], [29, 1, 1, "", "SigmoidTransform"], [29, 1, 1, "", "SoftmaxTransform"], [29, 1, 1, "", "SoftplusTransform"], [29, 1, 1, "", "StackTransform"], [29, 1, 1, "", "StickBreakingTransform"], [29, 1, 1, "", "TanhTransform"], [29, 1, 1, "", "Transform"]], "torch.distributions.transforms.Transform": [[29, 3, 1, "", "forward_shape"], [29, 4, 1, "", "inv"], [29, 3, 1, "", "inverse_shape"], [29, 3, 1, "", "log_abs_det_jacobian"], [29, 4, 1, "", "sign"]], "torch.distributions.uniform": [[29, 1, 1, "", "Uniform"]], "torch.distributions.uniform.Uniform": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "cdf"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 3, 1, "", "icdf"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 3, 1, "", "rsample"], [29, 4, 1, "", "stddev"], [29, 4, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.von_mises": [[29, 1, 1, "", "VonMises"]], "torch.distributions.von_mises.VonMises": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 3, 1, "", "sample"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.weibull": [[29, 1, 1, "", "Weibull"]], "torch.distributions.weibull.Weibull": [[29, 2, 1, "", "arg_constraints"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.distributions.wishart": [[29, 1, 1, "", "Wishart"]], "torch.distributions.wishart.Wishart": [[29, 2, 1, "", "arg_constraints"], [29, 4, 1, "", "covariance_matrix"], [29, 3, 1, "", "entropy"], [29, 3, 1, "", "expand"], [29, 2, 1, "", "has_rsample"], [29, 3, 1, "", "log_prob"], [29, 4, 1, "", "mean"], [29, 4, 1, "", "mode"], [29, 4, 1, "", "precision_matrix"], [29, 3, 1, "", "rsample"], [29, 4, 1, "", "scale_tril"], [29, 2, 1, "", "support"], [29, 4, 1, "", "variance"]], "torch.fft": [[921, 5, 1, "", "fft"], [922, 5, 1, "", "fft2"], [923, 5, 1, "", "fftfreq"], [924, 5, 1, "", "fftn"], [925, 5, 1, "", "fftshift"], [926, 5, 1, "", "hfft"], [927, 5, 1, "", "hfft2"], [928, 5, 1, "", "hfftn"], [929, 5, 1, "", "ifft"], [930, 5, 1, "", "ifft2"], [931, 5, 1, "", "ifftn"], [932, 5, 1, "", "ifftshift"], [933, 5, 1, "", "ihfft"], [934, 5, 1, "", "ihfft2"], [935, 5, 1, "", "ihfftn"], [936, 5, 1, "", "irfft"], [937, 5, 1, "", "irfft2"], [938, 5, 1, "", "irfftn"], [939, 5, 1, "", "rfft"], [940, 5, 1, "", "rfft2"], [941, 5, 1, "", "rfftfreq"], [942, 5, 1, "", "rfftn"]], "torch.func": [[961, 5, 1, "", "functional_call"], [962, 5, 1, "", "functionalize"], [963, 5, 1, "", "grad"], [964, 5, 1, "", "grad_and_value"], [965, 5, 1, "", "hessian"], [966, 5, 1, "", "jacfwd"], [967, 5, 1, "", "jacrev"], [968, 5, 1, "", "jvp"], [969, 5, 1, "", "stack_module_state"], [970, 5, 1, "", "vjp"], [971, 5, 1, "", "vmap"]], "torch.futures": [[59, 1, 1, "", "Future"], [59, 5, 1, "", "collect_all"], [59, 5, 1, "", "wait_all"]], "torch.futures.Future": [[59, 3, 1, "", "add_done_callback"], [59, 3, 1, "", "done"], [59, 3, 1, "", "set_exception"], [59, 3, 1, "", "set_result"], [59, 3, 1, "", "then"], [59, 3, 1, "", "value"], [59, 3, 1, "", "wait"]], "torch.fx": [[60, 1, 1, "", "Graph"], [60, 1, 1, "", "GraphModule"], [60, 1, 1, "", "Interpreter"], [60, 1, 1, "", "Node"], [60, 1, 1, "", "Proxy"], [60, 1, 1, "", "Tracer"], [60, 1, 1, "", "Transformer"], [60, 0, 0, "-", "experimental"], [60, 0, 0, "-", "passes"], [60, 5, 1, "", "replace_pattern"], [60, 5, 1, "", "symbolic_trace"], [60, 5, 1, "", "wrap"]], "torch.fx.Graph": [[60, 3, 1, "", "__init__"], [60, 3, 1, "", "call_function"], [60, 3, 1, "", "call_method"], [60, 3, 1, "", "call_module"], [60, 3, 1, "", "create_node"], [60, 3, 1, "", "eliminate_dead_code"], [60, 3, 1, "", "erase_node"], [60, 3, 1, "", "get_attr"], [60, 3, 1, "", "graph_copy"], [60, 3, 1, "", "inserting_after"], [60, 3, 1, "", "inserting_before"], [60, 3, 1, "", "lint"], [60, 3, 1, "", "node_copy"], [60, 4, 1, "", "nodes"], [60, 3, 1, "", "on_generate_code"], [60, 3, 1, "", "output"], [60, 3, 1, "", "placeholder"], [60, 3, 1, "", "print_tabular"], [60, 3, 1, "", "process_inputs"], [60, 3, 1, "", "process_outputs"], [60, 3, 1, "", "python_code"], [60, 3, 1, "", "set_codegen"]], "torch.fx.GraphModule": [[60, 3, 1, "", "__init__"], [60, 3, 1, "", "add_submodule"], [60, 4, 1, "", "code"], [60, 3, 1, "", "delete_all_unused_submodules"], [60, 3, 1, "", "delete_submodule"], [60, 4, 1, "", "graph"], [60, 3, 1, "", "print_readable"], [60, 3, 1, "", "recompile"], [60, 3, 1, "", "to_folder"]], "torch.fx.Interpreter": [[60, 3, 1, "", "call_function"], [60, 3, 1, "", "call_method"], [60, 3, 1, "", "call_module"], [60, 3, 1, "", "fetch_args_kwargs_from_env"], [60, 3, 1, "", "fetch_attr"], [60, 3, 1, "", "get_attr"], [60, 3, 1, "", "map_nodes_to_values"], [60, 3, 1, "", "output"], [60, 3, 1, "", "placeholder"], [60, 3, 1, "", "run"], [60, 3, 1, "", "run_node"]], "torch.fx.Node": [[60, 4, 1, "", "all_input_nodes"], [60, 3, 1, "", "append"], [60, 4, 1, "", "args"], [60, 3, 1, "", "format_node"], [60, 3, 1, "", "is_impure"], [60, 4, 1, "", "kwargs"], [60, 4, 1, "", "next"], [60, 3, 1, "", "normalized_arguments"], [60, 3, 1, "", "prepend"], [60, 4, 1, "", "prev"], [60, 3, 1, "", "replace_all_uses_with"], [60, 3, 1, "", "replace_input_with"], [60, 4, 1, "", "stack_trace"], [60, 3, 1, "", "update_arg"], [60, 3, 1, "", "update_kwarg"]], "torch.fx.Tracer": [[60, 3, 1, "", "call_module"], [60, 3, 1, "", "create_arg"], [60, 3, 1, "", "create_args_for_root"], [60, 3, 1, "", "create_node"], [60, 3, 1, "", "create_proxy"], [60, 3, 1, "", "getattr"], [60, 3, 1, "", "is_leaf_module"], [60, 3, 1, "", "iter"], [60, 3, 1, "", "keys"], [60, 3, 1, "", "path_of_module"], [60, 3, 1, "", "proxy"], [60, 3, 1, "", "to_bool"], [60, 3, 1, "", "trace"]], "torch.fx.Transformer": [[60, 3, 1, "", "call_function"], [60, 3, 1, "", "call_module"], [60, 3, 1, "", "get_attr"], [60, 3, 1, "", "placeholder"], [60, 3, 1, "", "transform"]], "torch.fx.experimental": [[60, 0, 0, "-", "migrate_gradual_types"], [60, 0, 0, "-", "unification"]], "torch.fx.experimental.unification": [[60, 0, 0, "-", "multipledispatch"]], "torch.fx.passes": [[60, 0, 0, "-", "backends"], [60, 0, 0, "-", "dialect"], [60, 0, 0, "-", "infra"], [60, 0, 0, "-", "tests"], [60, 0, 0, "-", "utils"]], "torch.fx.passes.dialect": [[60, 0, 0, "-", "common"]], "torch.hub": [[1735, 5, 1, "", "download_url_to_file"], [1735, 5, 1, "", "get_dir"], [1735, 5, 1, "", "help"], [1735, 5, 1, "", "list"], [1735, 5, 1, "", "load"], [1735, 5, 1, "", "load_state_dict_from_url"], [1735, 5, 1, "", "set_dir"]], "torch.jit": [[1028, 1, 1, "", "Attribute"], [1029, 1, 1, "", "ScriptFunction"], [1030, 1, 1, "", "ScriptModule"], [1031, 5, 1, "", "annotate"], [1032, 5, 1, "", "enable_onednn_fusion"], [1738, 5, 1, "", "export"], [1033, 5, 1, "", "fork"], [1034, 5, 1, "", "freeze"], [1035, 5, 1, "", "ignore"], [1740, 5, 1, "", "is_scripting"], [1740, 5, 1, "", "is_tracing"], [1036, 5, 1, "", "isinstance"], [1037, 5, 1, "", "load"], [1738, 0, 0, "-", "mobile"], [1038, 5, 1, "", "onednn_fusion_enabled"], [1039, 5, 1, "", "optimize_for_inference"], [1040, 5, 1, "", "save"], [1041, 5, 1, "", "script"], [1042, 5, 1, "", "script_if_tracing"], [1043, 5, 1, "", "set_fusion_strategy"], [1044, 1, 1, "", "strict_fusion"], [1739, 0, 0, "-", "supported_ops"], [1045, 5, 1, "", "trace"], [1046, 5, 1, "", "trace_module"], [1743, 0, 0, "-", "unsupported_tensor_ops"], [1047, 5, 1, "", "unused"], [1048, 5, 1, "", "wait"]], "torch.jit.Attribute": [[1028, 3, 1, "", "count"], [1028, 3, 1, "", "index"], [1028, 4, 1, "", "type"], [1028, 4, 1, "", "value"]], "torch.jit.ScriptFunction": [[1029, 3, 1, "", "get_debug_state"], [1029, 3, 1, "", "save"], [1029, 3, 1, "", "save_to_buffer"]], "torch.jit.ScriptModule": [[1030, 3, 1, "", "add_module"], [1030, 3, 1, "", "apply"], [1030, 3, 1, "", "bfloat16"], [1030, 3, 1, "", "buffers"], [1030, 3, 1, "", "children"], [1030, 4, 1, "", "code"], [1030, 4, 1, "", "code_with_constants"], [1030, 3, 1, "", "cpu"], [1030, 3, 1, "", "cuda"], [1030, 3, 1, "", "double"], [1030, 3, 1, "", "eval"], [1030, 3, 1, "", "extra_repr"], [1030, 3, 1, "", "float"], [1030, 3, 1, "", "get_buffer"], [1030, 3, 1, "", "get_extra_state"], [1030, 3, 1, "", "get_parameter"], [1030, 3, 1, "", "get_submodule"], [1030, 4, 1, "", "graph"], [1030, 3, 1, "", "half"], [1030, 4, 1, "", "inlined_graph"], [1030, 3, 1, "", "ipu"], [1030, 3, 1, "", "load_state_dict"], [1030, 3, 1, "", "modules"], [1030, 3, 1, "", "named_buffers"], [1030, 3, 1, "", "named_children"], [1030, 3, 1, "", "named_modules"], [1030, 3, 1, "", "named_parameters"], [1030, 3, 1, "", "parameters"], [1030, 3, 1, "", "register_backward_hook"], [1030, 3, 1, "", "register_buffer"], [1030, 3, 1, "", "register_forward_hook"], [1030, 3, 1, "", "register_forward_pre_hook"], [1030, 3, 1, "", "register_full_backward_hook"], [1030, 3, 1, "", "register_full_backward_pre_hook"], [1030, 3, 1, "", "register_load_state_dict_post_hook"], [1030, 3, 1, "", "register_module"], [1030, 3, 1, "", "register_parameter"], [1030, 3, 1, "", "register_state_dict_pre_hook"], [1030, 3, 1, "", "requires_grad_"], [1030, 3, 1, "", "save"], [1030, 3, 1, "", "set_extra_state"], [1030, 3, 1, "", "share_memory"], [1030, 3, 1, "", "state_dict"], [1030, 3, 1, "", "to"], [1030, 3, 1, "", "to_empty"], [1030, 3, 1, "", "train"], [1030, 3, 1, "", "type"], [1030, 3, 1, "", "xpu"], [1030, 3, 1, "", "zero_grad"]], "torch.library": [[1745, 1, 1, "", "Library"]], "torch.library.Library": [[1745, 3, 1, "", "define"], [1745, 3, 1, "", "impl"]], "torch.linalg": [[1059, 5, 1, "", "cholesky"], [1060, 5, 1, "", "cholesky_ex"], [1061, 5, 1, "", "cond"], [1062, 5, 1, "", "cross"], [1063, 5, 1, "", "det"], [1064, 5, 1, "", "diagonal"], [1065, 5, 1, "", "eig"], [1066, 5, 1, "", "eigh"], [1067, 5, 1, "", "eigvals"], [1068, 5, 1, "", "eigvalsh"], [1069, 5, 1, "", "householder_product"], [1070, 5, 1, "", "inv"], [1071, 5, 1, "", "inv_ex"], [1072, 5, 1, "", "ldl_factor"], [1073, 5, 1, "", "ldl_factor_ex"], [1074, 5, 1, "", "ldl_solve"], [1075, 5, 1, "", "lstsq"], [1076, 5, 1, "", "lu"], [1077, 5, 1, "", "lu_factor"], [1078, 5, 1, "", "lu_factor_ex"], [1079, 5, 1, "", "lu_solve"], [1080, 5, 1, "", "matmul"], [1081, 5, 1, "", "matrix_exp"], [1082, 5, 1, "", "matrix_norm"], [1083, 5, 1, "", "matrix_power"], [1084, 5, 1, "", "matrix_rank"], [1085, 5, 1, "", "multi_dot"], [1086, 5, 1, "", "norm"], [1087, 5, 1, "", "pinv"], [1088, 5, 1, "", "qr"], [1089, 5, 1, "", "slogdet"], [1090, 5, 1, "", "solve"], [1091, 5, 1, "", "solve_ex"], [1092, 5, 1, "", "solve_triangular"], [1093, 5, 1, "", "svd"], [1094, 5, 1, "", "svdvals"], [1095, 5, 1, "", "tensorinv"], [1096, 5, 1, "", "tensorsolve"], [1097, 5, 1, "", "vander"], [1098, 5, 1, "", "vecdot"], [1099, 5, 1, "", "vector_norm"]], "torch.masked": [[1747, 0, 0, "-", "maskedtensor"]], "torch.monitor": [[1750, 1, 1, "", "Aggregation"], [1750, 1, 1, "", "Event"], [1750, 1, 1, "", "EventHandlerHandle"], [1750, 1, 1, "", "Stat"], [1750, 1, 1, "", "TensorboardEventHandler"], [1750, 1, 1, "", "data_value_t"], [1750, 5, 1, "", "log_event"], [1750, 5, 1, "", "register_event_handler"], [1750, 5, 1, "", "unregister_event_handler"]], "torch.monitor.Aggregation": [[1750, 4, 1, "", "name"]], "torch.monitor.Event": [[1750, 3, 1, "", "__init__"], [1750, 4, 1, "", "data"], [1750, 4, 1, "", "name"], [1750, 4, 1, "", "timestamp"]], "torch.monitor.Stat": [[1750, 3, 1, "", "__init__"], [1750, 3, 1, "", "add"], [1750, 4, 1, "", "count"], [1750, 3, 1, "", "get"], [1750, 4, 1, "", "name"]], "torch.monitor.TensorboardEventHandler": [[1750, 3, 1, "", "__init__"]], "torch.multiprocessing": [[1751, 1, 1, "", "SpawnContext"], [1751, 5, 1, "", "get_all_sharing_strategies"], [1751, 5, 1, "", "get_sharing_strategy"], [1751, 5, 1, "", "set_sharing_strategy"], [1751, 5, 1, "", "spawn"]], "torch.multiprocessing.SpawnContext": [[1751, 3, 1, "", "join"]], "torch.nested": [[1754, 5, 1, "", "as_nested_tensor"], [1754, 5, 1, "", "nested_tensor"], [1754, 5, 1, "", "to_padded_tensor"]], "torch.nn": [[1155, 1, 1, "", "AdaptiveAvgPool1d"], [1156, 1, 1, "", "AdaptiveAvgPool2d"], [1157, 1, 1, "", "AdaptiveAvgPool3d"], [1158, 1, 1, "", "AdaptiveLogSoftmaxWithLoss"], [1159, 1, 1, "", "AdaptiveMaxPool1d"], [1160, 1, 1, "", "AdaptiveMaxPool2d"], [1161, 1, 1, "", "AdaptiveMaxPool3d"], [1162, 1, 1, "", "AlphaDropout"], [1163, 1, 1, "", "AvgPool1d"], [1164, 1, 1, "", "AvgPool2d"], [1165, 1, 1, "", "AvgPool3d"], [1166, 1, 1, "", "BCELoss"], [1167, 1, 1, "", "BCEWithLogitsLoss"], [1168, 1, 1, "", "BatchNorm1d"], [1169, 1, 1, "", "BatchNorm2d"], [1170, 1, 1, "", "BatchNorm3d"], [1171, 1, 1, "", "Bilinear"], [1172, 1, 1, "", "CELU"], [1173, 1, 1, "", "CTCLoss"], [1174, 1, 1, "", "ChannelShuffle"], [1175, 1, 1, "", "ConstantPad1d"], [1176, 1, 1, "", "ConstantPad2d"], [1177, 1, 1, "", "ConstantPad3d"], [1178, 1, 1, "", "Conv1d"], [1179, 1, 1, "", "Conv2d"], [1180, 1, 1, "", "Conv3d"], [1181, 1, 1, "", "ConvTranspose1d"], [1182, 1, 1, "", "ConvTranspose2d"], [1183, 1, 1, "", "ConvTranspose3d"], [1184, 1, 1, "", "CosineEmbeddingLoss"], [1185, 1, 1, "", "CosineSimilarity"], [1186, 1, 1, "", "CrossEntropyLoss"], [1187, 1, 1, "", "DataParallel"], [1188, 1, 1, "", "Dropout"], [1189, 1, 1, "", "Dropout1d"], [1190, 1, 1, "", "Dropout2d"], [1191, 1, 1, "", "Dropout3d"], [1192, 1, 1, "", "ELU"], [1193, 1, 1, "", "Embedding"], [1194, 1, 1, "", "EmbeddingBag"], [1195, 1, 1, "", "FeatureAlphaDropout"], [1196, 1, 1, "", "Flatten"], [1197, 1, 1, "", "Fold"], [1198, 1, 1, "", "FractionalMaxPool2d"], [1199, 1, 1, "", "FractionalMaxPool3d"], [1200, 1, 1, "", "GELU"], [1201, 1, 1, "", "GLU"], [1202, 1, 1, "", "GRU"], [1203, 1, 1, "", "GRUCell"], [1204, 1, 1, "", "GaussianNLLLoss"], [1205, 1, 1, "", "GroupNorm"], [1206, 1, 1, "", "Hardshrink"], [1207, 1, 1, "", "Hardsigmoid"], [1208, 1, 1, "", "Hardswish"], [1209, 1, 1, "", "Hardtanh"], [1210, 1, 1, "", "HingeEmbeddingLoss"], [1211, 1, 1, "", "HuberLoss"], [1212, 1, 1, "", "Identity"], [1213, 1, 1, "", "InstanceNorm1d"], [1214, 1, 1, "", "InstanceNorm2d"], [1215, 1, 1, "", "InstanceNorm3d"], [1216, 1, 1, "", "KLDivLoss"], [1217, 1, 1, "", "L1Loss"], [1218, 1, 1, "", "LPPool1d"], [1219, 1, 1, "", "LPPool2d"], [1220, 1, 1, "", "LSTM"], [1221, 1, 1, "", "LSTMCell"], [1222, 1, 1, "", "LayerNorm"], [1223, 1, 1, "", "LazyBatchNorm1d"], [1224, 1, 1, "", "LazyBatchNorm2d"], [1225, 1, 1, "", "LazyBatchNorm3d"], [1226, 1, 1, "", "LazyConv1d"], [1227, 1, 1, "", "LazyConv2d"], [1228, 1, 1, "", "LazyConv3d"], [1229, 1, 1, "", "LazyConvTranspose1d"], [1230, 1, 1, "", "LazyConvTranspose2d"], [1231, 1, 1, "", "LazyConvTranspose3d"], [1232, 1, 1, "", "LazyInstanceNorm1d"], [1233, 1, 1, "", "LazyInstanceNorm2d"], [1234, 1, 1, "", "LazyInstanceNorm3d"], [1235, 1, 1, "", "LazyLinear"], [1236, 1, 1, "", "LeakyReLU"], [1237, 1, 1, "", "Linear"], [1238, 1, 1, "", "LocalResponseNorm"], [1239, 1, 1, "", "LogSigmoid"], [1240, 1, 1, "", "LogSoftmax"], [1241, 1, 1, "", "MSELoss"], [1242, 1, 1, "", "MarginRankingLoss"], [1243, 1, 1, "", "MaxPool1d"], [1244, 1, 1, "", "MaxPool2d"], [1245, 1, 1, "", "MaxPool3d"], [1246, 1, 1, "", "MaxUnpool1d"], [1247, 1, 1, "", "MaxUnpool2d"], [1248, 1, 1, "", "MaxUnpool3d"], [1249, 1, 1, "", "Mish"], [1250, 1, 1, "", "Module"], [1251, 1, 1, "", "ModuleDict"], [1252, 1, 1, "", "ModuleList"], [1253, 1, 1, "", "MultiLabelMarginLoss"], [1254, 1, 1, "", "MultiLabelSoftMarginLoss"], [1255, 1, 1, "", "MultiMarginLoss"], [1256, 1, 1, "", "MultiheadAttention"], [1257, 1, 1, "", "NLLLoss"], [1258, 1, 1, "", "PReLU"], [1259, 1, 1, "", "PairwiseDistance"], [1260, 1, 1, "", "ParameterDict"], [1261, 1, 1, "", "ParameterList"], [1262, 1, 1, "", "PixelShuffle"], [1263, 1, 1, "", "PixelUnshuffle"], [1264, 1, 1, "", "PoissonNLLLoss"], [1265, 1, 1, "", "RNN"], [1266, 1, 1, "", "RNNBase"], [1267, 1, 1, "", "RNNCell"], [1268, 1, 1, "", "RReLU"], [1269, 1, 1, "", "ReLU"], [1270, 1, 1, "", "ReLU6"], [1271, 1, 1, "", "ReflectionPad1d"], [1272, 1, 1, "", "ReflectionPad2d"], [1273, 1, 1, "", "ReflectionPad3d"], [1274, 1, 1, "", "ReplicationPad1d"], [1275, 1, 1, "", "ReplicationPad2d"], [1276, 1, 1, "", "ReplicationPad3d"], [1277, 1, 1, "", "SELU"], [1278, 1, 1, "", "Sequential"], [1279, 1, 1, "", "SiLU"], [1280, 1, 1, "", "Sigmoid"], [1281, 1, 1, "", "SmoothL1Loss"], [1282, 1, 1, "", "SoftMarginLoss"], [1283, 1, 1, "", "Softmax"], [1284, 1, 1, "", "Softmax2d"], [1285, 1, 1, "", "Softmin"], [1286, 1, 1, "", "Softplus"], [1287, 1, 1, "", "Softshrink"], [1288, 1, 1, "", "Softsign"], [1289, 1, 1, "", "SyncBatchNorm"], [1290, 1, 1, "", "Tanh"], [1291, 1, 1, "", "Tanhshrink"], [1292, 1, 1, "", "Threshold"], [1293, 1, 1, "", "Transformer"], [1294, 1, 1, "", "TransformerDecoder"], [1295, 1, 1, "", "TransformerDecoderLayer"], [1296, 1, 1, "", "TransformerEncoder"], [1297, 1, 1, "", "TransformerEncoderLayer"], [1298, 1, 1, "", "TripletMarginLoss"], [1299, 1, 1, "", "TripletMarginWithDistanceLoss"], [1300, 1, 1, "", "Unflatten"], [1301, 1, 1, "", "Unfold"], [1302, 1, 1, "", "Upsample"], [1303, 1, 1, "", "UpsamplingBilinear2d"], [1304, 1, 1, "", "UpsamplingNearest2d"], [1305, 1, 1, "", "ZeroPad2d"], [1755, 0, 0, "-", "backends"], [1787, 0, 0, "-", "intrinsic"], [1755, 0, 0, "-", "modules"], [1755, 0, 0, "-", "parallel"], [1784, 0, 0, "-", "qat"], [1787, 0, 0, "-", "quantizable"], [1784, 0, 0, "-", "quantized"], [1755, 0, 0, "-", "utils"]], "torch.nn.AdaptiveLogSoftmaxWithLoss": [[1158, 3, 1, "", "log_prob"], [1158, 3, 1, "", "predict"]], "torch.nn.Embedding": [[1193, 3, 1, "", "from_pretrained"]], "torch.nn.EmbeddingBag": [[1194, 3, 1, "", "forward"], [1194, 3, 1, "", "from_pretrained"]], "torch.nn.LazyBatchNorm1d": [[1223, 2, 1, "", "cls_to_become"]], "torch.nn.LazyBatchNorm2d": [[1224, 2, 1, "", "cls_to_become"]], "torch.nn.LazyBatchNorm3d": [[1225, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConv1d": [[1226, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConv2d": [[1227, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConv3d": [[1228, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConvTranspose1d": [[1229, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConvTranspose2d": [[1230, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConvTranspose3d": [[1231, 2, 1, "", "cls_to_become"]], "torch.nn.LazyInstanceNorm1d": [[1232, 2, 1, "", "cls_to_become"]], "torch.nn.LazyInstanceNorm2d": [[1233, 2, 1, "", "cls_to_become"]], "torch.nn.LazyInstanceNorm3d": [[1234, 2, 1, "", "cls_to_become"]], "torch.nn.LazyLinear": [[1235, 2, 1, "", "cls_to_become"]], "torch.nn.Module": [[1250, 3, 1, "", "add_module"], [1250, 3, 1, "", "apply"], [1250, 3, 1, "", "bfloat16"], [1250, 3, 1, "", "buffers"], [1250, 3, 1, "", "children"], [1250, 3, 1, "", "cpu"], [1250, 3, 1, "", "cuda"], [1250, 3, 1, "", "double"], [1250, 3, 1, "", "eval"], [1250, 3, 1, "", "extra_repr"], [1250, 3, 1, "", "float"], [1250, 3, 1, "", "forward"], [1250, 3, 1, "", "get_buffer"], [1250, 3, 1, "", "get_extra_state"], [1250, 3, 1, "", "get_parameter"], [1250, 3, 1, "", "get_submodule"], [1250, 3, 1, "", "half"], [1250, 3, 1, "", "ipu"], [1250, 3, 1, "", "load_state_dict"], [1250, 3, 1, "", "modules"], [1250, 3, 1, "", "named_buffers"], [1250, 3, 1, "", "named_children"], [1250, 3, 1, "", "named_modules"], [1250, 3, 1, "", "named_parameters"], [1250, 3, 1, "", "parameters"], [1250, 3, 1, "", "register_backward_hook"], [1250, 3, 1, "", "register_buffer"], [1250, 3, 1, "", "register_forward_hook"], [1250, 3, 1, "", "register_forward_pre_hook"], [1250, 3, 1, "", "register_full_backward_hook"], [1250, 3, 1, "", "register_full_backward_pre_hook"], [1250, 3, 1, "", "register_load_state_dict_post_hook"], [1250, 3, 1, "", "register_module"], [1250, 3, 1, "", "register_parameter"], [1250, 3, 1, "", "register_state_dict_pre_hook"], [1250, 3, 1, "", "requires_grad_"], [1250, 3, 1, "", "set_extra_state"], [1250, 3, 1, "", "share_memory"], [1250, 3, 1, "", "state_dict"], [1250, 3, 1, "", "to"], [1250, 3, 1, "", "to_empty"], [1250, 3, 1, "", "train"], [1250, 3, 1, "", "type"], [1250, 3, 1, "", "xpu"], [1250, 3, 1, "", "zero_grad"]], "torch.nn.ModuleDict": [[1251, 3, 1, "", "clear"], [1251, 3, 1, "", "items"], [1251, 3, 1, "", "keys"], [1251, 3, 1, "", "pop"], [1251, 3, 1, "", "update"], [1251, 3, 1, "", "values"]], "torch.nn.ModuleList": [[1252, 3, 1, "", "append"], [1252, 3, 1, "", "extend"], [1252, 3, 1, "", "insert"]], "torch.nn.MultiheadAttention": [[1256, 3, 1, "", "forward"], [1256, 3, 1, "", "merge_masks"]], "torch.nn.ParameterDict": [[1260, 3, 1, "", "clear"], [1260, 3, 1, "", "copy"], [1260, 3, 1, "", "fromkeys"], [1260, 3, 1, "", "get"], [1260, 3, 1, "", "items"], [1260, 3, 1, "", "keys"], [1260, 3, 1, "", "pop"], [1260, 3, 1, "", "popitem"], [1260, 3, 1, "", "setdefault"], [1260, 3, 1, "", "update"], [1260, 3, 1, "", "values"]], "torch.nn.ParameterList": [[1261, 3, 1, "", "append"], [1261, 3, 1, "", "extend"]], "torch.nn.RNNBase": [[1266, 3, 1, "", "flatten_parameters"]], "torch.nn.Sequential": [[1278, 3, 1, "", "append"]], "torch.nn.SyncBatchNorm": [[1289, 3, 1, "", "convert_sync_batchnorm"]], "torch.nn.Transformer": [[1293, 3, 1, "", "forward"], [1293, 3, 1, "", "generate_square_subsequent_mask"]], "torch.nn.TransformerDecoder": [[1294, 3, 1, "", "forward"]], "torch.nn.TransformerDecoderLayer": [[1295, 3, 1, "", "forward"]], "torch.nn.TransformerEncoder": [[1296, 3, 1, "", "forward"]], "torch.nn.TransformerEncoderLayer": [[1297, 3, 1, "", "forward"]], "torch.nn.functional": [[1306, 5, 1, "", "adaptive_avg_pool1d"], [1307, 5, 1, "", "adaptive_avg_pool2d"], [1308, 5, 1, "", "adaptive_avg_pool3d"], [1309, 5, 1, "", "adaptive_max_pool1d"], [1310, 5, 1, "", "adaptive_max_pool2d"], [1311, 5, 1, "", "adaptive_max_pool3d"], [1312, 5, 1, "", "affine_grid"], [1313, 5, 1, "", "alpha_dropout"], [1314, 5, 1, "", "avg_pool1d"], [1315, 5, 1, "", "avg_pool2d"], [1316, 5, 1, "", "avg_pool3d"], [1317, 5, 1, "", "batch_norm"], [1318, 5, 1, "", "bilinear"], [1319, 5, 1, "", "binary_cross_entropy"], [1320, 5, 1, "", "binary_cross_entropy_with_logits"], [1321, 5, 1, "", "celu"], [1322, 5, 1, "", "conv1d"], [1323, 5, 1, "", "conv2d"], [1324, 5, 1, "", "conv3d"], [1325, 5, 1, "", "conv_transpose1d"], [1326, 5, 1, "", "conv_transpose2d"], [1327, 5, 1, "", "conv_transpose3d"], [1328, 5, 1, "", "cosine_embedding_loss"], [1329, 5, 1, "", "cosine_similarity"], [1330, 5, 1, "", "cross_entropy"], [1331, 5, 1, "", "ctc_loss"], [1332, 5, 1, "", "dropout"], [1333, 5, 1, "", "dropout1d"], [1334, 5, 1, "", "dropout2d"], [1335, 5, 1, "", "dropout3d"], [1336, 5, 1, "", "elu"], [1337, 5, 1, "", "elu_"], [1338, 5, 1, "", "embedding"], [1339, 5, 1, "", "embedding_bag"], [1340, 5, 1, "", "feature_alpha_dropout"], [1341, 5, 1, "", "fold"], [1342, 5, 1, "", "fractional_max_pool2d"], [1343, 5, 1, "", "fractional_max_pool3d"], [1344, 5, 1, "", "gaussian_nll_loss"], [1345, 5, 1, "", "gelu"], [1346, 5, 1, "", "glu"], [1347, 5, 1, "", "grid_sample"], [1348, 5, 1, "", "group_norm"], [1349, 5, 1, "", "gumbel_softmax"], [1350, 5, 1, "", "hardshrink"], [1351, 5, 1, "", "hardsigmoid"], [1352, 5, 1, "", "hardswish"], [1353, 5, 1, "", "hardtanh"], [1354, 5, 1, "", "hardtanh_"], [1355, 5, 1, "", "hinge_embedding_loss"], [1356, 5, 1, "", "huber_loss"], [1357, 5, 1, "", "instance_norm"], [1358, 5, 1, "", "interpolate"], [1359, 5, 1, "", "kl_div"], [1360, 5, 1, "", "l1_loss"], [1361, 5, 1, "", "layer_norm"], [1362, 5, 1, "", "leaky_relu"], [1363, 5, 1, "", "leaky_relu_"], [1364, 5, 1, "", "linear"], [1365, 5, 1, "", "local_response_norm"], [1366, 5, 1, "", "log_softmax"], [1367, 5, 1, "", "logsigmoid"], [1368, 5, 1, "", "lp_pool1d"], [1369, 5, 1, "", "lp_pool2d"], [1370, 5, 1, "", "margin_ranking_loss"], [1371, 5, 1, "", "max_pool1d"], [1372, 5, 1, "", "max_pool2d"], [1373, 5, 1, "", "max_pool3d"], [1374, 5, 1, "", "max_unpool1d"], [1375, 5, 1, "", "max_unpool2d"], [1376, 5, 1, "", "max_unpool3d"], [1377, 5, 1, "", "mish"], [1378, 5, 1, "", "mse_loss"], [1379, 5, 1, "", "multi_margin_loss"], [1380, 5, 1, "", "multilabel_margin_loss"], [1381, 5, 1, "", "multilabel_soft_margin_loss"], [1382, 5, 1, "", "nll_loss"], [1383, 5, 1, "", "normalize"], [1384, 5, 1, "", "one_hot"], [1385, 5, 1, "", "pad"], [1386, 5, 1, "", "pairwise_distance"], [1387, 5, 1, "", "pdist"], [1388, 5, 1, "", "pixel_shuffle"], [1389, 5, 1, "", "pixel_unshuffle"], [1390, 5, 1, "", "poisson_nll_loss"], [1391, 5, 1, "", "prelu"], [1392, 5, 1, "", "relu"], [1393, 5, 1, "", "relu6"], [1394, 5, 1, "", "relu_"], [1395, 5, 1, "", "rrelu"], [1396, 5, 1, "", "rrelu_"], [1397, 5, 1, "", "selu"], [1398, 5, 1, "", "sigmoid"], [1399, 5, 1, "", "silu"], [1400, 5, 1, "", "smooth_l1_loss"], [1401, 5, 1, "", "soft_margin_loss"], [1402, 5, 1, "", "softmax"], [1403, 5, 1, "", "softmin"], [1404, 5, 1, "", "softplus"], [1405, 5, 1, "", "softshrink"], [1406, 5, 1, "", "softsign"], [1407, 5, 1, "", "tanh"], [1408, 5, 1, "", "tanhshrink"], [1409, 5, 1, "", "threshold"], [1410, 5, 1, "", "threshold_"], [1412, 5, 1, "", "triplet_margin_loss"], [1413, 5, 1, "", "triplet_margin_with_distance_loss"], [1414, 5, 1, "", "unfold"], [1415, 5, 1, "", "upsample"], [1416, 5, 1, "", "upsample_bilinear"], [1417, 5, 1, "", "upsample_nearest"]], "torch.nn.init": [[1757, 5, 1, "", "calculate_gain"], [1757, 5, 1, "", "constant_"], [1757, 5, 1, "", "dirac_"], [1757, 5, 1, "", "eye_"], [1757, 5, 1, "", "kaiming_normal_"], [1757, 5, 1, "", "kaiming_uniform_"], [1757, 5, 1, "", "normal_"], [1757, 5, 1, "", "ones_"], [1757, 5, 1, "", "orthogonal_"], [1757, 5, 1, "", "sparse_"], [1757, 5, 1, "", "trunc_normal_"], [1757, 5, 1, "", "uniform_"], [1757, 5, 1, "", "xavier_normal_"], [1757, 5, 1, "", "xavier_uniform_"], [1757, 5, 1, "", "zeros_"]], "torch.nn.intrinsic": [[1787, 0, 0, "-", "modules"], [1787, 0, 0, "-", "qat"], [1787, 0, 0, "-", "quantized"]], "torch.nn.intrinsic.qat": [[1787, 0, 0, "-", "modules"]], "torch.nn.intrinsic.quantized": [[1787, 0, 0, "-", "dynamic"], [1787, 0, 0, "-", "modules"]], "torch.nn.intrinsic.quantized.dynamic": [[1787, 0, 0, "-", "modules"]], "torch.nn.modules.lazy": [[1418, 1, 1, "", "LazyModuleMixin"]], "torch.nn.modules.lazy.LazyModuleMixin": [[1418, 3, 1, "", "has_uninitialized_params"], [1418, 3, 1, "", "initialize_parameters"]], "torch.nn.modules.module": [[1419, 5, 1, "", "register_module_backward_hook"], [1420, 5, 1, "", "register_module_forward_hook"], [1421, 5, 1, "", "register_module_forward_pre_hook"], [1422, 5, 1, "", "register_module_full_backward_hook"]], "torch.nn.parallel": [[1423, 1, 1, "", "DistributedDataParallel"], [1411, 5, 1, "", "data_parallel"]], "torch.nn.parallel.DistributedDataParallel": [[1423, 3, 1, "", "join"], [1423, 3, 1, "", "join_hook"], [1423, 3, 1, "", "no_sync"], [1423, 3, 1, "", "register_comm_hook"]], "torch.nn.parameter": [[1424, 1, 1, "", "Parameter"], [1425, 1, 1, "", "UninitializedBuffer"], [1426, 1, 1, "", "UninitializedParameter"]], "torch.nn.parameter.UninitializedParameter": [[1426, 2, 1, "", "cls_to_become"]], "torch.nn.qat": [[1784, 0, 0, "-", "dynamic"], [1784, 0, 0, "-", "modules"]], "torch.nn.qat.dynamic": [[1784, 0, 0, "-", "modules"]], "torch.nn.quantizable": [[1427, 1, 1, "", "LSTM"], [1428, 1, 1, "", "MultiheadAttention"], [1787, 0, 0, "-", "modules"]], "torch.nn.quantizable.MultiheadAttention": [[1428, 3, 1, "", "dequantize"], [1428, 3, 1, "", "forward"]], "torch.nn.quantized": [[1784, 0, 0, "-", "dynamic"], [1784, 0, 0, "-", "modules"]], "torch.nn.quantized.dynamic": [[1784, 0, 0, "-", "modules"]], "torch.nn.utils": [[1429, 5, 1, "", "clip_grad_norm_"], [1430, 5, 1, "", "clip_grad_value_"], [1431, 5, 1, "", "parameters_to_vector"], [1456, 5, 1, "", "remove_spectral_norm"], [1457, 5, 1, "", "remove_weight_norm"], [1463, 5, 1, "", "skip_init"], [1464, 5, 1, "", "spectral_norm"], [1755, 0, 0, "-", "stateless"], [1466, 5, 1, "", "vector_to_parameters"], [1467, 5, 1, "", "weight_norm"]], "torch.nn.utils.parametrizations": [[1432, 5, 1, "", "orthogonal"], [1433, 5, 1, "", "spectral_norm"]], "torch.nn.utils.parametrize": [[1434, 1, 1, "", "ParametrizationList"], [1435, 5, 1, "", "cached"], [1436, 5, 1, "", "is_parametrized"], [1437, 5, 1, "", "register_parametrization"], [1438, 5, 1, "", "remove_parametrizations"]], "torch.nn.utils.parametrize.ParametrizationList": [[1434, 3, 1, "", "right_inverse"]], "torch.nn.utils.prune": [[1439, 1, 1, "", "BasePruningMethod"], [1440, 1, 1, "", "CustomFromMask"], [1441, 1, 1, "", "Identity"], [1442, 1, 1, "", "L1Unstructured"], [1443, 1, 1, "", "LnStructured"], [1444, 1, 1, "", "PruningContainer"], [1445, 1, 1, "", "RandomStructured"], [1446, 1, 1, "", "RandomUnstructured"], [1447, 5, 1, "", "custom_from_mask"], [1448, 5, 1, "", "global_unstructured"], [1449, 5, 1, "", "identity"], [1450, 5, 1, "", "is_pruned"], [1451, 5, 1, "", "l1_unstructured"], [1452, 5, 1, "", "ln_structured"], [1453, 5, 1, "", "random_structured"], [1454, 5, 1, "", "random_unstructured"], [1455, 5, 1, "", "remove"]], "torch.nn.utils.prune.BasePruningMethod": [[1439, 3, 1, "", "apply"], [1439, 3, 1, "", "apply_mask"], [1439, 3, 1, "", "compute_mask"], [1439, 3, 1, "", "prune"], [1439, 3, 1, "", "remove"]], "torch.nn.utils.prune.CustomFromMask": [[1440, 3, 1, "", "apply"], [1440, 3, 1, "", "apply_mask"], [1440, 3, 1, "", "prune"], [1440, 3, 1, "", "remove"]], "torch.nn.utils.prune.Identity": [[1441, 3, 1, "", "apply"], [1441, 3, 1, "", "apply_mask"], [1441, 3, 1, "", "prune"], [1441, 3, 1, "", "remove"]], "torch.nn.utils.prune.L1Unstructured": [[1442, 3, 1, "", "apply"], [1442, 3, 1, "", "apply_mask"], [1442, 3, 1, "", "prune"], [1442, 3, 1, "", "remove"]], "torch.nn.utils.prune.LnStructured": [[1443, 3, 1, "", "apply"], [1443, 3, 1, "", "apply_mask"], [1443, 3, 1, "", "compute_mask"], [1443, 3, 1, "", "prune"], [1443, 3, 1, "", "remove"]], "torch.nn.utils.prune.PruningContainer": [[1444, 3, 1, "", "add_pruning_method"], [1444, 3, 1, "", "apply"], [1444, 3, 1, "", "apply_mask"], [1444, 3, 1, "", "compute_mask"], [1444, 3, 1, "", "prune"], [1444, 3, 1, "", "remove"]], "torch.nn.utils.prune.RandomStructured": [[1445, 3, 1, "", "apply"], [1445, 3, 1, "", "apply_mask"], [1445, 3, 1, "", "compute_mask"], [1445, 3, 1, "", "prune"], [1445, 3, 1, "", "remove"]], "torch.nn.utils.prune.RandomUnstructured": [[1446, 3, 1, "", "apply"], [1446, 3, 1, "", "apply_mask"], [1446, 3, 1, "", "prune"], [1446, 3, 1, "", "remove"]], "torch.nn.utils.rnn": [[1458, 1, 1, "", "PackedSequence"], [1459, 5, 1, "", "pack_padded_sequence"], [1460, 5, 1, "", "pack_sequence"], [1461, 5, 1, "", "pad_packed_sequence"], [1462, 5, 1, "", "pad_sequence"]], "torch.nn.utils.rnn.PackedSequence": [[1458, 4, 1, "", "batch_sizes"], [1458, 3, 1, "", "count"], [1458, 4, 1, "", "data"], [1458, 3, 1, "", "index"], [1458, 4, 1, "", "is_cuda"], [1458, 3, 1, "", "is_pinned"], [1458, 4, 1, "", "sorted_indices"], [1458, 3, 1, "", "to"], [1458, 4, 1, "", "unsorted_indices"]], "torch.nn.utils.stateless": [[1465, 5, 1, "", "functional_call"]], "torch.onnx": [[1476, 1, 1, "", "JitScalarType"], [1777, 5, 1, "", "disable_log"], [1777, 5, 1, "", "enable_log"], [1777, 5, 1, "", "export"], [1777, 5, 1, "", "export_to_pretty_string"], [1777, 5, 1, "", "is_in_onnx_export"], [1777, 5, 1, "", "register_custom_op_symbolic"], [1777, 5, 1, "", "select_model_mode_for_export"], [1777, 5, 1, "", "unregister_custom_op_symbolic"]], "torch.onnx.JitScalarType": [[1476, 3, 1, "", "dtype"], [1476, 3, 1, "", "from_dtype"], [1476, 3, 1, "", "from_value"], [1476, 3, 1, "", "onnx_compatible"], [1476, 3, 1, "", "onnx_type"], [1476, 3, 1, "", "scalar_name"], [1476, 3, 1, "", "torch_name"]], "torch.onnx._internal": [[1778, 0, 0, "-", "diagnostics"]], "torch.onnx._internal.diagnostics": [[1778, 1, 1, "", "ExportDiagnostic"]], "torch.onnx._internal.diagnostics.ExportDiagnostic": [[1778, 3, 1, "", "record_cpp_call_stack"], [1778, 3, 1, "", "record_python_call_stack"]], "torch.onnx._internal.diagnostics.infra": [[1778, 1, 1, "", "DiagnosticEngine"]], "torch.onnx._internal.diagnostics.infra.DiagnosticEngine": [[1778, 3, 1, "", "clear"], [1778, 3, 1, "", "create_diagnostic_context"], [1778, 3, 1, "", "pretty_print"]], "torch.optim": [[1477, 1, 1, "", "ASGD"], [1478, 1, 1, "", "Adadelta"], [1479, 1, 1, "", "Adagrad"], [1480, 1, 1, "", "Adam"], [1481, 1, 1, "", "AdamW"], [1482, 1, 1, "", "Adamax"], [1483, 1, 1, "", "LBFGS"], [1484, 1, 1, "", "NAdam"], [1780, 1, 1, "", "Optimizer"], [1490, 1, 1, "", "RAdam"], [1491, 1, 1, "", "RMSprop"], [1492, 1, 1, "", "Rprop"], [1493, 1, 1, "", "SGD"], [1494, 1, 1, "", "SparseAdam"]], "torch.optim.ASGD": [[1477, 3, 1, "", "add_param_group"], [1477, 3, 1, "", "load_state_dict"], [1477, 3, 1, "", "register_step_post_hook"], [1477, 3, 1, "", "register_step_pre_hook"], [1477, 3, 1, "", "state_dict"], [1477, 3, 1, "", "zero_grad"]], "torch.optim.Adadelta": [[1478, 3, 1, "", "add_param_group"], [1478, 3, 1, "", "load_state_dict"], [1478, 3, 1, "", "register_step_post_hook"], [1478, 3, 1, "", "register_step_pre_hook"], [1478, 3, 1, "", "state_dict"], [1478, 3, 1, "", "zero_grad"]], "torch.optim.Adagrad": [[1479, 3, 1, "", "add_param_group"], [1479, 3, 1, "", "load_state_dict"], [1479, 3, 1, "", "register_step_post_hook"], [1479, 3, 1, "", "register_step_pre_hook"], [1479, 3, 1, "", "state_dict"], [1479, 3, 1, "", "zero_grad"]], "torch.optim.Adam": [[1480, 3, 1, "", "add_param_group"], [1480, 3, 1, "", "load_state_dict"], [1480, 3, 1, "", "register_step_post_hook"], [1480, 3, 1, "", "register_step_pre_hook"], [1480, 3, 1, "", "state_dict"], [1480, 3, 1, "", "zero_grad"]], "torch.optim.AdamW": [[1481, 3, 1, "", "add_param_group"], [1481, 3, 1, "", "load_state_dict"], [1481, 3, 1, "", "register_step_post_hook"], [1481, 3, 1, "", "register_step_pre_hook"], [1481, 3, 1, "", "state_dict"], [1481, 3, 1, "", "zero_grad"]], "torch.optim.Adamax": [[1482, 3, 1, "", "add_param_group"], [1482, 3, 1, "", "load_state_dict"], [1482, 3, 1, "", "register_step_post_hook"], [1482, 3, 1, "", "register_step_pre_hook"], [1482, 3, 1, "", "state_dict"], [1482, 3, 1, "", "zero_grad"]], "torch.optim.LBFGS": [[1483, 3, 1, "", "add_param_group"], [1483, 3, 1, "", "load_state_dict"], [1483, 3, 1, "", "register_step_post_hook"], [1483, 3, 1, "", "register_step_pre_hook"], [1483, 3, 1, "", "state_dict"], [1483, 3, 1, "", "step"], [1483, 3, 1, "", "zero_grad"]], "torch.optim.NAdam": [[1484, 3, 1, "", "add_param_group"], [1484, 3, 1, "", "load_state_dict"], [1484, 3, 1, "", "register_step_post_hook"], [1484, 3, 1, "", "register_step_pre_hook"], [1484, 3, 1, "", "state_dict"], [1484, 3, 1, "", "zero_grad"]], "torch.optim.Optimizer": [[1485, 3, 1, "", "add_param_group"], [1486, 3, 1, "", "load_state_dict"], [1487, 3, 1, "", "state_dict"], [1488, 3, 1, "", "step"], [1489, 3, 1, "", "zero_grad"]], "torch.optim.RAdam": [[1490, 3, 1, "", "add_param_group"], [1490, 3, 1, "", "load_state_dict"], [1490, 3, 1, "", "register_step_post_hook"], [1490, 3, 1, "", "register_step_pre_hook"], [1490, 3, 1, "", "state_dict"], [1490, 3, 1, "", "zero_grad"]], "torch.optim.RMSprop": [[1491, 3, 1, "", "add_param_group"], [1491, 3, 1, "", "load_state_dict"], [1491, 3, 1, "", "register_step_post_hook"], [1491, 3, 1, "", "register_step_pre_hook"], [1491, 3, 1, "", "state_dict"], [1491, 3, 1, "", "zero_grad"]], "torch.optim.Rprop": [[1492, 3, 1, "", "add_param_group"], [1492, 3, 1, "", "load_state_dict"], [1492, 3, 1, "", "register_step_post_hook"], [1492, 3, 1, "", "register_step_pre_hook"], [1492, 3, 1, "", "state_dict"], [1492, 3, 1, "", "zero_grad"]], "torch.optim.SGD": [[1493, 3, 1, "", "add_param_group"], [1493, 3, 1, "", "load_state_dict"], [1493, 3, 1, "", "register_step_post_hook"], [1493, 3, 1, "", "register_step_pre_hook"], [1493, 3, 1, "", "state_dict"], [1493, 3, 1, "", "zero_grad"]], "torch.optim.SparseAdam": [[1494, 3, 1, "", "add_param_group"], [1494, 3, 1, "", "load_state_dict"], [1494, 3, 1, "", "register_step_post_hook"], [1494, 3, 1, "", "register_step_pre_hook"], [1494, 3, 1, "", "state_dict"], [1494, 3, 1, "", "step"], [1494, 3, 1, "", "zero_grad"]], "torch.optim.lr_scheduler": [[1495, 1, 1, "", "ChainedScheduler"], [1496, 1, 1, "", "ConstantLR"], [1497, 1, 1, "", "CosineAnnealingLR"], [1498, 1, 1, "", "CosineAnnealingWarmRestarts"], [1499, 1, 1, "", "CyclicLR"], [1500, 1, 1, "", "ExponentialLR"], [1501, 1, 1, "", "LambdaLR"], [1502, 1, 1, "", "LinearLR"], [1503, 1, 1, "", "MultiStepLR"], [1504, 1, 1, "", "MultiplicativeLR"], [1505, 1, 1, "", "OneCycleLR"], [1506, 1, 1, "", "PolynomialLR"], [1507, 1, 1, "", "ReduceLROnPlateau"], [1508, 1, 1, "", "SequentialLR"], [1509, 1, 1, "", "StepLR"]], "torch.optim.lr_scheduler.ChainedScheduler": [[1495, 3, 1, "", "get_last_lr"], [1495, 3, 1, "", "load_state_dict"], [1495, 3, 1, "", "print_lr"], [1495, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.ConstantLR": [[1496, 3, 1, "", "get_last_lr"], [1496, 3, 1, "", "load_state_dict"], [1496, 3, 1, "", "print_lr"], [1496, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.CosineAnnealingLR": [[1497, 3, 1, "", "get_last_lr"], [1497, 3, 1, "", "load_state_dict"], [1497, 3, 1, "", "print_lr"], [1497, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts": [[1498, 3, 1, "", "get_last_lr"], [1498, 3, 1, "", "load_state_dict"], [1498, 3, 1, "", "print_lr"], [1498, 3, 1, "", "state_dict"], [1498, 3, 1, "", "step"]], "torch.optim.lr_scheduler.CyclicLR": [[1499, 3, 1, "", "get_last_lr"], [1499, 3, 1, "", "get_lr"], [1499, 3, 1, "", "print_lr"]], "torch.optim.lr_scheduler.ExponentialLR": [[1500, 3, 1, "", "get_last_lr"], [1500, 3, 1, "", "load_state_dict"], [1500, 3, 1, "", "print_lr"], [1500, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.LambdaLR": [[1501, 3, 1, "", "get_last_lr"], [1501, 3, 1, "", "load_state_dict"], [1501, 3, 1, "", "print_lr"], [1501, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.LinearLR": [[1502, 3, 1, "", "get_last_lr"], [1502, 3, 1, "", "load_state_dict"], [1502, 3, 1, "", "print_lr"], [1502, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.MultiStepLR": [[1503, 3, 1, "", "get_last_lr"], [1503, 3, 1, "", "load_state_dict"], [1503, 3, 1, "", "print_lr"], [1503, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.MultiplicativeLR": [[1504, 3, 1, "", "get_last_lr"], [1504, 3, 1, "", "load_state_dict"], [1504, 3, 1, "", "print_lr"], [1504, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.OneCycleLR": [[1505, 3, 1, "", "get_last_lr"], [1505, 3, 1, "", "load_state_dict"], [1505, 3, 1, "", "print_lr"], [1505, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.PolynomialLR": [[1506, 3, 1, "", "get_last_lr"], [1506, 3, 1, "", "load_state_dict"], [1506, 3, 1, "", "print_lr"], [1506, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.SequentialLR": [[1508, 3, 1, "", "get_last_lr"], [1508, 3, 1, "", "load_state_dict"], [1508, 3, 1, "", "print_lr"], [1508, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.StepLR": [[1509, 3, 1, "", "get_last_lr"], [1509, 3, 1, "", "load_state_dict"], [1509, 3, 1, "", "print_lr"], [1509, 3, 1, "", "state_dict"]], "torch.overrides": [[1804, 5, 1, "", "get_ignored_functions"], [1804, 5, 1, "", "get_overridable_functions"], [1804, 5, 1, "", "get_testing_overrides"], [1804, 5, 1, "", "handle_torch_function"], [1804, 5, 1, "", "has_torch_function"], [1804, 5, 1, "", "is_tensor_like"], [1804, 5, 1, "", "is_tensor_method_or_property"], [1804, 5, 1, "", "resolve_name"], [1804, 5, 1, "", "wrap_torch_function"]], "torch.package": [[1781, 1, 1, "", "Directory"], [1781, 1, 1, "", "EmptyMatchError"], [1781, 1, 1, "", "PackageExporter"], [1781, 1, 1, "", "PackageImporter"], [1781, 1, 1, "", "PackagingError"], [1781, 0, 0, "-", "analyze"]], "torch.package.Directory": [[1781, 3, 1, "", "has_file"]], "torch.package.PackageExporter": [[1781, 3, 1, "", "__init__"], [1781, 3, 1, "", "add_dependency"], [1781, 3, 1, "", "all_paths"], [1781, 3, 1, "", "close"], [1781, 3, 1, "", "denied_modules"], [1781, 3, 1, "", "deny"], [1781, 3, 1, "", "dependency_graph_string"], [1781, 3, 1, "", "extern"], [1781, 3, 1, "", "externed_modules"], [1781, 3, 1, "", "get_rdeps"], [1781, 3, 1, "", "get_unique_id"], [1781, 3, 1, "", "intern"], [1781, 3, 1, "", "interned_modules"], [1781, 3, 1, "", "mock"], [1781, 3, 1, "", "mocked_modules"], [1781, 3, 1, "", "register_extern_hook"], [1781, 3, 1, "", "register_intern_hook"], [1781, 3, 1, "", "register_mock_hook"], [1781, 3, 1, "", "save_binary"], [1781, 3, 1, "", "save_module"], [1781, 3, 1, "", "save_pickle"], [1781, 3, 1, "", "save_source_file"], [1781, 3, 1, "", "save_source_string"], [1781, 3, 1, "", "save_text"]], "torch.package.PackageImporter": [[1781, 3, 1, "", "__init__"], [1781, 3, 1, "", "file_structure"], [1781, 3, 1, "", "id"], [1781, 3, 1, "", "import_module"], [1781, 3, 1, "", "load_binary"], [1781, 3, 1, "", "load_pickle"], [1781, 3, 1, "", "load_text"], [1781, 3, 1, "", "python_version"]], "torch.profiler": [[1783, 1, 1, "", "ProfilerAction"], [1783, 1, 1, "", "ProfilerActivity"], [1783, 1, 1, "", "_KinetoProfile"], [1783, 1, 1, "", "profile"], [1783, 5, 1, "", "schedule"], [1783, 5, 1, "", "tensorboard_trace_handler"]], "torch.profiler.ProfilerActivity": [[1783, 4, 1, "", "name"]], "torch.profiler._KinetoProfile": [[1783, 3, 1, "", "add_metadata"], [1783, 3, 1, "", "add_metadata_json"], [1783, 3, 1, "", "events"], [1783, 3, 1, "", "export_chrome_trace"], [1783, 3, 1, "", "export_stacks"], [1783, 3, 1, "", "key_averages"]], "torch.profiler.itt": [[1783, 5, 1, "", "is_available"], [1783, 5, 1, "", "mark"], [1783, 5, 1, "", "range_pop"], [1783, 5, 1, "", "range_push"]], "torch.profiler.profile": [[1783, 3, 1, "", "step"]], "torch.quantization": [[1525, 1, 1, "", "DeQuantStub"], [1526, 1, 1, "", "QuantStub"], [1527, 1, 1, "", "QuantWrapper"], [1528, 1, 1, "", "add_quant_dequant"], [1529, 1, 1, "", "convert"], [1530, 1, 1, "", "default_eval_fn"], [1546, 1, 1, "", "fuse_modules"], [1784, 0, 0, "-", "fx"], [1566, 1, 1, "", "prepare"], [1567, 1, 1, "", "prepare_qat"], [1568, 1, 1, "", "propagate_qconfig_"], [1582, 1, 1, "", "quantize"], [1583, 1, 1, "", "quantize_dynamic"], [1588, 1, 1, "", "quantize_qat"], [1589, 1, 1, "", "swap_module"]], "torch.quantization.fake_quantize": [[1531, 1, 1, "", "FakeQuantize"], [1532, 1, 1, "", "FakeQuantizeBase"], [1533, 1, 1, "", "FixedQParamsFakeQuantize"], [1534, 1, 1, "", "FusedMovingAvgObsFakeQuantize"], [1535, 2, 1, "", "default_fake_quant"], [1536, 2, 1, "", "default_fused_act_fake_quant"], [1537, 2, 1, "", "default_fused_per_channel_wt_fake_quant"], [1538, 2, 1, "", "default_fused_wt_fake_quant"], [1539, 2, 1, "", "default_histogram_fake_quant"], [1540, 2, 1, "", "default_per_channel_weight_fake_quant"], [1541, 2, 1, "", "default_weight_fake_quant"], [1542, 1, 1, "", "disable_fake_quant"], [1543, 1, 1, "", "disable_observer"], [1544, 1, 1, "", "enable_fake_quant"], [1545, 1, 1, "", "enable_observer"]], "torch.quantization.observer": [[1547, 1, 1, "", "HistogramObserver"], [1548, 1, 1, "", "MinMaxObserver"], [1549, 1, 1, "", "MovingAverageMinMaxObserver"], [1550, 1, 1, "", "MovingAveragePerChannelMinMaxObserver"], [1551, 1, 1, "", "NoopObserver"], [1552, 1, 1, "", "ObserverBase"], [1553, 1, 1, "", "PerChannelMinMaxObserver"], [1554, 1, 1, "", "PlaceholderObserver"], [1555, 1, 1, "", "RecordingObserver"], [1556, 2, 1, "", "default_debug_observer"], [1557, 2, 1, "", "default_dynamic_quant_observer"], [1558, 2, 1, "", "default_float_qparams_observer"], [1559, 2, 1, "", "default_histogram_observer"], [1560, 2, 1, "", "default_observer"], [1561, 2, 1, "", "default_per_channel_weight_observer"], [1562, 2, 1, "", "default_placeholder_observer"], [1563, 2, 1, "", "default_weight_observer"], [1564, 1, 1, "", "get_observer_state_dict"], [1565, 1, 1, "", "load_observer_state_dict"]], "torch.quantization.observer.MinMaxObserver": [[1548, 3, 1, "", "calculate_qparams"], [1548, 3, 1, "", "forward"], [1548, 3, 1, "", "reset_min_max_vals"]], "torch.quantization.observer.ObserverBase": [[1552, 3, 1, "", "with_args"], [1552, 3, 1, "", "with_callable_args"]], "torch.quantization.observer.PerChannelMinMaxObserver": [[1553, 3, 1, "", "reset_min_max_vals"]], "torch.quantization.qconfig": [[1569, 1, 1, "", "QConfig"], [1570, 2, 1, "", "default_activation_only_qconfig"], [1571, 2, 1, "", "default_debug_qconfig"], [1572, 2, 1, "", "default_dynamic_qconfig"], [1573, 2, 1, "", "default_per_channel_qconfig"], [1574, 2, 1, "", "default_qat_qconfig"], [1575, 2, 1, "", "default_qat_qconfig_v2"], [1576, 2, 1, "", "default_qconfig"], [1577, 2, 1, "", "default_weight_only_qconfig"], [1578, 2, 1, "", "float16_dynamic_qconfig"], [1579, 2, 1, "", "float16_static_qconfig"], [1580, 2, 1, "", "float_qparams_weight_only_qconfig"], [1581, 2, 1, "", "per_channel_dynamic_qconfig"]], "torch.quantization.quantize_fx": [[1584, 1, 1, "", "convert_fx"], [1585, 1, 1, "", "fuse_fx"], [1586, 1, 1, "", "prepare_fx"], [1587, 1, 1, "", "prepare_qat_fx"]], "torch.quasirandom": [[1595, 1, 1, "", "SobolEngine"]], "torch.quasirandom.SobolEngine": [[1595, 3, 1, "", "draw"], [1595, 3, 1, "", "draw_base2"], [1595, 3, 1, "", "fast_forward"], [1595, 3, 1, "", "reset"]], "torch.random": [[1788, 5, 1, "", "fork_rng"], [1788, 5, 1, "", "get_rng_state"], [1788, 5, 1, "", "initial_seed"], [1788, 5, 1, "", "manual_seed"], [1788, 5, 1, "", "seed"], [1788, 5, 1, "", "set_rng_state"]], "torch.signal": [[1792, 0, 0, "-", "windows"]], "torch.signal.windows": [[1643, 5, 1, "", "bartlett"], [1644, 5, 1, "", "blackman"], [1645, 5, 1, "", "cosine"], [1646, 5, 1, "", "exponential"], [1647, 5, 1, "", "gaussian"], [1648, 5, 1, "", "general_cosine"], [1649, 5, 1, "", "general_hamming"], [1650, 5, 1, "", "hamming"], [1651, 5, 1, "", "hann"], [1652, 5, 1, "", "kaiser"], [1653, 5, 1, "", "nuttall"]], "torch.sparse": [[1663, 5, 1, "", "addmm"], [1664, 5, 1, "", "log_softmax"], [1665, 5, 1, "", "mm"], [1666, 5, 1, "", "sampled_addmm"], [1667, 5, 1, "", "softmax"], [1668, 5, 1, "", "spdiags"], [1669, 5, 1, "", "sum"]], "torch.special": [[1794, 5, 1, "", "airy_ai"], [1794, 5, 1, "", "bessel_j0"], [1794, 5, 1, "", "bessel_j1"], [1794, 5, 1, "", "digamma"], [1794, 5, 1, "", "entr"], [1794, 5, 1, "", "erf"], [1794, 5, 1, "", "erfc"], [1794, 5, 1, "", "erfcx"], [1794, 5, 1, "", "erfinv"], [1794, 5, 1, "", "exp2"], [1794, 5, 1, "", "expit"], [1794, 5, 1, "", "expm1"], [1794, 5, 1, "", "gammainc"], [1794, 5, 1, "", "gammaincc"], [1794, 5, 1, "", "gammaln"], [1794, 5, 1, "", "i0"], [1794, 5, 1, "", "i0e"], [1794, 5, 1, "", "i1"], [1794, 5, 1, "", "i1e"], [1794, 5, 1, "", "log1p"], [1794, 5, 1, "", "log_ndtr"], [1794, 5, 1, "", "log_softmax"], [1794, 5, 1, "", "logit"], [1794, 5, 1, "", "logsumexp"], [1794, 5, 1, "", "multigammaln"], [1794, 5, 1, "", "ndtr"], [1794, 5, 1, "", "ndtri"], [1794, 5, 1, "", "polygamma"], [1794, 5, 1, "", "psi"], [1794, 5, 1, "", "round"], [1794, 5, 1, "", "scaled_modified_bessel_k0"], [1794, 5, 1, "", "scaled_modified_bessel_k1"], [1794, 5, 1, "", "sinc"], [1794, 5, 1, "", "softmax"], [1794, 5, 1, "", "spherical_bessel_j0"], [1794, 5, 1, "", "xlog1py"], [1794, 5, 1, "", "xlogy"], [1794, 5, 1, "", "zeta"]], "torch.testing": [[1800, 5, 1, "", "assert_allclose"], [1800, 5, 1, "", "assert_close"], [1800, 5, 1, "", "make_tensor"]], "torch.torch": [[1801, 2, 1, "", "default_generator"], [1805, 1, 1, "", "finfo"], [1805, 1, 1, "", "iinfo"]], "torch.utils": [[1801, 0, 0, "-", "backcompat"], [4, 0, 0, "-", "benchmark"], [5, 0, 0, "-", "bottleneck"], [20, 0, 0, "-", "data"], [1801, 0, 0, "-", "hipify"], [1744, 0, 0, "-", "jit"], [1801, 0, 0, "-", "model_dump"], [1749, 0, 0, "-", "model_zoo"], [1798, 0, 0, "-", "tensorboard"]], "torch.utils.benchmark": [[4, 1, 1, "", "CallgrindStats"], [4, 1, 1, "", "FunctionCounts"], [4, 1, 1, "", "Measurement"], [4, 1, 1, "", "Timer"], [4, 0, 0, "-", "examples"], [4, 0, 0, "-", "op_fuzzers"], [4, 0, 0, "-", "utils"]], "torch.utils.benchmark.CallgrindStats": [[4, 3, 1, "", "as_standardized"], [4, 3, 1, "", "counts"], [4, 3, 1, "", "delta"], [4, 3, 1, "", "stats"]], "torch.utils.benchmark.FunctionCounts": [[4, 3, 1, "", "denoise"], [4, 3, 1, "", "filter"], [4, 3, 1, "", "transform"]], "torch.utils.benchmark.Measurement": [[4, 3, 1, "", "merge"], [4, 4, 1, "", "significant_figures"]], "torch.utils.benchmark.Timer": [[4, 3, 1, "", "blocked_autorange"], [4, 3, 1, "", "collect_callgrind"], [4, 3, 1, "", "timeit"]], "torch.utils.benchmark.utils": [[4, 0, 0, "-", "valgrind_wrapper"]], "torch.utils.checkpoint": [[6, 5, 1, "", "checkpoint"], [6, 5, 1, "", "checkpoint_sequential"]], "torch.utils.cpp_extension": [[14, 5, 1, "", "BuildExtension"], [14, 5, 1, "", "CUDAExtension"], [14, 5, 1, "", "CppExtension"], [14, 5, 1, "", "get_compiler_abi_compatibility_and_version"], [14, 5, 1, "", "include_paths"], [14, 5, 1, "", "is_ninja_available"], [14, 5, 1, "", "load"], [14, 5, 1, "", "load_inline"], [14, 5, 1, "", "verify_ninja_availability"]], "torch.utils.data": [[20, 1, 1, "", "BatchSampler"], [20, 1, 1, "", "ChainDataset"], [20, 1, 1, "", "ConcatDataset"], [20, 1, 1, "", "DataLoader"], [20, 1, 1, "", "Dataset"], [20, 1, 1, "", "IterableDataset"], [20, 1, 1, "", "RandomSampler"], [20, 1, 1, "", "Sampler"], [20, 1, 1, "", "SequentialSampler"], [20, 1, 1, "", "Subset"], [20, 1, 1, "", "SubsetRandomSampler"], [20, 1, 1, "", "TensorDataset"], [20, 1, 1, "", "WeightedRandomSampler"], [20, 0, 0, "-", "datapipes"], [20, 5, 1, "", "default_collate"], [20, 5, 1, "", "default_convert"], [20, 5, 1, "", "get_worker_info"], [20, 5, 1, "", "random_split"]], "torch.utils.data._utils.collate": [[20, 5, 1, "", "collate"]], "torch.utils.data.datapipes": [[20, 0, 0, "-", "dataframe"], [20, 0, 0, "-", "iter"], [20, 0, 0, "-", "map"], [20, 0, 0, "-", "utils"]], "torch.utils.data.distributed": [[20, 1, 1, "", "DistributedSampler"]], "torch.utils.dlpack": [[30, 5, 1, "", "from_dlpack"], [30, 5, 1, "", "to_dlpack"]], "torch.utils.mobile_optimizer": [[1748, 5, 1, "", "optimize_for_mobile"]], "torch.utils.model_zoo": [[1749, 5, 1, "", "load_url"]], "torch.utils.tensorboard.writer": [[1798, 1, 1, "", "SummaryWriter"]], "torch.utils.tensorboard.writer.SummaryWriter": [[1798, 3, 1, "", "__init__"], [1798, 3, 1, "", "add_audio"], [1798, 3, 1, "", "add_custom_scalars"], [1798, 3, 1, "", "add_embedding"], [1798, 3, 1, "", "add_figure"], [1798, 3, 1, "", "add_graph"], [1798, 3, 1, "", "add_histogram"], [1798, 3, 1, "", "add_hparams"], [1798, 3, 1, "", "add_image"], [1798, 3, 1, "", "add_images"], [1798, 3, 1, "", "add_mesh"], [1798, 3, 1, "", "add_pr_curve"], [1798, 3, 1, "", "add_scalar"], [1798, 3, 1, "", "add_scalars"], [1798, 3, 1, "", "add_text"], [1798, 3, 1, "", "add_video"], [1798, 3, 1, "", "close"], [1798, 3, 1, "", "flush"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:attribute", "3": "py:method", "4": "py:property", "5": "py:function", "6": "py:exception", "7": "std:envvar"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "attribute", "Python attribute"], "3": ["py", "method", "Python method"], "4": ["py", "property", "Python property"], "5": ["py", "function", "Python function"], "6": ["py", "exception", "Python exception"], "7": ["std", "envvar", "environment variable"]}, "titleterms": {"torch": [0, 1, 2, 3, 4, 5, 6, 11, 13, 14, 16, 20, 22, 23, 26, 29, 30, 49, 52, 54, 55, 57, 58, 59, 60, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 813, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 830, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1419, 1420, 1421, 1422, 1429, 1430, 1431, 1432, 1433, 1435, 1436, 1437, 1438, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1485, 1486, 1487, 1488, 1489, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1590, 1591, 1592, 1593, 1594, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1741, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1754, 1755, 1756, 1757, 1762, 1764, 1765, 1768, 1773, 1775, 1777, 1778, 1780, 1781, 1783, 1787, 1788, 1792, 1793, 1794, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805], "_dynamo": 0, "automat": [1, 2, 20, 1738, 1758, 1765], "mix": [1, 1738, 1758], "precis": [1, 1758, 1762, 1773], "packag": [1, 2, 15, 23, 1751, 1776, 1781], "amp": [1, 1762], "autocast": [1, 1758], "gradient": [1, 2, 58, 983, 1758, 1759, 1765, 1801], "scale": [1, 1758, 1769], "op": [1, 1743, 1758, 1777, 1801], "refer": [1, 17, 55, 60, 1738, 1740, 1741, 1742, 1750, 1753, 1768, 1778, 1781, 1783, 1784, 1787, 1791, 1799], "elig": 1, "cuda": [1, 3, 11, 16, 17, 37, 186, 813, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 830, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 1751, 1758, 1762, 1766, 1768, 1772, 1774, 1776], "specif": [1, 20, 1793], "behavior": [1, 20, 1767], "can": [1, 1759, 1766], "float16": 1, "float32": 1, "promot": [1, 8], "widest": 1, "input": [1, 1752, 1758, 1767], "type": [1, 20, 575, 1740, 1741, 1764, 1777, 1781, 1799, 1805], "prefer": 1, "binary_cross_entropy_with_logit": [1, 1320], "over": [1, 9, 1740], "binary_cross_entropi": [1, 1319], "cpu": [1, 11, 37, 183, 1759, 1761, 1784], "bfloat16": [1, 132], "differenti": [2, 1759], "autograd": [2, 11, 12, 15, 57, 737, 738, 739, 740, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 1753, 1758, 1759, 1764, 1765, 1777, 1789, 1790], "forward": [2, 738, 1764, 1790], "mode": [2, 49, 56, 389, 1135, 1759, 1764, 1767, 1777, 1784, 1790], "function": [2, 23, 29, 52, 54, 55, 58, 60, 62, 63, 737, 738, 739, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 962, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1738, 1739, 1740, 1741, 1743, 1746, 1747, 1752, 1754, 1755, 1756, 1758, 1759, 1765, 1767, 1777, 1787, 1793, 1794, 1804], "higher": 2, "level": [2, 11, 1787], "api": [2, 11, 15, 17, 26, 42, 55, 57, 60, 1736, 1738, 1741, 1750, 1753, 1761, 1762, 1764, 1768, 1769, 1778, 1781, 1782, 1783, 1784, 1787], "local": [2, 37, 1741, 1759, 1801], "disabl": [2, 20, 1738, 1759, 1801], "comput": [2, 58, 1759, 1773, 1790, 1801], "default": [2, 20, 21, 1740, 1759, 1762, 1767, 1786], "layout": [2, 1796], "manual": 2, "In": [2, 9, 1759, 1760, 1801], "place": [2, 57, 1752, 1759, 1760, 1777, 1801], "oper": [2, 11, 21, 23, 57, 64, 1740, 1741, 1746, 1747, 1752, 1753, 1754, 1759, 1764, 1769, 1776, 1777, 1779, 1784, 1793, 1799, 1801], "tensor": [2, 12, 15, 28, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 1700, 1739, 1743, 1746, 1751, 1752, 1753, 1754, 1759, 1764, 1775, 1777, 1784, 1787, 1793, 1796, 1797, 1799, 1801], "correct": [2, 60, 1759], "check": [2, 60, 1738, 1759, 1768], "variabl": [2, 23, 35, 49, 1738, 1740, 1741, 1762], "deprec": 2, "context": [2, 24, 46, 1790], "method": [2, 41, 42, 45, 50, 1739, 1740, 1743, 1777, 1787, 1793], "mixin": 2, "numer": [2, 1767, 1773, 1785], "profil": [2, 23, 38, 757, 758, 759, 760, 761, 1769, 1770, 1783], "anomali": 2, "detect": 2, "save": [2, 1040, 1620, 1735, 1759, 1769, 1775, 1784], "hook": [2, 21, 1759, 1770], "backend": [3, 23, 31, 34, 38, 48, 49, 1738, 1768, 1771, 1784, 1786, 1789], "cudnn": 3, "mp": [3, 11, 1771], "mkl": 3, "mkldnn": [3, 11], "openmp": 3, "opt_einsum": 3, "xeon": 3, "benchmark": [4, 1774], "util": [4, 5, 6, 11, 14, 20, 23, 30, 55, 883, 1429, 1430, 1431, 1432, 1433, 1435, 1436, 1437, 1438, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1744, 1748, 1749, 1755, 1787, 1798, 1801, 1803], "bottleneck": 5, "checkpoint": [6, 21, 25], "pytorch": [7, 8, 9, 10, 11, 15, 22, 23, 34, 57, 1736, 1738, 1739, 1743, 1759, 1762, 1764, 1774, 1775, 1777, 1782], "govern": [7, 10, 11], "build": [7, 8, 11, 1761, 1769, 1770, 1776], "ci": [7, 11], "how": [7, 21, 33, 56, 1735, 1759, 1764, 1780, 1781], "add": [7, 10, 74, 601], "new": [7, 8, 10], "maintain": [7, 10, 11], "contribut": [8, 1777], "guid": 8, "process": [8, 10, 20, 46, 1758], "get": [8, 26, 33, 34, 1777], "start": [8, 26, 34, 46], "propos": 8, "featur": [8, 1769, 1770], "report": [8, 1766], "issu": [8, 38, 1738], "implement": [8, 39, 48, 50, 1735, 1763, 1767, 1777, 1785, 1791], "fix": [8, 49, 56, 237, 943], "bug": 8, "ad": [8, 1764, 1777], "tutori": [8, 11, 1781, 1782, 1789], "improv": [8, 1770], "document": [8, 26, 1736], "particip": 8, "onlin": 8, "discuss": 8, "submit": 8, "pull": 8, "request": 8, "open": 8, "review": 8, "code": [8, 33, 34, 60, 1738, 1762, 1781], "readabl": 8, "test": [8, 1741, 1764, 1781, 1800], "case": [8, 1738], "make": [8, 10, 35], "codebas": 8, "more": [8, 54, 1789], "robust": 8, "triag": 8, "about": [8, 1759, 1789], "sourc": [8, 37, 1774, 1776, 1781], "develop": [8, 1736, 1777], "common": [8, 23, 60, 1769, 1784], "mistak": 8, "To": 8, "avoid": [8, 1772, 1774, 1777, 1781], "frequent": [8, 33, 1738, 1766, 1777, 1784], "ask": [8, 33, 1738, 1766, 1777, 1784], "question": [8, 33, 1738, 1766, 1777, 1784], "On": [8, 21, 1740], "python": [8, 9, 35, 57, 1736, 1738, 1739, 1740, 1741, 1742, 1743, 1774, 1777], "doc": [8, 11, 1768], "c": [8, 11, 15, 1759, 1764, 1768, 1775, 1777], "overview": [8, 17, 35, 36, 60, 1778, 1781, 1783, 1793], "design": [9, 1741, 1763, 1789, 1790, 1791], "philosophi": 9, "principl": [9, 10], "1": [9, 49, 56, 1738, 1765], "usabl": 9, "perform": [9, 11, 38, 1770, 1775], "2": [9, 56, 1738, 1762, 1765, 1766], "simpl": [9, 1740, 1741, 1770, 1790], "easi": 9, "3": [9, 49, 56], "first": [9, 1781], "best": [9, 1762, 1772, 1784], "class": [9, 41, 60, 1738, 1740, 1741, 1743, 1777, 1780, 1781, 1799], "languag": [9, 1736, 1738, 1740, 1741, 1742], "interoper": 9, "mechan": [10, 1759, 1767], "summari": [10, 35, 1784], "modul": [10, 11, 55, 60, 1250, 1419, 1420, 1421, 1422, 1738, 1739, 1740, 1741, 1743, 1755, 1759, 1764, 1770, 1775, 1781, 1784], "core": [10, 11], "lead": [10, 11], "bdfl": [10, 11], "nomin": [10, 1741], "confirm": 10, "remov": [10, 1455, 1752], "The": [10, 60, 1741], "re": [10, 1781], "scope": 10, "project": 10, "decis": 10, "uncontroversi": 10, "chang": [10, 33, 49, 56], "controversi": 10, "gener": [10, 16, 24, 57, 60, 65, 1760, 1765, 1774, 1784, 1785, 1801], "polici": 10, "faq": [10, 1776], "respons": 11, "nn": [11, 55, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1419, 1420, 1421, 1422, 1429, 1430, 1431, 1432, 1433, 1435, 1436, 1437, 1438, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1740, 1741, 1755, 1756, 1757, 1759, 1762, 1764, 1775, 1787], "optim": [11, 27, 34, 1485, 1486, 1487, 1488, 1489, 1758, 1759, 1780, 1789, 1790, 1801], "compil": [11, 33, 38, 795, 1762], "jit": [11, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1045, 1046, 1047, 1048, 1738, 1741, 1744], "torchscript": [11, 15, 1738, 1739, 1740, 1741, 1743, 1761, 1769, 1779, 1781], "fx": [11, 60, 1770, 1784, 1787, 1803], "torchdynamo": [11, 32, 33, 36, 37, 38, 1763], "distribut": [11, 23, 25, 26, 27, 29, 33, 49, 1755, 1756, 1763, 1768, 1770, 1789, 1790], "rng": 11, "multiprocess": [11, 46, 1751, 1762, 1772, 1776], "dataload": [11, 1774], "linear": [11, 12, 648, 649, 670, 678, 695, 1237, 1364, 1755, 1756, 1773, 1793], "algebra": [11, 12, 1773, 1793], "linalg": [11, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1746, 1773], "spars": [11, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1755, 1756, 1793], "nestedtensor": 11, "nest": [11, 1754], "maskedtensor": [11, 1747], "mask": [11, 1747], "fast": [11, 52, 1767, 1790], "fourier": [11, 52], "transform": [11, 29, 52, 54, 55, 58, 60, 1293, 1755, 1764, 1770], "fft": [11, 52, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942], "simd": 11, "nvidia": [11, 16, 1773], "nvfuser": 11, "intel": [11, 1783], "amd": [11, 1773], "rocm": [11, 1768], "hip": [11, 1768], "tool": [11, 16, 1785, 1793], "c10": 11, "dispatch": 11, "onnx": [11, 61, 1777, 1778, 1779], "export": [11, 33, 1777, 1781], "mobil": 11, "edg": [11, 1738, 1781], "model": [11, 15, 1735, 1758, 1766, 1769, 1780, 1781, 1782, 1784, 1787], "compress": [11, 1793], "window": [11, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1776, 1792], "appl": 11, "m1": 11, "powerpc": 11, "librari": [11, 1736, 1745, 1774], "xla": 11, "torchserv": 11, "torchvis": [11, 56], "torchtext": 11, "torchaudio": 11, "torchrec": 11, "torchx": 11, "torchdata": 11, "torcharrow": 11, "complex": [12, 797, 1759, 1767], "number": [12, 16, 49, 1759, 1761, 1766, 1774], "creat": [12, 1738, 1753], "transit": [12, 49], "from": [12, 37, 49, 60, 1735, 1752, 1776, 1777, 1781], "old": 12, "represent": 12, "access": [12, 38, 1740, 1781], "real": [12, 456, 1606, 1767], "imag": [12, 287, 1000], "angl": [12, 94, 614], "ab": [12, 66, 597], "serial": [12, 1775, 1801], "__config__": 13, "cpp_extens": 14, "extend": [15, 39, 1764, 1765], "extens": [15, 16, 1764, 1769, 1776], "author": [15, 60], "random": [16, 20, 57, 1766, 1774, 1788, 1801], "commun": [16, 21, 23, 1736], "collect": [16, 23], "stream": [16, 17, 814, 881, 1762], "event": [16, 40, 42, 811], "graph": [16, 33, 38, 60, 842, 1738, 1759, 1762, 1784], "beta": [16, 29], "memori": [16, 20, 1762, 1766, 1768, 1770], "manag": [16, 24, 1751, 1762, 1768, 1781], "nvtx": [16, 867, 868, 869], "jiter": [16, 850, 851], "sanit": [16, 17], "prototyp": [16, 1784, 1785], "usag": [17, 26, 49, 1762, 1765, 1769, 1770, 1776], "data": [20, 57, 1741, 1763, 1766, 1777, 1785, 1799], "dataset": 20, "map": [20, 1768], "style": 20, "iter": [20, 1740], "load": [20, 1037, 1101, 1735, 1775, 1781, 1784], "order": 20, "sampler": 20, "batch": [20, 56, 1773, 1780], "non": [20, 60, 1755, 1756, 1759, 1762, 1773, 1781, 1784], "work": [20, 55, 1758, 1766, 1793], "collate_fn": 20, "singl": [20, 49, 1758], "multi": [20, 23, 49, 1755, 1756], "platform": 20, "pin": [20, 1762], "ddp": 21, "us": [21, 23, 60, 1740, 1759, 1762, 1764, 1767, 1777, 1780, 1781, 1782, 1784, 1793], "what": [21, 32, 54, 56, 58, 1747, 1759, 1781], "doe": [21, 1759], "powersgd": 21, "state": [21, 1770, 1781], "debug": [21, 23, 31, 38, 60, 1738, 1784, 1785], "acknowledg": [21, 1782], "deploi": 22, "ha": 22, "been": 22, "move": 22, "multipi": 22, "come": [23, 1759], "which": 23, "environ": [23, 49, 1762, 1769, 1781], "choos": 23, "network": [23, 1762, 1766, 1770], "interfac": [23, 1768], "other": [23, 1755, 1774, 1781, 1793, 1801], "nccl": [23, 1762], "basic": [23, 1741, 1753, 1765, 1789, 1799], "initi": [23, 1755, 1770, 1799], "tcp": 23, "share": [23, 1751, 1762, 1781, 1791], "file": [23, 38, 1751, 1781], "system": [23, 1741, 1751, 1765], "post": [23, 1784], "kei": [23, 1776], "valu": [23, 586, 1740, 1741, 1773, 1786, 1791], "store": [23, 48], "group": 23, "point": [23, 1769], "synchron": [23, 882], "asynchron": [23, 1741, 1762, 1772], "gpu": [23, 37, 1755, 1756, 1758, 1766, 1782], "third": 23, "parti": 23, "launch": [23, 49], "spawn": [23, 1751], "applic": 23, "monitor": [23, 1750], "barrier": 23, "torch_distributed_debug": 23, "log": [23, 344, 1103, 1769], "join": [24, 1801], "elast": [26, 39, 49], "advanc": [26, 1770], "plugin": 26, "parallel": [28, 1411, 1762, 1763, 1766, 1782, 1801], "probabl": 29, "score": 29, "pathwis": 29, "deriv": [29, 1759], "exponentialfamili": 29, "bernoulli": [29, 130, 765], "binomi": 29, "categor": 29, "cauchi": 29, "chi2": 29, "continuousbernoulli": 29, "dirichlet": 29, "exponenti": [29, 1646], "fishersnedecor": 29, "gamma": 29, "geometr": 29, "gumbel": 29, "halfcauchi": 29, "halfnorm": 29, "independ": 29, "kumaraswami": 29, "lkjcholeski": 29, "laplac": 29, "lognorm": 29, "lowrankmultivariatenorm": 29, "mixturesamefamili": 29, "multinomi": [29, 395, 1140], "multivariatenorm": 29, "negativebinomi": 29, "normal": [29, 1383, 1471, 1755, 1780], "onehotcategor": 29, "pareto": 29, "poisson": [29, 1516], "relaxedbernoulli": 29, "logitrelaxedbernoulli": 29, "relaxedonehotcategor": 29, "studentt": 29, "transformeddistribut": 29, "uniform": 29, "vonmis": 29, "weibul": 29, "wishart": 29, "kl": 29, "diverg": [29, 1743], "constraint": [29, 1762], "registri": [29, 48], "dlpack": 30, "custom": [31, 40, 50, 60, 62, 1741, 1758, 1762, 1764, 1765, 1770, 1777, 1780, 1781, 1784], "speedi": 31, "compos": [31, 54, 58], "deeper": 32, "dive": 32, "guard": [32, 35], "dynamo": [32, 33], "do": [32, 33, 34, 1781], "you": [33, 34], "support": [33, 64, 1739, 1741, 1747, 1752, 1753, 1754, 1765, 1777, 1779, 1784, 1793], "i": [33, 1759, 1781], "still": 33, "need": [33, 34, 1758], "whole": [33, 1762], "why": [33, 34, 54, 58, 1762, 1767, 1781, 1793], "my": [33, 1735, 1759, 1766, 1781], "crash": 33, "error": [33, 38, 41, 1766, 1776, 1784, 1785], "torchinductor": [33, 38], "slow": 33, "inductor": 33, "excess": [33, 38], "recompil": [33, 38], "ar": [33, 54, 58, 1735, 1759, 1781], "product": [33, 58, 1746], "speed": [33, 1776], "up": [33, 49], "am": 33, "see": [33, 1781], "speedup": 33, "break": [33, 38, 1740, 1741], "identifi": [33, 38, 1741], "caus": [33, 38], "didn": 33, "t": [33, 542, 1695, 1741, 1766], "when": [33, 1741, 1764, 1777, 1784, 1793], "incorrect": 33, "result": 33, "oom": 33, "exist": 34, "anoth": [34, 1765], "wai": 34, "cach": [35, 1435, 1735, 1762, 1768], "frame": 35, "evalu": [35, 1759, 1767], "pep": 35, "523": 35, "instructiontransl": 35, "instal": [37, 1776], "requir": 37, "verifi": 37, "docker": 37, "troubleshoot": 38, "titl": 38, "diagnos": 38, "runtim": [38, 1761, 1766], "minifi": 38, "trace": [38, 60, 563, 1045, 1705, 1738, 1777, 1783, 1784], "accuraci": [38, 1773, 1784, 1785], "an": [38, 1735, 1777, 1780, 1781], "agent": 39, "server": [39, 48, 50], "concept": 39, "watchdog": 39, "launcher": 40, "rendezv": [40, 48, 49], "handler": [40, 45, 48, 1766], "metric": [40, 45], "propag": [41, 1753], "object": [42, 1781], "exampl": [43, 60, 1758, 1763, 1764, 1765, 1777, 1790], "torchelast": 44, "kubernet": 44, "multipl": [46, 1758, 1762, 1764, 1782], "worker": [46, 49, 1766], "quickstart": 47, "except": [48, 1766], "dynam": [48, 57, 60, 1784, 1787], "c10d": 48, "etcd": 48, "legaci": 48, "torchrun": 49, "node": [49, 61, 1759], "stack": [49, 1681, 1784], "fault": 49, "toler": 49, "size": [49, 508, 1754], "failur": 49, "min": [49, 386, 1132], "max": [49, 382, 1127], "4": [49, 56], "membership": [49, 1741], "note": [49, 1736, 1741, 1762, 1784, 1789], "definit": [49, 1741], "deploy": [49, 1769], "import": [49, 1735, 1776, 1781], "notic": [49, 1735], "expir": 50, "timer": 50, "client": 50, "write": [50, 60, 1759, 1764, 1777], "train": [51, 1758, 1770, 1772, 1784], "script": [51, 1041, 1738, 1776, 1777], "helper": 52, "fullyshardeddataparallel": 53, "func": [54, 55, 58, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 1764, 1765], "read": [54, 1777], "patch": [56, 1781], "norm": [56, 426, 1086, 1470], "s": [56, 1781], "happen": 56, "option": [56, 1740, 1761, 1776, 1780], "batchnorm": 56, "paramet": [56, 1424, 1740, 1780], "functorch": 56, "eval": [56, 1759], "ux": 57, "limit": [57, 60, 1735, 1765, 1777], "vmap": [57, 58, 971, 1728, 1764, 1765], "mutat": [57, 1801], "arbitrari": [57, 1781], "structur": [57, 1741], "out": [57, 1752, 1766], "depend": [57, 1781, 1790], "control": [57, 60, 1774], "flow": [57, 60, 1784], "item": [57, 328], "shape": [57, 61, 1777], "nonzero": [57, 425, 1469], "friend": 57, "whirlwind": 58, "tour": 58, "grad": [58, 266, 754, 963, 1759, 1762], "auto": 58, "vector": 58, "vjp": [58, 753, 970], "jacobian": [58, 750], "jvp": [58, 739, 751, 968, 1765], "jacrev": [58, 967], "jacfwd": [58, 966], "hessian": [58, 748, 965], "futur": 59, "A": [60, 1770], "quick": 60, "primer": 60, "manipul": [60, 1753], "direct": 60, "subgraph": 60, "rewrit": 60, "With": [60, 1743], "replace_pattern": 60, "proxi": 60, "retrac": 60, "interpret": [60, 1738], "pattern": [60, 1740, 1777, 1781], "introduct": [60, 1747, 1754, 1784], "pitfal": [60, 1777], "pdb": 60, "print": [60, 1740, 1741], "to_fold": 60, "graphmodul": 60, "avail": 60, "debugg": 60, "symbol": [60, 62, 63, 1777, 1784], "static": [60, 1777, 1784], "tracer": [60, 1738], "leaf": 60, "miscellanea": 60, "poe0001": 61, "miss": [61, 62, 63], "infer": [61, 1753, 1759, 1761, 1775], "poe0002": 62, "poe0003": 63, "standard": 63, "poe0004": 64, "newer": 64, "opset": 64, "version": [64, 1775], "abs_": 67, "absolut": [68, 598], "absolute_": 69, "aco": [70, 599], "acos_": 71, "acosh": [72, 600], "acosh_": 73, "add_": 75, "addbmm": [76, 602], "addbmm_": 77, "addcdiv": [78, 603], "addcdiv_": 79, "addcmul": [80, 604], "addcmul_": 81, "addmm": [82, 605, 1663], "addmm_": 83, "addmv": [84, 606], "addmv_": 85, "addr": [86, 607], "addr_": 87, "adjoint": [88, 608], "all": [89, 609, 1777, 1780], "allclos": [90, 610], "amax": [91, 611], "amin": [92, 612], "aminmax": [93, 613], "ani": [95, 615, 1741], "apply_": 96, "arcco": [97, 714], "arccos_": 98, "arccosh": [99, 715], "arccosh_": 100, "arcsin": [101, 716], "arcsin_": 102, "arcsinh": [103, 717], "arcsinh_": 104, "arctan": [105, 718], "arctan2": [106, 719], "arctan2_": 107, "arctan_": 108, "arctanh": [109, 720], "arctanh_": 110, "argmax": [111, 722], "argmin": [112, 723], "argsort": [113, 724], "argwher": [114, 725], "as_strid": [115, 726], "as_subclass": 116, "asin": [117, 729], "asin_": 118, "asinh": [119, 730], "asinh_": 120, "atan": [121, 731], "atan2": [122, 732], "atan2_": 123, "atan_": 124, "atanh": [125, 733], "atanh_": 126, "backward": [127, 737, 740, 1760, 1762, 1767, 1790], "baddbmm": [128, 763], "baddbmm_": 129, "bernoulli_": 131, "bincount": [133, 766], "bitwise_and": [134, 767], "bitwise_and_": 135, "bitwise_left_shift": [136, 768], "bitwise_left_shift_": 137, "bitwise_not": [138, 769], "bitwise_not_": 139, "bitwise_or": [140, 770], "bitwise_or_": 141, "bitwise_right_shift": [142, 771], "bitwise_right_shift_": 143, "bitwise_xor": [144, 772], "bitwise_xor_": 145, "bmm": [146, 775], "bool": 147, "broadcast_to": [148, 778], "byte": 149, "cauchy_": 150, "ccol_indic": 151, "cdoubl": 152, "ceil": [153, 784], "ceil_": 154, "cfloat": 155, "chalf": 156, "char": 157, "choleski": [158, 786, 1059], "cholesky_invers": [159, 787], "cholesky_solv": [160, 788], "chunk": [161, 789], "clamp": [162, 685, 790], "clamp_": 163, "clip": [164, 791, 1758], "clip_": 165, "clone": [166, 792], "coalesc": 167, "col_indic": 168, "conj": [169, 800], "conj_phys": [170, 801], "conj_physical_": 171, "contigu": 172, "copy_": 173, "copysign": [174, 802], "copysign_": 175, "corrcoef": [176, 803], "co": [177, 804], "cos_": 178, "cosh": [179, 805], "cosh_": 180, "count_nonzero": [181, 806], "cov": [182, 807], "cross": [184, 808, 1062, 1759], "crow_indic": 185, "cummax": [187, 884], "cummin": [188, 885], "cumprod": [189, 886], "cumprod_": 190, "cumsum": [191, 887], "cumsum_": 192, "data_ptr": 193, "deg2rad": [194, 889], "dense_dim": 195, "dequant": [196, 890, 1784], "det": [197, 891, 1063], "detach": 198, "detach_": 199, "devic": [200, 829, 1762, 1773, 1796], "diag": [201, 892], "diag_emb": [202, 893], "diagflat": [203, 894], "diagon": [204, 895, 1064], "diagonal_scatt": [205, 896], "diff": [206, 897], "digamma": [207, 898], "digamma_": 208, "dim": [209, 1752], "dist": [210, 899], "div": [211, 900, 1775], "div_": 212, "divid": [213, 901], "divide_": 214, "dot": [215, 902], "doubl": 216, "dsplit": [217, 903], "element_s": 218, "eq": [219, 910], "eq_": 220, "equal": [221, 911], "erf": [222, 912], "erf_": 223, "erfc": [224, 913], "erfc_": 225, "erfinv": [226, 914], "erfinv_": 227, "exp": [228, 915], "exp_": 229, "expand": 230, "expand_a": 231, "expm1": [232, 917], "expm1_": 233, "exponential_": 234, "fill_": 235, "fill_diagonal_": 236, "fix_": 238, "flatten": [239, 944, 1196], "flip": [240, 945], "fliplr": [241, 946], "flipud": [242, 947], "float": [243, 1775], "float_pow": [244, 948], "float_power_": 245, "floor": [246, 949], "floor_": 247, "floor_divid": [248, 950], "floor_divide_": 249, "fmax": [250, 951], "fmin": [251, 952], "fmod": [252, 953], "fmod_": 253, "frac": [254, 954], "frac_": 255, "frexp": [256, 955], "gather": [257, 822, 972], "gcd": [258, 973], "gcd_": 259, "ge": [260, 974], "ge_": 261, "geometric_": 262, "geqrf": [263, 975], "ger": [264, 976], "get_devic": 265, "greater": [267, 984], "greater_": 268, "greater_equ": [269, 985], "greater_equal_": 270, "gt": [271, 986], "gt_": 272, "half": 273, "hardshrink": [274, 1206, 1350], "heavisid": [275, 989], "histc": [276, 990], "histogram": [277, 991], "hsplit": [278, 993], "hypot": [279, 996], "hypot_": 280, "i0": [281, 997], "i0_": 282, "igamma": [283, 998], "igamma_": 284, "igammac": [285, 999], "igammac_": 286, "index_add": [288, 1001], "index_add_": 289, "index_copi": [290, 1002], "index_copy_": 291, "index_fil": 292, "index_fill_": 293, "index_put": 294, "index_put_": 295, "index_reduc": [296, 1003], "index_reduce_": 297, "index_select": [298, 1004], "indic": [299, 1736], "inner": [300, 1007], "int": 301, "int_repr": 302, "invers": [303, 1008, 1746], "is_coalesc": 304, "is_complex": [305, 1009], "is_conj": [306, 1010], "is_contigu": 307, "is_cuda": 308, "is_floating_point": [309, 1012], "is_infer": 310, "is_leaf": 311, "is_meta": 312, "is_pin": 313, "is_quant": 314, "is_set_to": 315, "is_shar": 316, "is_sign": 317, "is_spars": 318, "is_sparse_csr": 319, "isclos": [320, 1019], "isfinit": [321, 1020], "isinf": [322, 1022], "isnan": [323, 1023], "isneginf": [324, 1024], "isposinf": [325, 1025], "isreal": [326, 1026], "istft": [327, 1027], "kthvalu": [329, 1051], "lcm": [330, 1052], "lcm_": 331, "ldexp": [332, 1053], "ldexp_": 333, "le": [334, 1054], "le_": 335, "lerp": [336, 1055], "lerp_": 337, "less": [338, 1056], "less_": 339, "less_equ": [340, 1057], "less_equal_": 341, "lgamma": [342, 1058], "lgamma_": 343, "log10": [345, 1104], "log10_": 346, "log1p": [347, 1105], "log1p_": 348, "log2": [349, 1106], "log2_": 350, "log_": 351, "log_normal_": 352, "logaddexp": [353, 1107], "logaddexp2": [354, 1108], "logcumsumexp": [355, 1109], "logdet": [356, 1110], "logical_and": [357, 1111], "logical_and_": 358, "logical_not": [359, 1112], "logical_not_": 360, "logical_or": [361, 1113], "logical_or_": 362, "logical_xor": [363, 1114], "logical_xor_": 364, "logit": [365, 1115], "logit_": 366, "logsumexp": [367, 1117], "long": 368, "lt": [369, 1118], "lt_": 370, "lu": [371, 1076, 1119], "lu_solv": [372, 1079, 1120], "map_": 373, "masked_fil": 374, "masked_fill_": 375, "masked_scatt": 376, "masked_scatter_": 377, "masked_select": [378, 1123], "matmul": [379, 1080, 1124], "matrix_exp": [380, 1081, 1125], "matrix_pow": [381, 1083, 1126], "maximum": [383, 1128], "mean": [384, 1129], "median": [385, 1130], "minimum": [387, 1133], "mm": [388, 1134, 1665], "moveaxi": [390, 1136], "movedim": [391, 1137], "msort": [392, 1138], "mul": [393, 1139], "mul_": 394, "multipli": [396, 1141], "multiply_": 397, "mv": [398, 1142], "mvlgamma": [399, 1143], "mvlgamma_": 400, "nan_to_num": [401, 1144], "nan_to_num_": 402, "nanmean": [403, 1145], "nanmedian": [404, 1146], "nanquantil": [405, 1147], "nansum": [406, 1148], "narrow": [407, 1149], "narrow_copi": [408, 1150], "ndim": 409, "ndimens": 410, "ne": [411, 1151], "ne_": 412, "neg": [413, 415, 1152, 1153], "neg_": 414, "negative_": 416, "nelement": 417, "new_empti": 418, "new_ful": 419, "new_on": 420, "new_tensor": 421, "new_zero": 422, "nextaft": [423, 1154], "nextafter_": 424, "normal_": 427, "not_equ": [428, 1472], "not_equal_": 429, "numel": [430, 1473], "numpi": [431, 1777], "orgqr": [432, 1510], "ormqr": [433, 1511], "outer": [434, 1512], "permut": [435, 1514, 1752], "pin_memori": 436, "pinvers": [437, 1515], "polygamma": [438, 1518], "polygamma_": 439, "posit": [440, 1519], "pow": [441, 1520], "pow_": 442, "prod": [443, 1521], "put_": 444, "q_per_channel_axi": 445, "q_per_channel_scal": 446, "q_per_channel_zero_point": 447, "q_scale": 448, "q_zero_point": 449, "qr": [450, 1088, 1523], "qscheme": 451, "quantil": [452, 1524], "rad2deg": [453, 1596], "random_": 454, "ravel": [455, 1605], "reciproc": [457, 1607], "reciprocal_": 458, "record_stream": 459, "register_hook": 460, "remaind": [461, 1608], "remainder_": 462, "renorm": [463, 1609], "renorm_": 464, "repeat": 465, "repeat_interleav": [466, 1610], "requires_grad": [467, 1759], "requires_grad_": 468, "reshap": [469, 1611], "reshape_a": 470, "resize_": 471, "resize_as_": 472, "resolve_conj": [473, 1612], "resolve_neg": [474, 1613], "retain_grad": 475, "retains_grad": 476, "roll": [477, 1615], "rot90": [478, 1616], "round": [479, 1617], "round_": 480, "row_indic": 481, "rsqrt": [482, 1619], "rsqrt_": 483, "scatter": [484, 824, 1621], "scatter_": 485, "scatter_add": [486, 1622], "scatter_add_": 487, "scatter_reduc": [488, 1623], "scatter_reduce_": 489, "select": [490, 1626, 1747], "select_scatt": [491, 1627], "set_": 492, "sgn": [493, 1640], "sgn_": 494, "share_memory_": 495, "short": 496, "sigmoid": [497, 673, 1280, 1398, 1641], "sigmoid_": 498, "sign": [499, 1642], "sign_": 500, "signbit": [501, 1654], "sin": [502, 1655], "sin_": 503, "sinc": [504, 1656], "sinc_": 505, "sinh": [506, 1657], "sinh_": 507, "slice_scatt": [509, 1658], "slogdet": [510, 1089, 1659], "smm": [511, 1660], "softmax": [512, 1283, 1402, 1661, 1667], "sort": [513, 1662], "sparse_dim": 514, "sparse_mask": 515, "sparse_resize_": 516, "sparse_resize_and_clear_": 517, "split": [518, 1676], "sqrt": [519, 1677], "sqrt_": 520, "squar": [521, 1678], "square_": 522, "squeez": [523, 1679], "squeeze_": 524, "sspaddmm": [525, 1680], "std": [526, 1682], "stft": [527, 1684], "storag": [528, 1795], "storage_offset": 529, "storage_typ": 530, "stride": 531, "sub": [532, 1685], "sub_": 533, "subtract": [534, 1686], "subtract_": 535, "sum": [536, 1669, 1687, 1755], "sum_to_s": 537, "svd": [538, 1093, 1688], "swapax": [539, 1690], "swapdim": [540, 1691], "symeig": [541, 1694], "t_": 543, "take": [544, 1696, 1780], "take_along_dim": [545, 1697], "tan": [546, 1698], "tan_": 547, "tanh": [548, 1290, 1407, 1699], "tanh_": 549, "tensor_split": [550, 1701], "tile": [551, 1703], "to_dens": 553, "to_mkldnn": 554, "to_spars": 555, "to_sparse_bsc": 556, "to_sparse_bsr": 557, "to_sparse_coo": 558, "to_sparse_csc": 559, "to_sparse_csr": 560, "tolist": 561, "topk": [562, 1704], "transpos": [564, 1706], "transpose_": 565, "triangular_solv": [566, 1709], "tril": [567, 1710], "tril_": 568, "triu": [569, 1712], "triu_": 570, "true_divid": [571, 1714], "true_divide_": 572, "trunc": [573, 1715], "trunc_": 574, "type_a": 576, "unbind": [577, 1716, 1754], "unflatten": [578, 1300, 1717], "unfold": [579, 1301, 1414], "uniform_": 580, "uniqu": [581, 1718], "unique_consecut": [582, 1719], "unsqueez": [583, 1720], "unsqueeze_": 584, "untyped_storag": 585, "var": [587, 1723], "vdot": [588, 1725], "view": [589, 1747, 1775, 1797], "view_a": 590, "vsplit": [591, 1729], "where": [592, 1731, 1735], "xlogi": [593, 1732], "xlogy_": 594, "zero_": 595, "_assert": 596, "bnrelu2d": [616, 639], "bnrelu3d": [617, 640], "convbn1d": [618, 628], "convbn2d": [619, 629], "convbn3d": [620, 630], "convbnrelu1d": [621, 631], "convbnrelu2d": [622, 632], "convbnrelu3d": [623, 633], "convrelu1d": [624, 641], "convrelu2d": [625, 634, 642], "convrelu3d": [626, 635, 643], "linearrelu": [627, 636, 644, 645], "freeze_bn_stat": 637, "update_bn_stat": 638, "conv2d": [646, 653, 687, 1179, 1323], "conv3d": [647, 654, 688, 1180, 1324], "batchnorm2d": [650, 1169], "batchnorm3d": [651, 1170], "conv1d": [652, 686, 1178, 1322], "convtranspose1d": [655, 1181], "convtranspose2d": [656, 1182], "convtranspose3d": [657, 1183], "elu": [658, 689, 1192, 1336], "embed": [659, 1193, 1338], "embeddingbag": [660, 1194], "fxfloatfunct": 661, "floatfunct": 662, "groupnorm": [663, 1205], "hardswish": [664, 691, 1208, 1352], "instancenorm1d": [665, 1213], "instancenorm2d": [666, 1214], "instancenorm3d": [667, 1215], "layernorm": [668, 1222], "leakyrelu": [669, 1236], "qfunction": 671, "relu6": [672, 1270, 1393], "gru": [674, 1202], "grucel": [675, 1203], "lstm": [676, 1220, 1427, 1774], "lstmcell": [677, 1221], "rnncell": [679, 1267], "adaptive_avg_pool2d": [680, 1307], "adaptive_avg_pool3d": [681, 1308], "avg_pool2d": [682, 1315], "avg_pool3d": [683, 1316], "celu": [684, 1172, 1321], "hardsigmoid": [690, 1207, 1351], "hardtanh": [692, 1209, 1353], "interpol": [693, 1358], "leaky_relu": [694, 1362], "max_pool1d": [696, 1371], "max_pool2d": [697, 1372], "threshold": [698, 1292, 1409], "upsampl": [699, 1302, 1415], "upsample_bilinear": [700, 1416], "upsample_nearest": [701, 1417], "backendconfig": 702, "backendpatternconfig": 703, "dtypeconfig": 704, "observationtyp": 705, "convertcustomconfig": 706, "fusecustomconfig": 707, "preparecustomconfig": 708, "standalonemoduleconfigentri": 709, "qconfigmap": 710, "get_default_qat_qconfig_map": 711, "get_default_qconfig_map": 712, "arang": 713, "are_deterministic_algorithms_en": 721, "as_tensor": 727, "asarrai": 728, "atleast_1d": 734, "atleast_2d": 735, "atleast_3d": 736, "dual_level": 741, "forward_ad": [742, 743], "make_du": 742, "unpack_du": 743, "functionctx": [744, 745, 746, 747], "mark_dirti": 744, "mark_non_differenti": 745, "save_for_backward": 746, "set_materialize_grad": 747, "hvp": 749, "vhp": 752, "gradcheck": [755, 1767], "gradgradcheck": [756, 1767], "load_nvprof": 757, "export_chrome_trac": 758, "key_averag": 759, "self_cpu_time_tot": 760, "total_averag": 761, "set_multithreading_en": 762, "bartlett_window": 764, "blackman_window": 773, "block_diag": 774, "broadcast_shap": 776, "broadcast_tensor": 777, "bucket": 779, "can_cast": 780, "cartesian_prod": 781, "cat": 782, "cdist": 783, "chain_matmul": 785, "column_stack": 793, "combin": [794, 1764], "compiled_with_cxx11_abi": 796, "concat": 798, "concaten": 799, "cudagraph": 809, "cudapluggablealloc": 810, "externalstream": 812, "outofmemoryerror": 813, "streamcontext": 815, "caching_allocator_alloc": 816, "caching_allocator_delet": 817, "can_device_access_p": 818, "change_current_alloc": 819, "comm": [820, 821, 822, 823, 824], "broadcast": [820, 1760], "broadcast_coalesc": 821, "reduce_add": 823, "current_blas_handl": 825, "current_devic": 826, "current_stream": 827, "default_stream": 828, "device_count": 830, "device_of": 831, "empty_cach": 832, "get_allocator_backend": 833, "get_arch_list": 834, "get_device_cap": 835, "get_device_nam": 836, "get_device_properti": 837, "get_gencode_flag": 838, "get_rng_stat": [839, 982], "get_rng_state_al": 840, "get_sync_debug_mod": 841, "graph_pool_handl": 843, "init": [844, 1757], "initial_se": [845, 1006], "ipc_collect": 846, "is_avail": 847, "is_current_stream_captur": 848, "is_initi": 849, "_create_jit_fn": 850, "_create_multi_output_jit_fn": 851, "list_gpu_process": 852, "make_graphed_cal": 853, "manual_se": [854, 1122], "manual_seed_al": 855, "max_memory_alloc": 856, "max_memory_cach": 857, "max_memory_reserv": 858, "mem_get_info": 859, "memory_alloc": 860, "memory_cach": 861, "memory_reserv": 862, "memory_snapshot": 863, "memory_stat": 864, "memory_summari": 865, "memory_usag": 866, "mark": 867, "range_pop": 868, "range_push": 869, "reset_max_memory_alloc": 870, "reset_max_memory_cach": 871, "reset_peak_memory_stat": 872, "seed": [873, 1625], "seed_al": 874, "set_devic": 875, "set_per_process_memory_fract": 876, "set_rng_stat": [877, 1638], "set_rng_state_al": 878, "set_stream": 879, "set_sync_debug_mod": 880, "cumulative_trapezoid": 888, "dstack": 904, "einsum": 905, "empti": 906, "empty_lik": 907, "empty_strid": 908, "enable_grad": 909, "exp2": 916, "ey": 918, "fake_quantize_per_channel_affin": 919, "fake_quantize_per_tensor_affin": 920, "fft2": 922, "fftfreq": 923, "fftn": 924, "fftshift": 925, "hfft": 926, "hfft2": 927, "hfftn": 928, "ifft": 929, "ifft2": 930, "ifftn": 931, "ifftshift": 932, "ihfft": 933, "ihfft2": 934, "ihfftn": 935, "irfft": 936, "irfft2": 937, "irfftn": 938, "rfft": 939, "rfft2": 940, "rfftfreq": 941, "rfftn": 942, "from_dlpack": 956, "from_numpi": 957, "frombuff": 958, "full": [959, 1775], "full_lik": 960, "functional_cal": [961, 1465], "grad_and_valu": 964, "stack_module_st": 969, "get_default_dtyp": 977, "get_deterministic_debug_mod": 978, "get_float32_matmul_precis": 979, "get_num_interop_thread": 980, "get_num_thread": 981, "hamming_window": 987, "hann_window": 988, "histogramdd": 992, "hspmm": 994, "hstack": 995, "inference_mod": 1005, "is_deterministic_algorithms_warn_only_en": 1011, "is_grad_en": 1013, "is_inference_mode_en": 1014, "is_nonzero": 1015, "is_storag": 1016, "is_tensor": 1017, "is_warn_always_en": 1018, "isin": 1021, "attribut": [1028, 1738, 1740, 1741, 1743, 1796], "scriptfunct": 1029, "scriptmodul": [1030, 1775], "annot": [1031, 1741], "enable_onednn_fus": 1032, "fork": 1033, "freez": 1034, "ignor": 1035, "isinst": 1036, "onednn_fusion_en": 1038, "optimize_for_infer": 1039, "script_if_trac": 1042, "set_fusion_strategi": 1043, "strict_fus": 1044, "trace_modul": 1046, "unus": 1047, "wait": 1048, "kaiser_window": 1049, "kron": 1050, "cholesky_ex": 1060, "cond": 1061, "eig": 1065, "eigh": 1066, "eigval": 1067, "eigvalsh": 1068, "householder_product": 1069, "inv": 1070, "inv_ex": 1071, "ldl_factor": 1072, "ldl_factor_ex": 1073, "ldl_solv": 1074, "lstsq": 1075, "lu_factor": 1077, "lu_factor_ex": 1078, "matrix_norm": 1082, "matrix_rank": 1084, "multi_dot": 1085, "pinv": 1087, "solv": 1090, "solve_ex": 1091, "solve_triangular": 1092, "svdval": 1094, "tensorinv": 1095, "tensorsolv": 1096, "vander": [1097, 1722], "vecdot": 1098, "vector_norm": 1099, "linspac": 1100, "lobpcg": 1102, "logspac": 1116, "lu_unpack": 1121, "meshgrid": 1131, "adaptiveavgpool1d": 1155, "adaptiveavgpool2d": 1156, "adaptiveavgpool3d": 1157, "adaptivelogsoftmaxwithloss": 1158, "adaptivemaxpool1d": 1159, "adaptivemaxpool2d": 1160, "adaptivemaxpool3d": 1161, "alphadropout": 1162, "avgpool1d": 1163, "avgpool2d": 1164, "avgpool3d": 1165, "bceloss": 1166, "bcewithlogitsloss": 1167, "batchnorm1d": 1168, "bilinear": [1171, 1318], "ctcloss": 1173, "channelshuffl": 1174, "constantpad1d": 1175, "constantpad2d": 1176, "constantpad3d": 1177, "cosineembeddingloss": 1184, "cosinesimilar": 1185, "crossentropyloss": 1186, "dataparallel": [1187, 1755, 1756, 1758, 1762], "dropout": [1188, 1332, 1755, 1756], "dropout1d": [1189, 1333], "dropout2d": [1190, 1334], "dropout3d": [1191, 1335], "featurealphadropout": 1195, "fold": [1197, 1341], "fractionalmaxpool2d": 1198, "fractionalmaxpool3d": 1199, "gelu": [1200, 1345], "glu": [1201, 1346], "gaussiannllloss": 1204, "hingeembeddingloss": 1210, "huberloss": 1211, "ident": [1212, 1441, 1449, 1741, 1766], "kldivloss": 1216, "l1loss": 1217, "lppool1d": 1218, "lppool2d": 1219, "lazybatchnorm1d": 1223, "lazybatchnorm2d": 1224, "lazybatchnorm3d": 1225, "lazyconv1d": 1226, "lazyconv2d": 1227, "lazyconv3d": 1228, "lazyconvtranspose1d": 1229, "lazyconvtranspose2d": 1230, "lazyconvtranspose3d": 1231, "lazyinstancenorm1d": 1232, "lazyinstancenorm2d": 1233, "lazyinstancenorm3d": 1234, "lazylinear": 1235, "localresponsenorm": 1238, "logsigmoid": [1239, 1367], "logsoftmax": 1240, "mseloss": 1241, "marginrankingloss": 1242, "maxpool1d": 1243, "maxpool2d": 1244, "maxpool3d": 1245, "maxunpool1d": 1246, "maxunpool2d": 1247, "maxunpool3d": 1248, "mish": [1249, 1377], "moduledict": [1251, 1741], "modulelist": [1252, 1740, 1741], "multilabelmarginloss": 1253, "multilabelsoftmarginloss": 1254, "multimarginloss": 1255, "multiheadattent": [1256, 1428], "nllloss": 1257, "prelu": [1258, 1391], "pairwisedist": 1259, "parameterdict": 1260, "parameterlist": 1261, "pixelshuffl": 1262, "pixelunshuffl": 1263, "poissonnllloss": 1264, "rnn": [1265, 1459, 1460, 1461, 1462, 1774], "rnnbase": 1266, "rrelu": [1268, 1395], "relu": [1269, 1392], "reflectionpad1d": 1271, "reflectionpad2d": 1272, "reflectionpad3d": 1273, "replicationpad1d": 1274, "replicationpad2d": 1275, "replicationpad3d": 1276, "selu": [1277, 1397], "sequenti": 1278, "silu": [1279, 1399], "smoothl1loss": 1281, "softmarginloss": 1282, "softmax2d": 1284, "softmin": [1285, 1403], "softplu": [1286, 1404], "softshrink": [1287, 1405], "softsign": [1288, 1406], "syncbatchnorm": 1289, "tanhshrink": [1291, 1408], "transformerdecod": 1294, "transformerdecoderlay": 1295, "transformerencod": 1296, "transformerencoderlay": 1297, "tripletmarginloss": 1298, "tripletmarginwithdistanceloss": 1299, "upsamplingbilinear2d": 1303, "upsamplingnearest2d": 1304, "zeropad2d": 1305, "adaptive_avg_pool1d": 1306, "adaptive_max_pool1d": 1309, "adaptive_max_pool2d": 1310, "adaptive_max_pool3d": 1311, "affine_grid": 1312, "alpha_dropout": 1313, "avg_pool1d": 1314, "batch_norm": 1317, "conv_transpose1d": 1325, "conv_transpose2d": 1326, "conv_transpose3d": 1327, "cosine_embedding_loss": 1328, "cosine_similar": 1329, "cross_entropi": 1330, "ctc_loss": 1331, "elu_": 1337, "embedding_bag": 1339, "feature_alpha_dropout": 1340, "fractional_max_pool2d": 1342, "fractional_max_pool3d": 1343, "gaussian_nll_loss": 1344, "grid_sampl": 1347, "group_norm": 1348, "gumbel_softmax": 1349, "hardtanh_": 1354, "hinge_embedding_loss": 1355, "huber_loss": 1356, "instance_norm": 1357, "kl_div": 1359, "l1_loss": 1360, "layer_norm": 1361, "leaky_relu_": 1363, "local_response_norm": 1365, "log_softmax": [1366, 1664], "lp_pool1d": 1368, "lp_pool2d": 1369, "margin_ranking_loss": 1370, "max_pool3d": 1373, "max_unpool1d": 1374, "max_unpool2d": 1375, "max_unpool3d": 1376, "mse_loss": 1378, "multi_margin_loss": 1379, "multilabel_margin_loss": 1380, "multilabel_soft_margin_loss": 1381, "nll_loss": 1382, "one_hot": 1384, "pad": [1385, 1755], "pairwise_dist": 1386, "pdist": 1387, "pixel_shuffl": 1388, "pixel_unshuffl": 1389, "poisson_nll_loss": 1390, "relu_": 1394, "rrelu_": 1396, "smooth_l1_loss": 1400, "soft_margin_loss": 1401, "threshold_": 1410, "data_parallel": [1411, 1756], "triplet_margin_loss": 1412, "triplet_margin_with_distance_loss": 1413, "lazymodulemixin": 1418, "register_module_backward_hook": 1419, "register_module_forward_hook": 1420, "register_module_forward_pre_hook": 1421, "register_module_full_backward_hook": 1422, "distributeddataparallel": [1423, 1758, 1762, 1763], "uninitializedbuff": 1425, "uninitializedparamet": 1426, "clip_grad_norm_": 1429, "clip_grad_value_": 1430, "parameters_to_vector": 1431, "parametr": [1432, 1433, 1435, 1436, 1437, 1438, 1770], "orthogon": 1432, "spectral_norm": [1433, 1464], "parametrizationlist": 1434, "is_parametr": 1436, "register_parametr": 1437, "remove_parametr": 1438, "basepruningmethod": 1439, "customfrommask": 1440, "l1unstructur": 1442, "lnstructur": 1443, "pruningcontain": 1444, "randomstructur": 1445, "randomunstructur": 1446, "prune": [1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1770], "custom_from_mask": 1447, "global_unstructur": 1448, "is_prun": 1450, "l1_unstructur": 1451, "ln_structur": 1452, "random_structur": 1453, "random_unstructur": 1454, "remove_spectral_norm": 1456, "remove_weight_norm": 1457, "packedsequ": 1458, "pack_padded_sequ": 1459, "pack_sequ": 1460, "pad_packed_sequ": 1461, "pad_sequ": 1462, "skip_init": 1463, "stateless": 1465, "vector_to_paramet": 1466, "weight_norm": 1467, "no_grad": 1468, "ones": 1474, "ones_lik": 1475, "jitscalartyp": 1476, "asgd": 1477, "adadelta": 1478, "adagrad": 1479, "adam": 1480, "adamw": 1481, "adamax": 1482, "lbfg": 1483, "nadam": 1484, "add_param_group": 1485, "load_state_dict": 1486, "state_dict": 1487, "step": [1488, 1780], "zero_grad": 1489, "radam": 1490, "rmsprop": 1491, "rprop": 1492, "sgd": 1493, "sparseadam": 1494, "chainedschedul": 1495, "constantlr": 1496, "cosineannealinglr": 1497, "cosineannealingwarmrestart": 1498, "cycliclr": 1499, "exponentiallr": 1500, "lambdalr": 1501, "linearlr": 1502, "multisteplr": 1503, "multiplicativelr": 1504, "onecyclelr": 1505, "polynomiallr": 1506, "reducelronplateau": 1507, "sequentiallr": 1508, "steplr": 1509, "pca_lowrank": 1513, "polar": 1517, "promote_typ": 1522, "dequantstub": 1525, "quantstub": 1526, "quantwrapp": 1527, "add_quant_dequ": 1528, "convert": 1529, "default_eval_fn": 1530, "fakequant": [1531, 1784], "fakequantizebas": 1532, "fixedqparamsfakequant": 1533, "fusedmovingavgobsfakequant": 1534, "default_fake_qu": 1535, "default_fused_act_fake_qu": 1536, "default_fused_per_channel_wt_fake_qu": 1537, "default_fused_wt_fake_qu": 1538, "default_histogram_fake_qu": 1539, "default_per_channel_weight_fake_qu": 1540, "default_weight_fake_qu": 1541, "disable_fake_qu": 1542, "disable_observ": 1543, "enable_fake_qu": 1544, "enable_observ": 1545, "fuse_modul": 1546, "histogramobserv": 1547, "minmaxobserv": 1548, "movingaverageminmaxobserv": 1549, "movingaverageperchannelminmaxobserv": 1550, "noopobserv": 1551, "observerbas": 1552, "perchannelminmaxobserv": 1553, "placeholderobserv": 1554, "recordingobserv": 1555, "default_debug_observ": 1556, "default_dynamic_quant_observ": 1557, "default_float_qparams_observ": 1558, "default_histogram_observ": 1559, "default_observ": 1560, "default_per_channel_weight_observ": 1561, "default_placeholder_observ": 1562, "default_weight_observ": 1563, "get_observer_state_dict": 1564, "load_observer_state_dict": 1565, "prepar": [1566, 1784, 1787], "prepare_qat": 1567, "propagate_qconfig": 1568, "qconfig": [1569, 1784, 1787], "default_activation_only_qconfig": 1570, "default_debug_qconfig": 1571, "default_dynamic_qconfig": 1572, "default_per_channel_qconfig": 1573, "default_qat_qconfig": 1574, "default_qat_qconfig_v2": 1575, "default_qconfig": 1576, "default_weight_only_qconfig": 1577, "float16_dynamic_qconfig": 1578, "float16_static_qconfig": 1579, "float_qparams_weight_only_qconfig": 1580, "per_channel_dynamic_qconfig": 1581, "quantiz": [1582, 1755, 1770, 1777, 1784, 1785, 1786, 1787], "quantize_dynam": 1583, "convert_fx": 1584, "fuse_fx": 1585, "prepare_fx": 1586, "prepare_qat_fx": 1587, "quantize_qat": 1588, "swap_modul": 1589, "quantize_per_channel": 1590, "quantize_per_tensor": 1591, "quantized_batch_norm": 1592, "quantized_max_pool1d": 1593, "quantized_max_pool2d": 1594, "sobolengin": 1595, "rand": 1597, "rand_lik": 1598, "randint": 1599, "randint_lik": 1600, "randn": 1601, "randn_lik": 1602, "randperm": 1603, "rang": [1604, 1740], "result_typ": 1614, "row_stack": 1618, "searchsort": 1624, "set_default_devic": 1628, "set_default_dtyp": 1629, "set_default_tensor_typ": 1630, "set_deterministic_debug_mod": 1631, "set_float32_matmul_precis": 1632, "set_flush_denorm": 1633, "set_grad_en": 1634, "set_num_interop_thread": 1635, "set_num_thread": 1636, "set_printopt": 1637, "set_warn_alwai": 1639, "signal": [1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1792], "bartlett": 1643, "blackman": 1644, "cosin": 1645, "gaussian": 1647, "general_cosin": 1648, "general_ham": 1649, "ham": 1650, "hann": 1651, "kaiser": 1652, "nuttal": 1653, "sampled_addmm": 1666, "spdiag": 1668, "sparse_bsc_tensor": 1670, "sparse_bsr_tensor": 1671, "sparse_compressed_tensor": 1672, "sparse_coo_tensor": 1673, "sparse_csc_tensor": 1674, "sparse_csr_tensor": 1675, "std_mean": 1683, "svd_lowrank": 1689, "sym_float": 1692, "sym_int": 1693, "tensordot": 1702, "trapezoid": 1707, "trapz": 1708, "tril_indic": 1711, "triu_indic": 1713, "use_deterministic_algorithm": 1721, "var_mean": 1724, "view_as_complex": 1726, "view_as_r": 1727, "vstack": 1730, "zero": 1733, "zeros_lik": 1734, "hub": 1735, "publish": 1735, "entrypoint": 1735, "run": 1735, "download": 1735, "logic": [1735, 1740], "known": [1735, 1738], "bind": 1736, "tabl": [1736, 1775], "ir": 1737, "canon": 1737, "aten": [1737, 1777], "prim": 1737, "built": [1738, 1739, 1741, 1777], "comparison": [1738, 1740, 1741, 1801], "inspect": 1738, "warn": 1738, "appendix": [1738, 1741], "migrat": 1738, "recurs": 1738, "constant": [1738, 1740], "fusion": 1738, "builtin": 1739, "math": [1739, 1801], "unsupport": [1740, 1741, 1743, 1777, 1779], "construct": [1740, 1741, 1743, 1754, 1780, 1793], "refin": [1740, 1741], "enum": [1740, 1741], "name": [1740, 1752, 1753], "tupl": [1740, 1741], "express": [1740, 1741], "liter": [1740, 1741], "list": [1740, 1741, 1777], "dict": 1740, "arithmet": [1740, 1741], "subscript": [1740, 1741], "slice": [1740, 1741, 1773, 1801], "call": [1740, 1741, 1765], "ternari": [1740, 1741], "cast": 1740, "statement": [1740, 1741], "assign": [1740, 1741], "match": [1740, 1753], "If": 1740, "while": [1740, 1741], "loop": 1740, "For": 1740, "continu": [1740, 1741], "return": [1740, 1741, 1766, 1791], "resolut": [1740, 1741], "lookup": 1740, "defin": [1740, 1764, 1765], "terminolog": 1741, "meta": 1741, "primit": 1741, "special": [1741, 1794], "instanc": 1741, "signatur": 1741, "expr": 1741, "convers": [1741, 1754], "atom": 1741, "parenthes": 1741, "form": 1741, "dictionari": 1741, "displai": 1741, "primari": 1741, "power": 1741, "unari": [1741, 1747, 1793], "bitwis": 1741, "binari": [1741, 1747], "shift": 1741, "boolean": 1741, "condit": 1741, "augment": 1741, "rais": 1741, "assert": [1741, 1768], "del": 1741, "pass": [1741, 1762, 1772, 1784, 1790], "compound": 1741, "els": 1741, "getattr": 1741, "hasattr": 1741, "zip": [1741, 1781], "enumer": 1741, "rule": [1741, 1753, 1765, 1778], "remot": [1741, 1791], "procedur": 1741, "execut": [1741, 1762, 1781, 1782], "program": 1741, "coverag": [1742, 1752, 1764], "properti": [1743, 1746], "Not": 1743, "correctli": 1743, "bound": 1743, "schema": 1743, "between": [1743, 1781], "matrix": [1746, 1784], "decomposit": 1746, "solver": 1746, "misc": 1746, "experiment": 1746, "motiv": 1747, "reduct": [1747, 1762, 1773, 1801], "mobile_optim": 1748, "model_zoo": 1749, "strategi": [1751, 1780], "descriptor": 1751, "file_descriptor": 1751, "file_system": 1751, "subprocess": 1751, "keep": [1752, 1781], "dimens": [1752, 1753], "unifi": 1752, "contract": 1752, "awai": 1752, "factori": 1752, "variant": 1752, "semant": [1753, 1760, 1762, 1768, 1775], "explicit": 1753, "align": 1753, "current": 1753, "subsystem": 1753, "constructor": 1754, "contain": 1755, "convolut": [1755, 1756, 1773, 1774], "layer": 1755, "pool": [1755, 1756], "activ": [1755, 1756], "weight": [1755, 1780], "nonlinear": 1755, "recurr": [1755, 1766], "distanc": [1755, 1756], "loss": [1755, 1756, 1758], "vision": [1755, 1756], "shuffl": 1755, "lazi": 1755, "typic": 1758, "unscal": 1758, "accumul": 1758, "penalti": 1758, "one": 1758, "per": [1758, 1780], "particular": 1758, "dtype": [1758, 1775, 1787, 1796], "encod": 1759, "histori": 1759, "set": [1759, 1777], "No": 1759, "multithread": 1759, "concurr": 1759, "determin": [1759, 1774], "retain": 1759, "thread": [1759, 1761], "safeti": 1759, "wirting": 1759, "calculu": 1759, "pictur": 1759, "conjug": 1759, "own": 1759, "formula": 1759, "domain": 1759, "regist": 1759, "compat": 1760, "tune": 1761, "tensorfloat": [1762, 1768, 1773], "32": [1762, 1768, 1773, 1776], "tf32": [1762, 1768, 1773], "amper": [1762, 1773], "reduc": [1762, 1773], "fp16": [1762, 1773], "gemm": [1762, 1773], "bf16": [1762, 1773], "bc": 1762, "alloc": [1762, 1766], "cufft": 1762, "plan": [1762, 1768], "just": 1762, "time": 1762, "practic": [1762, 1772, 1784], "agnost": 1762, "buffer": [1762, 1772], "instead": 1762, "captur": 1762, "partial": 1762, "9": 1762, "6": 1762, "across": [1762, 1775], "intern": [1763, 1777, 1781], "processgroup": 1763, "ddpoptim": 1763, "separ": 1764, "setup_context": 1764, "like": [1764, 1781], "subclass": 1764, "wrapper": 1764, "__torch_function__": 1764, "overrid": [1764, 1804], "specifi": 1765, "gotcha": 1765, "staticmethod": 1765, "isn": 1766, "freed": 1766, "properli": 1766, "loader": 1766, "doesn": 1766, "notat": 1767, "background": [1767, 1790, 1791], "inform": [1767, 1789], "analyt": 1767, "output": 1767, "u": 1767, "reus": [1768, 1772], "hipfft": 1768, "rocfft": 1768, "enabl": 1768, "kernel": [1768, 1784], "larg": 1769, "fleet": 1769, "wide": 1769, "attach": 1769, "metadata": 1769, "consider": 1769, "block": 1770, "neural": 1770, "tip": [1772, 1785], "fight": 1772, "deadlock": 1772, "through": 1772, "queue": 1772, "e": 1772, "g": 1772, "hogwild": 1772, "extrem": 1773, "finit": 1773, "instinct": 1773, "mi200": 1773, "reproduc": 1774, "nondeterminist": 1774, "algorithm": [1774, 1780, 1790], "content": [1775, 1781], "preserv": 1775, "them": [1775, 1781], "integ": 1775, "divis": 1775, "alwai": 1775, "includ": [1776, 1781], "compon": 1776, "One": 1776, "cffi": 1776, "cpp": 1776, "found": 1776, "win": 1776, "channel": 1776, "without": 1776, "claus": 1776, "protect": 1776, "broken": 1776, "pipe": [1776, 1782], "driver": 1776, "shut": 1776, "down": 1776, "ipc": 1776, "alexnet": 1777, "vs": 1777, "differ": 1777, "index": [1777, 1801], "inlin": 1777, "discov": 1777, "unconvert": 1777, "onc": 1777, "diagnost": 1778, "closur": 1780, "base": 1780, "adjust": 1780, "learn": 1780, "rate": 1780, "stochast": 1780, "averag": 1780, "swa": 1780, "schedul": 1780, "care": 1780, "put": 1780, "togeth": 1780, "your": 1781, "insid": 1781, "treat": 1781, "archiv": 1781, "file_structur": 1781, "given": 1781, "wa": 1781, "resourc": 1781, "later": 1781, "whether": 1781, "distinguish": 1781, "explan": 1781, "format": 1781, "framework": [1781, 1789], "user": [1781, 1791], "find": 1781, "analyz": 1781, "extern": 1781, "mock": 1781, "refactor": 1781, "sharp": 1781, "global": 1781, "isol": 1781, "each": 1781, "mangl": 1781, "pipelin": 1782, "skip": 1782, "connect": 1782, "instrument": 1783, "technolog": 1783, "eager": 1784, "awar": 1784, "engin": [1784, 1801], "observ": [1784, 1787], "hardwar": 1784, "nativ": [1784, 1786], "configur": [1784, 1786, 1801], "insensit": 1785, "int8": 1785, "sensit": 1785, "top": 1787, "quantize_fx": 1787, "ao": [1787, 1802, 1803], "qconfig_map": 1787, "backend_config": 1787, "custom_config": 1787, "relat": 1787, "fake_quant": 1787, "intrins": 1787, "qat": 1787, "scheme": 1787, "rpc": 1789, "tensorpip": 1789, "rref": [1789, 1791], "remotemodul": 1789, "record": 1790, "dure": 1790, "smart": 1790, "end": 1790, "protocol": 1791, "assumpt": 1791, "lifetim": 1791, "reason": 1791, "scenario": 1791, "owner": 1791, "argument": 1791, "sparsiti": 1793, "coo": 1793, "hybrid": 1793, "uncoalesc": 1793, "csr": 1793, "csc": 1793, "bsr": 1793, "bsc": 1793, "memory_format": 1796, "tensorboard": 1798, "creation": 1801, "sampl": 1801, "quasi": 1801, "pointwis": 1801, "spectral": 1801, "bla": 1801, "lapack": 1801, "tag": 1801, "ns": [1802, 1803], "_numeric_suit": 1802, "_numeric_suite_fx": 1803, "info": 1805, "finfo": 1805, "iinfo": 1805}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})