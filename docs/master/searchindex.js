Search.setIndex({"docnames": ["amp", "autograd", "backends", "benchmark_utils", "bottleneck", "checkpoint", "community/contribution_guide", "community/design", "community/governance", "community/persons_of_interest", "complex_numbers", "config_mod", "cpp_extension", "cpp_index", "cuda", "cudnn_persistent_rnn", "cudnn_rnn_determinism", "data", "ddp_comm_hooks", "deploy", "distributed", "distributed.algorithms.join", "distributed.elastic", "distributed.optim", "distributions", "dlpack", "elastic/agent", "elastic/customization", "elastic/errors", "elastic/events", "elastic/examples", "elastic/kubernetes", "elastic/metrics", "elastic/multiprocessing", "elastic/quickstart", "elastic/rendezvous", "elastic/run", "elastic/timer", "elastic/train_script", "fft", "fsdp", "futures", "fx", "generated/torch.Generator", "generated/torch.Tensor.abs", "generated/torch.Tensor.abs_", "generated/torch.Tensor.absolute", "generated/torch.Tensor.absolute_", "generated/torch.Tensor.acos", "generated/torch.Tensor.acos_", "generated/torch.Tensor.acosh", "generated/torch.Tensor.acosh_", "generated/torch.Tensor.add", "generated/torch.Tensor.add_", "generated/torch.Tensor.addbmm", "generated/torch.Tensor.addbmm_", "generated/torch.Tensor.addcdiv", "generated/torch.Tensor.addcdiv_", "generated/torch.Tensor.addcmul", "generated/torch.Tensor.addcmul_", "generated/torch.Tensor.addmm", "generated/torch.Tensor.addmm_", "generated/torch.Tensor.addmv", "generated/torch.Tensor.addmv_", "generated/torch.Tensor.addr", "generated/torch.Tensor.addr_", "generated/torch.Tensor.adjoint", "generated/torch.Tensor.all", "generated/torch.Tensor.allclose", "generated/torch.Tensor.amax", "generated/torch.Tensor.amin", "generated/torch.Tensor.aminmax", "generated/torch.Tensor.angle", "generated/torch.Tensor.any", "generated/torch.Tensor.apply_", "generated/torch.Tensor.arccos", "generated/torch.Tensor.arccos_", "generated/torch.Tensor.arccosh", "generated/torch.Tensor.arccosh_", "generated/torch.Tensor.arcsin", "generated/torch.Tensor.arcsin_", "generated/torch.Tensor.arcsinh", "generated/torch.Tensor.arcsinh_", "generated/torch.Tensor.arctan", "generated/torch.Tensor.arctan2", "generated/torch.Tensor.arctan2_", "generated/torch.Tensor.arctan_", "generated/torch.Tensor.arctanh", "generated/torch.Tensor.arctanh_", "generated/torch.Tensor.argmax", "generated/torch.Tensor.argmin", "generated/torch.Tensor.argsort", "generated/torch.Tensor.argwhere", "generated/torch.Tensor.as_strided", "generated/torch.Tensor.as_subclass", "generated/torch.Tensor.asin", "generated/torch.Tensor.asin_", "generated/torch.Tensor.asinh", "generated/torch.Tensor.asinh_", "generated/torch.Tensor.atan", "generated/torch.Tensor.atan2", "generated/torch.Tensor.atan2_", "generated/torch.Tensor.atan_", "generated/torch.Tensor.atanh", "generated/torch.Tensor.atanh_", "generated/torch.Tensor.backward", "generated/torch.Tensor.baddbmm", "generated/torch.Tensor.baddbmm_", "generated/torch.Tensor.bernoulli", "generated/torch.Tensor.bernoulli_", "generated/torch.Tensor.bfloat16", "generated/torch.Tensor.bincount", "generated/torch.Tensor.bitwise_and", "generated/torch.Tensor.bitwise_and_", "generated/torch.Tensor.bitwise_left_shift", "generated/torch.Tensor.bitwise_left_shift_", "generated/torch.Tensor.bitwise_not", "generated/torch.Tensor.bitwise_not_", "generated/torch.Tensor.bitwise_or", "generated/torch.Tensor.bitwise_or_", "generated/torch.Tensor.bitwise_right_shift", "generated/torch.Tensor.bitwise_right_shift_", "generated/torch.Tensor.bitwise_xor", "generated/torch.Tensor.bitwise_xor_", "generated/torch.Tensor.bmm", "generated/torch.Tensor.bool", "generated/torch.Tensor.broadcast_to", "generated/torch.Tensor.byte", "generated/torch.Tensor.cauchy_", "generated/torch.Tensor.ccol_indices", "generated/torch.Tensor.cdouble", "generated/torch.Tensor.ceil", "generated/torch.Tensor.ceil_", "generated/torch.Tensor.cfloat", "generated/torch.Tensor.chalf", "generated/torch.Tensor.char", "generated/torch.Tensor.cholesky", "generated/torch.Tensor.cholesky_inverse", "generated/torch.Tensor.cholesky_solve", "generated/torch.Tensor.chunk", "generated/torch.Tensor.clamp", "generated/torch.Tensor.clamp_", "generated/torch.Tensor.clip", "generated/torch.Tensor.clip_", "generated/torch.Tensor.clone", "generated/torch.Tensor.coalesce", "generated/torch.Tensor.col_indices", "generated/torch.Tensor.conj", "generated/torch.Tensor.conj_physical", "generated/torch.Tensor.conj_physical_", "generated/torch.Tensor.contiguous", "generated/torch.Tensor.copy_", "generated/torch.Tensor.copysign", "generated/torch.Tensor.copysign_", "generated/torch.Tensor.corrcoef", "generated/torch.Tensor.cos", "generated/torch.Tensor.cos_", "generated/torch.Tensor.cosh", "generated/torch.Tensor.cosh_", "generated/torch.Tensor.count_nonzero", "generated/torch.Tensor.cov", "generated/torch.Tensor.cpu", "generated/torch.Tensor.cross", "generated/torch.Tensor.crow_indices", "generated/torch.Tensor.cuda", "generated/torch.Tensor.cummax", "generated/torch.Tensor.cummin", "generated/torch.Tensor.cumprod", "generated/torch.Tensor.cumprod_", "generated/torch.Tensor.cumsum", "generated/torch.Tensor.cumsum_", "generated/torch.Tensor.data_ptr", "generated/torch.Tensor.deg2rad", "generated/torch.Tensor.dense_dim", "generated/torch.Tensor.dequantize", "generated/torch.Tensor.det", "generated/torch.Tensor.detach", "generated/torch.Tensor.detach_", "generated/torch.Tensor.device", "generated/torch.Tensor.diag", "generated/torch.Tensor.diag_embed", "generated/torch.Tensor.diagflat", "generated/torch.Tensor.diagonal", "generated/torch.Tensor.diagonal_scatter", "generated/torch.Tensor.diff", "generated/torch.Tensor.digamma", "generated/torch.Tensor.digamma_", "generated/torch.Tensor.dim", "generated/torch.Tensor.dist", "generated/torch.Tensor.div", "generated/torch.Tensor.div_", "generated/torch.Tensor.divide", "generated/torch.Tensor.divide_", "generated/torch.Tensor.dot", "generated/torch.Tensor.double", "generated/torch.Tensor.dsplit", "generated/torch.Tensor.eig", "generated/torch.Tensor.element_size", "generated/torch.Tensor.eq", "generated/torch.Tensor.eq_", "generated/torch.Tensor.equal", "generated/torch.Tensor.erf", "generated/torch.Tensor.erf_", "generated/torch.Tensor.erfc", "generated/torch.Tensor.erfc_", "generated/torch.Tensor.erfinv", "generated/torch.Tensor.erfinv_", "generated/torch.Tensor.exp", "generated/torch.Tensor.exp_", "generated/torch.Tensor.expand", "generated/torch.Tensor.expand_as", "generated/torch.Tensor.expm1", "generated/torch.Tensor.expm1_", "generated/torch.Tensor.exponential_", "generated/torch.Tensor.fill_", "generated/torch.Tensor.fill_diagonal_", "generated/torch.Tensor.fix", "generated/torch.Tensor.fix_", "generated/torch.Tensor.flatten", "generated/torch.Tensor.flip", "generated/torch.Tensor.fliplr", "generated/torch.Tensor.flipud", "generated/torch.Tensor.float", "generated/torch.Tensor.float_power", "generated/torch.Tensor.float_power_", "generated/torch.Tensor.floor", "generated/torch.Tensor.floor_", "generated/torch.Tensor.floor_divide", "generated/torch.Tensor.floor_divide_", "generated/torch.Tensor.fmax", "generated/torch.Tensor.fmin", "generated/torch.Tensor.fmod", "generated/torch.Tensor.fmod_", "generated/torch.Tensor.frac", "generated/torch.Tensor.frac_", "generated/torch.Tensor.frexp", "generated/torch.Tensor.gather", "generated/torch.Tensor.gcd", "generated/torch.Tensor.gcd_", "generated/torch.Tensor.ge", "generated/torch.Tensor.ge_", "generated/torch.Tensor.geometric_", "generated/torch.Tensor.geqrf", "generated/torch.Tensor.ger", "generated/torch.Tensor.get_device", "generated/torch.Tensor.grad", "generated/torch.Tensor.greater", "generated/torch.Tensor.greater_", "generated/torch.Tensor.greater_equal", "generated/torch.Tensor.greater_equal_", "generated/torch.Tensor.gt", "generated/torch.Tensor.gt_", "generated/torch.Tensor.half", "generated/torch.Tensor.hardshrink", "generated/torch.Tensor.heaviside", "generated/torch.Tensor.histc", "generated/torch.Tensor.histogram", "generated/torch.Tensor.hsplit", "generated/torch.Tensor.hypot", "generated/torch.Tensor.hypot_", "generated/torch.Tensor.i0", "generated/torch.Tensor.i0_", "generated/torch.Tensor.igamma", "generated/torch.Tensor.igamma_", "generated/torch.Tensor.igammac", "generated/torch.Tensor.igammac_", "generated/torch.Tensor.imag", "generated/torch.Tensor.index_add", "generated/torch.Tensor.index_add_", "generated/torch.Tensor.index_copy", "generated/torch.Tensor.index_copy_", "generated/torch.Tensor.index_fill", "generated/torch.Tensor.index_fill_", "generated/torch.Tensor.index_put", "generated/torch.Tensor.index_put_", "generated/torch.Tensor.index_reduce", "generated/torch.Tensor.index_reduce_", "generated/torch.Tensor.index_select", "generated/torch.Tensor.indices", "generated/torch.Tensor.inner", "generated/torch.Tensor.int", "generated/torch.Tensor.int_repr", "generated/torch.Tensor.inverse", "generated/torch.Tensor.is_coalesced", "generated/torch.Tensor.is_complex", "generated/torch.Tensor.is_conj", "generated/torch.Tensor.is_contiguous", "generated/torch.Tensor.is_cuda", "generated/torch.Tensor.is_floating_point", "generated/torch.Tensor.is_inference", "generated/torch.Tensor.is_leaf", "generated/torch.Tensor.is_meta", "generated/torch.Tensor.is_pinned", "generated/torch.Tensor.is_quantized", "generated/torch.Tensor.is_set_to", "generated/torch.Tensor.is_shared", "generated/torch.Tensor.is_signed", "generated/torch.Tensor.is_sparse", "generated/torch.Tensor.is_sparse_csr", "generated/torch.Tensor.isclose", "generated/torch.Tensor.isfinite", "generated/torch.Tensor.isinf", "generated/torch.Tensor.isnan", "generated/torch.Tensor.isneginf", "generated/torch.Tensor.isposinf", "generated/torch.Tensor.isreal", "generated/torch.Tensor.istft", "generated/torch.Tensor.item", "generated/torch.Tensor.kthvalue", "generated/torch.Tensor.lcm", "generated/torch.Tensor.lcm_", "generated/torch.Tensor.ldexp", "generated/torch.Tensor.ldexp_", "generated/torch.Tensor.le", "generated/torch.Tensor.le_", "generated/torch.Tensor.lerp", "generated/torch.Tensor.lerp_", "generated/torch.Tensor.less", "generated/torch.Tensor.less_", "generated/torch.Tensor.less_equal", "generated/torch.Tensor.less_equal_", "generated/torch.Tensor.lgamma", "generated/torch.Tensor.lgamma_", "generated/torch.Tensor.log", "generated/torch.Tensor.log10", "generated/torch.Tensor.log10_", "generated/torch.Tensor.log1p", "generated/torch.Tensor.log1p_", "generated/torch.Tensor.log2", "generated/torch.Tensor.log2_", "generated/torch.Tensor.log_", "generated/torch.Tensor.log_normal_", "generated/torch.Tensor.logaddexp", "generated/torch.Tensor.logaddexp2", "generated/torch.Tensor.logcumsumexp", "generated/torch.Tensor.logdet", "generated/torch.Tensor.logical_and", "generated/torch.Tensor.logical_and_", "generated/torch.Tensor.logical_not", "generated/torch.Tensor.logical_not_", "generated/torch.Tensor.logical_or", "generated/torch.Tensor.logical_or_", "generated/torch.Tensor.logical_xor", "generated/torch.Tensor.logical_xor_", "generated/torch.Tensor.logit", "generated/torch.Tensor.logit_", "generated/torch.Tensor.logsumexp", "generated/torch.Tensor.long", "generated/torch.Tensor.lstsq", "generated/torch.Tensor.lt", "generated/torch.Tensor.lt_", "generated/torch.Tensor.lu", "generated/torch.Tensor.lu_solve", "generated/torch.Tensor.map_", "generated/torch.Tensor.masked_fill", "generated/torch.Tensor.masked_fill_", "generated/torch.Tensor.masked_scatter", "generated/torch.Tensor.masked_scatter_", "generated/torch.Tensor.masked_select", "generated/torch.Tensor.matmul", "generated/torch.Tensor.matrix_exp", "generated/torch.Tensor.matrix_power", "generated/torch.Tensor.max", "generated/torch.Tensor.maximum", "generated/torch.Tensor.mean", "generated/torch.Tensor.median", "generated/torch.Tensor.min", "generated/torch.Tensor.minimum", "generated/torch.Tensor.mm", "generated/torch.Tensor.mode", "generated/torch.Tensor.moveaxis", "generated/torch.Tensor.movedim", "generated/torch.Tensor.msort", "generated/torch.Tensor.mul", "generated/torch.Tensor.mul_", "generated/torch.Tensor.multinomial", "generated/torch.Tensor.multiply", "generated/torch.Tensor.multiply_", "generated/torch.Tensor.mv", "generated/torch.Tensor.mvlgamma", "generated/torch.Tensor.mvlgamma_", "generated/torch.Tensor.nan_to_num", "generated/torch.Tensor.nan_to_num_", "generated/torch.Tensor.nanmean", "generated/torch.Tensor.nanmedian", "generated/torch.Tensor.nanquantile", "generated/torch.Tensor.nansum", "generated/torch.Tensor.narrow", "generated/torch.Tensor.narrow_copy", "generated/torch.Tensor.ndim", "generated/torch.Tensor.ndimension", "generated/torch.Tensor.ne", "generated/torch.Tensor.ne_", "generated/torch.Tensor.neg", "generated/torch.Tensor.neg_", "generated/torch.Tensor.negative", "generated/torch.Tensor.negative_", "generated/torch.Tensor.nelement", "generated/torch.Tensor.new_empty", "generated/torch.Tensor.new_full", "generated/torch.Tensor.new_ones", "generated/torch.Tensor.new_tensor", "generated/torch.Tensor.new_zeros", "generated/torch.Tensor.nextafter", "generated/torch.Tensor.nextafter_", "generated/torch.Tensor.nonzero", "generated/torch.Tensor.norm", "generated/torch.Tensor.normal_", "generated/torch.Tensor.not_equal", "generated/torch.Tensor.not_equal_", "generated/torch.Tensor.numel", "generated/torch.Tensor.numpy", "generated/torch.Tensor.orgqr", "generated/torch.Tensor.ormqr", "generated/torch.Tensor.outer", "generated/torch.Tensor.permute", "generated/torch.Tensor.pin_memory", "generated/torch.Tensor.pinverse", "generated/torch.Tensor.polygamma", "generated/torch.Tensor.polygamma_", "generated/torch.Tensor.positive", "generated/torch.Tensor.pow", "generated/torch.Tensor.pow_", "generated/torch.Tensor.prod", "generated/torch.Tensor.put_", "generated/torch.Tensor.q_per_channel_axis", "generated/torch.Tensor.q_per_channel_scales", "generated/torch.Tensor.q_per_channel_zero_points", "generated/torch.Tensor.q_scale", "generated/torch.Tensor.q_zero_point", "generated/torch.Tensor.qr", "generated/torch.Tensor.qscheme", "generated/torch.Tensor.quantile", "generated/torch.Tensor.rad2deg", "generated/torch.Tensor.random_", "generated/torch.Tensor.ravel", "generated/torch.Tensor.real", "generated/torch.Tensor.reciprocal", "generated/torch.Tensor.reciprocal_", "generated/torch.Tensor.record_stream", "generated/torch.Tensor.register_hook", "generated/torch.Tensor.remainder", "generated/torch.Tensor.remainder_", "generated/torch.Tensor.renorm", "generated/torch.Tensor.renorm_", "generated/torch.Tensor.repeat", "generated/torch.Tensor.repeat_interleave", "generated/torch.Tensor.requires_grad", "generated/torch.Tensor.requires_grad_", "generated/torch.Tensor.reshape", "generated/torch.Tensor.reshape_as", "generated/torch.Tensor.resize_", "generated/torch.Tensor.resize_as_", "generated/torch.Tensor.resolve_conj", "generated/torch.Tensor.resolve_neg", "generated/torch.Tensor.retain_grad", "generated/torch.Tensor.retains_grad", "generated/torch.Tensor.roll", "generated/torch.Tensor.rot90", "generated/torch.Tensor.round", "generated/torch.Tensor.round_", "generated/torch.Tensor.row_indices", "generated/torch.Tensor.rsqrt", "generated/torch.Tensor.rsqrt_", "generated/torch.Tensor.scatter", "generated/torch.Tensor.scatter_", "generated/torch.Tensor.scatter_add", "generated/torch.Tensor.scatter_add_", "generated/torch.Tensor.scatter_reduce", "generated/torch.Tensor.scatter_reduce_", "generated/torch.Tensor.select", "generated/torch.Tensor.select_scatter", "generated/torch.Tensor.set_", "generated/torch.Tensor.sgn", "generated/torch.Tensor.sgn_", "generated/torch.Tensor.share_memory_", "generated/torch.Tensor.short", "generated/torch.Tensor.sigmoid", "generated/torch.Tensor.sigmoid_", "generated/torch.Tensor.sign", "generated/torch.Tensor.sign_", "generated/torch.Tensor.signbit", "generated/torch.Tensor.sin", "generated/torch.Tensor.sin_", "generated/torch.Tensor.sinc", "generated/torch.Tensor.sinc_", "generated/torch.Tensor.sinh", "generated/torch.Tensor.sinh_", "generated/torch.Tensor.size", "generated/torch.Tensor.slice_scatter", "generated/torch.Tensor.slogdet", "generated/torch.Tensor.smm", "generated/torch.Tensor.sort", "generated/torch.Tensor.sparse_dim", "generated/torch.Tensor.sparse_mask", "generated/torch.Tensor.sparse_resize_", "generated/torch.Tensor.sparse_resize_and_clear_", "generated/torch.Tensor.split", "generated/torch.Tensor.sqrt", "generated/torch.Tensor.sqrt_", "generated/torch.Tensor.square", "generated/torch.Tensor.square_", "generated/torch.Tensor.squeeze", "generated/torch.Tensor.squeeze_", "generated/torch.Tensor.sspaddmm", "generated/torch.Tensor.std", "generated/torch.Tensor.stft", "generated/torch.Tensor.storage", "generated/torch.Tensor.storage_offset", "generated/torch.Tensor.storage_type", "generated/torch.Tensor.stride", "generated/torch.Tensor.sub", "generated/torch.Tensor.sub_", "generated/torch.Tensor.subtract", "generated/torch.Tensor.subtract_", "generated/torch.Tensor.sum", "generated/torch.Tensor.sum_to_size", "generated/torch.Tensor.svd", "generated/torch.Tensor.swapaxes", "generated/torch.Tensor.swapdims", "generated/torch.Tensor.symeig", "generated/torch.Tensor.t", "generated/torch.Tensor.t_", "generated/torch.Tensor.take", "generated/torch.Tensor.take_along_dim", "generated/torch.Tensor.tan", "generated/torch.Tensor.tan_", "generated/torch.Tensor.tanh", "generated/torch.Tensor.tanh_", "generated/torch.Tensor.tensor_split", "generated/torch.Tensor.tile", "generated/torch.Tensor.to", "generated/torch.Tensor.to_dense", "generated/torch.Tensor.to_mkldnn", "generated/torch.Tensor.to_padded_tensor", "generated/torch.Tensor.to_sparse", "generated/torch.Tensor.to_sparse_bsc", "generated/torch.Tensor.to_sparse_bsr", "generated/torch.Tensor.to_sparse_coo", "generated/torch.Tensor.to_sparse_csc", "generated/torch.Tensor.to_sparse_csr", "generated/torch.Tensor.tolist", "generated/torch.Tensor.topk", "generated/torch.Tensor.trace", "generated/torch.Tensor.transpose", "generated/torch.Tensor.transpose_", "generated/torch.Tensor.triangular_solve", "generated/torch.Tensor.tril", "generated/torch.Tensor.tril_", "generated/torch.Tensor.triu", "generated/torch.Tensor.triu_", "generated/torch.Tensor.true_divide", "generated/torch.Tensor.true_divide_", "generated/torch.Tensor.trunc", "generated/torch.Tensor.trunc_", "generated/torch.Tensor.type", "generated/torch.Tensor.type_as", "generated/torch.Tensor.unbind", "generated/torch.Tensor.unflatten", "generated/torch.Tensor.unfold", "generated/torch.Tensor.uniform_", "generated/torch.Tensor.unique", "generated/torch.Tensor.unique_consecutive", "generated/torch.Tensor.unsqueeze", "generated/torch.Tensor.unsqueeze_", "generated/torch.Tensor.values", "generated/torch.Tensor.var", "generated/torch.Tensor.vdot", "generated/torch.Tensor.view", "generated/torch.Tensor.view_as", "generated/torch.Tensor.vsplit", "generated/torch.Tensor.where", "generated/torch.Tensor.xlogy", "generated/torch.Tensor.xlogy_", "generated/torch.Tensor.zero_", "generated/torch._assert", "generated/torch.abs", "generated/torch.absolute", "generated/torch.acos", "generated/torch.acosh", "generated/torch.add", "generated/torch.addbmm", "generated/torch.addcdiv", "generated/torch.addcmul", "generated/torch.addmm", "generated/torch.addmv", "generated/torch.addr", "generated/torch.adjoint", "generated/torch.all", "generated/torch.allclose", "generated/torch.amax", "generated/torch.amin", "generated/torch.aminmax", "generated/torch.angle", "generated/torch.any", "generated/torch.arange", "generated/torch.arccos", "generated/torch.arccosh", "generated/torch.arcsin", "generated/torch.arcsinh", "generated/torch.arctan", "generated/torch.arctan2", "generated/torch.arctanh", "generated/torch.are_deterministic_algorithms_enabled", "generated/torch.argmax", "generated/torch.argmin", "generated/torch.argsort", "generated/torch.argwhere", "generated/torch.as_strided", "generated/torch.as_tensor", "generated/torch.asarray", "generated/torch.asin", "generated/torch.asinh", "generated/torch.atan", "generated/torch.atan2", "generated/torch.atanh", "generated/torch.atleast_1d", "generated/torch.atleast_2d", "generated/torch.atleast_3d", "generated/torch.autograd.Function.backward", "generated/torch.autograd.Function.forward", "generated/torch.autograd.Function.jvp", "generated/torch.autograd.backward", "generated/torch.autograd.forward_ad.dual_level", "generated/torch.autograd.forward_ad.make_dual", "generated/torch.autograd.forward_ad.unpack_dual", "generated/torch.autograd.function.FunctionCtx.mark_dirty", "generated/torch.autograd.function.FunctionCtx.mark_non_differentiable", "generated/torch.autograd.function.FunctionCtx.save_for_backward", "generated/torch.autograd.function.FunctionCtx.set_materialize_grads", "generated/torch.autograd.functional.hessian", "generated/torch.autograd.functional.hvp", "generated/torch.autograd.functional.jacobian", "generated/torch.autograd.functional.jvp", "generated/torch.autograd.functional.vhp", "generated/torch.autograd.functional.vjp", "generated/torch.autograd.grad", "generated/torch.autograd.gradcheck", "generated/torch.autograd.gradgradcheck", "generated/torch.autograd.profiler.load_nvprof", "generated/torch.autograd.profiler.profile.export_chrome_trace", "generated/torch.autograd.profiler.profile.key_averages", "generated/torch.autograd.profiler.profile.self_cpu_time_total", "generated/torch.autograd.profiler.profile.total_average", "generated/torch.baddbmm", "generated/torch.bartlett_window", "generated/torch.bernoulli", "generated/torch.bincount", "generated/torch.bitwise_and", "generated/torch.bitwise_left_shift", "generated/torch.bitwise_not", "generated/torch.bitwise_or", "generated/torch.bitwise_right_shift", "generated/torch.bitwise_xor", "generated/torch.blackman_window", "generated/torch.block_diag", "generated/torch.bmm", "generated/torch.broadcast_shapes", "generated/torch.broadcast_tensors", "generated/torch.broadcast_to", "generated/torch.bucketize", "generated/torch.can_cast", "generated/torch.cartesian_prod", "generated/torch.cat", "generated/torch.cdist", "generated/torch.ceil", "generated/torch.chain_matmul", "generated/torch.cholesky", "generated/torch.cholesky_inverse", "generated/torch.cholesky_solve", "generated/torch.chunk", "generated/torch.clamp", "generated/torch.clip", "generated/torch.clone", "generated/torch.column_stack", "generated/torch.combinations", "generated/torch.compiled_with_cxx11_abi", "generated/torch.complex", "generated/torch.concat", "generated/torch.conj", "generated/torch.conj_physical", "generated/torch.copysign", "generated/torch.corrcoef", "generated/torch.cos", "generated/torch.cosh", "generated/torch.count_nonzero", "generated/torch.cov", "generated/torch.cross", "generated/torch.cuda.CUDAGraph", "generated/torch.cuda.Event", "generated/torch.cuda.ExternalStream", "generated/torch.cuda.Stream", "generated/torch.cuda.StreamContext", "generated/torch.cuda.caching_allocator_alloc", "generated/torch.cuda.caching_allocator_delete", "generated/torch.cuda.can_device_access_peer", "generated/torch.cuda.comm.broadcast", "generated/torch.cuda.comm.broadcast_coalesced", "generated/torch.cuda.comm.gather", "generated/torch.cuda.comm.reduce_add", "generated/torch.cuda.comm.scatter", "generated/torch.cuda.current_blas_handle", "generated/torch.cuda.current_device", "generated/torch.cuda.current_stream", "generated/torch.cuda.default_stream", "generated/torch.cuda.device", "generated/torch.cuda.device_count", "generated/torch.cuda.device_of", "generated/torch.cuda.empty_cache", "generated/torch.cuda.get_arch_list", "generated/torch.cuda.get_device_capability", "generated/torch.cuda.get_device_name", "generated/torch.cuda.get_device_properties", "generated/torch.cuda.get_gencode_flags", "generated/torch.cuda.get_rng_state", "generated/torch.cuda.get_rng_state_all", "generated/torch.cuda.get_sync_debug_mode", "generated/torch.cuda.graph", "generated/torch.cuda.graph_pool_handle", "generated/torch.cuda.init", "generated/torch.cuda.initial_seed", "generated/torch.cuda.ipc_collect", "generated/torch.cuda.is_available", "generated/torch.cuda.is_current_stream_capturing", "generated/torch.cuda.is_initialized", "generated/torch.cuda.jiterator._create_jit_fn", "generated/torch.cuda.jiterator._create_multi_output_jit_fn", "generated/torch.cuda.list_gpu_processes", "generated/torch.cuda.make_graphed_callables", "generated/torch.cuda.manual_seed", "generated/torch.cuda.manual_seed_all", "generated/torch.cuda.max_memory_allocated", "generated/torch.cuda.max_memory_cached", "generated/torch.cuda.max_memory_reserved", "generated/torch.cuda.mem_get_info", "generated/torch.cuda.memory_allocated", "generated/torch.cuda.memory_cached", "generated/torch.cuda.memory_reserved", "generated/torch.cuda.memory_snapshot", "generated/torch.cuda.memory_stats", "generated/torch.cuda.memory_summary", "generated/torch.cuda.memory_usage", "generated/torch.cuda.nvtx.mark", "generated/torch.cuda.nvtx.range_pop", "generated/torch.cuda.nvtx.range_push", "generated/torch.cuda.reset_max_memory_allocated", "generated/torch.cuda.reset_max_memory_cached", "generated/torch.cuda.reset_peak_memory_stats", "generated/torch.cuda.seed", "generated/torch.cuda.seed_all", "generated/torch.cuda.set_device", "generated/torch.cuda.set_per_process_memory_fraction", "generated/torch.cuda.set_rng_state", "generated/torch.cuda.set_rng_state_all", "generated/torch.cuda.set_stream", "generated/torch.cuda.set_sync_debug_mode", "generated/torch.cuda.stream", "generated/torch.cuda.synchronize", "generated/torch.cuda.utilization", "generated/torch.cummax", "generated/torch.cummin", "generated/torch.cumprod", "generated/torch.cumsum", "generated/torch.cumulative_trapezoid", "generated/torch.deg2rad", "generated/torch.dequantize", "generated/torch.det", "generated/torch.diag", "generated/torch.diag_embed", "generated/torch.diagflat", "generated/torch.diagonal", "generated/torch.diagonal_scatter", "generated/torch.diff", "generated/torch.digamma", "generated/torch.dist", "generated/torch.div", "generated/torch.divide", "generated/torch.dot", "generated/torch.dsplit", "generated/torch.dstack", "generated/torch.eig", "generated/torch.einsum", "generated/torch.empty", "generated/torch.empty_like", "generated/torch.empty_strided", "generated/torch.enable_grad", "generated/torch.eq", "generated/torch.equal", "generated/torch.erf", "generated/torch.erfc", "generated/torch.erfinv", "generated/torch.exp", "generated/torch.exp2", "generated/torch.expm1", "generated/torch.eye", "generated/torch.fake_quantize_per_channel_affine", "generated/torch.fake_quantize_per_tensor_affine", "generated/torch.fft.fft", "generated/torch.fft.fft2", "generated/torch.fft.fftfreq", "generated/torch.fft.fftn", "generated/torch.fft.fftshift", "generated/torch.fft.hfft", "generated/torch.fft.hfft2", "generated/torch.fft.hfftn", "generated/torch.fft.ifft", "generated/torch.fft.ifft2", "generated/torch.fft.ifftn", "generated/torch.fft.ifftshift", "generated/torch.fft.ihfft", "generated/torch.fft.ihfft2", "generated/torch.fft.ihfftn", "generated/torch.fft.irfft", "generated/torch.fft.irfft2", "generated/torch.fft.irfftn", "generated/torch.fft.rfft", "generated/torch.fft.rfft2", "generated/torch.fft.rfftfreq", "generated/torch.fft.rfftn", "generated/torch.fix", "generated/torch.flatten", "generated/torch.flip", "generated/torch.fliplr", "generated/torch.flipud", "generated/torch.float_power", "generated/torch.floor", "generated/torch.floor_divide", "generated/torch.fmax", "generated/torch.fmin", "generated/torch.fmod", "generated/torch.frac", "generated/torch.frexp", "generated/torch.from_dlpack", "generated/torch.from_numpy", "generated/torch.frombuffer", "generated/torch.full", "generated/torch.full_like", "generated/torch.gather", "generated/torch.gcd", "generated/torch.ge", "generated/torch.geqrf", "generated/torch.ger", "generated/torch.get_default_dtype", "generated/torch.get_deterministic_debug_mode", "generated/torch.get_float32_matmul_precision", "generated/torch.get_num_interop_threads", "generated/torch.get_num_threads", "generated/torch.get_rng_state", "generated/torch.gradient", "generated/torch.greater", "generated/torch.greater_equal", "generated/torch.gt", "generated/torch.hamming_window", "generated/torch.hann_window", "generated/torch.heaviside", "generated/torch.histc", "generated/torch.histogram", "generated/torch.histogramdd", "generated/torch.hsplit", "generated/torch.hspmm", "generated/torch.hstack", "generated/torch.hypot", "generated/torch.i0", "generated/torch.igamma", "generated/torch.igammac", "generated/torch.imag", "generated/torch.index_add", "generated/torch.index_copy", "generated/torch.index_reduce", "generated/torch.index_select", "generated/torch.inference_mode", "generated/torch.initial_seed", "generated/torch.inner", "generated/torch.inverse", "generated/torch.is_complex", "generated/torch.is_conj", "generated/torch.is_deterministic_algorithms_warn_only_enabled", "generated/torch.is_floating_point", "generated/torch.is_grad_enabled", "generated/torch.is_inference_mode_enabled", "generated/torch.is_nonzero", "generated/torch.is_storage", "generated/torch.is_tensor", "generated/torch.is_warn_always_enabled", "generated/torch.isclose", "generated/torch.isfinite", "generated/torch.isin", "generated/torch.isinf", "generated/torch.isnan", "generated/torch.isneginf", "generated/torch.isposinf", "generated/torch.isreal", "generated/torch.istft", "generated/torch.jit.Attribute", "generated/torch.jit.ScriptFunction", "generated/torch.jit.ScriptModule", "generated/torch.jit.annotate", "generated/torch.jit.enable_onednn_fusion", "generated/torch.jit.fork", "generated/torch.jit.freeze", "generated/torch.jit.ignore", "generated/torch.jit.isinstance", "generated/torch.jit.load", "generated/torch.jit.onednn_fusion_enabled", "generated/torch.jit.optimize_for_inference", "generated/torch.jit.save", "generated/torch.jit.script", "generated/torch.jit.script_if_tracing", "generated/torch.jit.set_fusion_strategy", "generated/torch.jit.strict_fusion", "generated/torch.jit.trace", "generated/torch.jit.trace_module", "generated/torch.jit.unused", "generated/torch.jit.wait", "generated/torch.kaiser_window", "generated/torch.kron", "generated/torch.kthvalue", "generated/torch.lcm", "generated/torch.ldexp", "generated/torch.le", "generated/torch.lerp", "generated/torch.less", "generated/torch.less_equal", "generated/torch.lgamma", "generated/torch.linalg.cholesky", "generated/torch.linalg.cholesky_ex", "generated/torch.linalg.cond", "generated/torch.linalg.cross", "generated/torch.linalg.det", "generated/torch.linalg.diagonal", "generated/torch.linalg.eig", "generated/torch.linalg.eigh", "generated/torch.linalg.eigvals", "generated/torch.linalg.eigvalsh", "generated/torch.linalg.householder_product", "generated/torch.linalg.inv", "generated/torch.linalg.inv_ex", "generated/torch.linalg.ldl_factor", "generated/torch.linalg.ldl_factor_ex", "generated/torch.linalg.ldl_solve", "generated/torch.linalg.lstsq", "generated/torch.linalg.lu", "generated/torch.linalg.lu_factor", "generated/torch.linalg.lu_factor_ex", "generated/torch.linalg.lu_solve", "generated/torch.linalg.matmul", "generated/torch.linalg.matrix_exp", "generated/torch.linalg.matrix_norm", "generated/torch.linalg.matrix_power", "generated/torch.linalg.matrix_rank", "generated/torch.linalg.multi_dot", "generated/torch.linalg.norm", "generated/torch.linalg.pinv", "generated/torch.linalg.qr", "generated/torch.linalg.slogdet", "generated/torch.linalg.solve", "generated/torch.linalg.solve_ex", "generated/torch.linalg.solve_triangular", "generated/torch.linalg.svd", "generated/torch.linalg.svdvals", "generated/torch.linalg.tensorinv", "generated/torch.linalg.tensorsolve", "generated/torch.linalg.vander", "generated/torch.linalg.vecdot", "generated/torch.linalg.vector_norm", "generated/torch.linspace", "generated/torch.load", "generated/torch.lobpcg", "generated/torch.log", "generated/torch.log10", "generated/torch.log1p", "generated/torch.log2", "generated/torch.logaddexp", "generated/torch.logaddexp2", "generated/torch.logcumsumexp", "generated/torch.logdet", "generated/torch.logical_and", "generated/torch.logical_not", "generated/torch.logical_or", "generated/torch.logical_xor", "generated/torch.logit", "generated/torch.logspace", "generated/torch.logsumexp", "generated/torch.lstsq", "generated/torch.lt", "generated/torch.lu", "generated/torch.lu_solve", "generated/torch.lu_unpack", "generated/torch.manual_seed", "generated/torch.masked_select", "generated/torch.matmul", "generated/torch.matrix_exp", "generated/torch.matrix_power", "generated/torch.matrix_rank", "generated/torch.max", "generated/torch.maximum", "generated/torch.mean", "generated/torch.median", "generated/torch.meshgrid", "generated/torch.min", "generated/torch.minimum", "generated/torch.mm", "generated/torch.mode", "generated/torch.moveaxis", "generated/torch.movedim", "generated/torch.msort", "generated/torch.mul", "generated/torch.multinomial", "generated/torch.multiply", "generated/torch.mv", "generated/torch.mvlgamma", "generated/torch.nan_to_num", "generated/torch.nanmean", "generated/torch.nanmedian", "generated/torch.nanquantile", "generated/torch.nansum", "generated/torch.narrow", "generated/torch.ne", "generated/torch.neg", "generated/torch.negative", "generated/torch.nextafter", "generated/torch.nn.AdaptiveAvgPool1d", "generated/torch.nn.AdaptiveAvgPool2d", "generated/torch.nn.AdaptiveAvgPool3d", "generated/torch.nn.AdaptiveLogSoftmaxWithLoss", "generated/torch.nn.AdaptiveMaxPool1d", "generated/torch.nn.AdaptiveMaxPool2d", "generated/torch.nn.AdaptiveMaxPool3d", "generated/torch.nn.AlphaDropout", "generated/torch.nn.AvgPool1d", "generated/torch.nn.AvgPool2d", "generated/torch.nn.AvgPool3d", "generated/torch.nn.BCELoss", "generated/torch.nn.BCEWithLogitsLoss", "generated/torch.nn.BatchNorm1d", "generated/torch.nn.BatchNorm2d", "generated/torch.nn.BatchNorm3d", "generated/torch.nn.Bilinear", "generated/torch.nn.CELU", "generated/torch.nn.CTCLoss", "generated/torch.nn.ChannelShuffle", "generated/torch.nn.ConstantPad1d", "generated/torch.nn.ConstantPad2d", "generated/torch.nn.ConstantPad3d", "generated/torch.nn.Conv1d", "generated/torch.nn.Conv2d", "generated/torch.nn.Conv3d", "generated/torch.nn.ConvTranspose1d", "generated/torch.nn.ConvTranspose2d", "generated/torch.nn.ConvTranspose3d", "generated/torch.nn.CosineEmbeddingLoss", "generated/torch.nn.CosineSimilarity", "generated/torch.nn.CrossEntropyLoss", "generated/torch.nn.DataParallel", "generated/torch.nn.Dropout", "generated/torch.nn.Dropout1d", "generated/torch.nn.Dropout2d", "generated/torch.nn.Dropout3d", "generated/torch.nn.ELU", "generated/torch.nn.Embedding", "generated/torch.nn.EmbeddingBag", "generated/torch.nn.FeatureAlphaDropout", "generated/torch.nn.Flatten", "generated/torch.nn.Fold", "generated/torch.nn.FractionalMaxPool2d", "generated/torch.nn.FractionalMaxPool3d", "generated/torch.nn.GELU", "generated/torch.nn.GLU", "generated/torch.nn.GRU", "generated/torch.nn.GRUCell", "generated/torch.nn.GaussianNLLLoss", "generated/torch.nn.GroupNorm", "generated/torch.nn.Hardshrink", "generated/torch.nn.Hardsigmoid", "generated/torch.nn.Hardswish", "generated/torch.nn.Hardtanh", "generated/torch.nn.HingeEmbeddingLoss", "generated/torch.nn.HuberLoss", "generated/torch.nn.Identity", "generated/torch.nn.InstanceNorm1d", "generated/torch.nn.InstanceNorm2d", "generated/torch.nn.InstanceNorm3d", "generated/torch.nn.KLDivLoss", "generated/torch.nn.L1Loss", "generated/torch.nn.LPPool1d", "generated/torch.nn.LPPool2d", "generated/torch.nn.LSTM", "generated/torch.nn.LSTMCell", "generated/torch.nn.LayerNorm", "generated/torch.nn.LazyBatchNorm1d", "generated/torch.nn.LazyBatchNorm2d", "generated/torch.nn.LazyBatchNorm3d", "generated/torch.nn.LazyConv1d", "generated/torch.nn.LazyConv2d", "generated/torch.nn.LazyConv3d", "generated/torch.nn.LazyConvTranspose1d", "generated/torch.nn.LazyConvTranspose2d", "generated/torch.nn.LazyConvTranspose3d", "generated/torch.nn.LazyInstanceNorm1d", "generated/torch.nn.LazyInstanceNorm2d", "generated/torch.nn.LazyInstanceNorm3d", "generated/torch.nn.LazyLinear", "generated/torch.nn.LeakyReLU", "generated/torch.nn.Linear", "generated/torch.nn.LocalResponseNorm", "generated/torch.nn.LogSigmoid", "generated/torch.nn.LogSoftmax", "generated/torch.nn.MSELoss", "generated/torch.nn.MarginRankingLoss", "generated/torch.nn.MaxPool1d", "generated/torch.nn.MaxPool2d", "generated/torch.nn.MaxPool3d", "generated/torch.nn.MaxUnpool1d", "generated/torch.nn.MaxUnpool2d", "generated/torch.nn.MaxUnpool3d", "generated/torch.nn.Mish", "generated/torch.nn.Module", "generated/torch.nn.ModuleDict", "generated/torch.nn.ModuleList", "generated/torch.nn.MultiLabelMarginLoss", "generated/torch.nn.MultiLabelSoftMarginLoss", "generated/torch.nn.MultiMarginLoss", "generated/torch.nn.MultiheadAttention", "generated/torch.nn.NLLLoss", "generated/torch.nn.PReLU", "generated/torch.nn.PairwiseDistance", "generated/torch.nn.ParameterDict", "generated/torch.nn.ParameterList", "generated/torch.nn.PixelShuffle", "generated/torch.nn.PixelUnshuffle", "generated/torch.nn.PoissonNLLLoss", "generated/torch.nn.RNN", "generated/torch.nn.RNNBase", "generated/torch.nn.RNNCell", "generated/torch.nn.RReLU", "generated/torch.nn.ReLU", "generated/torch.nn.ReLU6", "generated/torch.nn.ReflectionPad1d", "generated/torch.nn.ReflectionPad2d", "generated/torch.nn.ReflectionPad3d", "generated/torch.nn.ReplicationPad1d", "generated/torch.nn.ReplicationPad2d", "generated/torch.nn.ReplicationPad3d", "generated/torch.nn.SELU", "generated/torch.nn.Sequential", "generated/torch.nn.SiLU", "generated/torch.nn.Sigmoid", "generated/torch.nn.SmoothL1Loss", "generated/torch.nn.SoftMarginLoss", "generated/torch.nn.Softmax", "generated/torch.nn.Softmax2d", "generated/torch.nn.Softmin", "generated/torch.nn.Softplus", "generated/torch.nn.Softshrink", "generated/torch.nn.Softsign", "generated/torch.nn.SyncBatchNorm", "generated/torch.nn.Tanh", "generated/torch.nn.Tanhshrink", "generated/torch.nn.Threshold", "generated/torch.nn.Transformer", "generated/torch.nn.TransformerDecoder", "generated/torch.nn.TransformerDecoderLayer", "generated/torch.nn.TransformerEncoder", "generated/torch.nn.TransformerEncoderLayer", "generated/torch.nn.TripletMarginLoss", "generated/torch.nn.TripletMarginWithDistanceLoss", "generated/torch.nn.Unflatten", "generated/torch.nn.Unfold", "generated/torch.nn.Upsample", "generated/torch.nn.UpsamplingBilinear2d", "generated/torch.nn.UpsamplingNearest2d", "generated/torch.nn.ZeroPad2d", "generated/torch.nn.functional.adaptive_avg_pool1d", "generated/torch.nn.functional.adaptive_avg_pool2d", "generated/torch.nn.functional.adaptive_avg_pool3d", "generated/torch.nn.functional.adaptive_max_pool1d", "generated/torch.nn.functional.adaptive_max_pool2d", "generated/torch.nn.functional.adaptive_max_pool3d", "generated/torch.nn.functional.affine_grid", "generated/torch.nn.functional.alpha_dropout", "generated/torch.nn.functional.avg_pool1d", "generated/torch.nn.functional.avg_pool2d", "generated/torch.nn.functional.avg_pool3d", "generated/torch.nn.functional.batch_norm", "generated/torch.nn.functional.bilinear", "generated/torch.nn.functional.binary_cross_entropy", "generated/torch.nn.functional.binary_cross_entropy_with_logits", "generated/torch.nn.functional.celu", "generated/torch.nn.functional.conv1d", "generated/torch.nn.functional.conv2d", "generated/torch.nn.functional.conv3d", "generated/torch.nn.functional.conv_transpose1d", "generated/torch.nn.functional.conv_transpose2d", "generated/torch.nn.functional.conv_transpose3d", "generated/torch.nn.functional.cosine_embedding_loss", "generated/torch.nn.functional.cosine_similarity", "generated/torch.nn.functional.cross_entropy", "generated/torch.nn.functional.ctc_loss", "generated/torch.nn.functional.dropout", "generated/torch.nn.functional.dropout1d", "generated/torch.nn.functional.dropout2d", "generated/torch.nn.functional.dropout3d", "generated/torch.nn.functional.elu", "generated/torch.nn.functional.elu_", "generated/torch.nn.functional.embedding", "generated/torch.nn.functional.embedding_bag", "generated/torch.nn.functional.feature_alpha_dropout", "generated/torch.nn.functional.fold", "generated/torch.nn.functional.fractional_max_pool2d", "generated/torch.nn.functional.fractional_max_pool3d", "generated/torch.nn.functional.gaussian_nll_loss", "generated/torch.nn.functional.gelu", "generated/torch.nn.functional.glu", "generated/torch.nn.functional.grid_sample", "generated/torch.nn.functional.group_norm", "generated/torch.nn.functional.gumbel_softmax", "generated/torch.nn.functional.hardshrink", "generated/torch.nn.functional.hardsigmoid", "generated/torch.nn.functional.hardswish", "generated/torch.nn.functional.hardtanh", "generated/torch.nn.functional.hardtanh_", "generated/torch.nn.functional.hinge_embedding_loss", "generated/torch.nn.functional.huber_loss", "generated/torch.nn.functional.instance_norm", "generated/torch.nn.functional.interpolate", "generated/torch.nn.functional.kl_div", "generated/torch.nn.functional.l1_loss", "generated/torch.nn.functional.layer_norm", "generated/torch.nn.functional.leaky_relu", "generated/torch.nn.functional.leaky_relu_", "generated/torch.nn.functional.linear", "generated/torch.nn.functional.local_response_norm", "generated/torch.nn.functional.log_softmax", "generated/torch.nn.functional.logsigmoid", "generated/torch.nn.functional.lp_pool1d", "generated/torch.nn.functional.lp_pool2d", "generated/torch.nn.functional.margin_ranking_loss", "generated/torch.nn.functional.max_pool1d", "generated/torch.nn.functional.max_pool2d", "generated/torch.nn.functional.max_pool3d", "generated/torch.nn.functional.max_unpool1d", "generated/torch.nn.functional.max_unpool2d", "generated/torch.nn.functional.max_unpool3d", "generated/torch.nn.functional.mish", "generated/torch.nn.functional.mse_loss", "generated/torch.nn.functional.multi_margin_loss", "generated/torch.nn.functional.multilabel_margin_loss", "generated/torch.nn.functional.multilabel_soft_margin_loss", "generated/torch.nn.functional.nll_loss", "generated/torch.nn.functional.normalize", "generated/torch.nn.functional.one_hot", "generated/torch.nn.functional.pad", "generated/torch.nn.functional.pairwise_distance", "generated/torch.nn.functional.pdist", "generated/torch.nn.functional.pixel_shuffle", "generated/torch.nn.functional.pixel_unshuffle", "generated/torch.nn.functional.poisson_nll_loss", "generated/torch.nn.functional.prelu", "generated/torch.nn.functional.relu", "generated/torch.nn.functional.relu6", "generated/torch.nn.functional.relu_", "generated/torch.nn.functional.rrelu", "generated/torch.nn.functional.rrelu_", "generated/torch.nn.functional.selu", "generated/torch.nn.functional.sigmoid", "generated/torch.nn.functional.silu", "generated/torch.nn.functional.smooth_l1_loss", "generated/torch.nn.functional.soft_margin_loss", "generated/torch.nn.functional.softmax", "generated/torch.nn.functional.softmin", "generated/torch.nn.functional.softplus", "generated/torch.nn.functional.softshrink", "generated/torch.nn.functional.softsign", "generated/torch.nn.functional.tanh", "generated/torch.nn.functional.tanhshrink", "generated/torch.nn.functional.threshold", "generated/torch.nn.functional.threshold_", "generated/torch.nn.functional.torch.nn.parallel.data_parallel", "generated/torch.nn.functional.triplet_margin_loss", "generated/torch.nn.functional.triplet_margin_with_distance_loss", "generated/torch.nn.functional.unfold", "generated/torch.nn.functional.upsample", "generated/torch.nn.functional.upsample_bilinear", "generated/torch.nn.functional.upsample_nearest", "generated/torch.nn.intrinsic.BNReLU2d", "generated/torch.nn.intrinsic.BNReLU3d", "generated/torch.nn.intrinsic.ConvBn1d", "generated/torch.nn.intrinsic.ConvBn2d", "generated/torch.nn.intrinsic.ConvBn3d", "generated/torch.nn.intrinsic.ConvBnReLU1d", "generated/torch.nn.intrinsic.ConvBnReLU2d", "generated/torch.nn.intrinsic.ConvBnReLU3d", "generated/torch.nn.intrinsic.ConvReLU1d", "generated/torch.nn.intrinsic.ConvReLU2d", "generated/torch.nn.intrinsic.ConvReLU3d", "generated/torch.nn.intrinsic.LinearReLU", "generated/torch.nn.intrinsic.qat.ConvBn1d", "generated/torch.nn.intrinsic.qat.ConvBn2d", "generated/torch.nn.intrinsic.qat.ConvBn3d", "generated/torch.nn.intrinsic.qat.ConvBnReLU1d", "generated/torch.nn.intrinsic.qat.ConvBnReLU2d", "generated/torch.nn.intrinsic.qat.ConvBnReLU3d", "generated/torch.nn.intrinsic.qat.ConvReLU2d", "generated/torch.nn.intrinsic.qat.ConvReLU3d", "generated/torch.nn.intrinsic.qat.LinearReLU", "generated/torch.nn.intrinsic.qat.freeze_bn_stats", "generated/torch.nn.intrinsic.qat.update_bn_stats", "generated/torch.nn.intrinsic.quantized.BNReLU2d", "generated/torch.nn.intrinsic.quantized.BNReLU3d", "generated/torch.nn.intrinsic.quantized.ConvReLU1d", "generated/torch.nn.intrinsic.quantized.ConvReLU2d", "generated/torch.nn.intrinsic.quantized.ConvReLU3d", "generated/torch.nn.intrinsic.quantized.LinearReLU", "generated/torch.nn.intrinsic.quantized.dynamic.LinearReLU", "generated/torch.nn.modules.lazy.LazyModuleMixin", "generated/torch.nn.modules.module.register_module_backward_hook", "generated/torch.nn.modules.module.register_module_forward_hook", "generated/torch.nn.modules.module.register_module_forward_pre_hook", "generated/torch.nn.modules.module.register_module_full_backward_hook", "generated/torch.nn.parallel.DistributedDataParallel", "generated/torch.nn.parameter.Parameter", "generated/torch.nn.parameter.UninitializedBuffer", "generated/torch.nn.parameter.UninitializedParameter", "generated/torch.nn.qat.Conv2d", "generated/torch.nn.qat.Conv3d", "generated/torch.nn.qat.Linear", "generated/torch.nn.qat.dynamic.Linear", "generated/torch.nn.quantizable.LSTM", "generated/torch.nn.quantizable.MultiheadAttention", "generated/torch.nn.quantized.BatchNorm2d", "generated/torch.nn.quantized.BatchNorm3d", "generated/torch.nn.quantized.Conv1d", "generated/torch.nn.quantized.Conv2d", "generated/torch.nn.quantized.Conv3d", "generated/torch.nn.quantized.ConvTranspose1d", "generated/torch.nn.quantized.ConvTranspose2d", "generated/torch.nn.quantized.ConvTranspose3d", "generated/torch.nn.quantized.ELU", "generated/torch.nn.quantized.Embedding", "generated/torch.nn.quantized.EmbeddingBag", "generated/torch.nn.quantized.FXFloatFunctional", "generated/torch.nn.quantized.FloatFunctional", "generated/torch.nn.quantized.GroupNorm", "generated/torch.nn.quantized.Hardswish", "generated/torch.nn.quantized.InstanceNorm1d", "generated/torch.nn.quantized.InstanceNorm2d", "generated/torch.nn.quantized.InstanceNorm3d", "generated/torch.nn.quantized.LayerNorm", "generated/torch.nn.quantized.LeakyReLU", "generated/torch.nn.quantized.Linear", "generated/torch.nn.quantized.QFunctional", "generated/torch.nn.quantized.ReLU6", "generated/torch.nn.quantized.Sigmoid", "generated/torch.nn.quantized.dynamic.GRU", "generated/torch.nn.quantized.dynamic.GRUCell", "generated/torch.nn.quantized.dynamic.LSTM", "generated/torch.nn.quantized.dynamic.LSTMCell", "generated/torch.nn.quantized.dynamic.Linear", "generated/torch.nn.quantized.dynamic.RNNCell", "generated/torch.nn.quantized.functional.adaptive_avg_pool2d", "generated/torch.nn.quantized.functional.adaptive_avg_pool3d", "generated/torch.nn.quantized.functional.avg_pool2d", "generated/torch.nn.quantized.functional.avg_pool3d", "generated/torch.nn.quantized.functional.celu", "generated/torch.nn.quantized.functional.clamp", "generated/torch.nn.quantized.functional.conv1d", "generated/torch.nn.quantized.functional.conv2d", "generated/torch.nn.quantized.functional.conv3d", "generated/torch.nn.quantized.functional.elu", "generated/torch.nn.quantized.functional.hardsigmoid", "generated/torch.nn.quantized.functional.hardswish", "generated/torch.nn.quantized.functional.hardtanh", "generated/torch.nn.quantized.functional.interpolate", "generated/torch.nn.quantized.functional.leaky_relu", "generated/torch.nn.quantized.functional.linear", "generated/torch.nn.quantized.functional.max_pool1d", "generated/torch.nn.quantized.functional.max_pool2d", "generated/torch.nn.quantized.functional.threshold", "generated/torch.nn.quantized.functional.upsample", "generated/torch.nn.quantized.functional.upsample_bilinear", "generated/torch.nn.quantized.functional.upsample_nearest", "generated/torch.nn.utils.clip_grad_norm_", "generated/torch.nn.utils.clip_grad_value_", "generated/torch.nn.utils.parameters_to_vector", "generated/torch.nn.utils.parametrizations.orthogonal", "generated/torch.nn.utils.parametrizations.spectral_norm", "generated/torch.nn.utils.parametrize.ParametrizationList", "generated/torch.nn.utils.parametrize.cached", "generated/torch.nn.utils.parametrize.is_parametrized", "generated/torch.nn.utils.parametrize.register_parametrization", "generated/torch.nn.utils.parametrize.remove_parametrizations", "generated/torch.nn.utils.prune.BasePruningMethod", "generated/torch.nn.utils.prune.CustomFromMask", "generated/torch.nn.utils.prune.Identity", "generated/torch.nn.utils.prune.L1Unstructured", "generated/torch.nn.utils.prune.LnStructured", "generated/torch.nn.utils.prune.PruningContainer", "generated/torch.nn.utils.prune.RandomStructured", "generated/torch.nn.utils.prune.RandomUnstructured", "generated/torch.nn.utils.prune.custom_from_mask", "generated/torch.nn.utils.prune.global_unstructured", "generated/torch.nn.utils.prune.identity", "generated/torch.nn.utils.prune.is_pruned", "generated/torch.nn.utils.prune.l1_unstructured", "generated/torch.nn.utils.prune.ln_structured", "generated/torch.nn.utils.prune.random_structured", "generated/torch.nn.utils.prune.random_unstructured", "generated/torch.nn.utils.prune.remove", "generated/torch.nn.utils.remove_spectral_norm", "generated/torch.nn.utils.remove_weight_norm", "generated/torch.nn.utils.rnn.PackedSequence", "generated/torch.nn.utils.rnn.pack_padded_sequence", "generated/torch.nn.utils.rnn.pack_sequence", "generated/torch.nn.utils.rnn.pad_packed_sequence", "generated/torch.nn.utils.rnn.pad_sequence", "generated/torch.nn.utils.skip_init", "generated/torch.nn.utils.spectral_norm", "generated/torch.nn.utils.stateless.functional_call", "generated/torch.nn.utils.vector_to_parameters", "generated/torch.nn.utils.weight_norm", "generated/torch.no_grad", "generated/torch.nonzero", "generated/torch.norm", "generated/torch.normal", "generated/torch.not_equal", "generated/torch.numel", "generated/torch.ones", "generated/torch.ones_like", "generated/torch.onnx.JitScalarType", "generated/torch.onnx.SymbolicContext", "generated/torch.optim.ASGD", "generated/torch.optim.Adadelta", "generated/torch.optim.Adagrad", "generated/torch.optim.Adam", "generated/torch.optim.AdamW", "generated/torch.optim.Adamax", "generated/torch.optim.LBFGS", "generated/torch.optim.NAdam", "generated/torch.optim.Optimizer.add_param_group", "generated/torch.optim.Optimizer.load_state_dict", "generated/torch.optim.Optimizer.state_dict", "generated/torch.optim.Optimizer.step", "generated/torch.optim.Optimizer.zero_grad", "generated/torch.optim.RAdam", "generated/torch.optim.RMSprop", "generated/torch.optim.Rprop", "generated/torch.optim.SGD", "generated/torch.optim.SparseAdam", "generated/torch.optim.lr_scheduler.ChainedScheduler", "generated/torch.optim.lr_scheduler.ConstantLR", "generated/torch.optim.lr_scheduler.CosineAnnealingLR", "generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts", "generated/torch.optim.lr_scheduler.CyclicLR", "generated/torch.optim.lr_scheduler.ExponentialLR", "generated/torch.optim.lr_scheduler.LambdaLR", "generated/torch.optim.lr_scheduler.LinearLR", "generated/torch.optim.lr_scheduler.MultiStepLR", "generated/torch.optim.lr_scheduler.MultiplicativeLR", "generated/torch.optim.lr_scheduler.OneCycleLR", "generated/torch.optim.lr_scheduler.ReduceLROnPlateau", "generated/torch.optim.lr_scheduler.SequentialLR", "generated/torch.optim.lr_scheduler.StepLR", "generated/torch.orgqr", "generated/torch.ormqr", "generated/torch.outer", "generated/torch.pca_lowrank", "generated/torch.permute", "generated/torch.pinverse", "generated/torch.poisson", "generated/torch.polar", "generated/torch.polygamma", "generated/torch.positive", "generated/torch.pow", "generated/torch.prod", "generated/torch.promote_types", "generated/torch.qr", "generated/torch.quantile", "generated/torch.quantization.DeQuantStub", "generated/torch.quantization.QuantStub", "generated/torch.quantization.QuantWrapper", "generated/torch.quantization.add_observer_", "generated/torch.quantization.add_quant_dequant", "generated/torch.quantization.convert", "generated/torch.quantization.default_eval_fn", "generated/torch.quantization.fake_quantize.FakeQuantize", "generated/torch.quantization.fake_quantize.FakeQuantizeBase", "generated/torch.quantization.fake_quantize.FixedQParamsFakeQuantize", "generated/torch.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize", "generated/torch.quantization.fake_quantize.default_fake_quant", "generated/torch.quantization.fake_quantize.default_fused_act_fake_quant", "generated/torch.quantization.fake_quantize.default_fused_per_channel_wt_fake_quant", "generated/torch.quantization.fake_quantize.default_fused_wt_fake_quant", "generated/torch.quantization.fake_quantize.default_histogram_fake_quant", "generated/torch.quantization.fake_quantize.default_per_channel_weight_fake_quant", "generated/torch.quantization.fake_quantize.default_weight_fake_quant", "generated/torch.quantization.fake_quantize.disable_fake_quant", "generated/torch.quantization.fake_quantize.disable_observer", "generated/torch.quantization.fake_quantize.enable_fake_quant", "generated/torch.quantization.fake_quantize.enable_observer", "generated/torch.quantization.fuse_modules", "generated/torch.quantization.get_observer_dict", "generated/torch.quantization.observer.HistogramObserver", "generated/torch.quantization.observer.MinMaxObserver", "generated/torch.quantization.observer.MovingAverageMinMaxObserver", "generated/torch.quantization.observer.MovingAveragePerChannelMinMaxObserver", "generated/torch.quantization.observer.NoopObserver", "generated/torch.quantization.observer.ObserverBase", "generated/torch.quantization.observer.PerChannelMinMaxObserver", "generated/torch.quantization.observer.PlaceholderObserver", "generated/torch.quantization.observer.RecordingObserver", "generated/torch.quantization.observer.default_debug_observer", "generated/torch.quantization.observer.default_dynamic_quant_observer", "generated/torch.quantization.observer.default_float_qparams_observer", "generated/torch.quantization.observer.default_histogram_observer", "generated/torch.quantization.observer.default_observer", "generated/torch.quantization.observer.default_per_channel_weight_observer", "generated/torch.quantization.observer.default_placeholder_observer", "generated/torch.quantization.observer.default_weight_observer", "generated/torch.quantization.observer.get_observer_state_dict", "generated/torch.quantization.observer.load_observer_state_dict", "generated/torch.quantization.prepare", "generated/torch.quantization.prepare_qat", "generated/torch.quantization.propagate_qconfig_", "generated/torch.quantization.qconfig.QConfig", "generated/torch.quantization.qconfig.default_activation_only_qconfig", "generated/torch.quantization.qconfig.default_debug_qconfig", "generated/torch.quantization.qconfig.default_dynamic_qconfig", "generated/torch.quantization.qconfig.default_per_channel_qconfig", "generated/torch.quantization.qconfig.default_qat_qconfig", "generated/torch.quantization.qconfig.default_qat_qconfig_v2", "generated/torch.quantization.qconfig.default_qconfig", "generated/torch.quantization.qconfig.default_weight_only_qconfig", "generated/torch.quantization.qconfig.float16_dynamic_qconfig", "generated/torch.quantization.qconfig.float16_static_qconfig", "generated/torch.quantization.qconfig.float_qparams_weight_only_qconfig", "generated/torch.quantization.qconfig.per_channel_dynamic_qconfig", "generated/torch.quantization.quantize", "generated/torch.quantization.quantize_dynamic", "generated/torch.quantization.quantize_fx.convert_fx", "generated/torch.quantization.quantize_fx.fuse_fx", "generated/torch.quantization.quantize_fx.prepare_fx", "generated/torch.quantization.quantize_fx.prepare_qat_fx", "generated/torch.quantization.quantize_qat", "generated/torch.quantization.swap_module", "generated/torch.quantize_per_channel", "generated/torch.quantize_per_tensor", "generated/torch.quantized_batch_norm", "generated/torch.quantized_max_pool1d", "generated/torch.quantized_max_pool2d", "generated/torch.quasirandom.SobolEngine", "generated/torch.rad2deg", "generated/torch.rand", "generated/torch.rand_like", "generated/torch.randint", "generated/torch.randint_like", "generated/torch.randn", "generated/torch.randn_like", "generated/torch.randperm", "generated/torch.range", "generated/torch.ravel", "generated/torch.real", "generated/torch.reciprocal", "generated/torch.remainder", "generated/torch.renorm", "generated/torch.repeat_interleave", "generated/torch.reshape", "generated/torch.resolve_conj", "generated/torch.resolve_neg", "generated/torch.result_type", "generated/torch.roll", "generated/torch.rot90", "generated/torch.round", "generated/torch.row_stack", "generated/torch.rsqrt", "generated/torch.save", "generated/torch.scatter", "generated/torch.scatter_add", "generated/torch.scatter_reduce", "generated/torch.searchsorted", "generated/torch.seed", "generated/torch.select", "generated/torch.select_scatter", "generated/torch.set_default_dtype", "generated/torch.set_default_tensor_type", "generated/torch.set_deterministic_debug_mode", "generated/torch.set_float32_matmul_precision", "generated/torch.set_flush_denormal", "generated/torch.set_grad_enabled", "generated/torch.set_num_interop_threads", "generated/torch.set_num_threads", "generated/torch.set_printoptions", "generated/torch.set_rng_state", "generated/torch.set_warn_always", "generated/torch.sgn", "generated/torch.sigmoid", "generated/torch.sign", "generated/torch.signbit", "generated/torch.sin", "generated/torch.sinc", "generated/torch.sinh", "generated/torch.slice_scatter", "generated/torch.slogdet", "generated/torch.smm", "generated/torch.sort", "generated/torch.sparse.addmm", "generated/torch.sparse.log_softmax", "generated/torch.sparse.mm", "generated/torch.sparse.sampled_addmm", "generated/torch.sparse.softmax", "generated/torch.sparse.spdiags", "generated/torch.sparse.sum", "generated/torch.sparse_bsc_tensor", "generated/torch.sparse_bsr_tensor", "generated/torch.sparse_compressed_tensor", "generated/torch.sparse_coo_tensor", "generated/torch.sparse_csc_tensor", "generated/torch.sparse_csr_tensor", "generated/torch.split", "generated/torch.sqrt", "generated/torch.square", "generated/torch.squeeze", "generated/torch.sspaddmm", "generated/torch.stack", "generated/torch.std", "generated/torch.std_mean", "generated/torch.stft", "generated/torch.sub", "generated/torch.subtract", "generated/torch.sum", "generated/torch.svd", "generated/torch.svd_lowrank", "generated/torch.swapaxes", "generated/torch.swapdims", "generated/torch.symeig", "generated/torch.t", "generated/torch.take", "generated/torch.take_along_dim", "generated/torch.tan", "generated/torch.tanh", "generated/torch.tensor", "generated/torch.tensor_split", "generated/torch.tensordot", "generated/torch.tile", "generated/torch.topk", "generated/torch.trace", "generated/torch.transpose", "generated/torch.trapezoid", "generated/torch.trapz", "generated/torch.triangular_solve", "generated/torch.tril", "generated/torch.tril_indices", "generated/torch.triu", "generated/torch.triu_indices", "generated/torch.true_divide", "generated/torch.trunc", "generated/torch.unbind", "generated/torch.unflatten", "generated/torch.unique", "generated/torch.unique_consecutive", "generated/torch.unsqueeze", "generated/torch.use_deterministic_algorithms", "generated/torch.vander", "generated/torch.var", "generated/torch.var_mean", "generated/torch.vdot", "generated/torch.view_as_complex", "generated/torch.view_as_real", "generated/torch.vmap", "generated/torch.vsplit", "generated/torch.vstack", "generated/torch.where", "generated/torch.xlogy", "generated/torch.zeros", "generated/torch.zeros_like", "hub", "index", "jit", "jit_builtin_functions", "jit_language_reference", "jit_language_reference_v2", "jit_python_reference", "jit_unsupported", "jit_utils", "library", "linalg", "mobile_optimizer", "model_zoo", "monitor", "multiprocessing", "name_inference", "named_tensor", "nested", "nn", "nn.functional", "nn.init", "notes/amp_examples", "notes/autograd", "notes/broadcasting", "notes/cpu_threading_torchscript_inference", "notes/cuda", "notes/ddp", "notes/extending", "notes/faq", "notes/gradcheck", "notes/hip", "notes/large_scale_deployments", "notes/modules", "notes/mps", "notes/multiprocessing", "notes/numerical_accuracy", "notes/randomness", "notes/serialization", "notes/windows", "onnx", "onnx_supported_aten_ops", "optim", "package", "pipeline", "profiler", "quantization", "quantization-accuracy-debugging", "quantization-backend-configuration", "quantization-support", "random", "rpc", "rpc/distributed_autograd", "rpc/rref", "sparse", "special", "storage", "tensor_attributes", "tensor_view", "tensorboard", "tensors", "testing", "torch", "torch.ao.ns._numeric_suite", "torch.ao.ns._numeric_suite_fx", "torch.overrides", "type_info"], "filenames": ["amp.rst", "autograd.rst", "backends.rst", "benchmark_utils.rst", "bottleneck.rst", "checkpoint.rst", "community/contribution_guide.rst", "community/design.rst", "community/governance.rst", "community/persons_of_interest.rst", "complex_numbers.rst", "config_mod.rst", "cpp_extension.rst", "cpp_index.rst", "cuda.rst", "cudnn_persistent_rnn.rst", "cudnn_rnn_determinism.rst", "data.rst", "ddp_comm_hooks.rst", "deploy.rst", "distributed.rst", "distributed.algorithms.join.rst", "distributed.elastic.rst", "distributed.optim.rst", "distributions.rst", "dlpack.rst", "elastic/agent.rst", "elastic/customization.rst", "elastic/errors.rst", "elastic/events.rst", "elastic/examples.rst", "elastic/kubernetes.rst", "elastic/metrics.rst", "elastic/multiprocessing.rst", "elastic/quickstart.rst", "elastic/rendezvous.rst", "elastic/run.rst", "elastic/timer.rst", "elastic/train_script.rst", "fft.rst", "fsdp.rst", "futures.rst", "fx.rst", "generated/torch.Generator.rst", "generated/torch.Tensor.abs.rst", "generated/torch.Tensor.abs_.rst", "generated/torch.Tensor.absolute.rst", "generated/torch.Tensor.absolute_.rst", "generated/torch.Tensor.acos.rst", "generated/torch.Tensor.acos_.rst", "generated/torch.Tensor.acosh.rst", "generated/torch.Tensor.acosh_.rst", "generated/torch.Tensor.add.rst", "generated/torch.Tensor.add_.rst", "generated/torch.Tensor.addbmm.rst", "generated/torch.Tensor.addbmm_.rst", "generated/torch.Tensor.addcdiv.rst", "generated/torch.Tensor.addcdiv_.rst", "generated/torch.Tensor.addcmul.rst", "generated/torch.Tensor.addcmul_.rst", "generated/torch.Tensor.addmm.rst", "generated/torch.Tensor.addmm_.rst", "generated/torch.Tensor.addmv.rst", "generated/torch.Tensor.addmv_.rst", "generated/torch.Tensor.addr.rst", "generated/torch.Tensor.addr_.rst", "generated/torch.Tensor.adjoint.rst", "generated/torch.Tensor.all.rst", "generated/torch.Tensor.allclose.rst", "generated/torch.Tensor.amax.rst", "generated/torch.Tensor.amin.rst", "generated/torch.Tensor.aminmax.rst", "generated/torch.Tensor.angle.rst", "generated/torch.Tensor.any.rst", "generated/torch.Tensor.apply_.rst", "generated/torch.Tensor.arccos.rst", "generated/torch.Tensor.arccos_.rst", "generated/torch.Tensor.arccosh.rst", "generated/torch.Tensor.arccosh_.rst", "generated/torch.Tensor.arcsin.rst", "generated/torch.Tensor.arcsin_.rst", "generated/torch.Tensor.arcsinh.rst", "generated/torch.Tensor.arcsinh_.rst", "generated/torch.Tensor.arctan.rst", "generated/torch.Tensor.arctan2.rst", "generated/torch.Tensor.arctan2_.rst", "generated/torch.Tensor.arctan_.rst", "generated/torch.Tensor.arctanh.rst", "generated/torch.Tensor.arctanh_.rst", "generated/torch.Tensor.argmax.rst", "generated/torch.Tensor.argmin.rst", "generated/torch.Tensor.argsort.rst", "generated/torch.Tensor.argwhere.rst", "generated/torch.Tensor.as_strided.rst", "generated/torch.Tensor.as_subclass.rst", "generated/torch.Tensor.asin.rst", "generated/torch.Tensor.asin_.rst", "generated/torch.Tensor.asinh.rst", "generated/torch.Tensor.asinh_.rst", "generated/torch.Tensor.atan.rst", "generated/torch.Tensor.atan2.rst", "generated/torch.Tensor.atan2_.rst", "generated/torch.Tensor.atan_.rst", "generated/torch.Tensor.atanh.rst", "generated/torch.Tensor.atanh_.rst", "generated/torch.Tensor.backward.rst", "generated/torch.Tensor.baddbmm.rst", "generated/torch.Tensor.baddbmm_.rst", "generated/torch.Tensor.bernoulli.rst", "generated/torch.Tensor.bernoulli_.rst", "generated/torch.Tensor.bfloat16.rst", "generated/torch.Tensor.bincount.rst", "generated/torch.Tensor.bitwise_and.rst", "generated/torch.Tensor.bitwise_and_.rst", "generated/torch.Tensor.bitwise_left_shift.rst", "generated/torch.Tensor.bitwise_left_shift_.rst", "generated/torch.Tensor.bitwise_not.rst", "generated/torch.Tensor.bitwise_not_.rst", "generated/torch.Tensor.bitwise_or.rst", "generated/torch.Tensor.bitwise_or_.rst", "generated/torch.Tensor.bitwise_right_shift.rst", "generated/torch.Tensor.bitwise_right_shift_.rst", "generated/torch.Tensor.bitwise_xor.rst", "generated/torch.Tensor.bitwise_xor_.rst", "generated/torch.Tensor.bmm.rst", "generated/torch.Tensor.bool.rst", "generated/torch.Tensor.broadcast_to.rst", "generated/torch.Tensor.byte.rst", "generated/torch.Tensor.cauchy_.rst", "generated/torch.Tensor.ccol_indices.rst", "generated/torch.Tensor.cdouble.rst", "generated/torch.Tensor.ceil.rst", "generated/torch.Tensor.ceil_.rst", "generated/torch.Tensor.cfloat.rst", "generated/torch.Tensor.chalf.rst", "generated/torch.Tensor.char.rst", "generated/torch.Tensor.cholesky.rst", "generated/torch.Tensor.cholesky_inverse.rst", "generated/torch.Tensor.cholesky_solve.rst", "generated/torch.Tensor.chunk.rst", "generated/torch.Tensor.clamp.rst", "generated/torch.Tensor.clamp_.rst", "generated/torch.Tensor.clip.rst", "generated/torch.Tensor.clip_.rst", "generated/torch.Tensor.clone.rst", "generated/torch.Tensor.coalesce.rst", "generated/torch.Tensor.col_indices.rst", "generated/torch.Tensor.conj.rst", "generated/torch.Tensor.conj_physical.rst", "generated/torch.Tensor.conj_physical_.rst", "generated/torch.Tensor.contiguous.rst", "generated/torch.Tensor.copy_.rst", "generated/torch.Tensor.copysign.rst", "generated/torch.Tensor.copysign_.rst", "generated/torch.Tensor.corrcoef.rst", "generated/torch.Tensor.cos.rst", "generated/torch.Tensor.cos_.rst", "generated/torch.Tensor.cosh.rst", "generated/torch.Tensor.cosh_.rst", "generated/torch.Tensor.count_nonzero.rst", "generated/torch.Tensor.cov.rst", "generated/torch.Tensor.cpu.rst", "generated/torch.Tensor.cross.rst", "generated/torch.Tensor.crow_indices.rst", "generated/torch.Tensor.cuda.rst", "generated/torch.Tensor.cummax.rst", "generated/torch.Tensor.cummin.rst", "generated/torch.Tensor.cumprod.rst", "generated/torch.Tensor.cumprod_.rst", "generated/torch.Tensor.cumsum.rst", "generated/torch.Tensor.cumsum_.rst", "generated/torch.Tensor.data_ptr.rst", "generated/torch.Tensor.deg2rad.rst", "generated/torch.Tensor.dense_dim.rst", "generated/torch.Tensor.dequantize.rst", "generated/torch.Tensor.det.rst", "generated/torch.Tensor.detach.rst", "generated/torch.Tensor.detach_.rst", "generated/torch.Tensor.device.rst", "generated/torch.Tensor.diag.rst", "generated/torch.Tensor.diag_embed.rst", "generated/torch.Tensor.diagflat.rst", "generated/torch.Tensor.diagonal.rst", "generated/torch.Tensor.diagonal_scatter.rst", "generated/torch.Tensor.diff.rst", "generated/torch.Tensor.digamma.rst", "generated/torch.Tensor.digamma_.rst", "generated/torch.Tensor.dim.rst", "generated/torch.Tensor.dist.rst", "generated/torch.Tensor.div.rst", "generated/torch.Tensor.div_.rst", "generated/torch.Tensor.divide.rst", "generated/torch.Tensor.divide_.rst", "generated/torch.Tensor.dot.rst", "generated/torch.Tensor.double.rst", "generated/torch.Tensor.dsplit.rst", "generated/torch.Tensor.eig.rst", "generated/torch.Tensor.element_size.rst", "generated/torch.Tensor.eq.rst", "generated/torch.Tensor.eq_.rst", "generated/torch.Tensor.equal.rst", "generated/torch.Tensor.erf.rst", "generated/torch.Tensor.erf_.rst", "generated/torch.Tensor.erfc.rst", "generated/torch.Tensor.erfc_.rst", "generated/torch.Tensor.erfinv.rst", "generated/torch.Tensor.erfinv_.rst", "generated/torch.Tensor.exp.rst", "generated/torch.Tensor.exp_.rst", "generated/torch.Tensor.expand.rst", "generated/torch.Tensor.expand_as.rst", "generated/torch.Tensor.expm1.rst", "generated/torch.Tensor.expm1_.rst", "generated/torch.Tensor.exponential_.rst", "generated/torch.Tensor.fill_.rst", "generated/torch.Tensor.fill_diagonal_.rst", "generated/torch.Tensor.fix.rst", "generated/torch.Tensor.fix_.rst", "generated/torch.Tensor.flatten.rst", "generated/torch.Tensor.flip.rst", "generated/torch.Tensor.fliplr.rst", "generated/torch.Tensor.flipud.rst", "generated/torch.Tensor.float.rst", "generated/torch.Tensor.float_power.rst", "generated/torch.Tensor.float_power_.rst", "generated/torch.Tensor.floor.rst", "generated/torch.Tensor.floor_.rst", "generated/torch.Tensor.floor_divide.rst", "generated/torch.Tensor.floor_divide_.rst", "generated/torch.Tensor.fmax.rst", "generated/torch.Tensor.fmin.rst", "generated/torch.Tensor.fmod.rst", "generated/torch.Tensor.fmod_.rst", "generated/torch.Tensor.frac.rst", "generated/torch.Tensor.frac_.rst", "generated/torch.Tensor.frexp.rst", "generated/torch.Tensor.gather.rst", "generated/torch.Tensor.gcd.rst", "generated/torch.Tensor.gcd_.rst", "generated/torch.Tensor.ge.rst", "generated/torch.Tensor.ge_.rst", "generated/torch.Tensor.geometric_.rst", "generated/torch.Tensor.geqrf.rst", "generated/torch.Tensor.ger.rst", "generated/torch.Tensor.get_device.rst", "generated/torch.Tensor.grad.rst", "generated/torch.Tensor.greater.rst", "generated/torch.Tensor.greater_.rst", "generated/torch.Tensor.greater_equal.rst", "generated/torch.Tensor.greater_equal_.rst", "generated/torch.Tensor.gt.rst", "generated/torch.Tensor.gt_.rst", "generated/torch.Tensor.half.rst", "generated/torch.Tensor.hardshrink.rst", "generated/torch.Tensor.heaviside.rst", "generated/torch.Tensor.histc.rst", "generated/torch.Tensor.histogram.rst", "generated/torch.Tensor.hsplit.rst", "generated/torch.Tensor.hypot.rst", "generated/torch.Tensor.hypot_.rst", "generated/torch.Tensor.i0.rst", "generated/torch.Tensor.i0_.rst", "generated/torch.Tensor.igamma.rst", "generated/torch.Tensor.igamma_.rst", "generated/torch.Tensor.igammac.rst", "generated/torch.Tensor.igammac_.rst", "generated/torch.Tensor.imag.rst", "generated/torch.Tensor.index_add.rst", "generated/torch.Tensor.index_add_.rst", "generated/torch.Tensor.index_copy.rst", "generated/torch.Tensor.index_copy_.rst", "generated/torch.Tensor.index_fill.rst", "generated/torch.Tensor.index_fill_.rst", "generated/torch.Tensor.index_put.rst", "generated/torch.Tensor.index_put_.rst", "generated/torch.Tensor.index_reduce.rst", "generated/torch.Tensor.index_reduce_.rst", "generated/torch.Tensor.index_select.rst", "generated/torch.Tensor.indices.rst", "generated/torch.Tensor.inner.rst", "generated/torch.Tensor.int.rst", "generated/torch.Tensor.int_repr.rst", "generated/torch.Tensor.inverse.rst", "generated/torch.Tensor.is_coalesced.rst", "generated/torch.Tensor.is_complex.rst", "generated/torch.Tensor.is_conj.rst", "generated/torch.Tensor.is_contiguous.rst", "generated/torch.Tensor.is_cuda.rst", "generated/torch.Tensor.is_floating_point.rst", "generated/torch.Tensor.is_inference.rst", "generated/torch.Tensor.is_leaf.rst", "generated/torch.Tensor.is_meta.rst", "generated/torch.Tensor.is_pinned.rst", "generated/torch.Tensor.is_quantized.rst", "generated/torch.Tensor.is_set_to.rst", "generated/torch.Tensor.is_shared.rst", "generated/torch.Tensor.is_signed.rst", "generated/torch.Tensor.is_sparse.rst", "generated/torch.Tensor.is_sparse_csr.rst", "generated/torch.Tensor.isclose.rst", "generated/torch.Tensor.isfinite.rst", "generated/torch.Tensor.isinf.rst", "generated/torch.Tensor.isnan.rst", "generated/torch.Tensor.isneginf.rst", "generated/torch.Tensor.isposinf.rst", "generated/torch.Tensor.isreal.rst", "generated/torch.Tensor.istft.rst", "generated/torch.Tensor.item.rst", "generated/torch.Tensor.kthvalue.rst", "generated/torch.Tensor.lcm.rst", "generated/torch.Tensor.lcm_.rst", "generated/torch.Tensor.ldexp.rst", "generated/torch.Tensor.ldexp_.rst", "generated/torch.Tensor.le.rst", "generated/torch.Tensor.le_.rst", "generated/torch.Tensor.lerp.rst", "generated/torch.Tensor.lerp_.rst", "generated/torch.Tensor.less.rst", "generated/torch.Tensor.less_.rst", "generated/torch.Tensor.less_equal.rst", "generated/torch.Tensor.less_equal_.rst", "generated/torch.Tensor.lgamma.rst", "generated/torch.Tensor.lgamma_.rst", "generated/torch.Tensor.log.rst", "generated/torch.Tensor.log10.rst", "generated/torch.Tensor.log10_.rst", "generated/torch.Tensor.log1p.rst", "generated/torch.Tensor.log1p_.rst", "generated/torch.Tensor.log2.rst", "generated/torch.Tensor.log2_.rst", "generated/torch.Tensor.log_.rst", "generated/torch.Tensor.log_normal_.rst", "generated/torch.Tensor.logaddexp.rst", "generated/torch.Tensor.logaddexp2.rst", "generated/torch.Tensor.logcumsumexp.rst", "generated/torch.Tensor.logdet.rst", "generated/torch.Tensor.logical_and.rst", "generated/torch.Tensor.logical_and_.rst", "generated/torch.Tensor.logical_not.rst", "generated/torch.Tensor.logical_not_.rst", "generated/torch.Tensor.logical_or.rst", "generated/torch.Tensor.logical_or_.rst", "generated/torch.Tensor.logical_xor.rst", "generated/torch.Tensor.logical_xor_.rst", "generated/torch.Tensor.logit.rst", "generated/torch.Tensor.logit_.rst", "generated/torch.Tensor.logsumexp.rst", "generated/torch.Tensor.long.rst", "generated/torch.Tensor.lstsq.rst", "generated/torch.Tensor.lt.rst", "generated/torch.Tensor.lt_.rst", "generated/torch.Tensor.lu.rst", "generated/torch.Tensor.lu_solve.rst", "generated/torch.Tensor.map_.rst", "generated/torch.Tensor.masked_fill.rst", "generated/torch.Tensor.masked_fill_.rst", "generated/torch.Tensor.masked_scatter.rst", "generated/torch.Tensor.masked_scatter_.rst", "generated/torch.Tensor.masked_select.rst", "generated/torch.Tensor.matmul.rst", "generated/torch.Tensor.matrix_exp.rst", "generated/torch.Tensor.matrix_power.rst", "generated/torch.Tensor.max.rst", "generated/torch.Tensor.maximum.rst", "generated/torch.Tensor.mean.rst", "generated/torch.Tensor.median.rst", "generated/torch.Tensor.min.rst", "generated/torch.Tensor.minimum.rst", "generated/torch.Tensor.mm.rst", "generated/torch.Tensor.mode.rst", "generated/torch.Tensor.moveaxis.rst", "generated/torch.Tensor.movedim.rst", "generated/torch.Tensor.msort.rst", "generated/torch.Tensor.mul.rst", "generated/torch.Tensor.mul_.rst", "generated/torch.Tensor.multinomial.rst", "generated/torch.Tensor.multiply.rst", "generated/torch.Tensor.multiply_.rst", "generated/torch.Tensor.mv.rst", "generated/torch.Tensor.mvlgamma.rst", "generated/torch.Tensor.mvlgamma_.rst", "generated/torch.Tensor.nan_to_num.rst", "generated/torch.Tensor.nan_to_num_.rst", "generated/torch.Tensor.nanmean.rst", "generated/torch.Tensor.nanmedian.rst", "generated/torch.Tensor.nanquantile.rst", "generated/torch.Tensor.nansum.rst", "generated/torch.Tensor.narrow.rst", "generated/torch.Tensor.narrow_copy.rst", "generated/torch.Tensor.ndim.rst", "generated/torch.Tensor.ndimension.rst", "generated/torch.Tensor.ne.rst", "generated/torch.Tensor.ne_.rst", "generated/torch.Tensor.neg.rst", "generated/torch.Tensor.neg_.rst", "generated/torch.Tensor.negative.rst", "generated/torch.Tensor.negative_.rst", "generated/torch.Tensor.nelement.rst", "generated/torch.Tensor.new_empty.rst", "generated/torch.Tensor.new_full.rst", "generated/torch.Tensor.new_ones.rst", "generated/torch.Tensor.new_tensor.rst", "generated/torch.Tensor.new_zeros.rst", "generated/torch.Tensor.nextafter.rst", "generated/torch.Tensor.nextafter_.rst", "generated/torch.Tensor.nonzero.rst", "generated/torch.Tensor.norm.rst", "generated/torch.Tensor.normal_.rst", "generated/torch.Tensor.not_equal.rst", "generated/torch.Tensor.not_equal_.rst", "generated/torch.Tensor.numel.rst", "generated/torch.Tensor.numpy.rst", "generated/torch.Tensor.orgqr.rst", "generated/torch.Tensor.ormqr.rst", "generated/torch.Tensor.outer.rst", "generated/torch.Tensor.permute.rst", "generated/torch.Tensor.pin_memory.rst", "generated/torch.Tensor.pinverse.rst", "generated/torch.Tensor.polygamma.rst", "generated/torch.Tensor.polygamma_.rst", "generated/torch.Tensor.positive.rst", "generated/torch.Tensor.pow.rst", "generated/torch.Tensor.pow_.rst", "generated/torch.Tensor.prod.rst", "generated/torch.Tensor.put_.rst", "generated/torch.Tensor.q_per_channel_axis.rst", "generated/torch.Tensor.q_per_channel_scales.rst", "generated/torch.Tensor.q_per_channel_zero_points.rst", "generated/torch.Tensor.q_scale.rst", "generated/torch.Tensor.q_zero_point.rst", "generated/torch.Tensor.qr.rst", "generated/torch.Tensor.qscheme.rst", "generated/torch.Tensor.quantile.rst", "generated/torch.Tensor.rad2deg.rst", "generated/torch.Tensor.random_.rst", "generated/torch.Tensor.ravel.rst", "generated/torch.Tensor.real.rst", "generated/torch.Tensor.reciprocal.rst", "generated/torch.Tensor.reciprocal_.rst", "generated/torch.Tensor.record_stream.rst", "generated/torch.Tensor.register_hook.rst", "generated/torch.Tensor.remainder.rst", "generated/torch.Tensor.remainder_.rst", "generated/torch.Tensor.renorm.rst", "generated/torch.Tensor.renorm_.rst", "generated/torch.Tensor.repeat.rst", "generated/torch.Tensor.repeat_interleave.rst", "generated/torch.Tensor.requires_grad.rst", "generated/torch.Tensor.requires_grad_.rst", "generated/torch.Tensor.reshape.rst", "generated/torch.Tensor.reshape_as.rst", "generated/torch.Tensor.resize_.rst", "generated/torch.Tensor.resize_as_.rst", "generated/torch.Tensor.resolve_conj.rst", "generated/torch.Tensor.resolve_neg.rst", "generated/torch.Tensor.retain_grad.rst", "generated/torch.Tensor.retains_grad.rst", "generated/torch.Tensor.roll.rst", "generated/torch.Tensor.rot90.rst", "generated/torch.Tensor.round.rst", "generated/torch.Tensor.round_.rst", "generated/torch.Tensor.row_indices.rst", "generated/torch.Tensor.rsqrt.rst", "generated/torch.Tensor.rsqrt_.rst", "generated/torch.Tensor.scatter.rst", "generated/torch.Tensor.scatter_.rst", "generated/torch.Tensor.scatter_add.rst", "generated/torch.Tensor.scatter_add_.rst", "generated/torch.Tensor.scatter_reduce.rst", "generated/torch.Tensor.scatter_reduce_.rst", "generated/torch.Tensor.select.rst", "generated/torch.Tensor.select_scatter.rst", "generated/torch.Tensor.set_.rst", "generated/torch.Tensor.sgn.rst", "generated/torch.Tensor.sgn_.rst", "generated/torch.Tensor.share_memory_.rst", "generated/torch.Tensor.short.rst", "generated/torch.Tensor.sigmoid.rst", "generated/torch.Tensor.sigmoid_.rst", "generated/torch.Tensor.sign.rst", "generated/torch.Tensor.sign_.rst", "generated/torch.Tensor.signbit.rst", "generated/torch.Tensor.sin.rst", "generated/torch.Tensor.sin_.rst", "generated/torch.Tensor.sinc.rst", "generated/torch.Tensor.sinc_.rst", "generated/torch.Tensor.sinh.rst", "generated/torch.Tensor.sinh_.rst", "generated/torch.Tensor.size.rst", "generated/torch.Tensor.slice_scatter.rst", "generated/torch.Tensor.slogdet.rst", "generated/torch.Tensor.smm.rst", "generated/torch.Tensor.sort.rst", "generated/torch.Tensor.sparse_dim.rst", "generated/torch.Tensor.sparse_mask.rst", "generated/torch.Tensor.sparse_resize_.rst", "generated/torch.Tensor.sparse_resize_and_clear_.rst", "generated/torch.Tensor.split.rst", "generated/torch.Tensor.sqrt.rst", "generated/torch.Tensor.sqrt_.rst", "generated/torch.Tensor.square.rst", "generated/torch.Tensor.square_.rst", "generated/torch.Tensor.squeeze.rst", "generated/torch.Tensor.squeeze_.rst", "generated/torch.Tensor.sspaddmm.rst", "generated/torch.Tensor.std.rst", "generated/torch.Tensor.stft.rst", "generated/torch.Tensor.storage.rst", "generated/torch.Tensor.storage_offset.rst", "generated/torch.Tensor.storage_type.rst", "generated/torch.Tensor.stride.rst", "generated/torch.Tensor.sub.rst", "generated/torch.Tensor.sub_.rst", "generated/torch.Tensor.subtract.rst", "generated/torch.Tensor.subtract_.rst", "generated/torch.Tensor.sum.rst", "generated/torch.Tensor.sum_to_size.rst", "generated/torch.Tensor.svd.rst", "generated/torch.Tensor.swapaxes.rst", "generated/torch.Tensor.swapdims.rst", "generated/torch.Tensor.symeig.rst", "generated/torch.Tensor.t.rst", "generated/torch.Tensor.t_.rst", "generated/torch.Tensor.take.rst", "generated/torch.Tensor.take_along_dim.rst", "generated/torch.Tensor.tan.rst", "generated/torch.Tensor.tan_.rst", "generated/torch.Tensor.tanh.rst", "generated/torch.Tensor.tanh_.rst", "generated/torch.Tensor.tensor_split.rst", "generated/torch.Tensor.tile.rst", "generated/torch.Tensor.to.rst", "generated/torch.Tensor.to_dense.rst", "generated/torch.Tensor.to_mkldnn.rst", "generated/torch.Tensor.to_padded_tensor.rst", "generated/torch.Tensor.to_sparse.rst", "generated/torch.Tensor.to_sparse_bsc.rst", "generated/torch.Tensor.to_sparse_bsr.rst", "generated/torch.Tensor.to_sparse_coo.rst", "generated/torch.Tensor.to_sparse_csc.rst", "generated/torch.Tensor.to_sparse_csr.rst", "generated/torch.Tensor.tolist.rst", "generated/torch.Tensor.topk.rst", "generated/torch.Tensor.trace.rst", "generated/torch.Tensor.transpose.rst", "generated/torch.Tensor.transpose_.rst", "generated/torch.Tensor.triangular_solve.rst", "generated/torch.Tensor.tril.rst", "generated/torch.Tensor.tril_.rst", "generated/torch.Tensor.triu.rst", "generated/torch.Tensor.triu_.rst", "generated/torch.Tensor.true_divide.rst", "generated/torch.Tensor.true_divide_.rst", "generated/torch.Tensor.trunc.rst", "generated/torch.Tensor.trunc_.rst", "generated/torch.Tensor.type.rst", "generated/torch.Tensor.type_as.rst", "generated/torch.Tensor.unbind.rst", "generated/torch.Tensor.unflatten.rst", "generated/torch.Tensor.unfold.rst", "generated/torch.Tensor.uniform_.rst", "generated/torch.Tensor.unique.rst", "generated/torch.Tensor.unique_consecutive.rst", "generated/torch.Tensor.unsqueeze.rst", "generated/torch.Tensor.unsqueeze_.rst", "generated/torch.Tensor.values.rst", "generated/torch.Tensor.var.rst", "generated/torch.Tensor.vdot.rst", "generated/torch.Tensor.view.rst", "generated/torch.Tensor.view_as.rst", "generated/torch.Tensor.vsplit.rst", "generated/torch.Tensor.where.rst", "generated/torch.Tensor.xlogy.rst", "generated/torch.Tensor.xlogy_.rst", "generated/torch.Tensor.zero_.rst", "generated/torch._assert.rst", "generated/torch.abs.rst", "generated/torch.absolute.rst", "generated/torch.acos.rst", "generated/torch.acosh.rst", "generated/torch.add.rst", "generated/torch.addbmm.rst", "generated/torch.addcdiv.rst", "generated/torch.addcmul.rst", "generated/torch.addmm.rst", "generated/torch.addmv.rst", "generated/torch.addr.rst", "generated/torch.adjoint.rst", "generated/torch.all.rst", "generated/torch.allclose.rst", "generated/torch.amax.rst", "generated/torch.amin.rst", "generated/torch.aminmax.rst", "generated/torch.angle.rst", "generated/torch.any.rst", "generated/torch.arange.rst", "generated/torch.arccos.rst", "generated/torch.arccosh.rst", "generated/torch.arcsin.rst", "generated/torch.arcsinh.rst", "generated/torch.arctan.rst", "generated/torch.arctan2.rst", "generated/torch.arctanh.rst", "generated/torch.are_deterministic_algorithms_enabled.rst", "generated/torch.argmax.rst", "generated/torch.argmin.rst", "generated/torch.argsort.rst", "generated/torch.argwhere.rst", "generated/torch.as_strided.rst", "generated/torch.as_tensor.rst", "generated/torch.asarray.rst", "generated/torch.asin.rst", "generated/torch.asinh.rst", "generated/torch.atan.rst", "generated/torch.atan2.rst", "generated/torch.atanh.rst", "generated/torch.atleast_1d.rst", "generated/torch.atleast_2d.rst", "generated/torch.atleast_3d.rst", "generated/torch.autograd.Function.backward.rst", "generated/torch.autograd.Function.forward.rst", "generated/torch.autograd.Function.jvp.rst", "generated/torch.autograd.backward.rst", "generated/torch.autograd.forward_ad.dual_level.rst", "generated/torch.autograd.forward_ad.make_dual.rst", "generated/torch.autograd.forward_ad.unpack_dual.rst", "generated/torch.autograd.function.FunctionCtx.mark_dirty.rst", "generated/torch.autograd.function.FunctionCtx.mark_non_differentiable.rst", "generated/torch.autograd.function.FunctionCtx.save_for_backward.rst", "generated/torch.autograd.function.FunctionCtx.set_materialize_grads.rst", "generated/torch.autograd.functional.hessian.rst", "generated/torch.autograd.functional.hvp.rst", "generated/torch.autograd.functional.jacobian.rst", "generated/torch.autograd.functional.jvp.rst", "generated/torch.autograd.functional.vhp.rst", "generated/torch.autograd.functional.vjp.rst", "generated/torch.autograd.grad.rst", "generated/torch.autograd.gradcheck.rst", "generated/torch.autograd.gradgradcheck.rst", "generated/torch.autograd.profiler.load_nvprof.rst", "generated/torch.autograd.profiler.profile.export_chrome_trace.rst", "generated/torch.autograd.profiler.profile.key_averages.rst", "generated/torch.autograd.profiler.profile.self_cpu_time_total.rst", "generated/torch.autograd.profiler.profile.total_average.rst", "generated/torch.baddbmm.rst", "generated/torch.bartlett_window.rst", "generated/torch.bernoulli.rst", "generated/torch.bincount.rst", "generated/torch.bitwise_and.rst", "generated/torch.bitwise_left_shift.rst", "generated/torch.bitwise_not.rst", "generated/torch.bitwise_or.rst", "generated/torch.bitwise_right_shift.rst", "generated/torch.bitwise_xor.rst", "generated/torch.blackman_window.rst", "generated/torch.block_diag.rst", "generated/torch.bmm.rst", "generated/torch.broadcast_shapes.rst", "generated/torch.broadcast_tensors.rst", "generated/torch.broadcast_to.rst", "generated/torch.bucketize.rst", "generated/torch.can_cast.rst", "generated/torch.cartesian_prod.rst", "generated/torch.cat.rst", "generated/torch.cdist.rst", "generated/torch.ceil.rst", "generated/torch.chain_matmul.rst", "generated/torch.cholesky.rst", "generated/torch.cholesky_inverse.rst", "generated/torch.cholesky_solve.rst", "generated/torch.chunk.rst", "generated/torch.clamp.rst", "generated/torch.clip.rst", "generated/torch.clone.rst", "generated/torch.column_stack.rst", "generated/torch.combinations.rst", "generated/torch.compiled_with_cxx11_abi.rst", "generated/torch.complex.rst", "generated/torch.concat.rst", "generated/torch.conj.rst", "generated/torch.conj_physical.rst", "generated/torch.copysign.rst", "generated/torch.corrcoef.rst", "generated/torch.cos.rst", "generated/torch.cosh.rst", "generated/torch.count_nonzero.rst", "generated/torch.cov.rst", "generated/torch.cross.rst", "generated/torch.cuda.CUDAGraph.rst", "generated/torch.cuda.Event.rst", "generated/torch.cuda.ExternalStream.rst", "generated/torch.cuda.Stream.rst", "generated/torch.cuda.StreamContext.rst", "generated/torch.cuda.caching_allocator_alloc.rst", "generated/torch.cuda.caching_allocator_delete.rst", "generated/torch.cuda.can_device_access_peer.rst", "generated/torch.cuda.comm.broadcast.rst", "generated/torch.cuda.comm.broadcast_coalesced.rst", "generated/torch.cuda.comm.gather.rst", "generated/torch.cuda.comm.reduce_add.rst", "generated/torch.cuda.comm.scatter.rst", "generated/torch.cuda.current_blas_handle.rst", "generated/torch.cuda.current_device.rst", "generated/torch.cuda.current_stream.rst", "generated/torch.cuda.default_stream.rst", "generated/torch.cuda.device.rst", "generated/torch.cuda.device_count.rst", "generated/torch.cuda.device_of.rst", "generated/torch.cuda.empty_cache.rst", "generated/torch.cuda.get_arch_list.rst", "generated/torch.cuda.get_device_capability.rst", "generated/torch.cuda.get_device_name.rst", "generated/torch.cuda.get_device_properties.rst", "generated/torch.cuda.get_gencode_flags.rst", "generated/torch.cuda.get_rng_state.rst", "generated/torch.cuda.get_rng_state_all.rst", "generated/torch.cuda.get_sync_debug_mode.rst", "generated/torch.cuda.graph.rst", "generated/torch.cuda.graph_pool_handle.rst", "generated/torch.cuda.init.rst", "generated/torch.cuda.initial_seed.rst", "generated/torch.cuda.ipc_collect.rst", "generated/torch.cuda.is_available.rst", "generated/torch.cuda.is_current_stream_capturing.rst", "generated/torch.cuda.is_initialized.rst", "generated/torch.cuda.jiterator._create_jit_fn.rst", "generated/torch.cuda.jiterator._create_multi_output_jit_fn.rst", "generated/torch.cuda.list_gpu_processes.rst", "generated/torch.cuda.make_graphed_callables.rst", "generated/torch.cuda.manual_seed.rst", "generated/torch.cuda.manual_seed_all.rst", "generated/torch.cuda.max_memory_allocated.rst", "generated/torch.cuda.max_memory_cached.rst", "generated/torch.cuda.max_memory_reserved.rst", "generated/torch.cuda.mem_get_info.rst", "generated/torch.cuda.memory_allocated.rst", "generated/torch.cuda.memory_cached.rst", "generated/torch.cuda.memory_reserved.rst", "generated/torch.cuda.memory_snapshot.rst", "generated/torch.cuda.memory_stats.rst", "generated/torch.cuda.memory_summary.rst", "generated/torch.cuda.memory_usage.rst", "generated/torch.cuda.nvtx.mark.rst", "generated/torch.cuda.nvtx.range_pop.rst", "generated/torch.cuda.nvtx.range_push.rst", "generated/torch.cuda.reset_max_memory_allocated.rst", "generated/torch.cuda.reset_max_memory_cached.rst", "generated/torch.cuda.reset_peak_memory_stats.rst", "generated/torch.cuda.seed.rst", "generated/torch.cuda.seed_all.rst", "generated/torch.cuda.set_device.rst", "generated/torch.cuda.set_per_process_memory_fraction.rst", "generated/torch.cuda.set_rng_state.rst", "generated/torch.cuda.set_rng_state_all.rst", "generated/torch.cuda.set_stream.rst", "generated/torch.cuda.set_sync_debug_mode.rst", "generated/torch.cuda.stream.rst", "generated/torch.cuda.synchronize.rst", "generated/torch.cuda.utilization.rst", "generated/torch.cummax.rst", "generated/torch.cummin.rst", "generated/torch.cumprod.rst", "generated/torch.cumsum.rst", "generated/torch.cumulative_trapezoid.rst", "generated/torch.deg2rad.rst", "generated/torch.dequantize.rst", "generated/torch.det.rst", "generated/torch.diag.rst", "generated/torch.diag_embed.rst", "generated/torch.diagflat.rst", "generated/torch.diagonal.rst", "generated/torch.diagonal_scatter.rst", "generated/torch.diff.rst", "generated/torch.digamma.rst", "generated/torch.dist.rst", "generated/torch.div.rst", "generated/torch.divide.rst", "generated/torch.dot.rst", "generated/torch.dsplit.rst", "generated/torch.dstack.rst", "generated/torch.eig.rst", "generated/torch.einsum.rst", "generated/torch.empty.rst", "generated/torch.empty_like.rst", "generated/torch.empty_strided.rst", "generated/torch.enable_grad.rst", "generated/torch.eq.rst", "generated/torch.equal.rst", "generated/torch.erf.rst", "generated/torch.erfc.rst", "generated/torch.erfinv.rst", "generated/torch.exp.rst", "generated/torch.exp2.rst", "generated/torch.expm1.rst", "generated/torch.eye.rst", "generated/torch.fake_quantize_per_channel_affine.rst", "generated/torch.fake_quantize_per_tensor_affine.rst", "generated/torch.fft.fft.rst", "generated/torch.fft.fft2.rst", "generated/torch.fft.fftfreq.rst", "generated/torch.fft.fftn.rst", "generated/torch.fft.fftshift.rst", "generated/torch.fft.hfft.rst", "generated/torch.fft.hfft2.rst", "generated/torch.fft.hfftn.rst", "generated/torch.fft.ifft.rst", "generated/torch.fft.ifft2.rst", "generated/torch.fft.ifftn.rst", "generated/torch.fft.ifftshift.rst", "generated/torch.fft.ihfft.rst", "generated/torch.fft.ihfft2.rst", "generated/torch.fft.ihfftn.rst", "generated/torch.fft.irfft.rst", "generated/torch.fft.irfft2.rst", "generated/torch.fft.irfftn.rst", "generated/torch.fft.rfft.rst", "generated/torch.fft.rfft2.rst", "generated/torch.fft.rfftfreq.rst", "generated/torch.fft.rfftn.rst", "generated/torch.fix.rst", "generated/torch.flatten.rst", "generated/torch.flip.rst", "generated/torch.fliplr.rst", "generated/torch.flipud.rst", "generated/torch.float_power.rst", "generated/torch.floor.rst", "generated/torch.floor_divide.rst", "generated/torch.fmax.rst", "generated/torch.fmin.rst", "generated/torch.fmod.rst", "generated/torch.frac.rst", "generated/torch.frexp.rst", "generated/torch.from_dlpack.rst", "generated/torch.from_numpy.rst", "generated/torch.frombuffer.rst", "generated/torch.full.rst", "generated/torch.full_like.rst", "generated/torch.gather.rst", "generated/torch.gcd.rst", "generated/torch.ge.rst", "generated/torch.geqrf.rst", "generated/torch.ger.rst", "generated/torch.get_default_dtype.rst", "generated/torch.get_deterministic_debug_mode.rst", "generated/torch.get_float32_matmul_precision.rst", "generated/torch.get_num_interop_threads.rst", "generated/torch.get_num_threads.rst", "generated/torch.get_rng_state.rst", "generated/torch.gradient.rst", "generated/torch.greater.rst", "generated/torch.greater_equal.rst", "generated/torch.gt.rst", "generated/torch.hamming_window.rst", "generated/torch.hann_window.rst", "generated/torch.heaviside.rst", "generated/torch.histc.rst", "generated/torch.histogram.rst", "generated/torch.histogramdd.rst", "generated/torch.hsplit.rst", "generated/torch.hspmm.rst", "generated/torch.hstack.rst", "generated/torch.hypot.rst", "generated/torch.i0.rst", "generated/torch.igamma.rst", "generated/torch.igammac.rst", "generated/torch.imag.rst", "generated/torch.index_add.rst", "generated/torch.index_copy.rst", "generated/torch.index_reduce.rst", "generated/torch.index_select.rst", "generated/torch.inference_mode.rst", "generated/torch.initial_seed.rst", "generated/torch.inner.rst", "generated/torch.inverse.rst", "generated/torch.is_complex.rst", "generated/torch.is_conj.rst", "generated/torch.is_deterministic_algorithms_warn_only_enabled.rst", "generated/torch.is_floating_point.rst", "generated/torch.is_grad_enabled.rst", "generated/torch.is_inference_mode_enabled.rst", "generated/torch.is_nonzero.rst", "generated/torch.is_storage.rst", "generated/torch.is_tensor.rst", "generated/torch.is_warn_always_enabled.rst", "generated/torch.isclose.rst", "generated/torch.isfinite.rst", "generated/torch.isin.rst", "generated/torch.isinf.rst", "generated/torch.isnan.rst", "generated/torch.isneginf.rst", "generated/torch.isposinf.rst", "generated/torch.isreal.rst", "generated/torch.istft.rst", "generated/torch.jit.Attribute.rst", "generated/torch.jit.ScriptFunction.rst", "generated/torch.jit.ScriptModule.rst", "generated/torch.jit.annotate.rst", "generated/torch.jit.enable_onednn_fusion.rst", "generated/torch.jit.fork.rst", "generated/torch.jit.freeze.rst", "generated/torch.jit.ignore.rst", "generated/torch.jit.isinstance.rst", "generated/torch.jit.load.rst", "generated/torch.jit.onednn_fusion_enabled.rst", "generated/torch.jit.optimize_for_inference.rst", "generated/torch.jit.save.rst", "generated/torch.jit.script.rst", "generated/torch.jit.script_if_tracing.rst", "generated/torch.jit.set_fusion_strategy.rst", "generated/torch.jit.strict_fusion.rst", "generated/torch.jit.trace.rst", "generated/torch.jit.trace_module.rst", "generated/torch.jit.unused.rst", "generated/torch.jit.wait.rst", "generated/torch.kaiser_window.rst", "generated/torch.kron.rst", "generated/torch.kthvalue.rst", "generated/torch.lcm.rst", "generated/torch.ldexp.rst", "generated/torch.le.rst", "generated/torch.lerp.rst", "generated/torch.less.rst", "generated/torch.less_equal.rst", "generated/torch.lgamma.rst", "generated/torch.linalg.cholesky.rst", "generated/torch.linalg.cholesky_ex.rst", "generated/torch.linalg.cond.rst", "generated/torch.linalg.cross.rst", "generated/torch.linalg.det.rst", "generated/torch.linalg.diagonal.rst", "generated/torch.linalg.eig.rst", "generated/torch.linalg.eigh.rst", "generated/torch.linalg.eigvals.rst", "generated/torch.linalg.eigvalsh.rst", "generated/torch.linalg.householder_product.rst", "generated/torch.linalg.inv.rst", "generated/torch.linalg.inv_ex.rst", "generated/torch.linalg.ldl_factor.rst", "generated/torch.linalg.ldl_factor_ex.rst", "generated/torch.linalg.ldl_solve.rst", "generated/torch.linalg.lstsq.rst", "generated/torch.linalg.lu.rst", "generated/torch.linalg.lu_factor.rst", "generated/torch.linalg.lu_factor_ex.rst", "generated/torch.linalg.lu_solve.rst", "generated/torch.linalg.matmul.rst", "generated/torch.linalg.matrix_exp.rst", "generated/torch.linalg.matrix_norm.rst", "generated/torch.linalg.matrix_power.rst", "generated/torch.linalg.matrix_rank.rst", "generated/torch.linalg.multi_dot.rst", "generated/torch.linalg.norm.rst", "generated/torch.linalg.pinv.rst", "generated/torch.linalg.qr.rst", "generated/torch.linalg.slogdet.rst", "generated/torch.linalg.solve.rst", "generated/torch.linalg.solve_ex.rst", "generated/torch.linalg.solve_triangular.rst", "generated/torch.linalg.svd.rst", "generated/torch.linalg.svdvals.rst", "generated/torch.linalg.tensorinv.rst", "generated/torch.linalg.tensorsolve.rst", "generated/torch.linalg.vander.rst", "generated/torch.linalg.vecdot.rst", "generated/torch.linalg.vector_norm.rst", "generated/torch.linspace.rst", "generated/torch.load.rst", "generated/torch.lobpcg.rst", "generated/torch.log.rst", "generated/torch.log10.rst", "generated/torch.log1p.rst", "generated/torch.log2.rst", "generated/torch.logaddexp.rst", "generated/torch.logaddexp2.rst", "generated/torch.logcumsumexp.rst", "generated/torch.logdet.rst", "generated/torch.logical_and.rst", "generated/torch.logical_not.rst", "generated/torch.logical_or.rst", "generated/torch.logical_xor.rst", "generated/torch.logit.rst", "generated/torch.logspace.rst", "generated/torch.logsumexp.rst", "generated/torch.lstsq.rst", "generated/torch.lt.rst", "generated/torch.lu.rst", "generated/torch.lu_solve.rst", "generated/torch.lu_unpack.rst", "generated/torch.manual_seed.rst", "generated/torch.masked_select.rst", "generated/torch.matmul.rst", "generated/torch.matrix_exp.rst", "generated/torch.matrix_power.rst", "generated/torch.matrix_rank.rst", "generated/torch.max.rst", "generated/torch.maximum.rst", "generated/torch.mean.rst", "generated/torch.median.rst", "generated/torch.meshgrid.rst", "generated/torch.min.rst", "generated/torch.minimum.rst", "generated/torch.mm.rst", "generated/torch.mode.rst", "generated/torch.moveaxis.rst", "generated/torch.movedim.rst", "generated/torch.msort.rst", "generated/torch.mul.rst", "generated/torch.multinomial.rst", "generated/torch.multiply.rst", "generated/torch.mv.rst", "generated/torch.mvlgamma.rst", "generated/torch.nan_to_num.rst", "generated/torch.nanmean.rst", "generated/torch.nanmedian.rst", "generated/torch.nanquantile.rst", "generated/torch.nansum.rst", "generated/torch.narrow.rst", "generated/torch.ne.rst", "generated/torch.neg.rst", "generated/torch.negative.rst", "generated/torch.nextafter.rst", "generated/torch.nn.AdaptiveAvgPool1d.rst", "generated/torch.nn.AdaptiveAvgPool2d.rst", "generated/torch.nn.AdaptiveAvgPool3d.rst", "generated/torch.nn.AdaptiveLogSoftmaxWithLoss.rst", "generated/torch.nn.AdaptiveMaxPool1d.rst", "generated/torch.nn.AdaptiveMaxPool2d.rst", "generated/torch.nn.AdaptiveMaxPool3d.rst", "generated/torch.nn.AlphaDropout.rst", "generated/torch.nn.AvgPool1d.rst", "generated/torch.nn.AvgPool2d.rst", "generated/torch.nn.AvgPool3d.rst", "generated/torch.nn.BCELoss.rst", "generated/torch.nn.BCEWithLogitsLoss.rst", "generated/torch.nn.BatchNorm1d.rst", "generated/torch.nn.BatchNorm2d.rst", "generated/torch.nn.BatchNorm3d.rst", "generated/torch.nn.Bilinear.rst", "generated/torch.nn.CELU.rst", "generated/torch.nn.CTCLoss.rst", "generated/torch.nn.ChannelShuffle.rst", "generated/torch.nn.ConstantPad1d.rst", "generated/torch.nn.ConstantPad2d.rst", "generated/torch.nn.ConstantPad3d.rst", "generated/torch.nn.Conv1d.rst", "generated/torch.nn.Conv2d.rst", "generated/torch.nn.Conv3d.rst", "generated/torch.nn.ConvTranspose1d.rst", "generated/torch.nn.ConvTranspose2d.rst", "generated/torch.nn.ConvTranspose3d.rst", "generated/torch.nn.CosineEmbeddingLoss.rst", "generated/torch.nn.CosineSimilarity.rst", "generated/torch.nn.CrossEntropyLoss.rst", "generated/torch.nn.DataParallel.rst", "generated/torch.nn.Dropout.rst", "generated/torch.nn.Dropout1d.rst", "generated/torch.nn.Dropout2d.rst", "generated/torch.nn.Dropout3d.rst", "generated/torch.nn.ELU.rst", "generated/torch.nn.Embedding.rst", "generated/torch.nn.EmbeddingBag.rst", "generated/torch.nn.FeatureAlphaDropout.rst", "generated/torch.nn.Flatten.rst", "generated/torch.nn.Fold.rst", "generated/torch.nn.FractionalMaxPool2d.rst", "generated/torch.nn.FractionalMaxPool3d.rst", "generated/torch.nn.GELU.rst", "generated/torch.nn.GLU.rst", "generated/torch.nn.GRU.rst", "generated/torch.nn.GRUCell.rst", "generated/torch.nn.GaussianNLLLoss.rst", "generated/torch.nn.GroupNorm.rst", "generated/torch.nn.Hardshrink.rst", "generated/torch.nn.Hardsigmoid.rst", "generated/torch.nn.Hardswish.rst", "generated/torch.nn.Hardtanh.rst", "generated/torch.nn.HingeEmbeddingLoss.rst", "generated/torch.nn.HuberLoss.rst", "generated/torch.nn.Identity.rst", "generated/torch.nn.InstanceNorm1d.rst", "generated/torch.nn.InstanceNorm2d.rst", "generated/torch.nn.InstanceNorm3d.rst", "generated/torch.nn.KLDivLoss.rst", "generated/torch.nn.L1Loss.rst", "generated/torch.nn.LPPool1d.rst", "generated/torch.nn.LPPool2d.rst", "generated/torch.nn.LSTM.rst", "generated/torch.nn.LSTMCell.rst", "generated/torch.nn.LayerNorm.rst", "generated/torch.nn.LazyBatchNorm1d.rst", "generated/torch.nn.LazyBatchNorm2d.rst", "generated/torch.nn.LazyBatchNorm3d.rst", "generated/torch.nn.LazyConv1d.rst", "generated/torch.nn.LazyConv2d.rst", "generated/torch.nn.LazyConv3d.rst", "generated/torch.nn.LazyConvTranspose1d.rst", "generated/torch.nn.LazyConvTranspose2d.rst", "generated/torch.nn.LazyConvTranspose3d.rst", "generated/torch.nn.LazyInstanceNorm1d.rst", "generated/torch.nn.LazyInstanceNorm2d.rst", "generated/torch.nn.LazyInstanceNorm3d.rst", "generated/torch.nn.LazyLinear.rst", "generated/torch.nn.LeakyReLU.rst", "generated/torch.nn.Linear.rst", "generated/torch.nn.LocalResponseNorm.rst", "generated/torch.nn.LogSigmoid.rst", "generated/torch.nn.LogSoftmax.rst", "generated/torch.nn.MSELoss.rst", "generated/torch.nn.MarginRankingLoss.rst", "generated/torch.nn.MaxPool1d.rst", "generated/torch.nn.MaxPool2d.rst", "generated/torch.nn.MaxPool3d.rst", "generated/torch.nn.MaxUnpool1d.rst", "generated/torch.nn.MaxUnpool2d.rst", "generated/torch.nn.MaxUnpool3d.rst", "generated/torch.nn.Mish.rst", "generated/torch.nn.Module.rst", "generated/torch.nn.ModuleDict.rst", "generated/torch.nn.ModuleList.rst", "generated/torch.nn.MultiLabelMarginLoss.rst", "generated/torch.nn.MultiLabelSoftMarginLoss.rst", "generated/torch.nn.MultiMarginLoss.rst", "generated/torch.nn.MultiheadAttention.rst", "generated/torch.nn.NLLLoss.rst", "generated/torch.nn.PReLU.rst", "generated/torch.nn.PairwiseDistance.rst", "generated/torch.nn.ParameterDict.rst", "generated/torch.nn.ParameterList.rst", "generated/torch.nn.PixelShuffle.rst", "generated/torch.nn.PixelUnshuffle.rst", "generated/torch.nn.PoissonNLLLoss.rst", "generated/torch.nn.RNN.rst", "generated/torch.nn.RNNBase.rst", "generated/torch.nn.RNNCell.rst", "generated/torch.nn.RReLU.rst", "generated/torch.nn.ReLU.rst", "generated/torch.nn.ReLU6.rst", "generated/torch.nn.ReflectionPad1d.rst", "generated/torch.nn.ReflectionPad2d.rst", "generated/torch.nn.ReflectionPad3d.rst", "generated/torch.nn.ReplicationPad1d.rst", "generated/torch.nn.ReplicationPad2d.rst", "generated/torch.nn.ReplicationPad3d.rst", "generated/torch.nn.SELU.rst", "generated/torch.nn.Sequential.rst", "generated/torch.nn.SiLU.rst", "generated/torch.nn.Sigmoid.rst", "generated/torch.nn.SmoothL1Loss.rst", "generated/torch.nn.SoftMarginLoss.rst", "generated/torch.nn.Softmax.rst", "generated/torch.nn.Softmax2d.rst", "generated/torch.nn.Softmin.rst", "generated/torch.nn.Softplus.rst", "generated/torch.nn.Softshrink.rst", "generated/torch.nn.Softsign.rst", "generated/torch.nn.SyncBatchNorm.rst", "generated/torch.nn.Tanh.rst", "generated/torch.nn.Tanhshrink.rst", "generated/torch.nn.Threshold.rst", "generated/torch.nn.Transformer.rst", "generated/torch.nn.TransformerDecoder.rst", "generated/torch.nn.TransformerDecoderLayer.rst", "generated/torch.nn.TransformerEncoder.rst", "generated/torch.nn.TransformerEncoderLayer.rst", "generated/torch.nn.TripletMarginLoss.rst", "generated/torch.nn.TripletMarginWithDistanceLoss.rst", "generated/torch.nn.Unflatten.rst", "generated/torch.nn.Unfold.rst", "generated/torch.nn.Upsample.rst", "generated/torch.nn.UpsamplingBilinear2d.rst", "generated/torch.nn.UpsamplingNearest2d.rst", "generated/torch.nn.ZeroPad2d.rst", "generated/torch.nn.functional.adaptive_avg_pool1d.rst", "generated/torch.nn.functional.adaptive_avg_pool2d.rst", "generated/torch.nn.functional.adaptive_avg_pool3d.rst", "generated/torch.nn.functional.adaptive_max_pool1d.rst", "generated/torch.nn.functional.adaptive_max_pool2d.rst", "generated/torch.nn.functional.adaptive_max_pool3d.rst", "generated/torch.nn.functional.affine_grid.rst", "generated/torch.nn.functional.alpha_dropout.rst", "generated/torch.nn.functional.avg_pool1d.rst", "generated/torch.nn.functional.avg_pool2d.rst", "generated/torch.nn.functional.avg_pool3d.rst", "generated/torch.nn.functional.batch_norm.rst", "generated/torch.nn.functional.bilinear.rst", "generated/torch.nn.functional.binary_cross_entropy.rst", "generated/torch.nn.functional.binary_cross_entropy_with_logits.rst", "generated/torch.nn.functional.celu.rst", "generated/torch.nn.functional.conv1d.rst", "generated/torch.nn.functional.conv2d.rst", "generated/torch.nn.functional.conv3d.rst", "generated/torch.nn.functional.conv_transpose1d.rst", "generated/torch.nn.functional.conv_transpose2d.rst", "generated/torch.nn.functional.conv_transpose3d.rst", "generated/torch.nn.functional.cosine_embedding_loss.rst", "generated/torch.nn.functional.cosine_similarity.rst", "generated/torch.nn.functional.cross_entropy.rst", "generated/torch.nn.functional.ctc_loss.rst", "generated/torch.nn.functional.dropout.rst", "generated/torch.nn.functional.dropout1d.rst", "generated/torch.nn.functional.dropout2d.rst", "generated/torch.nn.functional.dropout3d.rst", "generated/torch.nn.functional.elu.rst", "generated/torch.nn.functional.elu_.rst", "generated/torch.nn.functional.embedding.rst", "generated/torch.nn.functional.embedding_bag.rst", "generated/torch.nn.functional.feature_alpha_dropout.rst", "generated/torch.nn.functional.fold.rst", "generated/torch.nn.functional.fractional_max_pool2d.rst", "generated/torch.nn.functional.fractional_max_pool3d.rst", "generated/torch.nn.functional.gaussian_nll_loss.rst", "generated/torch.nn.functional.gelu.rst", "generated/torch.nn.functional.glu.rst", "generated/torch.nn.functional.grid_sample.rst", "generated/torch.nn.functional.group_norm.rst", "generated/torch.nn.functional.gumbel_softmax.rst", "generated/torch.nn.functional.hardshrink.rst", "generated/torch.nn.functional.hardsigmoid.rst", "generated/torch.nn.functional.hardswish.rst", "generated/torch.nn.functional.hardtanh.rst", "generated/torch.nn.functional.hardtanh_.rst", "generated/torch.nn.functional.hinge_embedding_loss.rst", "generated/torch.nn.functional.huber_loss.rst", "generated/torch.nn.functional.instance_norm.rst", "generated/torch.nn.functional.interpolate.rst", "generated/torch.nn.functional.kl_div.rst", "generated/torch.nn.functional.l1_loss.rst", "generated/torch.nn.functional.layer_norm.rst", "generated/torch.nn.functional.leaky_relu.rst", "generated/torch.nn.functional.leaky_relu_.rst", "generated/torch.nn.functional.linear.rst", "generated/torch.nn.functional.local_response_norm.rst", "generated/torch.nn.functional.log_softmax.rst", "generated/torch.nn.functional.logsigmoid.rst", "generated/torch.nn.functional.lp_pool1d.rst", "generated/torch.nn.functional.lp_pool2d.rst", "generated/torch.nn.functional.margin_ranking_loss.rst", "generated/torch.nn.functional.max_pool1d.rst", "generated/torch.nn.functional.max_pool2d.rst", "generated/torch.nn.functional.max_pool3d.rst", "generated/torch.nn.functional.max_unpool1d.rst", "generated/torch.nn.functional.max_unpool2d.rst", "generated/torch.nn.functional.max_unpool3d.rst", "generated/torch.nn.functional.mish.rst", "generated/torch.nn.functional.mse_loss.rst", "generated/torch.nn.functional.multi_margin_loss.rst", "generated/torch.nn.functional.multilabel_margin_loss.rst", "generated/torch.nn.functional.multilabel_soft_margin_loss.rst", "generated/torch.nn.functional.nll_loss.rst", "generated/torch.nn.functional.normalize.rst", "generated/torch.nn.functional.one_hot.rst", "generated/torch.nn.functional.pad.rst", "generated/torch.nn.functional.pairwise_distance.rst", "generated/torch.nn.functional.pdist.rst", "generated/torch.nn.functional.pixel_shuffle.rst", "generated/torch.nn.functional.pixel_unshuffle.rst", "generated/torch.nn.functional.poisson_nll_loss.rst", "generated/torch.nn.functional.prelu.rst", "generated/torch.nn.functional.relu.rst", "generated/torch.nn.functional.relu6.rst", "generated/torch.nn.functional.relu_.rst", "generated/torch.nn.functional.rrelu.rst", "generated/torch.nn.functional.rrelu_.rst", "generated/torch.nn.functional.selu.rst", "generated/torch.nn.functional.sigmoid.rst", "generated/torch.nn.functional.silu.rst", "generated/torch.nn.functional.smooth_l1_loss.rst", "generated/torch.nn.functional.soft_margin_loss.rst", "generated/torch.nn.functional.softmax.rst", "generated/torch.nn.functional.softmin.rst", "generated/torch.nn.functional.softplus.rst", "generated/torch.nn.functional.softshrink.rst", "generated/torch.nn.functional.softsign.rst", "generated/torch.nn.functional.tanh.rst", "generated/torch.nn.functional.tanhshrink.rst", "generated/torch.nn.functional.threshold.rst", "generated/torch.nn.functional.threshold_.rst", "generated/torch.nn.functional.torch.nn.parallel.data_parallel.rst", "generated/torch.nn.functional.triplet_margin_loss.rst", "generated/torch.nn.functional.triplet_margin_with_distance_loss.rst", "generated/torch.nn.functional.unfold.rst", "generated/torch.nn.functional.upsample.rst", "generated/torch.nn.functional.upsample_bilinear.rst", "generated/torch.nn.functional.upsample_nearest.rst", "generated/torch.nn.intrinsic.BNReLU2d.rst", "generated/torch.nn.intrinsic.BNReLU3d.rst", "generated/torch.nn.intrinsic.ConvBn1d.rst", "generated/torch.nn.intrinsic.ConvBn2d.rst", "generated/torch.nn.intrinsic.ConvBn3d.rst", "generated/torch.nn.intrinsic.ConvBnReLU1d.rst", "generated/torch.nn.intrinsic.ConvBnReLU2d.rst", "generated/torch.nn.intrinsic.ConvBnReLU3d.rst", "generated/torch.nn.intrinsic.ConvReLU1d.rst", "generated/torch.nn.intrinsic.ConvReLU2d.rst", "generated/torch.nn.intrinsic.ConvReLU3d.rst", "generated/torch.nn.intrinsic.LinearReLU.rst", "generated/torch.nn.intrinsic.qat.ConvBn1d.rst", "generated/torch.nn.intrinsic.qat.ConvBn2d.rst", "generated/torch.nn.intrinsic.qat.ConvBn3d.rst", "generated/torch.nn.intrinsic.qat.ConvBnReLU1d.rst", "generated/torch.nn.intrinsic.qat.ConvBnReLU2d.rst", "generated/torch.nn.intrinsic.qat.ConvBnReLU3d.rst", "generated/torch.nn.intrinsic.qat.ConvReLU2d.rst", "generated/torch.nn.intrinsic.qat.ConvReLU3d.rst", "generated/torch.nn.intrinsic.qat.LinearReLU.rst", "generated/torch.nn.intrinsic.qat.freeze_bn_stats.rst", "generated/torch.nn.intrinsic.qat.update_bn_stats.rst", "generated/torch.nn.intrinsic.quantized.BNReLU2d.rst", "generated/torch.nn.intrinsic.quantized.BNReLU3d.rst", "generated/torch.nn.intrinsic.quantized.ConvReLU1d.rst", "generated/torch.nn.intrinsic.quantized.ConvReLU2d.rst", "generated/torch.nn.intrinsic.quantized.ConvReLU3d.rst", "generated/torch.nn.intrinsic.quantized.LinearReLU.rst", "generated/torch.nn.intrinsic.quantized.dynamic.LinearReLU.rst", "generated/torch.nn.modules.lazy.LazyModuleMixin.rst", "generated/torch.nn.modules.module.register_module_backward_hook.rst", "generated/torch.nn.modules.module.register_module_forward_hook.rst", "generated/torch.nn.modules.module.register_module_forward_pre_hook.rst", "generated/torch.nn.modules.module.register_module_full_backward_hook.rst", "generated/torch.nn.parallel.DistributedDataParallel.rst", "generated/torch.nn.parameter.Parameter.rst", "generated/torch.nn.parameter.UninitializedBuffer.rst", "generated/torch.nn.parameter.UninitializedParameter.rst", "generated/torch.nn.qat.Conv2d.rst", "generated/torch.nn.qat.Conv3d.rst", "generated/torch.nn.qat.Linear.rst", "generated/torch.nn.qat.dynamic.Linear.rst", "generated/torch.nn.quantizable.LSTM.rst", "generated/torch.nn.quantizable.MultiheadAttention.rst", "generated/torch.nn.quantized.BatchNorm2d.rst", "generated/torch.nn.quantized.BatchNorm3d.rst", "generated/torch.nn.quantized.Conv1d.rst", "generated/torch.nn.quantized.Conv2d.rst", "generated/torch.nn.quantized.Conv3d.rst", "generated/torch.nn.quantized.ConvTranspose1d.rst", "generated/torch.nn.quantized.ConvTranspose2d.rst", "generated/torch.nn.quantized.ConvTranspose3d.rst", "generated/torch.nn.quantized.ELU.rst", "generated/torch.nn.quantized.Embedding.rst", "generated/torch.nn.quantized.EmbeddingBag.rst", "generated/torch.nn.quantized.FXFloatFunctional.rst", "generated/torch.nn.quantized.FloatFunctional.rst", "generated/torch.nn.quantized.GroupNorm.rst", "generated/torch.nn.quantized.Hardswish.rst", "generated/torch.nn.quantized.InstanceNorm1d.rst", "generated/torch.nn.quantized.InstanceNorm2d.rst", "generated/torch.nn.quantized.InstanceNorm3d.rst", "generated/torch.nn.quantized.LayerNorm.rst", "generated/torch.nn.quantized.LeakyReLU.rst", "generated/torch.nn.quantized.Linear.rst", "generated/torch.nn.quantized.QFunctional.rst", "generated/torch.nn.quantized.ReLU6.rst", "generated/torch.nn.quantized.Sigmoid.rst", "generated/torch.nn.quantized.dynamic.GRU.rst", "generated/torch.nn.quantized.dynamic.GRUCell.rst", "generated/torch.nn.quantized.dynamic.LSTM.rst", "generated/torch.nn.quantized.dynamic.LSTMCell.rst", "generated/torch.nn.quantized.dynamic.Linear.rst", "generated/torch.nn.quantized.dynamic.RNNCell.rst", "generated/torch.nn.quantized.functional.adaptive_avg_pool2d.rst", "generated/torch.nn.quantized.functional.adaptive_avg_pool3d.rst", "generated/torch.nn.quantized.functional.avg_pool2d.rst", "generated/torch.nn.quantized.functional.avg_pool3d.rst", "generated/torch.nn.quantized.functional.celu.rst", "generated/torch.nn.quantized.functional.clamp.rst", "generated/torch.nn.quantized.functional.conv1d.rst", "generated/torch.nn.quantized.functional.conv2d.rst", "generated/torch.nn.quantized.functional.conv3d.rst", "generated/torch.nn.quantized.functional.elu.rst", "generated/torch.nn.quantized.functional.hardsigmoid.rst", "generated/torch.nn.quantized.functional.hardswish.rst", "generated/torch.nn.quantized.functional.hardtanh.rst", "generated/torch.nn.quantized.functional.interpolate.rst", "generated/torch.nn.quantized.functional.leaky_relu.rst", "generated/torch.nn.quantized.functional.linear.rst", "generated/torch.nn.quantized.functional.max_pool1d.rst", "generated/torch.nn.quantized.functional.max_pool2d.rst", "generated/torch.nn.quantized.functional.threshold.rst", "generated/torch.nn.quantized.functional.upsample.rst", "generated/torch.nn.quantized.functional.upsample_bilinear.rst", "generated/torch.nn.quantized.functional.upsample_nearest.rst", "generated/torch.nn.utils.clip_grad_norm_.rst", "generated/torch.nn.utils.clip_grad_value_.rst", "generated/torch.nn.utils.parameters_to_vector.rst", "generated/torch.nn.utils.parametrizations.orthogonal.rst", "generated/torch.nn.utils.parametrizations.spectral_norm.rst", "generated/torch.nn.utils.parametrize.ParametrizationList.rst", "generated/torch.nn.utils.parametrize.cached.rst", "generated/torch.nn.utils.parametrize.is_parametrized.rst", "generated/torch.nn.utils.parametrize.register_parametrization.rst", "generated/torch.nn.utils.parametrize.remove_parametrizations.rst", "generated/torch.nn.utils.prune.BasePruningMethod.rst", "generated/torch.nn.utils.prune.CustomFromMask.rst", "generated/torch.nn.utils.prune.Identity.rst", "generated/torch.nn.utils.prune.L1Unstructured.rst", "generated/torch.nn.utils.prune.LnStructured.rst", "generated/torch.nn.utils.prune.PruningContainer.rst", "generated/torch.nn.utils.prune.RandomStructured.rst", "generated/torch.nn.utils.prune.RandomUnstructured.rst", "generated/torch.nn.utils.prune.custom_from_mask.rst", "generated/torch.nn.utils.prune.global_unstructured.rst", "generated/torch.nn.utils.prune.identity.rst", "generated/torch.nn.utils.prune.is_pruned.rst", "generated/torch.nn.utils.prune.l1_unstructured.rst", "generated/torch.nn.utils.prune.ln_structured.rst", "generated/torch.nn.utils.prune.random_structured.rst", "generated/torch.nn.utils.prune.random_unstructured.rst", "generated/torch.nn.utils.prune.remove.rst", "generated/torch.nn.utils.remove_spectral_norm.rst", "generated/torch.nn.utils.remove_weight_norm.rst", "generated/torch.nn.utils.rnn.PackedSequence.rst", "generated/torch.nn.utils.rnn.pack_padded_sequence.rst", "generated/torch.nn.utils.rnn.pack_sequence.rst", "generated/torch.nn.utils.rnn.pad_packed_sequence.rst", "generated/torch.nn.utils.rnn.pad_sequence.rst", "generated/torch.nn.utils.skip_init.rst", "generated/torch.nn.utils.spectral_norm.rst", "generated/torch.nn.utils.stateless.functional_call.rst", "generated/torch.nn.utils.vector_to_parameters.rst", "generated/torch.nn.utils.weight_norm.rst", "generated/torch.no_grad.rst", "generated/torch.nonzero.rst", "generated/torch.norm.rst", "generated/torch.normal.rst", "generated/torch.not_equal.rst", "generated/torch.numel.rst", "generated/torch.ones.rst", "generated/torch.ones_like.rst", "generated/torch.onnx.JitScalarType.rst", "generated/torch.onnx.SymbolicContext.rst", "generated/torch.optim.ASGD.rst", "generated/torch.optim.Adadelta.rst", "generated/torch.optim.Adagrad.rst", "generated/torch.optim.Adam.rst", "generated/torch.optim.AdamW.rst", "generated/torch.optim.Adamax.rst", "generated/torch.optim.LBFGS.rst", "generated/torch.optim.NAdam.rst", "generated/torch.optim.Optimizer.add_param_group.rst", "generated/torch.optim.Optimizer.load_state_dict.rst", "generated/torch.optim.Optimizer.state_dict.rst", "generated/torch.optim.Optimizer.step.rst", "generated/torch.optim.Optimizer.zero_grad.rst", "generated/torch.optim.RAdam.rst", "generated/torch.optim.RMSprop.rst", "generated/torch.optim.Rprop.rst", "generated/torch.optim.SGD.rst", "generated/torch.optim.SparseAdam.rst", "generated/torch.optim.lr_scheduler.ChainedScheduler.rst", "generated/torch.optim.lr_scheduler.ConstantLR.rst", "generated/torch.optim.lr_scheduler.CosineAnnealingLR.rst", "generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.rst", "generated/torch.optim.lr_scheduler.CyclicLR.rst", "generated/torch.optim.lr_scheduler.ExponentialLR.rst", "generated/torch.optim.lr_scheduler.LambdaLR.rst", "generated/torch.optim.lr_scheduler.LinearLR.rst", "generated/torch.optim.lr_scheduler.MultiStepLR.rst", "generated/torch.optim.lr_scheduler.MultiplicativeLR.rst", "generated/torch.optim.lr_scheduler.OneCycleLR.rst", "generated/torch.optim.lr_scheduler.ReduceLROnPlateau.rst", "generated/torch.optim.lr_scheduler.SequentialLR.rst", "generated/torch.optim.lr_scheduler.StepLR.rst", "generated/torch.orgqr.rst", "generated/torch.ormqr.rst", "generated/torch.outer.rst", "generated/torch.pca_lowrank.rst", "generated/torch.permute.rst", "generated/torch.pinverse.rst", "generated/torch.poisson.rst", "generated/torch.polar.rst", "generated/torch.polygamma.rst", "generated/torch.positive.rst", "generated/torch.pow.rst", "generated/torch.prod.rst", "generated/torch.promote_types.rst", "generated/torch.qr.rst", "generated/torch.quantile.rst", "generated/torch.quantization.DeQuantStub.rst", "generated/torch.quantization.QuantStub.rst", "generated/torch.quantization.QuantWrapper.rst", "generated/torch.quantization.add_observer_.rst", "generated/torch.quantization.add_quant_dequant.rst", "generated/torch.quantization.convert.rst", "generated/torch.quantization.default_eval_fn.rst", "generated/torch.quantization.fake_quantize.FakeQuantize.rst", "generated/torch.quantization.fake_quantize.FakeQuantizeBase.rst", "generated/torch.quantization.fake_quantize.FixedQParamsFakeQuantize.rst", "generated/torch.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize.rst", "generated/torch.quantization.fake_quantize.default_fake_quant.rst", "generated/torch.quantization.fake_quantize.default_fused_act_fake_quant.rst", "generated/torch.quantization.fake_quantize.default_fused_per_channel_wt_fake_quant.rst", "generated/torch.quantization.fake_quantize.default_fused_wt_fake_quant.rst", "generated/torch.quantization.fake_quantize.default_histogram_fake_quant.rst", "generated/torch.quantization.fake_quantize.default_per_channel_weight_fake_quant.rst", "generated/torch.quantization.fake_quantize.default_weight_fake_quant.rst", "generated/torch.quantization.fake_quantize.disable_fake_quant.rst", "generated/torch.quantization.fake_quantize.disable_observer.rst", "generated/torch.quantization.fake_quantize.enable_fake_quant.rst", "generated/torch.quantization.fake_quantize.enable_observer.rst", "generated/torch.quantization.fuse_modules.rst", "generated/torch.quantization.get_observer_dict.rst", "generated/torch.quantization.observer.HistogramObserver.rst", "generated/torch.quantization.observer.MinMaxObserver.rst", "generated/torch.quantization.observer.MovingAverageMinMaxObserver.rst", "generated/torch.quantization.observer.MovingAveragePerChannelMinMaxObserver.rst", "generated/torch.quantization.observer.NoopObserver.rst", "generated/torch.quantization.observer.ObserverBase.rst", "generated/torch.quantization.observer.PerChannelMinMaxObserver.rst", "generated/torch.quantization.observer.PlaceholderObserver.rst", "generated/torch.quantization.observer.RecordingObserver.rst", "generated/torch.quantization.observer.default_debug_observer.rst", "generated/torch.quantization.observer.default_dynamic_quant_observer.rst", "generated/torch.quantization.observer.default_float_qparams_observer.rst", "generated/torch.quantization.observer.default_histogram_observer.rst", "generated/torch.quantization.observer.default_observer.rst", "generated/torch.quantization.observer.default_per_channel_weight_observer.rst", "generated/torch.quantization.observer.default_placeholder_observer.rst", "generated/torch.quantization.observer.default_weight_observer.rst", "generated/torch.quantization.observer.get_observer_state_dict.rst", "generated/torch.quantization.observer.load_observer_state_dict.rst", "generated/torch.quantization.prepare.rst", "generated/torch.quantization.prepare_qat.rst", "generated/torch.quantization.propagate_qconfig_.rst", "generated/torch.quantization.qconfig.QConfig.rst", "generated/torch.quantization.qconfig.default_activation_only_qconfig.rst", "generated/torch.quantization.qconfig.default_debug_qconfig.rst", "generated/torch.quantization.qconfig.default_dynamic_qconfig.rst", "generated/torch.quantization.qconfig.default_per_channel_qconfig.rst", "generated/torch.quantization.qconfig.default_qat_qconfig.rst", "generated/torch.quantization.qconfig.default_qat_qconfig_v2.rst", "generated/torch.quantization.qconfig.default_qconfig.rst", "generated/torch.quantization.qconfig.default_weight_only_qconfig.rst", "generated/torch.quantization.qconfig.float16_dynamic_qconfig.rst", "generated/torch.quantization.qconfig.float16_static_qconfig.rst", "generated/torch.quantization.qconfig.float_qparams_weight_only_qconfig.rst", "generated/torch.quantization.qconfig.per_channel_dynamic_qconfig.rst", "generated/torch.quantization.quantize.rst", "generated/torch.quantization.quantize_dynamic.rst", "generated/torch.quantization.quantize_fx.convert_fx.rst", "generated/torch.quantization.quantize_fx.fuse_fx.rst", "generated/torch.quantization.quantize_fx.prepare_fx.rst", "generated/torch.quantization.quantize_fx.prepare_qat_fx.rst", "generated/torch.quantization.quantize_qat.rst", "generated/torch.quantization.swap_module.rst", "generated/torch.quantize_per_channel.rst", "generated/torch.quantize_per_tensor.rst", "generated/torch.quantized_batch_norm.rst", "generated/torch.quantized_max_pool1d.rst", "generated/torch.quantized_max_pool2d.rst", "generated/torch.quasirandom.SobolEngine.rst", "generated/torch.rad2deg.rst", "generated/torch.rand.rst", "generated/torch.rand_like.rst", "generated/torch.randint.rst", "generated/torch.randint_like.rst", "generated/torch.randn.rst", "generated/torch.randn_like.rst", "generated/torch.randperm.rst", "generated/torch.range.rst", "generated/torch.ravel.rst", "generated/torch.real.rst", "generated/torch.reciprocal.rst", "generated/torch.remainder.rst", "generated/torch.renorm.rst", "generated/torch.repeat_interleave.rst", "generated/torch.reshape.rst", "generated/torch.resolve_conj.rst", "generated/torch.resolve_neg.rst", "generated/torch.result_type.rst", "generated/torch.roll.rst", "generated/torch.rot90.rst", "generated/torch.round.rst", "generated/torch.row_stack.rst", "generated/torch.rsqrt.rst", "generated/torch.save.rst", "generated/torch.scatter.rst", "generated/torch.scatter_add.rst", "generated/torch.scatter_reduce.rst", "generated/torch.searchsorted.rst", "generated/torch.seed.rst", "generated/torch.select.rst", "generated/torch.select_scatter.rst", "generated/torch.set_default_dtype.rst", "generated/torch.set_default_tensor_type.rst", "generated/torch.set_deterministic_debug_mode.rst", "generated/torch.set_float32_matmul_precision.rst", "generated/torch.set_flush_denormal.rst", "generated/torch.set_grad_enabled.rst", "generated/torch.set_num_interop_threads.rst", "generated/torch.set_num_threads.rst", "generated/torch.set_printoptions.rst", "generated/torch.set_rng_state.rst", "generated/torch.set_warn_always.rst", "generated/torch.sgn.rst", "generated/torch.sigmoid.rst", "generated/torch.sign.rst", "generated/torch.signbit.rst", "generated/torch.sin.rst", "generated/torch.sinc.rst", "generated/torch.sinh.rst", "generated/torch.slice_scatter.rst", "generated/torch.slogdet.rst", "generated/torch.smm.rst", "generated/torch.sort.rst", "generated/torch.sparse.addmm.rst", "generated/torch.sparse.log_softmax.rst", "generated/torch.sparse.mm.rst", "generated/torch.sparse.sampled_addmm.rst", "generated/torch.sparse.softmax.rst", "generated/torch.sparse.spdiags.rst", "generated/torch.sparse.sum.rst", "generated/torch.sparse_bsc_tensor.rst", "generated/torch.sparse_bsr_tensor.rst", "generated/torch.sparse_compressed_tensor.rst", "generated/torch.sparse_coo_tensor.rst", "generated/torch.sparse_csc_tensor.rst", "generated/torch.sparse_csr_tensor.rst", "generated/torch.split.rst", "generated/torch.sqrt.rst", "generated/torch.square.rst", "generated/torch.squeeze.rst", "generated/torch.sspaddmm.rst", "generated/torch.stack.rst", "generated/torch.std.rst", "generated/torch.std_mean.rst", "generated/torch.stft.rst", "generated/torch.sub.rst", "generated/torch.subtract.rst", "generated/torch.sum.rst", "generated/torch.svd.rst", "generated/torch.svd_lowrank.rst", "generated/torch.swapaxes.rst", "generated/torch.swapdims.rst", "generated/torch.symeig.rst", "generated/torch.t.rst", "generated/torch.take.rst", "generated/torch.take_along_dim.rst", "generated/torch.tan.rst", "generated/torch.tanh.rst", "generated/torch.tensor.rst", "generated/torch.tensor_split.rst", "generated/torch.tensordot.rst", "generated/torch.tile.rst", "generated/torch.topk.rst", "generated/torch.trace.rst", "generated/torch.transpose.rst", "generated/torch.trapezoid.rst", "generated/torch.trapz.rst", "generated/torch.triangular_solve.rst", "generated/torch.tril.rst", "generated/torch.tril_indices.rst", "generated/torch.triu.rst", "generated/torch.triu_indices.rst", "generated/torch.true_divide.rst", "generated/torch.trunc.rst", "generated/torch.unbind.rst", "generated/torch.unflatten.rst", "generated/torch.unique.rst", "generated/torch.unique_consecutive.rst", "generated/torch.unsqueeze.rst", "generated/torch.use_deterministic_algorithms.rst", "generated/torch.vander.rst", "generated/torch.var.rst", "generated/torch.var_mean.rst", "generated/torch.vdot.rst", "generated/torch.view_as_complex.rst", "generated/torch.view_as_real.rst", "generated/torch.vmap.rst", "generated/torch.vsplit.rst", "generated/torch.vstack.rst", "generated/torch.where.rst", "generated/torch.xlogy.rst", "generated/torch.zeros.rst", "generated/torch.zeros_like.rst", "hub.rst", "index.rst", "jit.rst", "jit_builtin_functions.rst", "jit_language_reference.rst", "jit_language_reference_v2.rst", "jit_python_reference.rst", "jit_unsupported.rst", "jit_utils.rst", "library.rst", "linalg.rst", "mobile_optimizer.rst", "model_zoo.rst", "monitor.rst", "multiprocessing.rst", "name_inference.rst", "named_tensor.rst", "nested.rst", "nn.rst", "nn.functional.rst", "nn.init.rst", "notes/amp_examples.rst", "notes/autograd.rst", "notes/broadcasting.rst", "notes/cpu_threading_torchscript_inference.rst", "notes/cuda.rst", "notes/ddp.rst", "notes/extending.rst", "notes/faq.rst", "notes/gradcheck.rst", "notes/hip.rst", "notes/large_scale_deployments.rst", "notes/modules.rst", "notes/mps.rst", "notes/multiprocessing.rst", "notes/numerical_accuracy.rst", "notes/randomness.rst", "notes/serialization.rst", "notes/windows.rst", "onnx.rst", "onnx_supported_aten_ops.rst", "optim.rst", "package.rst", "pipeline.rst", "profiler.rst", "quantization.rst", "quantization-accuracy-debugging.rst", "quantization-backend-configuration.rst", "quantization-support.rst", "random.rst", "rpc.rst", "rpc/distributed_autograd.rst", "rpc/rref.rst", "sparse.rst", "special.rst", "storage.rst", "tensor_attributes.rst", "tensor_view.rst", "tensorboard.rst", "tensors.rst", "testing.rst", "torch.rst", "torch.ao.ns._numeric_suite.rst", "torch.ao.ns._numeric_suite_fx.rst", "torch.overrides.rst", "type_info.rst"], "titles": ["Automatic Mixed Precision package - torch.amp", "Automatic differentiation package - torch.autograd", "torch.backends", "Benchmark Utils - torch.utils.benchmark", "torch.utils.bottleneck", "torch.utils.checkpoint", "PyTorch Contribution Guide", "PyTorch Design Philosophy", "PyTorch Governance | Mechanics", "PyTorch Governance | Maintainers", "Complex Numbers", "torch.__config__", "torch.utils.cpp_extension", "C++", "torch.cuda", "&lt;no title&gt;", "&lt;no title&gt;", "torch.utils.data", "DDP Communication Hooks", "torch::deploy", "Distributed communication package - torch.distributed", "Generic Join Context Manager", "Torch Distributed Elastic", "Distributed Optimizers", "Probability distributions - torch.distributions", "torch.utils.dlpack", "Elastic Agent", "Customization", "Error Propagation", "Events", "Examples", "TorchElastic Kubernetes", "Metrics", "Multiprocessing", "Quickstart", "Rendezvous", "torchrun (Elastic Launch)", "Expiration Timers", "Train script", "torch.fft", "FullyShardedDataParallel", "torch.futures", "torch.fx", "Generator", "torch.Tensor.abs", "torch.Tensor.abs_", "torch.Tensor.absolute", "torch.Tensor.absolute_", "torch.Tensor.acos", "torch.Tensor.acos_", "torch.Tensor.acosh", "torch.Tensor.acosh_", "torch.Tensor.add", "torch.Tensor.add_", "torch.Tensor.addbmm", "torch.Tensor.addbmm_", "torch.Tensor.addcdiv", "torch.Tensor.addcdiv_", "torch.Tensor.addcmul", "torch.Tensor.addcmul_", "torch.Tensor.addmm", "torch.Tensor.addmm_", "torch.Tensor.addmv", "torch.Tensor.addmv_", "torch.Tensor.addr", "torch.Tensor.addr_", "torch.Tensor.adjoint", "torch.Tensor.all", "torch.Tensor.allclose", "torch.Tensor.amax", "torch.Tensor.amin", "torch.Tensor.aminmax", "torch.Tensor.angle", "torch.Tensor.any", "torch.Tensor.apply_", "torch.Tensor.arccos", "torch.Tensor.arccos_", "torch.Tensor.arccosh", "torch.Tensor.arccosh_", "torch.Tensor.arcsin", "torch.Tensor.arcsin_", "torch.Tensor.arcsinh", "torch.Tensor.arcsinh_", "torch.Tensor.arctan", "torch.Tensor.arctan2", "torch.Tensor.arctan2_", "torch.Tensor.arctan_", "torch.Tensor.arctanh", "torch.Tensor.arctanh_", "torch.Tensor.argmax", "torch.Tensor.argmin", "torch.Tensor.argsort", "torch.Tensor.argwhere", "torch.Tensor.as_strided", "torch.Tensor.as_subclass", "torch.Tensor.asin", "torch.Tensor.asin_", "torch.Tensor.asinh", "torch.Tensor.asinh_", "torch.Tensor.atan", "torch.Tensor.atan2", "torch.Tensor.atan2_", "torch.Tensor.atan_", "torch.Tensor.atanh", "torch.Tensor.atanh_", "torch.Tensor.backward", "torch.Tensor.baddbmm", "torch.Tensor.baddbmm_", "torch.Tensor.bernoulli", "torch.Tensor.bernoulli_", "torch.Tensor.bfloat16", "torch.Tensor.bincount", "torch.Tensor.bitwise_and", "torch.Tensor.bitwise_and_", "torch.Tensor.bitwise_left_shift", "torch.Tensor.bitwise_left_shift_", "torch.Tensor.bitwise_not", "torch.Tensor.bitwise_not_", "torch.Tensor.bitwise_or", "torch.Tensor.bitwise_or_", "torch.Tensor.bitwise_right_shift", "torch.Tensor.bitwise_right_shift_", "torch.Tensor.bitwise_xor", "torch.Tensor.bitwise_xor_", "torch.Tensor.bmm", "torch.Tensor.bool", "torch.Tensor.broadcast_to", "torch.Tensor.byte", "torch.Tensor.cauchy_", "torch.Tensor.ccol_indices", "torch.Tensor.cdouble", "torch.Tensor.ceil", "torch.Tensor.ceil_", "torch.Tensor.cfloat", "torch.Tensor.chalf", "torch.Tensor.char", "torch.Tensor.cholesky", "torch.Tensor.cholesky_inverse", "torch.Tensor.cholesky_solve", "torch.Tensor.chunk", "torch.Tensor.clamp", "torch.Tensor.clamp_", "torch.Tensor.clip", "torch.Tensor.clip_", "torch.Tensor.clone", "torch.Tensor.coalesce", "torch.Tensor.col_indices", "torch.Tensor.conj", "torch.Tensor.conj_physical", "torch.Tensor.conj_physical_", "torch.Tensor.contiguous", "torch.Tensor.copy_", "torch.Tensor.copysign", "torch.Tensor.copysign_", "torch.Tensor.corrcoef", "torch.Tensor.cos", "torch.Tensor.cos_", "torch.Tensor.cosh", "torch.Tensor.cosh_", "torch.Tensor.count_nonzero", "torch.Tensor.cov", "torch.Tensor.cpu", "torch.Tensor.cross", "torch.Tensor.crow_indices", "torch.Tensor.cuda", "torch.Tensor.cummax", "torch.Tensor.cummin", "torch.Tensor.cumprod", "torch.Tensor.cumprod_", "torch.Tensor.cumsum", "torch.Tensor.cumsum_", "torch.Tensor.data_ptr", "torch.Tensor.deg2rad", "torch.Tensor.dense_dim", "torch.Tensor.dequantize", "torch.Tensor.det", "torch.Tensor.detach", "torch.Tensor.detach_", "torch.Tensor.device", "torch.Tensor.diag", "torch.Tensor.diag_embed", "torch.Tensor.diagflat", "torch.Tensor.diagonal", "torch.Tensor.diagonal_scatter", "torch.Tensor.diff", "torch.Tensor.digamma", "torch.Tensor.digamma_", "torch.Tensor.dim", "torch.Tensor.dist", "torch.Tensor.div", "torch.Tensor.div_", "torch.Tensor.divide", "torch.Tensor.divide_", "torch.Tensor.dot", "torch.Tensor.double", "torch.Tensor.dsplit", "torch.Tensor.eig", "torch.Tensor.element_size", "torch.Tensor.eq", "torch.Tensor.eq_", "torch.Tensor.equal", "torch.Tensor.erf", "torch.Tensor.erf_", "torch.Tensor.erfc", "torch.Tensor.erfc_", "torch.Tensor.erfinv", "torch.Tensor.erfinv_", "torch.Tensor.exp", "torch.Tensor.exp_", "torch.Tensor.expand", "torch.Tensor.expand_as", "torch.Tensor.expm1", "torch.Tensor.expm1_", "torch.Tensor.exponential_", "torch.Tensor.fill_", "torch.Tensor.fill_diagonal_", "torch.Tensor.fix", "torch.Tensor.fix_", "torch.Tensor.flatten", "torch.Tensor.flip", "torch.Tensor.fliplr", "torch.Tensor.flipud", "torch.Tensor.float", "torch.Tensor.float_power", "torch.Tensor.float_power_", "torch.Tensor.floor", "torch.Tensor.floor_", "torch.Tensor.floor_divide", "torch.Tensor.floor_divide_", "torch.Tensor.fmax", "torch.Tensor.fmin", "torch.Tensor.fmod", "torch.Tensor.fmod_", "torch.Tensor.frac", "torch.Tensor.frac_", "torch.Tensor.frexp", "torch.Tensor.gather", "torch.Tensor.gcd", "torch.Tensor.gcd_", "torch.Tensor.ge", "torch.Tensor.ge_", "torch.Tensor.geometric_", "torch.Tensor.geqrf", "torch.Tensor.ger", "torch.Tensor.get_device", "torch.Tensor.grad", "torch.Tensor.greater", "torch.Tensor.greater_", "torch.Tensor.greater_equal", "torch.Tensor.greater_equal_", "torch.Tensor.gt", "torch.Tensor.gt_", "torch.Tensor.half", "torch.Tensor.hardshrink", "torch.Tensor.heaviside", "torch.Tensor.histc", "torch.Tensor.histogram", "torch.Tensor.hsplit", "torch.Tensor.hypot", "torch.Tensor.hypot_", "torch.Tensor.i0", "torch.Tensor.i0_", "torch.Tensor.igamma", "torch.Tensor.igamma_", "torch.Tensor.igammac", "torch.Tensor.igammac_", "torch.Tensor.imag", "torch.Tensor.index_add", "torch.Tensor.index_add_", "torch.Tensor.index_copy", "torch.Tensor.index_copy_", "torch.Tensor.index_fill", "torch.Tensor.index_fill_", "torch.Tensor.index_put", "torch.Tensor.index_put_", "torch.Tensor.index_reduce", "torch.Tensor.index_reduce_", "torch.Tensor.index_select", "torch.Tensor.indices", "torch.Tensor.inner", "torch.Tensor.int", "torch.Tensor.int_repr", "torch.Tensor.inverse", "torch.Tensor.is_coalesced", "torch.Tensor.is_complex", "torch.Tensor.is_conj", "torch.Tensor.is_contiguous", "torch.Tensor.is_cuda", "torch.Tensor.is_floating_point", "torch.Tensor.is_inference", "torch.Tensor.is_leaf", "torch.Tensor.is_meta", "torch.Tensor.is_pinned", "torch.Tensor.is_quantized", "torch.Tensor.is_set_to", "torch.Tensor.is_shared", "torch.Tensor.is_signed", "torch.Tensor.is_sparse", "torch.Tensor.is_sparse_csr", "torch.Tensor.isclose", "torch.Tensor.isfinite", "torch.Tensor.isinf", "torch.Tensor.isnan", "torch.Tensor.isneginf", "torch.Tensor.isposinf", "torch.Tensor.isreal", "torch.Tensor.istft", "torch.Tensor.item", "torch.Tensor.kthvalue", "torch.Tensor.lcm", "torch.Tensor.lcm_", "torch.Tensor.ldexp", "torch.Tensor.ldexp_", "torch.Tensor.le", "torch.Tensor.le_", "torch.Tensor.lerp", "torch.Tensor.lerp_", "torch.Tensor.less", "torch.Tensor.less_", "torch.Tensor.less_equal", "torch.Tensor.less_equal_", "torch.Tensor.lgamma", "torch.Tensor.lgamma_", "torch.Tensor.log", "torch.Tensor.log10", "torch.Tensor.log10_", "torch.Tensor.log1p", "torch.Tensor.log1p_", "torch.Tensor.log2", "torch.Tensor.log2_", "torch.Tensor.log_", "torch.Tensor.log_normal_", "torch.Tensor.logaddexp", "torch.Tensor.logaddexp2", "torch.Tensor.logcumsumexp", "torch.Tensor.logdet", "torch.Tensor.logical_and", "torch.Tensor.logical_and_", "torch.Tensor.logical_not", "torch.Tensor.logical_not_", "torch.Tensor.logical_or", "torch.Tensor.logical_or_", "torch.Tensor.logical_xor", "torch.Tensor.logical_xor_", "torch.Tensor.logit", "torch.Tensor.logit_", "torch.Tensor.logsumexp", "torch.Tensor.long", "torch.Tensor.lstsq", "torch.Tensor.lt", "torch.Tensor.lt_", "torch.Tensor.lu", "torch.Tensor.lu_solve", "torch.Tensor.map_", "torch.Tensor.masked_fill", "torch.Tensor.masked_fill_", "torch.Tensor.masked_scatter", "torch.Tensor.masked_scatter_", "torch.Tensor.masked_select", "torch.Tensor.matmul", "torch.Tensor.matrix_exp", "torch.Tensor.matrix_power", "torch.Tensor.max", "torch.Tensor.maximum", "torch.Tensor.mean", "torch.Tensor.median", "torch.Tensor.min", "torch.Tensor.minimum", "torch.Tensor.mm", "torch.Tensor.mode", "torch.Tensor.moveaxis", "torch.Tensor.movedim", "torch.Tensor.msort", "torch.Tensor.mul", "torch.Tensor.mul_", "torch.Tensor.multinomial", "torch.Tensor.multiply", "torch.Tensor.multiply_", "torch.Tensor.mv", "torch.Tensor.mvlgamma", "torch.Tensor.mvlgamma_", "torch.Tensor.nan_to_num", "torch.Tensor.nan_to_num_", "torch.Tensor.nanmean", "torch.Tensor.nanmedian", "torch.Tensor.nanquantile", "torch.Tensor.nansum", "torch.Tensor.narrow", "torch.Tensor.narrow_copy", "torch.Tensor.ndim", "torch.Tensor.ndimension", "torch.Tensor.ne", "torch.Tensor.ne_", "torch.Tensor.neg", "torch.Tensor.neg_", "torch.Tensor.negative", "torch.Tensor.negative_", "torch.Tensor.nelement", "torch.Tensor.new_empty", "torch.Tensor.new_full", "torch.Tensor.new_ones", "torch.Tensor.new_tensor", "torch.Tensor.new_zeros", "torch.Tensor.nextafter", "torch.Tensor.nextafter_", "torch.Tensor.nonzero", "torch.Tensor.norm", "torch.Tensor.normal_", "torch.Tensor.not_equal", "torch.Tensor.not_equal_", "torch.Tensor.numel", "torch.Tensor.numpy", "torch.Tensor.orgqr", "torch.Tensor.ormqr", "torch.Tensor.outer", "torch.Tensor.permute", "torch.Tensor.pin_memory", "torch.Tensor.pinverse", "torch.Tensor.polygamma", "torch.Tensor.polygamma_", "torch.Tensor.positive", "torch.Tensor.pow", "torch.Tensor.pow_", "torch.Tensor.prod", "torch.Tensor.put_", "torch.Tensor.q_per_channel_axis", "torch.Tensor.q_per_channel_scales", "torch.Tensor.q_per_channel_zero_points", "torch.Tensor.q_scale", "torch.Tensor.q_zero_point", "torch.Tensor.qr", "torch.Tensor.qscheme", "torch.Tensor.quantile", "torch.Tensor.rad2deg", "torch.Tensor.random_", "torch.Tensor.ravel", "torch.Tensor.real", "torch.Tensor.reciprocal", "torch.Tensor.reciprocal_", "torch.Tensor.record_stream", "torch.Tensor.register_hook", "torch.Tensor.remainder", "torch.Tensor.remainder_", "torch.Tensor.renorm", "torch.Tensor.renorm_", "torch.Tensor.repeat", "torch.Tensor.repeat_interleave", "torch.Tensor.requires_grad", "torch.Tensor.requires_grad_", "torch.Tensor.reshape", "torch.Tensor.reshape_as", "torch.Tensor.resize_", "torch.Tensor.resize_as_", "torch.Tensor.resolve_conj", "torch.Tensor.resolve_neg", "torch.Tensor.retain_grad", "torch.Tensor.retains_grad", "torch.Tensor.roll", "torch.Tensor.rot90", "torch.Tensor.round", "torch.Tensor.round_", "torch.Tensor.row_indices", "torch.Tensor.rsqrt", "torch.Tensor.rsqrt_", "torch.Tensor.scatter", "torch.Tensor.scatter_", "torch.Tensor.scatter_add", "torch.Tensor.scatter_add_", "torch.Tensor.scatter_reduce", "torch.Tensor.scatter_reduce_", "torch.Tensor.select", "torch.Tensor.select_scatter", "torch.Tensor.set_", "torch.Tensor.sgn", "torch.Tensor.sgn_", "torch.Tensor.share_memory_", "torch.Tensor.short", "torch.Tensor.sigmoid", "torch.Tensor.sigmoid_", "torch.Tensor.sign", "torch.Tensor.sign_", "torch.Tensor.signbit", "torch.Tensor.sin", "torch.Tensor.sin_", "torch.Tensor.sinc", "torch.Tensor.sinc_", "torch.Tensor.sinh", "torch.Tensor.sinh_", "torch.Tensor.size", "torch.Tensor.slice_scatter", "torch.Tensor.slogdet", "torch.Tensor.smm", "torch.Tensor.sort", "torch.Tensor.sparse_dim", "torch.Tensor.sparse_mask", "torch.Tensor.sparse_resize_", "torch.Tensor.sparse_resize_and_clear_", "torch.Tensor.split", "torch.Tensor.sqrt", "torch.Tensor.sqrt_", "torch.Tensor.square", "torch.Tensor.square_", "torch.Tensor.squeeze", "torch.Tensor.squeeze_", "torch.Tensor.sspaddmm", "torch.Tensor.std", "torch.Tensor.stft", "torch.Tensor.storage", "torch.Tensor.storage_offset", "torch.Tensor.storage_type", "torch.Tensor.stride", "torch.Tensor.sub", "torch.Tensor.sub_", "torch.Tensor.subtract", "torch.Tensor.subtract_", "torch.Tensor.sum", "torch.Tensor.sum_to_size", "torch.Tensor.svd", "torch.Tensor.swapaxes", "torch.Tensor.swapdims", "torch.Tensor.symeig", "torch.Tensor.t", "torch.Tensor.t_", "torch.Tensor.take", "torch.Tensor.take_along_dim", "torch.Tensor.tan", "torch.Tensor.tan_", "torch.Tensor.tanh", "torch.Tensor.tanh_", "torch.Tensor.tensor_split", "torch.Tensor.tile", "torch.Tensor.to", "torch.Tensor.to_dense", "torch.Tensor.to_mkldnn", "torch.Tensor.to_padded_tensor", "torch.Tensor.to_sparse", "torch.Tensor.to_sparse_bsc", "torch.Tensor.to_sparse_bsr", "torch.Tensor.to_sparse_coo", "torch.Tensor.to_sparse_csc", "torch.Tensor.to_sparse_csr", "torch.Tensor.tolist", "torch.Tensor.topk", "torch.Tensor.trace", "torch.Tensor.transpose", "torch.Tensor.transpose_", "torch.Tensor.triangular_solve", "torch.Tensor.tril", "torch.Tensor.tril_", "torch.Tensor.triu", "torch.Tensor.triu_", "torch.Tensor.true_divide", "torch.Tensor.true_divide_", "torch.Tensor.trunc", "torch.Tensor.trunc_", "torch.Tensor.type", "torch.Tensor.type_as", "torch.Tensor.unbind", "torch.Tensor.unflatten", "torch.Tensor.unfold", "torch.Tensor.uniform_", "torch.Tensor.unique", "torch.Tensor.unique_consecutive", "torch.Tensor.unsqueeze", "torch.Tensor.unsqueeze_", "torch.Tensor.values", "torch.Tensor.var", "torch.Tensor.vdot", "torch.Tensor.view", "torch.Tensor.view_as", "torch.Tensor.vsplit", "torch.Tensor.where", "torch.Tensor.xlogy", "torch.Tensor.xlogy_", "torch.Tensor.zero_", "torch._assert", "torch.abs", "torch.absolute", "torch.acos", "torch.acosh", "torch.add", "torch.addbmm", "torch.addcdiv", "torch.addcmul", "torch.addmm", "torch.addmv", "torch.addr", "torch.adjoint", "torch.all", "torch.allclose", "torch.amax", "torch.amin", "torch.aminmax", "torch.angle", "torch.any", "torch.arange", "torch.arccos", "torch.arccosh", "torch.arcsin", "torch.arcsinh", "torch.arctan", "torch.arctan2", "torch.arctanh", "torch.are_deterministic_algorithms_enabled", "torch.argmax", "torch.argmin", "torch.argsort", "torch.argwhere", "torch.as_strided", "torch.as_tensor", "torch.asarray", "torch.asin", "torch.asinh", "torch.atan", "torch.atan2", "torch.atanh", "torch.atleast_1d", "torch.atleast_2d", "torch.atleast_3d", "torch.autograd.Function.backward", "torch.autograd.Function.forward", "torch.autograd.Function.jvp", "torch.autograd.backward", "dual_level", "torch.autograd.forward_ad.make_dual", "torch.autograd.forward_ad.unpack_dual", "torch.autograd.function.FunctionCtx.mark_dirty", "torch.autograd.function.FunctionCtx.mark_non_differentiable", "torch.autograd.function.FunctionCtx.save_for_backward", "torch.autograd.function.FunctionCtx.set_materialize_grads", "torch.autograd.functional.hessian", "torch.autograd.functional.hvp", "torch.autograd.functional.jacobian", "torch.autograd.functional.jvp", "torch.autograd.functional.vhp", "torch.autograd.functional.vjp", "torch.autograd.grad", "torch.autograd.gradcheck", "torch.autograd.gradgradcheck", "torch.autograd.profiler.load_nvprof", "torch.autograd.profiler.profile.export_chrome_trace", "torch.autograd.profiler.profile.key_averages", "torch.autograd.profiler.profile.self_cpu_time_total", "torch.autograd.profiler.profile.total_average", "torch.baddbmm", "torch.bartlett_window", "torch.bernoulli", "torch.bincount", "torch.bitwise_and", "torch.bitwise_left_shift", "torch.bitwise_not", "torch.bitwise_or", "torch.bitwise_right_shift", "torch.bitwise_xor", "torch.blackman_window", "torch.block_diag", "torch.bmm", "torch.broadcast_shapes", "torch.broadcast_tensors", "torch.broadcast_to", "torch.bucketize", "torch.can_cast", "torch.cartesian_prod", "torch.cat", "torch.cdist", "torch.ceil", "torch.chain_matmul", "torch.cholesky", "torch.cholesky_inverse", "torch.cholesky_solve", "torch.chunk", "torch.clamp", "torch.clip", "torch.clone", "torch.column_stack", "torch.combinations", "torch.compiled_with_cxx11_abi", "torch.complex", "torch.concat", "torch.conj", "torch.conj_physical", "torch.copysign", "torch.corrcoef", "torch.cos", "torch.cosh", "torch.count_nonzero", "torch.cov", "torch.cross", "CUDAGraph", "Event", "ExternalStream", "Stream", "StreamContext", "torch.cuda.caching_allocator_alloc", "torch.cuda.caching_allocator_delete", "torch.cuda.can_device_access_peer", "torch.cuda.comm.broadcast", "torch.cuda.comm.broadcast_coalesced", "torch.cuda.comm.gather", "torch.cuda.comm.reduce_add", "torch.cuda.comm.scatter", "torch.cuda.current_blas_handle", "torch.cuda.current_device", "torch.cuda.current_stream", "torch.cuda.default_stream", "device", "torch.cuda.device_count", "device_of", "torch.cuda.empty_cache", "torch.cuda.get_arch_list", "torch.cuda.get_device_capability", "torch.cuda.get_device_name", "torch.cuda.get_device_properties", "torch.cuda.get_gencode_flags", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state_all", "torch.cuda.get_sync_debug_mode", "graph", "torch.cuda.graph_pool_handle", "torch.cuda.init", "torch.cuda.initial_seed", "torch.cuda.ipc_collect", "torch.cuda.is_available", "torch.cuda.is_current_stream_capturing", "torch.cuda.is_initialized", "torch.cuda.jiterator._create_jit_fn", "torch.cuda.jiterator._create_multi_output_jit_fn", "torch.cuda.list_gpu_processes", "torch.cuda.make_graphed_callables", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_cached", "torch.cuda.max_memory_reserved", "torch.cuda.mem_get_info", "torch.cuda.memory_allocated", "torch.cuda.memory_cached", "torch.cuda.memory_reserved", "torch.cuda.memory_snapshot", "torch.cuda.memory_stats", "torch.cuda.memory_summary", "torch.cuda.memory_usage", "torch.cuda.nvtx.mark", "torch.cuda.nvtx.range_pop", "torch.cuda.nvtx.range_push", "torch.cuda.reset_max_memory_allocated", "torch.cuda.reset_max_memory_cached", "torch.cuda.reset_peak_memory_stats", "torch.cuda.seed", "torch.cuda.seed_all", "torch.cuda.set_device", "torch.cuda.set_per_process_memory_fraction", "torch.cuda.set_rng_state", "torch.cuda.set_rng_state_all", "torch.cuda.set_stream", "torch.cuda.set_sync_debug_mode", "torch.cuda.stream", "torch.cuda.synchronize", "torch.cuda.utilization", "torch.cummax", "torch.cummin", "torch.cumprod", "torch.cumsum", "torch.cumulative_trapezoid", "torch.deg2rad", "torch.dequantize", "torch.det", "torch.diag", "torch.diag_embed", "torch.diagflat", "torch.diagonal", "torch.diagonal_scatter", "torch.diff", "torch.digamma", "torch.dist", "torch.div", "torch.divide", "torch.dot", "torch.dsplit", "torch.dstack", "torch.eig", "torch.einsum", "torch.empty", "torch.empty_like", "torch.empty_strided", "enable_grad", "torch.eq", "torch.equal", "torch.erf", "torch.erfc", "torch.erfinv", "torch.exp", "torch.exp2", "torch.expm1", "torch.eye", "torch.fake_quantize_per_channel_affine", "torch.fake_quantize_per_tensor_affine", "torch.fft.fft", "torch.fft.fft2", "torch.fft.fftfreq", "torch.fft.fftn", "torch.fft.fftshift", "torch.fft.hfft", "torch.fft.hfft2", "torch.fft.hfftn", "torch.fft.ifft", "torch.fft.ifft2", "torch.fft.ifftn", "torch.fft.ifftshift", "torch.fft.ihfft", "torch.fft.ihfft2", "torch.fft.ihfftn", "torch.fft.irfft", "torch.fft.irfft2", "torch.fft.irfftn", "torch.fft.rfft", "torch.fft.rfft2", "torch.fft.rfftfreq", "torch.fft.rfftn", "torch.fix", "torch.flatten", "torch.flip", "torch.fliplr", "torch.flipud", "torch.float_power", "torch.floor", "torch.floor_divide", "torch.fmax", "torch.fmin", "torch.fmod", "torch.frac", "torch.frexp", "torch.from_dlpack", "torch.from_numpy", "torch.frombuffer", "torch.full", "torch.full_like", "torch.gather", "torch.gcd", "torch.ge", "torch.geqrf", "torch.ger", "torch.get_default_dtype", "torch.get_deterministic_debug_mode", "torch.get_float32_matmul_precision", "torch.get_num_interop_threads", "torch.get_num_threads", "torch.get_rng_state", "torch.gradient", "torch.greater", "torch.greater_equal", "torch.gt", "torch.hamming_window", "torch.hann_window", "torch.heaviside", "torch.histc", "torch.histogram", "torch.histogramdd", "torch.hsplit", "torch.hspmm", "torch.hstack", "torch.hypot", "torch.i0", "torch.igamma", "torch.igammac", "torch.imag", "torch.index_add", "torch.index_copy", "torch.index_reduce", "torch.index_select", "inference_mode", "torch.initial_seed", "torch.inner", "torch.inverse", "torch.is_complex", "torch.is_conj", "torch.is_deterministic_algorithms_warn_only_enabled", "torch.is_floating_point", "torch.is_grad_enabled", "torch.is_inference_mode_enabled", "torch.is_nonzero", "torch.is_storage", "torch.is_tensor", "torch.is_warn_always_enabled", "torch.isclose", "torch.isfinite", "torch.isin", "torch.isinf", "torch.isnan", "torch.isneginf", "torch.isposinf", "torch.isreal", "torch.istft", "Attribute", "ScriptFunction", "ScriptModule", "torch.jit.annotate", "torch.jit.enable_onednn_fusion", "torch.jit.fork", "torch.jit.freeze", "torch.jit.ignore", "torch.jit.isinstance", "torch.jit.load", "torch.jit.onednn_fusion_enabled", "torch.jit.optimize_for_inference", "torch.jit.save", "torch.jit.script", "torch.jit.script_if_tracing", "torch.jit.set_fusion_strategy", "strict_fusion", "torch.jit.trace", "torch.jit.trace_module", "torch.jit.unused", "torch.jit.wait", "torch.kaiser_window", "torch.kron", "torch.kthvalue", "torch.lcm", "torch.ldexp", "torch.le", "torch.lerp", "torch.less", "torch.less_equal", "torch.lgamma", "torch.linalg.cholesky", "torch.linalg.cholesky_ex", "torch.linalg.cond", "torch.linalg.cross", "torch.linalg.det", "torch.linalg.diagonal", "torch.linalg.eig", "torch.linalg.eigh", "torch.linalg.eigvals", "torch.linalg.eigvalsh", "torch.linalg.householder_product", "torch.linalg.inv", "torch.linalg.inv_ex", "torch.linalg.ldl_factor", "torch.linalg.ldl_factor_ex", "torch.linalg.ldl_solve", "torch.linalg.lstsq", "torch.linalg.lu", "torch.linalg.lu_factor", "torch.linalg.lu_factor_ex", "torch.linalg.lu_solve", "torch.linalg.matmul", "torch.linalg.matrix_exp", "torch.linalg.matrix_norm", "torch.linalg.matrix_power", "torch.linalg.matrix_rank", "torch.linalg.multi_dot", "torch.linalg.norm", "torch.linalg.pinv", "torch.linalg.qr", "torch.linalg.slogdet", "torch.linalg.solve", "torch.linalg.solve_ex", "torch.linalg.solve_triangular", "torch.linalg.svd", "torch.linalg.svdvals", "torch.linalg.tensorinv", "torch.linalg.tensorsolve", "torch.linalg.vander", "torch.linalg.vecdot", "torch.linalg.vector_norm", "torch.linspace", "torch.load", "torch.lobpcg", "torch.log", "torch.log10", "torch.log1p", "torch.log2", "torch.logaddexp", "torch.logaddexp2", "torch.logcumsumexp", "torch.logdet", "torch.logical_and", "torch.logical_not", "torch.logical_or", "torch.logical_xor", "torch.logit", "torch.logspace", "torch.logsumexp", "torch.lstsq", "torch.lt", "torch.lu", "torch.lu_solve", "torch.lu_unpack", "torch.manual_seed", "torch.masked_select", "torch.matmul", "torch.matrix_exp", "torch.matrix_power", "torch.matrix_rank", "torch.max", "torch.maximum", "torch.mean", "torch.median", "torch.meshgrid", "torch.min", "torch.minimum", "torch.mm", "torch.mode", "torch.moveaxis", "torch.movedim", "torch.msort", "torch.mul", "torch.multinomial", "torch.multiply", "torch.mv", "torch.mvlgamma", "torch.nan_to_num", "torch.nanmean", "torch.nanmedian", "torch.nanquantile", "torch.nansum", "torch.narrow", "torch.ne", "torch.neg", "torch.negative", "torch.nextafter", "AdaptiveAvgPool1d", "AdaptiveAvgPool2d", "AdaptiveAvgPool3d", "AdaptiveLogSoftmaxWithLoss", "AdaptiveMaxPool1d", "AdaptiveMaxPool2d", "AdaptiveMaxPool3d", "AlphaDropout", "AvgPool1d", "AvgPool2d", "AvgPool3d", "BCELoss", "BCEWithLogitsLoss", "BatchNorm1d", "BatchNorm2d", "BatchNorm3d", "Bilinear", "CELU", "CTCLoss", "ChannelShuffle", "ConstantPad1d", "ConstantPad2d", "ConstantPad3d", "Conv1d", "Conv2d", "Conv3d", "ConvTranspose1d", "ConvTranspose2d", "ConvTranspose3d", "CosineEmbeddingLoss", "CosineSimilarity", "CrossEntropyLoss", "DataParallel", "Dropout", "Dropout1d", "Dropout2d", "Dropout3d", "ELU", "Embedding", "EmbeddingBag", "FeatureAlphaDropout", "Flatten", "Fold", "FractionalMaxPool2d", "FractionalMaxPool3d", "GELU", "GLU", "GRU", "GRUCell", "GaussianNLLLoss", "GroupNorm", "Hardshrink", "Hardsigmoid", "Hardswish", "Hardtanh", "HingeEmbeddingLoss", "HuberLoss", "Identity", "InstanceNorm1d", "InstanceNorm2d", "InstanceNorm3d", "KLDivLoss", "L1Loss", "LPPool1d", "LPPool2d", "LSTM", "LSTMCell", "LayerNorm", "LazyBatchNorm1d", "LazyBatchNorm2d", "LazyBatchNorm3d", "LazyConv1d", "LazyConv2d", "LazyConv3d", "LazyConvTranspose1d", "LazyConvTranspose2d", "LazyConvTranspose3d", "LazyInstanceNorm1d", "LazyInstanceNorm2d", "LazyInstanceNorm3d", "LazyLinear", "LeakyReLU", "Linear", "LocalResponseNorm", "LogSigmoid", "LogSoftmax", "MSELoss", "MarginRankingLoss", "MaxPool1d", "MaxPool2d", "MaxPool3d", "MaxUnpool1d", "MaxUnpool2d", "MaxUnpool3d", "Mish", "Module", "ModuleDict", "ModuleList", "MultiLabelMarginLoss", "MultiLabelSoftMarginLoss", "MultiMarginLoss", "MultiheadAttention", "NLLLoss", "PReLU", "PairwiseDistance", "ParameterDict", "ParameterList", "PixelShuffle", "PixelUnshuffle", "PoissonNLLLoss", "RNN", "RNNBase", "RNNCell", "RReLU", "ReLU", "ReLU6", "ReflectionPad1d", "ReflectionPad2d", "ReflectionPad3d", "ReplicationPad1d", "ReplicationPad2d", "ReplicationPad3d", "SELU", "Sequential", "SiLU", "Sigmoid", "SmoothL1Loss", "SoftMarginLoss", "Softmax", "Softmax2d", "Softmin", "Softplus", "Softshrink", "Softsign", "SyncBatchNorm", "Tanh", "Tanhshrink", "Threshold", "Transformer", "TransformerDecoder", "TransformerDecoderLayer", "TransformerEncoder", "TransformerEncoderLayer", "TripletMarginLoss", "TripletMarginWithDistanceLoss", "Unflatten", "Unfold", "Upsample", "UpsamplingBilinear2d", "UpsamplingNearest2d", "ZeroPad2d", "torch.nn.functional.adaptive_avg_pool1d", "torch.nn.functional.adaptive_avg_pool2d", "torch.nn.functional.adaptive_avg_pool3d", "torch.nn.functional.adaptive_max_pool1d", "torch.nn.functional.adaptive_max_pool2d", "torch.nn.functional.adaptive_max_pool3d", "torch.nn.functional.affine_grid", "torch.nn.functional.alpha_dropout", "torch.nn.functional.avg_pool1d", "torch.nn.functional.avg_pool2d", "torch.nn.functional.avg_pool3d", "torch.nn.functional.batch_norm", "torch.nn.functional.bilinear", "torch.nn.functional.binary_cross_entropy", "torch.nn.functional.binary_cross_entropy_with_logits", "torch.nn.functional.celu", "torch.nn.functional.conv1d", "torch.nn.functional.conv2d", "torch.nn.functional.conv3d", "torch.nn.functional.conv_transpose1d", "torch.nn.functional.conv_transpose2d", "torch.nn.functional.conv_transpose3d", "torch.nn.functional.cosine_embedding_loss", "torch.nn.functional.cosine_similarity", "torch.nn.functional.cross_entropy", "torch.nn.functional.ctc_loss", "torch.nn.functional.dropout", "torch.nn.functional.dropout1d", "torch.nn.functional.dropout2d", "torch.nn.functional.dropout3d", "torch.nn.functional.elu", "torch.nn.functional.elu_", "torch.nn.functional.embedding", "torch.nn.functional.embedding_bag", "torch.nn.functional.feature_alpha_dropout", "torch.nn.functional.fold", "torch.nn.functional.fractional_max_pool2d", "torch.nn.functional.fractional_max_pool3d", "torch.nn.functional.gaussian_nll_loss", "torch.nn.functional.gelu", "torch.nn.functional.glu", "torch.nn.functional.grid_sample", "torch.nn.functional.group_norm", "torch.nn.functional.gumbel_softmax", "torch.nn.functional.hardshrink", "torch.nn.functional.hardsigmoid", "torch.nn.functional.hardswish", "torch.nn.functional.hardtanh", "torch.nn.functional.hardtanh_", "torch.nn.functional.hinge_embedding_loss", "torch.nn.functional.huber_loss", "torch.nn.functional.instance_norm", "torch.nn.functional.interpolate", "torch.nn.functional.kl_div", "torch.nn.functional.l1_loss", "torch.nn.functional.layer_norm", "torch.nn.functional.leaky_relu", "torch.nn.functional.leaky_relu_", "torch.nn.functional.linear", "torch.nn.functional.local_response_norm", "torch.nn.functional.log_softmax", "torch.nn.functional.logsigmoid", "torch.nn.functional.lp_pool1d", "torch.nn.functional.lp_pool2d", "torch.nn.functional.margin_ranking_loss", "torch.nn.functional.max_pool1d", "torch.nn.functional.max_pool2d", "torch.nn.functional.max_pool3d", "torch.nn.functional.max_unpool1d", "torch.nn.functional.max_unpool2d", "torch.nn.functional.max_unpool3d", "torch.nn.functional.mish", "torch.nn.functional.mse_loss", "torch.nn.functional.multi_margin_loss", "torch.nn.functional.multilabel_margin_loss", "torch.nn.functional.multilabel_soft_margin_loss", "torch.nn.functional.nll_loss", "torch.nn.functional.normalize", "torch.nn.functional.one_hot", "torch.nn.functional.pad", "torch.nn.functional.pairwise_distance", "torch.nn.functional.pdist", "torch.nn.functional.pixel_shuffle", "torch.nn.functional.pixel_unshuffle", "torch.nn.functional.poisson_nll_loss", "torch.nn.functional.prelu", "torch.nn.functional.relu", "torch.nn.functional.relu6", "torch.nn.functional.relu_", "torch.nn.functional.rrelu", "torch.nn.functional.rrelu_", "torch.nn.functional.selu", "torch.nn.functional.sigmoid", "torch.nn.functional.silu", "torch.nn.functional.smooth_l1_loss", "torch.nn.functional.soft_margin_loss", "torch.nn.functional.softmax", "torch.nn.functional.softmin", "torch.nn.functional.softplus", "torch.nn.functional.softshrink", "torch.nn.functional.softsign", "torch.nn.functional.tanh", "torch.nn.functional.tanhshrink", "torch.nn.functional.threshold", "torch.nn.functional.threshold_", "torch.nn.functional.torch.nn.parallel.data_parallel", "torch.nn.functional.triplet_margin_loss", "torch.nn.functional.triplet_margin_with_distance_loss", "torch.nn.functional.unfold", "torch.nn.functional.upsample", "torch.nn.functional.upsample_bilinear", "torch.nn.functional.upsample_nearest", "BNReLU2d", "BNReLU3d", "ConvBn1d", "ConvBn2d", "ConvBn3d", "ConvBnReLU1d", "ConvBnReLU2d", "ConvBnReLU3d", "ConvReLU1d", "ConvReLU2d", "ConvReLU3d", "LinearReLU", "ConvBn1d", "ConvBn2d", "ConvBn3d", "ConvBnReLU1d", "ConvBnReLU2d", "ConvBnReLU3d", "ConvReLU2d", "ConvReLU3d", "LinearReLU", "freeze_bn_stats", "update_bn_stats", "BNReLU2d", "BNReLU3d", "ConvReLU1d", "ConvReLU2d", "ConvReLU3d", "LinearReLU", "LinearReLU", "LazyModuleMixin", "torch.nn.modules.module.register_module_backward_hook", "torch.nn.modules.module.register_module_forward_hook", "torch.nn.modules.module.register_module_forward_pre_hook", "torch.nn.modules.module.register_module_full_backward_hook", "DistributedDataParallel", "Parameter", "UninitializedBuffer", "UninitializedParameter", "Conv2d", "Conv3d", "Linear", "Linear", "LSTM", "MultiheadAttention", "BatchNorm2d", "BatchNorm3d", "Conv1d", "Conv2d", "Conv3d", "ConvTranspose1d", "ConvTranspose2d", "ConvTranspose3d", "ELU", "Embedding", "EmbeddingBag", "FXFloatFunctional", "FloatFunctional", "GroupNorm", "Hardswish", "InstanceNorm1d", "InstanceNorm2d", "InstanceNorm3d", "LayerNorm", "LeakyReLU", "Linear", "QFunctional", "ReLU6", "Sigmoid", "GRU", "GRUCell", "LSTM", "LSTMCell", "Linear", "RNNCell", "adaptive_avg_pool2d", "adaptive_avg_pool3d", "avg_pool2d", "avg_pool3d", "celu", "clamp", "conv1d", "conv2d", "conv3d", "elu", "hardsigmoid", "hardswish", "hardtanh", "interpolate", "leaky_relu", "linear", "max_pool1d", "max_pool2d", "threshold", "upsample", "upsample_bilinear", "upsample_nearest", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.parameters_to_vector", "torch.nn.utils.parametrizations.orthogonal", "torch.nn.utils.parametrizations.spectral_norm", "ParametrizationList", "torch.nn.utils.parametrize.cached", "torch.nn.utils.parametrize.is_parametrized", "torch.nn.utils.parametrize.register_parametrization", "torch.nn.utils.parametrize.remove_parametrizations", "BasePruningMethod", "CustomFromMask", "Identity", "L1Unstructured", "LnStructured", "PruningContainer", "RandomStructured", "RandomUnstructured", "torch.nn.utils.prune.custom_from_mask", "torch.nn.utils.prune.global_unstructured", "torch.nn.utils.prune.identity", "torch.nn.utils.prune.is_pruned", "torch.nn.utils.prune.l1_unstructured", "torch.nn.utils.prune.ln_structured", "torch.nn.utils.prune.random_structured", "torch.nn.utils.prune.random_unstructured", "torch.nn.utils.prune.remove", "torch.nn.utils.remove_spectral_norm", "torch.nn.utils.remove_weight_norm", "PackedSequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.skip_init", "torch.nn.utils.spectral_norm", "torch.nn.utils.stateless.functional_call", "torch.nn.utils.vector_to_parameters", "torch.nn.utils.weight_norm", "no_grad", "torch.nonzero", "torch.norm", "torch.normal", "torch.not_equal", "torch.numel", "torch.ones", "torch.ones_like", "JitScalarType", "SymbolicContext", "ASGD", "Adadelta", "Adagrad", "Adam", "AdamW", "Adamax", "LBFGS", "NAdam", "torch.optim.Optimizer.add_param_group", "torch.optim.Optimizer.load_state_dict", "torch.optim.Optimizer.state_dict", "torch.optim.Optimizer.step", "torch.optim.Optimizer.zero_grad", "RAdam", "RMSprop", "Rprop", "SGD", "SparseAdam", "ChainedScheduler", "ConstantLR", "CosineAnnealingLR", "CosineAnnealingWarmRestarts", "CyclicLR", "ExponentialLR", "LambdaLR", "LinearLR", "MultiStepLR", "MultiplicativeLR", "OneCycleLR", "ReduceLROnPlateau", "SequentialLR", "StepLR", "torch.orgqr", "torch.ormqr", "torch.outer", "torch.pca_lowrank", "torch.permute", "torch.pinverse", "torch.poisson", "torch.polar", "torch.polygamma", "torch.positive", "torch.pow", "torch.prod", "torch.promote_types", "torch.qr", "torch.quantile", "DeQuantStub", "QuantStub", "QuantWrapper", "add_observer", "add_quant_dequant", "convert", "default_eval_fn", "FakeQuantize", "FakeQuantizeBase", "FixedQParamsFakeQuantize", "FusedMovingAvgObsFakeQuantize", "default_fake_quant", "default_fused_act_fake_quant", "default_fused_per_channel_wt_fake_quant", "default_fused_wt_fake_quant", "default_histogram_fake_quant", "default_per_channel_weight_fake_quant", "default_weight_fake_quant", "disable_fake_quant", "disable_observer", "enable_fake_quant", "enable_observer", "fuse_modules", "get_observer_dict", "HistogramObserver", "MinMaxObserver", "MovingAverageMinMaxObserver", "MovingAveragePerChannelMinMaxObserver", "NoopObserver", "ObserverBase", "PerChannelMinMaxObserver", "PlaceholderObserver", "RecordingObserver", "default_debug_observer", "default_dynamic_quant_observer", "default_float_qparams_observer", "default_histogram_observer", "default_observer", "default_per_channel_weight_observer", "default_placeholder_observer", "default_weight_observer", "get_observer_state_dict", "load_observer_state_dict", "prepare", "prepare_qat", "propagate_qconfig", "QConfig", "default_activation_only_qconfig", "default_debug_qconfig", "default_dynamic_qconfig", "default_per_channel_qconfig", "default_qat_qconfig", "default_qat_qconfig_v2", "default_qconfig", "default_weight_only_qconfig", "float16_dynamic_qconfig", "float16_static_qconfig", "float_qparams_weight_only_qconfig", "per_channel_dynamic_qconfig", "quantize", "quantize_dynamic", "convert_fx", "fuse_fx", "prepare_fx", "prepare_qat_fx", "quantize_qat", "swap_module", "torch.quantize_per_channel", "torch.quantize_per_tensor", "torch.quantized_batch_norm", "torch.quantized_max_pool1d", "torch.quantized_max_pool2d", "SobolEngine", "torch.rad2deg", "torch.rand", "torch.rand_like", "torch.randint", "torch.randint_like", "torch.randn", "torch.randn_like", "torch.randperm", "torch.range", "torch.ravel", "torch.real", "torch.reciprocal", "torch.remainder", "torch.renorm", "torch.repeat_interleave", "torch.reshape", "torch.resolve_conj", "torch.resolve_neg", "torch.result_type", "torch.roll", "torch.rot90", "torch.round", "torch.row_stack", "torch.rsqrt", "torch.save", "torch.scatter", "torch.scatter_add", "torch.scatter_reduce", "torch.searchsorted", "torch.seed", "torch.select", "torch.select_scatter", "torch.set_default_dtype", "torch.set_default_tensor_type", "torch.set_deterministic_debug_mode", "torch.set_float32_matmul_precision", "torch.set_flush_denormal", "set_grad_enabled", "torch.set_num_interop_threads", "torch.set_num_threads", "torch.set_printoptions", "torch.set_rng_state", "torch.set_warn_always", "torch.sgn", "torch.sigmoid", "torch.sign", "torch.signbit", "torch.sin", "torch.sinc", "torch.sinh", "torch.slice_scatter", "torch.slogdet", "torch.smm", "torch.sort", "torch.sparse.addmm", "torch.sparse.log_softmax", "torch.sparse.mm", "torch.sparse.sampled_addmm", "torch.sparse.softmax", "torch.sparse.spdiags", "torch.sparse.sum", "torch.sparse_bsc_tensor", "torch.sparse_bsr_tensor", "torch.sparse_compressed_tensor", "torch.sparse_coo_tensor", "torch.sparse_csc_tensor", "torch.sparse_csr_tensor", "torch.split", "torch.sqrt", "torch.square", "torch.squeeze", "torch.sspaddmm", "torch.stack", "torch.std", "torch.std_mean", "torch.stft", "torch.sub", "torch.subtract", "torch.sum", "torch.svd", "torch.svd_lowrank", "torch.swapaxes", "torch.swapdims", "torch.symeig", "torch.t", "torch.take", "torch.take_along_dim", "torch.tan", "torch.tanh", "torch.tensor", "torch.tensor_split", "torch.tensordot", "torch.tile", "torch.topk", "torch.trace", "torch.transpose", "torch.trapezoid", "torch.trapz", "torch.triangular_solve", "torch.tril", "torch.tril_indices", "torch.triu", "torch.triu_indices", "torch.true_divide", "torch.trunc", "torch.unbind", "torch.unflatten", "torch.unique", "torch.unique_consecutive", "torch.unsqueeze", "torch.use_deterministic_algorithms", "torch.vander", "torch.var", "torch.var_mean", "torch.vdot", "torch.view_as_complex", "torch.view_as_real", "torch.vmap", "torch.vsplit", "torch.vstack", "torch.where", "torch.xlogy", "torch.zeros", "torch.zeros_like", "torch.hub", "PyTorch documentation", "TorchScript", "TorchScript Builtins", "TorchScript Language Reference", "TorchScript Language Reference", "Python Language Reference Coverage", "TorchScript Unsupported Pytorch Constructs", "JIT Utils - torch.utils.jit", "torch.library", "torch.linalg", "torch.utils.mobile_optimizer", "torch.utils.model_zoo", "torch.monitor", "Multiprocessing package - torch.multiprocessing", "Named Tensors operator coverage", "Named Tensors", "torch.nested", "torch.nn", "torch.nn.functional", "torch.nn.init", "CUDA Automatic Mixed Precision examples", "Autograd mechanics", "Broadcasting semantics", "CPU threading and TorchScript inference", "CUDA semantics", "Distributed Data Parallel", "Extending PyTorch", "Frequently Asked Questions", "Gradcheck mechanics", "HIP (ROCm) semantics", "Features for large-scale deployments", "Modules", "MPS backend", "Multiprocessing best practices", "Numerical accuracy", "Reproducibility", "Serialization semantics", "Windows FAQ", "torch.onnx", "ONNX supported ATen operators", "torch.optim", "torch.package", "Pipeline Parallelism", "torch.profiler", "Quantization", "Quantization Accuracy Debugging", "Quantization Backend Configuration", "Quantization API Reference", "torch.random", "Distributed RPC Framework", "Distributed Autograd Design", "Remote Reference Protocol", "torch.sparse", "torch.special", "torch.Storage", "Tensor Attributes", "Tensor Views", "torch.utils.tensorboard", "torch.Tensor", "torch.testing", "torch", "torch.ao.ns._numeric_suite", "torch.ao.ns._numeric_suite_fx", "torch.overrides", "Type Info"], "terms": {"provid": [0, 1, 3, 6, 7, 8, 10, 12, 13, 17, 18, 19, 20, 21, 23, 24, 26, 28, 33, 35, 36, 37, 38, 40, 41, 42, 105, 555, 622, 631, 633, 634, 635, 655, 660, 663, 668, 669, 686, 739, 781, 801, 848, 856, 857, 892, 895, 901, 902, 906, 908, 910, 925, 942, 967, 1047, 1048, 1049, 1052, 1068, 1069, 1077, 1082, 1086, 1087, 1112, 1113, 1114, 1116, 1122, 1123, 1126, 1131, 1133, 1144, 1159, 1161, 1163, 1185, 1186, 1319, 1328, 1331, 1332, 1333, 1338, 1339, 1341, 1349, 1350, 1353, 1357, 1391, 1411, 1417, 1429, 1458, 1460, 1465, 1477, 1478, 1484, 1485, 1499, 1506, 1523, 1537, 1568, 1578, 1611, 1612, 1613, 1614, 1615, 1616, 1650, 1652, 1667, 1674, 1676, 1678, 1679, 1683, 1685, 1687, 1688, 1689, 1690, 1699, 1700, 1701, 1703, 1706, 1707, 1709, 1713, 1715, 1716, 1717, 1719, 1720, 1722, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1732, 1733, 1734, 1735, 1739], "conveni": [0, 3, 6, 12, 32, 35, 36, 952, 1314, 1674, 1678, 1683, 1695, 1696, 1699, 1701, 1705, 1706, 1716, 1723], "method": [0, 3, 6, 8, 12, 13, 17, 19, 20, 21, 23, 24, 25, 26, 27, 33, 35, 40, 41, 42, 176, 177, 278, 388, 439, 440, 449, 450, 451, 472, 565, 604, 605, 606, 622, 626, 627, 628, 629, 719, 832, 848, 893, 895, 896, 898, 899, 900, 905, 906, 910, 911, 912, 940, 958, 959, 966, 967, 993, 1014, 1024, 1032, 1059, 1116, 1117, 1118, 1126, 1127, 1144, 1213, 1314, 1319, 1385, 1386, 1389, 1391, 1393, 1396, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1407, 1413, 1416, 1431, 1432, 1433, 1435, 1445, 1476, 1482, 1484, 1520, 1523, 1610, 1625, 1629, 1674, 1676, 1679, 1680, 1685, 1687, 1688, 1689, 1690, 1694, 1695, 1696, 1699, 1701, 1702, 1703, 1706, 1708, 1711, 1715, 1716, 1719, 1721, 1724, 1726, 1729, 1730, 1732, 1733, 1735, 1738], "where": [0, 1, 2, 3, 4, 6, 7, 8, 10, 12, 13, 17, 18, 19, 20, 23, 24, 26, 28, 35, 36, 37, 38, 40, 42, 108, 178, 209, 355, 357, 439, 588, 590, 591, 594, 607, 625, 630, 632, 640, 645, 654, 660, 667, 668, 669, 682, 686, 690, 698, 700, 759, 760, 763, 767, 780, 786, 797, 798, 800, 803, 804, 806, 807, 809, 810, 811, 813, 814, 816, 818, 839, 848, 851, 852, 853, 854, 884, 885, 887, 888, 891, 892, 893, 896, 908, 914, 915, 916, 919, 924, 925, 926, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 946, 947, 948, 949, 951, 952, 953, 954, 955, 956, 957, 958, 959, 962, 963, 964, 966, 967, 972, 975, 982, 984, 985, 986, 990, 993, 994, 996, 997, 998, 999, 1002, 1007, 1012, 1013, 1015, 1017, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1058, 1059, 1060, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1128, 1129, 1130, 1131, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1145, 1146, 1147, 1148, 1149, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1184, 1196, 1197, 1204, 1209, 1211, 1212, 1230, 1231, 1248, 1250, 1251, 1254, 1255, 1257, 1265, 1319, 1321, 1322, 1328, 1351, 1353, 1374, 1384, 1411, 1412, 1413, 1414, 1421, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1440, 1443, 1444, 1445, 1446, 1447, 1450, 1451, 1452, 1463, 1473, 1475, 1476, 1502, 1503, 1563, 1564, 1600, 1603, 1607, 1608, 1611, 1612, 1613, 1614, 1615, 1616, 1625, 1628, 1629, 1633, 1639, 1648, 1649, 1650, 1651, 1652, 1657, 1658, 1664, 1665, 1666, 1667, 1676, 1677, 1679, 1680, 1686, 1688, 1694, 1695, 1696, 1697, 1699, 1701, 1702, 1703, 1706, 1709, 1710, 1713, 1714, 1715, 1716, 1717, 1719, 1722, 1724, 1726, 1727, 1728, 1730, 1732, 1738], "some": [0, 1, 3, 5, 6, 7, 8, 12, 16, 18, 19, 20, 24, 26, 28, 36, 37, 41, 42, 430, 448, 517, 735, 739, 742, 781, 802, 804, 812, 813, 814, 829, 870, 892, 893, 895, 896, 905, 908, 910, 940, 958, 964, 998, 1024, 1028, 1032, 1033, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1076, 1079, 1080, 1081, 1082, 1083, 1086, 1107, 1108, 1116, 1119, 1120, 1121, 1123, 1130, 1131, 1147, 1148, 1164, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1196, 1197, 1198, 1225, 1248, 1251, 1256, 1314, 1319, 1320, 1321, 1322, 1341, 1384, 1415, 1446, 1452, 1458, 1475, 1562, 1585, 1592, 1629, 1667, 1674, 1676, 1677, 1678, 1679, 1680, 1683, 1685, 1688, 1689, 1690, 1695, 1696, 1699, 1701, 1702, 1703, 1705, 1706, 1708, 1709, 1710, 1711, 1712, 1713, 1715, 1716, 1719, 1720, 1722, 1724, 1725, 1726, 1727, 1732], "oper": [0, 2, 4, 5, 6, 7, 10, 13, 17, 24, 25, 32, 33, 35, 36, 41, 42, 209, 268, 276, 290, 307, 357, 398, 399, 400, 401, 402, 445, 448, 465, 467, 469, 541, 581, 584, 595, 619, 620, 621, 626, 628, 644, 645, 647, 649, 652, 654, 656, 658, 663, 666, 669, 673, 680, 690, 691, 716, 725, 755, 759, 760, 761, 762, 775, 781, 782, 783, 784, 794, 799, 817, 829, 832, 834, 835, 836, 843, 846, 852, 853, 870, 895, 905, 906, 910, 911, 914, 924, 937, 947, 950, 951, 964, 965, 974, 981, 990, 996, 1001, 1012, 1015, 1028, 1033, 1038, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1063, 1064, 1065, 1073, 1074, 1075, 1076, 1078, 1083, 1102, 1107, 1112, 1113, 1114, 1116, 1129, 1134, 1135, 1136, 1143, 1158, 1159, 1161, 1163, 1167, 1181, 1182, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1198, 1199, 1200, 1201, 1205, 1206, 1208, 1209, 1213, 1217, 1224, 1230, 1232, 1238, 1239, 1249, 1251, 1255, 1268, 1269, 1280, 1281, 1282, 1283, 1319, 1321, 1322, 1334, 1335, 1336, 1340, 1341, 1350, 1351, 1361, 1362, 1372, 1378, 1413, 1417, 1422, 1426, 1427, 1444, 1450, 1459, 1463, 1472, 1473, 1484, 1505, 1508, 1538, 1540, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1562, 1568, 1584, 1585, 1605, 1607, 1608, 1611, 1612, 1613, 1614, 1615, 1616, 1620, 1628, 1633, 1639, 1660, 1667, 1670, 1672, 1673, 1675, 1676, 1680, 1683, 1695, 1697, 1698, 1699, 1700, 1702, 1706, 1707, 1708, 1709, 1710, 1718, 1720, 1722, 1723, 1724, 1725, 1728, 1730, 1731, 1734], "us": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 17, 19, 21, 23, 24, 25, 26, 27, 28, 32, 33, 34, 35, 36, 37, 40, 41, 43, 52, 74, 105, 109, 146, 163, 274, 276, 290, 297, 298, 361, 401, 411, 439, 440, 448, 451, 465, 469, 472, 494, 568, 581, 584, 595, 608, 609, 610, 619, 620, 621, 622, 623, 624, 625, 627, 628, 630, 631, 632, 633, 636, 637, 638, 641, 644, 645, 646, 654, 656, 657, 664, 666, 668, 679, 682, 684, 687, 688, 689, 690, 691, 693, 694, 697, 707, 708, 710, 711, 717, 721, 725, 727, 728, 729, 731, 733, 734, 740, 748, 750, 751, 757, 761, 762, 763, 772, 780, 781, 782, 784, 794, 795, 796, 799, 801, 809, 811, 815, 817, 824, 826, 829, 835, 840, 841, 845, 846, 848, 852, 853, 854, 855, 869, 870, 882, 892, 893, 895, 896, 899, 900, 901, 902, 904, 905, 906, 907, 908, 910, 911, 912, 914, 916, 918, 926, 930, 931, 933, 934, 935, 937, 938, 939, 940, 941, 942, 947, 948, 949, 951, 952, 958, 959, 960, 964, 965, 966, 967, 972, 975, 981, 985, 986, 989, 990, 993, 996, 997, 998, 1001, 1007, 1012, 1014, 1015, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1039, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1068, 1069, 1070, 1071, 1076, 1077, 1079, 1080, 1081, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1103, 1104, 1109, 1110, 1111, 1112, 1113, 1116, 1118, 1122, 1123, 1124, 1125, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1147, 1149, 1152, 1155, 1163, 1164, 1165, 1166, 1168, 1171, 1178, 1180, 1181, 1182, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1198, 1199, 1200, 1201, 1204, 1205, 1206, 1208, 1209, 1213, 1215, 1222, 1224, 1225, 1232, 1237, 1238, 1239, 1249, 1251, 1257, 1266, 1268, 1269, 1277, 1281, 1282, 1283, 1296, 1297, 1298, 1299, 1300, 1301, 1304, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1328, 1341, 1350, 1353, 1361, 1362, 1365, 1366, 1367, 1372, 1374, 1378, 1379, 1380, 1381, 1384, 1385, 1386, 1387, 1389, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1400, 1403, 1404, 1411, 1412, 1413, 1415, 1416, 1417, 1419, 1420, 1422, 1423, 1426, 1428, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1455, 1456, 1458, 1460, 1461, 1463, 1473, 1475, 1476, 1479, 1484, 1485, 1487, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1519, 1537, 1540, 1544, 1547, 1548, 1549, 1551, 1553, 1555, 1557, 1558, 1564, 1571, 1574, 1579, 1582, 1583, 1585, 1587, 1588, 1589, 1599, 1603, 1605, 1607, 1608, 1611, 1612, 1613, 1614, 1615, 1616, 1623, 1624, 1625, 1628, 1629, 1630, 1633, 1639, 1643, 1646, 1650, 1652, 1657, 1659, 1660, 1662, 1663, 1664, 1667, 1672, 1674, 1675, 1676, 1677, 1679, 1680, 1681, 1683, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1694, 1695, 1698, 1700, 1702, 1704, 1705, 1706, 1708, 1709, 1710, 1711, 1712, 1718, 1720, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738], "float": [0, 1, 3, 10, 17, 18, 20, 24, 29, 40, 42, 108, 109, 174, 268, 270, 272, 276, 288, 355, 428, 434, 465, 534, 580, 582, 587, 589, 593, 595, 610, 637, 638, 645, 646, 654, 661, 668, 677, 681, 682, 686, 687, 751, 763, 774, 775, 786, 799, 817, 826, 827, 828, 829, 831, 839, 842, 851, 852, 853, 856, 857, 877, 884, 885, 887, 888, 889, 890, 893, 895, 910, 911, 914, 918, 920, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 939, 940, 941, 942, 944, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 957, 958, 959, 960, 961, 962, 963, 964, 965, 967, 972, 981, 984, 986, 993, 1006, 1007, 1011, 1013, 1014, 1015, 1017, 1020, 1024, 1028, 1050, 1051, 1052, 1055, 1056, 1057, 1059, 1060, 1061, 1070, 1076, 1077, 1108, 1116, 1121, 1122, 1124, 1125, 1130, 1137, 1138, 1139, 1140, 1141, 1147, 1159, 1164, 1165, 1168, 1169, 1170, 1195, 1196, 1204, 1205, 1210, 1224, 1249, 1256, 1281, 1319, 1325, 1328, 1331, 1332, 1333, 1338, 1339, 1341, 1349, 1354, 1355, 1356, 1357, 1358, 1364, 1365, 1366, 1367, 1372, 1374, 1378, 1381, 1382, 1385, 1394, 1395, 1397, 1398, 1400, 1403, 1404, 1405, 1406, 1413, 1414, 1416, 1422, 1423, 1428, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1443, 1444, 1445, 1446, 1447, 1449, 1450, 1451, 1452, 1453, 1455, 1456, 1458, 1459, 1461, 1463, 1469, 1472, 1476, 1484, 1501, 1520, 1521, 1536, 1537, 1544, 1545, 1546, 1558, 1562, 1563, 1582, 1583, 1586, 1590, 1626, 1629, 1646, 1648, 1660, 1676, 1677, 1678, 1679, 1680, 1687, 1688, 1689, 1692, 1695, 1699, 1701, 1702, 1706, 1709, 1713, 1716, 1718, 1719, 1720, 1724, 1727, 1728, 1729, 1730, 1732, 1733, 1734, 1736, 1739], "datatyp": [0, 42, 610, 895, 993, 1116, 1321, 1322, 1585, 1709, 1713], "other": [0, 1, 2, 3, 4, 6, 7, 8, 12, 13, 17, 18, 21, 23, 24, 25, 26, 28, 32, 33, 35, 36, 40, 41, 42, 52, 53, 68, 84, 85, 88, 100, 101, 104, 105, 114, 115, 120, 121, 151, 152, 153, 162, 188, 193, 198, 199, 200, 210, 229, 230, 237, 238, 239, 240, 246, 247, 248, 249, 250, 251, 258, 259, 262, 263, 264, 265, 268, 270, 276, 279, 299, 307, 309, 310, 311, 312, 313, 314, 317, 318, 319, 320, 332, 333, 349, 350, 363, 367, 391, 392, 403, 404, 408, 409, 450, 472, 511, 512, 513, 514, 531, 567, 568, 569, 572, 573, 580, 589, 595, 601, 608, 609, 614, 620, 622, 623, 636, 637, 638, 648, 649, 651, 652, 653, 655, 660, 681, 687, 688, 690, 691, 693, 698, 708, 728, 768, 774, 775, 776, 777, 785, 786, 787, 801, 808, 826, 827, 828, 829, 832, 837, 838, 839, 849, 850, 851, 860, 861, 863, 864, 869, 870, 872, 884, 893, 895, 899, 906, 915, 917, 918, 919, 921, 922, 927, 945, 947, 950, 951, 964, 972, 973, 974, 976, 978, 979, 982, 983, 984, 990, 994, 995, 999, 1000, 1004, 1006, 1008, 1017, 1020, 1044, 1045, 1046, 1047, 1048, 1049, 1051, 1053, 1063, 1070, 1082, 1116, 1117, 1126, 1144, 1159, 1163, 1167, 1188, 1189, 1190, 1215, 1224, 1281, 1314, 1319, 1331, 1332, 1333, 1334, 1335, 1336, 1400, 1420, 1424, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1449, 1450, 1455, 1456, 1461, 1463, 1499, 1538, 1558, 1562, 1578, 1582, 1585, 1587, 1611, 1612, 1613, 1614, 1615, 1616, 1620, 1626, 1627, 1639, 1645, 1649, 1651, 1664, 1665, 1671, 1674, 1676, 1677, 1678, 1679, 1680, 1681, 1683, 1685, 1688, 1689, 1690, 1691, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1706, 1707, 1708, 1709, 1711, 1713, 1715, 1719, 1720, 1724, 1725, 1726, 1728, 1732, 1733, 1734, 1738], "lower": [0, 1, 7, 18, 20, 24, 655, 660, 667, 668, 669, 671, 795, 796, 855, 856, 924, 931, 933, 941, 942, 949, 952, 957, 997, 1007, 1014, 1024, 1134, 1188, 1189, 1190, 1261, 1262, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1452, 1458, 1459, 1474, 1476, 1563, 1578, 1585, 1609, 1633, 1648, 1649, 1650, 1676, 1677, 1679, 1692, 1694, 1696, 1706, 1719, 1728, 1734], "point": [0, 1, 6, 7, 8, 10, 17, 18, 19, 21, 23, 26, 32, 35, 36, 40, 42, 43, 108, 109, 276, 288, 294, 434, 593, 595, 610, 631, 633, 634, 635, 637, 638, 645, 646, 654, 681, 682, 686, 731, 733, 742, 745, 746, 827, 828, 829, 842, 848, 852, 853, 857, 877, 892, 895, 910, 911, 918, 920, 941, 942, 965, 967, 972, 981, 1014, 1020, 1029, 1030, 1031, 1044, 1045, 1046, 1047, 1048, 1049, 1063, 1109, 1110, 1111, 1116, 1167, 1168, 1178, 1204, 1213, 1224, 1281, 1319, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1352, 1354, 1355, 1356, 1357, 1358, 1368, 1370, 1372, 1373, 1374, 1378, 1422, 1430, 1460, 1476, 1484, 1501, 1502, 1503, 1504, 1507, 1544, 1545, 1549, 1558, 1571, 1582, 1583, 1590, 1660, 1676, 1678, 1679, 1680, 1683, 1687, 1692, 1694, 1695, 1696, 1700, 1703, 1706, 1709, 1717, 1718, 1719, 1720, 1722, 1724, 1725, 1727, 1730, 1732, 1733, 1734, 1736, 1739], "lower_precision_fp": 0, "half": [0, 1, 9, 18, 24, 568, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 895, 957, 963, 1044, 1045, 1046, 1047, 1048, 1049, 1064, 1065, 1067, 1116, 1208, 1209, 1212, 1452, 1571, 1625, 1689, 1706, 1709, 1729, 1730, 1733], "like": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 17, 18, 19, 20, 24, 33, 35, 36, 40, 42, 291, 541, 568, 608, 628, 637, 638, 645, 654, 725, 726, 735, 775, 781, 782, 802, 824, 827, 828, 834, 852, 853, 893, 895, 896, 902, 905, 910, 914, 941, 942, 953, 966, 1024, 1032, 1060, 1063, 1079, 1080, 1081, 1116, 1117, 1118, 1126, 1127, 1144, 1167, 1207, 1225, 1280, 1314, 1319, 1320, 1321, 1322, 1353, 1385, 1410, 1426, 1469, 1523, 1538, 1539, 1551, 1555, 1574, 1582, 1585, 1629, 1636, 1667, 1672, 1674, 1675, 1676, 1678, 1679, 1688, 1689, 1690, 1695, 1696, 1699, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1711, 1712, 1713, 1717, 1718, 1719, 1722, 1724, 1725, 1727, 1729, 1730, 1734, 1737, 1738], "linear": [0, 2, 8, 18, 20, 21, 23, 24, 40, 42, 385, 425, 426, 427, 428, 429, 432, 632, 669, 691, 781, 895, 899, 906, 920, 926, 937, 938, 939, 940, 941, 942, 944, 955, 957, 986, 1014, 1032, 1038, 1058, 1066, 1067, 1075, 1101, 1116, 1118, 1131, 1133, 1135, 1143, 1145, 1152, 1155, 1166, 1168, 1202, 1211, 1212, 1224, 1258, 1265, 1270, 1281, 1295, 1304, 1312, 1313, 1314, 1319, 1358, 1384, 1385, 1389, 1399, 1400, 1401, 1402, 1403, 1405, 1406, 1407, 1408, 1409, 1415, 1416, 1419, 1455, 1458, 1465, 1476, 1499, 1524, 1531, 1537, 1538, 1540, 1660, 1667, 1677, 1678, 1684, 1685, 1694, 1699, 1700, 1701, 1702, 1706, 1709, 1711, 1713, 1714, 1715, 1717, 1719, 1720, 1721, 1722, 1724], "layer": [0, 7, 18, 20, 23, 40, 1029, 1030, 1031, 1033, 1034, 1035, 1036, 1037, 1044, 1045, 1046, 1047, 1048, 1049, 1055, 1056, 1057, 1061, 1068, 1069, 1071, 1079, 1080, 1081, 1086, 1087, 1088, 1101, 1103, 1109, 1110, 1111, 1122, 1123, 1131, 1133, 1144, 1155, 1159, 1160, 1161, 1162, 1163, 1227, 1319, 1327, 1328, 1353, 1384, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1443, 1444, 1445, 1446, 1447, 1523, 1537, 1694, 1699, 1701, 1702, 1705, 1706, 1711, 1715, 1717, 1719, 1720, 1722, 1737], "convolut": [0, 1, 2, 904, 1044, 1045, 1046, 1047, 1048, 1049, 1055, 1056, 1057, 1061, 1092, 1093, 1094, 1095, 1096, 1097, 1128, 1129, 1134, 1164, 1165, 1167, 1188, 1189, 1190, 1191, 1192, 1193, 1212, 1213, 1331, 1332, 1333, 1334, 1335, 1336, 1365, 1366, 1367, 1585, 1677, 1685, 1694, 1698, 1699, 1703, 1706, 1714, 1718, 1719, 1722], "ar": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 32, 33, 35, 36, 37, 40, 41, 42, 43, 52, 105, 209, 274, 276, 290, 291, 294, 331, 401, 424, 434, 439, 451, 465, 469, 494, 531, 541, 568, 584, 585, 586, 592, 595, 604, 605, 616, 617, 618, 620, 622, 628, 630, 631, 632, 633, 634, 635, 637, 638, 645, 654, 655, 657, 658, 660, 663, 669, 677, 681, 682, 685, 686, 689, 690, 691, 692, 694, 697, 719, 725, 728, 729, 739, 748, 755, 763, 768, 772, 775, 780, 781, 797, 798, 799, 800, 802, 804, 809, 811, 817, 820, 822, 823, 827, 828, 829, 840, 848, 852, 853, 855, 857, 870, 872, 884, 885, 887, 888, 891, 892, 893, 895, 896, 899, 901, 902, 905, 908, 910, 911, 916, 924, 925, 926, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 947, 949, 950, 951, 952, 953, 955, 956, 957, 958, 959, 961, 964, 965, 966, 967, 976, 977, 978, 979, 981, 982, 983, 985, 987, 988, 990, 993, 994, 997, 998, 999, 1002, 1004, 1007, 1011, 1012, 1013, 1014, 1024, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1060, 1061, 1063, 1068, 1069, 1070, 1071, 1076, 1079, 1080, 1081, 1082, 1083, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1103, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1126, 1127, 1130, 1131, 1133, 1144, 1147, 1148, 1149, 1155, 1159, 1161, 1163, 1164, 1165, 1167, 1168, 1178, 1184, 1185, 1186, 1196, 1197, 1205, 1206, 1207, 1213, 1224, 1225, 1248, 1251, 1253, 1256, 1280, 1281, 1282, 1283, 1314, 1318, 1319, 1320, 1321, 1322, 1328, 1349, 1353, 1354, 1356, 1357, 1358, 1372, 1375, 1376, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1387, 1389, 1396, 1410, 1414, 1415, 1416, 1418, 1420, 1422, 1423, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1454, 1457, 1458, 1469, 1475, 1476, 1480, 1484, 1499, 1501, 1502, 1503, 1504, 1507, 1522, 1537, 1539, 1540, 1549, 1558, 1561, 1562, 1569, 1571, 1582, 1585, 1603, 1604, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1621, 1625, 1628, 1629, 1633, 1634, 1636, 1640, 1642, 1643, 1645, 1646, 1648, 1649, 1650, 1651, 1652, 1660, 1661, 1662, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1685, 1687, 1688, 1689, 1690, 1691, 1692, 1694, 1695, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1708, 1709, 1710, 1711, 1712, 1713, 1715, 1717, 1718, 1719, 1720, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1738, 1739], "much": [0, 4, 6, 8, 13, 17, 18, 40, 105, 622, 631, 636, 930, 931, 958, 967, 1060, 1319, 1400, 1458, 1676, 1696, 1699, 1703, 1706, 1711, 1716, 1717, 1724, 1725, 1727], "faster": [0, 7, 10, 17, 18, 40, 631, 637, 638, 781, 924, 925, 930, 931, 935, 940, 948, 950, 952, 955, 958, 960, 964, 967, 1132, 1149, 1253, 1268, 1319, 1384, 1445, 1611, 1612, 1613, 1615, 1616, 1685, 1696, 1699, 1703, 1719, 1727, 1732], "reduct": [0, 2, 20, 276, 465, 469, 940, 972, 1014, 1032, 1033, 1039, 1050, 1052, 1060, 1070, 1076, 1077, 1082, 1083, 1107, 1108, 1119, 1120, 1121, 1123, 1130, 1147, 1148, 1164, 1165, 1185, 1186, 1194, 1196, 1197, 1205, 1210, 1221, 1222, 1225, 1226, 1236, 1244, 1245, 1246, 1247, 1248, 1256, 1266, 1267, 1278, 1279, 1319, 1476, 1677, 1689, 1700, 1703, 1716, 1719], "often": [0, 2, 4, 6, 7, 12, 17, 20, 24, 36, 42, 105, 622, 636, 910, 941, 942, 951, 1002, 1059, 1079, 1080, 1081, 1178, 1186, 1196, 1204, 1213, 1314, 1384, 1459, 1679, 1696, 1699, 1702, 1705, 1706, 1709, 1710, 1716, 1724, 1732], "requir": [0, 1, 5, 7, 8, 12, 13, 17, 18, 19, 20, 21, 23, 24, 26, 34, 35, 40, 41, 42, 74, 105, 176, 290, 411, 448, 465, 467, 469, 510, 610, 619, 622, 627, 630, 631, 632, 633, 634, 635, 636, 687, 728, 738, 781, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 822, 823, 837, 908, 934, 965, 967, 981, 1052, 1059, 1060, 1159, 1160, 1161, 1162, 1163, 1165, 1205, 1314, 1319, 1320, 1387, 1389, 1391, 1436, 1446, 1505, 1508, 1540, 1613, 1660, 1667, 1674, 1676, 1679, 1681, 1685, 1688, 1690, 1695, 1696, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1708, 1711, 1713, 1716, 1717, 1719, 1720, 1724, 1725, 1726, 1727, 1732, 1734, 1738], "dynam": [0, 12, 13, 17, 19, 902, 908, 910, 966, 1313, 1326, 1353, 1354, 1355, 1356, 1357, 1358, 1384, 1537, 1538, 1678, 1679, 1680, 1694, 1699, 1706, 1709, 1713, 1715, 1716, 1720], "rang": [0, 1, 3, 17, 20, 21, 23, 24, 35, 36, 38, 42, 43, 256, 434, 579, 615, 646, 671, 743, 744, 751, 781, 831, 855, 856, 857, 961, 972, 988, 998, 1014, 1024, 1052, 1062, 1064, 1065, 1069, 1075, 1087, 1106, 1118, 1123, 1127, 1133, 1149, 1150, 1151, 1155, 1208, 1209, 1213, 1268, 1319, 1354, 1356, 1358, 1382, 1448, 1449, 1451, 1452, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1476, 1501, 1502, 1503, 1504, 1505, 1507, 1508, 1509, 1608, 1659, 1676, 1677, 1679, 1696, 1698, 1699, 1702, 1706, 1708, 1709, 1713, 1715, 1718, 1719, 1722, 1723, 1728, 1730, 1732, 1733, 1734, 1735], "tri": [0, 3, 6, 17, 24, 28, 42, 531, 895, 1116, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1678, 1679, 1688, 1702, 1713, 1716], "match": [0, 1, 3, 20, 23, 24, 35, 42, 105, 268, 270, 276, 426, 427, 451, 452, 531, 588, 594, 608, 622, 636, 637, 638, 687, 689, 698, 699, 700, 728, 772, 781, 872, 895, 908, 927, 966, 989, 1051, 1060, 1116, 1168, 1185, 1186, 1224, 1250, 1257, 1281, 1319, 1372, 1389, 1423, 1544, 1578, 1609, 1641, 1676, 1679, 1689, 1691, 1696, 1697, 1699, 1701, 1706, 1711, 1713, 1715, 1716, 1717, 1719, 1720, 1721, 1724, 1730, 1734, 1736], "each": [0, 1, 5, 8, 12, 17, 18, 20, 21, 23, 24, 26, 28, 33, 36, 37, 38, 40, 42, 52, 74, 108, 109, 353, 445, 465, 467, 469, 495, 534, 559, 568, 576, 578, 581, 588, 590, 591, 594, 595, 607, 616, 617, 618, 619, 621, 622, 627, 636, 644, 647, 656, 660, 664, 665, 667, 670, 674, 686, 696, 700, 728, 731, 733, 739, 741, 747, 753, 758, 759, 760, 763, 764, 775, 778, 780, 781, 798, 800, 801, 802, 803, 804, 806, 807, 810, 811, 812, 813, 814, 816, 818, 822, 823, 825, 830, 834, 837, 848, 854, 856, 857, 858, 884, 885, 886, 887, 888, 889, 890, 891, 895, 910, 911, 916, 948, 966, 967, 982, 983, 985, 994, 996, 997, 998, 999, 1002, 1004, 1007, 1013, 1015, 1024, 1029, 1032, 1033, 1037, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1059, 1060, 1061, 1063, 1068, 1069, 1071, 1076, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1088, 1096, 1097, 1101, 1103, 1107, 1108, 1116, 1119, 1120, 1121, 1122, 1123, 1124, 1130, 1131, 1133, 1144, 1147, 1148, 1150, 1155, 1158, 1164, 1165, 1167, 1183, 1185, 1186, 1191, 1192, 1193, 1196, 1197, 1199, 1200, 1201, 1204, 1205, 1206, 1210, 1213, 1223, 1225, 1248, 1249, 1251, 1253, 1256, 1275, 1314, 1318, 1319, 1328, 1353, 1410, 1411, 1413, 1421, 1422, 1423, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1440, 1443, 1444, 1445, 1446, 1447, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1461, 1468, 1472, 1473, 1476, 1522, 1523, 1538, 1550, 1558, 1563, 1564, 1569, 1573, 1578, 1590, 1596, 1610, 1611, 1612, 1613, 1615, 1616, 1617, 1628, 1629, 1633, 1640, 1642, 1643, 1646, 1657, 1658, 1661, 1667, 1668, 1674, 1678, 1679, 1689, 1690, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1705, 1706, 1708, 1710, 1711, 1713, 1715, 1717, 1718, 1719, 1724, 1725, 1726, 1727, 1728, 1730, 1732, 1733, 1734, 1736, 1737], "its": [0, 1, 4, 5, 6, 7, 8, 12, 13, 17, 18, 19, 20, 21, 23, 24, 26, 27, 35, 36, 37, 40, 41, 42, 105, 411, 440, 456, 465, 467, 469, 568, 604, 605, 606, 608, 609, 610, 622, 625, 668, 669, 677, 682, 686, 692, 717, 719, 728, 763, 767, 770, 781, 784, 829, 834, 856, 857, 861, 875, 895, 905, 930, 931, 935, 940, 947, 949, 952, 953, 958, 964, 990, 1005, 1032, 1034, 1035, 1036, 1044, 1045, 1046, 1047, 1048, 1049, 1053, 1079, 1080, 1081, 1116, 1117, 1126, 1147, 1155, 1213, 1224, 1251, 1257, 1314, 1318, 1320, 1321, 1322, 1385, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1411, 1415, 1419, 1423, 1433, 1434, 1435, 1437, 1443, 1444, 1447, 1466, 1505, 1508, 1558, 1562, 1566, 1567, 1582, 1583, 1587, 1596, 1630, 1645, 1646, 1648, 1656, 1665, 1676, 1678, 1679, 1683, 1685, 1687, 1688, 1695, 1696, 1697, 1699, 1700, 1701, 1702, 1703, 1706, 1710, 1711, 1712, 1713, 1715, 1716, 1717, 1724, 1725, 1726, 1727, 1730, 1731, 1733, 1736], "appropri": [0, 6, 7, 8, 19, 20, 21, 24, 40, 41, 42, 623, 728, 910, 1679, 1680, 1683, 1690, 1703, 1717, 1719, 1724, 1725, 1726, 1729, 1738], "ordinarili": [0, 1695], "train": [0, 1, 13, 17, 18, 20, 21, 22, 23, 26, 33, 34, 35, 36, 40, 42, 727, 728, 731, 733, 740, 870, 895, 900, 906, 909, 910, 1024, 1028, 1034, 1035, 1036, 1052, 1053, 1054, 1059, 1060, 1071, 1079, 1080, 1081, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1116, 1122, 1123, 1155, 1163, 1179, 1183, 1198, 1199, 1200, 1201, 1204, 1205, 1206, 1261, 1262, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1319, 1323, 1324, 1325, 1326, 1385, 1387, 1389, 1416, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1452, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1484, 1486, 1520, 1521, 1536, 1538, 1540, 1541, 1542, 1674, 1676, 1677, 1685, 1687, 1694, 1696, 1699, 1700, 1702, 1707, 1709, 1711, 1713, 1715, 1716, 1717, 1718, 1722, 1724, 1726, 1732], "gradscal": [0, 1695, 1699], "togeth": [0, 3, 8, 17, 20, 24, 40, 42, 725, 781, 840, 934, 1068, 1086, 1131, 1224, 1319, 1353, 1381, 1646, 1685, 1695, 1701, 1702, 1705, 1706, 1713, 1719, 1724, 1725, 1726, 1732], "shown": [0, 18, 19, 27, 36, 725, 735, 1088, 1389, 1458, 1676, 1679, 1695, 1699, 1701, 1702, 1706, 1717, 1719], "exampl": [0, 1, 2, 3, 5, 6, 7, 8, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 33, 34, 35, 36, 37, 38, 40, 41, 43, 146, 163, 197, 209, 215, 244, 266, 268, 270, 272, 276, 290, 307, 387, 398, 399, 400, 401, 402, 424, 434, 436, 440, 445, 448, 451, 465, 467, 469, 488, 494, 508, 510, 531, 532, 534, 535, 536, 537, 538, 539, 540, 541, 559, 568, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 644, 646, 647, 648, 649, 650, 651, 652, 653, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 674, 675, 677, 679, 680, 681, 682, 683, 684, 685, 686, 687, 725, 726, 731, 733, 759, 760, 761, 762, 763, 764, 767, 768, 769, 770, 771, 772, 774, 775, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 791, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 837, 838, 839, 842, 848, 851, 854, 855, 856, 857, 858, 860, 861, 865, 869, 870, 872, 880, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 896, 898, 899, 900, 901, 902, 904, 905, 906, 908, 909, 910, 911, 912, 913, 915, 916, 917, 918, 919, 920, 923, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 944, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 968, 969, 970, 971, 972, 974, 975, 976, 977, 978, 979, 981, 982, 983, 984, 985, 986, 987, 989, 990, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1009, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1178, 1180, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1195, 1196, 1197, 1204, 1205, 1208, 1209, 1213, 1215, 1248, 1250, 1251, 1254, 1255, 1281, 1304, 1312, 1313, 1314, 1319, 1327, 1331, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1341, 1349, 1350, 1351, 1353, 1354, 1355, 1356, 1357, 1358, 1365, 1366, 1367, 1378, 1384, 1385, 1387, 1389, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1412, 1413, 1414, 1415, 1416, 1417, 1419, 1420, 1421, 1422, 1423, 1425, 1426, 1427, 1428, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1451, 1452, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1464, 1466, 1468, 1469, 1471, 1472, 1473, 1474, 1475, 1476, 1482, 1485, 1495, 1496, 1497, 1498, 1499, 1506, 1520, 1538, 1539, 1540, 1541, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1553, 1555, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1573, 1574, 1578, 1580, 1581, 1582, 1583, 1586, 1587, 1590, 1593, 1595, 1596, 1597, 1599, 1600, 1603, 1606, 1607, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1623, 1624, 1626, 1628, 1629, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1648, 1649, 1650, 1651, 1652, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1672, 1673, 1674, 1675, 1676, 1678, 1679, 1680, 1683, 1686, 1689, 1690, 1694, 1696, 1697, 1698, 1699, 1702, 1704, 1705, 1706, 1708, 1709, 1710, 1711, 1715, 1716, 1717, 1718, 1719, 1720, 1724, 1726, 1727, 1728, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738], "recip": [0, 3, 23, 1116, 1319, 1391, 1695, 1706], "howev": [0, 2, 3, 4, 5, 6, 8, 12, 13, 17, 18, 20, 23, 24, 26, 32, 40, 41, 42, 434, 495, 623, 630, 689, 708, 728, 768, 770, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 895, 898, 899, 905, 907, 934, 949, 950, 952, 966, 967, 985, 1032, 1044, 1045, 1046, 1047, 1048, 1049, 1053, 1060, 1116, 1188, 1189, 1190, 1213, 1314, 1319, 1410, 1422, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1675, 1679, 1695, 1696, 1699, 1701, 1704, 1706, 1708, 1709, 1710, 1711, 1712, 1713, 1716, 1717, 1724, 1726, 1727], "modular": [0, 1695], "mai": [0, 1, 2, 3, 4, 6, 7, 8, 12, 16, 17, 18, 19, 20, 23, 24, 25, 26, 28, 32, 34, 35, 40, 41, 42, 151, 176, 209, 268, 276, 411, 467, 469, 506, 555, 568, 628, 630, 632, 636, 641, 647, 658, 670, 679, 680, 682, 684, 687, 688, 689, 690, 708, 717, 718, 719, 725, 726, 728, 739, 741, 758, 781, 820, 824, 829, 832, 834, 857, 892, 895, 898, 899, 904, 905, 907, 908, 910, 916, 925, 926, 930, 931, 932, 934, 936, 937, 938, 939, 940, 941, 942, 943, 950, 952, 953, 956, 957, 958, 964, 966, 967, 972, 1024, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1082, 1086, 1116, 1123, 1131, 1161, 1163, 1168, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1205, 1213, 1215, 1224, 1251, 1280, 1281, 1282, 1283, 1314, 1319, 1384, 1386, 1387, 1389, 1422, 1452, 1475, 1562, 1565, 1582, 1585, 1592, 1599, 1609, 1625, 1629, 1648, 1660, 1674, 1675, 1676, 1678, 1679, 1683, 1685, 1687, 1690, 1695, 1696, 1697, 1698, 1699, 1701, 1702, 1706, 1709, 1710, 1711, 1712, 1713, 1716, 1718, 1719, 1720, 1724, 1726, 1727, 1729, 1735, 1738], "separ": [0, 1, 3, 8, 12, 17, 20, 23, 35, 36, 40, 41, 42, 781, 798, 800, 806, 807, 810, 811, 816, 818, 905, 940, 955, 1071, 1079, 1080, 1081, 1122, 1124, 1232, 1328, 1353, 1423, 1674, 1677, 1679, 1695, 1696, 1698, 1699, 1711, 1715, 1716, 1725, 1727, 1728, 1732], "desir": [0, 1, 3, 17, 20, 24, 40, 42, 43, 110, 125, 127, 130, 133, 134, 135, 150, 161, 164, 194, 209, 222, 252, 280, 347, 398, 399, 400, 401, 402, 449, 451, 452, 472, 476, 495, 496, 510, 531, 555, 556, 568, 595, 609, 645, 654, 673, 729, 730, 752, 753, 761, 762, 782, 783, 784, 794, 799, 817, 834, 835, 836, 852, 853, 895, 914, 965, 981, 988, 996, 1012, 1014, 1015, 1032, 1116, 1166, 1232, 1268, 1269, 1314, 1410, 1422, 1426, 1427, 1466, 1473, 1476, 1544, 1545, 1549, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1591, 1605, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1628, 1639, 1650, 1652, 1672, 1673, 1689, 1690, 1695, 1696, 1699, 1704, 1706, 1709, 1711, 1717, 1723, 1724, 1728, 1729, 1730], "As": [0, 1, 7, 18, 19, 20, 24, 40, 42, 209, 658, 781, 899, 926, 930, 931, 941, 942, 953, 958, 1055, 1056, 1057, 1061, 1082, 1116, 1147, 1280, 1421, 1427, 1673, 1676, 1678, 1679, 1696, 1699, 1701, 1702, 1706, 1712, 1713, 1716, 1717, 1724, 1725, 1726, 1727], "section": [0, 1, 6, 17, 24, 26, 27, 42, 74, 739, 781, 848, 1053, 1068, 1086, 1114, 1131, 1196, 1413, 1640, 1676, 1677, 1678, 1679, 1680, 1688, 1690, 1695, 1696, 1699, 1700, 1701, 1703, 1704, 1706, 1708, 1725, 1732], "infer": [0, 1, 2, 3, 10, 13, 24, 35, 531, 534, 568, 595, 609, 610, 700, 834, 835, 857, 870, 879, 893, 896, 904, 909, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1168, 1224, 1250, 1314, 1420, 1458, 1558, 1565, 1582, 1583, 1611, 1612, 1613, 1614, 1615, 1616, 1639, 1656, 1675, 1676, 1678, 1679, 1683, 1689, 1706, 1713, 1718, 1719, 1720, 1722, 1727], "onli": [0, 1, 2, 3, 4, 5, 6, 7, 8, 12, 17, 18, 19, 20, 21, 23, 24, 25, 26, 33, 35, 36, 40, 41, 42, 74, 209, 266, 276, 278, 290, 307, 411, 434, 439, 465, 467, 469, 539, 540, 565, 568, 590, 591, 608, 623, 626, 627, 628, 629, 630, 632, 637, 645, 646, 654, 689, 690, 691, 696, 698, 700, 725, 726, 728, 748, 777, 780, 782, 784, 797, 798, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 820, 827, 828, 832, 833, 848, 852, 853, 857, 865, 876, 884, 893, 895, 898, 899, 906, 910, 911, 914, 925, 930, 931, 933, 934, 935, 936, 938, 940, 941, 942, 943, 953, 955, 956, 958, 959, 966, 967, 985, 990, 1024, 1047, 1048, 1049, 1052, 1053, 1059, 1060, 1063, 1086, 1116, 1119, 1121, 1122, 1124, 1132, 1155, 1167, 1168, 1196, 1205, 1207, 1213, 1224, 1251, 1280, 1281, 1314, 1316, 1317, 1318, 1319, 1321, 1322, 1328, 1331, 1332, 1333, 1334, 1336, 1365, 1366, 1367, 1372, 1378, 1379, 1380, 1390, 1410, 1411, 1412, 1422, 1436, 1447, 1450, 1454, 1457, 1458, 1459, 1475, 1481, 1486, 1499, 1502, 1503, 1506, 1537, 1557, 1559, 1585, 1586, 1588, 1592, 1607, 1610, 1620, 1625, 1629, 1633, 1639, 1650, 1652, 1657, 1658, 1660, 1664, 1665, 1666, 1674, 1677, 1678, 1679, 1683, 1685, 1687, 1688, 1689, 1690, 1691, 1694, 1695, 1696, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1708, 1709, 1710, 1711, 1712, 1713, 1715, 1716, 1717, 1718, 1719, 1722, 1724, 1725, 1726, 1727, 1728, 1730, 1731, 1732, 1733, 1734], "For": [0, 1, 3, 4, 5, 6, 7, 8, 10, 12, 13, 17, 18, 19, 20, 21, 24, 26, 32, 33, 35, 36, 38, 40, 41, 42, 151, 176, 209, 244, 268, 270, 276, 290, 307, 424, 434, 445, 451, 465, 467, 469, 541, 555, 568, 581, 582, 583, 584, 585, 588, 594, 637, 644, 648, 650, 651, 653, 656, 669, 717, 731, 733, 739, 761, 762, 763, 781, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 837, 848, 857, 872, 895, 905, 906, 908, 910, 911, 926, 930, 931, 934, 937, 938, 939, 940, 942, 951, 952, 954, 958, 967, 974, 982, 990, 997, 1001, 1024, 1028, 1032, 1033, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1053, 1059, 1060, 1062, 1063, 1068, 1070, 1077, 1082, 1086, 1088, 1116, 1119, 1120, 1121, 1122, 1130, 1131, 1137, 1138, 1139, 1140, 1141, 1142, 1147, 1152, 1166, 1167, 1171, 1188, 1189, 1190, 1213, 1249, 1251, 1270, 1314, 1318, 1319, 1327, 1331, 1332, 1333, 1334, 1335, 1336, 1353, 1387, 1410, 1411, 1412, 1414, 1422, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1459, 1499, 1537, 1538, 1580, 1614, 1620, 1629, 1640, 1642, 1646, 1665, 1666, 1674, 1675, 1676, 1679, 1681, 1683, 1687, 1689, 1690, 1692, 1695, 1696, 1697, 1698, 1699, 1701, 1702, 1703, 1704, 1706, 1708, 1709, 1710, 1713, 1715, 1716, 1717, 1718, 1719, 1720, 1724, 1725, 1726, 1727, 1729, 1730, 1731, 1732, 1733, 1734, 1738], "api": [0, 2, 3, 7, 8, 18, 19, 20, 21, 26, 27, 28, 32, 33, 34, 35, 36, 40, 41, 623, 624, 625, 633, 688, 717, 718, 719, 725, 726, 728, 754, 785, 905, 906, 908, 1319, 1420, 1485, 1506, 1587, 1667, 1674, 1683, 1685, 1688, 1689, 1691, 1696, 1700, 1711, 1713, 1720, 1724, 1725, 1727, 1732, 1738], "also": [0, 1, 2, 3, 5, 6, 7, 8, 10, 12, 13, 17, 18, 20, 23, 24, 25, 32, 35, 40, 41, 42, 109, 173, 176, 177, 209, 278, 465, 467, 469, 493, 565, 610, 619, 628, 645, 654, 668, 687, 725, 728, 739, 761, 762, 780, 781, 785, 801, 832, 837, 840, 842, 852, 853, 857, 870, 895, 898, 899, 901, 904, 908, 910, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 946, 947, 948, 949, 952, 953, 954, 955, 956, 957, 958, 959, 962, 963, 998, 1004, 1005, 1013, 1024, 1032, 1034, 1035, 1036, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1060, 1063, 1068, 1082, 1086, 1116, 1123, 1131, 1145, 1147, 1155, 1164, 1165, 1167, 1191, 1192, 1193, 1213, 1250, 1265, 1314, 1319, 1334, 1335, 1336, 1353, 1387, 1389, 1399, 1401, 1403, 1404, 1405, 1406, 1420, 1448, 1454, 1458, 1460, 1463, 1485, 1499, 1555, 1562, 1574, 1583, 1604, 1606, 1620, 1629, 1634, 1636, 1639, 1645, 1646, 1657, 1658, 1667, 1670, 1674, 1675, 1676, 1678, 1679, 1683, 1685, 1688, 1689, 1690, 1691, 1694, 1695, 1696, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1708, 1710, 1711, 1712, 1713, 1715, 1716, 1717, 1719, 1724, 1725, 1727, 1728, 1731, 1732, 1733, 1734, 1735, 1738], "seper": 0, "arg": [0, 1, 3, 4, 5, 12, 17, 18, 20, 23, 24, 26, 27, 33, 34, 36, 37, 38, 40, 41, 42, 531, 555, 620, 626, 627, 728, 895, 898, 985, 1032, 1033, 1050, 1052, 1068, 1076, 1078, 1083, 1086, 1107, 1108, 1116, 1119, 1120, 1121, 1123, 1130, 1131, 1144, 1147, 1148, 1155, 1164, 1175, 1176, 1177, 1185, 1186, 1196, 1208, 1209, 1225, 1248, 1256, 1314, 1319, 1325, 1342, 1344, 1345, 1346, 1347, 1353, 1355, 1356, 1391, 1396, 1410, 1415, 1417, 1506, 1606, 1630, 1658, 1664, 1674, 1677, 1679, 1680, 1688, 1690, 1696, 1699, 1700, 1701, 1708, 1713, 1716, 1717, 1724, 1725, 1726, 1729, 1738], "equival": [0, 5, 17, 18, 23, 24, 28, 35, 36, 42, 110, 125, 127, 130, 133, 134, 135, 194, 210, 222, 252, 274, 280, 347, 401, 411, 450, 452, 476, 556, 562, 568, 569, 571, 587, 606, 620, 657, 659, 662, 664, 667, 674, 675, 768, 772, 775, 778, 779, 781, 783, 798, 800, 803, 806, 807, 810, 811, 813, 816, 818, 836, 858, 860, 872, 894, 895, 905, 910, 911, 914, 926, 947, 951, 959, 964, 998, 1003, 1005, 1012, 1024, 1034, 1035, 1036, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1059, 1060, 1071, 1077, 1079, 1080, 1081, 1082, 1086, 1088, 1116, 1147, 1155, 1167, 1169, 1232, 1253, 1281, 1282, 1283, 1319, 1337, 1341, 1348, 1350, 1352, 1378, 1379, 1380, 1427, 1549, 1552, 1556, 1580, 1585, 1593, 1603, 1608, 1621, 1631, 1632, 1634, 1639, 1658, 1668, 1669, 1673, 1676, 1678, 1679, 1696, 1713, 1716, 1720, 1727, 1728, 1730, 1733, 1734, 1738, 1739], "support": [0, 1, 2, 3, 5, 6, 7, 8, 10, 12, 13, 14, 17, 18, 19, 20, 23, 24, 25, 27, 28, 35, 36, 40, 41, 42, 266, 276, 411, 534, 535, 568, 580, 581, 582, 584, 588, 590, 591, 594, 623, 628, 637, 638, 644, 645, 649, 652, 654, 656, 668, 669, 681, 687, 691, 725, 726, 728, 775, 777, 780, 781, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 826, 827, 828, 829, 831, 832, 833, 852, 853, 865, 899, 906, 910, 914, 915, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 939, 940, 941, 942, 943, 944, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 957, 958, 959, 960, 961, 962, 963, 964, 967, 983, 986, 990, 995, 1000, 1001, 1006, 1044, 1045, 1046, 1047, 1048, 1049, 1056, 1059, 1060, 1063, 1083, 1103, 1121, 1122, 1155, 1165, 1167, 1188, 1189, 1190, 1191, 1192, 1193, 1195, 1196, 1205, 1207, 1213, 1224, 1230, 1280, 1281, 1283, 1313, 1319, 1331, 1332, 1333, 1365, 1366, 1367, 1372, 1378, 1379, 1380, 1422, 1427, 1436, 1463, 1475, 1486, 1538, 1540, 1561, 1562, 1582, 1585, 1586, 1604, 1606, 1609, 1626, 1629, 1648, 1650, 1652, 1664, 1665, 1666, 1673, 1674, 1676, 1678, 1680, 1681, 1683, 1685, 1687, 1688, 1691, 1692, 1696, 1697, 1698, 1699, 1701, 1704, 1706, 1708, 1709, 1711, 1712, 1715, 1716, 1717, 1718, 1722, 1724, 1728, 1730, 1731, 1732, 1733, 1734, 1736, 1738], "now": [0, 1, 5, 19, 20, 25, 32, 36, 37, 40, 42, 176, 448, 629, 636, 698, 725, 745, 746, 832, 842, 893, 899, 910, 944, 1113, 1132, 1168, 1314, 1389, 1400, 1436, 1540, 1582, 1676, 1689, 1690, 1695, 1696, 1697, 1699, 1700, 1701, 1706, 1707, 1713, 1716, 1719, 1725, 1726, 1738], "class": [0, 1, 2, 3, 13, 17, 18, 20, 21, 23, 24, 26, 27, 29, 32, 33, 35, 37, 40, 41, 43, 623, 626, 627, 628, 629, 688, 689, 690, 691, 692, 705, 707, 717, 756, 785, 870, 893, 894, 895, 898, 900, 901, 905, 906, 909, 910, 911, 912, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1186, 1196, 1248, 1250, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1386, 1389, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1410, 1415, 1420, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1440, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1511, 1512, 1513, 1514, 1515, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1549, 1587, 1677, 1680, 1683, 1687, 1688, 1690, 1695, 1696, 1699, 1701, 1702, 1706, 1708, 1711, 1717, 1718, 1719, 1721, 1724, 1725, 1727, 1729, 1730, 1732, 1734, 1735, 1736, 1737, 1738, 1739], "device_typ": [0, 1695], "dtype": [0, 1, 10, 15, 17, 20, 40, 42, 108, 109, 146, 163, 167, 168, 169, 170, 197, 266, 268, 270, 272, 274, 276, 364, 383, 386, 398, 399, 400, 401, 402, 406, 411, 423, 434, 436, 465, 467, 515, 531, 555, 568, 582, 587, 588, 592, 594, 595, 609, 610, 626, 628, 630, 632, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 661, 668, 677, 679, 680, 686, 687, 699, 761, 762, 780, 782, 783, 784, 794, 798, 799, 800, 806, 807, 817, 824, 829, 831, 833, 834, 835, 836, 842, 852, 853, 865, 895, 899, 908, 914, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 944, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 976, 977, 978, 979, 981, 985, 986, 995, 996, 997, 1000, 1007, 1011, 1012, 1013, 1015, 1024, 1033, 1034, 1035, 1036, 1037, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1059, 1060, 1063, 1068, 1069, 1071, 1079, 1080, 1081, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1103, 1116, 1122, 1123, 1124, 1131, 1132, 1133, 1137, 1138, 1139, 1140, 1141, 1155, 1159, 1161, 1163, 1167, 1168, 1169, 1170, 1180, 1196, 1197, 1232, 1268, 1269, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1342, 1344, 1345, 1346, 1347, 1348, 1349, 1351, 1353, 1354, 1357, 1358, 1365, 1366, 1367, 1386, 1389, 1390, 1400, 1410, 1422, 1426, 1427, 1428, 1463, 1469, 1473, 1474, 1484, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1511, 1512, 1515, 1517, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1537, 1538, 1540, 1544, 1545, 1546, 1547, 1548, 1549, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1560, 1568, 1571, 1582, 1583, 1585, 1586, 1605, 1608, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1628, 1629, 1636, 1639, 1650, 1652, 1657, 1660, 1665, 1666, 1670, 1672, 1673, 1676, 1677, 1678, 1679, 1681, 1690, 1691, 1699, 1701, 1706, 1709, 1713, 1719, 1720, 1721, 1727, 1728, 1729, 1732, 1733, 1734, 1739], "none": [0, 1, 2, 3, 12, 17, 18, 20, 21, 23, 24, 26, 28, 32, 33, 35, 37, 40, 41, 42, 67, 69, 70, 71, 73, 89, 90, 93, 105, 108, 109, 111, 128, 140, 141, 142, 143, 159, 160, 162, 164, 167, 168, 169, 170, 184, 189, 190, 191, 192, 213, 241, 245, 256, 290, 306, 308, 331, 362, 364, 365, 366, 369, 375, 381, 382, 383, 384, 385, 386, 398, 399, 400, 401, 402, 406, 407, 423, 432, 434, 440, 446, 455, 465, 472, 488, 489, 502, 503, 506, 515, 531, 534, 542, 555, 561, 562, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 588, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 604, 605, 608, 609, 610, 611, 612, 613, 614, 615, 619, 621, 622, 623, 624, 625, 628, 629, 631, 633, 634, 635, 636, 637, 638, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 656, 660, 663, 665, 666, 667, 668, 669, 671, 672, 674, 677, 678, 680, 681, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 696, 698, 699, 700, 703, 704, 705, 710, 711, 717, 727, 731, 732, 733, 734, 735, 736, 737, 739, 740, 741, 745, 746, 747, 751, 754, 756, 757, 758, 759, 760, 761, 762, 763, 764, 767, 772, 773, 775, 776, 777, 779, 780, 782, 783, 784, 786, 788, 789, 790, 791, 792, 793, 794, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 824, 825, 826, 827, 828, 829, 830, 831, 835, 836, 837, 838, 839, 840, 841, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 859, 860, 861, 862, 863, 864, 866, 867, 868, 869, 872, 873, 889, 890, 892, 894, 895, 899, 902, 904, 905, 906, 908, 910, 911, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 989, 990, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1017, 1018, 1019, 1020, 1022, 1023, 1024, 1026, 1027, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1059, 1060, 1062, 1064, 1065, 1066, 1069, 1070, 1071, 1075, 1076, 1077, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1103, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1126, 1127, 1130, 1132, 1133, 1147, 1148, 1149, 1151, 1155, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1168, 1169, 1170, 1178, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1196, 1197, 1204, 1205, 1210, 1211, 1213, 1214, 1221, 1223, 1224, 1225, 1226, 1227, 1230, 1232, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1244, 1245, 1246, 1247, 1248, 1249, 1251, 1253, 1256, 1266, 1267, 1268, 1269, 1277, 1278, 1279, 1281, 1282, 1283, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1307, 1308, 1309, 1310, 1311, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1342, 1344, 1345, 1346, 1347, 1348, 1361, 1362, 1372, 1373, 1374, 1375, 1376, 1378, 1379, 1380, 1384, 1385, 1388, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1400, 1403, 1404, 1410, 1413, 1414, 1416, 1417, 1419, 1421, 1422, 1423, 1424, 1426, 1427, 1428, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1463, 1464, 1465, 1468, 1469, 1470, 1472, 1473, 1475, 1476, 1477, 1478, 1480, 1482, 1484, 1499, 1501, 1502, 1503, 1504, 1507, 1508, 1520, 1521, 1522, 1536, 1537, 1538, 1539, 1540, 1541, 1546, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1561, 1562, 1563, 1564, 1569, 1571, 1572, 1573, 1578, 1590, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1603, 1605, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1633, 1636, 1637, 1638, 1639, 1641, 1643, 1646, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1657, 1658, 1661, 1662, 1663, 1664, 1667, 1669, 1671, 1672, 1673, 1674, 1676, 1677, 1678, 1679, 1680, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1694, 1696, 1699, 1701, 1706, 1708, 1711, 1713, 1716, 1717, 1718, 1719, 1723, 1724, 1728, 1729, 1732, 1734, 1736, 1737, 1738], "enabl": [0, 1, 2, 7, 15, 17, 18, 19, 20, 21, 23, 24, 36, 40, 455, 456, 623, 628, 728, 781, 785, 870, 878, 879, 897, 903, 1068, 1086, 1131, 1132, 1162, 1319, 1353, 1386, 1387, 1389, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1420, 1446, 1497, 1498, 1586, 1587, 1590, 1660, 1679, 1685, 1691, 1695, 1696, 1697, 1698, 1699, 1705, 1707, 1710, 1713, 1717, 1718, 1723, 1724, 1725, 1727, 1735, 1738], "true": [0, 1, 2, 3, 5, 12, 17, 18, 20, 21, 23, 24, 26, 37, 40, 41, 42, 105, 151, 164, 215, 274, 276, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 296, 297, 298, 306, 351, 355, 357, 401, 411, 413, 424, 430, 440, 447, 448, 456, 468, 469, 505, 506, 517, 520, 531, 542, 546, 555, 561, 566, 568, 582, 587, 588, 589, 590, 591, 592, 594, 603, 605, 606, 610, 619, 622, 623, 626, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 645, 648, 651, 653, 654, 660, 661, 667, 668, 669, 675, 679, 689, 723, 775, 780, 785, 786, 787, 803, 804, 810, 811, 834, 837, 839, 851, 852, 853, 856, 857, 868, 870, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 895, 899, 900, 901, 904, 910, 911, 912, 914, 916, 919, 924, 925, 936, 937, 938, 941, 942, 943, 944, 947, 949, 951, 952, 953, 955, 956, 957, 958, 960, 961, 964, 967, 976, 977, 978, 979, 982, 984, 985, 987, 989, 993, 994, 996, 997, 998, 999, 1002, 1007, 1012, 1015, 1017, 1020, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1054, 1055, 1056, 1057, 1059, 1060, 1061, 1064, 1065, 1068, 1069, 1070, 1071, 1076, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1103, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1119, 1120, 1121, 1122, 1123, 1125, 1130, 1131, 1132, 1133, 1147, 1148, 1155, 1159, 1161, 1162, 1163, 1164, 1165, 1168, 1169, 1178, 1180, 1181, 1182, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1196, 1197, 1198, 1199, 1200, 1201, 1204, 1205, 1206, 1208, 1209, 1213, 1215, 1217, 1223, 1224, 1225, 1237, 1238, 1239, 1248, 1256, 1281, 1282, 1302, 1303, 1304, 1309, 1310, 1311, 1312, 1313, 1314, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1331, 1332, 1333, 1334, 1335, 1336, 1339, 1342, 1347, 1349, 1353, 1354, 1357, 1358, 1361, 1362, 1372, 1378, 1379, 1381, 1384, 1385, 1388, 1389, 1390, 1402, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1419, 1420, 1421, 1422, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1461, 1463, 1465, 1473, 1475, 1476, 1482, 1488, 1492, 1499, 1524, 1528, 1538, 1547, 1548, 1549, 1566, 1567, 1574, 1577, 1578, 1585, 1586, 1587, 1590, 1592, 1596, 1603, 1606, 1623, 1624, 1625, 1628, 1629, 1633, 1639, 1643, 1648, 1657, 1658, 1660, 1661, 1662, 1663, 1667, 1670, 1674, 1677, 1678, 1679, 1686, 1688, 1689, 1690, 1691, 1695, 1696, 1697, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1710, 1711, 1713, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1723, 1724, 1725, 1727, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1738], "cache_en": 0, "sourc": [0, 1, 2, 3, 4, 5, 8, 11, 12, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 32, 33, 35, 37, 40, 41, 42, 105, 151, 164, 267, 268, 276, 295, 306, 351, 357, 370, 371, 406, 424, 440, 465, 467, 469, 472, 475, 497, 506, 507, 509, 538, 555, 558, 561, 562, 575, 590, 591, 603, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 643, 655, 657, 658, 662, 664, 666, 676, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 781, 785, 832, 834, 837, 843, 844, 847, 866, 867, 868, 870, 871, 876, 881, 882, 883, 893, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 966, 967, 988, 998, 1003, 1004, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1173, 1174, 1178, 1179, 1183, 1185, 1186, 1187, 1194, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1204, 1205, 1206, 1207, 1210, 1212, 1213, 1214, 1215, 1217, 1218, 1219, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1231, 1232, 1234, 1235, 1236, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1256, 1258, 1259, 1261, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1272, 1273, 1274, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1428, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1465, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1518, 1519, 1520, 1521, 1522, 1523, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1549, 1574, 1579, 1582, 1583, 1584, 1585, 1587, 1590, 1591, 1592, 1610, 1617, 1625, 1630, 1641, 1660, 1667, 1674, 1676, 1677, 1678, 1683, 1685, 1687, 1688, 1690, 1694, 1702, 1704, 1705, 1709, 1713, 1714, 1715, 1717, 1718, 1719, 1723, 1724, 1725, 1729, 1732, 1734, 1736, 1737, 1738], "instanc": [0, 3, 17, 21, 23, 24, 25, 26, 32, 35, 36, 37, 40, 42, 94, 568, 688, 781, 832, 893, 895, 906, 910, 967, 1059, 1060, 1063, 1079, 1080, 1081, 1088, 1116, 1126, 1160, 1162, 1163, 1167, 1223, 1319, 1327, 1341, 1350, 1385, 1396, 1410, 1416, 1433, 1434, 1485, 1506, 1523, 1537, 1614, 1640, 1676, 1678, 1680, 1685, 1688, 1690, 1695, 1696, 1699, 1700, 1701, 1702, 1706, 1710, 1716, 1719, 1724, 1725, 1726, 1727, 1729, 1734, 1738], "serv": [0, 6, 7, 13, 20, 1715, 1724, 1725], "context": [0, 23, 26, 35, 36, 40, 42, 105, 619, 620, 621, 622, 623, 636, 692, 705, 707, 717, 723, 735, 754, 756, 785, 870, 895, 1116, 1314, 1319, 1387, 1389, 1420, 1429, 1587, 1679, 1680, 1688, 1695, 1696, 1699, 1701, 1704, 1705, 1708, 1713, 1716, 1718, 1723, 1724, 1726, 1735], "manag": [0, 1, 6, 19, 23, 24, 26, 33, 35, 36, 37, 40, 42, 43, 439, 623, 688, 690, 692, 693, 694, 705, 707, 708, 717, 718, 728, 731, 733, 734, 735, 737, 738, 739, 740, 745, 746, 747, 754, 756, 785, 870, 1319, 1386, 1387, 1389, 1420, 1587, 1679, 1680, 1696, 1702, 1705, 1713, 1717, 1718, 1723, 1724, 1725, 1735], "decor": [0, 1, 24, 28, 32, 36, 42, 628, 785, 870, 900, 906, 912, 1420, 1676, 1678, 1679, 1683, 1695, 1696, 1701, 1717, 1724, 1738], "allow": [0, 1, 2, 3, 5, 6, 7, 8, 10, 12, 13, 17, 18, 19, 20, 21, 24, 26, 27, 35, 36, 40, 42, 105, 465, 622, 624, 636, 637, 661, 675, 725, 728, 751, 781, 895, 900, 912, 950, 972, 1029, 1030, 1031, 1052, 1053, 1070, 1109, 1110, 1111, 1116, 1119, 1122, 1144, 1159, 1319, 1328, 1382, 1421, 1445, 1482, 1484, 1485, 1506, 1660, 1674, 1678, 1679, 1689, 1690, 1691, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1703, 1704, 1705, 1706, 1708, 1709, 1711, 1713, 1715, 1716, 1717, 1718, 1719, 1721, 1724, 1727, 1730, 1731, 1732, 1734], "region": [0, 3, 24, 32, 1029, 1030, 1031, 1064, 1065, 1075, 1077, 1109, 1110, 1111, 1181, 1182, 1208, 1209, 1238, 1239, 1361, 1362, 1633, 1676, 1688, 1695, 1699], "your": [0, 1, 2, 4, 6, 7, 10, 12, 13, 14, 17, 19, 20, 23, 24, 27, 28, 32, 34, 35, 36, 37, 38, 40, 41, 42, 622, 628, 630, 631, 636, 870, 895, 899, 900, 904, 907, 910, 911, 912, 1116, 1123, 1319, 1386, 1389, 1420, 1586, 1657, 1667, 1676, 1678, 1679, 1683, 1688, 1689, 1690, 1692, 1695, 1696, 1697, 1699, 1701, 1702, 1704, 1705, 1706, 1707, 1710, 1712, 1713, 1715, 1717, 1720, 1723, 1725, 1727, 1732, 1733, 1735, 1738], "script": [0, 4, 17, 19, 20, 22, 26, 28, 34, 36, 37, 896, 898, 899, 900, 901, 904, 905, 907, 909, 910, 912, 1674, 1678, 1679, 1685, 1698, 1705, 1707, 1711, 1714, 1716, 1719, 1724], "run": [0, 1, 2, 3, 4, 5, 6, 9, 12, 13, 17, 18, 20, 21, 23, 24, 26, 27, 28, 33, 34, 35, 36, 37, 38, 40, 41, 42, 105, 622, 636, 637, 638, 727, 728, 781, 870, 895, 896, 898, 899, 902, 904, 906, 908, 910, 911, 940, 966, 967, 997, 1034, 1035, 1036, 1053, 1079, 1080, 1081, 1089, 1090, 1091, 1098, 1099, 1100, 1116, 1144, 1155, 1314, 1319, 1431, 1433, 1434, 1435, 1437, 1443, 1447, 1483, 1501, 1502, 1503, 1504, 1507, 1536, 1540, 1541, 1542, 1585, 1589, 1608, 1650, 1652, 1660, 1667, 1675, 1676, 1679, 1685, 1687, 1688, 1694, 1695, 1696, 1698, 1699, 1700, 1701, 1702, 1703, 1705, 1706, 1707, 1708, 1710, 1711, 1712, 1713, 1715, 1716, 1717, 1719, 1722, 1723, 1724, 1725, 1726, 1732, 1735, 1736], "In": [0, 2, 3, 4, 5, 6, 8, 13, 17, 19, 20, 23, 24, 28, 35, 36, 37, 40, 41, 42, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 76, 78, 80, 82, 85, 86, 88, 96, 98, 101, 102, 104, 107, 109, 113, 115, 117, 119, 121, 123, 132, 141, 149, 153, 156, 158, 168, 170, 176, 186, 190, 192, 199, 202, 204, 206, 208, 212, 217, 224, 226, 228, 232, 234, 238, 240, 247, 249, 251, 259, 261, 263, 265, 310, 312, 314, 316, 318, 320, 322, 325, 327, 329, 330, 337, 339, 341, 343, 345, 350, 374, 377, 380, 382, 392, 394, 396, 404, 409, 419, 422, 438, 442, 444, 460, 463, 474, 478, 480, 483, 485, 487, 499, 501, 503, 512, 514, 522, 526, 528, 545, 548, 550, 552, 554, 564, 573, 628, 660, 679, 680, 687, 728, 739, 750, 751, 755, 756, 781, 802, 804, 812, 813, 814, 829, 893, 895, 904, 907, 908, 910, 926, 927, 935, 940, 941, 942, 950, 953, 958, 963, 967, 972, 975, 983, 985, 997, 998, 1012, 1029, 1030, 1031, 1033, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1053, 1055, 1056, 1057, 1061, 1063, 1068, 1077, 1082, 1086, 1101, 1109, 1110, 1111, 1116, 1122, 1159, 1161, 1163, 1167, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1203, 1213, 1220, 1225, 1229, 1257, 1260, 1262, 1276, 1319, 1353, 1384, 1389, 1390, 1420, 1447, 1458, 1459, 1485, 1506, 1562, 1578, 1629, 1630, 1648, 1660, 1664, 1665, 1674, 1676, 1678, 1679, 1688, 1689, 1690, 1691, 1694, 1695, 1698, 1699, 1701, 1702, 1703, 1705, 1706, 1708, 1709, 1710, 1711, 1713, 1715, 1716, 1718, 1719, 1720, 1721, 1724, 1725, 1726, 1727, 1732, 1734], "an": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 105, 109, 145, 173, 176, 197, 209, 244, 268, 270, 276, 278, 283, 290, 465, 467, 469, 488, 493, 495, 510, 559, 565, 568, 582, 583, 608, 609, 610, 619, 621, 622, 624, 626, 628, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 647, 663, 673, 679, 680, 682, 688, 689, 690, 691, 696, 697, 698, 699, 700, 717, 718, 725, 726, 728, 740, 742, 751, 755, 756, 765, 778, 780, 781, 783, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 824, 832, 834, 837, 840, 848, 856, 857, 858, 893, 895, 898, 899, 902, 905, 906, 908, 910, 911, 912, 913, 924, 925, 930, 931, 936, 938, 940, 943, 944, 948, 951, 953, 956, 957, 964, 966, 967, 985, 987, 990, 997, 1007, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1035, 1036, 1037, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1054, 1055, 1056, 1057, 1059, 1060, 1061, 1063, 1064, 1065, 1068, 1076, 1080, 1081, 1084, 1085, 1086, 1088, 1098, 1099, 1100, 1101, 1103, 1104, 1106, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1117, 1118, 1122, 1123, 1124, 1126, 1127, 1128, 1129, 1131, 1133, 1135, 1144, 1147, 1149, 1150, 1151, 1155, 1160, 1162, 1163, 1164, 1167, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1180, 1188, 1189, 1190, 1191, 1192, 1193, 1198, 1204, 1205, 1207, 1208, 1209, 1213, 1224, 1231, 1232, 1234, 1235, 1237, 1238, 1239, 1266, 1281, 1283, 1314, 1316, 1319, 1328, 1334, 1335, 1336, 1349, 1353, 1358, 1372, 1378, 1380, 1381, 1382, 1383, 1384, 1387, 1388, 1389, 1396, 1413, 1418, 1422, 1427, 1428, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1439, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1475, 1478, 1505, 1508, 1543, 1547, 1548, 1549, 1568, 1574, 1584, 1593, 1609, 1610, 1614, 1617, 1625, 1629, 1633, 1639, 1640, 1656, 1657, 1658, 1660, 1665, 1666, 1667, 1668, 1673, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1683, 1685, 1687, 1688, 1689, 1690, 1691, 1692, 1694, 1695, 1696, 1698, 1699, 1700, 1701, 1702, 1703, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1717, 1718, 1719, 1720, 1721, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739], "chosen": [0, 40, 768, 916, 1590, 1603, 1643, 1691, 1695, 1699, 1701, 1713, 1719], "improv": [0, 1, 3, 8, 12, 15, 18, 20, 42, 630, 632, 636, 682, 848, 1054, 1068, 1086, 1131, 1162, 1319, 1353, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1459, 1667, 1675, 1676, 1695, 1700, 1701, 1709, 1710, 1719, 1720, 1724], "perform": [0, 1, 2, 3, 4, 5, 10, 12, 15, 16, 17, 18, 20, 21, 23, 24, 26, 35, 36, 40, 41, 42, 74, 161, 164, 411, 531, 555, 568, 581, 582, 583, 584, 585, 586, 620, 623, 628, 630, 632, 633, 636, 637, 644, 656, 679, 680, 693, 739, 761, 762, 775, 801, 824, 826, 859, 870, 895, 904, 905, 910, 938, 940, 943, 947, 950, 951, 955, 956, 964, 965, 967, 972, 981, 996, 1001, 1009, 1012, 1015, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1056, 1059, 1060, 1068, 1086, 1116, 1124, 1131, 1144, 1159, 1162, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1232, 1249, 1268, 1269, 1314, 1319, 1321, 1322, 1353, 1374, 1385, 1389, 1410, 1415, 1417, 1422, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1465, 1473, 1537, 1540, 1568, 1585, 1602, 1605, 1606, 1607, 1608, 1628, 1630, 1660, 1667, 1675, 1676, 1679, 1687, 1688, 1689, 1690, 1692, 1694, 1695, 1696, 1698, 1699, 1700, 1701, 1703, 1704, 1707, 1709, 1710, 1713, 1716, 1718, 1719, 1720, 1722, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1734, 1738], "while": [0, 2, 3, 7, 10, 12, 17, 18, 20, 21, 24, 40, 41, 42, 534, 590, 591, 614, 690, 756, 857, 895, 898, 910, 911, 967, 1013, 1024, 1040, 1077, 1079, 1080, 1081, 1086, 1116, 1122, 1147, 1155, 1159, 1232, 1319, 1328, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1422, 1578, 1680, 1690, 1695, 1696, 1699, 1702, 1703, 1706, 1708, 1710, 1713, 1715, 1717, 1719, 1722, 1724, 1726, 1727, 1728, 1731, 1732, 1733], "maintain": [0, 6, 7, 17, 18, 20, 24, 40, 42, 1028, 1056, 1061, 1206, 1319, 1410, 1422, 1675, 1691, 1695, 1696, 1699, 1701, 1706], "accuraci": [0, 18, 40, 958, 1500, 1675, 1687, 1695, 1706, 1732, 1736], "see": [0, 1, 2, 3, 4, 5, 6, 7, 8, 12, 13, 16, 17, 19, 20, 21, 24, 27, 35, 36, 38, 40, 41, 42, 44, 48, 50, 52, 54, 56, 58, 60, 62, 64, 67, 68, 69, 70, 71, 72, 73, 75, 77, 79, 81, 83, 84, 87, 89, 90, 91, 92, 93, 95, 97, 99, 100, 103, 105, 106, 108, 109, 110, 111, 112, 114, 116, 118, 120, 122, 124, 125, 126, 127, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 144, 147, 148, 152, 154, 155, 157, 159, 160, 162, 165, 166, 167, 169, 172, 173, 175, 179, 180, 181, 182, 183, 184, 185, 188, 189, 191, 193, 194, 195, 196, 198, 200, 201, 203, 205, 207, 210, 211, 216, 218, 219, 220, 221, 222, 223, 225, 227, 229, 230, 231, 233, 235, 236, 237, 239, 242, 243, 246, 248, 250, 252, 253, 254, 255, 256, 257, 258, 260, 262, 264, 268, 276, 277, 278, 279, 280, 282, 283, 289, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 311, 313, 315, 317, 319, 321, 323, 324, 326, 328, 332, 333, 334, 335, 336, 338, 340, 342, 344, 346, 347, 348, 349, 351, 352, 358, 359, 360, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 375, 376, 378, 379, 381, 383, 384, 385, 386, 387, 391, 393, 395, 403, 405, 406, 408, 410, 412, 413, 414, 415, 417, 418, 420, 421, 423, 430, 432, 433, 435, 437, 441, 443, 445, 446, 447, 449, 450, 451, 453, 454, 457, 458, 459, 462, 467, 469, 470, 471, 473, 476, 477, 479, 481, 482, 484, 486, 489, 490, 491, 492, 493, 497, 498, 500, 502, 504, 505, 506, 511, 513, 515, 517, 518, 519, 520, 521, 523, 524, 525, 527, 529, 530, 542, 543, 544, 546, 547, 549, 551, 553, 557, 558, 561, 562, 563, 565, 566, 567, 569, 570, 571, 572, 588, 590, 591, 594, 595, 604, 605, 606, 609, 622, 623, 624, 625, 627, 628, 632, 636, 641, 645, 647, 654, 656, 659, 673, 684, 688, 689, 690, 691, 693, 694, 708, 717, 718, 728, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 745, 746, 747, 775, 778, 781, 782, 784, 785, 794, 799, 817, 820, 835, 840, 848, 852, 853, 857, 858, 866, 867, 868, 870, 895, 899, 906, 910, 911, 913, 914, 916, 926, 934, 937, 940, 942, 949, 951, 952, 960, 964, 965, 967, 973, 975, 981, 982, 985, 994, 996, 997, 998, 999, 1001, 1002, 1005, 1012, 1014, 1015, 1024, 1032, 1033, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1059, 1060, 1068, 1070, 1076, 1077, 1082, 1083, 1086, 1107, 1108, 1112, 1113, 1114, 1115, 1116, 1119, 1120, 1121, 1122, 1123, 1128, 1129, 1130, 1131, 1134, 1143, 1145, 1147, 1148, 1160, 1161, 1162, 1163, 1164, 1165, 1168, 1172, 1173, 1174, 1175, 1176, 1177, 1179, 1180, 1181, 1182, 1183, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1204, 1205, 1206, 1207, 1210, 1211, 1212, 1213, 1214, 1216, 1217, 1218, 1219, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1251, 1252, 1254, 1255, 1256, 1257, 1258, 1259, 1261, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1278, 1279, 1280, 1281, 1282, 1283, 1319, 1320, 1323, 1324, 1325, 1326, 1327, 1328, 1331, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1341, 1349, 1350, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1364, 1365, 1366, 1367, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1384, 1385, 1386, 1389, 1395, 1404, 1413, 1416, 1419, 1420, 1421, 1426, 1463, 1473, 1474, 1522, 1538, 1539, 1540, 1541, 1551, 1553, 1555, 1557, 1558, 1562, 1565, 1568, 1574, 1582, 1585, 1587, 1599, 1605, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1625, 1628, 1634, 1636, 1639, 1645, 1646, 1650, 1652, 1660, 1668, 1670, 1672, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1686, 1688, 1689, 1690, 1692, 1695, 1696, 1697, 1699, 1701, 1702, 1703, 1705, 1706, 1708, 1709, 1710, 1711, 1712, 1713, 1717, 1718, 1719, 1720, 1724, 1725, 1728, 1730, 1731, 1733, 1734, 1735, 1738, 1739], "detail": [0, 1, 3, 6, 7, 10, 11, 12, 13, 14, 17, 20, 21, 24, 26, 36, 42, 105, 278, 447, 565, 603, 622, 623, 624, 625, 628, 637, 659, 684, 691, 693, 694, 708, 717, 728, 731, 733, 734, 735, 737, 738, 739, 740, 745, 746, 747, 763, 781, 820, 840, 843, 844, 848, 876, 883, 895, 899, 910, 934, 952, 959, 967, 973, 975, 983, 997, 1024, 1028, 1038, 1047, 1048, 1049, 1053, 1059, 1060, 1061, 1064, 1065, 1068, 1086, 1116, 1122, 1128, 1129, 1131, 1143, 1164, 1172, 1173, 1174, 1175, 1176, 1177, 1179, 1180, 1181, 1182, 1183, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1214, 1216, 1217, 1218, 1219, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1252, 1254, 1255, 1256, 1257, 1258, 1259, 1261, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1278, 1279, 1280, 1314, 1319, 1320, 1328, 1331, 1332, 1333, 1334, 1335, 1336, 1353, 1359, 1360, 1361, 1364, 1365, 1366, 1367, 1372, 1373, 1375, 1376, 1377, 1378, 1413, 1421, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1452, 1463, 1475, 1538, 1539, 1540, 1574, 1584, 1599, 1605, 1646, 1660, 1674, 1676, 1677, 1678, 1679, 1696, 1697, 1699, 1700, 1701, 1702, 1703, 1705, 1706, 1709, 1710, 1711, 1713, 1716, 1717, 1721, 1724, 1725, 1726, 1731, 1732, 1735, 1738], "when": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 38, 40, 41, 42, 52, 105, 146, 163, 215, 268, 276, 401, 449, 450, 465, 467, 469, 494, 510, 531, 568, 581, 584, 595, 607, 610, 622, 630, 631, 632, 633, 634, 635, 636, 637, 638, 644, 647, 656, 664, 667, 675, 679, 680, 684, 689, 698, 700, 721, 727, 728, 740, 763, 780, 820, 824, 829, 834, 848, 870, 884, 885, 887, 888, 891, 895, 896, 898, 906, 907, 908, 910, 911, 915, 916, 924, 925, 926, 930, 931, 932, 933, 934, 935, 936, 937, 938, 940, 941, 942, 943, 944, 947, 948, 949, 951, 952, 953, 954, 955, 956, 958, 959, 960, 964, 965, 966, 967, 975, 981, 983, 985, 990, 993, 997, 998, 1001, 1007, 1012, 1013, 1014, 1024, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1059, 1060, 1063, 1066, 1068, 1069, 1071, 1076, 1077, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1103, 1107, 1108, 1109, 1110, 1111, 1116, 1119, 1120, 1121, 1122, 1123, 1124, 1130, 1131, 1143, 1144, 1147, 1148, 1149, 1150, 1152, 1155, 1161, 1162, 1163, 1164, 1166, 1167, 1168, 1169, 1170, 1178, 1180, 1181, 1182, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1196, 1197, 1205, 1211, 1213, 1224, 1225, 1248, 1251, 1253, 1256, 1257, 1270, 1281, 1282, 1283, 1314, 1318, 1319, 1320, 1321, 1322, 1328, 1361, 1362, 1372, 1378, 1384, 1385, 1386, 1387, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1413, 1416, 1420, 1421, 1422, 1423, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1442, 1443, 1444, 1445, 1446, 1447, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1461, 1463, 1465, 1472, 1475, 1476, 1481, 1485, 1506, 1522, 1537, 1565, 1571, 1578, 1582, 1585, 1592, 1599, 1604, 1606, 1608, 1609, 1610, 1620, 1625, 1629, 1633, 1634, 1639, 1641, 1646, 1650, 1652, 1657, 1660, 1667, 1670, 1674, 1676, 1678, 1685, 1687, 1688, 1689, 1690, 1694, 1696, 1697, 1698, 1699, 1700, 1702, 1703, 1704, 1705, 1706, 1708, 1709, 1710, 1711, 1712, 1715, 1716, 1717, 1718, 1723, 1724, 1725, 1726, 1727, 1728, 1730, 1731, 1732, 1733, 1734], "enter": [0, 20, 623, 870], "tensor": [0, 2, 5, 6, 7, 12, 14, 17, 18, 19, 20, 21, 23, 24, 25, 40, 41, 42, 43, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 696, 697, 698, 699, 700, 707, 721, 725, 728, 731, 735, 745, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 872, 873, 874, 875, 877, 880, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 896, 898, 899, 901, 902, 905, 906, 908, 910, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1024, 1028, 1029, 1032, 1033, 1037, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1059, 1060, 1061, 1062, 1063, 1068, 1069, 1070, 1076, 1082, 1083, 1086, 1087, 1103, 1106, 1107, 1108, 1109, 1112, 1113, 1114, 1116, 1119, 1120, 1121, 1122, 1123, 1124, 1126, 1127, 1128, 1129, 1131, 1133, 1137, 1138, 1139, 1140, 1141, 1142, 1148, 1149, 1150, 1151, 1158, 1159, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1178, 1180, 1181, 1182, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1203, 1204, 1205, 1206, 1207, 1210, 1211, 1212, 1213, 1215, 1216, 1219, 1220, 1221, 1224, 1225, 1226, 1228, 1229, 1230, 1232, 1233, 1236, 1237, 1238, 1239, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1280, 1281, 1282, 1283, 1304, 1314, 1318, 1319, 1320, 1321, 1325, 1327, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1341, 1343, 1348, 1349, 1350, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1361, 1362, 1364, 1365, 1366, 1367, 1368, 1370, 1372, 1373, 1374, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1407, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1442, 1443, 1444, 1445, 1446, 1447, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1475, 1476, 1477, 1478, 1479, 1483, 1484, 1485, 1486, 1487, 1501, 1502, 1503, 1504, 1506, 1507, 1509, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1581, 1582, 1583, 1586, 1587, 1590, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1675, 1676, 1678, 1679, 1683, 1692, 1694, 1695, 1697, 1698, 1699, 1700, 1702, 1704, 1706, 1707, 1708, 1709, 1710, 1712, 1714, 1715, 1716, 1717, 1718, 1720, 1724, 1725, 1728, 1729, 1732, 1734, 1736, 1737, 1738], "ani": [0, 1, 3, 4, 5, 6, 8, 10, 12, 17, 18, 20, 21, 23, 24, 26, 28, 29, 33, 34, 35, 36, 38, 40, 41, 42, 105, 209, 451, 495, 568, 592, 595, 620, 621, 622, 628, 630, 636, 637, 638, 658, 662, 663, 679, 689, 721, 728, 797, 798, 800, 801, 802, 804, 808, 812, 813, 814, 829, 857, 894, 895, 899, 901, 905, 906, 908, 910, 916, 924, 926, 930, 931, 935, 940, 941, 942, 947, 948, 951, 955, 958, 964, 1021, 1022, 1023, 1025, 1026, 1027, 1028, 1032, 1033, 1037, 1038, 1044, 1045, 1046, 1053, 1054, 1058, 1062, 1063, 1066, 1067, 1070, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1082, 1083, 1102, 1103, 1105, 1106, 1107, 1115, 1116, 1124, 1126, 1127, 1130, 1134, 1135, 1136, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1151, 1152, 1153, 1154, 1156, 1157, 1158, 1165, 1166, 1167, 1184, 1188, 1189, 1190, 1230, 1249, 1250, 1314, 1319, 1351, 1374, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1401, 1411, 1412, 1414, 1415, 1417, 1422, 1452, 1480, 1485, 1495, 1496, 1497, 1498, 1505, 1506, 1508, 1558, 1574, 1588, 1590, 1623, 1624, 1629, 1662, 1663, 1674, 1676, 1677, 1678, 1685, 1687, 1688, 1689, 1690, 1691, 1695, 1696, 1698, 1699, 1701, 1703, 1704, 1705, 1706, 1707, 1708, 1710, 1713, 1714, 1716, 1717, 1719, 1724, 1725, 1726, 1727, 1729, 1732, 1734, 1738], "you": [0, 1, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 18, 19, 20, 23, 24, 26, 27, 32, 34, 35, 36, 37, 38, 40, 41, 42, 105, 209, 290, 401, 451, 619, 621, 622, 627, 628, 630, 631, 632, 636, 658, 688, 707, 717, 719, 728, 729, 748, 781, 870, 895, 899, 900, 907, 910, 911, 912, 940, 958, 966, 998, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1086, 1112, 1113, 1114, 1116, 1121, 1122, 1123, 1131, 1150, 1159, 1161, 1163, 1168, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1224, 1280, 1281, 1314, 1319, 1327, 1328, 1341, 1350, 1374, 1385, 1411, 1417, 1420, 1433, 1434, 1458, 1475, 1565, 1574, 1611, 1612, 1613, 1615, 1616, 1667, 1674, 1676, 1678, 1679, 1681, 1683, 1685, 1687, 1688, 1689, 1691, 1694, 1695, 1696, 1697, 1699, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1710, 1711, 1712, 1713, 1715, 1716, 1717, 1719, 1720, 1723, 1724, 1725, 1726, 1727, 1730, 1731, 1732, 1733, 1735, 1738], "should": [0, 1, 3, 4, 5, 8, 12, 13, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 33, 34, 35, 36, 37, 40, 41, 42, 74, 105, 109, 268, 276, 353, 357, 398, 399, 400, 401, 402, 440, 448, 465, 467, 469, 581, 584, 585, 595, 619, 620, 621, 622, 626, 627, 628, 629, 630, 631, 632, 636, 644, 645, 646, 647, 654, 667, 686, 689, 699, 700, 717, 719, 728, 771, 780, 782, 783, 784, 794, 799, 802, 803, 804, 812, 813, 814, 817, 832, 834, 835, 836, 852, 853, 856, 857, 892, 893, 895, 896, 900, 904, 906, 907, 910, 911, 912, 914, 939, 964, 965, 966, 972, 981, 983, 985, 986, 987, 1024, 1032, 1033, 1037, 1050, 1052, 1053, 1055, 1056, 1057, 1060, 1061, 1082, 1108, 1116, 1122, 1123, 1124, 1143, 1164, 1168, 1178, 1184, 1188, 1189, 1190, 1191, 1192, 1193, 1196, 1205, 1213, 1314, 1316, 1317, 1318, 1319, 1328, 1353, 1365, 1366, 1367, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1400, 1403, 1404, 1405, 1406, 1410, 1411, 1412, 1415, 1426, 1427, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1441, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1475, 1485, 1506, 1520, 1521, 1538, 1544, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1565, 1581, 1611, 1612, 1613, 1614, 1615, 1616, 1629, 1633, 1639, 1648, 1667, 1672, 1673, 1674, 1675, 1676, 1678, 1679, 1683, 1686, 1687, 1688, 1690, 1694, 1695, 1696, 1698, 1699, 1700, 1701, 1702, 1706, 1708, 1709, 1710, 1712, 1713, 1715, 1716, 1717, 1718, 1719, 1720, 1724, 1726, 1727, 1731, 1732, 1734, 1738], "call": [0, 1, 2, 3, 7, 10, 12, 13, 17, 18, 19, 20, 21, 23, 24, 25, 26, 35, 37, 40, 41, 42, 105, 245, 278, 290, 388, 411, 439, 440, 506, 531, 565, 568, 592, 622, 626, 627, 628, 629, 630, 632, 633, 636, 659, 688, 690, 691, 717, 719, 729, 730, 739, 745, 746, 748, 749, 778, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 840, 858, 870, 880, 895, 898, 900, 905, 906, 907, 914, 950, 958, 962, 964, 966, 967, 998, 1028, 1034, 1035, 1036, 1053, 1054, 1055, 1056, 1057, 1059, 1061, 1063, 1101, 1112, 1113, 1114, 1116, 1123, 1124, 1144, 1155, 1167, 1191, 1192, 1193, 1199, 1200, 1201, 1206, 1224, 1281, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1315, 1316, 1317, 1318, 1319, 1374, 1386, 1389, 1396, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1412, 1416, 1417, 1419, 1420, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1439, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1479, 1482, 1506, 1536, 1555, 1588, 1589, 1625, 1641, 1660, 1667, 1668, 1674, 1676, 1680, 1683, 1687, 1688, 1690, 1691, 1692, 1695, 1696, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1712, 1713, 1715, 1716, 1717, 1718, 1719, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1736, 1738, 1739], "model": [0, 1, 2, 3, 4, 5, 7, 8, 18, 20, 21, 23, 24, 34, 36, 38, 40, 42, 729, 748, 870, 895, 899, 900, 904, 906, 910, 912, 966, 1024, 1053, 1070, 1081, 1082, 1116, 1122, 1144, 1155, 1159, 1161, 1162, 1163, 1212, 1319, 1320, 1383, 1385, 1387, 1400, 1418, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1441, 1443, 1444, 1445, 1446, 1447, 1452, 1458, 1459, 1482, 1483, 1495, 1496, 1497, 1498, 1499, 1501, 1518, 1519, 1520, 1521, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1625, 1667, 1676, 1678, 1679, 1680, 1685, 1686, 1696, 1698, 1699, 1700, 1701, 1704, 1706, 1707, 1708, 1709, 1710, 1711, 1713, 1718, 1720, 1724, 1725, 1728, 1732, 1736, 1737], "s": [0, 1, 2, 3, 4, 6, 7, 8, 12, 13, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 31, 32, 33, 35, 36, 40, 41, 42, 416, 434, 445, 448, 465, 494, 508, 532, 575, 589, 590, 591, 605, 607, 608, 609, 610, 623, 625, 626, 627, 631, 632, 633, 634, 638, 660, 662, 675, 679, 680, 681, 686, 688, 689, 692, 705, 717, 719, 724, 725, 728, 729, 730, 748, 749, 750, 756, 772, 775, 777, 778, 780, 781, 795, 796, 798, 799, 800, 803, 804, 806, 807, 810, 811, 813, 814, 815, 816, 818, 820, 821, 822, 823, 824, 827, 828, 829, 834, 835, 840, 848, 856, 857, 858, 882, 884, 892, 893, 895, 899, 905, 906, 910, 925, 926, 936, 937, 938, 940, 943, 947, 949, 951, 952, 956, 957, 958, 959, 964, 966, 967, 982, 993, 996, 998, 1003, 1004, 1011, 1012, 1015, 1022, 1023, 1024, 1032, 1033, 1034, 1035, 1036, 1039, 1053, 1059, 1070, 1116, 1117, 1122, 1126, 1132, 1144, 1147, 1149, 1155, 1159, 1161, 1163, 1169, 1170, 1185, 1186, 1197, 1210, 1213, 1224, 1225, 1268, 1281, 1314, 1318, 1319, 1320, 1328, 1353, 1389, 1400, 1413, 1415, 1422, 1423, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1442, 1443, 1444, 1445, 1446, 1447, 1452, 1463, 1465, 1469, 1476, 1502, 1505, 1508, 1558, 1561, 1562, 1565, 1566, 1567, 1569, 1571, 1578, 1584, 1609, 1610, 1614, 1623, 1624, 1625, 1628, 1629, 1630, 1631, 1632, 1633, 1636, 1640, 1642, 1648, 1662, 1663, 1664, 1667, 1668, 1674, 1676, 1677, 1678, 1679, 1680, 1683, 1686, 1687, 1688, 1689, 1690, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1708, 1709, 1711, 1712, 1713, 1714, 1715, 1717, 1718, 1719, 1721, 1722, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1737, 1738], "wrap": [0, 1, 13, 17, 18, 20, 23, 28, 37, 40, 42, 215, 690, 895, 910, 1053, 1116, 1155, 1317, 1319, 1387, 1413, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1479, 1481, 1676, 1677, 1679, 1695, 1696, 1699, 1700, 1701, 1706, 1712, 1717, 1718, 1719, 1724, 1725, 1738], "forward": [0, 5, 6, 7, 12, 18, 20, 21, 23, 24, 40, 42, 105, 176, 177, 619, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 636, 637, 728, 772, 785, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 870, 895, 898, 899, 900, 901, 905, 906, 910, 911, 912, 1028, 1032, 1053, 1054, 1055, 1056, 1057, 1059, 1060, 1061, 1068, 1086, 1101, 1112, 1113, 1114, 1116, 1117, 1118, 1122, 1123, 1126, 1127, 1131, 1144, 1159, 1160, 1161, 1162, 1163, 1199, 1200, 1201, 1206, 1251, 1314, 1316, 1317, 1318, 1319, 1328, 1341, 1350, 1353, 1387, 1389, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1407, 1416, 1419, 1420, 1485, 1502, 1506, 1540, 1549, 1587, 1604, 1660, 1676, 1678, 1679, 1685, 1688, 1690, 1694, 1695, 1696, 1698, 1699, 1700, 1702, 1703, 1705, 1706, 1709, 1711, 1713, 1715, 1716, 1717, 1718, 1719, 1724, 1736, 1737], "pass": [0, 1, 3, 5, 6, 12, 17, 18, 20, 21, 23, 24, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 105, 209, 401, 465, 467, 469, 510, 610, 619, 620, 621, 622, 628, 636, 660, 688, 717, 728, 770, 780, 802, 803, 804, 812, 813, 814, 820, 834, 857, 893, 895, 896, 899, 904, 906, 910, 911, 939, 955, 957, 966, 1024, 1025, 1026, 1027, 1053, 1059, 1060, 1064, 1065, 1116, 1121, 1122, 1144, 1160, 1161, 1162, 1163, 1168, 1178, 1208, 1209, 1213, 1224, 1225, 1251, 1314, 1316, 1317, 1318, 1319, 1387, 1389, 1391, 1396, 1410, 1413, 1415, 1417, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1505, 1508, 1538, 1574, 1578, 1629, 1674, 1676, 1680, 1683, 1685, 1687, 1688, 1689, 1690, 1691, 1694, 1695, 1696, 1698, 1700, 1701, 1703, 1705, 1706, 1709, 1713, 1715, 1716, 1717, 1724, 1726, 1727, 1728, 1732, 1733, 1734, 1738], "es": 0, "network": [0, 1, 6, 7, 13, 23, 24, 35, 728, 895, 910, 911, 1028, 1034, 1035, 1036, 1039, 1047, 1048, 1049, 1053, 1054, 1055, 1056, 1057, 1058, 1061, 1070, 1082, 1086, 1116, 1123, 1128, 1129, 1134, 1143, 1145, 1155, 1159, 1161, 1163, 1178, 1212, 1213, 1265, 1314, 1385, 1387, 1413, 1416, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1443, 1444, 1445, 1446, 1447, 1452, 1458, 1523, 1676, 1678, 1679, 1694, 1695, 1709, 1710, 1713, 1715, 1719, 1724, 1725, 1726], "includ": [0, 1, 2, 3, 4, 5, 6, 8, 12, 13, 17, 18, 19, 20, 32, 35, 36, 40, 42, 276, 469, 535, 809, 811, 856, 893, 895, 896, 924, 1029, 1030, 1031, 1037, 1039, 1053, 1062, 1070, 1103, 1112, 1113, 1114, 1116, 1166, 1180, 1181, 1182, 1197, 1210, 1230, 1319, 1361, 1362, 1411, 1412, 1414, 1538, 1540, 1649, 1650, 1651, 1652, 1674, 1676, 1678, 1679, 1685, 1687, 1688, 1696, 1698, 1699, 1702, 1705, 1706, 1711, 1713, 1718, 1719, 1724, 1726, 1732, 1735, 1738], "loss": [0, 1, 18, 20, 21, 23, 24, 40, 892, 930, 931, 940, 958, 1024, 1032, 1033, 1039, 1050, 1052, 1059, 1070, 1076, 1077, 1082, 1083, 1107, 1108, 1119, 1120, 1121, 1123, 1130, 1147, 1148, 1164, 1165, 1185, 1186, 1196, 1197, 1210, 1225, 1248, 1256, 1319, 1411, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1441, 1443, 1444, 1445, 1447, 1451, 1459, 1585, 1674, 1687, 1690, 1696, 1699, 1700, 1702, 1703, 1706, 1715, 1719, 1720, 1724, 1725, 1732], "comput": [0, 3, 5, 6, 7, 10, 12, 14, 17, 18, 20, 24, 26, 28, 40, 105, 245, 440, 447, 576, 578, 592, 593, 619, 622, 623, 624, 626, 627, 630, 631, 632, 633, 634, 635, 636, 637, 638, 648, 649, 650, 651, 652, 653, 664, 666, 667, 668, 675, 680, 682, 687, 725, 763, 772, 774, 777, 780, 781, 785, 786, 797, 798, 799, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 824, 826, 827, 828, 830, 838, 839, 840, 848, 851, 854, 855, 856, 857, 870, 872, 895, 898, 906, 914, 915, 917, 919, 923, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 939, 940, 941, 942, 943, 944, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 957, 958, 959, 960, 961, 963, 964, 965, 967, 975, 976, 977, 978, 979, 981, 982, 983, 984, 985, 993, 995, 996, 997, 1000, 1012, 1014, 1017, 1024, 1028, 1029, 1030, 1031, 1034, 1035, 1036, 1047, 1048, 1049, 1051, 1052, 1054, 1059, 1060, 1068, 1071, 1079, 1080, 1081, 1082, 1084, 1085, 1086, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1106, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1122, 1123, 1125, 1130, 1131, 1149, 1151, 1155, 1164, 1165, 1168, 1180, 1181, 1182, 1195, 1196, 1204, 1205, 1212, 1213, 1215, 1224, 1232, 1237, 1238, 1239, 1240, 1241, 1242, 1253, 1256, 1268, 1269, 1314, 1316, 1318, 1319, 1320, 1353, 1361, 1362, 1381, 1384, 1387, 1389, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1403, 1404, 1411, 1415, 1419, 1420, 1422, 1431, 1433, 1434, 1435, 1437, 1443, 1444, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1463, 1469, 1475, 1476, 1485, 1487, 1501, 1502, 1503, 1504, 1506, 1507, 1547, 1548, 1562, 1563, 1585, 1587, 1593, 1604, 1605, 1606, 1607, 1608, 1625, 1629, 1630, 1633, 1641, 1646, 1664, 1667, 1676, 1679, 1687, 1689, 1690, 1692, 1695, 1698, 1699, 1701, 1702, 1703, 1704, 1706, 1707, 1713, 1715, 1719, 1722, 1724, 1727, 1728, 1733, 1736], "backward": [0, 1, 5, 8, 20, 21, 23, 24, 40, 42, 245, 290, 440, 448, 455, 456, 465, 467, 469, 581, 584, 620, 624, 625, 626, 627, 628, 629, 631, 633, 636, 637, 644, 656, 728, 780, 785, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 895, 967, 975, 990, 1001, 1032, 1033, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1053, 1059, 1068, 1069, 1070, 1083, 1086, 1087, 1103, 1107, 1108, 1116, 1123, 1130, 1131, 1164, 1165, 1185, 1186, 1196, 1197, 1213, 1224, 1248, 1251, 1315, 1318, 1319, 1353, 1389, 1420, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1451, 1475, 1604, 1606, 1610, 1629, 1633, 1660, 1674, 1675, 1677, 1679, 1690, 1694, 1695, 1696, 1700, 1701, 1702, 1705, 1706, 1708, 1709, 1715, 1716, 1718, 1719, 1724, 1727, 1728, 1733], "under": [0, 1, 3, 4, 17, 20, 35, 40, 41, 637, 640, 661, 870, 895, 1039, 1116, 1178, 1204, 1205, 1384, 1386, 1389, 1563, 1688, 1695, 1696, 1699, 1700, 1703, 1708, 1716, 1717, 1719, 1723, 1726, 1728, 1732, 1735, 1737], "recommend": [0, 1, 17, 18, 20, 24, 26, 35, 36, 40, 41, 42, 43, 401, 622, 679, 680, 687, 802, 803, 804, 812, 813, 814, 882, 898, 940, 967, 1024, 1053, 1225, 1319, 1549, 1657, 1674, 1676, 1688, 1690, 1694, 1695, 1696, 1698, 1699, 1701, 1706, 1708, 1711, 1713, 1716], "same": [0, 1, 3, 6, 12, 13, 14, 17, 18, 19, 20, 21, 23, 24, 26, 32, 33, 35, 36, 37, 38, 40, 41, 42, 94, 108, 150, 176, 210, 266, 268, 270, 274, 276, 294, 388, 398, 399, 400, 401, 402, 424, 436, 449, 450, 452, 465, 467, 469, 472, 494, 531, 568, 569, 581, 588, 590, 591, 592, 594, 608, 609, 610, 624, 627, 630, 631, 632, 633, 634, 635, 637, 638, 644, 646, 647, 656, 658, 660, 663, 668, 670, 677, 687, 688, 689, 697, 699, 717, 728, 763, 768, 770, 771, 777, 781, 783, 784, 787, 797, 798, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 818, 829, 833, 834, 836, 837, 840, 848, 856, 857, 865, 869, 886, 892, 895, 905, 906, 910, 911, 915, 916, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 939, 940, 941, 942, 944, 946, 947, 948, 949, 952, 953, 954, 955, 957, 958, 959, 962, 982, 987, 989, 994, 996, 997, 998, 999, 1002, 1012, 1015, 1016, 1022, 1023, 1026, 1027, 1028, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1054, 1055, 1056, 1057, 1058, 1060, 1061, 1063, 1066, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1085, 1088, 1098, 1099, 1100, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1119, 1120, 1121, 1122, 1124, 1125, 1130, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1167, 1168, 1171, 1178, 1184, 1185, 1186, 1188, 1189, 1190, 1196, 1205, 1213, 1215, 1224, 1225, 1281, 1304, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1319, 1323, 1324, 1325, 1326, 1338, 1339, 1349, 1351, 1354, 1355, 1356, 1357, 1358, 1372, 1378, 1384, 1389, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1400, 1403, 1404, 1410, 1414, 1422, 1423, 1427, 1463, 1468, 1469, 1472, 1473, 1477, 1478, 1485, 1487, 1499, 1501, 1504, 1506, 1507, 1538, 1552, 1554, 1556, 1560, 1562, 1564, 1565, 1569, 1578, 1581, 1593, 1604, 1611, 1612, 1613, 1615, 1616, 1622, 1628, 1629, 1635, 1646, 1657, 1658, 1659, 1660, 1664, 1667, 1673, 1674, 1676, 1678, 1679, 1687, 1688, 1689, 1690, 1691, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1708, 1709, 1710, 1711, 1713, 1716, 1717, 1719, 1722, 1724, 1725, 1726, 1727, 1729, 1730, 1731, 1732, 1733, 1734, 1736, 1738], "correspond": [0, 1, 6, 8, 17, 18, 20, 23, 24, 35, 40, 42, 426, 427, 465, 467, 469, 494, 495, 619, 621, 622, 627, 630, 632, 637, 668, 681, 728, 747, 775, 780, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 848, 857, 884, 895, 911, 925, 930, 931, 936, 939, 958, 965, 967, 981, 998, 1007, 1053, 1059, 1086, 1116, 1122, 1162, 1204, 1213, 1250, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1318, 1319, 1328, 1385, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1416, 1422, 1452, 1468, 1469, 1482, 1518, 1520, 1536, 1537, 1543, 1546, 1569, 1578, 1593, 1629, 1656, 1659, 1674, 1676, 1677, 1679, 1683, 1687, 1689, 1690, 1695, 1699, 1700, 1701, 1703, 1705, 1706, 1710, 1713, 1716, 1718, 1719, 1724, 1725, 1727, 1728, 1729, 1732, 1734, 1736, 1737], "devic": [0, 1, 2, 5, 7, 12, 17, 18, 20, 21, 36, 37, 40, 41, 43, 151, 161, 164, 244, 268, 276, 290, 398, 399, 400, 401, 402, 467, 469, 531, 581, 584, 595, 607, 609, 610, 630, 632, 644, 645, 647, 654, 656, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 702, 703, 704, 707, 710, 711, 712, 714, 715, 723, 725, 726, 727, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 745, 746, 747, 750, 751, 752, 753, 757, 758, 780, 782, 783, 784, 794, 799, 817, 835, 836, 852, 853, 895, 899, 902, 905, 908, 914, 924, 925, 926, 930, 931, 932, 933, 935, 936, 937, 938, 941, 942, 943, 949, 952, 953, 955, 956, 958, 959, 965, 966, 981, 985, 990, 997, 1001, 1024, 1034, 1035, 1036, 1037, 1044, 1045, 1046, 1047, 1048, 1049, 1053, 1059, 1060, 1069, 1071, 1079, 1080, 1081, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1103, 1116, 1122, 1124, 1132, 1133, 1155, 1159, 1161, 1163, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1205, 1224, 1277, 1281, 1282, 1283, 1307, 1308, 1309, 1310, 1311, 1314, 1319, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1342, 1344, 1345, 1346, 1347, 1348, 1410, 1415, 1421, 1423, 1426, 1427, 1436, 1475, 1480, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1585, 1607, 1611, 1612, 1613, 1614, 1615, 1616, 1629, 1639, 1641, 1650, 1652, 1660, 1672, 1673, 1675, 1676, 1677, 1678, 1679, 1681, 1685, 1689, 1691, 1695, 1700, 1702, 1704, 1706, 1707, 1710, 1713, 1714, 1716, 1717, 1718, 1719, 1723, 1724, 1729, 1733, 1734], "creat": [0, 1, 3, 5, 6, 8, 12, 17, 18, 20, 23, 24, 26, 27, 33, 35, 36, 38, 40, 41, 42, 43, 105, 177, 209, 290, 531, 532, 608, 609, 610, 622, 624, 636, 655, 657, 673, 674, 681, 725, 726, 735, 768, 784, 833, 834, 835, 892, 895, 898, 907, 913, 918, 924, 925, 931, 933, 952, 965, 981, 998, 1007, 1032, 1050, 1059, 1060, 1063, 1077, 1083, 1107, 1108, 1116, 1119, 1120, 1121, 1144, 1147, 1148, 1155, 1164, 1165, 1167, 1319, 1325, 1331, 1332, 1333, 1338, 1339, 1349, 1357, 1389, 1410, 1415, 1485, 1499, 1501, 1506, 1581, 1600, 1609, 1614, 1639, 1646, 1679, 1680, 1683, 1685, 1688, 1695, 1696, 1699, 1700, 1701, 1703, 1706, 1707, 1708, 1711, 1713, 1715, 1716, 1718, 1719, 1724, 1725, 1726, 1727, 1729, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1739], "optim": [0, 1, 6, 7, 10, 12, 13, 18, 20, 21, 24, 40, 42, 637, 641, 781, 895, 899, 904, 906, 910, 911, 950, 967, 1034, 1035, 1036, 1052, 1059, 1079, 1080, 1081, 1116, 1119, 1120, 1121, 1122, 1148, 1155, 1163, 1314, 1319, 1384, 1389, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1465, 1501, 1675, 1676, 1678, 1685, 1690, 1694, 1698, 1699, 1700, 1701, 1702, 1703, 1706, 1708, 1713, 1718, 1719, 1727], "default": [0, 2, 3, 5, 8, 10, 12, 19, 20, 21, 23, 24, 26, 27, 32, 33, 34, 35, 36, 38, 40, 42, 105, 110, 125, 127, 130, 133, 134, 135, 150, 161, 164, 194, 222, 245, 252, 280, 286, 347, 398, 399, 400, 401, 402, 411, 448, 451, 452, 472, 476, 531, 589, 592, 595, 609, 610, 622, 623, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 645, 654, 660, 664, 667, 668, 669, 673, 686, 687, 689, 691, 693, 698, 699, 700, 703, 704, 710, 711, 714, 725, 727, 728, 731, 733, 734, 735, 737, 739, 740, 741, 745, 746, 747, 751, 752, 755, 757, 758, 761, 762, 763, 768, 769, 770, 771, 772, 775, 780, 782, 783, 784, 794, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 834, 835, 836, 840, 842, 848, 852, 853, 856, 857, 884, 886, 892, 895, 896, 899, 906, 910, 911, 914, 915, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 981, 985, 987, 993, 994, 996, 997, 998, 1002, 1011, 1012, 1014, 1015, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1130, 1131, 1133, 1134, 1135, 1136, 1143, 1147, 1148, 1152, 1153, 1155, 1158, 1159, 1161, 1162, 1163, 1164, 1165, 1167, 1168, 1175, 1176, 1177, 1178, 1180, 1181, 1182, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1204, 1205, 1206, 1210, 1212, 1213, 1215, 1217, 1224, 1225, 1232, 1237, 1238, 1239, 1248, 1249, 1251, 1256, 1268, 1269, 1277, 1281, 1296, 1297, 1298, 1299, 1300, 1301, 1304, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1328, 1348, 1351, 1353, 1361, 1362, 1363, 1365, 1366, 1367, 1372, 1378, 1381, 1384, 1385, 1386, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1411, 1412, 1414, 1415, 1416, 1419, 1421, 1422, 1426, 1427, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1443, 1444, 1445, 1446, 1447, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1463, 1465, 1473, 1475, 1476, 1483, 1499, 1501, 1502, 1503, 1504, 1507, 1523, 1537, 1547, 1548, 1549, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1561, 1564, 1571, 1574, 1578, 1582, 1583, 1584, 1585, 1590, 1592, 1605, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1625, 1628, 1629, 1630, 1633, 1639, 1640, 1646, 1648, 1650, 1652, 1657, 1658, 1660, 1661, 1667, 1672, 1673, 1674, 1676, 1679, 1683, 1685, 1686, 1688, 1694, 1695, 1698, 1700, 1701, 1702, 1704, 1706, 1709, 1711, 1712, 1713, 1715, 1716, 1717, 1718, 1719, 1723, 1724, 1727, 1728, 1729, 1732, 1733, 1734, 1735, 1736, 1739], "net": [0, 13, 26, 42, 895, 910, 911, 1053, 1116, 1319, 1400, 1451, 1678, 1679, 1695, 1696, 1699, 1706, 1732], "sgd": [0, 17, 18, 23, 1059, 1314, 1319, 1452, 1458, 1459, 1695, 1699, 1700, 1706, 1715, 1724, 1725], "paramet": [0, 1, 2, 3, 5, 10, 12, 17, 18, 20, 21, 23, 24, 25, 26, 29, 33, 35, 40, 41, 42, 43, 105, 110, 125, 127, 130, 133, 134, 135, 150, 151, 161, 164, 194, 209, 210, 215, 222, 252, 268, 270, 272, 274, 276, 280, 286, 347, 355, 357, 398, 399, 400, 401, 402, 411, 424, 445, 448, 449, 450, 451, 452, 465, 467, 469, 472, 476, 488, 494, 495, 496, 510, 516, 534, 535, 555, 556, 559, 568, 569, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 588, 589, 590, 591, 592, 593, 594, 595, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 622, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 673, 674, 675, 677, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 696, 697, 698, 699, 700, 703, 704, 705, 707, 710, 711, 712, 714, 717, 725, 726, 727, 728, 729, 730, 731, 733, 734, 735, 737, 739, 740, 741, 742, 744, 745, 746, 747, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 767, 768, 769, 770, 771, 772, 774, 775, 777, 778, 779, 780, 781, 782, 783, 784, 786, 791, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 832, 834, 835, 836, 837, 838, 839, 840, 848, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 865, 869, 870, 872, 874, 875, 877, 880, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 901, 902, 905, 906, 907, 908, 910, 911, 914, 915, 916, 917, 918, 919, 920, 923, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1004, 1005, 1006, 1007, 1009, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1147, 1148, 1149, 1151, 1152, 1153, 1155, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1180, 1181, 1182, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1204, 1205, 1206, 1208, 1209, 1210, 1212, 1213, 1215, 1217, 1224, 1225, 1232, 1237, 1238, 1239, 1248, 1249, 1250, 1251, 1253, 1254, 1255, 1256, 1257, 1268, 1269, 1277, 1281, 1282, 1283, 1314, 1319, 1321, 1322, 1328, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1343, 1348, 1349, 1351, 1352, 1353, 1357, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1370, 1372, 1373, 1374, 1375, 1376, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1421, 1422, 1423, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1463, 1464, 1465, 1466, 1468, 1469, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1480, 1481, 1482, 1484, 1485, 1486, 1499, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1520, 1521, 1522, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1568, 1569, 1570, 1571, 1573, 1574, 1578, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1590, 1591, 1592, 1593, 1595, 1596, 1597, 1599, 1600, 1602, 1603, 1604, 1605, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1628, 1629, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1645, 1646, 1648, 1649, 1650, 1651, 1652, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1672, 1673, 1674, 1676, 1679, 1681, 1683, 1685, 1686, 1688, 1690, 1692, 1694, 1695, 1696, 1699, 1700, 1701, 1705, 1706, 1708, 1710, 1711, 1713, 1716, 1717, 1718, 1719, 1723, 1724, 1725, 1727, 1728, 1729, 1732, 1734, 1736, 1737, 1738], "target": [0, 12, 23, 40, 41, 42, 451, 661, 895, 904, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1032, 1033, 1039, 1050, 1052, 1064, 1065, 1070, 1076, 1077, 1082, 1083, 1107, 1108, 1112, 1113, 1114, 1116, 1119, 1120, 1121, 1122, 1123, 1130, 1147, 1148, 1159, 1168, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1185, 1186, 1194, 1196, 1197, 1208, 1209, 1210, 1221, 1222, 1225, 1226, 1236, 1244, 1245, 1246, 1247, 1248, 1256, 1266, 1267, 1319, 1328, 1359, 1360, 1446, 1482, 1540, 1541, 1660, 1677, 1679, 1695, 1696, 1699, 1708, 1713, 1715, 1716, 1719, 1720, 1724, 1732, 1736], "data": [0, 1, 2, 3, 6, 10, 15, 18, 20, 23, 24, 25, 26, 29, 32, 35, 37, 40, 42, 94, 105, 150, 151, 281, 284, 288, 291, 296, 398, 401, 434, 445, 449, 451, 534, 568, 595, 609, 610, 620, 622, 645, 654, 660, 690, 761, 762, 782, 783, 784, 794, 795, 796, 799, 801, 802, 804, 812, 813, 814, 817, 820, 821, 822, 823, 832, 834, 835, 836, 852, 853, 855, 874, 877, 902, 906, 910, 914, 965, 966, 967, 981, 987, 996, 998, 1012, 1014, 1015, 1037, 1039, 1044, 1045, 1046, 1053, 1068, 1071, 1079, 1080, 1081, 1086, 1088, 1103, 1123, 1131, 1132, 1168, 1178, 1183, 1184, 1188, 1189, 1190, 1223, 1230, 1232, 1268, 1269, 1319, 1320, 1321, 1322, 1331, 1332, 1333, 1353, 1365, 1366, 1367, 1374, 1410, 1411, 1412, 1413, 1422, 1426, 1427, 1428, 1452, 1458, 1465, 1473, 1476, 1483, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1544, 1545, 1549, 1551, 1552, 1554, 1555, 1556, 1557, 1558, 1565, 1578, 1605, 1608, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1628, 1629, 1639, 1648, 1650, 1652, 1659, 1660, 1672, 1673, 1675, 1676, 1677, 1680, 1687, 1688, 1691, 1695, 1696, 1697, 1699, 1701, 1705, 1708, 1710, 1711, 1712, 1714, 1715, 1716, 1717, 1719, 1722, 1724, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1734, 1735, 1736, 1737], "zero_grad": [0, 1, 23, 895, 1116, 1319, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1443, 1444, 1445, 1446, 1447, 1451, 1695, 1699, 1702, 1706, 1708, 1715], "output": [0, 1, 4, 5, 6, 17, 18, 19, 20, 23, 24, 26, 32, 33, 42, 94, 268, 276, 399, 400, 402, 465, 469, 516, 534, 568, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 588, 590, 591, 592, 593, 594, 595, 604, 605, 608, 611, 612, 613, 614, 615, 616, 617, 618, 619, 621, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 644, 646, 647, 648, 649, 650, 651, 652, 653, 656, 660, 663, 664, 665, 666, 667, 668, 669, 671, 674, 680, 681, 683, 684, 687, 696, 698, 699, 700, 725, 726, 728, 738, 739, 759, 760, 761, 762, 764, 767, 768, 770, 772, 775, 777, 779, 780, 781, 782, 783, 784, 786, 791, 794, 795, 796, 797, 798, 799, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 824, 825, 826, 827, 828, 829, 831, 835, 836, 837, 838, 839, 840, 848, 851, 854, 855, 856, 857, 859, 860, 861, 869, 872, 889, 890, 892, 895, 899, 906, 910, 911, 915, 916, 917, 918, 919, 920, 923, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 968, 969, 970, 971, 972, 973, 974, 976, 977, 978, 979, 981, 982, 984, 985, 986, 987, 989, 990, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1005, 1006, 1007, 1009, 1011, 1012, 1013, 1014, 1015, 1017, 1018, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1128, 1129, 1130, 1131, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1180, 1181, 1182, 1184, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1195, 1196, 1197, 1204, 1205, 1207, 1208, 1209, 1210, 1213, 1215, 1224, 1225, 1230, 1232, 1237, 1238, 1239, 1248, 1249, 1253, 1254, 1255, 1256, 1277, 1281, 1282, 1283, 1304, 1312, 1313, 1316, 1319, 1327, 1328, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1365, 1366, 1367, 1368, 1370, 1372, 1373, 1374, 1375, 1376, 1378, 1379, 1380, 1385, 1386, 1387, 1390, 1411, 1413, 1414, 1416, 1419, 1421, 1422, 1423, 1426, 1427, 1451, 1463, 1464, 1472, 1473, 1476, 1484, 1487, 1499, 1537, 1542, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1561, 1562, 1563, 1564, 1566, 1567, 1571, 1573, 1578, 1585, 1590, 1593, 1595, 1596, 1597, 1599, 1603, 1606, 1607, 1609, 1610, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1628, 1629, 1633, 1636, 1637, 1638, 1643, 1646, 1648, 1649, 1651, 1654, 1656, 1657, 1658, 1660, 1661, 1662, 1663, 1664, 1667, 1669, 1672, 1673, 1674, 1676, 1677, 1679, 1685, 1689, 1690, 1695, 1696, 1698, 1699, 1700, 1701, 1702, 1706, 1709, 1713, 1715, 1716, 1717, 1718, 1719, 1721, 1725, 1727, 1728, 1730, 1731, 1732, 1734, 1736, 1737], "loss_fn": [0, 23, 1446, 1695, 1699, 1700, 1708, 1715], "exit": [0, 1, 4, 20, 26, 35, 40, 41, 42, 623, 1319, 1679, 1688, 1696, 1708, 1713, 1726], "befor": [0, 1, 3, 6, 12, 17, 18, 20, 21, 23, 24, 27, 32, 34, 35, 36, 37, 40, 42, 52, 105, 622, 626, 628, 674, 689, 761, 762, 763, 772, 781, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 822, 823, 826, 834, 895, 906, 908, 947, 951, 964, 996, 1012, 1015, 1053, 1059, 1060, 1063, 1116, 1117, 1118, 1155, 1159, 1167, 1213, 1232, 1268, 1269, 1314, 1316, 1317, 1318, 1319, 1340, 1385, 1416, 1419, 1431, 1444, 1459, 1473, 1476, 1477, 1478, 1479, 1569, 1578, 1588, 1589, 1605, 1608, 1611, 1612, 1613, 1615, 1616, 1625, 1628, 1646, 1657, 1676, 1678, 1679, 1688, 1695, 1696, 1699, 1700, 1701, 1703, 1705, 1706, 1711, 1712, 1713, 1715, 1716, 1717, 1719, 1724, 1725, 1726, 1727, 1728, 1732, 1734], "step": [0, 1, 2, 4, 8, 12, 17, 18, 19, 20, 21, 23, 24, 36, 40, 42, 489, 559, 581, 595, 623, 624, 625, 647, 671, 854, 942, 965, 967, 981, 985, 998, 1064, 1065, 1086, 1181, 1182, 1208, 1209, 1319, 1361, 1362, 1410, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1536, 1549, 1558, 1600, 1676, 1677, 1690, 1695, 1696, 1699, 1700, 1701, 1702, 1706, 1708, 1710, 1712, 1716, 1718, 1719, 1724, 1725, 1727, 1732], "usag": [0, 1, 4, 6, 13, 17, 19, 20, 23, 24, 25, 26, 29, 32, 33, 35, 37, 40, 42, 731, 750, 754, 832, 908, 967, 1319, 1341, 1350, 1495, 1496, 1497, 1498, 1537, 1676, 1679, 1687, 1690, 1695, 1696, 1701, 1702, 1713, 1726, 1727, 1732, 1733, 1735, 1736, 1737], "along": [0, 12, 17, 20, 24, 28, 35, 268, 270, 272, 276, 445, 465, 467, 469, 534, 581, 592, 605, 606, 670, 685, 687, 698, 700, 763, 771, 772, 779, 781, 797, 802, 805, 809, 812, 815, 821, 837, 860, 869, 872, 916, 927, 963, 1005, 1012, 1016, 1025, 1026, 1027, 1051, 1064, 1065, 1106, 1109, 1110, 1111, 1149, 1151, 1178, 1195, 1208, 1209, 1212, 1215, 1232, 1237, 1238, 1239, 1249, 1268, 1269, 1395, 1397, 1404, 1405, 1414, 1421, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1443, 1444, 1445, 1446, 1447, 1458, 1476, 1501, 1563, 1564, 1569, 1580, 1603, 1605, 1608, 1609, 1617, 1622, 1636, 1640, 1643, 1646, 1655, 1664, 1669, 1674, 1678, 1683, 1697, 1701, 1702, 1705, 1706, 1716, 1719, 1728], "more": [0, 1, 3, 4, 7, 8, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 31, 34, 35, 36, 37, 40, 42, 105, 209, 210, 268, 276, 445, 447, 450, 467, 469, 495, 569, 603, 616, 617, 618, 622, 628, 630, 632, 636, 637, 638, 647, 655, 658, 660, 666, 667, 668, 669, 689, 690, 691, 693, 694, 708, 726, 731, 733, 734, 735, 737, 738, 739, 740, 745, 746, 747, 751, 758, 763, 769, 778, 781, 785, 797, 798, 800, 802, 821, 822, 823, 824, 843, 844, 848, 857, 858, 870, 876, 880, 882, 883, 895, 908, 911, 924, 925, 926, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 962, 964, 967, 970, 973, 975, 986, 987, 1013, 1024, 1028, 1033, 1038, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1059, 1060, 1061, 1077, 1086, 1116, 1122, 1128, 1129, 1130, 1131, 1143, 1155, 1163, 1178, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1202, 1204, 1205, 1213, 1216, 1217, 1218, 1219, 1224, 1228, 1232, 1233, 1243, 1250, 1257, 1258, 1259, 1261, 1263, 1264, 1265, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1280, 1281, 1282, 1283, 1314, 1319, 1320, 1328, 1364, 1373, 1377, 1384, 1386, 1387, 1420, 1421, 1422, 1463, 1474, 1475, 1538, 1539, 1540, 1568, 1574, 1578, 1587, 1605, 1629, 1633, 1646, 1648, 1660, 1667, 1668, 1674, 1676, 1678, 1679, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1694, 1696, 1698, 1699, 1701, 1702, 1703, 1704, 1705, 1706, 1709, 1711, 1713, 1715, 1716, 1717, 1718, 1719, 1720, 1725, 1726, 1727, 1730, 1731, 1732, 1733, 1734, 1735, 1738, 1739], "complex": [0, 1, 3, 6, 7, 18, 20, 42, 266, 284, 436, 580, 587, 637, 638, 669, 679, 680, 775, 780, 802, 824, 829, 848, 865, 874, 885, 887, 888, 891, 892, 895, 915, 924, 925, 926, 928, 930, 931, 932, 933, 934, 935, 937, 944, 947, 949, 951, 952, 953, 954, 958, 959, 963, 964, 965, 967, 975, 981, 995, 1000, 1006, 1044, 1045, 1046, 1083, 1116, 1188, 1189, 1190, 1384, 1422, 1469, 1549, 1562, 1582, 1593, 1625, 1626, 1629, 1633, 1660, 1664, 1665, 1666, 1675, 1677, 1679, 1680, 1708, 1729, 1730, 1733, 1734], "scenario": [0, 17, 20, 35, 1699, 1703, 1713, 1718, 1724], "e": [0, 1, 2, 3, 5, 6, 8, 10, 12, 13, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 38, 40, 41, 42, 43, 105, 213, 290, 331, 531, 568, 619, 622, 627, 637, 638, 655, 657, 660, 714, 728, 752, 780, 781, 791, 832, 845, 870, 874, 875, 877, 880, 892, 895, 901, 902, 910, 930, 931, 946, 958, 966, 967, 968, 970, 972, 990, 1002, 1032, 1033, 1034, 1035, 1036, 1039, 1044, 1045, 1046, 1052, 1053, 1055, 1056, 1057, 1059, 1060, 1061, 1063, 1068, 1071, 1076, 1079, 1080, 1081, 1082, 1083, 1086, 1088, 1089, 1090, 1091, 1107, 1116, 1117, 1122, 1123, 1126, 1130, 1131, 1147, 1155, 1159, 1163, 1164, 1165, 1167, 1188, 1189, 1190, 1197, 1199, 1200, 1201, 1204, 1205, 1206, 1213, 1224, 1256, 1281, 1283, 1314, 1319, 1320, 1321, 1322, 1328, 1341, 1350, 1353, 1385, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1410, 1411, 1415, 1419, 1422, 1468, 1537, 1546, 1564, 1571, 1578, 1588, 1593, 1625, 1629, 1633, 1674, 1676, 1677, 1678, 1679, 1680, 1683, 1685, 1688, 1689, 1690, 1691, 1695, 1696, 1697, 1698, 1699, 1701, 1702, 1704, 1705, 1706, 1709, 1711, 1713, 1715, 1716, 1718, 1719, 1724, 1725, 1726, 1727, 1728, 1730, 1731, 1732, 1734, 1738, 1739], "g": [0, 1, 2, 3, 5, 6, 10, 12, 13, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 38, 40, 41, 42, 531, 568, 619, 627, 637, 638, 657, 728, 781, 832, 845, 848, 870, 892, 895, 901, 902, 910, 966, 1039, 1040, 1053, 1055, 1056, 1057, 1061, 1063, 1068, 1076, 1082, 1086, 1087, 1116, 1117, 1126, 1131, 1147, 1197, 1199, 1200, 1201, 1206, 1213, 1319, 1320, 1321, 1322, 1341, 1350, 1353, 1419, 1422, 1431, 1432, 1433, 1434, 1437, 1443, 1444, 1445, 1446, 1564, 1571, 1588, 1625, 1674, 1676, 1678, 1679, 1680, 1683, 1688, 1695, 1696, 1699, 1701, 1702, 1703, 1705, 1706, 1709, 1710, 1713, 1715, 1716, 1718, 1719, 1724, 1727, 1730, 1731, 1732, 1738], "penalti": [0, 739, 1374, 1430, 1431, 1432, 1433, 1435, 1437, 1443, 1444, 1446, 1720], "multipl": [0, 1, 2, 3, 17, 18, 19, 20, 21, 24, 25, 28, 35, 36, 37, 40, 41, 42, 146, 163, 270, 465, 581, 583, 584, 590, 591, 604, 605, 608, 636, 664, 666, 682, 686, 698, 699, 700, 778, 781, 784, 834, 840, 844, 858, 859, 908, 911, 916, 917, 932, 933, 934, 950, 955, 960, 961, 990, 994, 999, 1001, 1032, 1033, 1047, 1048, 1049, 1050, 1052, 1060, 1063, 1076, 1082, 1083, 1104, 1107, 1108, 1119, 1120, 1121, 1123, 1130, 1147, 1148, 1164, 1167, 1185, 1186, 1196, 1205, 1225, 1248, 1256, 1319, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1445, 1453, 1454, 1455, 1456, 1457, 1461, 1463, 1523, 1585, 1602, 1606, 1607, 1611, 1612, 1613, 1615, 1616, 1640, 1641, 1648, 1656, 1660, 1668, 1674, 1678, 1679, 1688, 1689, 1690, 1691, 1696, 1698, 1700, 1703, 1705, 1706, 1708, 1709, 1710, 1711, 1712, 1713, 1715, 1716, 1718, 1719, 1720, 1724, 1725, 1726, 1727], "custom": [0, 1, 3, 5, 12, 13, 17, 20, 21, 22, 23, 28, 31, 32, 34, 40, 451, 628, 756, 895, 1116, 1159, 1164, 1165, 1391, 1400, 1415, 1452, 1482, 1499, 1520, 1522, 1538, 1539, 1540, 1680, 1683, 1688, 1689, 1696, 1705, 1710, 1711, 1712, 1722, 1736], "autograd": [0, 4, 5, 6, 7, 20, 23, 24, 94, 290, 398, 399, 400, 401, 402, 448, 595, 609, 610, 623, 645, 654, 673, 728, 782, 783, 784, 794, 799, 817, 834, 835, 836, 852, 853, 870, 895, 914, 934, 965, 981, 1001, 1070, 1116, 1122, 1163, 1215, 1319, 1426, 1427, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1589, 1611, 1612, 1613, 1614, 1615, 1616, 1639, 1667, 1672, 1673, 1675, 1677, 1681, 1694, 1699, 1700, 1702, 1703, 1705, 1706, 1718, 1733, 1734, 1738], "function": [0, 2, 3, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 19, 21, 23, 25, 26, 28, 32, 33, 35, 36, 40, 41, 43, 74, 105, 150, 215, 244, 253, 276, 440, 445, 448, 469, 506, 588, 589, 593, 594, 607, 608, 622, 623, 624, 625, 636, 637, 638, 641, 645, 654, 656, 664, 666, 670, 673, 679, 680, 687, 690, 691, 693, 710, 711, 714, 719, 720, 725, 726, 728, 729, 730, 731, 733, 738, 739, 745, 746, 748, 749, 750, 754, 763, 768, 770, 771, 778, 781, 785, 797, 798, 800, 820, 824, 827, 828, 829, 832, 834, 840, 841, 848, 852, 853, 854, 856, 858, 866, 867, 868, 870, 882, 892, 893, 894, 895, 896, 898, 900, 901, 905, 906, 907, 908, 910, 912, 914, 915, 916, 918, 923, 924, 925, 926, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 942, 943, 944, 946, 949, 950, 951, 952, 953, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 966, 967, 970, 972, 981, 985, 986, 990, 994, 997, 999, 1001, 1002, 1003, 1009, 1012, 1013, 1028, 1032, 1038, 1039, 1041, 1042, 1043, 1050, 1054, 1058, 1061, 1066, 1067, 1068, 1069, 1070, 1072, 1073, 1074, 1075, 1076, 1082, 1084, 1085, 1086, 1087, 1102, 1105, 1106, 1108, 1115, 1116, 1121, 1124, 1131, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1144, 1145, 1146, 1147, 1149, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1159, 1161, 1163, 1164, 1165, 1167, 1169, 1171, 1315, 1318, 1319, 1341, 1350, 1351, 1353, 1357, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1384, 1385, 1389, 1400, 1410, 1411, 1412, 1414, 1415, 1416, 1417, 1420, 1422, 1423, 1427, 1429, 1436, 1441, 1448, 1451, 1452, 1454, 1457, 1458, 1464, 1465, 1469, 1475, 1479, 1480, 1481, 1482, 1483, 1485, 1499, 1506, 1520, 1523, 1536, 1538, 1540, 1542, 1549, 1553, 1558, 1571, 1580, 1581, 1584, 1587, 1593, 1600, 1604, 1605, 1606, 1607, 1608, 1614, 1621, 1625, 1631, 1632, 1633, 1636, 1640, 1642, 1646, 1656, 1657, 1658, 1660, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1680, 1683, 1686, 1687, 1688, 1690, 1694, 1697, 1699, 1700, 1701, 1702, 1705, 1706, 1711, 1715, 1716, 1717, 1718, 1719, 1721, 1723, 1724, 1725, 1726, 1730, 1732, 1734, 1735, 1736, 1737], "autocastmodel": 0, "nn": [0, 3, 5, 13, 17, 18, 20, 21, 23, 36, 40, 42, 253, 725, 728, 781, 893, 895, 896, 898, 899, 900, 901, 904, 905, 906, 910, 911, 912, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1386, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1410, 1499, 1524, 1531, 1538, 1539, 1540, 1541, 1543, 1625, 1660, 1674, 1675, 1676, 1677, 1681, 1690, 1695, 1700, 1702, 1706, 1708, 1709, 1710, 1713, 1715, 1716, 1717, 1719, 1721, 1724, 1732, 1734, 1737], "modul": [0, 1, 3, 5, 7, 10, 12, 18, 19, 20, 23, 27, 29, 32, 35, 36, 40, 440, 581, 584, 644, 656, 728, 870, 893, 895, 896, 898, 899, 900, 901, 902, 904, 905, 906, 910, 911, 912, 966, 990, 1001, 1024, 1028, 1034, 1035, 1036, 1037, 1044, 1045, 1046, 1047, 1048, 1049, 1053, 1054, 1055, 1056, 1057, 1059, 1060, 1061, 1069, 1071, 1079, 1080, 1081, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1103, 1117, 1118, 1126, 1127, 1132, 1144, 1149, 1155, 1159, 1204, 1205, 1277, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1319, 1320, 1323, 1324, 1325, 1326, 1331, 1332, 1333, 1338, 1339, 1340, 1349, 1354, 1355, 1356, 1357, 1358, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1413, 1415, 1416, 1417, 1419, 1477, 1478, 1479, 1480, 1481, 1482, 1484, 1485, 1487, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1520, 1521, 1522, 1524, 1531, 1536, 1537, 1538, 1539, 1540, 1541, 1543, 1574, 1674, 1675, 1680, 1685, 1687, 1688, 1690, 1691, 1694, 1698, 1699, 1700, 1702, 1705, 1707, 1708, 1710, 1712, 1713, 1715, 1717, 1718, 1721, 1722, 1724, 1728, 1732, 1735, 1736, 1737, 1738], "def": [0, 1, 17, 18, 20, 21, 24, 26, 27, 28, 32, 33, 36, 37, 38, 40, 41, 42, 353, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 785, 870, 893, 895, 896, 898, 899, 900, 901, 905, 906, 909, 910, 911, 912, 1116, 1117, 1118, 1126, 1127, 1165, 1314, 1319, 1389, 1420, 1540, 1541, 1667, 1674, 1676, 1678, 1679, 1683, 1690, 1695, 1696, 1698, 1700, 1701, 1702, 1706, 1708, 1710, 1711, 1712, 1713, 1715, 1716, 1717, 1718, 1719, 1724, 1725, 1726, 1738], "self": [0, 1, 8, 17, 18, 20, 26, 27, 32, 37, 40, 42, 52, 94, 105, 108, 109, 110, 125, 127, 130, 133, 134, 135, 145, 146, 150, 151, 163, 171, 173, 187, 194, 209, 210, 213, 214, 222, 241, 245, 252, 266, 268, 270, 272, 274, 276, 278, 280, 281, 283, 284, 285, 286, 288, 296, 331, 347, 353, 355, 357, 388, 407, 424, 434, 436, 449, 450, 451, 452, 465, 467, 469, 472, 476, 488, 493, 494, 495, 496, 508, 510, 531, 532, 556, 559, 560, 565, 568, 569, 571, 574, 642, 865, 893, 894, 895, 898, 899, 900, 901, 905, 906, 910, 911, 912, 1024, 1028, 1061, 1115, 1116, 1117, 1118, 1122, 1126, 1127, 1143, 1145, 1155, 1161, 1163, 1243, 1265, 1314, 1386, 1387, 1389, 1395, 1397, 1410, 1417, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1472, 1560, 1676, 1677, 1678, 1679, 1683, 1687, 1689, 1690, 1694, 1696, 1697, 1698, 1701, 1702, 1706, 1711, 1713, 1716, 1717, 1719, 1724, 1729], "produc": [0, 6, 12, 17, 20, 25, 27, 29, 32, 41, 42, 43, 647, 667, 721, 812, 813, 814, 832, 848, 906, 910, 911, 914, 930, 931, 934, 941, 942, 953, 958, 994, 997, 998, 999, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1092, 1093, 1094, 1095, 1096, 1097, 1122, 1197, 1205, 1213, 1224, 1281, 1282, 1283, 1325, 1331, 1332, 1333, 1338, 1339, 1349, 1357, 1422, 1475, 1538, 1549, 1558, 1629, 1660, 1676, 1678, 1679, 1688, 1689, 1695, 1696, 1697, 1699, 1701, 1704, 1705, 1706, 1709, 1710, 1711, 1712, 1713, 1727, 1731], "after": [0, 1, 6, 8, 12, 17, 18, 20, 21, 23, 35, 37, 40, 41, 42, 215, 622, 623, 626, 688, 689, 721, 728, 779, 880, 895, 899, 927, 950, 990, 1020, 1053, 1101, 1116, 1119, 1159, 1161, 1163, 1178, 1213, 1314, 1316, 1319, 1389, 1391, 1395, 1397, 1451, 1452, 1458, 1459, 1479, 1536, 1538, 1625, 1646, 1669, 1674, 1678, 1679, 1687, 1688, 1694, 1695, 1696, 1699, 1700, 1701, 1702, 1703, 1705, 1706, 1708, 1709, 1713, 1715, 1716, 1718, 1719, 1724, 1725, 1726, 1728, 1730, 1732], "return": [0, 1, 2, 3, 5, 10, 11, 12, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 33, 35, 37, 40, 41, 42, 43, 74, 108, 110, 125, 127, 130, 133, 134, 135, 145, 146, 150, 151, 161, 163, 164, 171, 173, 174, 176, 187, 194, 197, 209, 215, 222, 244, 252, 266, 274, 278, 280, 281, 283, 284, 285, 286, 288, 292, 294, 296, 307, 331, 347, 388, 398, 399, 400, 401, 402, 411, 425, 426, 427, 428, 429, 431, 436, 440, 448, 449, 450, 465, 467, 476, 488, 493, 494, 506, 507, 508, 509, 510, 531, 532, 533, 534, 535, 541, 555, 556, 559, 561, 565, 568, 579, 587, 588, 590, 591, 592, 593, 594, 595, 603, 604, 605, 606, 607, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 621, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 641, 642, 643, 645, 646, 647, 654, 655, 657, 660, 662, 665, 666, 667, 668, 669, 670, 671, 673, 675, 676, 679, 680, 682, 683, 684, 686, 687, 688, 689, 690, 691, 696, 697, 698, 699, 700, 701, 702, 703, 704, 706, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 720, 722, 723, 724, 725, 726, 727, 728, 731, 733, 734, 735, 737, 738, 739, 740, 741, 743, 744, 745, 746, 747, 758, 759, 760, 761, 762, 763, 764, 765, 767, 768, 769, 770, 771, 774, 780, 782, 783, 784, 785, 786, 791, 794, 795, 796, 797, 798, 799, 800, 801, 817, 820, 821, 822, 823, 824, 825, 829, 832, 833, 834, 835, 836, 839, 840, 843, 844, 845, 846, 847, 851, 852, 853, 855, 856, 857, 861, 865, 869, 870, 871, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 891, 892, 893, 895, 896, 898, 899, 900, 901, 902, 903, 905, 906, 907, 909, 910, 911, 912, 913, 914, 916, 919, 920, 924, 925, 926, 930, 931, 932, 933, 936, 937, 938, 940, 941, 942, 943, 944, 947, 948, 949, 951, 952, 953, 954, 955, 956, 957, 958, 959, 961, 962, 964, 965, 966, 967, 968, 969, 970, 971, 974, 975, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 993, 994, 995, 996, 997, 998, 999, 1000, 1002, 1007, 1012, 1013, 1015, 1016, 1017, 1018, 1020, 1024, 1025, 1026, 1027, 1032, 1033, 1050, 1051, 1052, 1053, 1060, 1064, 1065, 1076, 1082, 1083, 1106, 1107, 1108, 1109, 1110, 1111, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1126, 1127, 1130, 1144, 1147, 1148, 1149, 1150, 1151, 1155, 1163, 1164, 1165, 1175, 1176, 1177, 1178, 1185, 1186, 1195, 1196, 1205, 1208, 1209, 1213, 1215, 1225, 1232, 1237, 1238, 1239, 1248, 1250, 1256, 1268, 1269, 1277, 1314, 1315, 1316, 1317, 1318, 1319, 1328, 1381, 1383, 1384, 1385, 1386, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1401, 1402, 1403, 1404, 1405, 1406, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1419, 1420, 1421, 1422, 1423, 1425, 1426, 1427, 1428, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1439, 1440, 1441, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1465, 1466, 1468, 1471, 1472, 1473, 1474, 1475, 1480, 1481, 1499, 1518, 1522, 1523, 1536, 1538, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1563, 1564, 1565, 1566, 1567, 1568, 1573, 1578, 1579, 1580, 1581, 1586, 1595, 1596, 1597, 1599, 1600, 1603, 1605, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1618, 1619, 1620, 1624, 1625, 1628, 1629, 1630, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1641, 1643, 1644, 1645, 1648, 1649, 1650, 1651, 1652, 1654, 1655, 1656, 1657, 1658, 1659, 1661, 1663, 1665, 1666, 1667, 1670, 1672, 1673, 1674, 1676, 1680, 1683, 1685, 1686, 1687, 1688, 1690, 1694, 1695, 1696, 1698, 1699, 1701, 1703, 1704, 1705, 1706, 1711, 1712, 1713, 1715, 1716, 1717, 1718, 1719, 1723, 1724, 1725, 1727, 1728, 1729, 1730, 1731, 1733, 1734, 1735, 1736, 1737, 1738, 1739], "disabl": [0, 2, 21, 24, 40, 42, 785, 870, 895, 897, 910, 911, 1116, 1122, 1155, 1163, 1319, 1320, 1417, 1420, 1495, 1496, 1586, 1587, 1590, 1678, 1695, 1698, 1699, 1701, 1704, 1710, 1713, 1717, 1723, 1734], "them": [0, 1, 3, 5, 6, 7, 8, 10, 12, 13, 17, 19, 20, 27, 32, 35, 37, 40, 41, 42, 105, 176, 209, 622, 628, 632, 658, 728, 765, 768, 781, 916, 925, 936, 950, 962, 966, 996, 1015, 1040, 1059, 1116, 1149, 1151, 1268, 1327, 1396, 1411, 1414, 1448, 1480, 1608, 1610, 1628, 1674, 1678, 1679, 1685, 1687, 1688, 1689, 1690, 1691, 1695, 1696, 1697, 1699, 1701, 1702, 1704, 1705, 1706, 1710, 1712, 1713, 1715, 1717, 1718, 1719, 1720, 1724, 1725, 1726, 1727, 1728, 1732, 1733, 1736], "differ": [0, 1, 3, 5, 7, 12, 17, 20, 23, 24, 26, 27, 28, 32, 33, 35, 36, 38, 40, 42, 151, 439, 445, 534, 568, 581, 584, 590, 591, 595, 609, 610, 637, 638, 644, 656, 657, 686, 763, 768, 770, 772, 781, 821, 822, 823, 827, 828, 834, 848, 869, 895, 905, 910, 924, 930, 931, 941, 942, 950, 953, 958, 962, 990, 1001, 1024, 1034, 1035, 1036, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1053, 1069, 1077, 1079, 1080, 1081, 1082, 1086, 1087, 1103, 1116, 1119, 1122, 1137, 1138, 1140, 1141, 1142, 1144, 1147, 1155, 1161, 1163, 1165, 1168, 1171, 1178, 1213, 1224, 1226, 1237, 1238, 1239, 1314, 1319, 1321, 1322, 1328, 1384, 1422, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1440, 1442, 1443, 1444, 1445, 1446, 1447, 1452, 1459, 1465, 1475, 1482, 1485, 1504, 1506, 1507, 1564, 1629, 1646, 1657, 1658, 1660, 1674, 1676, 1678, 1679, 1681, 1688, 1689, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1703, 1706, 1708, 1709, 1710, 1712, 1715, 1716, 1717, 1718, 1719, 1720, 1724, 1726, 1727, 1730, 1732, 1733, 1734], "caus": [0, 1, 2, 3, 5, 12, 17, 20, 23, 28, 34, 35, 36, 42, 506, 568, 607, 610, 622, 780, 834, 906, 910, 930, 931, 958, 1224, 1225, 1281, 1314, 1319, 1421, 1592, 1625, 1660, 1676, 1679, 1688, 1697, 1699, 1701, 1702, 1708, 1710, 1712, 1713, 1716, 1719, 1720, 1726], "mismatch": [0, 20, 42, 610, 896, 1678, 1695, 1700, 1701, 1702, 1713, 1734], "error": [0, 1, 5, 7, 12, 17, 18, 19, 20, 21, 22, 24, 33, 35, 36, 40, 41, 42, 145, 173, 176, 244, 268, 270, 276, 278, 283, 493, 495, 506, 565, 568, 595, 608, 610, 628, 630, 631, 632, 633, 634, 635, 636, 739, 751, 755, 778, 858, 895, 900, 909, 924, 925, 934, 936, 938, 941, 942, 943, 953, 956, 966, 985, 1007, 1032, 1033, 1066, 1077, 1083, 1107, 1116, 1145, 1147, 1211, 1222, 1244, 1265, 1266, 1319, 1321, 1322, 1381, 1422, 1471, 1501, 1578, 1584, 1620, 1625, 1660, 1668, 1674, 1676, 1678, 1679, 1688, 1689, 1690, 1691, 1695, 1696, 1699, 1701, 1703, 1704, 1710, 1713, 1716, 1722, 1724, 1728, 1733, 1734, 1736, 1737], "If": [0, 1, 2, 3, 4, 5, 6, 8, 10, 12, 13, 15, 17, 18, 20, 21, 23, 24, 25, 26, 28, 32, 33, 34, 35, 36, 38, 40, 41, 42, 52, 105, 109, 150, 161, 164, 209, 270, 274, 276, 398, 399, 400, 401, 402, 411, 424, 434, 448, 451, 469, 472, 488, 495, 531, 534, 555, 559, 568, 581, 584, 585, 586, 588, 590, 591, 592, 594, 595, 604, 605, 606, 607, 608, 609, 610, 619, 621, 622, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 644, 645, 647, 654, 656, 657, 658, 660, 664, 666, 667, 668, 669, 670, 671, 677, 679, 680, 681, 685, 686, 687, 689, 690, 691, 693, 696, 698, 700, 707, 717, 723, 728, 729, 748, 751, 761, 762, 763, 767, 768, 769, 770, 771, 780, 781, 782, 783, 784, 794, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 820, 824, 832, 834, 835, 836, 837, 848, 852, 853, 855, 856, 857, 858, 869, 872, 886, 892, 895, 898, 899, 900, 902, 904, 906, 907, 910, 911, 914, 915, 916, 920, 924, 925, 927, 930, 931, 933, 934, 936, 937, 938, 940, 941, 942, 944, 946, 947, 948, 949, 950, 951, 952, 953, 955, 957, 958, 960, 961, 962, 964, 965, 966, 967, 977, 981, 982, 983, 985, 987, 990, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1007, 1009, 1011, 1012, 1013, 1014, 1015, 1024, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1039, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1054, 1055, 1056, 1057, 1059, 1060, 1061, 1063, 1064, 1065, 1068, 1069, 1070, 1076, 1077, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1092, 1093, 1094, 1095, 1096, 1097, 1101, 1103, 1107, 1108, 1109, 1110, 1111, 1116, 1117, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1130, 1131, 1133, 1137, 1138, 1139, 1140, 1141, 1142, 1147, 1148, 1155, 1159, 1161, 1163, 1164, 1165, 1167, 1168, 1171, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1196, 1197, 1198, 1199, 1200, 1201, 1204, 1205, 1206, 1208, 1209, 1213, 1215, 1217, 1224, 1225, 1232, 1234, 1235, 1237, 1238, 1239, 1248, 1249, 1250, 1253, 1256, 1257, 1268, 1269, 1280, 1281, 1319, 1320, 1328, 1349, 1353, 1357, 1372, 1374, 1378, 1384, 1385, 1386, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1400, 1403, 1404, 1405, 1406, 1410, 1411, 1412, 1413, 1415, 1416, 1417, 1420, 1421, 1422, 1426, 1427, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1461, 1463, 1464, 1469, 1473, 1475, 1476, 1502, 1503, 1504, 1507, 1537, 1547, 1548, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1563, 1564, 1569, 1571, 1574, 1578, 1584, 1585, 1590, 1592, 1603, 1605, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1620, 1623, 1624, 1625, 1628, 1629, 1633, 1639, 1640, 1642, 1643, 1645, 1646, 1648, 1649, 1650, 1651, 1652, 1657, 1658, 1660, 1661, 1662, 1663, 1667, 1672, 1673, 1674, 1676, 1679, 1681, 1683, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1695, 1696, 1697, 1699, 1701, 1702, 1703, 1704, 1705, 1708, 1709, 1710, 1711, 1712, 1713, 1715, 1716, 1717, 1718, 1719, 1720, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1732, 1733, 1734, 1738], "so": [0, 1, 3, 6, 8, 12, 14, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 35, 36, 38, 40, 41, 42, 290, 411, 448, 623, 628, 630, 631, 636, 673, 708, 768, 770, 781, 798, 799, 800, 801, 802, 803, 804, 806, 807, 810, 811, 812, 813, 814, 815, 816, 817, 818, 832, 834, 882, 892, 895, 898, 899, 904, 906, 908, 950, 952, 962, 967, 972, 985, 1044, 1045, 1046, 1047, 1048, 1049, 1053, 1060, 1063, 1070, 1116, 1132, 1149, 1151, 1167, 1178, 1188, 1189, 1190, 1213, 1268, 1269, 1314, 1319, 1421, 1433, 1434, 1596, 1608, 1620, 1625, 1629, 1645, 1657, 1661, 1676, 1678, 1679, 1685, 1687, 1688, 1689, 1690, 1691, 1694, 1695, 1696, 1699, 1700, 1701, 1703, 1704, 1705, 1706, 1708, 1709, 1710, 1711, 1712, 1713, 1715, 1716, 1719, 1723, 1724, 1727, 1728, 1730, 1732, 1733, 1735], "cast": [0, 18, 33, 40, 290, 555, 556, 661, 761, 762, 895, 947, 951, 964, 996, 1012, 1015, 1116, 1232, 1268, 1269, 1422, 1473, 1605, 1608, 1614, 1628, 1676, 1695, 1709, 1713, 1728, 1729, 1730], "back": [0, 1, 12, 18, 20, 24, 35, 40, 42, 637, 673, 801, 896, 908, 960, 966, 1162, 1328, 1519, 1610, 1674, 1676, 1679, 1696, 1701, 1708, 1709, 1710, 1713, 1715, 1716, 1719, 1724, 1738], "from": [0, 1, 3, 5, 6, 7, 8, 12, 13, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 32, 33, 35, 37, 38, 40, 41, 43, 108, 109, 128, 151, 176, 177, 213, 241, 268, 270, 274, 276, 331, 357, 401, 407, 424, 426, 427, 434, 439, 440, 445, 465, 467, 469, 494, 496, 510, 531, 559, 560, 562, 568, 595, 609, 610, 621, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 637, 638, 645, 646, 654, 655, 660, 661, 673, 689, 691, 698, 699, 700, 717, 721, 739, 764, 781, 801, 803, 804, 809, 810, 811, 815, 816, 817, 818, 821, 822, 823, 832, 833, 834, 835, 852, 853, 857, 872, 892, 893, 895, 896, 898, 900, 901, 902, 905, 906, 918, 934, 938, 947, 950, 951, 964, 965, 966, 967, 981, 986, 987, 1007, 1016, 1024, 1028, 1034, 1035, 1036, 1037, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1053, 1054, 1055, 1056, 1057, 1059, 1060, 1061, 1063, 1068, 1069, 1070, 1071, 1077, 1079, 1080, 1081, 1082, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1103, 1116, 1117, 1118, 1122, 1126, 1127, 1131, 1133, 1134, 1155, 1160, 1161, 1165, 1167, 1168, 1178, 1198, 1199, 1200, 1201, 1205, 1206, 1210, 1213, 1215, 1224, 1237, 1238, 1239, 1251, 1280, 1296, 1297, 1298, 1299, 1300, 1301, 1304, 1312, 1313, 1314, 1319, 1325, 1328, 1331, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1349, 1353, 1357, 1365, 1366, 1367, 1374, 1381, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1400, 1402, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1419, 1423, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1439, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1463, 1465, 1468, 1476, 1477, 1478, 1482, 1485, 1506, 1522, 1537, 1538, 1539, 1540, 1541, 1543, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1564, 1565, 1568, 1570, 1571, 1578, 1590, 1609, 1611, 1612, 1613, 1614, 1615, 1616, 1625, 1626, 1630, 1633, 1636, 1639, 1648, 1650, 1652, 1657, 1658, 1660, 1661, 1667, 1670, 1676, 1677, 1678, 1679, 1681, 1683, 1685, 1686, 1687, 1688, 1690, 1691, 1692, 1694, 1696, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1708, 1709, 1710, 1711, 1715, 1717, 1719, 1720, 1724, 1725, 1726, 1727, 1728, 1730, 1732, 1733, 1734, 1735, 1736, 1737, 1738], "alreadi": [0, 1, 10, 17, 18, 20, 21, 35, 36, 40, 41, 42, 150, 161, 164, 416, 439, 475, 531, 555, 556, 609, 719, 895, 904, 966, 1116, 1317, 1319, 1410, 1522, 1537, 1655, 1657, 1674, 1676, 1686, 1689, 1690, 1695, 1696, 1701, 1703, 1708, 1713, 1715, 1716, 1719, 1725, 1726, 1729, 1731], "incur": [0, 5, 18, 40, 666, 1708, 1724], "addit": [0, 1, 3, 5, 6, 8, 12, 13, 17, 20, 21, 24, 29, 35, 36, 40, 41, 42, 290, 465, 559, 739, 892, 895, 899, 904, 909, 1024, 1035, 1036, 1037, 1047, 1048, 1049, 1060, 1067, 1070, 1077, 1080, 1081, 1095, 1096, 1097, 1101, 1102, 1103, 1104, 1106, 1112, 1113, 1114, 1116, 1122, 1124, 1149, 1151, 1155, 1159, 1163, 1165, 1184, 1191, 1192, 1193, 1230, 1319, 1342, 1344, 1345, 1346, 1347, 1351, 1374, 1436, 1499, 1538, 1657, 1658, 1665, 1676, 1678, 1679, 1687, 1689, 1690, 1696, 1698, 1699, 1701, 1705, 1708, 1709, 1712, 1713, 1718, 1719, 1720, 1722, 1724, 1725, 1726, 1727, 1731, 1734], "overhead": [0, 1, 3, 4, 7, 18, 20, 40, 906, 1319, 1374, 1698, 1699, 1700, 1705, 1706, 1717, 1718, 1725, 1727, 1733], "here": [0, 1, 6, 7, 13, 17, 18, 20, 21, 24, 34, 36, 40, 41, 42, 531, 684, 694, 781, 798, 800, 801, 806, 807, 808, 810, 811, 816, 818, 893, 906, 1034, 1035, 1036, 1047, 1048, 1049, 1079, 1080, 1081, 1124, 1155, 1213, 1215, 1386, 1444, 1458, 1599, 1674, 1676, 1678, 1679, 1681, 1689, 1690, 1695, 1696, 1699, 1701, 1702, 1703, 1704, 1705, 1706, 1712, 1713, 1715, 1716, 1717, 1719, 1727, 1731, 1732], "assum": [0, 10, 17, 19, 20, 24, 26, 28, 35, 36, 40, 42, 763, 799, 802, 804, 812, 813, 814, 817, 886, 892, 893, 896, 910, 930, 931, 933, 940, 949, 952, 955, 957, 967, 993, 1039, 1108, 1168, 1197, 1319, 1386, 1389, 1414, 1448, 1449, 1454, 1455, 1456, 1460, 1461, 1465, 1630, 1646, 1648, 1674, 1676, 1678, 1679, 1689, 1696, 1699, 1701, 1703, 1705, 1713, 1715, 1716, 1717, 1724, 1725, 1726, 1727], "a_float32": 0, "rand": [0, 1, 24, 42, 290, 588, 594, 630, 631, 632, 633, 634, 635, 686, 725, 726, 798, 800, 803, 804, 806, 807, 810, 811, 813, 814, 816, 818, 901, 906, 910, 911, 912, 968, 969, 971, 1082, 1159, 1160, 1161, 1162, 1163, 1185, 1204, 1205, 1319, 1389, 1468, 1546, 1547, 1548, 1552, 1676, 1677, 1678, 1679, 1681, 1689, 1690, 1713, 1714, 1717, 1719, 1724, 1725, 1728, 1731, 1732, 1735], "8": [0, 1, 12, 16, 17, 18, 19, 20, 24, 26, 268, 270, 272, 276, 387, 424, 465, 469, 510, 559, 568, 580, 581, 592, 593, 633, 647, 655, 666, 669, 670, 674, 725, 726, 759, 763, 778, 784, 797, 813, 814, 820, 821, 824, 831, 848, 857, 858, 892, 918, 947, 950, 951, 952, 960, 962, 965, 966, 983, 1016, 1021, 1022, 1023, 1025, 1026, 1027, 1040, 1051, 1086, 1112, 1113, 1119, 1121, 1123, 1130, 1131, 1134, 1137, 1138, 1139, 1140, 1141, 1142, 1155, 1159, 1160, 1161, 1162, 1163, 1167, 1189, 1192, 1195, 1251, 1256, 1261, 1262, 1338, 1339, 1354, 1356, 1358, 1366, 1367, 1422, 1423, 1433, 1434, 1435, 1437, 1443, 1444, 1447, 1452, 1459, 1464, 1468, 1472, 1502, 1503, 1504, 1507, 1559, 1569, 1570, 1571, 1578, 1590, 1600, 1603, 1609, 1611, 1612, 1617, 1625, 1629, 1633, 1635, 1640, 1641, 1642, 1644, 1646, 1655, 1660, 1661, 1668, 1676, 1680, 1699, 1701, 1711, 1713, 1714, 1716, 1717, 1718, 1719, 1722, 1724, 1727, 1728, 1730, 1731, 1733], "b_float32": 0, "c_float32": 0, "d_float32": 0, "mm": [0, 668, 669, 899, 950, 1126, 1127, 1475, 1629, 1660, 1677, 1678, 1689, 1695, 1698, 1701, 1709, 1714, 1727], "list": [0, 1, 5, 6, 8, 12, 13, 17, 18, 20, 21, 23, 24, 35, 40, 41, 42, 139, 195, 257, 400, 402, 529, 541, 570, 609, 616, 617, 618, 658, 659, 662, 666, 670, 675, 709, 715, 765, 778, 781, 782, 821, 835, 848, 858, 895, 899, 901, 906, 908, 910, 911, 996, 998, 1015, 1053, 1059, 1088, 1116, 1118, 1127, 1144, 1155, 1166, 1204, 1277, 1319, 1320, 1389, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1407, 1410, 1411, 1412, 1413, 1414, 1422, 1426, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1440, 1443, 1444, 1445, 1446, 1447, 1448, 1452, 1454, 1456, 1457, 1458, 1459, 1460, 1480, 1483, 1499, 1520, 1545, 1547, 1548, 1551, 1555, 1570, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1628, 1639, 1640, 1641, 1657, 1658, 1660, 1668, 1672, 1674, 1676, 1677, 1680, 1681, 1685, 1687, 1689, 1690, 1691, 1701, 1704, 1706, 1709, 1710, 1711, 1714, 1715, 1716, 1717, 1718, 1719, 1724, 1725, 1727, 1729, 1730, 1731, 1732, 1733, 1735, 1736, 1738], "No": [0, 8, 38, 41, 629, 1319, 1420, 1678, 1699, 1713, 1722, 1731, 1734], "manual": [0, 17, 19, 20, 33, 35, 36, 38, 40, 42, 608, 636, 857, 899, 1032, 1033, 1052, 1120, 1121, 1123, 1144, 1163, 1185, 1186, 1196, 1248, 1389, 1410, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1482, 1520, 1676, 1679, 1688, 1695, 1699, 1701, 1702, 1703, 1706, 1712, 1713, 1719, 1720, 1732], "e_float16": 0, "handl": [0, 5, 8, 10, 12, 17, 18, 19, 20, 21, 23, 26, 27, 28, 35, 36, 40, 41, 42, 440, 629, 681, 689, 701, 727, 740, 781, 827, 828, 895, 925, 1053, 1116, 1165, 1213, 1315, 1316, 1317, 1318, 1319, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1522, 1562, 1596, 1630, 1667, 1674, 1687, 1688, 1690, 1699, 1701, 1702, 1703, 1708, 1713, 1716, 1719, 1724, 1726, 1734], "f_float16": 0, "g_float32": 0, "epoch": [0, 17, 28, 38, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1687, 1695, 1715, 1732], "eval": [0, 42, 895, 899, 904, 910, 1034, 1035, 1036, 1079, 1080, 1081, 1089, 1090, 1091, 1098, 1099, 1100, 1116, 1122, 1155, 1163, 1385, 1499, 1539, 1540, 1679, 1685, 1706, 1713, 1719, 1737, 1738], "jit": [0, 10, 12, 19, 725, 726, 756, 845, 893, 894, 895, 909, 1428, 1588, 1589, 1675, 1678, 1681, 1685, 1690, 1698, 1705, 1711, 1713, 1714, 1719, 1724, 1732], "trace": [0, 1, 13, 17, 18, 20, 28, 639, 640, 641, 781, 898, 906, 907, 911, 967, 1677, 1678, 1679, 1681, 1696, 1699, 1711, 1716, 1718, 1732], "testmodel": 0, "__init__": [0, 1, 17, 18, 20, 24, 40, 42, 893, 896, 898, 901, 906, 910, 911, 912, 1116, 1117, 1118, 1126, 1127, 1314, 1676, 1678, 1679, 1687, 1696, 1701, 1702, 1706, 1711, 1713, 1716, 1719, 1732], "input_s": [0, 1068, 1069, 1086, 1087, 1131, 1132, 1133, 1327, 1353, 1354, 1358], "num_class": [0, 1250, 1677], "super": [0, 8, 17, 18, 20, 42, 893, 898, 901, 906, 910, 911, 912, 1116, 1117, 1118, 1126, 1127, 1128, 1129, 1314, 1458, 1676, 1678, 1679, 1680, 1696, 1701, 1706, 1711, 1713, 1716, 1719], "fc1": [0, 18, 1314, 1717], "x": [0, 1, 3, 10, 12, 17, 18, 20, 24, 26, 32, 40, 41, 42, 128, 209, 213, 241, 244, 266, 268, 270, 272, 276, 307, 331, 387, 401, 436, 445, 451, 508, 510, 559, 560, 568, 587, 608, 614, 616, 617, 618, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 658, 659, 660, 663, 664, 679, 682, 685, 686, 725, 726, 763, 770, 774, 775, 781, 785, 795, 796, 797, 798, 800, 801, 806, 807, 809, 811, 815, 816, 818, 821, 822, 823, 831, 848, 865, 869, 870, 882, 900, 901, 905, 906, 909, 910, 911, 912, 916, 926, 939, 940, 944, 947, 951, 955, 957, 960, 961, 962, 963, 964, 967, 972, 973, 974, 982, 983, 986, 989, 990, 998, 1011, 1012, 1016, 1022, 1023, 1032, 1033, 1034, 1035, 1036, 1038, 1050, 1052, 1058, 1064, 1065, 1066, 1068, 1069, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1079, 1080, 1081, 1083, 1084, 1085, 1086, 1087, 1088, 1102, 1105, 1106, 1107, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1123, 1124, 1125, 1126, 1127, 1131, 1133, 1134, 1135, 1136, 1143, 1145, 1146, 1147, 1148, 1150, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1164, 1165, 1168, 1187, 1211, 1213, 1217, 1218, 1224, 1228, 1232, 1243, 1248, 1253, 1257, 1259, 1263, 1264, 1265, 1269, 1270, 1272, 1273, 1274, 1281, 1314, 1351, 1353, 1363, 1372, 1373, 1377, 1378, 1385, 1387, 1389, 1410, 1411, 1412, 1413, 1414, 1420, 1421, 1422, 1431, 1452, 1465, 1466, 1484, 1487, 1502, 1503, 1544, 1546, 1560, 1563, 1564, 1566, 1567, 1569, 1570, 1574, 1578, 1587, 1603, 1606, 1620, 1625, 1631, 1632, 1634, 1640, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1658, 1659, 1661, 1665, 1666, 1667, 1670, 1674, 1676, 1677, 1678, 1679, 1680, 1688, 1689, 1690, 1694, 1696, 1697, 1698, 1699, 1701, 1702, 1703, 1704, 1706, 1707, 1712, 1713, 1716, 1719, 1724, 1727, 1728, 1730, 1732, 1733, 1735, 1736, 1737], "2": [0, 1, 3, 10, 12, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 33, 35, 40, 41, 42, 128, 146, 163, 180, 188, 209, 215, 268, 270, 272, 276, 290, 331, 387, 398, 399, 400, 401, 402, 434, 440, 445, 448, 451, 465, 467, 469, 494, 508, 510, 531, 532, 534, 535, 541, 559, 568, 576, 578, 579, 580, 581, 584, 585, 586, 587, 588, 590, 592, 593, 594, 595, 604, 605, 606, 607, 608, 609, 610, 614, 616, 617, 618, 628, 630, 631, 632, 633, 634, 635, 645, 647, 648, 649, 650, 651, 652, 653, 654, 655, 657, 658, 659, 660, 662, 663, 664, 666, 667, 668, 669, 670, 674, 675, 677, 679, 680, 681, 682, 685, 686, 687, 755, 759, 762, 763, 767, 768, 769, 770, 771, 772, 774, 775, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 791, 794, 795, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 820, 821, 822, 823, 824, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 837, 838, 839, 848, 851, 852, 853, 854, 855, 856, 857, 858, 860, 861, 869, 870, 872, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 898, 899, 904, 906, 908, 910, 914, 915, 916, 918, 919, 920, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 937, 938, 939, 940, 941, 942, 944, 946, 947, 948, 949, 950, 951, 952, 955, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 971, 972, 973, 974, 981, 983, 984, 985, 986, 987, 989, 990, 993, 994, 995, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1009, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1020, 1023, 1028, 1029, 1030, 1031, 1032, 1033, 1038, 1039, 1040, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1049, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1066, 1067, 1068, 1070, 1072, 1073, 1074, 1075, 1077, 1084, 1085, 1086, 1087, 1088, 1102, 1104, 1105, 1106, 1107, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1118, 1119, 1121, 1124, 1125, 1127, 1128, 1129, 1130, 1131, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1143, 1145, 1146, 1147, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1164, 1166, 1167, 1168, 1169, 1170, 1171, 1178, 1180, 1185, 1186, 1197, 1204, 1205, 1211, 1213, 1215, 1217, 1224, 1237, 1238, 1239, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1278, 1314, 1319, 1327, 1331, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1348, 1351, 1353, 1355, 1381, 1384, 1385, 1389, 1401, 1402, 1403, 1404, 1406, 1407, 1410, 1412, 1413, 1415, 1416, 1420, 1421, 1422, 1423, 1425, 1426, 1427, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1455, 1459, 1460, 1464, 1465, 1466, 1468, 1469, 1472, 1473, 1475, 1476, 1502, 1544, 1545, 1546, 1547, 1548, 1549, 1551, 1553, 1555, 1557, 1558, 1559, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1574, 1578, 1580, 1581, 1582, 1583, 1584, 1587, 1590, 1595, 1596, 1597, 1600, 1603, 1604, 1606, 1607, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1625, 1626, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1637, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1648, 1649, 1650, 1651, 1652, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1672, 1673, 1677, 1678, 1679, 1680, 1685, 1688, 1689, 1690, 1691, 1694, 1695, 1696, 1697, 1698, 1700, 1701, 1703, 1704, 1706, 1707, 1709, 1710, 1711, 1712, 1713, 1715, 1716, 1717, 1718, 1719, 1721, 1722, 1724, 1725, 1726, 1727, 1728, 1730, 1731, 1732, 1733, 1734, 1735, 1737], "we": [0, 1, 2, 5, 6, 7, 8, 10, 12, 13, 17, 18, 19, 20, 23, 24, 25, 26, 35, 36, 38, 40, 41, 42, 448, 595, 622, 623, 626, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 645, 654, 687, 691, 739, 799, 801, 802, 803, 804, 811, 816, 817, 818, 832, 848, 852, 853, 869, 893, 895, 898, 899, 906, 908, 910, 950, 953, 958, 966, 967, 987, 1007, 1024, 1032, 1033, 1082, 1116, 1168, 1213, 1215, 1224, 1281, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1317, 1319, 1323, 1324, 1325, 1326, 1338, 1339, 1349, 1354, 1355, 1356, 1357, 1358, 1372, 1378, 1384, 1386, 1395, 1397, 1400, 1404, 1405, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1449, 1455, 1459, 1476, 1477, 1478, 1480, 1481, 1500, 1520, 1536, 1538, 1667, 1674, 1675, 1676, 1678, 1679, 1681, 1683, 1685, 1688, 1689, 1690, 1691, 1696, 1699, 1701, 1702, 1703, 1704, 1706, 1708, 1709, 1712, 1713, 1715, 1716, 1717, 1719, 1720, 1724, 1725, 1726, 1727, 1730, 1732, 1736, 1737], "suggest": [0, 8, 18, 1050, 1674, 1681, 1695, 1696, 1702], "issu": [0, 2, 3, 5, 8, 9, 10, 12, 16, 17, 20, 25, 40, 42, 630, 636, 832, 940, 985, 998, 1082, 1086, 1131, 1168, 1224, 1225, 1674, 1679, 1681, 1688, 1689, 1690, 1695, 1696, 1699, 1701, 1708, 1710, 1712, 1713, 1716, 1720, 1724, 1728], "http": [0, 3, 4, 6, 12, 13, 18, 20, 24, 35, 36, 40, 105, 622, 781, 967, 998, 1039, 1086, 1134, 1135, 1159, 1162, 1165, 1323, 1324, 1325, 1326, 1338, 1339, 1349, 1354, 1355, 1356, 1357, 1358, 1419, 1465, 1549, 1660, 1674, 1680, 1686, 1696, 1697, 1703, 1704, 1706, 1710, 1712, 1713, 1716, 1718, 1732, 1739], "github": [0, 6, 8, 12, 20, 31, 40, 105, 622, 636, 998, 1159, 1452, 1674, 1681, 1701, 1703, 1710, 1713, 1718, 1728], "com": [0, 6, 12, 20, 34, 36, 40, 105, 622, 998, 1159, 1660, 1674, 1686, 1703, 1704, 1710, 1712, 1713, 1718], "pytorch": [0, 1, 2, 3, 4, 5, 10, 11, 12, 17, 18, 19, 22, 23, 24, 25, 26, 28, 35, 36, 40, 42, 105, 535, 593, 622, 661, 666, 667, 676, 687, 691, 708, 719, 724, 780, 781, 826, 832, 841, 881, 882, 905, 925, 936, 938, 939, 940, 943, 956, 965, 981, 983, 985, 986, 993, 998, 1032, 1039, 1082, 1159, 1319, 1323, 1324, 1325, 1326, 1338, 1339, 1349, 1354, 1355, 1356, 1357, 1358, 1410, 1416, 1422, 1475, 1495, 1496, 1497, 1498, 1538, 1574, 1582, 1592, 1625, 1629, 1633, 1648, 1660, 1667, 1674, 1678, 1679, 1683, 1686, 1687, 1690, 1691, 1692, 1697, 1698, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1712, 1715, 1716, 1718, 1719, 1720, 1721, 1724, 1725, 1727, 1728, 1730, 1731, 1732, 1738, 1739], "75956": 0, "_c": [0, 17, 18, 20, 41, 630, 636, 894, 906, 1429, 1677, 1679, 1687, 1705, 1709, 1712, 1713], "_jit_set_autocast_mod": 0, "fals": [0, 1, 3, 5, 12, 17, 18, 20, 21, 23, 24, 26, 40, 42, 67, 68, 69, 70, 71, 73, 89, 90, 91, 105, 136, 137, 138, 151, 164, 196, 215, 256, 273, 274, 276, 283, 287, 290, 291, 293, 297, 298, 299, 306, 308, 346, 351, 362, 364, 365, 366, 369, 375, 383, 384, 385, 386, 398, 399, 400, 401, 402, 406, 411, 413, 423, 424, 432, 447, 448, 456, 469, 492, 505, 506, 515, 520, 531, 546, 555, 561, 562, 566, 568, 588, 589, 590, 591, 592, 594, 595, 604, 605, 606, 610, 622, 623, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 641, 645, 648, 651, 653, 654, 660, 661, 667, 668, 669, 675, 679, 689, 723, 728, 740, 780, 782, 783, 784, 786, 787, 794, 798, 799, 800, 801, 806, 807, 812, 813, 814, 816, 817, 818, 834, 835, 836, 837, 839, 851, 852, 853, 856, 857, 870, 880, 884, 885, 886, 887, 888, 889, 890, 891, 892, 895, 900, 901, 910, 911, 912, 914, 916, 919, 924, 925, 936, 937, 938, 939, 941, 942, 943, 944, 947, 949, 951, 952, 955, 956, 957, 958, 959, 964, 965, 976, 977, 978, 979, 981, 982, 984, 985, 987, 989, 993, 994, 996, 997, 999, 1002, 1007, 1012, 1013, 1014, 1015, 1017, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1050, 1052, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1064, 1065, 1068, 1069, 1070, 1071, 1073, 1074, 1075, 1076, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1101, 1102, 1103, 1107, 1108, 1109, 1110, 1111, 1115, 1116, 1119, 1120, 1121, 1122, 1123, 1125, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1143, 1145, 1147, 1148, 1155, 1158, 1159, 1161, 1163, 1164, 1165, 1168, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1185, 1186, 1187, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1204, 1205, 1206, 1210, 1213, 1215, 1217, 1218, 1219, 1224, 1225, 1228, 1234, 1235, 1237, 1238, 1239, 1243, 1248, 1252, 1256, 1258, 1259, 1261, 1262, 1263, 1265, 1275, 1278, 1279, 1281, 1296, 1297, 1298, 1299, 1300, 1301, 1319, 1321, 1327, 1328, 1338, 1339, 1344, 1345, 1346, 1348, 1351, 1353, 1361, 1362, 1369, 1371, 1372, 1373, 1375, 1376, 1378, 1381, 1384, 1386, 1389, 1390, 1402, 1411, 1412, 1413, 1414, 1420, 1421, 1422, 1426, 1427, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1463, 1473, 1475, 1476, 1482, 1485, 1493, 1494, 1499, 1501, 1502, 1503, 1504, 1506, 1507, 1520, 1521, 1528, 1531, 1536, 1537, 1542, 1547, 1548, 1549, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1566, 1567, 1574, 1578, 1585, 1586, 1587, 1590, 1592, 1596, 1603, 1611, 1612, 1613, 1614, 1615, 1616, 1623, 1624, 1625, 1628, 1629, 1633, 1639, 1643, 1648, 1657, 1660, 1661, 1662, 1663, 1670, 1672, 1673, 1674, 1676, 1677, 1678, 1679, 1685, 1686, 1688, 1690, 1695, 1696, 1699, 1701, 1702, 1706, 1709, 1710, 1713, 1716, 1717, 1718, 1720, 1721, 1723, 1724, 1727, 1728, 1729, 1731, 1732, 1734, 1735, 1737, 1738], "randn": [0, 1, 10, 20, 24, 42, 244, 266, 436, 494, 531, 534, 536, 537, 538, 539, 540, 541, 568, 578, 579, 580, 581, 582, 583, 584, 585, 590, 591, 594, 604, 605, 606, 608, 611, 612, 613, 614, 615, 616, 617, 618, 644, 656, 663, 665, 666, 667, 668, 669, 671, 681, 682, 683, 684, 685, 687, 759, 760, 761, 762, 767, 768, 769, 770, 774, 781, 795, 796, 825, 865, 869, 872, 906, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 941, 942, 944, 948, 949, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 963, 970, 974, 975, 982, 985, 986, 987, 989, 990, 994, 996, 997, 999, 1001, 1002, 1003, 1004, 1005, 1006, 1009, 1018, 1021, 1022, 1023, 1025, 1026, 1027, 1028, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1048, 1049, 1051, 1052, 1054, 1055, 1056, 1057, 1058, 1059, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1114, 1115, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1133, 1134, 1135, 1136, 1142, 1143, 1145, 1146, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1164, 1166, 1167, 1171, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1195, 1196, 1197, 1208, 1209, 1215, 1248, 1254, 1255, 1304, 1312, 1313, 1327, 1331, 1332, 1333, 1334, 1335, 1336, 1349, 1351, 1353, 1354, 1355, 1356, 1357, 1358, 1365, 1366, 1367, 1425, 1466, 1471, 1472, 1473, 1475, 1476, 1540, 1556, 1560, 1561, 1573, 1597, 1599, 1603, 1606, 1607, 1610, 1618, 1619, 1628, 1629, 1633, 1634, 1637, 1638, 1641, 1645, 1648, 1649, 1651, 1654, 1656, 1660, 1665, 1666, 1667, 1670, 1677, 1678, 1679, 1681, 1689, 1690, 1691, 1696, 1697, 1698, 1699, 1700, 1701, 1704, 1706, 1710, 1711, 1713, 1714, 1715, 1716, 1719, 1724, 1727, 1728, 1730, 1732, 1735, 1737], "1": [0, 1, 3, 10, 12, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 32, 33, 35, 38, 40, 41, 42, 43, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 91, 106, 107, 128, 146, 160, 163, 180, 182, 183, 184, 197, 209, 213, 218, 241, 266, 267, 268, 270, 272, 276, 307, 331, 387, 398, 400, 401, 407, 424, 434, 436, 440, 445, 448, 451, 465, 467, 469, 488, 489, 492, 494, 504, 506, 508, 510, 511, 512, 513, 514, 532, 534, 535, 536, 537, 559, 560, 568, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 623, 626, 628, 629, 630, 631, 632, 633, 634, 635, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 657, 658, 659, 660, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 674, 675, 676, 677, 679, 680, 681, 682, 683, 684, 685, 686, 687, 691, 725, 726, 741, 751, 755, 758, 759, 760, 761, 762, 763, 764, 767, 768, 769, 770, 771, 772, 774, 775, 777, 778, 779, 780, 781, 784, 785, 786, 787, 791, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 837, 838, 839, 848, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 865, 866, 869, 870, 872, 880, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 895, 899, 905, 906, 910, 911, 914, 915, 916, 918, 919, 920, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 937, 938, 940, 941, 942, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 970, 972, 974, 975, 976, 977, 978, 979, 981, 982, 983, 984, 985, 986, 989, 990, 994, 995, 996, 997, 998, 999, 1000, 1002, 1003, 1004, 1005, 1006, 1007, 1009, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1058, 1059, 1060, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1073, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1154, 1155, 1158, 1159, 1161, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1178, 1180, 1183, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1195, 1196, 1197, 1202, 1203, 1204, 1205, 1207, 1208, 1209, 1211, 1212, 1213, 1215, 1217, 1219, 1220, 1221, 1222, 1223, 1231, 1233, 1237, 1238, 1239, 1245, 1248, 1249, 1250, 1251, 1253, 1254, 1255, 1257, 1261, 1262, 1263, 1264, 1266, 1268, 1269, 1270, 1272, 1277, 1278, 1279, 1280, 1281, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1307, 1308, 1309, 1310, 1311, 1314, 1319, 1323, 1324, 1327, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1339, 1344, 1345, 1346, 1349, 1350, 1351, 1353, 1363, 1365, 1366, 1367, 1368, 1371, 1375, 1376, 1378, 1384, 1385, 1389, 1394, 1395, 1397, 1398, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1410, 1411, 1412, 1413, 1415, 1416, 1417, 1419, 1420, 1421, 1422, 1423, 1425, 1426, 1427, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1464, 1465, 1466, 1468, 1469, 1472, 1473, 1475, 1476, 1501, 1502, 1503, 1504, 1507, 1509, 1540, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1573, 1574, 1578, 1581, 1582, 1583, 1584, 1586, 1587, 1590, 1593, 1595, 1596, 1599, 1600, 1603, 1604, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1669, 1670, 1677, 1678, 1679, 1680, 1683, 1685, 1688, 1689, 1690, 1691, 1694, 1695, 1696, 1697, 1698, 1699, 1701, 1702, 1703, 1704, 1706, 1709, 1710, 1711, 1712, 1713, 1715, 1716, 1717, 1718, 1719, 1721, 1724, 1725, 1726, 1727, 1728, 1730, 1731, 1732, 1733, 1734, 1735, 1737, 1738, 1739], "freez": [0, 895, 904, 1059, 1060, 1116, 1696], "_": [0, 1, 3, 17, 18, 20, 21, 23, 28, 42, 576, 578, 579, 593, 595, 611, 612, 613, 614, 615, 623, 629, 646, 665, 680, 681, 683, 684, 686, 780, 825, 830, 861, 915, 923, 974, 982, 983, 1034, 1035, 1036, 1079, 1080, 1081, 1155, 1319, 1385, 1416, 1444, 1446, 1465, 1555, 1558, 1561, 1573, 1593, 1595, 1597, 1599, 1618, 1629, 1633, 1637, 1638, 1696, 1699, 1702, 1706, 1712, 1716, 1718, 1728], "3": [0, 1, 3, 4, 8, 10, 15, 17, 18, 19, 20, 23, 24, 25, 26, 28, 33, 35, 40, 41, 42, 146, 163, 209, 215, 244, 268, 270, 272, 276, 387, 398, 399, 400, 401, 402, 424, 440, 445, 448, 451, 465, 467, 469, 488, 494, 508, 510, 532, 534, 535, 559, 568, 576, 580, 581, 582, 583, 584, 585, 586, 587, 588, 592, 593, 594, 595, 605, 606, 608, 609, 610, 618, 630, 631, 632, 633, 634, 635, 644, 646, 647, 648, 649, 650, 651, 652, 653, 655, 656, 657, 658, 659, 660, 662, 663, 664, 666, 667, 668, 669, 670, 674, 675, 677, 679, 680, 685, 686, 687, 725, 726, 728, 762, 763, 764, 767, 768, 769, 770, 771, 772, 774, 775, 777, 778, 779, 780, 781, 782, 783, 784, 786, 794, 797, 802, 805, 809, 815, 820, 821, 822, 823, 824, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 837, 838, 839, 848, 851, 854, 855, 856, 857, 858, 860, 861, 869, 870, 872, 880, 882, 884, 886, 895, 899, 901, 904, 906, 910, 911, 915, 916, 917, 918, 919, 920, 924, 926, 927, 928, 930, 931, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 944, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 972, 975, 977, 981, 982, 983, 984, 985, 986, 987, 989, 990, 994, 995, 996, 997, 998, 999, 1000, 1001, 1003, 1004, 1005, 1006, 1007, 1009, 1011, 1012, 1013, 1015, 1016, 1017, 1029, 1030, 1031, 1032, 1033, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1048, 1049, 1052, 1059, 1060, 1063, 1064, 1065, 1066, 1068, 1069, 1071, 1073, 1074, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1117, 1119, 1121, 1123, 1128, 1129, 1131, 1133, 1134, 1137, 1138, 1139, 1140, 1141, 1142, 1149, 1150, 1151, 1155, 1163, 1167, 1168, 1169, 1170, 1171, 1178, 1180, 1185, 1186, 1189, 1190, 1192, 1193, 1196, 1204, 1205, 1208, 1209, 1211, 1213, 1217, 1218, 1224, 1232, 1248, 1250, 1251, 1254, 1255, 1261, 1262, 1268, 1269, 1281, 1319, 1327, 1331, 1332, 1333, 1334, 1335, 1336, 1339, 1341, 1350, 1353, 1354, 1355, 1356, 1358, 1365, 1366, 1367, 1378, 1385, 1399, 1401, 1403, 1404, 1405, 1406, 1410, 1412, 1413, 1414, 1416, 1421, 1422, 1423, 1425, 1426, 1427, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1455, 1458, 1460, 1464, 1466, 1468, 1472, 1473, 1475, 1476, 1485, 1506, 1540, 1546, 1547, 1548, 1549, 1550, 1551, 1553, 1555, 1557, 1558, 1559, 1562, 1563, 1564, 1565, 1566, 1567, 1569, 1570, 1571, 1574, 1578, 1582, 1583, 1590, 1593, 1595, 1596, 1603, 1606, 1607, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1628, 1629, 1631, 1632, 1633, 1634, 1635, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1648, 1649, 1650, 1651, 1652, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1664, 1667, 1668, 1669, 1670, 1672, 1673, 1676, 1677, 1678, 1679, 1680, 1688, 1689, 1690, 1691, 1694, 1695, 1696, 1697, 1699, 1700, 1701, 1703, 1706, 1707, 1711, 1712, 1713, 1715, 1716, 1719, 1724, 1725, 1726, 1727, 1728, 1730, 1731, 1732, 1733, 1734, 1735], "bug": [0, 12, 20, 42, 985, 1695, 1708], "thi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 33, 34, 35, 36, 37, 38, 40, 41, 42, 74, 105, 109, 150, 151, 161, 164, 176, 177, 178, 210, 215, 244, 245, 268, 276, 278, 290, 292, 295, 307, 388, 398, 399, 400, 401, 402, 411, 439, 440, 445, 447, 448, 449, 450, 451, 452, 455, 456, 465, 467, 469, 475, 506, 516, 541, 555, 556, 565, 568, 569, 579, 581, 584, 588, 589, 594, 604, 605, 606, 607, 608, 615, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 641, 644, 647, 649, 652, 656, 657, 664, 666, 667, 670, 671, 673, 679, 680, 682, 687, 688, 689, 690, 691, 692, 693, 705, 707, 709, 710, 711, 713, 714, 717, 718, 719, 720, 725, 726, 727, 728, 729, 730, 731, 733, 735, 738, 739, 740, 745, 746, 748, 749, 750, 754, 755, 756, 761, 762, 763, 768, 770, 771, 775, 778, 779, 780, 781, 785, 797, 798, 800, 801, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 820, 821, 822, 823, 824, 827, 828, 829, 832, 834, 838, 840, 841, 842, 848, 852, 858, 860, 870, 882, 892, 893, 895, 896, 898, 900, 901, 902, 904, 905, 906, 909, 910, 911, 912, 914, 915, 916, 917, 918, 924, 925, 926, 927, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 946, 947, 949, 950, 951, 952, 953, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 966, 967, 970, 972, 975, 985, 986, 990, 994, 996, 997, 998, 999, 1001, 1002, 1003, 1009, 1012, 1013, 1014, 1015, 1024, 1028, 1032, 1033, 1034, 1035, 1036, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1059, 1060, 1061, 1063, 1064, 1065, 1068, 1069, 1071, 1076, 1077, 1079, 1080, 1081, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1101, 1103, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1119, 1122, 1123, 1126, 1128, 1131, 1132, 1144, 1147, 1149, 1152, 1155, 1161, 1162, 1163, 1164, 1167, 1168, 1169, 1170, 1178, 1188, 1189, 1190, 1191, 1192, 1193, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1204, 1205, 1206, 1208, 1209, 1213, 1215, 1217, 1224, 1230, 1232, 1237, 1238, 1239, 1249, 1251, 1253, 1268, 1269, 1277, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1328, 1329, 1330, 1337, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1350, 1352, 1368, 1369, 1370, 1371, 1372, 1378, 1379, 1380, 1384, 1385, 1386, 1387, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1400, 1403, 1404, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1419, 1420, 1423, 1427, 1428, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1449, 1450, 1451, 1452, 1455, 1456, 1458, 1459, 1461, 1464, 1465, 1469, 1473, 1475, 1477, 1478, 1479, 1480, 1481, 1484, 1485, 1487, 1495, 1496, 1497, 1498, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1538, 1540, 1549, 1553, 1558, 1562, 1564, 1571, 1578, 1580, 1581, 1583, 1584, 1585, 1587, 1590, 1592, 1593, 1600, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1620, 1621, 1625, 1628, 1629, 1631, 1632, 1633, 1634, 1636, 1640, 1642, 1646, 1648, 1656, 1657, 1658, 1659, 1660, 1664, 1665, 1666, 1668, 1669, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1683, 1685, 1687, 1688, 1689, 1690, 1691, 1694, 1695, 1696, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739], "what": [0, 1, 3, 5, 6, 7, 8, 20, 24, 28, 32, 33, 40, 42, 910, 911, 985, 1044, 1045, 1046, 1047, 1048, 1049, 1063, 1110, 1111, 1144, 1167, 1237, 1238, 1239, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1443, 1444, 1445, 1446, 1447, 1476, 1667, 1674, 1676, 1678, 1679, 1689, 1701, 1703, 1706, 1715, 1718, 1719, 1724, 1725], "observ": [0, 18, 26, 35, 682, 686, 908, 998, 1032, 1033, 1034, 1035, 1036, 1050, 1052, 1076, 1079, 1080, 1081, 1082, 1083, 1107, 1108, 1119, 1120, 1121, 1123, 1130, 1147, 1148, 1155, 1164, 1185, 1186, 1196, 1225, 1248, 1256, 1349, 1478, 1479, 1480, 1482, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1496, 1498, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1538, 1540, 1543, 1695, 1696, 1705, 1720, 1721, 1737], "pleas": [0, 1, 4, 6, 7, 8, 10, 13, 18, 19, 20, 24, 27, 30, 31, 35, 36, 40, 42, 209, 210, 450, 569, 623, 624, 625, 630, 632, 633, 636, 658, 763, 895, 958, 1039, 1047, 1082, 1116, 1213, 1225, 1251, 1280, 1319, 1323, 1324, 1325, 1326, 1327, 1328, 1334, 1335, 1336, 1338, 1339, 1349, 1354, 1355, 1356, 1357, 1358, 1416, 1417, 1454, 1540, 1667, 1681, 1689, 1690, 1691, 1692, 1695, 1696, 1701, 1704, 1709, 1710, 1712, 1713, 1715, 1716, 1719, 1724, 1725, 1727, 1728, 1731, 1732], "file": [0, 1, 3, 6, 8, 10, 12, 17, 19, 26, 28, 33, 35, 42, 630, 636, 639, 640, 721, 870, 902, 905, 966, 1574, 1674, 1676, 1679, 1680, 1681, 1686, 1689, 1690, 1691, 1696, 1701, 1705, 1710, 1711, 1712, 1713, 1714, 1718, 1719, 1725, 1729, 1732], "subregion": 0, "nest": [0, 1, 5, 12, 40, 42, 534, 541, 623, 632, 743, 744, 895, 898, 910, 1116, 1162, 1667, 1675, 1713, 1724], "local": [0, 20, 23, 26, 33, 35, 36, 37, 38, 40, 42, 725, 785, 870, 895, 967, 1055, 1056, 1057, 1061, 1063, 1104, 1116, 1167, 1207, 1231, 1280, 1319, 1320, 1420, 1587, 1674, 1678, 1688, 1695, 1700, 1702, 1713, 1716, 1717, 1721, 1724, 1725, 1726, 1732], "want": [0, 1, 6, 7, 8, 12, 17, 20, 24, 32, 40, 41, 42, 401, 448, 451, 721, 907, 910, 911, 998, 1064, 1065, 1168, 1208, 1209, 1224, 1281, 1319, 1320, 1374, 1417, 1420, 1480, 1481, 1500, 1520, 1574, 1674, 1683, 1695, 1696, 1698, 1699, 1701, 1703, 1706, 1713, 1715, 1716, 1719, 1727, 1732, 1733, 1736], "forc": [0, 1, 12, 411, 610, 721, 898, 909, 913, 1592, 1674, 1676, 1679, 1695, 1699, 1732], "particular": [0, 3, 6, 17, 26, 32, 35, 36, 40, 42, 510, 755, 895, 1053, 1116, 1667, 1676, 1678, 1696, 1699, 1701, 1702, 1705, 1706, 1709, 1713, 1715, 1727, 1729, 1738], "give": [0, 3, 4, 6, 8, 17, 18, 23, 34, 42, 637, 638, 686, 799, 801, 802, 804, 808, 817, 908, 924, 931, 1044, 1045, 1046, 1121, 1167, 1168, 1384, 1421, 1625, 1660, 1667, 1674, 1676, 1688, 1690, 1694, 1696, 1699, 1701, 1703, 1704, 1706, 1710, 1713, 1715, 1717, 1727, 1738], "explicit": [0, 7, 20, 42, 717, 848, 882, 1225, 1641, 1674, 1679, 1680, 1689, 1695, 1699, 1701, 1716, 1731], "control": [0, 1, 2, 12, 17, 18, 20, 21, 24, 26, 31, 34, 35, 606, 610, 623, 645, 654, 767, 768, 769, 770, 771, 852, 853, 906, 907, 908, 910, 925, 931, 933, 936, 938, 941, 943, 947, 953, 956, 958, 964, 985, 1024, 1044, 1045, 1046, 1047, 1048, 1049, 1063, 1102, 1110, 1111, 1167, 1319, 1348, 1463, 1484, 1537, 1585, 1586, 1603, 1609, 1625, 1629, 1633, 1643, 1649, 1650, 1651, 1652, 1676, 1696, 1698, 1699, 1700, 1706, 1708, 1709, 1711, 1713, 1719, 1726], "execut": [0, 1, 2, 3, 4, 5, 6, 12, 13, 17, 20, 23, 26, 27, 29, 36, 41, 42, 691, 700, 758, 896, 898, 910, 911, 966, 1053, 1316, 1319, 1588, 1676, 1678, 1680, 1685, 1695, 1696, 1697, 1698, 1702, 1705, 1706, 1708, 1710, 1712, 1713, 1718, 1719, 1724, 1725], "surround": [0, 42, 1479, 1678, 1695, 1699], "ensur": [0, 1, 4, 6, 8, 17, 19, 20, 21, 23, 26, 35, 36, 38, 40, 41, 42, 434, 439, 626, 628, 895, 1028, 1109, 1116, 1119, 1120, 1159, 1213, 1237, 1238, 1239, 1319, 1328, 1501, 1589, 1674, 1676, 1678, 1686, 1688, 1695, 1696, 1699, 1701, 1703, 1708, 1710, 1716, 1719, 1720, 1724, 1725], "necessari": [0, 1, 3, 8, 12, 17, 19, 26, 35, 36, 40, 41, 43, 146, 163, 510, 541, 629, 869, 906, 1411, 1412, 1676, 1679, 1690, 1694, 1696, 1697, 1699, 1700, 1704, 1706, 1709, 1712, 1716, 1719, 1724, 1725, 1726, 1730], "becaus": [0, 1, 3, 4, 5, 6, 7, 12, 17, 18, 20, 23, 24, 28, 40, 41, 42, 448, 632, 637, 638, 802, 803, 804, 812, 813, 814, 892, 896, 899, 902, 941, 942, 966, 985, 1034, 1035, 1036, 1053, 1155, 1314, 1319, 1320, 1450, 1558, 1625, 1675, 1676, 1679, 1681, 1688, 1689, 1690, 1695, 1696, 1697, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1709, 1713, 1716, 1719, 1720, 1724, 1726, 1727, 1732, 1734, 1737, 1738], "wa": [0, 1, 3, 6, 18, 19, 20, 33, 34, 35, 36, 40, 41, 42, 290, 439, 448, 666, 676, 689, 690, 709, 713, 728, 741, 758, 801, 892, 901, 910, 925, 936, 938, 942, 966, 985, 993, 1007, 1086, 1112, 1113, 1114, 1145, 1168, 1178, 1213, 1265, 1281, 1319, 1320, 1378, 1413, 1452, 1458, 1657, 1658, 1674, 1676, 1678, 1679, 1680, 1683, 1687, 1688, 1695, 1696, 1697, 1699, 1701, 1702, 1705, 1707, 1713, 1715, 1717, 1719, 1723, 1724, 1734], "f_float32": 0, "re": [0, 1, 4, 5, 6, 12, 17, 20, 23, 25, 32, 35, 40, 41, 42, 656, 832, 895, 899, 1116, 1268, 1320, 1413, 1569, 1608, 1667, 1676, 1679, 1688, 1695, 1696, 1699, 1701, 1703, 1708, 1719, 1725, 1726, 1728, 1738], "again": [0, 5, 17, 20, 23, 26, 1007, 1696, 1706], "regardless": [0, 17, 34, 40, 680, 899, 904, 1657, 1695, 1699, 1711, 1724, 1734], "g_float16": 0, "The": [0, 1, 2, 3, 5, 6, 7, 10, 12, 13, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 40, 41, 43, 105, 146, 151, 163, 164, 176, 210, 245, 266, 268, 270, 274, 276, 353, 355, 357, 401, 411, 436, 439, 440, 445, 447, 450, 451, 465, 467, 469, 488, 494, 534, 555, 568, 569, 579, 582, 583, 584, 585, 589, 590, 591, 592, 607, 608, 610, 614, 615, 619, 620, 622, 623, 624, 625, 630, 631, 633, 634, 635, 636, 637, 638, 640, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 661, 662, 668, 675, 677, 682, 686, 689, 694, 699, 714, 725, 726, 728, 729, 730, 739, 751, 752, 753, 763, 767, 768, 769, 770, 771, 772, 774, 780, 781, 782, 786, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 820, 829, 831, 832, 833, 834, 835, 839, 840, 848, 851, 852, 853, 854, 855, 856, 857, 859, 861, 865, 869, 872, 892, 895, 898, 900, 902, 905, 906, 908, 910, 911, 914, 915, 919, 920, 924, 925, 926, 930, 931, 932, 933, 934, 935, 936, 937, 940, 941, 942, 944, 947, 949, 950, 951, 952, 953, 954, 957, 958, 959, 961, 964, 966, 967, 982, 983, 984, 985, 986, 988, 989, 990, 993, 997, 1007, 1013, 1016, 1017, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1059, 1060, 1061, 1063, 1064, 1065, 1068, 1069, 1070, 1071, 1076, 1077, 1079, 1080, 1081, 1082, 1083, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1103, 1106, 1107, 1108, 1109, 1110, 1111, 1116, 1119, 1121, 1123, 1130, 1131, 1133, 1134, 1144, 1145, 1147, 1155, 1158, 1159, 1164, 1165, 1167, 1168, 1178, 1181, 1182, 1196, 1197, 1204, 1205, 1206, 1208, 1209, 1212, 1213, 1215, 1224, 1225, 1237, 1238, 1239, 1248, 1251, 1265, 1281, 1314, 1316, 1317, 1318, 1319, 1321, 1322, 1328, 1341, 1350, 1353, 1359, 1360, 1361, 1362, 1365, 1366, 1367, 1372, 1373, 1375, 1376, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1387, 1389, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1400, 1401, 1403, 1404, 1407, 1413, 1415, 1416, 1419, 1421, 1422, 1423, 1444, 1445, 1446, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1465, 1466, 1469, 1472, 1475, 1484, 1487, 1501, 1502, 1503, 1504, 1507, 1509, 1519, 1520, 1538, 1540, 1543, 1547, 1548, 1549, 1551, 1553, 1555, 1560, 1562, 1564, 1566, 1567, 1569, 1574, 1581, 1582, 1583, 1590, 1591, 1600, 1606, 1607, 1609, 1611, 1612, 1613, 1614, 1615, 1616, 1620, 1625, 1629, 1630, 1633, 1635, 1641, 1642, 1643, 1645, 1646, 1649, 1650, 1651, 1652, 1659, 1660, 1661, 1665, 1667, 1670, 1674, 1676, 1677, 1678, 1680, 1681, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1715, 1716, 1717, 1718, 1719, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1732, 1733, 1734, 1735, 1736, 1739], "state": [0, 1, 5, 8, 17, 20, 23, 24, 26, 28, 35, 38, 40, 42, 43, 714, 715, 719, 724, 728, 738, 752, 753, 847, 895, 898, 910, 967, 1068, 1069, 1086, 1087, 1116, 1131, 1133, 1314, 1316, 1317, 1318, 1319, 1320, 1341, 1353, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1439, 1440, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1518, 1549, 1591, 1685, 1695, 1696, 1699, 1700, 1701, 1704, 1708, 1711, 1713, 1715, 1723, 1736], "thread": [0, 1, 3, 17, 19, 20, 26, 41, 689, 785, 845, 846, 870, 1053, 1420, 1587, 1588, 1589, 1675, 1676, 1687, 1695, 1699, 1705, 1708, 1724, 1726, 1735], "new": [0, 1, 5, 7, 12, 17, 20, 24, 26, 35, 36, 40, 41, 42, 176, 209, 266, 401, 436, 440, 448, 451, 494, 531, 534, 535, 568, 579, 609, 611, 612, 613, 614, 615, 624, 659, 660, 665, 674, 681, 683, 684, 690, 691, 764, 768, 791, 795, 796, 822, 823, 825, 865, 869, 870, 884, 885, 888, 891, 895, 901, 906, 908, 968, 969, 970, 971, 989, 1016, 1018, 1034, 1035, 1036, 1068, 1079, 1080, 1081, 1116, 1117, 1122, 1126, 1155, 1166, 1168, 1224, 1318, 1319, 1353, 1385, 1389, 1391, 1395, 1396, 1397, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1414, 1416, 1459, 1481, 1499, 1501, 1550, 1560, 1561, 1565, 1566, 1567, 1573, 1574, 1578, 1582, 1583, 1593, 1595, 1597, 1599, 1618, 1619, 1622, 1635, 1637, 1638, 1654, 1656, 1659, 1665, 1666, 1667, 1674, 1676, 1678, 1679, 1683, 1685, 1688, 1689, 1690, 1691, 1692, 1696, 1699, 1701, 1704, 1705, 1706, 1707, 1708, 1710, 1711, 1712, 1713, 1716, 1718, 1719, 1726, 1727, 1728, 1729, 1731, 1732, 1733, 1734], "must": [0, 3, 12, 17, 20, 23, 24, 25, 26, 33, 36, 37, 40, 41, 42, 43, 52, 94, 108, 109, 151, 215, 268, 270, 276, 353, 355, 357, 465, 494, 495, 516, 534, 568, 581, 582, 583, 584, 585, 586, 592, 608, 614, 619, 620, 621, 623, 629, 631, 633, 634, 635, 637, 638, 644, 646, 648, 649, 650, 651, 652, 653, 656, 660, 663, 677, 686, 689, 696, 697, 698, 700, 725, 726, 728, 768, 770, 771, 772, 774, 777, 778, 781, 802, 803, 804, 809, 811, 812, 813, 814, 815, 822, 823, 832, 834, 837, 838, 848, 857, 858, 861, 872, 895, 905, 910, 917, 920, 949, 950, 951, 952, 958, 960, 961, 964, 967, 986, 988, 989, 990, 997, 1004, 1007, 1013, 1020, 1033, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1053, 1059, 1060, 1063, 1070, 1071, 1077, 1109, 1116, 1119, 1122, 1147, 1153, 1168, 1186, 1195, 1197, 1205, 1224, 1237, 1238, 1239, 1257, 1319, 1341, 1350, 1365, 1366, 1367, 1400, 1410, 1411, 1415, 1422, 1456, 1458, 1464, 1465, 1469, 1472, 1538, 1539, 1540, 1541, 1547, 1548, 1569, 1578, 1581, 1589, 1604, 1606, 1607, 1609, 1625, 1630, 1636, 1640, 1641, 1650, 1652, 1656, 1660, 1664, 1665, 1667, 1668, 1670, 1676, 1677, 1678, 1679, 1688, 1689, 1690, 1691, 1694, 1695, 1696, 1697, 1699, 1700, 1701, 1704, 1708, 1711, 1712, 1713, 1716, 1717, 1719, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1734, 1738], "invok": [0, 2, 7, 13, 20, 33, 35, 36, 41, 42, 630, 632, 725, 726, 895, 898, 904, 1053, 1116, 1317, 1452, 1458, 1676, 1679, 1680, 1685, 1695, 1698, 1699, 1700, 1701, 1705, 1706, 1716, 1724, 1725], "affect": [0, 1, 2, 6, 8, 16, 25, 176, 177, 690, 691, 785, 832, 842, 870, 895, 1086, 1116, 1131, 1168, 1281, 1378, 1420, 1584, 1585, 1587, 1695, 1696, 1699, 1703, 1706, 1709, 1710, 1729], "dataparallel": [0, 20, 1277, 1319, 1413, 1696, 1702, 1708, 1724], "parallel": [0, 11, 12, 17, 18, 20, 21, 23, 35, 36, 40, 845, 846, 898, 1053, 1122, 1155, 1213, 1319, 1588, 1589, 1675, 1679, 1695, 1696, 1698, 1708, 1712, 1724, 1726], "distributeddataparallel": [0, 17, 18, 20, 21, 23, 36, 1053, 1155, 1708, 1717, 1724], "than": [0, 3, 4, 5, 7, 8, 10, 12, 17, 18, 20, 21, 24, 25, 26, 28, 32, 35, 36, 37, 40, 42, 105, 209, 388, 451, 495, 534, 568, 588, 594, 622, 631, 632, 641, 647, 658, 665, 666, 670, 671, 691, 698, 735, 739, 751, 768, 769, 780, 821, 822, 823, 825, 829, 834, 839, 851, 855, 869, 880, 892, 893, 896, 906, 915, 916, 919, 924, 925, 931, 935, 940, 948, 949, 951, 952, 955, 960, 970, 984, 987, 994, 997, 999, 1002, 1007, 1032, 1033, 1044, 1045, 1046, 1053, 1059, 1060, 1077, 1108, 1122, 1130, 1147, 1153, 1163, 1164, 1165, 1178, 1188, 1189, 1190, 1204, 1205, 1213, 1224, 1250, 1280, 1281, 1314, 1319, 1372, 1378, 1384, 1385, 1386, 1387, 1413, 1416, 1422, 1458, 1459, 1473, 1474, 1562, 1563, 1590, 1610, 1611, 1612, 1613, 1615, 1616, 1642, 1650, 1652, 1660, 1674, 1676, 1678, 1679, 1681, 1690, 1692, 1694, 1696, 1697, 1699, 1701, 1702, 1703, 1706, 1708, 1709, 1710, 1711, 1713, 1716, 1717, 1719, 1720, 1724, 1727, 1728, 1730, 1732, 1733, 1734], "one": [0, 1, 2, 3, 4, 5, 6, 7, 10, 12, 13, 17, 18, 20, 21, 23, 24, 26, 28, 32, 33, 35, 37, 38, 40, 41, 42, 105, 176, 209, 307, 439, 465, 472, 495, 510, 592, 610, 616, 622, 623, 624, 626, 632, 647, 658, 660, 670, 674, 690, 691, 696, 700, 726, 748, 758, 769, 781, 785, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 811, 812, 813, 814, 815, 817, 820, 824, 827, 828, 829, 848, 857, 858, 870, 874, 877, 880, 899, 904, 908, 914, 915, 925, 926, 936, 937, 938, 939, 940, 942, 947, 951, 953, 955, 958, 964, 965, 981, 990, 995, 1000, 1007, 1013, 1024, 1029, 1032, 1033, 1034, 1035, 1036, 1039, 1044, 1047, 1048, 1049, 1060, 1064, 1065, 1070, 1079, 1080, 1081, 1083, 1084, 1085, 1095, 1096, 1097, 1107, 1116, 1120, 1122, 1155, 1163, 1168, 1178, 1188, 1191, 1192, 1193, 1208, 1209, 1210, 1215, 1250, 1280, 1314, 1319, 1320, 1341, 1350, 1383, 1385, 1386, 1390, 1400, 1411, 1418, 1419, 1420, 1421, 1422, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1454, 1456, 1457, 1458, 1544, 1545, 1562, 1578, 1585, 1587, 1590, 1593, 1620, 1629, 1640, 1645, 1646, 1648, 1656, 1659, 1660, 1667, 1675, 1676, 1679, 1683, 1685, 1687, 1688, 1689, 1690, 1691, 1696, 1697, 1698, 1699, 1700, 1701, 1703, 1705, 1706, 1708, 1710, 1712, 1713, 1715, 1716, 1717, 1719, 1720, 1724, 1726, 1727, 1728, 1729, 1730, 1732, 1733, 1734], "gpu": [0, 1, 2, 3, 4, 6, 12, 14, 15, 17, 18, 26, 36, 37, 40, 41, 151, 164, 244, 287, 555, 693, 694, 696, 697, 698, 699, 700, 706, 707, 708, 714, 720, 721, 727, 729, 730, 731, 733, 734, 735, 737, 738, 739, 740, 745, 746, 747, 748, 749, 752, 758, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 829, 895, 904, 941, 966, 983, 997, 1024, 1053, 1068, 1086, 1116, 1131, 1132, 1155, 1277, 1319, 1353, 1410, 1629, 1675, 1676, 1699, 1704, 1706, 1707, 1709, 1710, 1712, 1719, 1724, 1729, 1733, 1735], "per": [0, 12, 17, 18, 20, 21, 23, 25, 26, 28, 36, 37, 40, 425, 426, 427, 630, 632, 692, 763, 795, 967, 1032, 1033, 1034, 1035, 1036, 1050, 1052, 1053, 1060, 1071, 1076, 1079, 1080, 1081, 1082, 1083, 1088, 1107, 1108, 1116, 1119, 1120, 1121, 1122, 1123, 1130, 1147, 1148, 1155, 1159, 1160, 1161, 1162, 1163, 1164, 1185, 1186, 1196, 1225, 1248, 1256, 1319, 1327, 1328, 1419, 1423, 1436, 1452, 1458, 1465, 1486, 1501, 1504, 1507, 1544, 1590, 1592, 1630, 1642, 1646, 1667, 1687, 1690, 1692, 1698, 1699, 1700, 1705, 1717, 1719, 1720, 1722, 1725, 1732], "process": [0, 1, 3, 10, 12, 18, 19, 20, 21, 24, 26, 27, 28, 29, 35, 36, 37, 38, 40, 42, 689, 721, 727, 751, 905, 967, 1032, 1033, 1050, 1052, 1059, 1060, 1076, 1083, 1107, 1108, 1112, 1113, 1114, 1119, 1120, 1121, 1123, 1130, 1147, 1148, 1155, 1159, 1161, 1163, 1164, 1185, 1186, 1196, 1225, 1248, 1256, 1319, 1455, 1460, 1592, 1674, 1676, 1687, 1688, 1689, 1690, 1696, 1698, 1699, 1700, 1701, 1705, 1706, 1708, 1710, 1712, 1713, 1716, 1717, 1718, 1719, 1724, 1726, 1727, 1729, 1736], "work": [0, 1, 2, 3, 5, 6, 7, 8, 10, 12, 13, 14, 19, 20, 21, 23, 24, 25, 26, 35, 36, 37, 38, 40, 42, 74, 105, 307, 439, 539, 540, 622, 636, 688, 689, 690, 691, 717, 728, 729, 748, 782, 784, 801, 821, 822, 823, 895, 899, 906, 907, 930, 931, 958, 959, 967, 1053, 1113, 1116, 1132, 1149, 1251, 1268, 1319, 1458, 1503, 1557, 1582, 1588, 1636, 1639, 1674, 1676, 1679, 1680, 1688, 1689, 1690, 1694, 1696, 1698, 1699, 1700, 1701, 1703, 1704, 1706, 1708, 1711, 1712, 1713, 1716, 1717, 1719, 1724, 1725, 1733, 1735, 1738], "str": [0, 2, 12, 17, 18, 20, 26, 29, 33, 35, 40, 42, 276, 465, 469, 555, 630, 632, 639, 640, 696, 697, 698, 700, 711, 712, 725, 726, 742, 744, 755, 775, 781, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 893, 894, 895, 896, 898, 899, 901, 904, 940, 953, 958, 959, 967, 998, 1014, 1032, 1033, 1039, 1044, 1045, 1046, 1050, 1052, 1060, 1066, 1070, 1076, 1077, 1082, 1083, 1092, 1093, 1094, 1107, 1108, 1116, 1117, 1119, 1120, 1121, 1123, 1126, 1130, 1147, 1148, 1164, 1165, 1166, 1168, 1185, 1186, 1196, 1197, 1205, 1210, 1213, 1224, 1225, 1248, 1256, 1281, 1372, 1378, 1384, 1385, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1401, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1416, 1417, 1419, 1429, 1436, 1452, 1458, 1459, 1476, 1578, 1584, 1585, 1625, 1674, 1676, 1677, 1678, 1679, 1680, 1686, 1687, 1688, 1690, 1696, 1713, 1716, 1717, 1718, 1724, 1729, 1732, 1734, 1738], "whether": [0, 1, 2, 6, 12, 17, 18, 20, 21, 24, 26, 34, 35, 40, 42, 274, 276, 424, 469, 568, 588, 590, 591, 594, 604, 605, 610, 619, 626, 629, 630, 632, 637, 638, 645, 654, 667, 668, 669, 675, 676, 724, 740, 852, 853, 870, 892, 895, 903, 916, 924, 925, 931, 933, 936, 937, 938, 939, 941, 942, 943, 944, 949, 951, 952, 955, 956, 957, 958, 982, 985, 993, 994, 996, 997, 999, 1002, 1007, 1012, 1013, 1014, 1015, 1039, 1050, 1076, 1082, 1116, 1125, 1130, 1165, 1175, 1176, 1177, 1197, 1225, 1256, 1319, 1384, 1386, 1389, 1402, 1422, 1428, 1430, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446, 1452, 1463, 1473, 1476, 1538, 1586, 1587, 1623, 1624, 1625, 1628, 1629, 1633, 1643, 1648, 1657, 1658, 1660, 1662, 1663, 1674, 1679, 1686, 1695, 1696, 1699, 1701, 1704, 1713, 1717, 1719, 1724, 1727, 1729, 1731, 1732, 1737], "bool": [0, 1, 2, 5, 12, 17, 18, 20, 21, 23, 24, 29, 35, 40, 42, 105, 151, 164, 200, 215, 274, 276, 283, 284, 285, 286, 288, 289, 294, 296, 398, 399, 400, 401, 402, 411, 424, 448, 469, 555, 588, 589, 590, 591, 592, 594, 595, 604, 605, 606, 610, 622, 630, 631, 632, 633, 634, 635, 636, 637, 638, 645, 648, 650, 651, 653, 654, 660, 661, 667, 668, 669, 675, 689, 722, 740, 780, 782, 783, 784, 787, 794, 799, 817, 833, 834, 835, 836, 837, 852, 853, 856, 857, 870, 880, 884, 886, 892, 895, 899, 901, 910, 911, 914, 916, 924, 925, 936, 937, 938, 939, 941, 942, 943, 944, 947, 949, 951, 952, 955, 956, 957, 958, 964, 965, 967, 976, 977, 978, 979, 981, 982, 985, 987, 993, 994, 996, 997, 999, 1002, 1007, 1012, 1013, 1014, 1015, 1024, 1028, 1032, 1033, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1055, 1056, 1057, 1059, 1060, 1061, 1070, 1076, 1082, 1083, 1092, 1093, 1094, 1095, 1096, 1097, 1107, 1108, 1116, 1119, 1120, 1121, 1123, 1125, 1130, 1143, 1147, 1148, 1164, 1165, 1168, 1178, 1185, 1186, 1196, 1197, 1204, 1205, 1210, 1213, 1224, 1225, 1248, 1256, 1281, 1319, 1320, 1372, 1378, 1381, 1384, 1386, 1389, 1390, 1411, 1412, 1413, 1414, 1422, 1426, 1427, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1463, 1465, 1471, 1473, 1475, 1476, 1499, 1547, 1548, 1549, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1578, 1582, 1586, 1587, 1592, 1603, 1611, 1612, 1613, 1614, 1615, 1616, 1623, 1624, 1625, 1628, 1629, 1633, 1639, 1643, 1648, 1657, 1658, 1660, 1661, 1662, 1663, 1672, 1673, 1674, 1676, 1677, 1678, 1679, 1686, 1687, 1688, 1689, 1690, 1711, 1713, 1716, 1717, 1718, 1723, 1724, 1729, 1730, 1732, 1733, 1734, 1738], "option": [0, 1, 3, 5, 12, 17, 20, 23, 24, 29, 33, 34, 35, 38, 40, 42, 43, 105, 110, 125, 127, 130, 133, 134, 135, 150, 161, 164, 194, 222, 252, 280, 286, 347, 398, 399, 400, 401, 402, 440, 451, 452, 465, 472, 476, 488, 510, 531, 535, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 588, 589, 590, 591, 592, 593, 594, 595, 606, 608, 609, 610, 611, 612, 613, 614, 615, 622, 630, 631, 632, 633, 634, 635, 636, 637, 638, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 656, 660, 663, 665, 666, 667, 668, 669, 671, 673, 674, 675, 680, 681, 683, 684, 685, 686, 687, 688, 689, 690, 691, 693, 696, 698, 699, 700, 703, 704, 710, 711, 714, 717, 725, 726, 727, 731, 733, 734, 735, 737, 739, 740, 741, 745, 746, 747, 751, 752, 757, 758, 759, 760, 761, 762, 764, 767, 768, 769, 770, 771, 772, 774, 775, 777, 779, 780, 781, 782, 783, 784, 786, 791, 794, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 824, 825, 826, 827, 828, 829, 831, 834, 835, 836, 837, 838, 839, 840, 848, 851, 852, 853, 854, 855, 856, 859, 860, 861, 869, 872, 884, 886, 889, 890, 892, 893, 895, 896, 899, 901, 908, 910, 911, 914, 915, 916, 917, 918, 919, 920, 923, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 976, 977, 978, 979, 981, 982, 983, 984, 985, 986, 987, 989, 990, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1005, 1006, 1007, 1009, 1011, 1012, 1013, 1014, 1015, 1017, 1018, 1020, 1024, 1028, 1032, 1033, 1038, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1063, 1064, 1065, 1066, 1070, 1073, 1074, 1075, 1076, 1077, 1082, 1083, 1088, 1092, 1093, 1094, 1095, 1096, 1097, 1102, 1107, 1108, 1112, 1113, 1114, 1116, 1117, 1118, 1119, 1120, 1121, 1123, 1125, 1126, 1127, 1130, 1134, 1135, 1136, 1143, 1147, 1148, 1155, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1167, 1168, 1169, 1170, 1178, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1195, 1196, 1197, 1204, 1205, 1208, 1209, 1210, 1213, 1215, 1224, 1225, 1232, 1237, 1238, 1239, 1248, 1249, 1256, 1268, 1269, 1281, 1318, 1319, 1320, 1351, 1372, 1378, 1384, 1385, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1416, 1419, 1421, 1422, 1423, 1426, 1427, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1441, 1443, 1444, 1445, 1446, 1447, 1451, 1463, 1464, 1465, 1468, 1472, 1473, 1475, 1476, 1484, 1538, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1561, 1562, 1563, 1564, 1571, 1573, 1578, 1590, 1593, 1595, 1596, 1597, 1599, 1600, 1603, 1604, 1605, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1628, 1629, 1630, 1633, 1636, 1637, 1638, 1639, 1640, 1643, 1648, 1649, 1650, 1651, 1652, 1654, 1657, 1658, 1660, 1661, 1662, 1663, 1664, 1669, 1672, 1673, 1674, 1676, 1677, 1679, 1681, 1683, 1685, 1686, 1687, 1694, 1699, 1701, 1702, 1705, 1706, 1710, 1716, 1718, 1719, 1724, 1727, 1728, 1730, 1732, 1734, 1737], "torch_dtyp": 0, "weight": [0, 17, 20, 24, 40, 42, 111, 256, 315, 316, 448, 647, 686, 856, 857, 895, 899, 904, 906, 911, 920, 1007, 1032, 1033, 1037, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1059, 1060, 1068, 1069, 1071, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1103, 1116, 1120, 1121, 1122, 1123, 1124, 1131, 1133, 1145, 1159, 1183, 1184, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1196, 1204, 1205, 1214, 1223, 1227, 1230, 1245, 1247, 1248, 1257, 1265, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1314, 1319, 1323, 1324, 1325, 1326, 1327, 1328, 1331, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1342, 1344, 1345, 1346, 1347, 1349, 1353, 1354, 1356, 1357, 1358, 1365, 1366, 1367, 1374, 1384, 1385, 1387, 1389, 1400, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1415, 1416, 1419, 1430, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1446, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1537, 1546, 1667, 1674, 1677, 1678, 1679, 1685, 1690, 1694, 1701, 1702, 1706, 1711, 1719, 1720, 1722, 1732, 1736, 1737], "cach": [0, 2, 3, 24, 439, 708, 725, 733, 735, 737, 739, 746, 751, 1320, 1389, 1688, 1702], "insid": [0, 1, 6, 17, 35, 40, 41, 42, 626, 627, 628, 629, 694, 728, 906, 1319, 1676, 1678, 1679, 1685, 1695, 1699, 1701, 1705, 1713, 1736], "custom_fwd": [0, 1695], "fwd": 0, "cast_input": [0, 1695], "helper": [0, 3, 5, 20, 42, 1155, 1674, 1678, 1699, 1700, 1713, 1716, 1724, 1738], "subclass": [0, 1, 12, 17, 24, 28, 42, 94, 488, 619, 620, 621, 893, 896, 905, 1116, 1320, 1391, 1396, 1415, 1676, 1679, 1680, 1695, 1706, 1713, 1724, 1738], "page": [0, 6, 8, 17, 21, 36, 38, 967, 1159, 1161, 1163, 1699, 1700, 1706, 1724], "incom": [0, 20, 37, 1037, 1103, 1184, 1230, 1374, 1501, 1502, 1503, 1504, 1507, 1688, 1696], "non": [0, 1, 3, 5, 12, 16, 18, 20, 21, 24, 26, 28, 35, 37, 38, 40, 41, 43, 105, 290, 456, 465, 469, 495, 534, 593, 595, 607, 619, 621, 622, 627, 629, 637, 638, 647, 660, 663, 679, 680, 685, 739, 827, 828, 834, 872, 895, 898, 907, 910, 911, 930, 931, 938, 942, 943, 956, 958, 967, 977, 985, 990, 996, 1007, 1012, 1013, 1029, 1030, 1031, 1045, 1046, 1048, 1049, 1052, 1062, 1068, 1085, 1086, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1119, 1121, 1122, 1123, 1131, 1133, 1147, 1159, 1196, 1215, 1243, 1248, 1318, 1319, 1327, 1328, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1349, 1353, 1357, 1358, 1365, 1366, 1367, 1421, 1480, 1520, 1578, 1579, 1593, 1607, 1611, 1612, 1613, 1614, 1615, 1616, 1641, 1657, 1674, 1676, 1678, 1679, 1681, 1688, 1694, 1697, 1701, 1702, 1706, 1709, 1710, 1713, 1717, 1718, 1723, 1724, 1726, 1727, 1728, 1730, 1731, 1732, 1734, 1738], "intern": [0, 3, 7, 8, 12, 17, 18, 19, 20, 24, 32, 42, 688, 717, 738, 895, 931, 933, 949, 952, 975, 1034, 1035, 1036, 1070, 1155, 1188, 1189, 1190, 1213, 1386, 1585, 1614, 1660, 1680, 1695, 1696, 1698, 1699, 1703, 1709, 1710, 1713, 1725, 1726, 1729, 1731], "current": [0, 1, 2, 3, 5, 6, 8, 10, 12, 17, 19, 20, 23, 24, 26, 28, 35, 36, 40, 41, 42, 43, 105, 164, 176, 439, 449, 450, 451, 595, 620, 622, 623, 630, 631, 632, 637, 645, 654, 688, 689, 690, 691, 698, 699, 701, 702, 703, 704, 707, 708, 710, 711, 714, 716, 717, 720, 722, 723, 727, 728, 729, 731, 733, 734, 735, 737, 739, 740, 741, 745, 746, 747, 748, 750, 752, 754, 757, 758, 782, 784, 794, 799, 817, 833, 835, 842, 843, 844, 852, 853, 878, 879, 895, 899, 910, 914, 965, 967, 981, 998, 1056, 1059, 1063, 1116, 1155, 1167, 1207, 1213, 1224, 1280, 1281, 1283, 1319, 1334, 1336, 1374, 1390, 1394, 1395, 1396, 1397, 1398, 1403, 1404, 1405, 1406, 1426, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1440, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1475, 1500, 1551, 1553, 1555, 1557, 1558, 1585, 1611, 1612, 1613, 1614, 1615, 1616, 1650, 1652, 1657, 1672, 1676, 1678, 1679, 1680, 1681, 1683, 1687, 1688, 1695, 1696, 1699, 1704, 1705, 1706, 1707, 1711, 1712, 1713, 1715, 1716, 1717, 1719, 1722, 1724, 1725, 1727, 1729, 1730, 1732, 1733, 1736, 1738], "outsid": [0, 5, 8, 17, 28, 40, 579, 615, 896, 1213, 1319, 1449, 1450, 1455, 1456, 1461, 1678, 1679, 1694, 1696, 1699, 1702, 1706, 1734], "ha": [0, 1, 5, 6, 7, 8, 10, 12, 13, 14, 15, 17, 18, 20, 21, 23, 24, 25, 26, 28, 32, 34, 35, 36, 37, 38, 40, 41, 42, 43, 105, 151, 164, 210, 215, 290, 398, 399, 400, 401, 402, 426, 427, 448, 450, 494, 531, 555, 556, 569, 588, 590, 591, 592, 594, 604, 605, 607, 619, 622, 624, 626, 632, 637, 638, 646, 664, 667, 668, 679, 680, 681, 687, 689, 690, 691, 721, 724, 725, 768, 770, 785, 817, 829, 848, 857, 858, 869, 892, 895, 899, 902, 905, 906, 907, 910, 915, 916, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 944, 946, 948, 949, 952, 953, 954, 955, 957, 958, 959, 961, 962, 966, 975, 982, 983, 985, 994, 996, 997, 998, 999, 1002, 1012, 1013, 1014, 1015, 1032, 1033, 1034, 1035, 1036, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1053, 1054, 1060, 1063, 1064, 1065, 1068, 1071, 1076, 1079, 1080, 1081, 1086, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1108, 1109, 1110, 1111, 1116, 1120, 1121, 1122, 1123, 1124, 1131, 1147, 1149, 1155, 1163, 1167, 1168, 1178, 1188, 1189, 1190, 1196, 1205, 1208, 1209, 1213, 1224, 1248, 1250, 1251, 1253, 1257, 1268, 1281, 1283, 1314, 1316, 1317, 1319, 1328, 1353, 1372, 1374, 1378, 1380, 1384, 1386, 1388, 1391, 1395, 1397, 1400, 1410, 1411, 1416, 1417, 1421, 1423, 1430, 1450, 1451, 1452, 1454, 1458, 1459, 1463, 1473, 1475, 1476, 1480, 1481, 1482, 1520, 1522, 1537, 1543, 1544, 1545, 1562, 1564, 1574, 1585, 1596, 1607, 1608, 1609, 1620, 1622, 1623, 1624, 1625, 1628, 1629, 1633, 1642, 1648, 1662, 1663, 1667, 1676, 1678, 1679, 1687, 1688, 1689, 1690, 1691, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1704, 1705, 1706, 1708, 1711, 1712, 1713, 1715, 1716, 1717, 1718, 1719, 1720, 1723, 1724, 1725, 1726, 1727, 1729, 1730, 1732, 1733, 1734, 1735], "effect": [0, 3, 6, 12, 17, 18, 20, 24, 37, 42, 151, 164, 555, 717, 763, 895, 937, 938, 939, 940, 998, 1024, 1039, 1047, 1048, 1049, 1054, 1055, 1056, 1057, 1061, 1116, 1122, 1168, 1224, 1251, 1281, 1316, 1319, 1320, 1328, 1372, 1378, 1396, 1444, 1452, 1609, 1629, 1646, 1667, 1674, 1676, 1685, 1694, 1695, 1696, 1699, 1701, 1719, 1722, 1729, 1732], "custom_bwd": [0, 1695], "bwd": 0, "valu": [0, 1, 3, 5, 6, 7, 8, 10, 12, 17, 18, 21, 23, 24, 26, 27, 29, 32, 33, 35, 36, 40, 41, 42, 43, 56, 57, 58, 59, 74, 105, 109, 176, 189, 190, 191, 192, 209, 214, 215, 227, 228, 254, 266, 268, 270, 271, 272, 273, 274, 276, 278, 281, 307, 354, 355, 373, 374, 376, 377, 424, 434, 436, 465, 467, 469, 488, 494, 510, 534, 535, 551, 552, 576, 579, 582, 583, 586, 590, 591, 592, 595, 604, 605, 606, 610, 615, 619, 621, 622, 624, 625, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 645, 646, 647, 654, 660, 664, 669, 671, 681, 682, 685, 690, 716, 725, 726, 739, 751, 759, 760, 763, 771, 772, 780, 786, 795, 796, 798, 800, 802, 803, 804, 809, 811, 812, 813, 814, 815, 824, 829, 835, 837, 839, 843, 844, 848, 851, 852, 853, 854, 855, 856, 857, 865, 880, 885, 886, 887, 888, 891, 892, 893, 895, 896, 898, 901, 902, 910, 913, 915, 916, 919, 923, 924, 926, 928, 930, 931, 932, 933, 934, 937, 938, 939, 940, 944, 947, 949, 951, 952, 954, 958, 959, 964, 965, 966, 967, 970, 975, 981, 984, 985, 988, 993, 994, 996, 997, 999, 1002, 1005, 1007, 1011, 1012, 1013, 1014, 1017, 1020, 1024, 1029, 1030, 1031, 1032, 1034, 1035, 1036, 1037, 1038, 1039, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1058, 1059, 1060, 1061, 1063, 1070, 1071, 1072, 1075, 1076, 1077, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1101, 1103, 1106, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1117, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1130, 1144, 1147, 1149, 1150, 1151, 1152, 1153, 1155, 1158, 1159, 1161, 1163, 1164, 1165, 1167, 1168, 1185, 1186, 1188, 1189, 1190, 1195, 1196, 1205, 1206, 1210, 1213, 1215, 1224, 1225, 1226, 1237, 1238, 1239, 1248, 1249, 1250, 1251, 1253, 1256, 1275, 1276, 1281, 1283, 1314, 1317, 1319, 1328, 1349, 1357, 1363, 1364, 1372, 1377, 1378, 1380, 1382, 1384, 1385, 1386, 1387, 1389, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1403, 1404, 1410, 1413, 1414, 1415, 1417, 1421, 1422, 1426, 1427, 1428, 1429, 1432, 1436, 1452, 1458, 1465, 1469, 1472, 1476, 1484, 1487, 1501, 1502, 1503, 1504, 1507, 1509, 1538, 1545, 1546, 1558, 1560, 1562, 1563, 1564, 1569, 1571, 1578, 1581, 1590, 1593, 1600, 1603, 1606, 1607, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1625, 1629, 1630, 1636, 1640, 1643, 1646, 1649, 1650, 1651, 1652, 1654, 1657, 1658, 1659, 1670, 1672, 1673, 1674, 1676, 1677, 1680, 1686, 1687, 1688, 1694, 1695, 1696, 1698, 1699, 1701, 1702, 1703, 1704, 1706, 1710, 1711, 1713, 1715, 1716, 1718, 1719, 1722, 1723, 1724, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1737], "small": [0, 3, 6, 8, 17, 18, 19, 20, 24, 35, 595, 637, 638, 697, 739, 957, 958, 970, 972, 1024, 1051, 1125, 1130, 1144, 1168, 1195, 1249, 1256, 1319, 1449, 1455, 1629, 1676, 1678, 1679, 1699, 1701, 1702, 1706, 1711, 1713, 1716, 1719, 1720, 1727, 1728, 1734], "magnitud": [0, 681, 1419, 1593, 1694, 1695, 1699], "represent": [0, 3, 12, 17, 20, 33, 42, 434, 690, 797, 798, 800, 824, 840, 895, 934, 937, 939, 942, 1011, 1116, 1122, 1351, 1463, 1676, 1679, 1691, 1701, 1709, 1713, 1716, 1719, 1734, 1739], "These": [0, 2, 3, 7, 12, 13, 17, 20, 21, 24, 40, 42, 610, 686, 781, 892, 895, 937, 1004, 1024, 1314, 1385, 1675, 1676, 1677, 1678, 1679, 1687, 1689, 1690, 1692, 1695, 1696, 1699, 1700, 1701, 1706, 1711, 1713, 1716, 1722, 1724, 1725, 1730, 1735, 1738], "flush": [0, 1, 739, 905, 1574, 1586, 1709, 1713, 1732], "zero": [0, 1, 2, 18, 20, 21, 23, 24, 40, 42, 105, 215, 270, 465, 467, 494, 495, 574, 586, 593, 607, 616, 617, 618, 622, 627, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 646, 647, 667, 668, 669, 674, 681, 685, 743, 744, 771, 775, 794, 795, 796, 797, 798, 800, 801, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 820, 829, 834, 854, 855, 858, 880, 892, 895, 906, 924, 925, 926, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 940, 941, 942, 943, 944, 946, 947, 948, 949, 951, 952, 953, 954, 955, 956, 957, 958, 959, 962, 967, 975, 976, 977, 978, 979, 985, 986, 1007, 1011, 1015, 1028, 1029, 1030, 1031, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1051, 1054, 1055, 1056, 1057, 1059, 1060, 1061, 1063, 1068, 1069, 1071, 1084, 1085, 1086, 1087, 1088, 1092, 1093, 1094, 1095, 1096, 1097, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1122, 1125, 1128, 1129, 1130, 1131, 1133, 1153, 1159, 1167, 1168, 1171, 1180, 1181, 1182, 1191, 1192, 1193, 1195, 1197, 1198, 1199, 1200, 1201, 1205, 1206, 1213, 1234, 1235, 1249, 1250, 1251, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1309, 1310, 1311, 1323, 1324, 1328, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1352, 1353, 1357, 1361, 1362, 1365, 1366, 1367, 1368, 1370, 1373, 1374, 1394, 1395, 1396, 1397, 1412, 1417, 1421, 1425, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1463, 1475, 1484, 1501, 1502, 1503, 1504, 1507, 1544, 1545, 1546, 1562, 1571, 1581, 1596, 1600, 1607, 1611, 1612, 1613, 1614, 1615, 1616, 1620, 1629, 1633, 1639, 1640, 1642, 1648, 1673, 1676, 1677, 1679, 1681, 1687, 1688, 1689, 1690, 1694, 1696, 1699, 1701, 1706, 1709, 1712, 1714, 1716, 1718, 1719, 1722, 1727, 1728, 1730, 1732, 1733, 1734, 1735], "underflow": [0, 1082, 1695], "updat": [0, 8, 10, 18, 23, 26, 35, 42, 176, 388, 465, 467, 895, 1034, 1035, 1036, 1053, 1059, 1060, 1068, 1079, 1080, 1081, 1116, 1117, 1126, 1155, 1204, 1205, 1353, 1385, 1389, 1430, 1436, 1441, 1446, 1447, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1461, 1484, 1485, 1506, 1674, 1676, 1685, 1695, 1696, 1699, 1700, 1701, 1706, 1708, 1711, 1712, 1715, 1717, 1719, 1724, 1725, 1726, 1732], "lost": [0, 26, 36, 38, 1053, 1112, 1113, 1114], "To": [0, 1, 2, 3, 4, 5, 8, 12, 13, 17, 18, 20, 21, 23, 24, 26, 27, 33, 34, 36, 37, 40, 42, 290, 451, 623, 636, 673, 729, 748, 768, 770, 809, 811, 815, 826, 895, 896, 898, 899, 905, 906, 940, 962, 967, 997, 1024, 1056, 1082, 1112, 1113, 1114, 1116, 1169, 1170, 1319, 1327, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1419, 1458, 1465, 1476, 1589, 1630, 1633, 1674, 1676, 1678, 1679, 1683, 1688, 1689, 1690, 1692, 1695, 1696, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1706, 1707, 1711, 1713, 1715, 1716, 1717, 1718, 1719, 1724, 1725, 1726, 1727, 1730, 1731, 1732, 1733], "prevent": [0, 6, 7, 17, 18, 20, 21, 26, 42, 628, 689, 761, 762, 892, 996, 1012, 1015, 1054, 1122, 1147, 1232, 1268, 1269, 1314, 1319, 1328, 1473, 1605, 1608, 1628, 1650, 1652, 1660, 1688, 1695, 1696, 1699, 1700, 1702, 1706, 1716, 1718, 1726, 1727, 1728], "multipli": [0, 268, 276, 377, 465, 580, 581, 582, 583, 584, 585, 586, 644, 656, 751, 763, 781, 848, 859, 918, 930, 931, 935, 948, 950, 952, 958, 960, 990, 1001, 1006, 1009, 1032, 1044, 1045, 1046, 1049, 1068, 1086, 1168, 1169, 1170, 1224, 1281, 1282, 1283, 1353, 1372, 1378, 1379, 1380, 1389, 1449, 1455, 1457, 1463, 1602, 1604, 1606, 1607, 1621, 1625, 1626, 1629, 1646, 1677, 1689, 1699, 1703, 1706, 1709, 1727, 1728], "factor": [0, 3, 18, 24, 42, 584, 585, 586, 644, 667, 668, 669, 937, 938, 939, 942, 944, 983, 985, 986, 987, 1054, 1077, 1104, 1128, 1129, 1254, 1255, 1444, 1445, 1446, 1448, 1449, 1451, 1453, 1454, 1455, 1456, 1457, 1459, 1460, 1461, 1475, 1484, 1501, 1607, 1629, 1694, 1695, 1719], "flow": [0, 673, 907, 910, 1178, 1213, 1319, 1676, 1694, 1696, 1699, 1701, 1711, 1713, 1726], "through": [0, 5, 6, 8, 13, 17, 20, 24, 28, 41, 42, 448, 628, 637, 638, 693, 728, 808, 893, 896, 898, 910, 911, 913, 930, 931, 952, 958, 975, 1123, 1160, 1161, 1162, 1163, 1215, 1314, 1389, 1475, 1522, 1633, 1667, 1674, 1675, 1678, 1679, 1683, 1687, 1688, 1689, 1690, 1696, 1701, 1702, 1703, 1705, 1706, 1712, 1713, 1716, 1717, 1719, 1722, 1724, 1725, 1726, 1731, 1735, 1739], "word": [0, 1, 7, 20, 35, 36, 41, 42, 660, 1024, 1044, 1045, 1046, 1059, 1060, 1159, 1204, 1205, 1224, 1281, 1319, 1384, 1578, 1678, 1696, 1702, 1716, 1725], "have": [0, 1, 3, 5, 6, 7, 8, 10, 12, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 108, 109, 176, 177, 268, 270, 276, 290, 353, 357, 388, 401, 411, 424, 439, 440, 455, 465, 467, 469, 472, 494, 568, 588, 590, 591, 592, 594, 610, 619, 622, 630, 632, 645, 646, 654, 663, 664, 686, 691, 698, 699, 728, 739, 771, 779, 787, 801, 811, 816, 818, 832, 837, 838, 852, 853, 856, 857, 869, 870, 894, 895, 898, 899, 902, 904, 906, 907, 908, 909, 910, 911, 916, 917, 926, 930, 931, 947, 954, 955, 958, 960, 966, 975, 977, 982, 983, 994, 996, 997, 998, 999, 1002, 1007, 1012, 1013, 1015, 1024, 1028, 1032, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1053, 1059, 1060, 1064, 1065, 1070, 1075, 1079, 1080, 1081, 1108, 1116, 1119, 1120, 1121, 1122, 1123, 1163, 1165, 1195, 1204, 1205, 1208, 1209, 1213, 1248, 1250, 1253, 1316, 1317, 1318, 1319, 1320, 1381, 1382, 1384, 1386, 1389, 1413, 1415, 1420, 1422, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1473, 1480, 1523, 1566, 1567, 1581, 1593, 1604, 1606, 1610, 1611, 1612, 1613, 1615, 1616, 1625, 1628, 1629, 1633, 1636, 1640, 1646, 1648, 1660, 1665, 1667, 1669, 1674, 1676, 1677, 1678, 1679, 1681, 1683, 1685, 1687, 1688, 1689, 1690, 1691, 1694, 1695, 1696, 1697, 1699, 1700, 1701, 1702, 1703, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1715, 1716, 1717, 1719, 1720, 1723, 1724, 1725, 1726, 1727, 1729, 1730, 1731, 1732, 1733, 1734, 1738], "larger": [0, 8, 20, 24, 40, 42, 209, 451, 638, 647, 739, 949, 952, 1024, 1053, 1059, 1060, 1108, 1165, 1168, 1204, 1205, 1319, 1660, 1696, 1699, 1702, 1703, 1705, 1709, 1711, 1727, 1732], "thei": [0, 1, 3, 5, 6, 8, 10, 14, 17, 19, 20, 24, 25, 35, 40, 41, 42, 276, 290, 291, 581, 584, 585, 592, 620, 628, 638, 644, 728, 785, 832, 870, 884, 885, 892, 895, 902, 907, 916, 930, 931, 937, 958, 966, 983, 989, 994, 997, 999, 1002, 1007, 1029, 1030, 1031, 1047, 1048, 1049, 1063, 1101, 1109, 1110, 1111, 1116, 1132, 1144, 1167, 1213, 1215, 1314, 1319, 1320, 1381, 1384, 1386, 1387, 1410, 1413, 1420, 1454, 1457, 1480, 1485, 1506, 1523, 1587, 1625, 1629, 1660, 1661, 1674, 1676, 1678, 1679, 1681, 1683, 1685, 1687, 1688, 1689, 1690, 1692, 1694, 1695, 1696, 1699, 1700, 1701, 1706, 1708, 1709, 1711, 1712, 1713, 1715, 1716, 1717, 1719, 1724, 1732, 1734, 1735, 1736, 1738], "don": [0, 1, 4, 6, 8, 10, 20, 34, 42, 105, 622, 623, 636, 755, 989, 1079, 1080, 1081, 1168, 1281, 1314, 1319, 1378, 1423, 1433, 1434, 1540, 1584, 1674, 1676, 1680, 1688, 1689, 1690, 1691, 1696, 1699, 1701, 1702, 1706, 1708, 1712, 1715, 1716, 1717, 1724, 1725, 1738], "t": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 17, 18, 20, 24, 25, 34, 35, 41, 42, 105, 268, 270, 276, 411, 488, 522, 582, 583, 592, 607, 608, 609, 619, 621, 622, 623, 626, 628, 631, 636, 637, 638, 667, 668, 669, 674, 686, 688, 690, 708, 725, 726, 755, 778, 797, 802, 803, 804, 805, 809, 810, 811, 812, 813, 814, 815, 816, 818, 820, 832, 833, 834, 837, 848, 858, 892, 893, 895, 896, 898, 901, 902, 906, 908, 913, 915, 924, 925, 931, 933, 934, 937, 944, 952, 953, 958, 966, 967, 975, 989, 1003, 1004, 1005, 1014, 1033, 1037, 1039, 1044, 1045, 1046, 1053, 1059, 1060, 1068, 1077, 1079, 1080, 1081, 1082, 1086, 1103, 1116, 1131, 1147, 1149, 1159, 1167, 1168, 1184, 1188, 1189, 1190, 1197, 1204, 1205, 1225, 1230, 1249, 1268, 1281, 1314, 1316, 1317, 1319, 1320, 1353, 1374, 1378, 1384, 1389, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1400, 1411, 1413, 1414, 1423, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1443, 1444, 1445, 1446, 1450, 1459, 1465, 1471, 1475, 1505, 1508, 1540, 1559, 1583, 1584, 1593, 1604, 1606, 1625, 1629, 1630, 1633, 1636, 1639, 1645, 1648, 1667, 1668, 1674, 1676, 1677, 1678, 1680, 1687, 1688, 1689, 1690, 1691, 1695, 1696, 1697, 1698, 1699, 1701, 1703, 1705, 1706, 1708, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1724, 1725, 1726, 1727, 1728, 1730, 1731, 1732, 1733, 1734, 1735, 1738], "grad": [0, 1, 5, 20, 24, 40, 42, 105, 290, 411, 440, 447, 448, 455, 456, 610, 619, 622, 623, 629, 630, 632, 637, 638, 728, 785, 870, 878, 895, 967, 1116, 1319, 1420, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1587, 1606, 1660, 1667, 1676, 1677, 1689, 1690, 1695, 1700, 1701, 1703, 1706, 1708, 1713, 1724, 1725, 1727, 1733], "attribut": [0, 1, 10, 17, 18, 20, 21, 25, 42, 105, 245, 447, 448, 619, 622, 624, 628, 832, 894, 895, 896, 898, 899, 905, 906, 967, 1053, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1116, 1159, 1311, 1319, 1320, 1331, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1349, 1357, 1388, 1389, 1390, 1411, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1480, 1481, 1487, 1520, 1521, 1522, 1537, 1538, 1675, 1677, 1680, 1691, 1695, 1696, 1699, 1701, 1706, 1711, 1713, 1716, 1719, 1724, 1733, 1734, 1738, 1739], "unscal": 0, "doe": [0, 1, 3, 4, 5, 6, 7, 8, 12, 20, 23, 24, 26, 28, 32, 34, 35, 37, 40, 41, 42, 105, 209, 290, 411, 568, 590, 591, 610, 656, 719, 723, 771, 781, 785, 834, 869, 894, 896, 899, 905, 910, 920, 925, 937, 938, 942, 943, 950, 956, 958, 964, 967, 983, 985, 989, 990, 997, 1001, 1009, 1034, 1035, 1036, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1056, 1059, 1060, 1063, 1068, 1069, 1079, 1080, 1081, 1086, 1087, 1089, 1090, 1091, 1098, 1099, 1100, 1110, 1111, 1117, 1123, 1126, 1131, 1133, 1155, 1167, 1196, 1248, 1319, 1341, 1350, 1353, 1386, 1389, 1393, 1417, 1420, 1422, 1427, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1460, 1464, 1469, 1479, 1578, 1581, 1585, 1587, 1600, 1604, 1629, 1645, 1648, 1660, 1667, 1673, 1674, 1676, 1678, 1679, 1681, 1685, 1688, 1689, 1690, 1691, 1695, 1697, 1698, 1699, 1700, 1701, 1703, 1706, 1708, 1710, 1713, 1716, 1717, 1719, 1724, 1726, 1727, 1730, 1734], "interfer": [0, 1687, 1699, 1713], "learn": [0, 6, 7, 13, 19, 24, 34, 42, 1037, 1050, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1076, 1101, 1103, 1124, 1145, 1164, 1165, 1265, 1319, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1675, 1683, 1692, 1694, 1704, 1706, 1707, 1713, 1716, 1719, 1724, 1726], "rate": [0, 7, 18, 24, 1055, 1056, 1057, 1061, 1162, 1319, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1468, 1705, 1732], "init_scal": 0, "65536": 0, "0": [0, 1, 3, 10, 12, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 33, 35, 36, 37, 40, 41, 42, 43, 109, 111, 128, 139, 146, 163, 179, 180, 181, 182, 183, 209, 215, 218, 244, 253, 255, 266, 268, 270, 272, 276, 307, 381, 382, 387, 398, 401, 402, 407, 434, 436, 440, 448, 459, 460, 465, 467, 469, 472, 489, 494, 497, 506, 508, 510, 529, 531, 532, 534, 535, 536, 537, 541, 547, 548, 549, 550, 557, 559, 560, 568, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 594, 595, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 627, 630, 631, 632, 634, 637, 638, 641, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 657, 658, 660, 663, 664, 665, 666, 667, 668, 669, 670, 671, 674, 678, 681, 682, 683, 684, 685, 686, 687, 691, 698, 700, 725, 726, 751, 755, 759, 760, 761, 762, 763, 764, 767, 768, 769, 770, 771, 772, 774, 775, 778, 780, 781, 783, 784, 791, 794, 795, 796, 797, 798, 799, 800, 801, 802, 805, 806, 807, 808, 809, 810, 811, 812, 815, 816, 817, 818, 820, 821, 822, 823, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 837, 838, 848, 852, 854, 855, 856, 857, 858, 861, 865, 869, 872, 880, 891, 892, 893, 895, 899, 901, 902, 906, 914, 915, 916, 917, 918, 920, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 936, 937, 938, 939, 940, 941, 946, 947, 948, 949, 951, 952, 953, 954, 956, 961, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 974, 975, 976, 977, 978, 979, 981, 985, 989, 993, 994, 995, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1009, 1011, 1012, 1013, 1014, 1015, 1016, 1018, 1020, 1022, 1023, 1024, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1038, 1039, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1068, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1102, 1104, 1106, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1130, 1131, 1132, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1143, 1147, 1149, 1150, 1151, 1153, 1155, 1158, 1159, 1161, 1163, 1164, 1165, 1167, 1168, 1171, 1178, 1179, 1180, 1181, 1182, 1183, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1211, 1213, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1228, 1229, 1231, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1248, 1249, 1250, 1251, 1252, 1253, 1256, 1257, 1259, 1261, 1262, 1263, 1266, 1268, 1271, 1277, 1278, 1279, 1280, 1281, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1307, 1308, 1309, 1310, 1311, 1314, 1319, 1323, 1324, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1341, 1344, 1345, 1346, 1348, 1349, 1350, 1351, 1353, 1361, 1362, 1363, 1365, 1366, 1367, 1368, 1371, 1373, 1375, 1376, 1378, 1381, 1384, 1385, 1389, 1394, 1395, 1397, 1398, 1399, 1400, 1402, 1403, 1404, 1405, 1406, 1407, 1410, 1411, 1413, 1414, 1415, 1416, 1417, 1419, 1421, 1422, 1423, 1427, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1466, 1468, 1469, 1471, 1472, 1473, 1475, 1476, 1484, 1487, 1488, 1489, 1492, 1493, 1502, 1503, 1504, 1507, 1512, 1513, 1514, 1524, 1527, 1528, 1529, 1530, 1534, 1540, 1544, 1545, 1546, 1547, 1548, 1549, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1560, 1561, 1562, 1563, 1564, 1565, 1568, 1569, 1570, 1571, 1573, 1574, 1578, 1580, 1581, 1584, 1586, 1590, 1593, 1595, 1596, 1597, 1599, 1600, 1603, 1604, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1622, 1623, 1624, 1625, 1626, 1628, 1629, 1631, 1632, 1633, 1634, 1635, 1637, 1638, 1639, 1640, 1641, 1645, 1646, 1648, 1649, 1650, 1651, 1652, 1654, 1655, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1665, 1666, 1667, 1668, 1670, 1672, 1673, 1674, 1676, 1677, 1678, 1679, 1689, 1690, 1691, 1694, 1695, 1696, 1697, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1709, 1710, 1711, 1712, 1713, 1715, 1716, 1717, 1718, 1719, 1721, 1722, 1724, 1725, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1738, 1739], "growth_factor": 0, "backoff_factor": 0, "5": [0, 1, 10, 12, 15, 17, 18, 19, 20, 24, 33, 41, 42, 109, 146, 163, 215, 244, 253, 268, 270, 272, 276, 387, 398, 424, 451, 465, 467, 469, 488, 494, 508, 510, 534, 536, 537, 538, 539, 540, 559, 580, 581, 585, 592, 595, 616, 617, 618, 630, 633, 635, 644, 647, 654, 655, 656, 660, 662, 666, 669, 670, 671, 674, 681, 685, 759, 761, 763, 770, 772, 774, 775, 778, 779, 781, 784, 797, 799, 801, 802, 808, 809, 812, 817, 820, 821, 824, 827, 829, 830, 831, 838, 848, 854, 856, 858, 860, 861, 872, 880, 884, 901, 905, 906, 915, 916, 917, 920, 923, 924, 940, 941, 944, 947, 950, 951, 952, 953, 958, 959, 962, 964, 965, 967, 968, 969, 970, 971, 977, 981, 983, 989, 990, 997, 998, 1002, 1014, 1016, 1018, 1021, 1022, 1023, 1025, 1026, 1027, 1028, 1029, 1033, 1034, 1035, 1036, 1040, 1041, 1042, 1043, 1045, 1046, 1048, 1049, 1050, 1052, 1054, 1055, 1056, 1057, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1068, 1070, 1071, 1072, 1077, 1079, 1080, 1081, 1082, 1083, 1086, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1104, 1107, 1112, 1113, 1116, 1123, 1126, 1130, 1131, 1137, 1138, 1139, 1140, 1141, 1144, 1147, 1153, 1155, 1159, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1179, 1180, 1188, 1189, 1191, 1192, 1196, 1198, 1199, 1200, 1201, 1204, 1205, 1206, 1208, 1209, 1211, 1213, 1216, 1224, 1248, 1250, 1256, 1271, 1281, 1282, 1283, 1319, 1327, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1353, 1355, 1366, 1367, 1389, 1399, 1402, 1404, 1405, 1407, 1412, 1413, 1415, 1421, 1422, 1423, 1425, 1426, 1436, 1443, 1445, 1449, 1455, 1464, 1466, 1468, 1469, 1471, 1472, 1475, 1476, 1546, 1547, 1548, 1549, 1553, 1558, 1559, 1562, 1563, 1569, 1570, 1571, 1578, 1590, 1603, 1607, 1609, 1610, 1611, 1612, 1614, 1617, 1625, 1628, 1629, 1630, 1631, 1632, 1633, 1635, 1637, 1639, 1640, 1641, 1643, 1644, 1646, 1655, 1656, 1660, 1661, 1667, 1668, 1669, 1672, 1676, 1677, 1678, 1679, 1680, 1690, 1691, 1694, 1695, 1696, 1697, 1699, 1701, 1702, 1703, 1706, 1707, 1711, 1712, 1713, 1715, 1717, 1719, 1724, 1727, 1728, 1730, 1732, 1733, 1734], "growth_interv": 0, "2000": [0, 20, 23, 799, 801, 808, 817, 830, 972, 1168, 1452, 1546, 1595, 1639], "get_backoff_factor": 0, "python": [0, 1, 3, 4, 8, 12, 13, 17, 20, 23, 24, 25, 26, 28, 29, 32, 33, 35, 36, 40, 42, 307, 541, 575, 610, 630, 631, 632, 633, 634, 635, 637, 638, 662, 663, 675, 719, 725, 726, 728, 775, 781, 784, 799, 801, 829, 834, 856, 857, 871, 893, 895, 896, 898, 899, 900, 905, 906, 910, 966, 1053, 1117, 1118, 1126, 1127, 1277, 1319, 1374, 1466, 1469, 1547, 1558, 1562, 1565, 1582, 1667, 1674, 1683, 1688, 1690, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1705, 1706, 1708, 1711, 1712, 1716, 1719, 1723, 1724, 1725, 1726, 1733, 1734], "contain": [0, 1, 2, 3, 5, 10, 12, 13, 17, 20, 21, 23, 24, 26, 28, 29, 33, 36, 40, 41, 42, 43, 105, 109, 146, 150, 163, 245, 266, 268, 270, 274, 276, 424, 436, 534, 555, 559, 581, 592, 607, 622, 630, 631, 632, 633, 634, 635, 636, 641, 644, 645, 646, 654, 656, 660, 681, 682, 686, 696, 697, 698, 699, 700, 780, 781, 815, 816, 818, 824, 852, 853, 856, 857, 865, 869, 886, 893, 895, 896, 901, 902, 905, 910, 911, 914, 925, 931, 934, 936, 938, 941, 957, 966, 983, 985, 989, 997, 1007, 1013, 1024, 1033, 1052, 1053, 1059, 1060, 1063, 1068, 1069, 1071, 1076, 1086, 1087, 1108, 1116, 1117, 1118, 1123, 1126, 1131, 1133, 1144, 1148, 1155, 1167, 1196, 1204, 1205, 1207, 1277, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1314, 1316, 1317, 1319, 1353, 1385, 1386, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1401, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1415, 1416, 1419, 1421, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1440, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1465, 1468, 1499, 1519, 1523, 1560, 1574, 1578, 1624, 1625, 1629, 1633, 1641, 1648, 1650, 1652, 1657, 1658, 1663, 1667, 1676, 1678, 1679, 1680, 1687, 1690, 1695, 1696, 1700, 1701, 1702, 1703, 1705, 1706, 1709, 1711, 1713, 1715, 1716, 1717, 1718, 1719, 1721, 1722, 1724, 1726, 1727, 1729, 1730, 1732, 1733, 1735, 1736, 1737, 1738], "backoff": [0, 1724], "get_growth_factor": 0, "growth": [0, 7], "get_growth_interv": 0, "int": [0, 2, 3, 17, 18, 19, 20, 23, 24, 26, 29, 32, 35, 36, 38, 40, 42, 43, 171, 173, 187, 197, 209, 268, 270, 272, 276, 390, 397, 400, 402, 410, 425, 429, 445, 449, 451, 465, 467, 469, 472, 488, 493, 495, 496, 508, 510, 516, 534, 535, 559, 568, 588, 590, 591, 592, 594, 604, 605, 606, 608, 628, 645, 647, 654, 661, 663, 670, 675, 685, 686, 687, 690, 691, 693, 694, 696, 697, 698, 699, 700, 703, 704, 705, 710, 711, 712, 714, 726, 727, 728, 729, 730, 731, 733, 734, 735, 737, 739, 740, 741, 745, 746, 747, 750, 751, 752, 755, 757, 758, 759, 760, 761, 762, 763, 767, 768, 769, 770, 771, 772, 778, 782, 784, 794, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 820, 834, 835, 837, 845, 846, 848, 852, 853, 855, 856, 857, 858, 869, 892, 893, 895, 896, 898, 901, 906, 914, 916, 926, 927, 947, 948, 951, 960, 961, 962, 963, 964, 965, 967, 974, 981, 982, 988, 994, 996, 997, 999, 1002, 1004, 1007, 1012, 1013, 1014, 1015, 1016, 1022, 1023, 1024, 1026, 1027, 1029, 1030, 1031, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1051, 1052, 1053, 1059, 1060, 1063, 1067, 1071, 1084, 1085, 1088, 1092, 1093, 1094, 1095, 1096, 1097, 1106, 1110, 1111, 1112, 1113, 1114, 1116, 1118, 1121, 1123, 1124, 1127, 1128, 1129, 1137, 1138, 1139, 1140, 1141, 1142, 1149, 1151, 1155, 1164, 1166, 1167, 1168, 1169, 1170, 1171, 1195, 1196, 1197, 1204, 1205, 1212, 1215, 1224, 1232, 1248, 1249, 1250, 1254, 1255, 1268, 1269, 1277, 1281, 1282, 1283, 1319, 1349, 1372, 1378, 1379, 1380, 1381, 1382, 1385, 1394, 1395, 1397, 1398, 1400, 1403, 1404, 1405, 1406, 1411, 1413, 1416, 1419, 1422, 1423, 1425, 1426, 1436, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1465, 1466, 1473, 1476, 1544, 1545, 1546, 1547, 1548, 1549, 1551, 1553, 1554, 1555, 1557, 1563, 1564, 1565, 1568, 1569, 1570, 1571, 1580, 1581, 1584, 1588, 1589, 1600, 1603, 1605, 1608, 1609, 1610, 1617, 1620, 1622, 1623, 1624, 1625, 1628, 1630, 1636, 1640, 1641, 1643, 1645, 1646, 1649, 1650, 1651, 1652, 1655, 1656, 1657, 1658, 1659, 1661, 1662, 1663, 1667, 1668, 1672, 1676, 1677, 1678, 1679, 1680, 1687, 1688, 1689, 1694, 1713, 1717, 1718, 1719, 1723, 1724, 1728, 1729, 1730, 1732, 1733, 1734, 1739], "interv": [0, 24, 595, 682, 831, 848, 1460, 1551, 1552, 1687, 1718], "get_scal": [0, 1695], "sync": [0, 20, 23, 40, 41, 42, 1319, 1699, 1700, 1717], "is_en": 0, "indic": [0, 1, 2, 3, 17, 18, 19, 20, 21, 24, 35, 146, 163, 176, 268, 270, 272, 273, 274, 276, 424, 465, 467, 469, 494, 523, 524, 535, 565, 590, 591, 604, 605, 606, 607, 608, 627, 637, 638, 660, 667, 668, 688, 689, 690, 691, 722, 759, 760, 784, 837, 848, 869, 893, 895, 900, 908, 912, 916, 925, 936, 938, 949, 952, 966, 974, 982, 985, 987, 993, 994, 997, 999, 1002, 1007, 1013, 1024, 1025, 1026, 1027, 1052, 1059, 1060, 1064, 1065, 1110, 1111, 1112, 1113, 1114, 1119, 1121, 1122, 1175, 1176, 1177, 1196, 1204, 1205, 1208, 1209, 1225, 1240, 1241, 1242, 1250, 1277, 1319, 1328, 1338, 1339, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1403, 1404, 1421, 1422, 1456, 1458, 1476, 1578, 1603, 1606, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1635, 1636, 1640, 1643, 1649, 1650, 1651, 1652, 1657, 1658, 1660, 1667, 1670, 1676, 1677, 1679, 1683, 1689, 1690, 1701, 1713, 1724, 1727, 1731, 1732, 1734], "load_state_dict": [0, 18, 23, 40, 895, 966, 1116, 1314, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1674, 1706, 1711, 1719], "state_dict": [0, 18, 23, 40, 895, 1116, 1314, 1403, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1439, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1518, 1519, 1674, 1686, 1700, 1706, 1708, 1711, 1713, 1719, 1736], "load": [0, 1, 10, 12, 13, 18, 23, 40, 640, 899, 905, 910, 1060, 1314, 1319, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1439, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1519, 1574, 1676, 1685, 1686, 1690, 1696, 1705, 1706, 1710, 1712, 1713, 1732], "scaler": [0, 1695, 1699], "dict": [0, 3, 5, 18, 20, 21, 23, 24, 40, 42, 725, 726, 747, 893, 894, 895, 896, 901, 906, 910, 911, 966, 967, 1053, 1063, 1116, 1117, 1126, 1167, 1314, 1319, 1400, 1417, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1500, 1518, 1674, 1676, 1677, 1679, 1680, 1686, 1687, 1701, 1706, 1711, 1713, 1715, 1724, 1725, 1732, 1736, 1738], "object": [0, 1, 3, 5, 7, 12, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 35, 37, 40, 41, 42, 43, 161, 164, 555, 610, 621, 641, 643, 707, 717, 756, 781, 820, 832, 834, 881, 882, 895, 901, 902, 905, 906, 910, 911, 926, 947, 951, 964, 966, 967, 988, 998, 1053, 1055, 1056, 1057, 1061, 1079, 1080, 1081, 1116, 1126, 1155, 1319, 1387, 1402, 1411, 1412, 1415, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1439, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1574, 1674, 1678, 1679, 1680, 1683, 1685, 1686, 1688, 1692, 1696, 1698, 1699, 1701, 1702, 1703, 1705, 1708, 1710, 1711, 1712, 1713, 1715, 1719, 1721, 1722, 1723, 1724, 1726, 1729, 1730, 1732, 1734, 1738, 1739], "unmodifi": [0, 20], "iter": [0, 1, 2, 3, 6, 18, 20, 21, 23, 24, 36, 38, 40, 42, 696, 697, 698, 699, 700, 728, 731, 733, 753, 895, 967, 1116, 1117, 1118, 1126, 1127, 1319, 1320, 1381, 1382, 1383, 1385, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1400, 1416, 1418, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1443, 1444, 1445, 1446, 1447, 1450, 1451, 1452, 1455, 1465, 1630, 1677, 1679, 1680, 1688, 1690, 1695, 1696, 1697, 1699, 1700, 1701, 1703, 1706, 1715, 1718, 1723, 1732, 1738], "set_backoff_factor": 0, "new_factor": 0, "new_scal": 0, "set_growth_factor": 0, "set_growth_interv": 0, "new_interv": 0, "It": [0, 1, 3, 4, 5, 6, 7, 14, 17, 18, 20, 21, 24, 26, 28, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 105, 151, 426, 427, 465, 467, 469, 619, 620, 621, 622, 626, 679, 680, 700, 705, 710, 711, 729, 730, 748, 749, 757, 804, 833, 837, 856, 892, 895, 896, 901, 905, 931, 935, 938, 940, 942, 943, 948, 952, 953, 955, 956, 958, 960, 963, 964, 966, 967, 975, 1024, 1033, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1053, 1063, 1110, 1111, 1112, 1113, 1114, 1116, 1123, 1144, 1147, 1167, 1169, 1215, 1225, 1268, 1316, 1317, 1319, 1385, 1386, 1389, 1410, 1413, 1414, 1420, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1440, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1463, 1549, 1562, 1578, 1587, 1593, 1608, 1656, 1667, 1674, 1678, 1679, 1687, 1688, 1690, 1696, 1698, 1699, 1700, 1701, 1702, 1703, 1705, 1706, 1707, 1708, 1709, 1710, 1712, 1713, 1715, 1716, 1717, 1719, 1724, 1725, 1726, 1728, 1729, 1731, 1735], "five": [0, 1679, 1711], "entri": [0, 3, 20, 21, 23, 24, 33, 35, 36, 40, 270, 534, 641, 725, 726, 770, 822, 823, 869, 895, 915, 1059, 1060, 1116, 1122, 1204, 1205, 1318, 1328, 1395, 1396, 1404, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1440, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1537, 1538, 1608, 1676, 1679, 1680, 1691, 1696, 1700, 1701, 1703, 1706, 1719, 1727, 1732, 1736], "_growth_track": 0, "number": [0, 1, 2, 3, 4, 5, 6, 12, 17, 18, 20, 23, 24, 26, 33, 34, 35, 38, 40, 42, 43, 109, 128, 173, 187, 209, 268, 307, 331, 353, 357, 399, 424, 426, 427, 434, 445, 449, 451, 465, 467, 469, 493, 495, 496, 508, 535, 541, 560, 568, 580, 581, 582, 583, 584, 585, 586, 593, 595, 607, 620, 637, 644, 646, 647, 656, 658, 662, 670, 671, 675, 681, 685, 686, 693, 697, 706, 714, 715, 726, 728, 729, 730, 739, 748, 749, 752, 753, 772, 775, 777, 780, 781, 782, 786, 794, 824, 826, 829, 834, 836, 837, 839, 845, 846, 847, 848, 851, 855, 856, 857, 869, 871, 893, 895, 908, 915, 918, 919, 926, 940, 949, 958, 962, 967, 972, 984, 988, 997, 1006, 1007, 1011, 1015, 1017, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1029, 1030, 1031, 1032, 1033, 1034, 1037, 1038, 1039, 1040, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1058, 1059, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1082, 1083, 1086, 1087, 1092, 1093, 1094, 1095, 1096, 1097, 1102, 1103, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1115, 1116, 1119, 1120, 1121, 1122, 1123, 1124, 1130, 1131, 1133, 1134, 1135, 1136, 1143, 1145, 1146, 1147, 1148, 1149, 1151, 1152, 1153, 1154, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1180, 1181, 1182, 1184, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1196, 1197, 1204, 1205, 1208, 1209, 1214, 1224, 1225, 1227, 1230, 1237, 1238, 1239, 1248, 1250, 1256, 1257, 1314, 1319, 1351, 1353, 1361, 1362, 1365, 1366, 1367, 1374, 1385, 1389, 1394, 1395, 1397, 1398, 1400, 1403, 1404, 1405, 1406, 1410, 1411, 1412, 1414, 1416, 1421, 1422, 1423, 1425, 1426, 1436, 1449, 1450, 1451, 1452, 1455, 1456, 1458, 1459, 1465, 1468, 1472, 1501, 1549, 1551, 1552, 1553, 1555, 1556, 1557, 1562, 1564, 1565, 1568, 1569, 1570, 1571, 1579, 1582, 1586, 1588, 1589, 1590, 1591, 1604, 1607, 1609, 1611, 1612, 1613, 1614, 1615, 1616, 1621, 1622, 1625, 1626, 1630, 1640, 1641, 1642, 1650, 1652, 1657, 1658, 1661, 1664, 1665, 1666, 1672, 1675, 1677, 1678, 1679, 1680, 1681, 1687, 1688, 1694, 1697, 1699, 1701, 1703, 1706, 1709, 1711, 1713, 1715, 1716, 1717, 1718, 1720, 1723, 1724, 1725, 1727, 1728, 1729, 1730, 1732, 1733, 1734, 1735, 1739], "recent": [0, 1, 6, 7, 38, 41, 870, 880, 1678, 1679, 1691, 1701, 1709, 1710, 1734], "consecut": [0, 20, 562, 1412, 1448, 1646, 1657, 1658, 1690, 1713], "unskip": 0, "empti": [0, 3, 20, 26, 33, 40, 42, 276, 465, 467, 488, 495, 646, 647, 657, 663, 780, 781, 783, 893, 896, 920, 940, 941, 946, 953, 976, 977, 978, 979, 987, 1032, 1033, 1052, 1060, 1123, 1186, 1205, 1251, 1415, 1427, 1614, 1629, 1633, 1639, 1673, 1676, 1677, 1678, 1679, 1681, 1685, 1689, 1690, 1694, 1697, 1699, 1701, 1713, 1714, 1716, 1727, 1728, 1735], "wish": [0, 1695, 1701], "checkpoint": [0, 23, 36, 38, 40, 640, 966, 1319, 1674, 1675, 1686, 1702, 1717, 1726], "kwarg": [0, 1, 5, 12, 20, 21, 23, 35, 40, 42, 531, 555, 620, 690, 691, 725, 726, 895, 898, 900, 958, 985, 1068, 1078, 1086, 1116, 1131, 1175, 1176, 1177, 1208, 1209, 1314, 1318, 1319, 1353, 1355, 1356, 1391, 1396, 1400, 1410, 1415, 1417, 1485, 1503, 1504, 1506, 1509, 1574, 1658, 1674, 1679, 1680, 1701, 1706, 1713, 1724, 1729, 1738], "carri": [0, 291, 1482, 1520, 1521, 1536, 1537, 1697, 1719], "out": [0, 1, 2, 3, 6, 7, 8, 10, 13, 17, 19, 20, 24, 32, 33, 36, 40, 42, 267, 269, 271, 273, 354, 356, 401, 448, 464, 466, 468, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 588, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 607, 611, 612, 613, 614, 615, 623, 624, 625, 628, 637, 644, 646, 647, 648, 649, 650, 651, 652, 653, 656, 660, 663, 665, 666, 667, 668, 669, 671, 672, 674, 677, 678, 680, 681, 683, 684, 687, 696, 698, 700, 726, 727, 739, 740, 751, 755, 759, 760, 761, 762, 764, 767, 772, 773, 775, 776, 777, 779, 780, 781, 782, 786, 788, 789, 790, 791, 792, 793, 794, 797, 798, 799, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 824, 825, 826, 827, 828, 829, 830, 831, 834, 835, 837, 838, 839, 840, 841, 849, 850, 851, 854, 855, 856, 857, 859, 860, 861, 862, 863, 864, 866, 867, 868, 869, 870, 872, 873, 889, 890, 895, 906, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 941, 942, 943, 944, 945, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 963, 964, 965, 968, 969, 970, 971, 972, 973, 974, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 989, 990, 992, 993, 994, 995, 996, 997, 999, 1000, 1001, 1002, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1017, 1018, 1019, 1020, 1021, 1025, 1026, 1027, 1029, 1030, 1031, 1037, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1054, 1055, 1056, 1057, 1059, 1061, 1064, 1065, 1068, 1069, 1084, 1085, 1086, 1101, 1103, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1128, 1129, 1131, 1133, 1137, 1138, 1139, 1140, 1141, 1142, 1159, 1160, 1161, 1162, 1163, 1167, 1168, 1169, 1170, 1171, 1184, 1188, 1189, 1190, 1191, 1192, 1193, 1199, 1200, 1201, 1206, 1209, 1213, 1224, 1230, 1249, 1251, 1281, 1319, 1349, 1353, 1357, 1365, 1366, 1367, 1372, 1374, 1378, 1394, 1395, 1396, 1397, 1421, 1422, 1423, 1424, 1426, 1427, 1463, 1464, 1468, 1469, 1470, 1472, 1475, 1476, 1482, 1518, 1520, 1521, 1536, 1537, 1549, 1550, 1551, 1553, 1555, 1557, 1558, 1561, 1562, 1563, 1567, 1571, 1572, 1573, 1575, 1576, 1577, 1578, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1603, 1606, 1607, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1626, 1627, 1629, 1633, 1636, 1637, 1638, 1641, 1643, 1645, 1648, 1649, 1651, 1653, 1654, 1660, 1662, 1663, 1664, 1667, 1669, 1670, 1671, 1672, 1673, 1674, 1676, 1677, 1679, 1687, 1688, 1690, 1696, 1697, 1699, 1700, 1701, 1706, 1708, 1713, 1716, 1719, 1720, 1722, 1724, 1725, 1726, 1727, 1728, 1730, 1732, 1733, 1738], "follow": [0, 1, 2, 3, 6, 8, 10, 12, 13, 15, 16, 17, 18, 19, 20, 23, 24, 26, 32, 33, 34, 35, 36, 40, 42, 440, 568, 619, 620, 621, 624, 660, 725, 739, 780, 781, 799, 801, 834, 848, 895, 896, 904, 908, 915, 926, 937, 947, 950, 951, 964, 967, 987, 990, 1024, 1033, 1039, 1060, 1063, 1068, 1086, 1116, 1122, 1131, 1147, 1163, 1167, 1232, 1316, 1317, 1318, 1319, 1353, 1372, 1378, 1384, 1422, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1455, 1458, 1465, 1476, 1485, 1499, 1501, 1502, 1503, 1504, 1506, 1507, 1578, 1605, 1606, 1607, 1614, 1625, 1646, 1660, 1674, 1676, 1677, 1678, 1679, 1680, 1681, 1685, 1686, 1688, 1689, 1690, 1691, 1694, 1695, 1696, 1697, 1698, 1699, 1701, 1702, 1703, 1706, 1708, 1709, 1710, 1711, 1712, 1713, 1715, 1716, 1717, 1719, 1720, 1722, 1724, 1725, 1726, 1727, 1728, 1730, 1731, 1733, 1734, 1738, 1739], "two": [0, 1, 3, 4, 7, 10, 12, 13, 17, 18, 20, 21, 23, 24, 26, 32, 33, 35, 36, 40, 42, 559, 568, 587, 589, 617, 632, 637, 664, 666, 691, 695, 731, 733, 759, 760, 768, 777, 781, 787, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 827, 828, 856, 858, 884, 893, 895, 905, 908, 915, 918, 920, 925, 927, 930, 931, 936, 937, 942, 947, 950, 951, 953, 954, 956, 958, 963, 966, 990, 994, 997, 999, 1002, 1014, 1030, 1032, 1033, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1063, 1068, 1076, 1077, 1083, 1085, 1086, 1107, 1108, 1110, 1116, 1119, 1120, 1121, 1123, 1124, 1130, 1131, 1147, 1148, 1163, 1164, 1165, 1167, 1185, 1186, 1196, 1215, 1225, 1232, 1248, 1256, 1353, 1384, 1389, 1411, 1419, 1421, 1422, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1440, 1443, 1444, 1445, 1446, 1447, 1451, 1452, 1454, 1458, 1476, 1558, 1571, 1609, 1614, 1629, 1641, 1646, 1648, 1664, 1668, 1674, 1676, 1678, 1679, 1683, 1689, 1690, 1696, 1697, 1698, 1699, 1700, 1701, 1703, 1706, 1711, 1712, 1713, 1715, 1716, 1717, 1719, 1720, 1724, 1725, 1726, 1727, 1728, 1732, 1733, 1734, 1736, 1737], "unscale_": [0, 1695], "unless": [0, 1, 4, 6, 18, 20, 37, 40, 42, 105, 451, 626, 647, 895, 938, 943, 956, 997, 1070, 1116, 1163, 1317, 1400, 1441, 1522, 1537, 1578, 1660, 1679, 1696, 1699, 1710, 1713, 1716, 1720], "explicitli": [0, 7, 12, 20, 28, 719, 768, 770, 781, 857, 935, 948, 952, 960, 1004, 1224, 1281, 1458, 1625, 1676, 1678, 1679, 1680, 1699, 1701, 1703, 1705, 1711, 1713, 1716, 1717, 1723, 1724, 1727], "earlier": [0, 1, 19, 1629, 1699, 1702, 1705, 1711, 1713, 1718], "part": [0, 3, 4, 5, 6, 8, 12, 13, 18, 20, 24, 35, 36, 40, 42, 636, 677, 780, 781, 885, 887, 888, 891, 895, 905, 907, 910, 911, 925, 931, 933, 942, 949, 952, 1116, 1155, 1319, 1387, 1450, 1476, 1523, 1610, 1646, 1649, 1650, 1651, 1652, 1674, 1675, 1676, 1678, 1679, 1685, 1686, 1695, 1696, 1699, 1701, 1702, 1703, 1706, 1711, 1713, 1716, 1717, 1719, 1724, 1725, 1726, 1727, 1732, 1734], "check": [0, 4, 10, 12, 17, 20, 21, 24, 26, 35, 40, 176, 295, 451, 589, 626, 628, 629, 637, 638, 689, 690, 691, 695, 721, 882, 892, 895, 910, 911, 924, 925, 930, 931, 933, 936, 938, 943, 949, 952, 956, 958, 959, 985, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1116, 1314, 1319, 1386, 1389, 1402, 1412, 1674, 1678, 1679, 1680, 1689, 1690, 1695, 1699, 1701, 1702, 1705, 1706, 1707, 1710, 1713, 1715, 1716, 1717, 1724, 1732, 1734, 1738], "inf": [0, 24, 40, 579, 581, 584, 585, 586, 615, 644, 660, 884, 885, 887, 889, 890, 926, 941, 947, 951, 954, 964, 975, 1011, 1106, 1149, 1159, 1381, 1395, 1404, 1422, 1571, 1578, 1695, 1696, 1709, 1728, 1734], "nan": [0, 1, 24, 381, 382, 579, 581, 584, 585, 586, 589, 592, 593, 611, 615, 644, 660, 827, 828, 829, 884, 885, 887, 888, 934, 941, 954, 957, 970, 975, 995, 996, 1000, 1011, 1012, 1013, 1014, 1015, 1213, 1381, 1469, 1573, 1578, 1618, 1648, 1677, 1695, 1696, 1728, 1734], "found": [0, 6, 13, 19, 35, 42, 660, 687, 759, 760, 895, 899, 916, 994, 997, 999, 1002, 1013, 1028, 1038, 1061, 1116, 1143, 1538, 1578, 1674, 1676, 1679, 1691, 1695, 1701, 1703, 1706, 1708, 1713, 1716, 1718, 1719, 1724, 1732, 1738], "otherwis": [0, 1, 3, 5, 6, 8, 10, 12, 17, 20, 21, 25, 28, 40, 42, 43, 164, 276, 283, 287, 291, 293, 297, 298, 447, 456, 510, 531, 532, 555, 568, 581, 582, 583, 584, 585, 588, 590, 591, 592, 594, 595, 624, 632, 637, 644, 660, 723, 780, 787, 820, 832, 886, 895, 898, 901, 907, 916, 940, 955, 964, 966, 967, 982, 988, 994, 996, 997, 999, 1002, 1012, 1015, 1030, 1031, 1050, 1052, 1055, 1056, 1057, 1061, 1068, 1072, 1073, 1074, 1075, 1077, 1086, 1102, 1116, 1120, 1121, 1122, 1123, 1124, 1126, 1131, 1132, 1134, 1147, 1153, 1155, 1158, 1159, 1161, 1163, 1164, 1165, 1181, 1182, 1215, 1217, 1218, 1222, 1257, 1266, 1319, 1328, 1353, 1361, 1362, 1377, 1384, 1389, 1410, 1414, 1420, 1441, 1463, 1465, 1473, 1475, 1502, 1503, 1549, 1558, 1565, 1578, 1585, 1593, 1623, 1624, 1625, 1628, 1633, 1656, 1657, 1658, 1662, 1663, 1670, 1674, 1676, 1678, 1679, 1685, 1689, 1695, 1701, 1708, 1713, 1720, 1722, 1723, 1724, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1734, 1738], "skip": [0, 35, 834, 924, 925, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1538, 1600, 1676, 1695, 1696, 1699, 1700, 1701, 1706, 1715, 1718], "avoid": [0, 7, 8, 17, 24, 33, 36, 40, 42, 43, 146, 163, 401, 595, 622, 657, 739, 895, 940, 966, 1051, 1082, 1083, 1107, 1116, 1125, 1130, 1167, 1195, 1225, 1249, 1256, 1319, 1374, 1385, 1564, 1592, 1625, 1639, 1657, 1687, 1690, 1696, 1698, 1699, 1702, 1703, 1706, 1717, 1724, 1725, 1731, 1732, 1733], "corrupt": [0, 20, 35, 1053, 1699, 1708], "param": [0, 1, 23, 24, 27, 35, 40, 42, 895, 913, 1116, 1126, 1127, 1319, 1357, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1442, 1443, 1444, 1445, 1446, 1447, 1459, 1500, 1567, 1677, 1683, 1685, 1694, 1695, 1699, 1700, 1715, 1738], "appli": [0, 1, 3, 5, 7, 18, 23, 24, 26, 28, 35, 40, 42, 74, 276, 353, 425, 465, 469, 626, 628, 629, 637, 649, 652, 681, 768, 770, 775, 785, 797, 798, 800, 801, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 829, 895, 899, 944, 967, 985, 1021, 1022, 1023, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1058, 1064, 1065, 1066, 1067, 1068, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1088, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1115, 1116, 1119, 1120, 1121, 1123, 1124, 1130, 1131, 1134, 1135, 1136, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1159, 1164, 1165, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1206, 1208, 1209, 1210, 1211, 1214, 1216, 1217, 1218, 1219, 1223, 1224, 1225, 1227, 1228, 1230, 1231, 1232, 1233, 1234, 1235, 1237, 1238, 1239, 1243, 1248, 1256, 1257, 1258, 1259, 1263, 1264, 1265, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1314, 1318, 1319, 1331, 1332, 1333, 1334, 1335, 1336, 1351, 1353, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1373, 1374, 1375, 1376, 1377, 1384, 1385, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1410, 1411, 1416, 1417, 1419, 1420, 1422, 1431, 1447, 1459, 1472, 1495, 1496, 1497, 1498, 1522, 1537, 1544, 1545, 1546, 1547, 1548, 1587, 1605, 1608, 1625, 1657, 1658, 1659, 1676, 1679, 1688, 1690, 1695, 1696, 1699, 1701, 1703, 1706, 1709, 1713, 1715, 1716, 1717, 1719, 1722, 1725, 1727, 1728], "argument": [0, 1, 3, 4, 5, 7, 8, 12, 17, 20, 21, 23, 24, 26, 33, 36, 38, 40, 41, 42, 43, 105, 151, 164, 268, 276, 440, 465, 469, 510, 531, 555, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 588, 590, 591, 592, 593, 594, 595, 610, 611, 612, 613, 614, 615, 619, 620, 621, 622, 626, 627, 628, 631, 633, 634, 635, 636, 644, 645, 646, 648, 649, 650, 651, 652, 653, 654, 656, 660, 663, 665, 666, 667, 668, 669, 671, 673, 674, 677, 680, 681, 683, 684, 686, 687, 705, 707, 710, 711, 717, 725, 726, 728, 750, 754, 759, 760, 761, 762, 763, 764, 767, 768, 769, 770, 771, 772, 775, 777, 778, 779, 780, 782, 783, 784, 786, 791, 794, 797, 798, 799, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 824, 825, 826, 827, 828, 829, 831, 834, 835, 836, 837, 838, 839, 840, 848, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 869, 872, 889, 890, 892, 895, 898, 906, 910, 911, 914, 915, 916, 917, 918, 919, 920, 923, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 976, 977, 978, 979, 981, 982, 983, 984, 986, 987, 989, 990, 993, 994, 995, 996, 997, 999, 1000, 1001, 1002, 1005, 1006, 1007, 1009, 1011, 1012, 1013, 1014, 1015, 1017, 1018, 1020, 1034, 1035, 1036, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1060, 1063, 1066, 1068, 1075, 1078, 1079, 1080, 1081, 1082, 1086, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1112, 1113, 1114, 1116, 1117, 1122, 1123, 1124, 1131, 1155, 1163, 1167, 1169, 1170, 1211, 1213, 1249, 1314, 1316, 1317, 1318, 1319, 1327, 1331, 1332, 1333, 1334, 1335, 1336, 1388, 1389, 1391, 1395, 1396, 1400, 1404, 1410, 1417, 1421, 1423, 1426, 1427, 1452, 1463, 1464, 1468, 1469, 1472, 1473, 1475, 1476, 1484, 1485, 1506, 1523, 1536, 1537, 1542, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1561, 1562, 1563, 1564, 1571, 1573, 1578, 1587, 1593, 1595, 1596, 1597, 1599, 1603, 1607, 1609, 1611, 1612, 1613, 1614, 1615, 1616, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1626, 1628, 1629, 1633, 1636, 1637, 1638, 1639, 1641, 1642, 1643, 1646, 1648, 1649, 1650, 1651, 1652, 1654, 1657, 1660, 1662, 1663, 1667, 1668, 1669, 1672, 1673, 1674, 1677, 1678, 1679, 1681, 1683, 1688, 1689, 1690, 1691, 1695, 1696, 1697, 1699, 1700, 1701, 1702, 1703, 1705, 1710, 1713, 1715, 1716, 1717, 1718, 1719, 1720, 1722, 1723, 1724, 1727, 1728, 1729, 1730, 1732, 1734, 1738, 1739], "keyword": [0, 1, 5, 17, 20, 21, 23, 42, 43, 268, 276, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 588, 590, 591, 592, 593, 594, 595, 610, 611, 612, 613, 614, 615, 644, 645, 646, 648, 649, 650, 651, 652, 653, 654, 656, 660, 663, 665, 667, 668, 669, 671, 673, 674, 677, 680, 681, 683, 684, 686, 687, 696, 698, 700, 725, 726, 728, 759, 760, 761, 762, 763, 764, 767, 772, 775, 777, 779, 780, 782, 783, 784, 786, 791, 794, 797, 798, 799, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 824, 825, 826, 827, 828, 829, 831, 834, 835, 836, 837, 838, 839, 840, 848, 851, 852, 853, 854, 855, 856, 857, 859, 860, 861, 869, 872, 889, 890, 895, 898, 910, 911, 914, 915, 916, 917, 918, 919, 920, 923, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 968, 969, 970, 971, 972, 973, 974, 976, 977, 978, 979, 981, 982, 983, 984, 986, 987, 989, 990, 993, 994, 995, 996, 997, 999, 1000, 1001, 1002, 1005, 1006, 1007, 1009, 1011, 1012, 1013, 1014, 1015, 1017, 1018, 1020, 1053, 1075, 1078, 1116, 1316, 1317, 1319, 1389, 1391, 1396, 1400, 1417, 1421, 1423, 1426, 1427, 1463, 1464, 1468, 1469, 1472, 1473, 1475, 1476, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1561, 1562, 1563, 1564, 1571, 1573, 1578, 1593, 1595, 1596, 1597, 1599, 1603, 1607, 1609, 1611, 1612, 1613, 1614, 1615, 1616, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1626, 1628, 1629, 1633, 1636, 1637, 1638, 1639, 1643, 1646, 1648, 1649, 1650, 1651, 1652, 1654, 1660, 1662, 1663, 1664, 1669, 1672, 1673, 1674, 1679, 1680, 1690, 1691, 1701, 1713, 1715, 1724, 1728, 1732, 1738], "closur": [0, 23, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1441, 1443, 1444, 1445, 1447], "divid": [0, 5, 18, 20, 23, 192, 700, 775, 778, 799, 817, 826, 857, 858, 905, 1032, 1033, 1039, 1040, 1050, 1076, 1077, 1083, 1107, 1108, 1119, 1120, 1121, 1130, 1147, 1148, 1164, 1165, 1185, 1186, 1196, 1197, 1225, 1248, 1256, 1319, 1629, 1668, 1677], "case": [0, 1, 3, 4, 7, 8, 10, 12, 13, 17, 18, 20, 23, 24, 26, 27, 28, 35, 37, 38, 40, 41, 42, 105, 109, 151, 307, 448, 451, 595, 622, 630, 632, 636, 645, 647, 681, 687, 708, 729, 730, 748, 749, 750, 781, 802, 804, 812, 813, 814, 829, 854, 880, 893, 896, 904, 907, 908, 910, 924, 926, 927, 930, 931, 935, 940, 941, 942, 944, 950, 953, 958, 960, 964, 966, 967, 972, 975, 983, 985, 997, 1007, 1024, 1029, 1030, 1031, 1032, 1033, 1044, 1045, 1046, 1048, 1049, 1050, 1052, 1055, 1056, 1057, 1058, 1060, 1061, 1063, 1072, 1073, 1074, 1075, 1076, 1077, 1083, 1084, 1085, 1102, 1107, 1109, 1110, 1111, 1122, 1123, 1124, 1134, 1147, 1153, 1158, 1163, 1165, 1167, 1178, 1196, 1205, 1213, 1217, 1218, 1248, 1250, 1257, 1319, 1321, 1322, 1353, 1377, 1384, 1386, 1389, 1390, 1421, 1422, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1458, 1481, 1502, 1503, 1505, 1508, 1537, 1562, 1565, 1578, 1593, 1629, 1630, 1656, 1660, 1667, 1670, 1674, 1679, 1688, 1689, 1690, 1694, 1695, 1696, 1697, 1698, 1699, 1701, 1702, 1703, 1706, 1708, 1709, 1711, 1713, 1716, 1717, 1719, 1720, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1731, 1732, 1733, 1734, 1738, 1739], "need": [0, 1, 3, 5, 6, 7, 8, 12, 13, 17, 18, 19, 20, 21, 23, 24, 27, 28, 33, 35, 36, 38, 40, 42, 105, 209, 424, 447, 451, 619, 622, 626, 627, 636, 657, 658, 666, 719, 728, 735, 768, 770, 781, 802, 804, 824, 895, 989, 1007, 1059, 1112, 1113, 1114, 1116, 1122, 1159, 1161, 1163, 1188, 1189, 1190, 1280, 1319, 1327, 1328, 1389, 1391, 1395, 1397, 1423, 1485, 1506, 1523, 1537, 1559, 1564, 1578, 1622, 1633, 1646, 1675, 1676, 1678, 1679, 1685, 1688, 1690, 1691, 1696, 1698, 1699, 1700, 1701, 1702, 1703, 1705, 1708, 1710, 1711, 1712, 1713, 1715, 1716, 1717, 1719, 1722, 1724, 1725, 1726, 1727, 1729, 1730, 1734, 1737, 1738], "modifi": [0, 1, 17, 18, 20, 21, 23, 40, 42, 215, 440, 626, 628, 629, 679, 680, 848, 892, 895, 898, 899, 914, 1059, 1116, 1159, 1161, 1163, 1204, 1205, 1316, 1317, 1318, 1319, 1381, 1382, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1441, 1446, 1450, 1458, 1480, 1481, 1520, 1521, 1522, 1676, 1679, 1689, 1695, 1696, 1699, 1701, 1706, 1711, 1713, 1714, 1716, 1717, 1719, 1724, 1728, 1731, 1733, 1737], "inspect": [0, 1, 20, 42, 640, 895, 906, 1695, 1701, 1705, 1716, 1720, 1730, 1738], "between": [0, 1, 2, 3, 6, 18, 20, 24, 25, 35, 36, 37, 40, 41, 42, 151, 465, 559, 568, 584, 585, 586, 590, 591, 595, 614, 622, 624, 631, 633, 634, 635, 637, 638, 664, 686, 689, 695, 741, 758, 763, 781, 797, 798, 799, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 832, 848, 855, 892, 895, 906, 930, 931, 953, 958, 1014, 1032, 1033, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1051, 1052, 1055, 1056, 1057, 1061, 1063, 1077, 1083, 1092, 1093, 1094, 1095, 1096, 1097, 1107, 1109, 1110, 1111, 1116, 1119, 1120, 1121, 1125, 1144, 1147, 1148, 1149, 1164, 1165, 1167, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1195, 1196, 1212, 1237, 1238, 1239, 1253, 1268, 1319, 1365, 1366, 1367, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1400, 1403, 1404, 1405, 1406, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1440, 1443, 1444, 1445, 1446, 1447, 1451, 1452, 1458, 1459, 1468, 1476, 1487, 1536, 1538, 1547, 1548, 1553, 1554, 1558, 1582, 1622, 1625, 1629, 1646, 1676, 1678, 1679, 1680, 1688, 1695, 1696, 1698, 1699, 1703, 1704, 1706, 1708, 1710, 1711, 1713, 1715, 1717, 1719, 1720, 1724, 1726, 1729, 1732, 1736], "dure": [0, 1, 5, 12, 18, 20, 26, 27, 29, 35, 40, 41, 42, 290, 455, 456, 619, 620, 628, 727, 728, 740, 741, 758, 905, 907, 908, 910, 966, 1028, 1034, 1035, 1036, 1053, 1054, 1059, 1060, 1079, 1080, 1081, 1155, 1161, 1163, 1198, 1204, 1205, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1314, 1319, 1321, 1322, 1415, 1460, 1509, 1610, 1650, 1652, 1678, 1685, 1687, 1689, 1695, 1696, 1698, 1699, 1700, 1701, 1703, 1705, 1706, 1709, 1710, 1713, 1714, 1716, 1718, 1719, 1722, 1724, 1726, 1734], "simpl": [0, 13, 18, 19, 28, 35, 42, 686, 739, 895, 899, 906, 1034, 1035, 1036, 1059, 1089, 1090, 1091, 1116, 1155, 1204, 1667, 1674, 1676, 1680, 1691, 1698, 1699, 1700, 1701, 1702, 1703, 1705, 1713, 1716, 1724], "clip": [0, 40, 682, 1381, 1382, 1677, 1713], "util": [0, 6, 14, 19, 36, 40, 41, 42, 700, 832, 895, 1068, 1086, 1116, 1131, 1315, 1316, 1317, 1318, 1319, 1325, 1328, 1331, 1332, 1333, 1338, 1339, 1349, 1353, 1357, 1386, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1410, 1452, 1458, 1479, 1483, 1675, 1679, 1687, 1695, 1697, 1698, 1699, 1701, 1702, 1703, 1705, 1706, 1713, 1715, 1716, 1717], "clip_grad_norm_": [0, 40, 1695], "max_norm": [0, 40, 1059, 1060, 1204, 1205, 1338, 1339, 1381, 1677, 1695], "own": [0, 6, 8, 20, 21, 23, 24, 27, 35, 37, 40, 42, 717, 815, 834, 857, 895, 966, 1044, 1045, 1046, 1047, 1048, 1049, 1116, 1386, 1389, 1667, 1679, 1692, 1695, 1699, 1716, 1719, 1720, 1724, 1726], "onc": [0, 1, 6, 8, 13, 17, 18, 20, 21, 23, 24, 25, 27, 28, 35, 40, 41, 42, 626, 627, 628, 630, 632, 781, 895, 899, 966, 1053, 1116, 1319, 1387, 1389, 1456, 1459, 1475, 1588, 1592, 1676, 1679, 1685, 1687, 1688, 1695, 1696, 1698, 1699, 1701, 1703, 1705, 1706, 1715, 1716, 1732], "all": [0, 1, 2, 3, 5, 6, 8, 10, 12, 13, 17, 18, 19, 20, 21, 23, 24, 26, 28, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 105, 215, 268, 270, 276, 290, 439, 465, 467, 469, 496, 510, 534, 559, 562, 568, 581, 582, 587, 589, 593, 594, 604, 607, 619, 620, 621, 622, 623, 626, 627, 628, 630, 631, 632, 633, 634, 635, 636, 637, 638, 641, 642, 643, 646, 655, 657, 662, 663, 667, 670, 671, 675, 685, 689, 690, 691, 692, 698, 699, 708, 715, 719, 725, 728, 729, 730, 738, 739, 745, 746, 748, 749, 753, 755, 757, 780, 798, 799, 800, 801, 804, 807, 808, 811, 814, 816, 818, 834, 837, 857, 860, 891, 892, 895, 902, 905, 906, 909, 910, 930, 957, 966, 982, 985, 994, 996, 999, 1012, 1013, 1014, 1015, 1024, 1031, 1033, 1037, 1039, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1053, 1059, 1060, 1063, 1068, 1069, 1070, 1071, 1076, 1082, 1083, 1086, 1087, 1103, 1107, 1111, 1112, 1113, 1114, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1126, 1127, 1131, 1133, 1137, 1138, 1139, 1140, 1141, 1142, 1155, 1159, 1161, 1163, 1164, 1167, 1171, 1178, 1184, 1205, 1210, 1215, 1234, 1235, 1268, 1314, 1315, 1316, 1317, 1318, 1319, 1328, 1353, 1381, 1384, 1389, 1396, 1400, 1410, 1414, 1421, 1422, 1423, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1440, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1452, 1455, 1456, 1459, 1460, 1461, 1473, 1480, 1481, 1499, 1500, 1522, 1537, 1608, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1620, 1622, 1623, 1624, 1625, 1628, 1633, 1640, 1642, 1649, 1650, 1651, 1652, 1655, 1658, 1662, 1663, 1665, 1669, 1674, 1676, 1677, 1678, 1679, 1685, 1687, 1688, 1689, 1690, 1691, 1694, 1695, 1696, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1706, 1708, 1709, 1710, 1711, 1712, 1714, 1716, 1717, 1718, 1719, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1732, 1734, 1736, 1737, 1738], "assign": [0, 1, 6, 8, 9, 17, 20, 26, 35, 36, 42, 893, 896, 1024, 1052, 1116, 1123, 1126, 1127, 1320, 1389, 1520, 1521, 1522, 1676, 1680, 1695, 1701, 1702, 1713, 1719, 1725, 1726, 1731, 1732], "been": [0, 1, 10, 17, 18, 19, 20, 21, 23, 24, 28, 35, 38, 40, 42, 626, 690, 691, 721, 724, 779, 785, 898, 899, 904, 909, 966, 1068, 1075, 1086, 1131, 1178, 1213, 1319, 1353, 1386, 1391, 1395, 1397, 1415, 1416, 1430, 1450, 1451, 1452, 1458, 1459, 1475, 1625, 1669, 1687, 1688, 1689, 1690, 1695, 1696, 1698, 1699, 1703, 1704, 1706, 1708, 1710, 1712, 1713, 1715, 1716, 1724, 1726, 1727, 1732], "accumul": [0, 1, 2, 40, 105, 245, 268, 273, 274, 276, 424, 581, 622, 636, 964, 1319, 1431, 1432, 1660, 1676, 1677, 1687, 1696, 1699, 1700, 1702, 1709, 1715, 1720, 1724, 1725, 1727], "twice": [0, 41, 568, 631, 1695, 1696, 1702, 1703], "given": [0, 1, 2, 3, 6, 8, 12, 17, 18, 20, 21, 23, 24, 26, 33, 35, 37, 40, 41, 42, 105, 174, 268, 270, 272, 276, 281, 331, 353, 357, 425, 426, 427, 428, 429, 431, 465, 467, 469, 534, 536, 537, 556, 559, 588, 590, 591, 593, 594, 595, 606, 619, 621, 622, 624, 626, 628, 630, 631, 632, 633, 634, 635, 638, 646, 647, 650, 658, 662, 663, 669, 670, 675, 680, 682, 685, 686, 687, 689, 690, 691, 692, 693, 703, 704, 707, 710, 711, 727, 731, 733, 734, 735, 737, 739, 740, 741, 745, 746, 747, 756, 757, 758, 765, 767, 772, 781, 797, 798, 799, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 821, 861, 892, 895, 902, 910, 911, 916, 920, 930, 932, 933, 942, 944, 950, 958, 967, 974, 976, 977, 978, 979, 982, 983, 994, 996, 998, 999, 1002, 1015, 1024, 1032, 1033, 1039, 1044, 1045, 1046, 1048, 1049, 1050, 1052, 1053, 1059, 1060, 1064, 1065, 1068, 1076, 1086, 1108, 1112, 1113, 1114, 1116, 1118, 1120, 1121, 1123, 1127, 1131, 1144, 1150, 1164, 1165, 1168, 1169, 1170, 1178, 1188, 1189, 1190, 1191, 1192, 1193, 1196, 1197, 1204, 1205, 1208, 1209, 1213, 1224, 1248, 1277, 1281, 1282, 1283, 1316, 1317, 1318, 1319, 1328, 1353, 1372, 1378, 1385, 1410, 1415, 1416, 1419, 1422, 1423, 1454, 1457, 1460, 1463, 1468, 1473, 1476, 1484, 1485, 1487, 1502, 1506, 1519, 1522, 1537, 1544, 1545, 1558, 1564, 1569, 1580, 1581, 1600, 1603, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1620, 1625, 1628, 1630, 1635, 1636, 1641, 1643, 1645, 1655, 1660, 1674, 1675, 1676, 1679, 1686, 1688, 1691, 1692, 1694, 1695, 1696, 1698, 1700, 1701, 1703, 1705, 1706, 1710, 1711, 1713, 1715, 1719, 1724, 1725, 1727, 1728, 1729, 1732, 1734, 1738], "trigger": [0, 6, 8, 20, 35, 40, 41, 176, 755, 1590, 1695, 1699, 1700, 1705, 1711, 1724], "runtimeerror": [0, 1, 12, 20, 23, 42, 43, 244, 534, 592, 626, 657, 829, 870, 880, 895, 924, 925, 926, 927, 934, 935, 936, 938, 942, 948, 955, 960, 961, 988, 1007, 1116, 1660, 1676, 1678, 1679, 1689, 1691, 1695, 1697, 1702, 1710, 1712, 1713, 1719, 1723, 1727, 1730], "spars": [0, 1, 10, 145, 146, 163, 173, 176, 278, 283, 297, 298, 388, 493, 494, 495, 496, 535, 536, 537, 538, 539, 540, 565, 755, 837, 859, 880, 967, 1001, 1059, 1060, 1149, 1204, 1205, 1338, 1339, 1447, 1465, 1602, 1611, 1612, 1613, 1614, 1615, 1616, 1621, 1630, 1645, 1660, 1675, 1677, 1681, 1694, 1709, 1710, 1721, 1730, 1731, 1734], "place": [0, 3, 6, 10, 17, 18, 20, 25, 26, 40, 42, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 76, 78, 80, 82, 85, 86, 88, 96, 98, 101, 102, 104, 107, 113, 115, 117, 119, 121, 123, 132, 141, 149, 153, 156, 158, 168, 170, 176, 177, 186, 190, 192, 199, 202, 204, 206, 208, 209, 212, 215, 217, 224, 226, 228, 232, 234, 238, 240, 247, 249, 251, 259, 261, 263, 265, 267, 269, 271, 273, 310, 312, 314, 316, 318, 320, 322, 325, 327, 329, 330, 337, 339, 341, 343, 345, 350, 354, 356, 374, 377, 380, 382, 392, 394, 396, 404, 409, 419, 422, 438, 440, 442, 444, 448, 451, 460, 463, 464, 466, 468, 474, 478, 480, 483, 485, 487, 499, 501, 503, 512, 514, 522, 526, 528, 545, 548, 550, 552, 554, 555, 564, 573, 626, 628, 658, 696, 697, 699, 700, 719, 781, 832, 895, 939, 957, 1007, 1028, 1038, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1061, 1073, 1074, 1075, 1102, 1116, 1133, 1134, 1135, 1136, 1143, 1158, 1198, 1199, 1200, 1201, 1203, 1204, 1205, 1206, 1217, 1220, 1229, 1260, 1262, 1276, 1280, 1314, 1318, 1319, 1351, 1381, 1382, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1417, 1482, 1499, 1520, 1521, 1536, 1537, 1569, 1571, 1575, 1576, 1577, 1609, 1641, 1676, 1678, 1679, 1690, 1695, 1699, 1701, 1705, 1715, 1716, 1717, 1724, 1725, 1729, 1731, 1733], "replac": [0, 1, 12, 17, 18, 20, 34, 36, 42, 74, 375, 667, 728, 780, 781, 900, 902, 912, 983, 985, 986, 1007, 1011, 1147, 1158, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1314, 1340, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1417, 1419, 1475, 1499, 1521, 1537, 1625, 1629, 1633, 1648, 1676, 1677, 1679, 1685, 1699, 1703, 1705, 1708, 1712, 1713, 1716, 1719, 1734], "were": [0, 1, 2, 3, 19, 20, 26, 35, 38, 40, 41, 42, 105, 276, 290, 424, 619, 621, 622, 636, 902, 966, 1178, 1319, 1381, 1386, 1396, 1413, 1578, 1635, 1642, 1667, 1678, 1695, 1699, 1701, 1711, 1713, 1716], "reduc": [0, 2, 3, 12, 18, 20, 21, 23, 40, 276, 465, 468, 469, 581, 588, 590, 591, 592, 594, 604, 605, 697, 708, 868, 947, 951, 953, 958, 964, 982, 994, 996, 997, 999, 1002, 1012, 1013, 1014, 1015, 1032, 1033, 1034, 1035, 1036, 1050, 1052, 1060, 1076, 1082, 1083, 1107, 1108, 1119, 1120, 1121, 1123, 1130, 1147, 1148, 1155, 1164, 1185, 1186, 1194, 1196, 1205, 1221, 1224, 1225, 1226, 1236, 1244, 1245, 1246, 1247, 1248, 1249, 1256, 1266, 1267, 1278, 1281, 1319, 1385, 1420, 1436, 1459, 1473, 1475, 1476, 1501, 1502, 1503, 1504, 1507, 1509, 1577, 1610, 1623, 1624, 1628, 1629, 1646, 1662, 1663, 1677, 1688, 1689, 1696, 1698, 1700, 1701, 1706, 1710, 1711, 1712, 1715, 1716, 1717, 1719, 1738], "occur": [0, 10, 17, 28, 29, 35, 40, 151, 270, 742, 892, 898, 908, 938, 1039, 1155, 1197, 1422, 1678, 1687, 1690, 1695, 1699, 1702, 1709, 1713, 1724, 1726, 1731, 1734, 1738], "increas": [0, 1, 3, 6, 18, 20, 24, 32, 627, 660, 708, 739, 781, 856, 857, 1024, 1033, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1128, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1254, 1255, 1445, 1451, 1452, 1456, 1458, 1459, 1578, 1585, 1646, 1661, 1677, 1698, 1699, 1704, 1720], "set": [0, 1, 2, 3, 5, 7, 8, 11, 12, 16, 17, 18, 19, 20, 21, 23, 24, 26, 28, 33, 35, 36, 37, 38, 40, 41, 42, 43, 105, 109, 209, 285, 411, 448, 472, 531, 595, 608, 622, 629, 630, 631, 632, 633, 634, 635, 636, 655, 660, 671, 675, 680, 717, 729, 730, 748, 749, 750, 751, 752, 753, 754, 755, 782, 784, 842, 857, 875, 876, 895, 899, 902, 904, 906, 908, 910, 911, 930, 931, 934, 940, 947, 949, 951, 952, 964, 965, 966, 967, 981, 985, 988, 993, 1024, 1028, 1032, 1033, 1034, 1035, 1036, 1037, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1061, 1068, 1071, 1076, 1077, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1101, 1103, 1107, 1108, 1112, 1113, 1114, 1116, 1119, 1120, 1121, 1123, 1126, 1130, 1131, 1147, 1148, 1155, 1164, 1165, 1178, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1196, 1197, 1198, 1199, 1200, 1201, 1206, 1213, 1217, 1224, 1225, 1234, 1235, 1248, 1250, 1256, 1281, 1319, 1321, 1322, 1328, 1334, 1336, 1353, 1372, 1378, 1385, 1390, 1417, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1461, 1475, 1482, 1502, 1503, 1504, 1507, 1523, 1537, 1538, 1549, 1557, 1558, 1566, 1567, 1578, 1579, 1582, 1583, 1584, 1585, 1587, 1588, 1589, 1590, 1591, 1592, 1596, 1609, 1639, 1649, 1650, 1651, 1652, 1660, 1674, 1676, 1678, 1679, 1680, 1683, 1685, 1686, 1687, 1688, 1694, 1695, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1708, 1709, 1710, 1712, 1715, 1717, 1718, 1719, 1720, 1722, 1723, 1724, 1732, 1734, 1738], "directli": [0, 1, 3, 6, 8, 12, 13, 17, 18, 20, 24, 25, 26, 34, 40, 42, 620, 628, 763, 832, 840, 925, 1149, 1168, 1224, 1268, 1325, 1340, 1411, 1646, 1676, 1678, 1679, 1687, 1696, 1699, 1700, 1701, 1703, 1705, 1706, 1707, 1708, 1711, 1714, 1716, 1718, 1719, 1724, 1727, 1732, 1734], "fill": [0, 20, 109, 128, 213, 214, 215, 241, 272, 276, 331, 355, 398, 399, 400, 402, 407, 434, 534, 560, 574, 647, 768, 782, 784, 835, 836, 925, 936, 938, 1060, 1159, 1205, 1251, 1426, 1427, 1551, 1552, 1553, 1554, 1555, 1556, 1629, 1672, 1673, 1677, 1683, 1690, 1694, 1699, 1701, 1711, 1714, 1727, 1734], "later": [0, 1, 3, 6, 16, 18, 20, 40, 41, 42, 640, 717, 966, 1086, 1109, 1110, 1111, 1131, 1145, 1237, 1238, 1239, 1265, 1319, 1338, 1339, 1349, 1357, 1629, 1676, 1696, 1698, 1699, 1700, 1706, 1711, 1725, 1726], "chang": [0, 1, 2, 3, 6, 10, 18, 19, 20, 23, 24, 26, 34, 40, 41, 42, 94, 176, 209, 276, 411, 448, 451, 469, 472, 506, 568, 607, 637, 638, 679, 680, 687, 688, 705, 707, 717, 718, 725, 726, 728, 768, 817, 842, 848, 869, 895, 905, 906, 925, 936, 938, 939, 940, 943, 956, 998, 1056, 1059, 1077, 1082, 1086, 1116, 1147, 1168, 1178, 1213, 1225, 1237, 1238, 1239, 1314, 1315, 1319, 1321, 1322, 1386, 1389, 1390, 1421, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1449, 1452, 1455, 1456, 1458, 1459, 1461, 1475, 1501, 1540, 1585, 1609, 1620, 1625, 1633, 1645, 1667, 1674, 1675, 1676, 1685, 1687, 1688, 1689, 1690, 1691, 1695, 1696, 1697, 1698, 1699, 1701, 1703, 1704, 1706, 1709, 1711, 1713, 1715, 1716, 1717, 1718, 1719, 1720, 1724, 1726, 1727, 1729, 1730, 1731, 1732, 1733, 1736, 1737], "further": [0, 1, 4, 8, 12, 18, 20, 41, 840, 899, 934, 1024, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1319, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1463, 1679, 1706, 1708, 1716, 1718, 1726, 1732, 1737], "floattensor": [0, 20, 244, 276, 440, 581, 582, 583, 584, 585, 637, 638, 644, 842, 1059, 1060, 1119, 1159, 1328, 1583, 1730, 1733], "end": [0, 6, 7, 8, 17, 18, 19, 20, 24, 28, 32, 42, 315, 316, 489, 595, 645, 681, 688, 743, 770, 781, 820, 834, 848, 854, 855, 892, 895, 915, 920, 950, 960, 962, 965, 967, 981, 983, 1016, 1031, 1032, 1033, 1050, 1052, 1058, 1062, 1068, 1069, 1072, 1073, 1074, 1075, 1076, 1077, 1083, 1086, 1087, 1102, 1107, 1110, 1111, 1116, 1118, 1123, 1124, 1127, 1131, 1134, 1144, 1147, 1153, 1158, 1165, 1196, 1205, 1217, 1218, 1319, 1353, 1377, 1384, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446, 1450, 1455, 1482, 1502, 1503, 1558, 1590, 1593, 1600, 1646, 1657, 1658, 1670, 1676, 1677, 1678, 1679, 1688, 1695, 1696, 1699, 1700, 1701, 1702, 1703, 1709, 1712, 1713, 1715, 1719, 1722, 1724, 1728], "float64": [0, 10, 194, 399, 402, 531, 677, 780, 824, 833, 842, 877, 895, 924, 930, 931, 933, 935, 951, 1116, 1469, 1544, 1582, 1583, 1586, 1611, 1612, 1613, 1614, 1615, 1616, 1639, 1665, 1670, 1706, 1709, 1727, 1729, 1730, 1733, 1734, 1739], "variant": [0, 18, 925, 936, 949, 952, 1014, 1433, 1434, 1435, 1447, 1537, 1648, 1705, 1722, 1733], "suppli": [0, 5, 6, 12, 13, 20, 40, 717, 1679, 1699, 1727], "won": [0, 5, 7, 18, 35, 411, 895, 906, 1116, 1249, 1316, 1317, 1674, 1696, 1701, 1724, 1735], "go": [0, 1, 6, 8, 13, 20, 32, 37, 42, 451, 452, 510, 627, 967, 1029, 1030, 1031, 1109, 1110, 1111, 1678, 1679, 1688, 1689, 1690, 1696, 1698, 1699, 1705, 1706, 1708, 1712, 1713, 1716, 1730, 1732], "addmm": [0, 61, 1621, 1677, 1689, 1709, 1714, 1727], "b": [0, 1, 3, 10, 17, 20, 24, 33, 42, 215, 290, 353, 568, 580, 581, 610, 626, 628, 629, 644, 655, 656, 658, 662, 664, 666, 669, 674, 681, 687, 725, 726, 772, 775, 779, 781, 826, 827, 828, 829, 834, 838, 860, 872, 898, 905, 906, 914, 915, 917, 926, 927, 935, 939, 940, 944, 947, 948, 949, 950, 951, 952, 955, 956, 957, 960, 961, 964, 967, 976, 978, 979, 983, 986, 993, 995, 1000, 1002, 1006, 1037, 1059, 1060, 1067, 1103, 1184, 1205, 1212, 1230, 1341, 1350, 1374, 1384, 1411, 1412, 1413, 1414, 1422, 1444, 1446, 1476, 1485, 1506, 1549, 1562, 1565, 1581, 1592, 1600, 1606, 1611, 1612, 1613, 1615, 1616, 1620, 1626, 1628, 1641, 1648, 1649, 1651, 1664, 1669, 1676, 1677, 1678, 1679, 1689, 1690, 1691, 1694, 1695, 1697, 1699, 1702, 1703, 1704, 1709, 1711, 1718, 1719, 1725, 1726, 1727, 1728, 1731, 1732, 1737], "c": [0, 1, 3, 7, 8, 12, 17, 20, 33, 42, 215, 290, 451, 472, 568, 580, 607, 610, 628, 655, 666, 669, 682, 719, 725, 772, 775, 781, 827, 828, 829, 838, 848, 895, 905, 917, 924, 926, 930, 931, 932, 933, 934, 935, 940, 941, 944, 946, 950, 951, 953, 955, 957, 958, 1006, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1029, 1030, 1031, 1033, 1034, 1035, 1036, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1052, 1055, 1056, 1057, 1061, 1063, 1064, 1065, 1071, 1079, 1080, 1081, 1084, 1085, 1087, 1088, 1098, 1099, 1100, 1104, 1109, 1110, 1111, 1112, 1113, 1114, 1119, 1120, 1121, 1123, 1128, 1129, 1137, 1138, 1139, 1140, 1141, 1142, 1150, 1155, 1166, 1167, 1168, 1169, 1170, 1171, 1178, 1196, 1197, 1209, 1213, 1248, 1254, 1255, 1384, 1412, 1414, 1421, 1422, 1463, 1503, 1546, 1562, 1620, 1641, 1658, 1675, 1676, 1677, 1678, 1679, 1683, 1689, 1690, 1698, 1699, 1700, 1703, 1705, 1706, 1712, 1713, 1716, 1725, 1726, 1727, 1728, 1731, 1732, 1738], "addmm_": [0, 1677, 1689, 1727], "d": [0, 10, 18, 20, 24, 42, 268, 276, 290, 424, 465, 467, 469, 494, 535, 568, 581, 585, 595, 610, 628, 644, 645, 647, 654, 655, 656, 660, 666, 767, 769, 779, 794, 798, 799, 800, 801, 806, 807, 810, 811, 816, 817, 818, 821, 822, 823, 837, 852, 853, 860, 869, 892, 896, 900, 937, 938, 989, 993, 1001, 1009, 1023, 1031, 1032, 1036, 1046, 1050, 1051, 1055, 1056, 1057, 1059, 1061, 1063, 1068, 1070, 1081, 1086, 1088, 1100, 1111, 1125, 1131, 1155, 1164, 1165, 1167, 1178, 1213, 1224, 1257, 1280, 1281, 1385, 1416, 1421, 1422, 1445, 1464, 1549, 1558, 1570, 1578, 1582, 1620, 1625, 1634, 1635, 1641, 1644, 1649, 1650, 1651, 1652, 1661, 1667, 1669, 1674, 1677, 1689, 1690, 1694, 1696, 1699, 1701, 1703, 1704, 1711, 1713, 1724, 1725, 1727, 1728, 1732, 1733], "cannot": [0, 3, 7, 8, 17, 18, 20, 24, 25, 28, 35, 40, 41, 42, 177, 209, 475, 495, 610, 802, 804, 812, 813, 814, 820, 892, 900, 1007, 1039, 1059, 1168, 1197, 1319, 1630, 1674, 1676, 1677, 1678, 1679, 1680, 1681, 1687, 1690, 1696, 1700, 1701, 1711, 1712, 1713, 1719, 1724, 1726, 1727, 1729, 1730, 1738], "best": [0, 1, 6, 13, 17, 20, 24, 36, 40, 641, 663, 910, 911, 940, 1459, 1675, 1676, 1678, 1688, 1694, 1695, 1696, 1701, 1702, 1716, 1724], "stabil": [0, 926, 982, 1033, 1034, 1035, 1036, 1070, 1071, 1079, 1080, 1081, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1152, 1155, 1210, 1270, 1385, 1416, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1447, 1546], "respect": [0, 7, 20, 21, 23, 24, 33, 35, 40, 41, 42, 151, 164, 440, 531, 555, 584, 585, 586, 615, 621, 622, 636, 638, 671, 686, 768, 770, 771, 848, 895, 926, 930, 931, 940, 950, 953, 955, 958, 967, 1001, 1011, 1032, 1039, 1047, 1048, 1049, 1053, 1068, 1070, 1086, 1116, 1117, 1131, 1164, 1165, 1166, 1168, 1213, 1318, 1353, 1391, 1395, 1397, 1446, 1459, 1501, 1523, 1604, 1606, 1629, 1641, 1690, 1695, 1699, 1701, 1703, 1706, 1707, 1717, 1722, 1727, 1728, 1729, 1734], "describ": [0, 5, 6, 7, 10, 17, 18, 23, 26, 27, 33, 35, 40, 42, 465, 661, 725, 742, 781, 848, 915, 955, 1024, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1054, 1055, 1056, 1057, 1058, 1061, 1063, 1064, 1065, 1071, 1074, 1077, 1079, 1080, 1081, 1083, 1088, 1107, 1109, 1110, 1111, 1122, 1123, 1130, 1134, 1147, 1155, 1164, 1165, 1167, 1196, 1208, 1209, 1218, 1251, 1458, 1523, 1538, 1625, 1646, 1675, 1676, 1678, 1679, 1694, 1695, 1696, 1699, 1700, 1702, 1703, 1705, 1706, 1711, 1713, 1716, 1719, 1722, 1725, 1726, 1734], "alwai": [0, 6, 12, 14, 17, 18, 20, 33, 37, 40, 42, 295, 401, 411, 534, 610, 627, 630, 636, 645, 654, 664, 670, 767, 775, 797, 798, 800, 801, 802, 803, 804, 812, 813, 814, 815, 817, 820, 824, 852, 853, 895, 905, 910, 925, 930, 931, 932, 933, 935, 936, 948, 951, 952, 953, 954, 958, 960, 983, 1013, 1032, 1034, 1035, 1036, 1053, 1079, 1080, 1081, 1089, 1090, 1091, 1098, 1099, 1100, 1116, 1152, 1155, 1314, 1319, 1410, 1566, 1567, 1592, 1625, 1629, 1657, 1660, 1679, 1680, 1688, 1696, 1697, 1698, 1699, 1700, 1701, 1703, 1705, 1706, 1716, 1717, 1723, 1724, 1726, 1727, 1730, 1733, 1734], "expos": [0, 1, 7, 20, 23, 40, 41, 42, 834, 1696, 1699, 1705, 1716, 1719, 1738], "namespac": [0, 42, 755, 1676, 1680, 1683, 1701, 1706, 1713, 1717, 1722, 1738], "below": [0, 1, 12, 17, 18, 19, 20, 24, 26, 27, 32, 35, 36, 37, 38, 42, 725, 767, 768, 769, 770, 771, 781, 809, 811, 815, 840, 848, 895, 911, 951, 952, 957, 964, 993, 998, 1047, 1048, 1049, 1068, 1070, 1077, 1086, 1088, 1112, 1113, 1114, 1116, 1131, 1147, 1168, 1196, 1222, 1266, 1319, 1327, 1341, 1350, 1389, 1421, 1499, 1582, 1609, 1636, 1646, 1649, 1650, 1651, 1652, 1676, 1678, 1679, 1681, 1688, 1689, 1695, 1696, 1699, 1700, 1701, 1703, 1704, 1706, 1708, 1710, 1711, 1713, 1715, 1716, 1717, 1719, 1721, 1724, 1725, 1726, 1728, 1731, 1734], "do": [0, 1, 4, 6, 7, 8, 10, 12, 13, 17, 18, 20, 23, 25, 26, 28, 35, 36, 37, 40, 41, 42, 388, 447, 465, 467, 469, 623, 628, 637, 662, 675, 728, 759, 760, 761, 762, 832, 834, 837, 857, 870, 882, 892, 898, 906, 910, 940, 958, 967, 974, 985, 987, 997, 1007, 1028, 1038, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1073, 1074, 1075, 1102, 1134, 1135, 1136, 1143, 1158, 1198, 1199, 1200, 1201, 1204, 1205, 1206, 1215, 1217, 1232, 1314, 1319, 1351, 1423, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446, 1469, 1505, 1508, 1542, 1660, 1674, 1676, 1677, 1679, 1681, 1683, 1688, 1689, 1690, 1695, 1696, 1697, 1699, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1718, 1719, 1720, 1724, 1726, 1728, 1729, 1730, 1731, 1732, 1734], "defin": [0, 1, 3, 5, 8, 12, 13, 17, 18, 20, 21, 24, 26, 27, 33, 35, 36, 40, 42, 400, 402, 469, 516, 619, 621, 739, 763, 781, 782, 801, 829, 835, 838, 840, 854, 856, 857, 884, 917, 924, 926, 930, 931, 932, 933, 934, 935, 940, 941, 944, 946, 947, 951, 952, 953, 955, 957, 958, 964, 1002, 1053, 1058, 1072, 1073, 1074, 1075, 1082, 1084, 1085, 1116, 1122, 1134, 1149, 1151, 1156, 1158, 1178, 1213, 1268, 1314, 1319, 1395, 1397, 1404, 1405, 1423, 1426, 1428, 1430, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446, 1447, 1449, 1450, 1452, 1455, 1458, 1475, 1482, 1484, 1520, 1539, 1551, 1553, 1555, 1562, 1590, 1608, 1633, 1646, 1649, 1650, 1651, 1652, 1670, 1672, 1674, 1676, 1679, 1681, 1683, 1688, 1689, 1691, 1696, 1699, 1700, 1703, 1704, 1706, 1712, 1713, 1715, 1716, 1717, 1718, 1719, 1722, 1724, 1727, 1728, 1733, 1734, 1735, 1738], "still": [0, 1, 2, 7, 17, 20, 24, 26, 35, 41, 42, 627, 632, 899, 904, 912, 1083, 1107, 1319, 1321, 1322, 1459, 1484, 1540, 1574, 1676, 1679, 1688, 1689, 1690, 1695, 1696, 1699, 1700, 1701, 1702, 1704, 1711, 1712, 1713, 1715, 1716, 1717, 1719, 1724, 1725, 1726, 1727], "which": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 17, 18, 19, 21, 23, 24, 25, 26, 28, 33, 34, 35, 36, 37, 40, 41, 42, 43, 105, 244, 268, 270, 272, 274, 276, 290, 388, 425, 439, 440, 451, 465, 467, 469, 488, 510, 556, 559, 568, 575, 579, 592, 606, 610, 615, 622, 623, 624, 630, 631, 632, 633, 634, 635, 636, 641, 647, 660, 663, 666, 670, 684, 685, 686, 687, 688, 691, 696, 697, 698, 699, 700, 710, 711, 712, 739, 741, 745, 746, 757, 758, 763, 767, 768, 769, 770, 771, 780, 781, 797, 802, 805, 809, 812, 815, 820, 821, 822, 823, 824, 829, 832, 837, 840, 857, 869, 880, 886, 892, 893, 895, 896, 898, 904, 905, 906, 910, 927, 930, 931, 940, 944, 946, 947, 950, 951, 955, 957, 958, 960, 963, 964, 966, 972, 989, 993, 997, 1002, 1007, 1013, 1016, 1022, 1023, 1024, 1026, 1027, 1028, 1030, 1031, 1034, 1035, 1036, 1039, 1045, 1046, 1048, 1049, 1053, 1060, 1067, 1068, 1077, 1079, 1080, 1081, 1082, 1084, 1085, 1086, 1088, 1106, 1110, 1111, 1112, 1113, 1114, 1116, 1119, 1121, 1122, 1144, 1147, 1149, 1151, 1155, 1164, 1165, 1195, 1212, 1213, 1215, 1225, 1232, 1250, 1251, 1268, 1269, 1277, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1314, 1319, 1353, 1357, 1374, 1384, 1386, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1407, 1419, 1422, 1430, 1446, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1465, 1479, 1481, 1482, 1484, 1501, 1505, 1508, 1520, 1536, 1537, 1538, 1544, 1558, 1562, 1564, 1565, 1569, 1571, 1578, 1590, 1592, 1599, 1603, 1605, 1606, 1608, 1609, 1617, 1620, 1640, 1646, 1649, 1650, 1651, 1652, 1656, 1657, 1659, 1660, 1667, 1674, 1676, 1678, 1679, 1681, 1685, 1686, 1687, 1688, 1690, 1691, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1710, 1712, 1713, 1716, 1717, 1718, 1719, 1720, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1732, 1733, 1734, 1736, 1737, 1738, 1739], "unlist": 0, "downstream": [0, 3, 1687], "numer": [0, 17, 24, 582, 637, 638, 660, 899, 910, 911, 926, 930, 931, 935, 940, 948, 949, 952, 955, 958, 960, 982, 985, 993, 1033, 1034, 1035, 1036, 1071, 1079, 1080, 1081, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1149, 1152, 1155, 1225, 1232, 1268, 1270, 1385, 1416, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1447, 1546, 1578, 1629, 1675, 1679, 1680, 1685, 1699, 1701, 1713, 1719, 1728, 1733, 1739], "stabl": [0, 1, 20, 24, 35, 36, 606, 781, 930, 931, 935, 940, 948, 952, 955, 958, 960, 967, 1033, 1323, 1324, 1325, 1326, 1338, 1339, 1349, 1354, 1355, 1356, 1357, 1358, 1603, 1633, 1675, 1677, 1694, 1697, 1710, 1724], "believ": [0, 7], "unstabl": [0, 24, 930, 931, 958, 975, 985, 1232, 1629, 1728], "__matmul__": 0, "addbmm": [0, 55, 644, 1677, 1709], "addmv": [0, 63, 1677, 1689], "addr": [0, 65, 1677], "baddbmm": [0, 107, 1677, 1709, 1714], "bmm": [0, 1660, 1677, 1689, 1709, 1710, 1714, 1727], "chain_matmul": [0, 1677], "multi_dot": [0, 666], "conv1d": [0, 1047, 1055, 1092, 1292, 1296, 1299, 1309, 1334, 1660, 1677, 1714, 1719, 1721], "conv2d": [0, 895, 904, 906, 910, 911, 1048, 1056, 1093, 1116, 1117, 1123, 1144, 1167, 1293, 1297, 1300, 1302, 1310, 1335, 1404, 1499, 1660, 1676, 1677, 1685, 1713, 1714, 1719, 1721, 1722, 1732, 1737], "conv3d": [0, 1049, 1057, 1094, 1294, 1298, 1301, 1303, 1311, 1336, 1660, 1677, 1714, 1719, 1721], "conv_transpose1d": [0, 1677, 1714], "conv_transpose2d": [0, 1677, 1714], "conv_transpose3d": [0, 1677, 1714], "grucel": [0, 1709, 1719, 1721, 1722], "lstmcell": [0, 1709, 1719, 1721, 1722], "matmul": [0, 2, 10, 656, 1001, 1167, 1465, 1475, 1585, 1629, 1633, 1677, 1689, 1699, 1709, 1714, 1727], "mv": [0, 10, 906, 1660, 1677, 1689, 1714, 1727], "prelu": [0, 1117, 1677, 1714, 1721], "rnncell": [0, 1719, 1721, 1722], "__pow__": 0, "__rdiv__": 0, "__rpow__": 0, "__rtruediv__": 0, "aco": [0, 49, 596, 1677, 1689, 1714, 1734], "asin": [0, 96, 598, 1677, 1689, 1714, 1727], "cosh": [0, 158, 579, 1677, 1689], "cosine_embedding_loss": [0, 1677], "cdist": [0, 1699, 1714], "cosine_similar": [0, 1165, 1677, 1714], "cross_entropi": [0, 1677], "cumprod": [0, 168, 1677, 1689], "cumsum": [0, 170, 763, 1660, 1677, 1689, 1714], "dist": [0, 18, 20, 21, 23, 24, 36, 40, 667, 668, 924, 930, 931, 932, 934, 935, 936, 940, 941, 952, 953, 956, 958, 959, 982, 986, 1155, 1319, 1384, 1629, 1677, 1700, 1724, 1726], "erfinv": [0, 206, 1677, 1689, 1727, 1728], "exp": [0, 1, 24, 208, 632, 633, 635, 824, 954, 974, 982, 1033, 1038, 1052, 1058, 1082, 1105, 1106, 1120, 1130, 1143, 1146, 1148, 1149, 1151, 1152, 1156, 1187, 1233, 1256, 1263, 1264, 1268, 1270, 1273, 1363, 1384, 1472, 1608, 1625, 1677, 1689, 1696, 1713, 1714, 1728], "expm1": [0, 212, 1677, 1689, 1727, 1728], "group_norm": [0, 1677, 1714], "hinge_embedding_loss": [0, 1677], "kl_div": [0, 1677, 1714], "l1_loss": [0, 1677], "layer_norm": [0, 1088, 1677, 1714, 1721], "log": [0, 12, 17, 18, 24, 26, 28, 29, 32, 33, 330, 331, 791, 970, 972, 974, 975, 982, 1024, 1032, 1033, 1052, 1070, 1082, 1105, 1106, 1120, 1123, 1130, 1148, 1149, 1152, 1210, 1215, 1225, 1232, 1233, 1248, 1256, 1268, 1270, 1319, 1677, 1687, 1689, 1696, 1699, 1701, 1713, 1714, 1718, 1728, 1732, 1735, 1736, 1737], "log_softmax": [0, 1039, 1082, 1197, 1248, 1268, 1677, 1690, 1714, 1728], "log10": [0, 325, 1677, 1689, 1714], "log1p": [0, 327, 1677, 1689, 1714, 1727, 1728], "log2": [0, 329, 1677, 1689, 1714, 1728], "margin_ranking_loss": [0, 1677], "mse_loss": [0, 1677], "multilabel_margin_loss": [0, 1677], "multi_margin_loss": [0, 1677], "nll_loss": [0, 1677, 1714], "norm": [0, 24, 40, 42, 664, 774, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 926, 930, 939, 940, 947, 952, 964, 983, 1059, 1060, 1107, 1125, 1160, 1161, 1162, 1163, 1164, 1204, 1205, 1249, 1253, 1286, 1287, 1288, 1289, 1290, 1291, 1381, 1385, 1394, 1395, 1400, 1403, 1404, 1416, 1419, 1435, 1563, 1677, 1681, 1695, 1696, 1703, 1706, 1709, 1714], "normal": [0, 1, 18, 23, 35, 40, 42, 291, 306, 331, 407, 506, 686, 780, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 856, 892, 895, 900, 930, 972, 1028, 1034, 1035, 1036, 1055, 1056, 1057, 1061, 1071, 1079, 1080, 1081, 1088, 1098, 1099, 1100, 1104, 1143, 1155, 1159, 1160, 1161, 1162, 1163, 1183, 1213, 1214, 1223, 1227, 1231, 1257, 1381, 1382, 1385, 1400, 1408, 1409, 1416, 1419, 1444, 1459, 1546, 1555, 1556, 1563, 1625, 1660, 1674, 1676, 1677, 1681, 1689, 1694, 1696, 1699, 1713, 1714, 1716, 1721, 1724, 1728, 1732, 1734, 1735, 1739], "pdist": [0, 1125, 1677], "poisson_nll_loss": [0, 1677], "pow": [0, 1, 422, 448, 630, 631, 634, 824, 1677, 1679, 1689, 1695, 1696, 1714, 1727, 1733], "prod": [0, 32, 276, 469, 798, 800, 803, 804, 806, 807, 810, 811, 813, 814, 816, 818, 960, 961, 1059, 1063, 1167, 1677, 1689, 1714, 1727], "reciproc": [0, 438, 1573, 1677, 1689, 1714], "rsqrt": [0, 463, 1677, 1689, 1714], "sinh": [0, 487, 612, 1677, 1689, 1727], "smooth_l1_loss": [0, 1677], "soft_margin_loss": [0, 1677], "softmax": [0, 24, 1024, 1052, 1082, 1106, 1150, 1196, 1215, 1225, 1232, 1269, 1605, 1677, 1690, 1699, 1714, 1721, 1727, 1728], "softmin": [0, 1677], "softplu": [0, 24, 1115, 1243, 1677, 1714], "sum": [0, 1, 17, 20, 21, 23, 24, 26, 40, 42, 448, 469, 516, 622, 630, 631, 632, 633, 634, 635, 636, 642, 686, 698, 699, 700, 762, 763, 781, 872, 926, 947, 951, 964, 972, 973, 974, 982, 983, 1007, 1015, 1032, 1033, 1039, 1049, 1050, 1052, 1053, 1060, 1063, 1070, 1076, 1077, 1082, 1083, 1084, 1085, 1107, 1108, 1119, 1120, 1121, 1123, 1130, 1147, 1148, 1149, 1151, 1164, 1165, 1167, 1185, 1186, 1196, 1197, 1205, 1210, 1215, 1225, 1234, 1235, 1248, 1256, 1268, 1269, 1319, 1339, 1400, 1405, 1406, 1422, 1452, 1564, 1606, 1608, 1644, 1646, 1660, 1677, 1679, 1683, 1687, 1689, 1695, 1696, 1699, 1700, 1701, 1706, 1709, 1713, 1714, 1724, 1725, 1727, 1728, 1733], "renorm": [0, 444, 1059, 1060, 1204, 1205, 1677], "tan": [0, 526, 613, 1677, 1689, 1714, 1727, 1732], "triplet_margin_loss": [0, 1677], "take": [0, 1, 2, 3, 4, 6, 8, 12, 17, 18, 20, 23, 24, 26, 34, 35, 36, 37, 40, 41, 42, 534, 630, 631, 632, 633, 634, 635, 637, 638, 669, 687, 719, 768, 770, 771, 797, 799, 802, 805, 809, 810, 812, 815, 927, 949, 952, 1024, 1033, 1060, 1064, 1065, 1068, 1086, 1110, 1111, 1112, 1113, 1114, 1116, 1124, 1131, 1159, 1169, 1170, 1208, 1209, 1226, 1250, 1319, 1353, 1444, 1448, 1472, 1483, 1499, 1502, 1648, 1667, 1674, 1676, 1677, 1679, 1685, 1688, 1689, 1690, 1695, 1696, 1698, 1699, 1700, 1701, 1702, 1704, 1706, 1710, 1712, 1713, 1714, 1716, 1718, 1719, 1724, 1725, 1726, 1727, 1730, 1731, 1732, 1736], "addcdiv": [0, 57, 1677], "addcmul": [0, 59, 1677, 1714], "atan2": [0, 101, 601, 1677, 1689], "bilinear": [0, 781, 1168, 1169, 1213, 1224, 1281, 1282, 1372, 1378, 1379, 1660, 1677], "cross": [0, 6, 7, 24, 26, 1032, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1185, 1186, 1196, 1677, 1699, 1712, 1714], "dot": [0, 12, 568, 631, 633, 634, 635, 759, 760, 761, 762, 872, 915, 962, 963, 990, 1032, 1033, 1052, 1063, 1076, 1083, 1107, 1122, 1123, 1165, 1625, 1664, 1665, 1666, 1667, 1677, 1689, 1703, 1714, 1716], "grid_sampl": [0, 1178, 1660, 1677, 1714], "index_put": [0, 1660, 1677, 1714], "scatter_add": [0, 1677, 1714], "tensordot": [0, 872, 960, 961, 1681, 1699, 1714], "binari": [0, 2, 12, 13, 18, 19, 24, 26, 28, 33, 35, 42, 109, 646, 989, 1032, 1033, 1122, 1185, 1186, 1328, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1675, 1680, 1689, 1690, 1705, 1713, 1716, 1732], "add": [0, 1, 3, 6, 13, 14, 17, 20, 23, 32, 35, 40, 41, 42, 53, 245, 268, 465, 467, 581, 582, 583, 586, 699, 728, 895, 906, 1024, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1092, 1093, 1094, 1095, 1096, 1097, 1116, 1118, 1122, 1123, 1127, 1130, 1215, 1256, 1314, 1316, 1317, 1318, 1319, 1340, 1341, 1350, 1389, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1443, 1444, 1445, 1446, 1447, 1479, 1480, 1520, 1538, 1621, 1674, 1676, 1677, 1678, 1679, 1683, 1685, 1687, 1689, 1691, 1695, 1697, 1698, 1701, 1705, 1706, 1713, 1714, 1716, 1718, 1719, 1720, 1721, 1724, 1725, 1726, 1727, 1730, 1731, 1732, 1736, 1737, 1738], "nativ": [0, 10, 18, 42, 905, 1585, 1676, 1679, 1688, 1716, 1724], "without": [0, 1, 3, 5, 6, 7, 8, 12, 17, 18, 19, 20, 21, 23, 24, 28, 35, 40, 41, 42, 209, 568, 673, 690, 691, 723, 802, 803, 804, 812, 813, 814, 892, 893, 895, 896, 941, 942, 957, 964, 1007, 1034, 1035, 1036, 1056, 1060, 1079, 1080, 1081, 1113, 1116, 1124, 1155, 1163, 1205, 1314, 1319, 1401, 1415, 1452, 1549, 1565, 1582, 1623, 1624, 1655, 1662, 1663, 1674, 1678, 1679, 1685, 1687, 1688, 1690, 1695, 1696, 1697, 1699, 1701, 1703, 1704, 1706, 1708, 1710, 1711, 1713, 1716, 1717, 1719, 1723, 1724, 1732, 1737, 1739], "intervent": [0, 7, 1724], "mixtur": [0, 24, 1052, 1196], "bceloss": [0, 1033, 1185], "aren": [0, 7, 42, 1689, 1696, 1725, 1738], "mean": [0, 2, 3, 5, 6, 7, 13, 17, 18, 19, 20, 23, 24, 35, 37, 40, 41, 42, 209, 276, 290, 331, 407, 447, 469, 644, 657, 686, 905, 997, 1007, 1012, 1022, 1023, 1024, 1026, 1027, 1028, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1050, 1052, 1054, 1058, 1060, 1061, 1062, 1066, 1067, 1068, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1086, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1102, 1103, 1105, 1106, 1107, 1108, 1115, 1119, 1120, 1121, 1123, 1124, 1130, 1131, 1134, 1135, 1136, 1143, 1145, 1146, 1147, 1148, 1149, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1164, 1165, 1166, 1184, 1185, 1186, 1194, 1196, 1197, 1205, 1206, 1210, 1221, 1222, 1225, 1226, 1230, 1236, 1244, 1245, 1246, 1247, 1248, 1256, 1266, 1267, 1278, 1279, 1319, 1351, 1353, 1374, 1423, 1546, 1555, 1556, 1624, 1630, 1663, 1674, 1676, 1677, 1678, 1687, 1688, 1689, 1690, 1694, 1695, 1696, 1699, 1700, 1701, 1702, 1703, 1706, 1712, 1713, 1714, 1715, 1716, 1718, 1719, 1720, 1721, 1724, 1725, 1726, 1727], "doesn": [0, 1, 2, 6, 7, 10, 17, 20, 41, 42, 626, 636, 690, 708, 902, 908, 934, 958, 966, 975, 1044, 1045, 1046, 1053, 1082, 1149, 1188, 1189, 1190, 1225, 1268, 1319, 1320, 1400, 1436, 1505, 1508, 1604, 1606, 1667, 1676, 1679, 1680, 1689, 1696, 1697, 1699, 1701, 1705, 1708, 1712, 1715, 1717, 1725], "help": [0, 1, 4, 6, 7, 10, 12, 17, 18, 20, 32, 35, 40, 42, 637, 638, 641, 708, 739, 895, 896, 914, 998, 1055, 1056, 1057, 1061, 1116, 1384, 1592, 1667, 1674, 1679, 1689, 1690, 1695, 1696, 1697, 1699, 1700, 1704, 1706, 1713, 1716, 1724, 1725, 1735], "revers": [0, 24, 42, 465, 630, 632, 799, 801, 821, 962, 983, 1086, 1129, 1255, 1319, 1327, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1407, 1648, 1661, 1677, 1678, 1679, 1696, 1700, 1721, 1733], "therefor": [0, 3, 5, 17, 18, 20, 24, 25, 33, 401, 636, 645, 654, 728, 815, 832, 834, 852, 853, 907, 910, 940, 953, 1059, 1060, 1167, 1204, 1205, 1213, 1452, 1679, 1695, 1696, 1699, 1701, 1702, 1705, 1713, 1726], "rais": [0, 1, 5, 6, 12, 20, 23, 24, 26, 28, 35, 40, 41, 42, 43, 268, 270, 276, 592, 628, 630, 631, 632, 633, 634, 635, 637, 638, 657, 751, 824, 829, 893, 895, 900, 902, 912, 924, 926, 927, 934, 935, 938, 942, 943, 948, 955, 956, 960, 961, 966, 988, 1116, 1389, 1390, 1395, 1397, 1400, 1410, 1428, 1660, 1674, 1680, 1688, 1696, 1699, 1701, 1702, 1713, 1716, 1717, 1723, 1724, 1734, 1738], "mani": [0, 3, 6, 10, 12, 17, 18, 19, 20, 24, 35, 42, 43, 357, 619, 621, 630, 632, 781, 907, 1039, 1600, 1642, 1649, 1650, 1651, 1652, 1676, 1678, 1689, 1694, 1696, 1697, 1698, 1699, 1701, 1705, 1706, 1709, 1713, 1715, 1719, 1726, 1727, 1730, 1732, 1733, 1735], "sigmoid": [0, 24, 42, 478, 1032, 1033, 1059, 1068, 1069, 1086, 1087, 1145, 1185, 1212, 1265, 1353, 1677, 1689, 1690, 1694, 1714, 1721, 1728], "right": [0, 6, 8, 20, 24, 40, 42, 595, 645, 652, 654, 655, 660, 665, 774, 822, 825, 826, 830, 852, 853, 857, 861, 892, 914, 939, 944, 955, 957, 958, 966, 972, 973, 1007, 1024, 1029, 1030, 1031, 1032, 1033, 1044, 1045, 1046, 1063, 1070, 1083, 1084, 1085, 1104, 1105, 1106, 1107, 1109, 1110, 1111, 1119, 1120, 1121, 1125, 1126, 1132, 1164, 1167, 1168, 1169, 1170, 1213, 1233, 1251, 1382, 1389, 1436, 1450, 1451, 1502, 1540, 1558, 1578, 1625, 1641, 1646, 1648, 1661, 1674, 1677, 1679, 1688, 1689, 1690, 1701, 1703, 1713, 1722, 1726, 1728], "entropi": [0, 24, 1032, 1052, 1120, 1185, 1186, 1196, 1728], "combin": [0, 3, 17, 18, 20, 35, 41, 568, 739, 810, 811, 816, 818, 857, 1033, 1052, 1063, 1077, 1167, 1207, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1396, 1676, 1677, 1678, 1695, 1699, 1701, 1713, 1717, 1719, 1722, 1724], "bcewithlogitsloss": [0, 1186], "bcewithlogit": 0, "safe": [0, 20, 35, 41, 42, 729, 730, 748, 749, 1319, 1433, 1434, 1676, 1679, 1695, 1696, 1699, 1705, 1724], "_convolut": [0, 1714], "avg_pool3d": [0, 1677, 1714, 1721], "grid_sampler_2d": [0, 1677], "_grid_sampler_2d_cpu_fallback": 0, "grid_sampler_3d": [0, 1677], "polar": [0, 24, 954, 1677], "quantil": [0, 997, 1014, 1677, 1728], "nanquantil": [0, 1677], "stft": [0, 645, 654, 852, 853, 892, 914, 1677], "view_as_complex": [0, 10, 1677], "choleski": [0, 2, 24, 668, 669, 925, 931, 967, 1677], "cholesky_invers": [0, 2, 1677], "cholesky_solv": [0, 2, 1677], "invers": [0, 24, 578, 579, 612, 615, 663, 668, 669, 797, 798, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 818, 892, 935, 936, 948, 952, 955, 960, 961, 1047, 1048, 1049, 1059, 1060, 1063, 1112, 1113, 1114, 1167, 1204, 1205, 1240, 1241, 1242, 1386, 1389, 1413, 1452, 1458, 1656, 1677, 1679, 1728], "lu_solv": [0, 2, 942, 1677], "matrix_rank": [0, 1389, 1677], "orgqr": [0, 1677], "ormqr": [0, 840, 934, 1677], "pinvers": [0, 940, 1677], "max_pool3d": [0, 1677, 1714, 1721], "max_unpool2d": [0, 1208, 1238, 1677], "max_unpool3d": [0, 1209, 1239, 1677], "adaptive_avg_pool3d": [0, 1677, 1701, 1714, 1721], "reflection_pad1d": [0, 1677, 1714], "reflection_pad2d": [0, 1677, 1714], "replication_pad1d": [0, 1677, 1714], "replication_pad2d": [0, 1677, 1714], "replication_pad3d": [0, 1677, 1714], "ctc_loss": [0, 1039, 1677], "fft_fft": [0, 1677], "fft_ifft": [0, 1677], "fft_fft2": [0, 1677], "fft_ifft2": [0, 1677], "fft_fftn": [0, 1677], "fft_ifftn": [0, 1677], "fft_rfft": [0, 1677], "fft_irfft": [0, 1677], "fft_rfft2": [0, 1677], "fft_irfft2": [0, 1677], "fft_rfftn": [0, 1677], "fft_irfftn": [0, 1677], "fft_hfft": [0, 1677], "fft_ihfft": [0, 1677], "linalg_matrix_norm": [0, 1677, 1714], "linalg_cond": [0, 1677], "linalg_matrix_rank": [0, 1677], "linalg_solv": [0, 1677], "linalg_choleski": [0, 1677], "linalg_svdv": [0, 1677], "linalg_eigv": [0, 1677], "linalg_eigvalsh": [0, 1677], "linalg_inv": [0, 1677], "linalg_householder_product": [0, 1677], "linalg_tensorinv": [0, 1677], "linalg_tensorsolv": [0, 1677], "fake_quantize_per_tensor_affin": [0, 1677, 1714], "eig": [0, 931, 932, 958, 1677], "geqrf": [0, 934, 1463, 1677], "lstsq": [0, 840, 926, 952, 1677], "_lu_with_info": 0, "qr": [0, 2, 840, 930, 931, 934, 940, 958, 983, 1384, 1463, 1677], "solv": [0, 6, 10, 669, 840, 926, 935, 937, 938, 941, 942, 944, 948, 956, 957, 961, 967, 983, 986, 1648, 1696, 1703, 1712], "svd": [0, 2, 10, 930, 931, 940, 952, 959, 975, 993, 1389, 1465, 1630, 1677, 1727], "symeig": [0, 1677], "triangular_solv": [0, 1677], "fractional_max_pool2d": [0, 1677], "fractional_max_pool3d": [0, 1677], "adaptive_max_pool3d": [0, 1677, 1714], "multilabel_margin_loss_forward": 0, "linalg_qr": [0, 1677], "linalg_cholesky_ex": [0, 1677], "linalg_svd": [0, 1677], "linalg_eig": [0, 1677], "linalg_eigh": [0, 1677], "linalg_lstsq": [0, 1677], "linalg_inv_ex": [0, 1677], "cat": [0, 24, 42, 494, 678, 998, 1135, 1340, 1341, 1350, 1610, 1676, 1677, 1689, 1713, 1714, 1716, 1719, 1721, 1727, 1736], "stack": [0, 7, 17, 18, 24, 28, 42, 641, 674, 743, 744, 779, 860, 998, 1039, 1068, 1086, 1087, 1131, 1160, 1162, 1353, 1414, 1667, 1669, 1677, 1691, 1699, 1700, 1702, 1714, 1716, 1718, 1721, 1727], "index_copi": [0, 1660, 1677, 1714], "implement": [1, 2, 5, 7, 14, 17, 18, 20, 21, 23, 24, 27, 32, 33, 36, 40, 42, 105, 244, 465, 467, 469, 582, 608, 610, 622, 631, 637, 638, 684, 781, 824, 829, 834, 895, 902, 904, 905, 908, 950, 953, 966, 967, 997, 1024, 1039, 1053, 1084, 1085, 1116, 1122, 1128, 1135, 1152, 1161, 1163, 1213, 1251, 1270, 1319, 1331, 1332, 1333, 1334, 1335, 1336, 1372, 1374, 1378, 1384, 1385, 1389, 1400, 1413, 1415, 1416, 1419, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1443, 1444, 1445, 1446, 1447, 1450, 1452, 1458, 1475, 1485, 1506, 1549, 1562, 1571, 1574, 1599, 1607, 1629, 1630, 1641, 1657, 1660, 1678, 1679, 1680, 1683, 1688, 1692, 1694, 1695, 1696, 1698, 1701, 1702, 1705, 1706, 1708, 1709, 1710, 1711, 1712, 1715, 1716, 1717, 1719, 1722, 1724, 1725, 1727, 1728, 1731, 1733, 1738], "arbitrari": [1, 3, 20, 23, 209, 620, 763, 958, 966, 1053, 1059, 1083, 1107, 1167, 1185, 1186, 1204, 1225, 1251, 1410, 1629, 1646, 1679, 1696, 1705, 1706, 1715, 1717, 1719, 1727, 1735, 1738], "scalar": [1, 24, 52, 105, 109, 215, 268, 399, 541, 582, 583, 609, 610, 622, 630, 631, 634, 636, 649, 652, 660, 682, 686, 775, 781, 829, 835, 848, 855, 872, 886, 919, 920, 990, 998, 1014, 1024, 1032, 1033, 1039, 1050, 1052, 1053, 1070, 1076, 1077, 1082, 1083, 1088, 1108, 1119, 1120, 1121, 1123, 1130, 1147, 1148, 1164, 1165, 1215, 1257, 1331, 1332, 1333, 1334, 1335, 1336, 1421, 1426, 1427, 1428, 1459, 1472, 1474, 1476, 1561, 1562, 1578, 1612, 1613, 1614, 1615, 1616, 1639, 1657, 1658, 1670, 1672, 1673, 1677, 1678, 1679, 1687, 1694, 1696, 1701, 1703, 1713, 1724, 1727, 1730, 1732, 1734], "minim": [1, 6, 7, 19, 605, 999, 1430, 1431, 1432, 1433, 1434, 1435, 1444, 1445, 1446, 1447, 1459, 1501, 1674, 1687, 1695, 1699, 1706, 1708, 1711, 1717, 1719], "exist": [1, 6, 7, 8, 10, 12, 17, 20, 21, 24, 26, 28, 33, 35, 36, 40, 42, 209, 451, 608, 630, 631, 632, 633, 634, 635, 636, 637, 723, 895, 899, 910, 930, 935, 941, 942, 967, 1014, 1116, 1117, 1126, 1674, 1676, 1683, 1688, 1689, 1692, 1696, 1697, 1701, 1704, 1705, 1706, 1707, 1716, 1717, 1718, 1719, 1724, 1726, 1727, 1731, 1733], "code": [1, 3, 4, 7, 8, 10, 12, 13, 17, 18, 19, 20, 24, 26, 36, 37, 41, 74, 725, 726, 870, 895, 899, 900, 905, 906, 907, 910, 911, 912, 925, 936, 938, 966, 1132, 1144, 1319, 1589, 1674, 1678, 1679, 1690, 1696, 1697, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1708, 1711, 1712, 1713, 1715, 1723, 1724, 1725, 1726, 1730, 1731, 1738], "declar": [1, 8, 12, 17, 36, 1678, 1679, 1680, 1701, 1713, 1716, 1717], "requires_grad": [1, 5, 24, 290, 398, 399, 400, 401, 402, 440, 448, 595, 610, 626, 628, 629, 637, 638, 645, 654, 728, 782, 783, 784, 785, 794, 799, 817, 834, 835, 836, 852, 853, 870, 895, 914, 965, 981, 1032, 1033, 1052, 1059, 1060, 1070, 1082, 1083, 1107, 1108, 1116, 1122, 1123, 1130, 1163, 1164, 1185, 1186, 1196, 1248, 1319, 1320, 1321, 1322, 1415, 1420, 1426, 1427, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1587, 1606, 1611, 1612, 1613, 1614, 1615, 1616, 1639, 1660, 1667, 1672, 1673, 1677, 1681, 1689, 1690, 1699, 1701, 1706, 1711, 1713, 1715, 1724, 1725, 1733, 1734, 1735], "type": [1, 2, 12, 13, 14, 18, 20, 23, 24, 26, 28, 33, 35, 36, 37, 40, 41, 42, 43, 105, 146, 151, 163, 244, 281, 284, 288, 296, 398, 399, 400, 401, 402, 434, 509, 556, 580, 581, 582, 583, 584, 585, 595, 609, 620, 630, 631, 632, 633, 634, 635, 637, 638, 644, 645, 647, 648, 649, 650, 651, 652, 653, 654, 655, 657, 658, 660, 661, 662, 663, 666, 675, 710, 711, 712, 725, 728, 739, 756, 761, 762, 775, 780, 782, 783, 784, 794, 795, 796, 799, 817, 824, 826, 827, 828, 829, 834, 835, 836, 838, 842, 852, 853, 855, 856, 857, 874, 877, 880, 891, 892, 893, 895, 896, 898, 901, 906, 908, 910, 911, 913, 914, 917, 926, 930, 947, 951, 958, 964, 965, 967, 981, 983, 985, 996, 998, 1006, 1012, 1015, 1024, 1028, 1044, 1045, 1046, 1053, 1060, 1116, 1117, 1126, 1178, 1188, 1189, 1190, 1195, 1204, 1213, 1232, 1268, 1269, 1315, 1316, 1317, 1318, 1319, 1327, 1331, 1332, 1333, 1342, 1344, 1345, 1346, 1347, 1349, 1357, 1365, 1366, 1367, 1374, 1381, 1386, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1414, 1417, 1421, 1422, 1426, 1427, 1428, 1473, 1474, 1475, 1482, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1522, 1536, 1537, 1544, 1545, 1546, 1547, 1548, 1549, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1561, 1562, 1564, 1567, 1568, 1578, 1582, 1583, 1585, 1605, 1608, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1625, 1626, 1628, 1629, 1633, 1639, 1648, 1650, 1652, 1657, 1658, 1661, 1670, 1672, 1673, 1674, 1675, 1676, 1680, 1685, 1687, 1689, 1691, 1695, 1698, 1699, 1703, 1704, 1705, 1706, 1709, 1712, 1717, 1719, 1721, 1722, 1724, 1727, 1728, 1729, 1730, 1732, 1734, 1735, 1736, 1737, 1738], "doubl": [1, 3, 26, 434, 440, 568, 626, 628, 633, 637, 638, 661, 668, 677, 687, 728, 780, 796, 824, 848, 895, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 939, 940, 941, 942, 944, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 957, 958, 959, 960, 961, 962, 963, 964, 975, 976, 977, 978, 979, 986, 1060, 1116, 1173, 1176, 1205, 1314, 1342, 1344, 1345, 1346, 1347, 1349, 1359, 1360, 1374, 1463, 1469, 1611, 1612, 1613, 1615, 1616, 1629, 1639, 1648, 1670, 1679, 1689, 1699, 1701, 1709, 1713, 1716, 1729, 1730, 1733], "bfloat16": [1, 18, 877, 895, 946, 963, 1116, 1585, 1689, 1729, 1730, 1733, 1734, 1739], "cfloat": [1, 10, 20, 266, 436, 568, 668, 687, 780, 865, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 939, 940, 941, 942, 944, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 957, 958, 959, 960, 961, 962, 963, 964, 986, 1463, 1560, 1629, 1648, 1666, 1730, 1733], "cdoubl": [1, 10, 668, 687, 780, 895, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 939, 940, 941, 942, 944, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 957, 958, 959, 960, 961, 962, 963, 964, 986, 1116, 1463, 1629, 1648, 1730, 1733], "beta": [1, 10, 41, 54, 55, 60, 61, 62, 63, 64, 65, 106, 107, 276, 469, 504, 581, 584, 585, 586, 644, 688, 717, 718, 725, 726, 728, 852, 914, 1034, 1035, 1036, 1071, 1077, 1079, 1080, 1081, 1088, 1104, 1147, 1152, 1155, 1231, 1266, 1270, 1433, 1434, 1435, 1437, 1443, 1447, 1546, 1604, 1607, 1621, 1675, 1677, 1685, 1699, 1713, 1719, 1724, 1727, 1730], "even": [1, 7, 17, 18, 20, 26, 41, 42, 494, 531, 622, 686, 797, 798, 799, 800, 801, 802, 803, 804, 812, 813, 814, 817, 880, 907, 924, 926, 930, 931, 932, 933, 947, 951, 953, 954, 958, 959, 964, 990, 997, 1053, 1155, 1188, 1189, 1190, 1251, 1319, 1384, 1420, 1422, 1458, 1571, 1629, 1665, 1676, 1679, 1680, 1687, 1691, 1695, 1696, 1699, 1701, 1702, 1704, 1706, 1708, 1709, 1710, 1711, 1713, 1716, 1717, 1726, 1730], "though": [1, 20, 42, 105, 620, 622, 632, 797, 798, 800, 893, 896, 990, 1422, 1676, 1680, 1690, 1691, 1696, 1708, 1709, 1719], "signatur": [1, 17, 28, 40, 42, 353, 440, 506, 895, 1116, 1316, 1317, 1318, 1319, 1389, 1410, 1422, 1625, 1701, 1713, 1716, 1717, 1724, 1727, 1738], "veri": [1, 4, 6, 7, 17, 18, 20, 42, 684, 957, 1079, 1080, 1081, 1319, 1320, 1384, 1436, 1458, 1599, 1648, 1667, 1678, 1688, 1696, 1701, 1702, 1703, 1704, 1706, 1708, 1712, 1715, 1716, 1723, 1724, 1725, 1727], "unlik": [1, 3, 6, 24, 40, 445, 777, 817, 820, 824, 870, 930, 931, 950, 953, 958, 962, 994, 997, 999, 1088, 1321, 1322, 1561, 1582, 1664, 1678, 1679, 1688, 1699, 1708, 1710, 1730], "coverag": [1, 6, 42, 1675, 1676, 1681, 1690, 1719, 1738], "plan": [1, 2, 6, 8, 20, 623, 1319, 1475, 1691, 1696, 1716], "consid": [1, 5, 7, 18, 20, 26, 35, 40, 41, 42, 589, 630, 632, 633, 637, 669, 686, 767, 768, 769, 770, 771, 802, 884, 888, 891, 895, 935, 937, 938, 939, 940, 948, 949, 952, 957, 960, 993, 1052, 1063, 1116, 1119, 1167, 1178, 1213, 1224, 1281, 1320, 1372, 1378, 1384, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1446, 1633, 1649, 1650, 1651, 1652, 1674, 1676, 1679, 1683, 1695, 1696, 1697, 1701, 1702, 1703, 1706, 1716, 1718, 1720, 1725, 1726, 1727, 1730, 1733, 1734, 1738], "ad": [1, 3, 8, 12, 17, 18, 20, 23, 24, 32, 40, 41, 42, 176, 177, 268, 274, 424, 467, 581, 582, 583, 584, 585, 586, 595, 623, 624, 625, 630, 631, 632, 633, 637, 644, 781, 785, 870, 895, 908, 972, 1029, 1030, 1031, 1033, 1034, 1035, 1036, 1044, 1045, 1046, 1047, 1048, 1049, 1063, 1071, 1079, 1080, 1081, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1122, 1123, 1130, 1144, 1155, 1159, 1167, 1191, 1192, 1193, 1210, 1237, 1238, 1239, 1315, 1316, 1317, 1318, 1319, 1320, 1328, 1389, 1396, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1420, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1443, 1444, 1445, 1446, 1447, 1480, 1546, 1547, 1548, 1587, 1604, 1607, 1621, 1674, 1676, 1678, 1683, 1687, 1690, 1695, 1703, 1705, 1706, 1716, 1719, 1732], "tutori": [1, 3, 8, 13, 20, 21, 23, 42, 623, 624, 625, 628, 1676, 1683, 1692, 1701, 1705, 1706, 1711, 1713, 1719], "how": [1, 3, 5, 6, 7, 8, 13, 17, 19, 20, 27, 35, 36, 37, 40, 42, 623, 624, 625, 628, 763, 785, 848, 870, 895, 905, 966, 1063, 1116, 1167, 1168, 1251, 1281, 1319, 1378, 1410, 1420, 1523, 1538, 1540, 1562, 1585, 1587, 1600, 1676, 1678, 1679, 1683, 1686, 1688, 1689, 1690, 1692, 1695, 1698, 1700, 1702, 1703, 1706, 1708, 1710, 1711, 1713, 1717, 1719, 1724, 1725, 1726, 1732], "major": [1, 6, 7, 8, 710, 1225, 1629, 1675, 1679], "build": [1, 7, 8, 12, 13, 20, 24, 42, 895, 904, 1116, 1162, 1178, 1213, 1676, 1692, 1696, 1713, 1714, 1717, 1719, 1725, 1732, 1733], "basic": [1, 3, 6, 8, 35, 42, 901, 967, 1319, 1452, 1680, 1692, 1697, 1703, 1716, 1725, 1731, 1732], "abov": [1, 3, 13, 19, 20, 24, 28, 35, 37, 42, 568, 610, 645, 654, 669, 739, 763, 767, 768, 769, 770, 771, 781, 840, 852, 853, 895, 896, 915, 926, 930, 931, 949, 951, 952, 955, 958, 961, 964, 967, 1032, 1063, 1116, 1144, 1152, 1167, 1314, 1423, 1452, 1475, 1553, 1554, 1585, 1590, 1609, 1625, 1646, 1649, 1650, 1651, 1652, 1674, 1676, 1678, 1679, 1696, 1697, 1698, 1699, 1701, 1703, 1706, 1710, 1711, 1713, 1716, 1719, 1724, 1725, 1726, 1727, 1728, 1734], "jacobian": [1, 24, 622, 624, 630, 633, 635, 636, 637, 638, 1667, 1696, 1701, 1703], "hessian": [1, 631, 634, 1694], "etc": [1, 3, 5, 10, 17, 18, 20, 24, 26, 35, 36, 40, 892, 895, 1052, 1116, 1319, 1538, 1539, 1540, 1564, 1674, 1678, 1679, 1701, 1702, 1706, 1708, 1713, 1715, 1716, 1719, 1724, 1727, 1729, 1732, 1735], "user": [1, 5, 6, 7, 8, 9, 10, 13, 17, 18, 20, 21, 24, 25, 26, 28, 32, 35, 36, 38, 40, 41, 42, 105, 290, 622, 628, 636, 690, 719, 832, 895, 966, 1116, 1159, 1161, 1162, 1163, 1317, 1319, 1325, 1331, 1332, 1333, 1338, 1339, 1349, 1357, 1386, 1400, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1482, 1484, 1520, 1674, 1675, 1676, 1678, 1679, 1683, 1688, 1690, 1691, 1695, 1696, 1697, 1699, 1701, 1703, 1704, 1705, 1706, 1708, 1713, 1717, 1718, 1719, 1721, 1724, 1725, 1727, 1731, 1732, 1734, 1738], "input": [1, 2, 3, 5, 8, 10, 13, 15, 17, 18, 19, 20, 21, 23, 24, 25, 28, 40, 42, 43, 105, 215, 235, 256, 436, 469, 561, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 604, 605, 606, 607, 608, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 621, 622, 626, 628, 630, 631, 632, 633, 634, 635, 636, 637, 638, 641, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 659, 660, 662, 664, 665, 667, 668, 669, 670, 671, 672, 673, 675, 677, 679, 680, 681, 682, 683, 684, 685, 686, 687, 699, 725, 726, 728, 759, 760, 761, 762, 764, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 780, 781, 783, 786, 787, 788, 789, 790, 791, 792, 793, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 836, 837, 838, 839, 840, 841, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 861, 862, 863, 864, 865, 866, 867, 868, 869, 872, 873, 874, 875, 877, 880, 884, 885, 886, 887, 888, 889, 890, 891, 892, 895, 898, 899, 901, 906, 908, 910, 911, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 982, 983, 984, 986, 988, 989, 990, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1128, 1129, 1130, 1131, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1280, 1281, 1282, 1283, 1304, 1312, 1313, 1314, 1316, 1317, 1318, 1319, 1327, 1328, 1331, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1349, 1351, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1387, 1389, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1401, 1403, 1404, 1405, 1406, 1410, 1411, 1412, 1414, 1417, 1420, 1421, 1422, 1424, 1425, 1427, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446, 1451, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1475, 1476, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1487, 1499, 1501, 1519, 1520, 1521, 1522, 1536, 1537, 1540, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1550, 1552, 1554, 1556, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1573, 1575, 1576, 1577, 1580, 1581, 1582, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1610, 1618, 1619, 1620, 1621, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1640, 1642, 1643, 1644, 1645, 1648, 1649, 1651, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1671, 1673, 1676, 1677, 1678, 1679, 1680, 1681, 1683, 1685, 1690, 1691, 1692, 1694, 1696, 1698, 1699, 1700, 1701, 1702, 1705, 1706, 1709, 1710, 1711, 1713, 1715, 1717, 1718, 1719, 1720, 1722, 1723, 1724, 1725, 1727, 1728, 1730, 1731, 1734, 1736, 1737, 1738], "can": [1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 105, 109, 209, 278, 290, 411, 440, 465, 467, 495, 565, 568, 582, 609, 610, 619, 620, 621, 622, 623, 624, 625, 628, 630, 631, 632, 633, 634, 635, 636, 637, 638, 640, 646, 663, 669, 679, 688, 689, 691, 696, 698, 700, 707, 708, 725, 727, 731, 733, 735, 739, 740, 763, 780, 781, 782, 785, 786, 799, 801, 802, 803, 804, 817, 820, 839, 840, 848, 851, 856, 857, 870, 886, 892, 893, 895, 896, 898, 899, 901, 905, 906, 908, 910, 911, 916, 919, 926, 934, 937, 941, 942, 947, 950, 953, 954, 958, 964, 966, 984, 985, 987, 998, 1014, 1017, 1022, 1023, 1024, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1038, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1053, 1054, 1058, 1059, 1060, 1061, 1064, 1065, 1068, 1073, 1074, 1075, 1077, 1083, 1085, 1086, 1089, 1090, 1091, 1102, 1106, 1107, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1117, 1118, 1121, 1122, 1123, 1126, 1127, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1143, 1144, 1147, 1152, 1155, 1158, 1159, 1161, 1162, 1163, 1165, 1166, 1168, 1180, 1181, 1182, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1208, 1209, 1224, 1237, 1238, 1239, 1257, 1281, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1321, 1322, 1334, 1335, 1336, 1341, 1350, 1351, 1353, 1361, 1362, 1365, 1366, 1367, 1378, 1381, 1389, 1410, 1411, 1415, 1420, 1422, 1426, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1442, 1443, 1444, 1445, 1446, 1447, 1449, 1450, 1451, 1452, 1455, 1456, 1458, 1461, 1463, 1472, 1476, 1481, 1482, 1484, 1485, 1499, 1502, 1505, 1506, 1508, 1519, 1523, 1537, 1538, 1542, 1551, 1555, 1565, 1571, 1574, 1585, 1587, 1588, 1590, 1603, 1611, 1612, 1613, 1614, 1615, 1616, 1620, 1625, 1629, 1639, 1643, 1646, 1648, 1656, 1659, 1667, 1672, 1674, 1675, 1676, 1677, 1678, 1679, 1683, 1685, 1687, 1688, 1689, 1690, 1691, 1692, 1695, 1697, 1698, 1699, 1700, 1701, 1703, 1704, 1705, 1706, 1708, 1709, 1710, 1711, 1712, 1713, 1715, 1716, 1717, 1718, 1719, 1720, 1722, 1724, 1725, 1726, 1727, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739], "lambda": [1, 17, 24, 41, 42, 213, 440, 664, 930, 931, 932, 933, 966, 1072, 1153, 1165, 1253, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1446, 1452, 1454, 1457, 1667, 1680, 1696, 1701, 1715, 1716, 1724, 1734, 1738], "captur": [1, 13, 42, 688, 689, 717, 723, 728, 898, 1433, 1434, 1676, 1680, 1701, 1704, 1713, 1716, 1719, 1737], "f": [1, 9, 18, 24, 26, 27, 32, 33, 41, 42, 128, 213, 241, 290, 331, 624, 625, 799, 801, 808, 817, 848, 895, 902, 905, 906, 966, 1082, 1084, 1085, 1087, 1116, 1165, 1180, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1195, 1196, 1197, 1204, 1205, 1208, 1209, 1215, 1248, 1250, 1251, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446, 1574, 1667, 1676, 1678, 1679, 1689, 1690, 1696, 1699, 1701, 1702, 1703, 1704, 1706, 1712, 1713, 1716, 1717, 1727, 1732, 1734, 1738], "three": [1, 20, 23, 40, 42, 618, 778, 848, 857, 938, 941, 942, 943, 958, 987, 1031, 1046, 1049, 1088, 1111, 1384, 1422, 1452, 1585, 1679, 1696, 1699, 1700, 1701, 1713, 1716, 1717, 1719, 1724, 1726, 1727, 1732], "anoth": [1, 6, 17, 18, 20, 24, 25, 40, 42, 439, 688, 689, 690, 691, 832, 904, 930, 931, 934, 958, 1059, 1060, 1117, 1126, 1314, 1385, 1676, 1678, 1679, 1695, 1696, 1698, 1699, 1701, 1706, 1708, 1712, 1716, 1717, 1725, 1726, 1727, 1733, 1735], "constant": [1, 17, 42, 763, 821, 822, 823, 892, 895, 899, 910, 942, 967, 1041, 1042, 1043, 1060, 1063, 1070, 1147, 1167, 1210, 1213, 1251, 1337, 1368, 1385, 1444, 1449, 1452, 1503, 1504, 1646, 1677, 1679, 1695, 1701, 1706, 1710, 1713, 1715, 1727], "boolean": [1, 12, 24, 35, 42, 355, 357, 619, 648, 650, 651, 653, 689, 690, 691, 786, 839, 851, 884, 885, 886, 887, 888, 891, 919, 967, 984, 989, 1017, 1034, 1035, 1036, 1071, 1079, 1080, 1081, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1116, 1155, 1386, 1389, 1475, 1633, 1643, 1678, 1680, 1701, 1730, 1732, 1733, 1734], "flag": [1, 2, 12, 19, 20, 21, 25, 36, 38, 40, 42, 603, 630, 632, 645, 654, 667, 668, 713, 832, 852, 853, 870, 876, 883, 987, 1122, 1224, 1225, 1319, 1328, 1386, 1389, 1538, 1585, 1587, 1592, 1648, 1660, 1675, 1676, 1679, 1688, 1696, 1699, 1701, 1710, 1713, 1716, 1719, 1732, 1733], "inform": [1, 2, 3, 4, 6, 7, 8, 16, 17, 18, 19, 20, 21, 23, 26, 27, 28, 31, 35, 36, 40, 42, 146, 163, 210, 268, 276, 450, 467, 469, 569, 632, 637, 638, 647, 785, 816, 818, 870, 892, 895, 911, 924, 931, 940, 983, 1044, 1045, 1046, 1047, 1048, 1049, 1077, 1086, 1116, 1122, 1131, 1143, 1159, 1161, 1163, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1205, 1224, 1281, 1282, 1283, 1319, 1328, 1410, 1420, 1474, 1568, 1587, 1592, 1660, 1667, 1676, 1679, 1692, 1696, 1698, 1699, 1701, 1705, 1706, 1709, 1713, 1716, 1718, 1719, 1730, 1732, 1733, 1734, 1737, 1739], "well": [1, 3, 5, 6, 8, 12, 18, 20, 35, 40, 42, 568, 725, 895, 899, 905, 910, 930, 931, 932, 934, 940, 953, 958, 1034, 1035, 1036, 1052, 1086, 1116, 1155, 1234, 1235, 1319, 1475, 1481, 1504, 1507, 1676, 1679, 1689, 1691, 1695, 1696, 1699, 1701, 1703, 1706, 1708, 1710, 1713, 1716, 1719, 1724, 1726, 1727, 1731, 1732, 1735], "relat": [1, 6, 17, 19, 20, 26, 39, 848, 934, 1063, 1147, 1167, 1319, 1465, 1691, 1696, 1716, 1724, 1727, 1728, 1734, 1738], "mechan": [1, 7, 20, 29, 33, 35, 42, 609, 785, 870, 895, 1116, 1420, 1587, 1639, 1675, 1688, 1701, 1705, 1706, 1722, 1724, 1725], "confus": [1, 7, 895, 1116, 1696, 1699, 1716], "receiv": [1, 6, 8, 17, 20, 23, 24, 41, 739, 895, 1116, 1318, 1319, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1460, 1679, 1687, 1688, 1695, 1708, 1717, 1724, 1725, 1726], "initi": [1, 3, 4, 7, 14, 17, 18, 23, 26, 28, 35, 36, 38, 40, 43, 448, 531, 609, 689, 714, 719, 720, 723, 724, 748, 842, 871, 893, 895, 907, 908, 966, 967, 985, 1034, 1035, 1036, 1037, 1039, 1047, 1048, 1049, 1053, 1059, 1060, 1068, 1069, 1071, 1079, 1080, 1081, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1103, 1116, 1124, 1131, 1133, 1155, 1165, 1296, 1297, 1298, 1299, 1300, 1301, 1304, 1314, 1319, 1321, 1322, 1323, 1324, 1325, 1326, 1338, 1339, 1349, 1353, 1357, 1384, 1386, 1389, 1415, 1429, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1461, 1582, 1583, 1611, 1612, 1613, 1614, 1615, 1616, 1639, 1677, 1678, 1679, 1687, 1694, 1696, 1699, 1700, 1701, 1705, 1712, 1713, 1715, 1716, 1717, 1723, 1724, 1725], "memori": [1, 3, 5, 10, 18, 19, 23, 24, 25, 40, 42, 105, 110, 125, 127, 130, 133, 134, 135, 150, 161, 164, 194, 209, 222, 252, 280, 286, 292, 294, 295, 347, 411, 416, 439, 451, 452, 475, 476, 531, 534, 555, 568, 608, 610, 622, 628, 637, 638, 658, 673, 688, 693, 694, 708, 717, 718, 721, 725, 727, 728, 731, 733, 734, 735, 737, 738, 739, 740, 741, 745, 746, 747, 751, 781, 782, 783, 784, 832, 833, 834, 836, 895, 912, 940, 1060, 1086, 1087, 1116, 1159, 1160, 1161, 1280, 1319, 1327, 1356, 1384, 1410, 1420, 1427, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1552, 1554, 1556, 1557, 1639, 1660, 1673, 1676, 1685, 1688, 1690, 1691, 1696, 1701, 1708, 1713, 1717, 1718, 1719, 1724, 1727, 1729, 1730, 1731, 1733], "overlap": [1, 17, 18, 20, 23, 40, 42, 608, 637, 638, 784, 892, 1063, 1167, 1319, 1625, 1660, 1699, 1730], "dens": [1, 23, 173, 388, 495, 496, 536, 537, 538, 539, 540, 645, 654, 852, 853, 914, 967, 1602, 1604, 1606, 1607, 1610, 1611, 1612, 1613, 1615, 1616, 1621, 1630, 1660, 1710, 1727, 1730], "stride": [1, 10, 93, 176, 209, 294, 451, 472, 494, 532, 568, 595, 608, 645, 654, 782, 784, 794, 799, 817, 835, 836, 852, 853, 859, 895, 904, 908, 914, 965, 981, 983, 1001, 1029, 1030, 1031, 1044, 1045, 1046, 1047, 1048, 1049, 1063, 1084, 1085, 1092, 1093, 1094, 1095, 1096, 1097, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1128, 1167, 1180, 1181, 1182, 1188, 1189, 1190, 1191, 1192, 1193, 1207, 1234, 1235, 1237, 1238, 1239, 1240, 1241, 1242, 1280, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1309, 1310, 1311, 1319, 1323, 1324, 1331, 1332, 1333, 1334, 1335, 1336, 1361, 1362, 1365, 1366, 1367, 1375, 1376, 1426, 1547, 1548, 1551, 1553, 1554, 1555, 1557, 1558, 1565, 1606, 1633, 1645, 1650, 1652, 1665, 1672, 1677, 1680, 1689, 1713, 1724, 1727, 1729, 1730, 1732, 1733, 1734], "thu": [1, 10, 17, 20, 24, 36, 40, 42, 802, 958, 990, 1056, 1168, 1281, 1319, 1378, 1444, 1504, 1507, 1614, 1676, 1679, 1685, 1696, 1698, 1702, 1703, 1705, 1706, 1713, 1719, 1724, 1731, 1733, 1734], "rowmajor": [1, 1319], "contigu": [1, 10, 18, 286, 451, 472, 568, 1062, 1119, 1253, 1319, 1559, 1565, 1629, 1633, 1677, 1690, 1691, 1714, 1721, 1727, 1729, 1731], "create_graph": [1, 105, 622, 630, 631, 632, 633, 634, 635, 636, 1677, 1695], "preserv": [1, 17, 24, 42, 451, 606, 609, 822, 823, 899, 905, 1117, 1126, 1168, 1224, 1281, 1372, 1378, 1574, 1578, 1603, 1639, 1676, 1685, 1689, 1694, 1699, 1710, 1713, 1724, 1727, 1730], "attempt": [1, 7, 12, 35, 36, 40, 670, 682, 899, 905, 985, 1321, 1322, 1660, 1676, 1679, 1689, 1690, 1695, 1699, 1701, 1712, 1716, 1724], "guarante": [1, 5, 8, 17, 20, 23, 24, 35, 37, 41, 42, 606, 895, 904, 1053, 1116, 1319, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1603, 1660, 1696, 1698, 1709, 1710, 1716, 1718, 1720, 1724, 1726], "preexist": 1, "behavior": [1, 2, 6, 12, 16, 18, 20, 21, 23, 24, 25, 28, 33, 36, 40, 41, 42, 209, 274, 424, 465, 568, 582, 608, 658, 662, 675, 775, 784, 826, 833, 834, 895, 905, 908, 910, 940, 947, 951, 964, 965, 966, 981, 990, 998, 1053, 1056, 1077, 1086, 1116, 1131, 1155, 1168, 1178, 1213, 1280, 1281, 1314, 1315, 1319, 1378, 1421, 1422, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1469, 1475, 1558, 1565, 1629, 1633, 1646, 1660, 1674, 1676, 1680, 1681, 1683, 1689, 1696, 1697, 1699, 1701, 1709, 1710, 1711, 1713, 1715, 1716, 1717, 1720, 1721, 1724, 1731], "let": [1, 6, 7, 17, 18, 19, 24, 36, 42, 439, 448, 671, 848, 895, 914, 924, 926, 930, 931, 932, 933, 934, 935, 940, 941, 944, 946, 953, 955, 957, 958, 1116, 1319, 1384, 1639, 1683, 1689, 1690, 1696, 1699, 1700, 1701, 1706, 1708, 1709, 1710, 1711, 1712, 1716, 1725, 1726, 1727, 1732], "first": [1, 4, 5, 6, 8, 12, 17, 18, 20, 21, 23, 24, 26, 28, 32, 35, 36, 40, 42, 171, 209, 245, 541, 562, 581, 584, 586, 589, 604, 605, 614, 619, 620, 621, 636, 637, 644, 648, 649, 651, 652, 653, 656, 658, 660, 674, 687, 689, 697, 768, 770, 771, 772, 777, 780, 781, 786, 799, 801, 820, 834, 839, 848, 851, 859, 860, 861, 872, 884, 893, 902, 907, 908, 914, 919, 924, 927, 934, 950, 953, 960, 961, 963, 966, 967, 983, 984, 990, 994, 997, 998, 999, 1001, 1005, 1007, 1013, 1017, 1020, 1024, 1030, 1031, 1037, 1045, 1046, 1048, 1049, 1059, 1060, 1062, 1067, 1068, 1082, 1085, 1086, 1101, 1108, 1110, 1111, 1131, 1144, 1195, 1280, 1314, 1319, 1353, 1386, 1387, 1389, 1400, 1410, 1433, 1434, 1435, 1436, 1437, 1443, 1451, 1455, 1458, 1459, 1465, 1475, 1476, 1499, 1536, 1569, 1570, 1578, 1606, 1609, 1614, 1640, 1641, 1645, 1650, 1652, 1658, 1661, 1664, 1669, 1674, 1676, 1678, 1679, 1686, 1688, 1689, 1691, 1695, 1696, 1699, 1701, 1702, 1703, 1706, 1708, 1709, 1710, 1711, 1712, 1713, 1715, 1717, 1718, 1719, 1724, 1725, 1726, 1727, 1728, 1732, 1736, 1738], "accord": [1, 8, 26, 610, 646, 658, 778, 858, 955, 989, 1007, 1024, 1060, 1314, 1319, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1452, 1458, 1476, 1482, 1617, 1640, 1668, 1679, 1687, 1690, 1694, 1706, 1710, 1712, 1716, 1726, 1734], "retain": [1, 20, 588, 590, 591, 594, 604, 605, 610, 899, 916, 947, 951, 964, 982, 994, 996, 997, 999, 1002, 1012, 1013, 1014, 1015, 1422, 1473, 1476, 1574, 1623, 1624, 1628, 1649, 1650, 1651, 1652, 1662, 1663, 1688, 1708], "over": [1, 8, 17, 18, 19, 20, 21, 24, 26, 33, 36, 40, 42, 434, 592, 641, 663, 739, 741, 758, 759, 760, 761, 762, 781, 848, 856, 895, 910, 947, 951, 963, 964, 966, 974, 996, 998, 1015, 1021, 1022, 1023, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1060, 1063, 1064, 1065, 1071, 1076, 1077, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1088, 1104, 1107, 1108, 1109, 1110, 1111, 1116, 1119, 1120, 1121, 1123, 1130, 1144, 1147, 1148, 1150, 1155, 1164, 1167, 1172, 1173, 1174, 1175, 1176, 1177, 1180, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1196, 1197, 1208, 1209, 1225, 1231, 1234, 1235, 1237, 1238, 1239, 1248, 1249, 1256, 1317, 1331, 1332, 1333, 1334, 1335, 1336, 1359, 1360, 1365, 1366, 1367, 1375, 1376, 1381, 1419, 1547, 1548, 1563, 1608, 1610, 1625, 1628, 1641, 1656, 1667, 1679, 1687, 1688, 1689, 1690, 1695, 1697, 1698, 1700, 1701, 1703, 1706, 1708, 1709, 1715, 1724, 1725, 1727, 1735], "time": [1, 3, 4, 6, 7, 8, 12, 17, 18, 20, 21, 23, 24, 25, 26, 32, 35, 36, 37, 40, 41, 42, 43, 245, 268, 440, 445, 568, 580, 581, 582, 583, 584, 585, 586, 589, 607, 636, 642, 644, 656, 664, 666, 679, 686, 689, 690, 691, 728, 741, 758, 761, 772, 780, 802, 803, 804, 810, 821, 822, 823, 831, 834, 884, 892, 895, 902, 907, 910, 911, 915, 920, 924, 925, 926, 930, 931, 932, 933, 934, 935, 939, 940, 941, 944, 946, 950, 953, 955, 957, 958, 966, 967, 983, 990, 1001, 1006, 1007, 1009, 1018, 1026, 1027, 1029, 1030, 1031, 1033, 1034, 1035, 1036, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1053, 1060, 1063, 1064, 1065, 1068, 1079, 1080, 1081, 1086, 1088, 1102, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1128, 1129, 1131, 1152, 1155, 1167, 1168, 1169, 1170, 1178, 1181, 1182, 1208, 1209, 1253, 1254, 1255, 1270, 1316, 1317, 1318, 1319, 1338, 1339, 1349, 1353, 1357, 1361, 1362, 1384, 1385, 1387, 1389, 1421, 1454, 1463, 1464, 1475, 1484, 1486, 1506, 1523, 1564, 1570, 1606, 1620, 1625, 1626, 1641, 1675, 1678, 1679, 1680, 1685, 1688, 1694, 1696, 1698, 1700, 1701, 1702, 1703, 1705, 1706, 1708, 1710, 1712, 1713, 1715, 1716, 1717, 1718, 1719, 1720, 1724, 1725, 1726, 1728, 1732], "4": [1, 3, 10, 15, 17, 18, 19, 20, 23, 24, 25, 26, 33, 35, 42, 146, 163, 197, 209, 244, 266, 268, 270, 272, 276, 387, 398, 399, 424, 436, 440, 445, 448, 451, 465, 469, 488, 494, 506, 508, 510, 534, 559, 568, 578, 579, 580, 581, 584, 586, 587, 588, 590, 591, 592, 594, 595, 604, 605, 606, 611, 612, 613, 614, 615, 628, 630, 633, 634, 635, 644, 647, 650, 654, 655, 656, 660, 662, 665, 666, 669, 670, 671, 674, 677, 681, 682, 683, 684, 687, 760, 763, 770, 772, 774, 775, 778, 779, 781, 784, 786, 796, 797, 799, 801, 809, 815, 817, 820, 821, 822, 823, 824, 825, 826, 829, 831, 832, 834, 837, 838, 839, 848, 851, 855, 856, 857, 858, 860, 861, 865, 869, 872, 884, 886, 892, 901, 906, 908, 915, 916, 917, 918, 919, 920, 924, 926, 927, 933, 935, 937, 938, 939, 940, 942, 944, 947, 949, 951, 953, 955, 957, 960, 961, 962, 964, 965, 968, 970, 971, 976, 978, 979, 981, 983, 984, 989, 990, 994, 995, 996, 997, 998, 999, 1000, 1005, 1006, 1007, 1015, 1016, 1017, 1024, 1029, 1040, 1041, 1042, 1045, 1046, 1048, 1049, 1057, 1059, 1060, 1061, 1063, 1067, 1068, 1086, 1087, 1112, 1113, 1119, 1121, 1123, 1128, 1129, 1131, 1137, 1138, 1139, 1140, 1141, 1155, 1167, 1168, 1169, 1170, 1171, 1178, 1180, 1189, 1192, 1204, 1205, 1213, 1224, 1248, 1251, 1254, 1255, 1280, 1281, 1282, 1283, 1314, 1319, 1332, 1334, 1335, 1336, 1339, 1341, 1350, 1353, 1366, 1367, 1384, 1389, 1400, 1412, 1413, 1415, 1421, 1422, 1423, 1425, 1427, 1430, 1443, 1448, 1449, 1455, 1459, 1460, 1464, 1468, 1469, 1472, 1473, 1475, 1476, 1485, 1506, 1545, 1549, 1551, 1553, 1555, 1557, 1558, 1559, 1560, 1561, 1562, 1564, 1565, 1569, 1570, 1571, 1573, 1574, 1578, 1590, 1597, 1599, 1603, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1625, 1628, 1631, 1632, 1633, 1635, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1646, 1649, 1650, 1651, 1652, 1654, 1655, 1656, 1658, 1659, 1660, 1661, 1664, 1665, 1666, 1668, 1669, 1673, 1676, 1677, 1678, 1679, 1680, 1688, 1690, 1691, 1694, 1696, 1697, 1699, 1700, 1701, 1706, 1708, 1711, 1712, 1713, 1716, 1717, 1719, 1724, 1727, 1728, 1730, 1731, 1732, 1733, 1734], "fact": [1, 3, 7, 447, 645, 654, 680, 848, 852, 853, 930, 931, 958, 1676, 1701, 1703, 1713, 1725], "reset": [1, 622, 688, 731, 733, 745, 746, 747, 1068, 1132, 1353, 1465, 1502, 1507, 1549, 1630, 1687, 1713, 1723], "phase": [1, 18, 930, 931, 1458, 1629, 1677, 1712], "recreat": [1, 1696], "everi": [1, 2, 7, 8, 17, 18, 20, 23, 24, 26, 40, 42, 434, 440, 562, 626, 763, 781, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 848, 857, 895, 926, 940, 950, 953, 985, 1028, 1054, 1055, 1056, 1057, 1061, 1109, 1116, 1149, 1151, 1155, 1199, 1200, 1201, 1206, 1237, 1238, 1239, 1253, 1269, 1316, 1317, 1318, 1319, 1374, 1385, 1416, 1419, 1420, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1501, 1629, 1658, 1679, 1687, 1695, 1696, 1699, 1700, 1701, 1703, 1707, 1713, 1715, 1716, 1717, 1718, 1719, 1720, 1724, 1725, 1726, 1729, 1732, 1734], "valid": [1, 20, 24, 33, 35, 42, 667, 725, 781, 893, 895, 896, 916, 930, 931, 940, 941, 942, 953, 958, 990, 1044, 1045, 1046, 1188, 1189, 1190, 1213, 1314, 1340, 1341, 1350, 1395, 1400, 1404, 1428, 1448, 1449, 1454, 1455, 1456, 1457, 1459, 1460, 1461, 1475, 1480, 1481, 1676, 1677, 1678, 1679, 1690, 1691, 1696, 1701, 1704, 1713, 1715, 1718, 1724, 1725], "altern": [1, 17, 20, 42, 857, 902, 966, 1144, 1161, 1163, 1232, 1319, 1427, 1499, 1584, 1660, 1673, 1674, 1680, 1696, 1706, 1709, 1710, 1712, 1713], "never": [1, 5, 6, 18, 20, 35, 36, 176, 177, 609, 664, 892, 941, 942, 953, 966, 1319, 1410, 1696, 1699, 1701, 1716, 1717, 1724, 1734], "long": [1, 6, 8, 17, 35, 41, 795, 871, 997, 1002, 1013, 1039, 1052, 1060, 1086, 1087, 1123, 1197, 1327, 1342, 1344, 1345, 1346, 1347, 1349, 1356, 1374, 1474, 1636, 1640, 1650, 1652, 1657, 1675, 1679, 1688, 1689, 1690, 1696, 1697, 1699, 1701, 1702, 1708, 1710, 1713, 1716, 1718, 1723, 1729, 1730, 1732, 1733], "hard": [1, 6, 7, 20, 36, 967, 1072, 1215, 1216, 1676, 1677, 1678, 1696, 1713, 1716], "matter": [1, 4, 626, 768, 902, 905, 910, 1319, 1696, 1716], "discourag": [1, 750, 754, 1696, 1724], "most": [1, 3, 4, 6, 7, 13, 17, 20, 23, 24, 25, 26, 27, 34, 35, 37, 38, 41, 42, 451, 626, 627, 628, 633, 637, 641, 750, 763, 781, 870, 880, 893, 896, 1002, 1024, 1122, 1163, 1213, 1319, 1389, 1441, 1646, 1674, 1676, 1678, 1679, 1681, 1688, 1690, 1691, 1696, 1699, 1701, 1708, 1709, 1710, 1715, 1718, 1719, 1725, 1726, 1727, 1730, 1732, 1734], "aggress": [1, 892, 1696, 1724], "buffer": [1, 4, 17, 18, 40, 610, 697, 728, 834, 895, 902, 905, 916, 966, 1034, 1035, 1036, 1053, 1089, 1090, 1091, 1116, 1155, 1319, 1321, 1386, 1389, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1407, 1415, 1417, 1444, 1574, 1603, 1643, 1678, 1692, 1696, 1700, 1701, 1706, 1711, 1713, 1717], "free": [1, 6, 19, 20, 24, 26, 35, 36, 42, 734, 751, 898, 910, 967, 1685, 1694, 1696, 1699, 1701, 1702, 1708, 1712], "reus": [1, 20, 42, 439, 1696, 1699, 1724], "make": [1, 2, 3, 4, 5, 7, 12, 13, 17, 18, 19, 20, 22, 24, 26, 27, 32, 35, 36, 37, 38, 40, 42, 94, 177, 448, 622, 667, 668, 669, 689, 690, 691, 768, 785, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 821, 822, 823, 870, 895, 899, 904, 905, 924, 925, 937, 938, 939, 967, 1032, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1077, 1116, 1126, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1213, 1215, 1224, 1281, 1319, 1372, 1378, 1384, 1400, 1415, 1420, 1454, 1582, 1603, 1611, 1612, 1613, 1615, 1616, 1633, 1643, 1660, 1674, 1676, 1678, 1679, 1683, 1687, 1688, 1689, 1691, 1695, 1696, 1697, 1699, 1700, 1701, 1702, 1703, 1706, 1708, 1710, 1712, 1713, 1715, 1716, 1718, 1719, 1720, 1724, 1725, 1726, 1730, 1732, 1736, 1738], "effici": [1, 3, 7, 10, 17, 24, 40, 105, 622, 627, 636, 666, 840, 912, 950, 967, 987, 1024, 1055, 1056, 1057, 1060, 1061, 1122, 1128, 1129, 1163, 1685, 1691, 1696, 1700, 1701, 1703, 1707, 1709, 1717, 1719, 1724, 1725, 1727, 1730, 1731, 1735], "few": [1, 6, 7, 18, 26, 781, 1060, 1319, 1674, 1679, 1696, 1699, 1701, 1702, 1704, 1709, 1712, 1717, 1719, 1731, 1733, 1735], "occas": [1, 6, 1696], "actual": [1, 7, 26, 28, 40, 42, 679, 799, 817, 906, 910, 1047, 1048, 1049, 1213, 1319, 1401, 1452, 1479, 1674, 1678, 1679, 1689, 1696, 1699, 1700, 1701, 1703, 1708, 1712, 1719, 1724, 1727, 1729, 1734], "signific": [1, 3, 1459, 1667, 1696, 1699], "amount": [1, 2, 3, 4, 6, 17, 20, 26, 35, 42, 638, 708, 733, 735, 739, 892, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1063, 1104, 1119, 1167, 1196, 1394, 1395, 1397, 1398, 1400, 1402, 1403, 1404, 1405, 1406, 1407, 1690, 1696, 1698, 1699, 1702, 1704, 1724], "heavi": [1, 20, 1696, 1712], "pressur": [1, 1696], "might": [1, 3, 4, 8, 12, 13, 20, 23, 24, 35, 41, 42, 105, 439, 622, 687, 780, 910, 911, 1213, 1319, 1320, 1674, 1676, 1687, 1691, 1696, 1698, 1699, 1700, 1701, 1703, 1705, 1710, 1713, 1716, 1717, 1719, 1724, 1725, 1726, 1731, 1733, 1734], "keep": [1, 3, 6, 17, 18, 23, 26, 35, 690, 966, 1034, 1035, 1036, 1040, 1059, 1079, 1080, 1081, 1125, 1155, 1213, 1224, 1319, 1396, 1563, 1674, 1676, 1688, 1690, 1691, 1696, 1699, 1700, 1702, 1703, 1708, 1715, 1719, 1724, 1725, 1726], "track": [1, 5, 26, 290, 694, 731, 733, 745, 746, 747, 870, 998, 1034, 1035, 1036, 1079, 1080, 1081, 1089, 1090, 1091, 1098, 1099, 1100, 1155, 1319, 1396, 1687, 1688, 1690, 1691, 1696, 1699, 1701, 1702, 1705, 1706, 1715, 1717, 1718, 1725, 1726, 1727], "afterward": [1, 1116, 1314, 1319], "start": [1, 3, 4, 7, 8, 10, 17, 18, 20, 26, 32, 34, 35, 36, 37, 40, 41, 42, 387, 388, 448, 489, 593, 595, 731, 733, 744, 745, 746, 803, 804, 820, 834, 893, 907, 920, 965, 981, 1016, 1024, 1029, 1030, 1031, 1060, 1062, 1109, 1110, 1111, 1117, 1119, 1205, 1251, 1319, 1391, 1395, 1397, 1410, 1430, 1452, 1458, 1558, 1588, 1600, 1611, 1612, 1613, 1615, 1616, 1674, 1677, 1678, 1683, 1688, 1690, 1696, 1697, 1699, 1700, 1702, 1706, 1707, 1708, 1712, 1713, 1715, 1718, 1724, 1725, 1726, 1727], "sure": [1, 6, 8, 17, 20, 25, 27, 36, 38, 42, 622, 785, 832, 870, 899, 910, 911, 967, 1319, 1420, 1454, 1643, 1679, 1689, 1696, 1700, 1702, 1703, 1712, 1713, 1718, 1719, 1724, 1725, 1726, 1732], "longer": [1, 20, 37, 582, 637, 638, 892, 899, 1319, 1422, 1687, 1696, 1699, 1724, 1726], "find": [1, 6, 12, 20, 35, 42, 848, 916, 967, 1047, 1048, 1049, 1086, 1465, 1476, 1578, 1630, 1674, 1685, 1688, 1690, 1696, 1698, 1699, 1700, 1701, 1702, 1703, 1708, 1710, 1713, 1724, 1730, 1732, 1736, 1738], "quick": [1, 6, 1706], "guid": [1, 7, 8, 17, 906, 1675, 1699, 1716, 1719], "expect": [1, 3, 5, 6, 8, 17, 18, 20, 23, 26, 33, 35, 37, 42, 592, 630, 631, 632, 633, 634, 635, 728, 802, 804, 821, 822, 823, 869, 892, 895, 910, 911, 939, 960, 961, 997, 1035, 1036, 1052, 1068, 1069, 1070, 1071, 1080, 1081, 1082, 1086, 1087, 1088, 1098, 1099, 1100, 1116, 1122, 1123, 1131, 1133, 1149, 1155, 1159, 1161, 1163, 1168, 1210, 1224, 1248, 1256, 1257, 1268, 1281, 1282, 1283, 1314, 1319, 1353, 1411, 1460, 1582, 1634, 1665, 1674, 1675, 1681, 1696, 1700, 1702, 1703, 1706, 1713, 1715, 1716, 1719, 1720, 1721, 1732, 1734], "instead": [1, 3, 5, 7, 8, 12, 17, 18, 20, 24, 26, 32, 35, 36, 40, 42, 176, 361, 411, 451, 610, 620, 630, 631, 632, 633, 636, 637, 660, 666, 816, 818, 841, 882, 892, 893, 895, 896, 900, 924, 925, 931, 933, 949, 952, 958, 964, 983, 997, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1050, 1052, 1053, 1055, 1056, 1057, 1061, 1068, 1076, 1082, 1083, 1084, 1085, 1086, 1107, 1108, 1109, 1110, 1111, 1116, 1119, 1120, 1121, 1123, 1130, 1131, 1143, 1147, 1148, 1149, 1155, 1164, 1180, 1181, 1182, 1185, 1186, 1196, 1206, 1213, 1225, 1237, 1238, 1239, 1248, 1256, 1268, 1319, 1341, 1350, 1361, 1362, 1422, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1451, 1452, 1458, 1547, 1548, 1558, 1578, 1610, 1629, 1660, 1667, 1676, 1678, 1679, 1690, 1694, 1695, 1696, 1700, 1701, 1702, 1703, 1704, 1708, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1718, 1719, 1725, 1727, 1738], "var": [1, 28, 33, 35, 38, 1034, 1035, 1036, 1070, 1071, 1079, 1080, 1081, 1088, 1155, 1210, 1546, 1663, 1677, 1679, 1689, 1714], "thing": [1, 3, 6, 7, 20, 42, 904, 998, 1032, 1215, 1604, 1678, 1696, 1699, 1701, 1702, 1703, 1708, 1716, 1719, 1720, 1726], "detach": [1, 5, 177, 401, 411, 673, 895, 1039, 1116, 1197, 1215, 1639, 1676, 1677, 1689, 1702, 1713, 1714, 1721, 1727, 1731, 1733], "register_hook": [1, 1689, 1696], "name": [1, 2, 3, 12, 18, 19, 20, 24, 26, 28, 29, 32, 33, 35, 40, 42, 592, 641, 711, 893, 895, 896, 902, 905, 911, 925, 930, 931, 937, 938, 940, 941, 942, 943, 953, 954, 956, 958, 959, 966, 983, 1116, 1166, 1340, 1341, 1350, 1384, 1385, 1386, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1416, 1417, 1419, 1428, 1429, 1499, 1506, 1522, 1537, 1574, 1583, 1661, 1674, 1675, 1676, 1677, 1679, 1680, 1683, 1686, 1687, 1688, 1694, 1696, 1700, 1701, 1703, 1705, 1706, 1713, 1716, 1717, 1718, 1724, 1725, 1729, 1732, 1734, 1735, 1736, 1737, 1738, 1739], "factori": [1, 10, 24, 26, 29, 33, 1485, 1506, 1677, 1690, 1699], "ones": [1, 17, 19, 23, 24, 40, 41, 42, 105, 209, 268, 357, 398, 399, 401, 467, 622, 631, 633, 634, 635, 636, 637, 646, 658, 763, 771, 794, 870, 892, 895, 906, 915, 941, 957, 966, 1033, 1059, 1063, 1070, 1071, 1088, 1116, 1120, 1121, 1123, 1167, 1280, 1314, 1319, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1400, 1401, 1414, 1417, 1427, 1538, 1546, 1563, 1581, 1600, 1642, 1646, 1670, 1677, 1679, 1681, 1689, 1690, 1696, 1697, 1699, 1701, 1707, 1709, 1710, 1713, 1714, 1715, 1716, 1719, 1724, 1726, 1728, 1730, 1733], "autograd_tensor": 1, "base": [1, 3, 6, 8, 12, 13, 17, 20, 21, 23, 24, 26, 28, 33, 35, 36, 42, 628, 686, 743, 744, 778, 781, 824, 848, 858, 897, 908, 920, 958, 969, 971, 973, 981, 1053, 1116, 1119, 1120, 1121, 1125, 1159, 1161, 1163, 1230, 1319, 1384, 1391, 1395, 1397, 1430, 1431, 1432, 1433, 1434, 1435, 1444, 1446, 1447, 1472, 1481, 1485, 1487, 1502, 1503, 1504, 1506, 1507, 1549, 1574, 1587, 1629, 1630, 1640, 1650, 1652, 1668, 1675, 1677, 1679, 1698, 1699, 1700, 1701, 1706, 1717, 1719, 1724, 1725, 1727, 1728, 1731, 1732, 1734, 1736, 1737], "static": [1, 3, 7, 12, 19, 21, 24, 26, 40, 619, 620, 621, 908, 1159, 1319, 1536, 1538, 1540, 1676, 1677, 1678, 1679, 1699, 1705, 1717, 1720, 1724, 1729], "Then": [1, 36, 42, 1063, 1167, 1386, 1697, 1700, 1701, 1709, 1710, 1713, 1715, 1716, 1724, 1725, 1736], "op": [1, 4, 20, 42, 105, 455, 475, 556, 622, 628, 636, 666, 692, 705, 707, 710, 711, 725, 726, 750, 754, 756, 845, 896, 908, 910, 911, 972, 1132, 1350, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1463, 1505, 1508, 1540, 1588, 1648, 1679, 1683, 1685, 1687, 1689, 1690, 1698, 1699, 1701, 1708, 1716, 1718, 1719, 1720, 1721, 1722, 1729, 1731, 1733], "ctx": [1, 33, 619, 620, 621, 626, 627, 628, 629, 1695, 1701, 1713], "gradcheck": [1, 638, 1675, 1701], "extend": [1, 24, 27, 37, 42, 628, 1118, 1127, 1675, 1683, 1696, 1705, 1707, 1708, 1713, 1716, 1727, 1738], "staticmethod": [1, 626, 627, 628, 629, 1679, 1695, 1701, 1713, 1724], "i": [1, 5, 6, 7, 8, 12, 17, 18, 20, 21, 23, 24, 25, 35, 38, 40, 42, 43, 105, 108, 109, 268, 270, 276, 465, 467, 469, 494, 568, 576, 578, 579, 581, 593, 595, 611, 612, 613, 614, 615, 622, 630, 632, 637, 638, 646, 647, 660, 665, 666, 680, 681, 683, 684, 686, 714, 752, 772, 780, 781, 791, 797, 798, 799, 800, 801, 803, 804, 806, 807, 809, 810, 811, 813, 814, 815, 816, 818, 825, 830, 832, 834, 837, 861, 874, 875, 877, 880, 892, 914, 923, 930, 931, 932, 933, 934, 935, 942, 958, 963, 967, 968, 969, 971, 974, 982, 985, 990, 1002, 1024, 1032, 1033, 1034, 1035, 1036, 1044, 1045, 1046, 1048, 1049, 1052, 1053, 1055, 1056, 1057, 1059, 1060, 1061, 1062, 1063, 1069, 1083, 1087, 1088, 1089, 1090, 1091, 1106, 1107, 1118, 1119, 1120, 1121, 1122, 1123, 1125, 1127, 1130, 1133, 1148, 1149, 1151, 1155, 1159, 1163, 1164, 1165, 1166, 1167, 1188, 1189, 1190, 1199, 1200, 1201, 1204, 1205, 1206, 1224, 1248, 1256, 1268, 1281, 1283, 1314, 1319, 1328, 1354, 1356, 1358, 1384, 1385, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1410, 1411, 1415, 1437, 1445, 1451, 1468, 1476, 1537, 1549, 1555, 1558, 1561, 1573, 1578, 1593, 1595, 1597, 1599, 1608, 1609, 1610, 1614, 1618, 1625, 1629, 1633, 1637, 1638, 1646, 1649, 1650, 1651, 1652, 1664, 1676, 1677, 1678, 1679, 1680, 1685, 1688, 1689, 1690, 1691, 1695, 1697, 1698, 1699, 1701, 1702, 1703, 1706, 1711, 1712, 1713, 1724, 1726, 1727, 1728, 1730, 1732, 1734, 1739], "result": [1, 3, 4, 6, 7, 8, 12, 17, 18, 20, 24, 26, 28, 33, 36, 40, 41, 42, 108, 176, 177, 209, 210, 270, 290, 353, 448, 450, 506, 569, 581, 582, 583, 584, 585, 588, 590, 591, 592, 594, 607, 609, 624, 625, 630, 631, 632, 633, 634, 635, 637, 638, 644, 647, 658, 662, 667, 673, 675, 682, 684, 696, 698, 700, 725, 726, 739, 759, 760, 761, 762, 763, 775, 799, 802, 808, 817, 824, 826, 829, 833, 834, 840, 856, 857, 859, 872, 886, 895, 898, 899, 906, 910, 911, 913, 915, 916, 920, 934, 936, 938, 939, 947, 951, 953, 955, 956, 957, 964, 974, 975, 982, 994, 996, 997, 998, 999, 1002, 1012, 1015, 1053, 1055, 1056, 1057, 1061, 1063, 1068, 1082, 1086, 1116, 1131, 1167, 1195, 1213, 1224, 1277, 1280, 1281, 1319, 1353, 1384, 1386, 1417, 1420, 1421, 1422, 1423, 1458, 1463, 1465, 1472, 1473, 1476, 1549, 1562, 1568, 1582, 1599, 1607, 1609, 1610, 1621, 1625, 1628, 1629, 1630, 1635, 1639, 1640, 1645, 1646, 1648, 1649, 1651, 1667, 1676, 1677, 1678, 1679, 1685, 1689, 1690, 1691, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1706, 1709, 1710, 1713, 1715, 1717, 1718, 1720, 1721, 1724, 1725, 1727, 1730, 1732, 1733, 1734, 1737, 1738], "save_for_backward": [1, 620, 627, 629, 1695, 1696, 1701, 1713], "grad_output": [1, 619, 626, 636, 638, 895, 1116, 1318, 1677, 1696, 1699, 1701, 1706], "saved_tensor": [1, 627, 628, 629, 1695, 1696, 1701], "avail": [1, 2, 7, 8, 12, 13, 17, 19, 20, 26, 35, 36, 40, 706, 708, 719, 722, 729, 730, 748, 749, 751, 901, 958, 959, 985, 1159, 1168, 1224, 1281, 1465, 1585, 1625, 1630, 1660, 1674, 1675, 1676, 1678, 1679, 1683, 1688, 1696, 1699, 1701, 1704, 1706, 1707, 1710, 1712, 1716, 1718, 1720, 1724, 1737, 1738], "cost": [1, 3, 4, 7, 8, 18, 40, 666, 950, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1699, 1710, 1720, 1725], "both": [1, 2, 3, 12, 17, 18, 20, 21, 24, 28, 33, 34, 35, 36, 40, 41, 42, 52, 294, 625, 631, 632, 633, 634, 635, 644, 686, 707, 775, 780, 797, 827, 828, 829, 838, 840, 848, 855, 872, 885, 886, 892, 895, 908, 916, 917, 965, 981, 990, 997, 1029, 1030, 1034, 1035, 1036, 1041, 1044, 1045, 1046, 1047, 1048, 1049, 1063, 1071, 1077, 1079, 1080, 1081, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1109, 1110, 1111, 1116, 1155, 1167, 1168, 1180, 1181, 1182, 1188, 1189, 1190, 1191, 1192, 1193, 1237, 1238, 1239, 1313, 1319, 1361, 1362, 1365, 1366, 1367, 1389, 1458, 1547, 1548, 1604, 1606, 1625, 1629, 1633, 1646, 1676, 1678, 1679, 1689, 1690, 1692, 1695, 1696, 1697, 1701, 1703, 1706, 1710, 1711, 1713, 1716, 1717, 1719, 1722, 1724, 1726, 1727, 1728, 1734, 1736, 1737], "cpu": [1, 4, 12, 14, 17, 20, 40, 43, 74, 151, 244, 281, 290, 411, 531, 541, 595, 609, 610, 642, 645, 654, 684, 689, 696, 697, 698, 700, 782, 784, 794, 799, 817, 829, 834, 835, 845, 846, 852, 853, 895, 902, 904, 905, 914, 924, 926, 930, 931, 932, 933, 935, 937, 940, 942, 943, 949, 952, 955, 958, 959, 965, 966, 981, 985, 997, 1053, 1059, 1116, 1277, 1319, 1410, 1411, 1423, 1426, 1475, 1551, 1553, 1555, 1557, 1558, 1586, 1588, 1589, 1599, 1611, 1612, 1613, 1614, 1615, 1616, 1629, 1639, 1640, 1641, 1650, 1652, 1657, 1660, 1672, 1675, 1676, 1677, 1679, 1683, 1685, 1688, 1689, 1699, 1704, 1706, 1708, 1709, 1710, 1712, 1713, 1717, 1718, 1720, 1723, 1724, 1729, 1730, 1733, 1734, 1735], "There": [1, 6, 8, 12, 16, 20, 35, 42, 1053, 1086, 1131, 1319, 1327, 1415, 1674, 1676, 1678, 1679, 1690, 1696, 1699, 1701, 1702, 1705, 1708, 1712, 1713, 1716, 1719, 1720, 1724, 1726, 1733, 1735], "moment": [1, 40, 682, 1365, 1366, 1367, 1433, 1434, 1435, 1437, 1443, 1447, 1685, 1688, 1691, 1718, 1724], "nvprof": [1, 4, 639, 1699], "regist": [1, 13, 18, 20, 23, 24, 35, 37, 40, 42, 440, 728, 895, 966, 1116, 1117, 1118, 1126, 1127, 1144, 1315, 1316, 1317, 1318, 1319, 1320, 1384, 1385, 1386, 1387, 1389, 1683, 1687, 1688, 1700, 1701, 1705, 1706, 1713, 1716, 1724], "activ": [1, 5, 6, 8, 19, 37, 721, 739, 967, 1028, 1055, 1056, 1057, 1061, 1071, 1088, 1115, 1117, 1134, 1145, 1159, 1161, 1163, 1206, 1243, 1265, 1319, 1387, 1388, 1389, 1417, 1422, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1667, 1685, 1688, 1699, 1701, 1706, 1713, 1715, 1717, 1718, 1719, 1720, 1721, 1724, 1736, 1737], "emit_nvtx": [1, 4], "vtune": [1, 4], "emit_itt": 1, "use_cuda": [1, 1718], "record_shap": [1, 1718], "with_flop": [1, 1718], "profile_memori": [1, 1718], "with_stack": [1, 1718], "with_modul": [1, 1718], "use_kineto": 1, "use_cpu": 1, "experimental_config": [1, 1718], "hold": [1, 20, 33, 35, 37, 38, 40, 41, 42, 488, 967, 1063, 1117, 1118, 1126, 1127, 1167, 1314, 1319, 1321, 1322, 1386, 1396, 1410, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1440, 1443, 1444, 1445, 1446, 1447, 1611, 1612, 1613, 1614, 1615, 1616, 1697, 1699, 1701, 1702, 1705, 1708, 1715, 1718, 1724, 1725, 1726, 1727, 1729, 1730, 1732, 1733], "summari": [1, 3, 36, 740, 1590, 1687, 1732], "hood": [1, 40, 41, 1688, 1696, 1699, 1700, 1708, 1716, 1726], "just": [1, 2, 6, 12, 18, 19, 20, 24, 26, 33, 40, 42, 541, 582, 592, 619, 621, 641, 679, 680, 910, 911, 949, 952, 957, 958, 985, 1055, 1056, 1057, 1061, 1319, 1389, 1390, 1448, 1479, 1505, 1508, 1649, 1650, 1651, 1652, 1674, 1676, 1688, 1695, 1696, 1701, 1703, 1705, 1706, 1707, 1711, 1716, 1717, 1724, 1725, 1731, 1733, 1737], "record": [1, 5, 8, 23, 27, 28, 29, 33, 36, 41, 42, 398, 399, 400, 401, 402, 448, 595, 645, 654, 689, 690, 691, 782, 783, 784, 794, 799, 817, 834, 835, 836, 852, 853, 895, 910, 914, 965, 981, 1053, 1116, 1426, 1427, 1501, 1502, 1503, 1504, 1507, 1509, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1611, 1612, 1613, 1614, 1615, 1616, 1639, 1672, 1673, 1676, 1678, 1695, 1696, 1699, 1701, 1713, 1718, 1724, 1732, 1733, 1734, 1736, 1737], "event": [1, 22, 24, 26, 34, 41, 641, 642, 643, 690, 691, 739, 742, 910, 911, 972, 1687, 1688, 1699, 1718, 1732], "being": [1, 3, 8, 17, 20, 23, 24, 26, 28, 35, 36, 37, 40, 41, 42, 52, 630, 636, 674, 690, 741, 758, 794, 827, 828, 884, 895, 899, 985, 995, 1000, 1032, 1033, 1050, 1052, 1059, 1060, 1064, 1065, 1070, 1076, 1083, 1107, 1108, 1116, 1119, 1120, 1121, 1122, 1123, 1130, 1147, 1148, 1164, 1178, 1185, 1186, 1196, 1208, 1209, 1213, 1225, 1248, 1256, 1319, 1353, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1403, 1404, 1429, 1475, 1476, 1484, 1625, 1676, 1679, 1687, 1689, 1690, 1691, 1695, 1696, 1699, 1701, 1702, 1703, 1706, 1708, 1713, 1716, 1719, 1722, 1724, 1725, 1727, 1734, 1736, 1738], "those": [1, 2, 4, 12, 17, 18, 20, 23, 24, 41, 42, 698, 708, 768, 770, 910, 952, 958, 966, 1024, 1032, 1033, 1050, 1052, 1060, 1076, 1083, 1107, 1108, 1119, 1120, 1121, 1123, 1130, 1147, 1148, 1164, 1168, 1185, 1186, 1196, 1205, 1225, 1248, 1256, 1447, 1506, 1585, 1629, 1646, 1667, 1678, 1689, 1690, 1695, 1696, 1699, 1704, 1706, 1710, 1711, 1713, 1715, 1722, 1724, 1726, 1727], "report": [1, 3, 4, 20, 28, 36, 41, 42, 1695, 1699, 1717], "runtim": [1, 3, 5, 12, 20, 42, 608, 641, 778, 858, 895, 1116, 1321, 1322, 1471, 1509, 1660, 1668, 1679, 1689, 1690, 1696, 1699, 1701, 1708, 1713], "note": [1, 2, 3, 5, 7, 10, 12, 13, 16, 17, 18, 19, 20, 23, 24, 25, 26, 33, 35, 37, 40, 41, 42, 105, 176, 331, 451, 452, 465, 467, 469, 595, 614, 622, 628, 630, 631, 632, 633, 634, 635, 636, 638, 666, 687, 756, 763, 768, 781, 802, 832, 834, 837, 848, 870, 882, 892, 893, 895, 896, 901, 967, 990, 1032, 1033, 1039, 1047, 1048, 1049, 1050, 1052, 1059, 1060, 1068, 1070, 1076, 1082, 1083, 1086, 1107, 1108, 1116, 1117, 1119, 1120, 1121, 1122, 1123, 1126, 1127, 1130, 1131, 1147, 1148, 1155, 1159, 1164, 1168, 1185, 1186, 1196, 1204, 1205, 1213, 1224, 1225, 1248, 1251, 1256, 1257, 1269, 1314, 1319, 1328, 1334, 1335, 1336, 1422, 1444, 1450, 1452, 1458, 1459, 1475, 1481, 1484, 1523, 1549, 1610, 1611, 1612, 1613, 1615, 1616, 1621, 1625, 1629, 1646, 1660, 1674, 1676, 1677, 1680, 1688, 1691, 1692, 1696, 1697, 1698, 1700, 1701, 1703, 1704, 1705, 1706, 1708, 1709, 1710, 1711, 1716, 1718, 1720, 1722, 1725, 1726, 1727, 1731, 1732, 1739], "propag": [1, 22, 24, 35, 42, 465, 581, 584, 585, 586, 590, 591, 592, 593, 644, 827, 828, 1012, 1359, 1360, 1361, 1362, 1372, 1375, 1376, 1378, 1379, 1380, 1520, 1522, 1610, 1688, 1689, 1695, 1699, 1701, 1703, 1705, 1736, 1737], "async": [1, 20, 21, 41, 555, 1319, 1680, 1699, 1705, 1729], "task": [1, 3, 6, 18, 898, 913, 1079, 1080, 1081, 1679, 1698, 1705, 1706, 1712], "cuda": [1, 3, 4, 5, 10, 12, 16, 17, 18, 20, 23, 40, 43, 105, 244, 268, 276, 290, 295, 467, 469, 475, 531, 595, 607, 609, 622, 636, 645, 647, 654, 688, 689, 690, 691, 692, 705, 707, 717, 780, 782, 783, 784, 794, 797, 798, 799, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 835, 852, 853, 895, 914, 916, 924, 925, 926, 930, 931, 932, 933, 935, 936, 937, 938, 940, 941, 942, 943, 949, 952, 955, 956, 958, 959, 965, 966, 981, 985, 1002, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1053, 1059, 1086, 1116, 1131, 1155, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1205, 1213, 1224, 1251, 1281, 1282, 1283, 1314, 1319, 1321, 1322, 1421, 1423, 1426, 1433, 1434, 1475, 1551, 1553, 1555, 1557, 1558, 1585, 1607, 1611, 1612, 1613, 1614, 1615, 1616, 1629, 1639, 1641, 1650, 1652, 1657, 1660, 1672, 1675, 1677, 1683, 1689, 1691, 1701, 1706, 1709, 1713, 1717, 1718, 1723, 1724, 1729, 1730, 1733, 1734, 1735], "cudaev": 1, "approxim": [1, 3, 18, 23, 35, 42, 848, 958, 967, 1024, 1066, 1130, 1145, 1152, 1211, 1256, 1265, 1385, 1430, 1465, 1630, 1646, 1677, 1679, 1699, 1700, 1701, 1703, 1739], "4u": 1, "shape": [1, 7, 10, 18, 20, 24, 40, 42, 52, 126, 146, 163, 355, 357, 388, 400, 402, 424, 449, 450, 465, 467, 469, 494, 516, 568, 580, 582, 583, 592, 608, 614, 627, 631, 633, 634, 635, 641, 646, 647, 649, 652, 657, 659, 663, 664, 681, 699, 770, 771, 772, 774, 775, 780, 781, 782, 784, 786, 801, 802, 803, 804, 812, 813, 814, 820, 826, 827, 828, 829, 835, 837, 839, 851, 856, 857, 861, 869, 872, 886, 908, 910, 911, 914, 919, 920, 924, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 983, 984, 985, 989, 998, 1003, 1004, 1006, 1007, 1017, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1128, 1129, 1130, 1131, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1180, 1181, 1182, 1184, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1195, 1196, 1204, 1205, 1209, 1213, 1215, 1224, 1225, 1230, 1237, 1238, 1239, 1249, 1250, 1253, 1254, 1255, 1257, 1281, 1314, 1319, 1321, 1322, 1328, 1338, 1339, 1349, 1351, 1353, 1357, 1359, 1360, 1361, 1362, 1365, 1366, 1367, 1374, 1384, 1386, 1389, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1400, 1403, 1404, 1423, 1426, 1463, 1472, 1476, 1547, 1548, 1551, 1553, 1554, 1555, 1562, 1564, 1565, 1569, 1578, 1581, 1606, 1607, 1609, 1612, 1614, 1620, 1625, 1626, 1629, 1633, 1635, 1642, 1646, 1656, 1657, 1658, 1670, 1672, 1676, 1677, 1679, 1689, 1690, 1691, 1696, 1697, 1699, 1701, 1702, 1718, 1721, 1724, 1727, 1728, 1732, 1733, 1734], "about": [1, 7, 8, 14, 17, 19, 20, 21, 23, 26, 28, 32, 34, 36, 42, 210, 450, 569, 637, 638, 693, 694, 708, 731, 733, 734, 735, 737, 738, 739, 740, 745, 746, 747, 924, 931, 983, 1060, 1410, 1458, 1584, 1674, 1676, 1678, 1679, 1683, 1698, 1699, 1701, 1702, 1705, 1708, 1709, 1711, 1716, 1718, 1719, 1722, 1725, 1726, 1727, 1731, 1733], "dimens": [1, 10, 17, 24, 42, 173, 187, 209, 215, 268, 270, 272, 276, 387, 388, 425, 426, 427, 445, 465, 467, 469, 488, 493, 495, 496, 510, 534, 535, 559, 568, 581, 587, 588, 590, 591, 592, 594, 604, 605, 606, 607, 616, 617, 618, 636, 655, 663, 666, 667, 668, 669, 670, 687, 698, 700, 759, 760, 761, 762, 763, 768, 769, 770, 771, 772, 778, 781, 797, 798, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 818, 820, 837, 848, 857, 858, 869, 872, 892, 915, 916, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 946, 947, 948, 949, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 974, 975, 982, 986, 990, 994, 996, 997, 998, 999, 1002, 1004, 1005, 1012, 1013, 1014, 1015, 1016, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1045, 1046, 1048, 1049, 1050, 1051, 1052, 1053, 1056, 1058, 1059, 1060, 1062, 1063, 1066, 1067, 1070, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1085, 1086, 1088, 1096, 1097, 1102, 1103, 1104, 1105, 1106, 1107, 1110, 1111, 1115, 1122, 1123, 1124, 1125, 1128, 1129, 1130, 1134, 1135, 1136, 1143, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1161, 1163, 1164, 1165, 1166, 1167, 1178, 1184, 1188, 1189, 1190, 1191, 1192, 1193, 1195, 1212, 1213, 1214, 1215, 1224, 1227, 1230, 1231, 1232, 1249, 1250, 1251, 1268, 1269, 1281, 1319, 1328, 1351, 1372, 1374, 1378, 1384, 1385, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1411, 1412, 1414, 1416, 1419, 1421, 1422, 1463, 1466, 1473, 1475, 1476, 1544, 1549, 1563, 1564, 1565, 1569, 1578, 1580, 1581, 1590, 1600, 1603, 1605, 1608, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1620, 1622, 1623, 1624, 1625, 1628, 1629, 1633, 1634, 1636, 1640, 1641, 1642, 1643, 1645, 1646, 1648, 1649, 1650, 1651, 1652, 1655, 1656, 1657, 1658, 1659, 1660, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1677, 1678, 1679, 1691, 1694, 1697, 1699, 1702, 1703, 1709, 1717, 1719, 1727, 1728, 1730, 1732, 1733], "collect": [1, 3, 6, 17, 19, 21, 23, 26, 35, 41, 42, 664, 721, 782, 857, 998, 1319, 1426, 1484, 1485, 1506, 1551, 1555, 1672, 1677, 1678, 1679, 1687, 1699, 1715, 1718, 1719, 1722, 1726, 1727, 1732, 1734], "group": [1, 3, 8, 17, 18, 21, 23, 26, 32, 35, 36, 37, 38, 40, 42, 562, 610, 641, 1040, 1044, 1045, 1046, 1047, 1048, 1049, 1071, 1092, 1093, 1094, 1095, 1096, 1097, 1155, 1188, 1189, 1190, 1191, 1192, 1193, 1214, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1309, 1310, 1311, 1319, 1323, 1324, 1331, 1332, 1333, 1334, 1335, 1336, 1365, 1366, 1367, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1440, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1658, 1674, 1677, 1679, 1688, 1694, 1699, 1700, 1713, 1715, 1716, 1718, 1724, 1732], "prof": [1, 32, 1718], "key_averag": [1, 1718], "group_by_input_shap": [1, 641, 1718], "skew": [1, 3, 4, 946, 1384], "neglig": [1, 907, 1585], "bottom": [1, 1213], "But": [1, 6, 41, 439, 910, 940, 1319, 1696, 1701, 1702, 1703, 1716, 1717, 1731, 1738], "total": [1, 3, 4, 6, 17, 18, 20, 32, 34, 35, 36, 40, 607, 642, 700, 734, 739, 751, 834, 856, 857, 1039, 1063, 1076, 1083, 1107, 1122, 1167, 1250, 1319, 1381, 1421, 1423, 1425, 1452, 1458, 1564, 1590, 1625, 1674, 1678, 1687, 1699, 1704, 1715], "artifici": 1, "estim": [1, 3, 17, 24, 682, 686, 848, 892, 1034, 1035, 1036, 1066, 1070, 1071, 1079, 1080, 1081, 1088, 1155, 1211, 1385, 1444, 1718], "flop": [1, 1718], "hardwar": [1, 7, 930, 931, 958, 1660, 1699, 1710, 1720], "matrix": [1, 2, 18, 20, 24, 146, 163, 581, 584, 585, 586, 644, 646, 655, 656, 664, 666, 667, 668, 669, 682, 686, 763, 767, 768, 770, 780, 781, 840, 844, 859, 915, 924, 925, 926, 928, 930, 931, 932, 933, 934, 935, 936, 937, 939, 940, 941, 942, 944, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 957, 958, 959, 960, 962, 964, 967, 975, 983, 985, 987, 990, 993, 1001, 1007, 1009, 1059, 1060, 1086, 1167, 1204, 1205, 1384, 1389, 1416, 1422, 1463, 1464, 1465, 1475, 1585, 1602, 1604, 1606, 1607, 1609, 1611, 1612, 1613, 1614, 1615, 1616, 1621, 1629, 1630, 1633, 1641, 1644, 1646, 1648, 1649, 1650, 1651, 1652, 1661, 1667, 1679, 1689, 1690, 1694, 1698, 1699, 1701, 1703, 1706, 1709, 1718, 1727, 1732, 1733], "2d": [1, 24, 539, 540, 669, 682, 686, 768, 781, 950, 951, 1022, 1026, 1030, 1034, 1035, 1045, 1048, 1052, 1056, 1060, 1064, 1079, 1080, 1085, 1110, 1119, 1121, 1122, 1123, 1168, 1169, 1170, 1173, 1176, 1178, 1181, 1189, 1192, 1200, 1205, 1208, 1235, 1238, 1248, 1251, 1284, 1287, 1290, 1328, 1332, 1335, 1359, 1361, 1366, 1372, 1376, 1378, 1379, 1380, 1385, 1416, 1548, 1609, 1614, 1648, 1685, 1694, 1701, 1718, 1719], "alloc": [1, 4, 10, 18, 24, 26, 35, 209, 286, 439, 690, 691, 693, 694, 707, 708, 731, 733, 735, 737, 738, 739, 740, 746, 747, 751, 782, 784, 1557, 1639, 1688, 1691, 1696, 1699, 1700, 1704, 1718, 1730], "dealloc": [1, 834, 1688, 1699, 1702, 1704, 1718], "line": [1, 4, 20, 42, 641, 870, 895, 905, 1116, 1178, 1213, 1590, 1676, 1679, 1680, 1691, 1697, 1701, 1703, 1710, 1712, 1713, 1718], "hierarchi": [1, 42, 899, 1522, 1680, 1701, 1718, 1719], "callstack": [1, 20, 1718], "A": [1, 2, 3, 5, 6, 7, 8, 12, 17, 18, 20, 21, 23, 24, 26, 32, 35, 36, 37, 40, 41, 43, 348, 510, 531, 546, 575, 587, 592, 643, 645, 654, 655, 657, 662, 667, 668, 675, 682, 686, 689, 690, 691, 697, 699, 700, 765, 780, 781, 786, 794, 795, 796, 808, 839, 848, 851, 852, 853, 857, 885, 886, 887, 888, 891, 893, 895, 898, 902, 905, 907, 910, 911, 915, 919, 924, 925, 926, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 964, 967, 975, 983, 984, 985, 986, 987, 991, 1017, 1033, 1037, 1039, 1052, 1059, 1060, 1069, 1070, 1078, 1087, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1106, 1115, 1116, 1122, 1144, 1149, 1151, 1159, 1164, 1165, 1178, 1184, 1196, 1204, 1215, 1225, 1232, 1243, 1268, 1269, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1338, 1339, 1349, 1354, 1355, 1356, 1357, 1358, 1384, 1386, 1389, 1411, 1412, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1441, 1443, 1444, 1445, 1447, 1451, 1452, 1454, 1457, 1458, 1459, 1465, 1475, 1479, 1499, 1537, 1538, 1540, 1541, 1544, 1545, 1546, 1547, 1548, 1559, 1565, 1571, 1574, 1603, 1605, 1608, 1620, 1624, 1625, 1629, 1630, 1633, 1643, 1648, 1649, 1650, 1651, 1652, 1656, 1657, 1658, 1659, 1660, 1663, 1667, 1670, 1674, 1676, 1677, 1678, 1679, 1683, 1685, 1689, 1690, 1694, 1695, 1698, 1699, 1701, 1702, 1708, 1709, 1711, 1713, 1716, 1717, 1718, 1719, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1732, 1733, 1737, 1738, 1739], "aten": [1, 3, 12, 725, 1007, 1676, 1677, 1683, 1698, 1712, 1718, 1719], "torchscript": [1, 3, 7, 23, 42, 568, 893, 896, 898, 899, 900, 901, 906, 910, 912, 1675, 1680, 1711, 1713, 1718, 1724], "eager": [1, 7, 756, 893, 896, 906, 1589, 1679, 1699, 1718, 1720, 1722], "experiment": [1, 2, 18, 20, 23, 40, 42, 630, 632, 636, 755, 925, 936, 938, 939, 943, 956, 1319, 1667, 1676, 1678, 1689, 1690, 1710, 1712, 1716, 1717, 1718], "kineto": [1, 1718], "_experimentalconfig": [1, 1718], "librari": [1, 2, 3, 4, 7, 8, 10, 12, 13, 17, 19, 20, 25, 33, 37, 42, 684, 690, 709, 713, 725, 832, 907, 938, 985, 1599, 1687, 1698, 1700, 1701, 1702, 1705, 1706, 1708, 1709, 1712, 1713, 1716, 1718, 1719, 1724, 1738], "compat": [1, 12, 17, 24, 26, 40, 42, 449, 450, 555, 568, 620, 657, 679, 680, 895, 900, 912, 925, 936, 949, 952, 1116, 1224, 1428, 1565, 1674, 1675, 1678, 1679, 1688, 1689, 1695, 1701, 1711, 1716, 1718, 1719, 1724, 1729], "100": [1, 3, 17, 20, 23, 24, 42, 255, 855, 895, 906, 912, 950, 965, 972, 981, 998, 1006, 1024, 1032, 1033, 1034, 1035, 1036, 1045, 1046, 1048, 1049, 1051, 1052, 1079, 1080, 1081, 1116, 1123, 1125, 1155, 1164, 1195, 1196, 1248, 1331, 1332, 1335, 1336, 1436, 1448, 1449, 1454, 1455, 1456, 1457, 1460, 1461, 1544, 1677, 1679, 1688, 1698, 1699, 1715, 1720, 1726, 1727, 1732], "realli": [1, 6, 42, 1679, 1696, 1716], "y": [1, 10, 12, 17, 24, 32, 40, 42, 568, 571, 614, 616, 617, 618, 624, 625, 628, 630, 631, 632, 633, 634, 635, 658, 664, 679, 686, 725, 726, 763, 774, 781, 785, 870, 901, 906, 910, 963, 972, 973, 998, 1032, 1033, 1034, 1035, 1036, 1037, 1050, 1052, 1071, 1076, 1077, 1079, 1080, 1081, 1083, 1088, 1103, 1107, 1108, 1119, 1120, 1121, 1123, 1147, 1148, 1155, 1158, 1164, 1165, 1184, 1213, 1230, 1253, 1314, 1374, 1389, 1420, 1546, 1564, 1566, 1567, 1587, 1606, 1620, 1642, 1646, 1647, 1667, 1670, 1676, 1677, 1678, 1679, 1689, 1690, 1694, 1696, 1697, 1698, 1699, 1703, 1704, 1707, 1713, 1716, 1719, 1724, 1726, 1728, 1732, 1735, 1736, 1737], "column": [1, 3, 18, 146, 215, 536, 539, 674, 682, 686, 763, 780, 794, 822, 823, 860, 930, 931, 934, 950, 953, 958, 962, 967, 983, 1007, 1167, 1204, 1205, 1384, 1465, 1475, 1609, 1611, 1612, 1613, 1615, 1616, 1629, 1646, 1650, 1652, 1661, 1694, 1703, 1727], "remov": [1, 3, 18, 19, 20, 24, 36, 38, 40, 42, 440, 496, 592, 666, 667, 728, 780, 841, 892, 895, 899, 983, 985, 986, 990, 993, 1116, 1117, 1126, 1215, 1315, 1316, 1317, 1318, 1319, 1385, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1403, 1404, 1405, 1406, 1408, 1409, 1422, 1475, 1482, 1538, 1558, 1580, 1620, 1629, 1633, 1648, 1655, 1674, 1685, 1696, 1706, 1711, 1713, 1716, 1726], "breviti": [1, 42, 1713], "print": [1, 3, 17, 19, 20, 26, 27, 32, 33, 36, 40, 41, 895, 899, 901, 902, 906, 985, 1037, 1040, 1078, 1103, 1116, 1128, 1129, 1195, 1251, 1254, 1255, 1304, 1312, 1313, 1327, 1338, 1339, 1349, 1357, 1389, 1399, 1400, 1401, 1402, 1405, 1417, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1461, 1590, 1674, 1676, 1677, 1696, 1698, 1699, 1701, 1706, 1707, 1713, 1716, 1718, 1724, 1732, 1733, 1736], "tabl": [1, 3, 19, 20, 42, 1059, 1204, 1677, 1679, 1701, 1716, 1718, 1719, 1724, 1727, 1734], "sort_bi": [1, 1718], "self_cpu_time_tot": [1, 1718], "avg": [1, 20, 1431], "mul": [1, 42, 374, 872, 1008, 1340, 1341, 1350, 1676, 1677, 1679, 1689, 1701, 1713, 1714, 1721, 1725, 1727, 1730, 1736], "32": [1, 2, 18, 20, 834, 892, 904, 985, 1030, 1055, 1056, 1057, 1061, 1062, 1064, 1065, 1085, 1104, 1110, 1159, 1160, 1161, 1162, 1163, 1178, 1208, 1209, 1215, 1339, 1690, 1691, 1706, 1710, 1713, 1722, 1727, 1730, 1732, 1733], "048m": 1, "200": [1, 23, 895, 972, 1116, 1544, 1679, 1727], "27": [1, 568, 962, 1451, 1472, 1661, 1713], "041m": 1, "powbackward0": 1, "9": [1, 6, 17, 18, 20, 25, 42, 268, 270, 272, 276, 387, 424, 465, 510, 532, 535, 592, 660, 666, 670, 674, 686, 763, 778, 782, 803, 804, 813, 814, 824, 827, 828, 831, 832, 848, 858, 924, 926, 940, 947, 949, 951, 962, 964, 993, 1016, 1022, 1023, 1026, 1027, 1040, 1059, 1060, 1112, 1113, 1128, 1129, 1138, 1141, 1204, 1205, 1251, 1254, 1255, 1338, 1339, 1422, 1423, 1431, 1433, 1434, 1435, 1436, 1437, 1443, 1446, 1447, 1448, 1452, 1458, 1459, 1460, 1464, 1468, 1540, 1571, 1578, 1586, 1590, 1603, 1609, 1617, 1639, 1640, 1644, 1646, 1655, 1661, 1668, 1676, 1680, 1702, 1706, 1711, 1712, 1713, 1714, 1715, 1716, 1724, 1727, 1728, 1730, 1734], "727m": 1, "55": [1, 1070, 1713], "483m": 1, "accumulategrad": [1, 1696], "148m": 1, "graphroot": 1, "691": 1, "816u": 1, "emit": [1, 12, 27, 32, 42, 910, 1592, 1679, 1723], "nvtx": [1, 4], "program": [1, 3, 4, 7, 17, 19, 20, 27, 36, 38, 42, 568, 679, 680, 731, 733, 1585, 1676, 1678, 1680, 1696, 1699, 1702, 1705, 1706, 1707, 1708, 1711, 1712, 1732], "off": [1, 6, 7, 12, 20, 26, 40, 42, 645, 654, 743, 852, 853, 892, 910, 958, 1029, 1030, 1031, 1033, 1109, 1110, 1111, 1213, 1251, 1587, 1698, 1699, 1700, 1702, 1705, 1709, 1718, 1719, 1720, 1724, 1725], "o": [1, 19, 24, 895, 1087, 1116, 1122, 1680, 1702, 1712, 1716], "trace_nam": 1, "regular": [1, 3, 4, 20, 26, 36, 42, 725, 726, 942, 943, 1039, 1054, 1055, 1056, 1057, 1061, 1101, 1115, 1116, 1117, 1118, 1126, 1127, 1206, 1243, 1314, 1321, 1322, 1417, 1434, 1679, 1690, 1691, 1701, 1705, 1706, 1713, 1716, 1719, 1722, 1724, 1728, 1737], "command": [1, 4, 19, 20, 26, 33, 36, 42, 1699, 1712, 1717, 1718, 1725], "unfortun": [1, 5, 8, 17, 1319, 1696], "wai": [1, 3, 5, 6, 7, 8, 12, 17, 18, 20, 23, 24, 28, 32, 40, 41, 42, 105, 531, 622, 631, 633, 634, 635, 636, 637, 802, 804, 848, 895, 924, 925, 940, 955, 1032, 1060, 1079, 1080, 1081, 1086, 1098, 1099, 1100, 1116, 1144, 1161, 1163, 1205, 1257, 1319, 1387, 1415, 1451, 1458, 1501, 1504, 1507, 1676, 1678, 1679, 1683, 1687, 1688, 1689, 1690, 1696, 1698, 1701, 1702, 1703, 1706, 1708, 1709, 1712, 1713, 1715, 1716, 1719, 1724, 1725, 1727, 1731, 1733], "disk": [1, 17, 19, 1574, 1696, 1706, 1716, 1732], "annot": [1, 28, 33, 42, 639, 893, 906, 1676, 1678, 1680, 1713, 1724], "wait": [1, 20, 26, 33, 35, 41, 689, 690, 691, 757, 898, 1459, 1506, 1677, 1679, 1688, 1698, 1699, 1700, 1718, 1724], "either": [1, 7, 8, 12, 17, 18, 20, 23, 24, 26, 28, 33, 35, 36, 37, 40, 41, 42, 109, 176, 268, 276, 465, 467, 568, 620, 628, 637, 638, 663, 691, 697, 781, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 834, 872, 888, 892, 895, 950, 965, 966, 981, 998, 1022, 1023, 1026, 1027, 1030, 1031, 1032, 1033, 1044, 1045, 1046, 1048, 1049, 1050, 1052, 1060, 1070, 1076, 1083, 1085, 1107, 1108, 1110, 1111, 1116, 1119, 1120, 1121, 1122, 1123, 1130, 1131, 1133, 1147, 1148, 1163, 1164, 1166, 1168, 1169, 1170, 1185, 1186, 1196, 1224, 1225, 1248, 1256, 1281, 1317, 1319, 1325, 1331, 1332, 1333, 1338, 1339, 1349, 1357, 1372, 1378, 1402, 1422, 1436, 1458, 1472, 1474, 1481, 1537, 1582, 1625, 1629, 1670, 1674, 1676, 1678, 1679, 1681, 1690, 1694, 1696, 1697, 1699, 1701, 1702, 1703, 1705, 1706, 1708, 1710, 1713, 1715, 1716, 1717, 1719, 1725, 1726, 1727, 1728, 1731, 1734, 1739], "nvidia": [1, 12, 20, 708, 735, 741, 758, 1660, 1699, 1702, 1704, 1710, 1712, 1719, 1735], "visual": [1, 42, 998, 1044, 1045, 1046, 1047, 1048, 1049, 1063, 1109, 1110, 1111, 1167, 1706, 1712, 1718, 1732], "nvvp": 1, "timelin": [1, 4], "load_nvprof": 1, "repl": 1, "append": [1, 20, 41, 42, 184, 209, 559, 728, 770, 772, 990, 1069, 1087, 1118, 1127, 1133, 1144, 1319, 1354, 1356, 1358, 1429, 1677, 1678, 1679, 1696, 1698, 1708, 1712, 1713, 1714, 1732], "size": [1, 2, 3, 6, 17, 18, 20, 24, 26, 35, 40, 42, 93, 163, 176, 197, 209, 210, 268, 270, 276, 294, 398, 399, 400, 402, 440, 445, 450, 451, 452, 465, 467, 469, 472, 494, 495, 496, 516, 532, 534, 535, 558, 559, 568, 569, 585, 586, 588, 590, 591, 592, 594, 595, 607, 608, 610, 630, 631, 632, 633, 634, 635, 641, 644, 645, 647, 654, 656, 657, 658, 659, 660, 667, 668, 669, 670, 686, 687, 693, 697, 698, 700, 739, 761, 762, 768, 771, 778, 781, 782, 783, 784, 787, 798, 799, 800, 802, 803, 804, 806, 807, 810, 811, 812, 813, 814, 816, 817, 818, 834, 835, 836, 837, 852, 853, 857, 858, 869, 872, 892, 895, 916, 925, 927, 934, 939, 947, 951, 955, 958, 960, 961, 962, 964, 965, 967, 975, 981, 982, 983, 985, 986, 990, 993, 994, 996, 997, 998, 999, 1002, 1003, 1004, 1007, 1009, 1012, 1015, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1039, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1059, 1060, 1062, 1063, 1064, 1065, 1068, 1070, 1071, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1103, 1104, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1119, 1120, 1121, 1122, 1123, 1128, 1129, 1131, 1137, 1138, 1139, 1140, 1141, 1142, 1147, 1155, 1159, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1180, 1181, 1182, 1191, 1192, 1193, 1196, 1197, 1204, 1205, 1208, 1209, 1213, 1224, 1231, 1237, 1238, 1239, 1248, 1249, 1251, 1254, 1255, 1257, 1281, 1282, 1283, 1304, 1312, 1313, 1314, 1319, 1328, 1334, 1335, 1336, 1338, 1339, 1349, 1357, 1359, 1360, 1361, 1362, 1372, 1378, 1379, 1380, 1400, 1410, 1411, 1412, 1413, 1414, 1416, 1419, 1421, 1423, 1426, 1427, 1436, 1445, 1463, 1464, 1465, 1466, 1468, 1473, 1474, 1475, 1476, 1537, 1544, 1545, 1546, 1547, 1548, 1549, 1551, 1552, 1553, 1554, 1555, 1556, 1558, 1564, 1569, 1578, 1581, 1606, 1607, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1620, 1622, 1625, 1628, 1629, 1630, 1633, 1639, 1640, 1641, 1646, 1648, 1656, 1657, 1658, 1659, 1665, 1666, 1668, 1672, 1673, 1676, 1677, 1679, 1685, 1687, 1689, 1690, 1695, 1696, 1697, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1710, 1711, 1713, 1714, 1717, 1719, 1721, 1727, 1729, 1730, 1732, 1733], "format": [1, 15, 18, 28, 42, 110, 125, 127, 130, 133, 134, 135, 150, 161, 164, 194, 222, 252, 280, 286, 347, 451, 452, 476, 531, 535, 536, 537, 538, 539, 540, 673, 728, 781, 782, 783, 836, 895, 908, 937, 1039, 1060, 1068, 1086, 1116, 1131, 1319, 1328, 1353, 1411, 1413, 1427, 1552, 1554, 1556, 1574, 1604, 1606, 1611, 1612, 1613, 1614, 1615, 1616, 1673, 1674, 1676, 1679, 1680, 1699, 1701, 1706, 1711, 1713, 1718, 1719, 1724, 1725, 1727, 1730, 1732], "arg0": [1, 20], "arg1": [1, 20, 33, 34, 36], "repres": [1, 7, 10, 17, 18, 24, 25, 26, 28, 29, 35, 37, 40, 42, 619, 682, 686, 688, 715, 718, 781, 802, 804, 809, 811, 812, 813, 814, 848, 855, 884, 885, 888, 891, 894, 910, 911, 942, 985, 1024, 1039, 1116, 1122, 1163, 1165, 1167, 1319, 1353, 1383, 1386, 1391, 1394, 1395, 1396, 1397, 1398, 1400, 1403, 1404, 1405, 1406, 1410, 1418, 1452, 1458, 1463, 1465, 1476, 1611, 1612, 1613, 1615, 1616, 1625, 1629, 1633, 1657, 1658, 1665, 1666, 1676, 1678, 1679, 1687, 1691, 1696, 1701, 1703, 1705, 1706, 1709, 1713, 1717, 1719, 1720, 1722, 1724, 1727, 1730, 1739], "order": [1, 3, 5, 19, 20, 21, 23, 24, 36, 40, 41, 42, 105, 146, 163, 268, 270, 272, 276, 286, 606, 622, 623, 636, 655, 666, 690, 728, 768, 771, 772, 780, 781, 799, 801, 802, 808, 820, 821, 822, 823, 848, 895, 914, 925, 931, 933, 940, 947, 950, 951, 958, 959, 962, 964, 967, 998, 1004, 1005, 1007, 1024, 1039, 1053, 1116, 1117, 1126, 1143, 1144, 1178, 1213, 1237, 1238, 1239, 1314, 1319, 1386, 1396, 1410, 1411, 1412, 1413, 1422, 1436, 1458, 1463, 1466, 1476, 1487, 1578, 1581, 1603, 1629, 1633, 1643, 1650, 1652, 1657, 1660, 1661, 1667, 1674, 1676, 1677, 1679, 1680, 1688, 1689, 1690, 1691, 1694, 1696, 1697, 1699, 1700, 1701, 1703, 1706, 1709, 1713, 1715, 1716, 1717, 1719, 1721, 1724, 1725, 1726, 1727, 1728, 1730, 1734], "backend": [1, 12, 34, 38, 630, 636, 908, 938, 958, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1213, 1251, 1319, 1334, 1335, 1336, 1538, 1540, 1585, 1675, 1677, 1678, 1683, 1685, 1698, 1699, 1709, 1710, 1713, 1720, 1727], "side": [1, 12, 20, 35, 37, 42, 717, 774, 797, 798, 800, 803, 804, 809, 811, 812, 813, 814, 817, 892, 893, 939, 944, 955, 957, 1029, 1030, 1031, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1063, 1092, 1093, 1094, 1095, 1096, 1097, 1109, 1110, 1111, 1137, 1138, 1140, 1141, 1142, 1167, 1171, 1180, 1181, 1182, 1188, 1189, 1190, 1191, 1192, 1193, 1237, 1238, 1239, 1251, 1361, 1362, 1365, 1366, 1367, 1452, 1547, 1548, 1578, 1625, 1648, 1674, 1676, 1677, 1679, 1695, 1696, 1699, 1701, 1703, 1724], "creation": [1, 2, 17, 42, 689, 1319, 1338, 1339, 1349, 1357, 1391, 1485, 1506, 1676, 1680, 1687, 1688, 1696, 1699, 1724, 1726, 1733], "warmup": [1, 3, 728, 1699, 1718], "correl": [1, 24, 36, 682, 1044, 1045, 1046, 1047, 1048, 1049, 1055, 1056, 1057, 1061], "view": [1, 6, 7, 10, 17, 18, 23, 26, 40, 42, 177, 209, 449, 450, 451, 559, 569, 587, 592, 608, 616, 617, 618, 625, 658, 670, 679, 680, 770, 771, 778, 820, 821, 822, 823, 858, 870, 895, 950, 961, 1060, 1068, 1086, 1116, 1131, 1167, 1168, 1169, 1170, 1205, 1250, 1318, 1319, 1353, 1381, 1466, 1565, 1569, 1570, 1574, 1580, 1581, 1600, 1617, 1628, 1635, 1640, 1644, 1656, 1665, 1666, 1668, 1675, 1676, 1677, 1688, 1690, 1691, 1697, 1701, 1714, 1721, 1726, 1729, 1730, 1733], "difficult": [1, 6, 8, 1667], "eas": [1, 42, 1698, 1701, 1704], "sequenc": [1, 17, 23, 24, 105, 516, 610, 622, 636, 660, 662, 663, 666, 674, 691, 696, 697, 700, 765, 779, 782, 856, 857, 860, 910, 950, 998, 1024, 1034, 1039, 1044, 1053, 1060, 1068, 1086, 1122, 1131, 1144, 1159, 1160, 1161, 1162, 1163, 1205, 1328, 1353, 1386, 1389, 1396, 1410, 1411, 1412, 1413, 1414, 1423, 1426, 1444, 1499, 1549, 1551, 1555, 1578, 1622, 1625, 1667, 1669, 1672, 1676, 1677, 1678, 1699, 1702, 1713, 1716, 1717, 1724, 1733, 1734], "gener": [1, 2, 3, 6, 7, 8, 12, 17, 18, 20, 24, 28, 29, 36, 108, 109, 128, 213, 241, 331, 375, 407, 434, 638, 646, 714, 717, 725, 726, 729, 730, 748, 749, 751, 752, 753, 781, 803, 804, 847, 852, 871, 899, 904, 915, 926, 931, 940, 957, 958, 962, 967, 988, 997, 1007, 1052, 1063, 1077, 1159, 1167, 1168, 1178, 1314, 1385, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1416, 1423, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1463, 1465, 1468, 1549, 1551, 1553, 1554, 1555, 1557, 1579, 1591, 1630, 1641, 1661, 1667, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1685, 1689, 1694, 1696, 1699, 1701, 1702, 1703, 1705, 1706, 1712, 1713, 1714, 1715, 1716, 1718, 1723, 1724, 1725, 1727, 1730, 1732, 1734, 1736, 1738], "seq": [1, 557, 663, 675, 998, 1068, 1086, 1122, 1131, 1159, 1161, 1163, 1353, 1413, 1655], "n": [1, 3, 19, 20, 24, 26, 28, 33, 36, 42, 184, 215, 361, 418, 419, 581, 584, 585, 586, 607, 641, 644, 645, 647, 654, 656, 660, 666, 667, 668, 686, 761, 762, 772, 780, 794, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 821, 848, 852, 853, 857, 892, 895, 906, 910, 911, 914, 915, 924, 925, 926, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 967, 975, 983, 985, 990, 992, 998, 1001, 1009, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1039, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1055, 1056, 1057, 1059, 1060, 1061, 1063, 1064, 1065, 1067, 1068, 1069, 1070, 1071, 1076, 1077, 1079, 1080, 1081, 1083, 1084, 1085, 1086, 1088, 1098, 1099, 1100, 1104, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1119, 1120, 1121, 1122, 1123, 1125, 1131, 1133, 1137, 1138, 1139, 1140, 1141, 1142, 1147, 1149, 1150, 1151, 1155, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1178, 1184, 1196, 1197, 1205, 1209, 1213, 1248, 1251, 1253, 1319, 1328, 1351, 1353, 1374, 1384, 1395, 1404, 1421, 1463, 1464, 1465, 1470, 1475, 1476, 1549, 1555, 1557, 1570, 1578, 1606, 1607, 1623, 1624, 1625, 1629, 1630, 1633, 1640, 1641, 1646, 1650, 1652, 1661, 1662, 1663, 1664, 1667, 1677, 1679, 1689, 1690, 1694, 1696, 1699, 1701, 1702, 1703, 1713, 1716, 1718, 1719, 1727, 1728, 1732, 1733, 1734], "counter": [1, 20, 721, 739, 870, 1053, 1687, 1688, 1696], "increment": [1, 20, 35, 834, 857, 899, 1053, 1676, 1678, 1696, 1724], "stash": [1, 5, 1699, 1701, 1717], "associ": [1, 7, 8, 20, 29, 624, 694, 742, 744, 856, 857, 895, 944, 955, 957, 966, 1039, 1116, 1126, 1197, 1319, 1385, 1676, 1679, 1689, 1690, 1696, 1703, 1706, 1709, 1716, 1717, 1724, 1725, 1730, 1733], "tell": [1, 6, 42, 448, 896, 902, 966, 1676, 1696, 1701, 1716], "top": [1, 3, 6, 7, 17, 24, 28, 40, 42, 641, 1032, 1033, 1052, 1076, 1083, 1107, 1123, 1165, 1168, 1213, 1340, 1391, 1395, 1397, 1500, 1643, 1680, 1688, 1701], "m": [1, 4, 7, 18, 19, 20, 24, 36, 42, 581, 584, 585, 586, 644, 656, 660, 664, 669, 794, 857, 893, 895, 900, 901, 905, 906, 912, 915, 926, 934, 940, 941, 942, 943, 947, 948, 949, 951, 952, 953, 958, 959, 960, 961, 967, 983, 985, 986, 990, 1001, 1007, 1009, 1021, 1022, 1023, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1034, 1035, 1036, 1037, 1038, 1041, 1042, 1043, 1044, 1045, 1046, 1048, 1049, 1054, 1055, 1056, 1057, 1058, 1059, 1061, 1062, 1064, 1065, 1066, 1067, 1071, 1072, 1073, 1074, 1075, 1078, 1079, 1080, 1081, 1084, 1085, 1102, 1103, 1105, 1106, 1109, 1110, 1111, 1115, 1116, 1123, 1124, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1145, 1146, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1166, 1168, 1169, 1170, 1171, 1251, 1253, 1304, 1312, 1313, 1319, 1331, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1349, 1351, 1357, 1384, 1389, 1399, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1415, 1416, 1419, 1463, 1464, 1465, 1475, 1499, 1539, 1549, 1578, 1606, 1607, 1625, 1629, 1630, 1633, 1641, 1648, 1676, 1677, 1678, 1679, 1699, 1701, 1702, 1703, 1706, 1711, 1719, 1727, 1737], "By": [1, 3, 5, 12, 17, 20, 27, 32, 40, 42, 398, 399, 400, 401, 402, 686, 691, 731, 733, 763, 775, 780, 799, 801, 802, 803, 804, 812, 813, 814, 848, 856, 857, 899, 947, 958, 966, 997, 1002, 1011, 1032, 1033, 1034, 1035, 1036, 1050, 1052, 1070, 1076, 1079, 1080, 1081, 1082, 1083, 1107, 1108, 1119, 1120, 1121, 1123, 1130, 1147, 1148, 1155, 1164, 1185, 1186, 1196, 1225, 1248, 1256, 1419, 1465, 1476, 1564, 1646, 1674, 1678, 1683, 1685, 1696, 1699, 1701, 1702, 1706, 1711, 1713, 1715, 1723, 1724, 1727, 1734], "compar": [1, 3, 5, 12, 17, 40, 42, 589, 595, 606, 636, 785, 786, 809, 810, 811, 815, 816, 817, 818, 827, 828, 839, 851, 870, 884, 919, 984, 995, 1000, 1017, 1122, 1319, 1420, 1587, 1679, 1687, 1699, 1701, 1703, 1709, 1712, 1719, 1720, 1724, 1727, 1732, 1734, 1736, 1737], "down": [1, 6, 12, 17, 24, 26, 33, 34, 36, 40, 42, 739, 775, 823, 829, 904, 940, 1224, 1372, 1476, 1571, 1705, 1708, 1713, 1724, 1726, 1732], "irrelev": [1, 3, 1680], "simpli": [1, 3, 12, 17, 24, 28, 36, 41, 42, 882, 893, 1028, 1054, 1319, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1542, 1676, 1678, 1696, 1703, 1706, 1707, 1718, 1727], "hand": [1, 4, 20, 42, 774, 781, 893, 939, 944, 955, 957, 1028, 1126, 1144, 1648, 1660, 1676, 1678, 1679, 1696, 1703, 1706, 1711, 1716, 1727], "underwai": [1, 723, 1699], "up": [1, 6, 7, 8, 12, 17, 18, 20, 23, 24, 26, 28, 32, 34, 35, 37, 38, 42, 725, 726, 728, 763, 810, 811, 816, 818, 823, 886, 899, 904, 907, 908, 953, 1024, 1039, 1063, 1161, 1163, 1167, 1168, 1178, 1204, 1213, 1224, 1281, 1319, 1372, 1378, 1447, 1549, 1571, 1657, 1658, 1674, 1676, 1678, 1683, 1687, 1688, 1689, 1690, 1696, 1697, 1698, 1699, 1702, 1703, 1704, 1706, 1709, 1713, 1716, 1718, 1719, 1724, 1725, 1734], "nonzero": [1, 40, 892, 976, 978, 979, 985, 1670, 1677, 1714], "themselv": [1, 8, 24, 35, 40, 1523, 1643, 1699, 1716, 1738], "origin": [1, 10, 17, 18, 20, 28, 40, 41, 42, 161, 164, 176, 439, 495, 555, 559, 568, 661, 666, 690, 801, 802, 804, 808, 812, 813, 814, 820, 869, 892, 902, 906, 907, 910, 911, 989, 1004, 1024, 1028, 1040, 1052, 1053, 1145, 1155, 1196, 1265, 1384, 1385, 1386, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1410, 1413, 1416, 1417, 1419, 1458, 1466, 1482, 1520, 1521, 1536, 1537, 1569, 1580, 1603, 1617, 1633, 1646, 1657, 1658, 1676, 1679, 1688, 1690, 1696, 1699, 1701, 1702, 1705, 1708, 1709, 1711, 1713, 1716, 1717, 1719, 1720, 1729, 1736, 1737, 1738], "did": [1, 6, 7, 20, 35, 1014, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1678, 1679, 1703, 1711, 1716], "relationship": [1, 8, 32, 42, 673, 848, 1165, 1696, 1699, 1711, 1716], "conceptu": [1, 3, 1696, 1726], "tag": [1, 3, 6, 20, 966, 1674, 1675, 1705, 1716, 1732], "eventu": [1, 6, 35, 40, 1674, 1717], "itt": 1, "intel": [1, 4, 1712], "r": [1, 24, 105, 619, 621, 622, 636, 637, 638, 664, 675, 682, 781, 837, 840, 848, 906, 924, 926, 930, 931, 932, 933, 934, 935, 940, 941, 944, 946, 953, 955, 957, 958, 967, 1059, 1060, 1069, 1128, 1129, 1147, 1204, 1205, 1254, 1255, 1384, 1445, 1475, 1667, 1676, 1677, 1678, 1696, 1698, 1701, 1703, 1712, 1732], "vtune_flag": 1, "instrument": [1, 3, 18, 1705, 1737], "technolog": 1, "applic": [1, 2, 24, 35, 40, 628, 708, 1052, 1053, 1161, 1163, 1196, 1319, 1484, 1495, 1496, 1497, 1498, 1660, 1696, 1698, 1699, 1700, 1701, 1704, 1705, 1706, 1710, 1713, 1719, 1724, 1725, 1726, 1727, 1733], "across": [1, 7, 12, 17, 18, 19, 20, 23, 26, 36, 40, 42, 568, 604, 642, 700, 738, 739, 781, 795, 905, 910, 998, 1053, 1063, 1104, 1122, 1124, 1155, 1167, 1183, 1215, 1231, 1277, 1319, 1328, 1396, 1400, 1422, 1501, 1574, 1675, 1676, 1687, 1689, 1691, 1696, 1700, 1702, 1705, 1706, 1708, 1709, 1710, 1717, 1720, 1724, 1725, 1729, 1732, 1737], "tool": [1, 4, 7, 8, 20, 36, 42, 640, 1540, 1674, 1676, 1678, 1698, 1699, 1712, 1716, 1718, 1737], "With": [1, 17, 20, 24, 40, 41, 802, 803, 804, 812, 813, 814, 911, 1034, 1035, 1036, 1045, 1046, 1048, 1049, 1062, 1079, 1080, 1081, 1155, 1166, 1168, 1189, 1192, 1224, 1249, 1281, 1332, 1333, 1334, 1335, 1336, 1378, 1444, 1553, 1680, 1696, 1699, 1701, 1724, 1727, 1732], "abl": [1, 2, 6, 7, 20, 35, 893, 905, 1159, 1319, 1667, 1676, 1683, 1689, 1696, 1701, 1711, 1713, 1716, 1719, 1724, 1734], "labl": 1, "gui": 1, "detect_anomali": 1, "engin": [1, 7, 8, 10, 13, 290, 626, 636, 1334, 1335, 1336, 1549, 1667, 1696, 1699, 1700, 1701, 1724, 1725], "traceback": [1, 28, 36, 41, 42, 870, 880, 1678, 1679, 1680, 1688, 1691, 1701, 1710, 1734], "fail": [1, 6, 20, 24, 26, 27, 28, 33, 34, 35, 36, 38, 41, 42, 637, 638, 690, 739, 896, 902, 905, 924, 953, 958, 966, 967, 985, 1679, 1681, 1688, 1696, 1701, 1708, 1709, 1712, 1713, 1716, 1724], "debug": [1, 2, 4, 7, 17, 32, 637, 638, 716, 755, 843, 924, 1316, 1317, 1318, 1500, 1509, 1584, 1592, 1678, 1696, 1698, 1699, 1704, 1705, 1706, 1710, 1712, 1716, 1736], "test": [1, 3, 12, 20, 33, 35, 36, 42, 588, 594, 798, 800, 801, 806, 807, 812, 813, 814, 816, 818, 881, 882, 886, 887, 889, 890, 1596, 1675, 1676, 1680, 1687, 1688, 1696, 1703, 1710, 1713, 1715, 1732, 1738], "slow": [1, 637, 904, 908, 924, 925, 1415, 1657, 1703, 1708, 1732], "import": [1, 2, 3, 6, 8, 12, 14, 17, 18, 19, 20, 21, 23, 25, 27, 29, 32, 33, 37, 40, 41, 42, 176, 655, 686, 832, 834, 870, 892, 893, 896, 898, 900, 901, 902, 904, 905, 906, 910, 911, 912, 946, 947, 950, 951, 964, 998, 1116, 1319, 1327, 1365, 1366, 1367, 1387, 1389, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1400, 1403, 1404, 1412, 1413, 1414, 1415, 1422, 1446, 1469, 1538, 1539, 1540, 1541, 1676, 1678, 1679, 1680, 1687, 1688, 1691, 1695, 1696, 1698, 1699, 1700, 1701, 1702, 1705, 1706, 1708, 1709, 1710, 1711, 1713, 1719, 1724, 1725, 1726, 1727, 1730, 1732, 1733, 1734, 1737, 1738], "myfunc": 1, "inp": [1, 17, 20, 42, 623, 624, 625, 1167, 1319, 1738], "clone": [1, 13, 17, 40, 209, 401, 626, 629, 658, 899, 1059, 1280, 1639, 1648, 1677, 1688, 1711, 1714, 1718, 1727, 1729, 1730, 1734], "run_fn": [1, 5, 1536, 1542], "10": [1, 16, 17, 18, 20, 21, 24, 25, 35, 37, 268, 276, 290, 424, 465, 510, 532, 535, 536, 537, 580, 581, 592, 644, 656, 666, 668, 669, 670, 674, 686, 759, 760, 761, 762, 763, 778, 781, 798, 800, 803, 804, 806, 807, 810, 811, 813, 814, 816, 818, 824, 832, 838, 848, 858, 884, 900, 905, 906, 912, 917, 920, 940, 947, 949, 950, 965, 967, 969, 974, 976, 977, 978, 979, 981, 983, 990, 993, 1002, 1007, 1022, 1023, 1024, 1026, 1027, 1033, 1036, 1039, 1040, 1043, 1046, 1049, 1059, 1060, 1068, 1069, 1070, 1071, 1081, 1086, 1087, 1088, 1113, 1117, 1118, 1123, 1126, 1127, 1131, 1133, 1155, 1159, 1160, 1161, 1162, 1163, 1167, 1190, 1193, 1197, 1204, 1205, 1215, 1314, 1319, 1327, 1338, 1339, 1353, 1354, 1355, 1356, 1358, 1400, 1408, 1423, 1432, 1452, 1458, 1459, 1544, 1545, 1553, 1578, 1590, 1603, 1617, 1629, 1630, 1636, 1640, 1641, 1644, 1646, 1660, 1668, 1674, 1676, 1677, 1678, 1679, 1680, 1696, 1699, 1700, 1706, 1709, 1710, 1711, 1712, 1713, 1714, 1727, 1728, 1730, 1732, 1733, 1734, 1739], "last": [1, 5, 10, 17, 18, 19, 21, 23, 24, 35, 41, 42, 270, 568, 587, 607, 645, 654, 660, 670, 725, 763, 768, 772, 798, 800, 803, 804, 806, 807, 810, 811, 813, 814, 816, 818, 820, 852, 853, 857, 870, 872, 880, 892, 916, 950, 953, 958, 983, 997, 1002, 1024, 1037, 1052, 1060, 1062, 1068, 1086, 1088, 1103, 1123, 1126, 1130, 1131, 1144, 1160, 1161, 1167, 1184, 1205, 1214, 1227, 1250, 1251, 1319, 1320, 1353, 1421, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1569, 1578, 1603, 1611, 1612, 1613, 1615, 1616, 1617, 1625, 1629, 1641, 1643, 1646, 1665, 1666, 1678, 1679, 1687, 1689, 1691, 1696, 1699, 1701, 1703, 1710, 1713, 1716, 1717, 1727, 1733, 1734], "stdin": [1, 870, 1691, 1701, 1710], "instal": [1, 3, 12, 13, 20, 42, 1674, 1676, 1706, 1707, 1713, 1716, 1724, 1732], "_tensor": [1, 109], "py": [1, 4, 12, 19, 20, 23, 24, 27, 34, 36, 42, 1319, 1539, 1674, 1676, 1679, 1700, 1703, 1705, 1713, 1714, 1716, 1725], "93": [1, 568], "retain_graph": [1, 105, 622, 636, 1667, 1677, 1695, 1696, 1724], "90": [1, 764, 1461, 1570], "allow_unreach": 1, "76": 1, "_forward_cl": 1, "tmp": [1, 3, 12, 20, 33, 35, 1674, 1699, 1718], "53": [1, 434], "44": [1, 276, 398, 784, 1031, 1111, 1415], "set_detect_anomali": 1, "behaviour": [1, 588, 589, 594, 687, 1213, 1251, 1458, 1592, 1674], "intermediari": [1, 12, 24, 628, 1696, 1703], "pack": [1, 23, 987, 1053, 1068, 1086, 1131, 1331, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1353, 1374, 1410, 1411, 1412, 1413, 1677, 1685, 1691, 1696, 1702, 1712, 1719], "unpack": [1, 625, 942, 983, 987, 1053, 1353, 1413, 1420, 1679, 1680, 1696, 1701, 1702], "common": [1, 3, 7, 17, 26, 35, 580, 595, 649, 652, 657, 681, 775, 781, 826, 827, 828, 829, 838, 917, 927, 966, 1006, 1034, 1035, 1036, 1039, 1155, 1195, 1315, 1317, 1318, 1538, 1562, 1574, 1626, 1679, 1684, 1690, 1696, 1699, 1701, 1702, 1706, 1708, 1711, 1713, 1716, 1727, 1728, 1731, 1734], "trade": [1, 5, 7, 40, 958, 1033, 1698, 1702, 1720], "leav": [1, 7, 26, 36, 105, 622, 900, 912, 1387, 1390, 1433, 1434, 1620, 1676, 1678, 1679, 1696, 1716, 1720], "especi": [1, 8, 10, 17, 20, 42, 209, 658, 1280, 1678, 1696, 1701, 1709, 1711, 1719, 1724], "notic": [1, 20, 801, 815, 1032, 1168, 1449, 1450, 1455, 1456, 1461, 1675, 1676, 1696, 1727], "fit": [1, 8, 27, 40, 451, 641, 892, 1436, 1564, 1717, 1734], "evalu": [1, 4, 7, 8, 23, 24, 42, 588, 594, 739, 895, 1024, 1028, 1034, 1035, 1036, 1054, 1071, 1079, 1080, 1081, 1088, 1116, 1130, 1134, 1155, 1256, 1277, 1387, 1436, 1452, 1483, 1542, 1549, 1679, 1680, 1701, 1706, 1727], "graph": [1, 5, 7, 20, 24, 94, 105, 176, 177, 622, 628, 636, 688, 718, 723, 728, 895, 898, 899, 904, 906, 910, 1319, 1340, 1429, 1433, 1434, 1505, 1508, 1679, 1685, 1692, 1695, 1700, 1701, 1703, 1706, 1707, 1713, 1716, 1720, 1721, 1722, 1724, 1725, 1726, 1732], "saved_tensors_hook": [1, 628, 1696], "pack_hook": [1, 1696], "unpack_hook": [1, 1696], "pair": [1, 20, 24, 35, 37, 568, 595, 664, 686, 780, 815, 908, 958, 998, 1108, 1117, 1122, 1126, 1253, 1328, 1445, 1558, 1678, 1679, 1689, 1696, 1717, 1724, 1725, 1726, 1732, 1734, 1737], "retriev": [1, 5, 17, 18, 19, 20, 23, 26, 35, 42, 488, 619, 620, 1059, 1063, 1167, 1204, 1319, 1411, 1691, 1696, 1705, 1713, 1716, 1717, 1724, 1725, 1726], "everytim": 1, "store": [1, 3, 5, 12, 18, 19, 26, 36, 40, 42, 281, 287, 353, 581, 620, 656, 696, 698, 700, 840, 895, 902, 905, 925, 936, 937, 938, 967, 972, 983, 985, 1059, 1116, 1144, 1319, 1384, 1386, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1410, 1504, 1507, 1609, 1674, 1676, 1690, 1691, 1692, 1700, 1701, 1702, 1705, 1716, 1719, 1724, 1725, 1726, 1727, 1729, 1732, 1733, 1737], "access": [1, 8, 17, 19, 20, 40, 41, 628, 695, 895, 898, 910, 957, 1024, 1116, 1314, 1321, 1322, 1327, 1385, 1389, 1411, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1676, 1677, 1679, 1680, 1683, 1685, 1688, 1690, 1691, 1696, 1699, 1702, 1703, 1705, 1706, 1713, 1724, 1727, 1730, 1731, 1733, 1739], "content": [1, 3, 6, 28, 42, 628, 902, 905, 925, 936, 938, 943, 956, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1440, 1443, 1444, 1445, 1446, 1447, 1620, 1645, 1674, 1679, 1686, 1688, 1696, 1724, 1731, 1732, 1733], "equal": [1, 18, 20, 24, 35, 36, 37, 42, 215, 451, 495, 568, 589, 590, 591, 606, 645, 654, 665, 666, 677, 686, 698, 700, 751, 769, 786, 825, 839, 852, 853, 855, 856, 857, 880, 884, 919, 940, 953, 957, 960, 961, 985, 986, 998, 1017, 1021, 1022, 1023, 1025, 1026, 1027, 1032, 1033, 1039, 1045, 1046, 1048, 1049, 1053, 1060, 1063, 1064, 1065, 1068, 1070, 1086, 1121, 1122, 1130, 1131, 1167, 1181, 1182, 1186, 1189, 1192, 1204, 1205, 1208, 1209, 1215, 1319, 1332, 1333, 1334, 1335, 1336, 1353, 1361, 1362, 1411, 1414, 1463, 1476, 1502, 1503, 1504, 1507, 1540, 1617, 1625, 1640, 1656, 1670, 1677, 1680, 1689, 1690, 1691, 1696, 1697, 1703, 1709, 1715, 1717, 1727, 1728, 1732, 1734], "term": [1, 7, 8, 24, 35, 42, 508, 666, 797, 798, 799, 800, 801, 802, 804, 812, 813, 814, 817, 829, 926, 1024, 1032, 1070, 1077, 1086, 1087, 1121, 1130, 1147, 1210, 1222, 1256, 1266, 1319, 1327, 1356, 1384, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1430, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1447, 1562, 1675, 1679, 1695, 1696, 1701, 1702, 1703, 1716, 1719, 1725, 1727], "inplac": [1, 42, 626, 895, 1028, 1038, 1054, 1055, 1056, 1057, 1058, 1061, 1073, 1074, 1075, 1102, 1115, 1116, 1134, 1135, 1136, 1143, 1145, 1158, 1179, 1187, 1198, 1199, 1200, 1201, 1202, 1206, 1217, 1218, 1219, 1228, 1243, 1258, 1259, 1261, 1263, 1265, 1275, 1316, 1348, 1351, 1369, 1371, 1373, 1480, 1481, 1482, 1499, 1520, 1521, 1522, 1536, 1537, 1542, 1660, 1677, 1696, 1701, 1713, 1737], "lead": [1, 6, 16, 25, 40, 42, 534, 626, 630, 632, 636, 638, 832, 925, 1086, 1131, 1147, 1620, 1667, 1679, 1690, 1696, 1698, 1700, 1701, 1709, 1712, 1715, 1716, 1719, 1727, 1732, 1733], "undefin": [1, 20, 25, 28, 40, 274, 424, 568, 608, 629, 637, 638, 784, 833, 834, 1032, 1469, 1696, 1699, 1701], "recurs": [1, 24, 40, 42, 772, 895, 906, 908, 1116, 1450, 1678, 1701, 1706, 1716, 1724], "inner": [1, 3, 40, 630, 763, 1646, 1677, 1724], "save_on_cpu": 1, "pin_memori": [1, 17, 782, 784, 1557, 1639, 1676, 1677, 1699, 1729], "within": [1, 5, 8, 17, 18, 19, 20, 23, 24, 35, 36, 37, 40, 41, 42, 43, 608, 637, 638, 692, 763, 895, 899, 988, 1029, 1030, 1031, 1039, 1055, 1056, 1057, 1061, 1063, 1109, 1110, 1111, 1116, 1122, 1155, 1167, 1213, 1237, 1238, 1239, 1319, 1387, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1401, 1403, 1404, 1405, 1406, 1407, 1547, 1548, 1578, 1659, 1676, 1678, 1679, 1687, 1694, 1698, 1699, 1701, 1704, 1705, 1706, 1713, 1715, 1716, 1719, 1722, 1723, 1724, 1725, 1732], "move": [1, 5, 6, 7, 8, 12, 20, 40, 42, 475, 541, 801, 895, 902, 961, 966, 1004, 1034, 1035, 1036, 1089, 1090, 1091, 1116, 1155, 1251, 1321, 1322, 1444, 1503, 1667, 1678, 1685, 1686, 1688, 1690, 1699, 1702, 1706, 1707, 1708, 1715, 1716, 1717, 1724, 1729, 1734], "copi": [1, 6, 10, 17, 18, 19, 20, 26, 33, 40, 42, 145, 151, 161, 164, 270, 357, 388, 401, 411, 416, 424, 445, 451, 531, 532, 533, 534, 535, 555, 568, 609, 610, 624, 673, 696, 697, 820, 821, 822, 823, 895, 906, 967, 1053, 1063, 1116, 1126, 1167, 1319, 1410, 1499, 1520, 1521, 1559, 1565, 1639, 1648, 1676, 1677, 1688, 1691, 1696, 1697, 1699, 1701, 1708, 1713, 1716, 1717, 1718, 1719, 1724, 1727, 1729, 1730, 1731, 1733, 1737], "pin": [1, 164, 292, 416, 531, 555, 782, 784, 895, 1116, 1410, 1557, 1639, 1729], "asynchron": [1, 3, 4, 41, 151, 164, 531, 555, 895, 898, 913, 1116, 1680, 1698, 1700, 1724, 1729, 1732], "prod_1": 1, "prod_2": 1, "del": [1, 1680, 1688, 1701, 1702], "illustr": [1, 1679, 1695, 1701, 1727], "aliv": [1, 17, 26, 35, 690, 1696, 1699, 1702, 1708, 1724, 1725, 1726], "live": [1, 23, 725, 728, 895, 1116, 1676, 1699, 1702, 1724, 1726], "releas": [1, 6, 16, 19, 20, 35, 37, 42, 582, 666, 667, 687, 688, 693, 708, 717, 718, 721, 725, 726, 728, 739, 780, 841, 895, 925, 936, 938, 939, 940, 943, 956, 983, 985, 986, 993, 1056, 1082, 1086, 1116, 1131, 1225, 1237, 1238, 1239, 1422, 1475, 1558, 1574, 1625, 1629, 1633, 1648, 1674, 1675, 1678, 1687, 1688, 1696, 1698, 1699, 1704, 1709, 1710, 1711, 1712, 1713, 1719, 1724, 1733], "delet": [1, 20, 42, 623, 688, 694, 1667, 1674, 1685, 1688, 1696, 1714, 1723, 1724, 1726], "variou": [2, 5, 12, 17, 20, 42, 967, 1683, 1688, 1706, 1708, 1715, 1719, 1721, 1727, 1738], "is_built": [2, 1707], "built": [2, 3, 6, 7, 12, 18, 19, 20, 28, 42, 676, 904, 1165, 1452, 1691, 1696, 1698, 1701, 1704, 1706, 1707, 1708, 1721, 1738], "necessarili": [2, 18, 20, 24, 26, 35, 424, 780, 931, 953, 964, 997, 1052, 1123, 1699, 1701], "machin": [2, 20, 26, 35, 40, 899, 904, 940, 1152, 1319, 1704, 1705, 1706, 1707, 1710, 1713, 1716, 1723, 1724, 1725], "driver": [2, 840, 940, 958, 959, 1677, 1699, 1724], "would": [2, 3, 5, 7, 8, 10, 12, 17, 19, 20, 24, 26, 28, 35, 36, 40, 42, 105, 593, 622, 626, 636, 666, 782, 784, 802, 893, 895, 896, 900, 902, 910, 911, 1029, 1030, 1031, 1032, 1033, 1068, 1082, 1086, 1109, 1110, 1111, 1116, 1126, 1131, 1213, 1224, 1314, 1319, 1320, 1353, 1410, 1420, 1557, 1568, 1578, 1639, 1640, 1645, 1676, 1678, 1679, 1689, 1690, 1692, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1703, 1711, 1713, 1716, 1717, 1719, 1724, 1725, 1726, 1727, 1728], "allow_tf32": [2, 1585, 1677, 1699, 1709], "tensorfloat": 2, "core": [2, 3, 6, 7, 19, 739, 1679, 1683, 1698, 1699, 1700, 1709, 1716], "amper": 2, "newer": [2, 12, 1416, 1698, 1699, 1711, 1716, 1720], "tf32": 2, "allow_fp16_reduced_precision_reduct": [2, 1699, 1709], "precis": [2, 3, 7, 10, 12, 18, 24, 40, 581, 584, 637, 638, 644, 656, 824, 844, 940, 958, 964, 990, 1001, 1029, 1030, 1031, 1033, 1044, 1045, 1046, 1047, 1048, 1049, 1069, 1087, 1103, 1109, 1110, 1111, 1168, 1224, 1319, 1571, 1585, 1590, 1675, 1679, 1687, 1692, 1696, 1706, 1716, 1719, 1720, 1722, 1728, 1730, 1732, 1733, 1739], "fp16": [2, 1313, 1319, 1719, 1720], "gemm": [2, 1698, 1713], "cufft_plan_cach": [2, 1699], "cufft": 2, "readonli": 2, "show": [2, 4, 6, 11, 17, 18, 20, 25, 42, 630, 636, 832, 895, 998, 1116, 1314, 1447, 1674, 1679, 1689, 1698, 1699, 1700, 1703, 1704, 1706, 1713, 1716, 1724, 1726], "max_siz": [2, 34, 36, 1699], "capac": [2, 751, 1699], "clear": [2, 7, 8, 37, 42, 1117, 1126, 1674, 1696, 1699, 1706, 1711, 1715], "preferred_linalg_librari": 2, "subject": [2, 3, 10, 20, 23, 40, 41, 42, 595, 983, 1319, 1667, 1679, 1689, 1690, 1696, 1701, 1717, 1718, 1719, 1720, 1724, 1730, 1736, 1737], "algebra": [2, 8, 781, 952, 1684], "cusolv": [2, 958, 959, 1629], "magma": [2, 668, 940, 985, 1475, 1629, 1712, 1727], "decid": [2, 4, 6, 20, 35, 1400], "heurist": [2, 12, 17, 35, 36, 42], "overrid": [2, 12, 18, 20, 21, 24, 28, 36, 40, 42, 725, 1032, 1033, 1050, 1052, 1076, 1083, 1107, 1108, 1119, 1120, 1121, 1123, 1130, 1147, 1148, 1164, 1185, 1186, 1196, 1225, 1248, 1256, 1391, 1574, 1590, 1675, 1679, 1683, 1715, 1716, 1719, 1724, 1732, 1737], "wherev": [2, 8, 1689], "possibl": [2, 8, 12, 13, 17, 20, 24, 35, 40, 42, 449, 450, 531, 568, 609, 610, 670, 695, 829, 895, 908, 910, 935, 937, 942, 948, 951, 952, 955, 960, 966, 1033, 1039, 1116, 1204, 1205, 1224, 1257, 1281, 1319, 1389, 1390, 1537, 1562, 1565, 1617, 1625, 1639, 1676, 1678, 1679, 1688, 1689, 1694, 1696, 1698, 1700, 1701, 1703, 1708, 1709, 1710, 1712, 1716, 1719, 1724, 1726, 1730, 1734], "pick": [2, 20, 34, 36, 465, 1696, 1724], "prefer": [2, 8, 17, 26, 608, 632, 893, 935, 948, 952, 960, 967, 1123, 1578, 1625, 1639, 1676, 1699, 1716], "achiev": [2, 17, 18, 20, 24, 36, 40, 895, 1039, 1116, 1123, 1215, 1319, 1699, 1705, 1716, 1724, 1726], "better": [2, 3, 6, 7, 8, 12, 17, 26, 750, 870, 882, 910, 1052, 1149, 1268, 1319, 1458, 1549, 1679, 1695, 1696, 1698, 1699, 1703, 1709, 1712, 1713, 1715, 1718, 1720, 1727, 1732], "select": [2, 10, 13, 15, 17, 19, 20, 24, 26, 268, 270, 272, 276, 666, 692, 693, 702, 703, 704, 705, 707, 727, 731, 733, 734, 735, 737, 739, 740, 741, 745, 746, 747, 750, 751, 754, 756, 758, 801, 967, 998, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1068, 1086, 1131, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1353, 1405, 1406, 1581, 1636, 1670, 1676, 1677, 1679, 1688, 1689, 1690, 1698, 1699, 1703, 1710, 1714, 1719, 1727, 1731, 1734], "incorrect": [2, 4, 40, 42, 209, 465, 506, 628, 658, 910, 953, 966, 1280, 1422, 1625, 1676, 1679, 1699, 1713], "linalg": [2, 361, 666, 667, 668, 669, 687, 766, 780, 840, 873, 975, 983, 985, 986, 987, 991, 992, 993, 1384, 1385, 1389, 1422, 1462, 1467, 1469, 1475, 1601, 1629, 1630, 1633, 1648, 1664, 1675], "inv": [2, 24, 668, 873, 926, 930, 936, 952, 956, 960], "inv_ex": 2, "cholesky_ex": [2, 924], "lu_factor": [2, 943, 944, 985, 986, 987], "lu": [2, 9, 936, 942, 943, 944, 986, 987, 1677], "eigh": [2, 924, 930, 933, 952, 958, 1633], "eighval": 2, "svdval": [2, 926, 940, 949, 958, 1629], "version": [2, 5, 7, 12, 16, 18, 19, 20, 24, 36, 40, 42, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 76, 78, 80, 82, 85, 86, 88, 96, 98, 101, 102, 104, 107, 113, 115, 117, 119, 121, 123, 132, 141, 149, 153, 156, 158, 168, 170, 186, 190, 192, 199, 202, 204, 206, 208, 212, 217, 224, 226, 228, 232, 234, 238, 240, 247, 249, 251, 259, 261, 263, 265, 267, 269, 271, 273, 310, 312, 314, 316, 318, 320, 322, 325, 327, 329, 330, 337, 339, 341, 343, 345, 350, 354, 356, 374, 377, 380, 382, 392, 394, 396, 404, 409, 419, 422, 438, 442, 444, 460, 463, 464, 466, 468, 474, 478, 480, 483, 485, 487, 499, 501, 503, 506, 512, 514, 522, 526, 528, 545, 548, 550, 552, 554, 564, 573, 691, 728, 852, 870, 892, 895, 898, 899, 902, 905, 924, 937, 938, 942, 943, 956, 990, 1016, 1033, 1086, 1116, 1117, 1131, 1168, 1178, 1203, 1213, 1220, 1229, 1260, 1262, 1276, 1277, 1281, 1315, 1328, 1329, 1330, 1342, 1343, 1344, 1345, 1346, 1347, 1368, 1369, 1370, 1371, 1373, 1377, 1378, 1389, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1416, 1444, 1446, 1447, 1521, 1537, 1575, 1576, 1577, 1625, 1629, 1645, 1660, 1674, 1689, 1690, 1696, 1697, 1699, 1701, 1703, 1704, 1705, 1706, 1707, 1710, 1712, 1713, 1715, 1716, 1718, 1722, 1735], "is_avail": [2, 14, 20, 1699, 1704, 1707], "determinist": [2, 3, 5, 16, 20, 24, 42, 43, 465, 603, 843, 876, 898, 910, 911, 994, 997, 999, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1086, 1131, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1579, 1584, 1660, 1677, 1696, 1710, 1715, 1723], "algorithm": [2, 3, 6, 10, 15, 18, 21, 23, 24, 26, 40, 43, 666, 892, 935, 942, 948, 952, 958, 967, 985, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1063, 1066, 1068, 1086, 1131, 1167, 1168, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1213, 1224, 1281, 1319, 1353, 1372, 1378, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1443, 1444, 1445, 1447, 1465, 1571, 1585, 1629, 1630, 1660, 1675, 1696, 1699, 1724, 1727], "are_deterministic_algorithms_en": 2, "use_deterministic_algorithm": [2, 603, 876, 1584, 1710], "benchmark": [2, 1675, 1677, 1699, 1704], "fastest": [2, 607, 1319, 1421, 1703, 1710], "benchmark_limit": 2, "specifi": [2, 3, 5, 7, 12, 17, 18, 19, 20, 23, 24, 26, 28, 33, 34, 35, 36, 40, 42, 52, 105, 150, 214, 274, 286, 424, 434, 445, 449, 451, 452, 465, 467, 469, 488, 495, 496, 510, 531, 555, 608, 610, 622, 636, 647, 670, 685, 686, 687, 689, 690, 696, 697, 698, 700, 714, 717, 752, 761, 762, 763, 767, 768, 770, 781, 784, 795, 798, 800, 801, 803, 804, 806, 807, 808, 810, 811, 812, 813, 814, 816, 818, 837, 848, 856, 857, 895, 899, 910, 911, 937, 947, 949, 951, 952, 961, 964, 966, 967, 977, 993, 996, 998, 1004, 1011, 1012, 1015, 1030, 1031, 1032, 1033, 1039, 1048, 1050, 1052, 1053, 1059, 1060, 1063, 1070, 1076, 1077, 1082, 1083, 1086, 1107, 1108, 1113, 1116, 1119, 1120, 1121, 1122, 1123, 1130, 1147, 1148, 1159, 1164, 1165, 1166, 1167, 1169, 1170, 1181, 1182, 1185, 1186, 1196, 1197, 1204, 1205, 1210, 1213, 1225, 1232, 1248, 1249, 1256, 1268, 1269, 1319, 1328, 1334, 1335, 1336, 1361, 1362, 1382, 1384, 1385, 1388, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1400, 1403, 1404, 1405, 1406, 1419, 1422, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1441, 1443, 1444, 1445, 1446, 1447, 1452, 1457, 1458, 1465, 1473, 1484, 1499, 1505, 1508, 1522, 1537, 1538, 1540, 1549, 1565, 1570, 1571, 1574, 1590, 1605, 1607, 1608, 1609, 1611, 1612, 1613, 1614, 1615, 1616, 1628, 1640, 1642, 1646, 1656, 1657, 1658, 1659, 1661, 1667, 1674, 1676, 1678, 1679, 1683, 1686, 1687, 1689, 1690, 1699, 1701, 1704, 1706, 1712, 1713, 1715, 1716, 1717, 1718, 1719, 1723, 1724, 1727, 1728, 1729, 1730, 1732, 1734], "maximum": [2, 24, 35, 36, 590, 592, 604, 697, 731, 733, 739, 745, 746, 759, 760, 827, 855, 856, 857, 967, 994, 1075, 1204, 1205, 1364, 1382, 1450, 1458, 1502, 1503, 1504, 1507, 1549, 1563, 1677, 1694, 1695, 1699, 1714, 1722, 1734], "try": [2, 3, 4, 6, 7, 19, 20, 27, 28, 32, 35, 40, 751, 834, 900, 901, 910, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1168, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1319, 1436, 1667, 1674, 1676, 1679, 1680, 1696, 1699, 1701, 1702, 1703, 1708, 1713, 1716, 1719, 1720, 1724], "dispatch": [2, 20, 40, 42, 900, 1679, 1683, 1699, 1701, 1713, 1738], "via": [2, 6, 10, 12, 13, 17, 20, 24, 33, 40, 42, 469, 568, 637, 638, 663, 719, 739, 785, 967, 1034, 1035, 1036, 1053, 1071, 1079, 1080, 1081, 1088, 1155, 1384, 1416, 1419, 1458, 1676, 1678, 1679, 1687, 1688, 1691, 1694, 1696, 1699, 1701, 1702, 1704, 1706, 1708, 1713, 1714, 1716, 1719, 1724, 1725, 1730, 1731, 1738], "v8": 2, "verbos": [2, 12, 20, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1674, 1690, 1713, 1732], "On": [2, 12, 16, 17, 20, 21, 24, 36, 42, 581, 584, 644, 656, 942, 990, 1001, 1044, 1045, 1046, 1047, 1048, 1049, 1069, 1084, 1085, 1086, 1087, 1103, 1126, 1131, 1144, 1319, 1433, 1434, 1443, 1446, 1676, 1698, 1699, 1709, 1716, 1724, 1725, 1726, 1727], "demand": [2, 17, 719, 1678, 1705, 1724], "onemkl": 2, "easier": [2, 6, 17, 42, 1676, 1678, 1691, 1696, 1697, 1701], "dump": [2, 42, 1712], "messag": [2, 20, 28, 37, 42, 575, 742, 744, 924, 925, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1461, 1674, 1676, 1677, 1679, 1680, 1702, 1713, 1717, 1724, 1726, 1734], "durat": [2, 20, 32, 35, 1687, 1718], "kernel": [2, 3, 4, 10, 12, 20, 40, 41, 690, 691, 692, 725, 726, 757, 758, 1029, 1030, 1031, 1044, 1045, 1046, 1047, 1048, 1049, 1063, 1064, 1065, 1084, 1085, 1092, 1093, 1094, 1095, 1096, 1097, 1109, 1110, 1111, 1112, 1113, 1114, 1167, 1188, 1189, 1190, 1191, 1192, 1193, 1208, 1209, 1332, 1333, 1334, 1335, 1336, 1365, 1366, 1367, 1387, 1676, 1683, 1685, 1691, 1699, 1701, 1707, 1709, 1713, 1718, 1720, 1727], "environ": [2, 3, 6, 12, 13, 16, 18, 19, 24, 26, 28, 33, 38, 42, 904, 910, 1086, 1131, 1660, 1674, 1676, 1696, 1698, 1699, 1700, 1704, 1709, 1710, 1712, 1717, 1724], "variabl": [2, 3, 5, 12, 16, 18, 19, 24, 28, 33, 38, 40, 42, 401, 626, 682, 686, 750, 782, 908, 910, 967, 1037, 1044, 1045, 1046, 1047, 1048, 1049, 1053, 1059, 1060, 1068, 1069, 1086, 1087, 1088, 1101, 1103, 1116, 1119, 1124, 1131, 1133, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1307, 1308, 1309, 1310, 1312, 1313, 1319, 1323, 1324, 1325, 1327, 1331, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1349, 1353, 1357, 1410, 1411, 1412, 1413, 1414, 1426, 1431, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1484, 1551, 1553, 1555, 1660, 1667, 1672, 1674, 1690, 1696, 1698, 1699, 1700, 1702, 1703, 1709, 1710, 1712, 1713, 1715, 1719, 1724, 1732], "mkl_verbos": 2, "methodolog": 2, "larg": [2, 3, 6, 7, 17, 20, 42, 43, 534, 684, 686, 739, 940, 958, 1024, 1063, 1167, 1207, 1319, 1458, 1537, 1599, 1609, 1675, 1688, 1690, 1698, 1699, 1702, 1706, 1709, 1711, 1713, 1716, 1717, 1720, 1724, 1727, 1730, 1733], "moreov": [2, 465, 1319], "investig": [2, 6, 20], "singl": [2, 3, 12, 18, 20, 23, 24, 26, 28, 34, 35, 40, 41, 42, 209, 590, 591, 623, 630, 631, 632, 633, 634, 635, 636, 645, 654, 658, 682, 686, 725, 728, 852, 853, 857, 880, 894, 895, 910, 911, 914, 972, 998, 1022, 1023, 1026, 1027, 1030, 1031, 1033, 1044, 1045, 1046, 1048, 1049, 1052, 1053, 1064, 1065, 1071, 1084, 1085, 1088, 1110, 1111, 1116, 1124, 1128, 1129, 1144, 1155, 1172, 1173, 1174, 1175, 1176, 1177, 1180, 1181, 1182, 1188, 1189, 1190, 1191, 1192, 1193, 1208, 1209, 1210, 1237, 1238, 1239, 1280, 1317, 1319, 1359, 1360, 1361, 1362, 1365, 1366, 1367, 1381, 1382, 1383, 1418, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1441, 1443, 1444, 1445, 1447, 1452, 1472, 1499, 1565, 1617, 1657, 1658, 1660, 1667, 1676, 1678, 1679, 1688, 1690, 1691, 1696, 1698, 1699, 1701, 1703, 1706, 1708, 1709, 1710, 1711, 1713, 1715, 1716, 1717, 1718, 1719, 1725, 1726, 1727, 1730, 1733, 1734], "enough": [2, 7, 18, 42, 534, 906, 1007, 1165, 1611, 1612, 1613, 1614, 1615, 1616, 1660, 1678, 1688, 1701, 1703, 1715, 1716, 1730, 1738], "scope": [2, 6, 37, 42, 834, 1155, 1400, 1676, 1678, 1679, 1699, 1702, 1713, 1716, 1726], "second": [2, 5, 12, 20, 23, 26, 28, 35, 37, 42, 581, 584, 586, 589, 604, 605, 606, 614, 637, 638, 644, 648, 649, 651, 652, 653, 656, 687, 741, 758, 768, 770, 771, 777, 780, 786, 827, 828, 838, 839, 848, 851, 859, 860, 861, 872, 884, 917, 919, 927, 963, 966, 972, 973, 984, 990, 995, 997, 998, 1000, 1001, 1013, 1017, 1020, 1024, 1030, 1031, 1037, 1045, 1046, 1048, 1049, 1059, 1060, 1067, 1068, 1082, 1085, 1086, 1104, 1108, 1110, 1111, 1131, 1144, 1195, 1197, 1231, 1314, 1353, 1400, 1433, 1434, 1437, 1443, 1458, 1570, 1606, 1614, 1645, 1650, 1652, 1661, 1664, 1678, 1679, 1696, 1699, 1702, 1703, 1706, 1710, 1713, 1718, 1724, 1728, 1732], "verbose_on": 2, "level": [2, 3, 6, 7, 8, 13, 17, 20, 26, 27, 28, 32, 40, 42, 451, 623, 624, 625, 633, 691, 840, 1053, 1319, 1340, 1676, 1679, 1680, 1687, 1688, 1691, 1694, 1696, 1698, 1701, 1703, 1716, 1718, 1719, 1720, 1724, 1727, 1732, 1736, 1738], "verbose_off": 2, "dnn": [2, 1698], "onednn": [2, 897, 903], "former": [2, 40, 1086, 1116], "dnnl_verbos": 2, "verbose_on_cr": 2, "timer": [3, 22], "stmt": [3, 1698], "setup": [3, 12, 18, 19, 35, 36, 1319, 1502, 1503, 1504, 1507, 1667, 1698, 1699, 1707, 1724, 1725], "global_setup": 3, "perf_count": 3, "global": [3, 5, 7, 17, 19, 20, 23, 24, 26, 36, 40, 41, 42, 595, 603, 645, 654, 734, 741, 782, 784, 794, 799, 817, 835, 852, 853, 876, 883, 898, 910, 914, 965, 981, 1316, 1317, 1318, 1319, 1396, 1400, 1426, 1551, 1553, 1555, 1558, 1672, 1676, 1679, 1680, 1692, 1695, 1701, 1705, 1706, 1708, 1710, 1719, 1724, 1725, 1726, 1732], "label": [3, 6, 17, 23, 781, 1024, 1033, 1039, 1050, 1052, 1076, 1108, 1119, 1120, 1197, 1411, 1451, 1700, 1708, 1710, 1732], "sub_label": 3, "descript": [3, 6, 11, 12, 17, 28, 35, 42, 866, 867, 868, 940, 967, 1178, 1327, 1475, 1678, 1679, 1699, 1701, 1703, 1705, 1706, 1713, 1739], "env": [3, 19, 20, 24, 28, 33, 35, 38, 42, 739, 1429, 1700, 1709, 1724], "num_thread": 3, "languag": [3, 12, 28, 906, 1024, 1159, 1212, 1702], "measur": [3, 24, 32, 689, 731, 733, 926, 1032, 1033, 1050, 1076, 1083, 1107, 1108, 1164, 1165, 1185, 1186, 1244, 1459, 1699, 1705, 1706, 1715], "statement": [3, 24, 42, 896, 910, 1680, 1696, 1701, 1708, 1711, 1713, 1716, 1719, 1724], "full": [3, 7, 13, 17, 18, 20, 23, 24, 35, 38, 40, 42, 465, 629, 645, 654, 809, 810, 811, 815, 816, 818, 836, 852, 853, 899, 932, 933, 940, 941, 942, 953, 958, 959, 967, 983, 985, 1033, 1039, 1070, 1130, 1159, 1188, 1189, 1190, 1197, 1210, 1256, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1590, 1629, 1630, 1667, 1674, 1676, 1677, 1678, 1679, 1681, 1690, 1695, 1699, 1701, 1703, 1706, 1709, 1710, 1714, 1716, 1719, 1722, 1725, 1731], "org": [3, 4, 6, 8, 9, 13, 18, 24, 36, 967, 1086, 1134, 1135, 1162, 1165, 1323, 1324, 1325, 1326, 1338, 1339, 1349, 1354, 1355, 1356, 1357, 1358, 1419, 1465, 1674, 1680, 1696, 1697, 1706, 1710, 1712, 1713, 1716, 1732, 1739], "html": [3, 4, 6, 13, 36, 1165, 1323, 1324, 1325, 1326, 1338, 1339, 1349, 1354, 1355, 1356, 1357, 1358, 1660, 1697, 1704, 1706, 1710, 1716, 1732], "timeit": [3, 1698], "sever": [3, 13, 17, 20, 24, 40, 42, 728, 785, 870, 895, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1029, 1030, 1031, 1032, 1044, 1045, 1046, 1047, 1048, 1049, 1064, 1065, 1084, 1085, 1104, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1180, 1188, 1189, 1190, 1191, 1192, 1193, 1208, 1209, 1231, 1234, 1235, 1237, 1238, 1239, 1319, 1331, 1332, 1333, 1334, 1335, 1336, 1359, 1360, 1365, 1366, 1367, 1375, 1376, 1386, 1387, 1389, 1390, 1420, 1547, 1548, 1587, 1656, 1676, 1695, 1696, 1698, 1699, 1705, 1706, 1713, 1715, 1719, 1724], "kei": [3, 17, 26, 33, 35, 36, 40, 42, 555, 641, 747, 895, 911, 966, 1116, 1117, 1122, 1126, 1159, 1160, 1161, 1162, 1163, 1328, 1403, 1417, 1538, 1677, 1678, 1679, 1683, 1701, 1705, 1706, 1711, 1713, 1715, 1718, 1719, 1722, 1724, 1725, 1729, 1732, 1734, 1736], "awar": [3, 6, 439, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1319, 1323, 1324, 1325, 1326, 1520, 1521, 1541, 1542, 1690, 1696, 1699, 1716, 1722, 1725], "element": [3, 17, 20, 24, 42, 52, 74, 105, 109, 151, 171, 197, 209, 213, 241, 268, 270, 272, 274, 276, 307, 353, 355, 357, 407, 424, 426, 427, 449, 451, 465, 467, 469, 472, 495, 496, 508, 510, 561, 562, 568, 576, 578, 579, 582, 583, 588, 589, 593, 594, 604, 606, 607, 608, 611, 612, 613, 614, 615, 622, 630, 631, 633, 634, 635, 646, 655, 658, 665, 671, 675, 680, 682, 683, 684, 725, 759, 760, 761, 762, 763, 764, 767, 769, 770, 771, 775, 777, 780, 781, 784, 786, 787, 791, 811, 815, 816, 818, 820, 825, 827, 828, 830, 834, 837, 838, 839, 840, 848, 851, 854, 855, 856, 857, 872, 880, 884, 885, 886, 887, 888, 889, 890, 891, 892, 914, 916, 917, 919, 936, 938, 942, 953, 957, 968, 969, 971, 974, 976, 977, 978, 979, 983, 984, 985, 994, 995, 996, 997, 998, 999, 1000, 1005, 1007, 1012, 1013, 1015, 1017, 1018, 1028, 1029, 1032, 1033, 1034, 1035, 1036, 1038, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1054, 1055, 1056, 1057, 1058, 1060, 1061, 1063, 1068, 1069, 1072, 1073, 1074, 1075, 1076, 1077, 1082, 1083, 1086, 1088, 1092, 1093, 1094, 1095, 1096, 1097, 1102, 1105, 1107, 1108, 1109, 1110, 1111, 1115, 1117, 1119, 1120, 1121, 1122, 1123, 1124, 1126, 1127, 1128, 1129, 1130, 1131, 1133, 1134, 1135, 1136, 1143, 1145, 1146, 1147, 1148, 1149, 1151, 1152, 1154, 1155, 1156, 1157, 1158, 1159, 1164, 1165, 1167, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1196, 1198, 1202, 1205, 1206, 1211, 1212, 1216, 1217, 1218, 1219, 1222, 1225, 1226, 1228, 1233, 1237, 1238, 1239, 1243, 1244, 1248, 1249, 1251, 1254, 1255, 1256, 1257, 1258, 1259, 1263, 1264, 1265, 1266, 1268, 1270, 1272, 1273, 1274, 1275, 1280, 1328, 1351, 1353, 1363, 1364, 1365, 1366, 1367, 1373, 1377, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1403, 1404, 1410, 1411, 1413, 1414, 1421, 1422, 1423, 1425, 1468, 1469, 1472, 1473, 1547, 1548, 1550, 1561, 1564, 1565, 1569, 1571, 1573, 1590, 1593, 1595, 1596, 1597, 1599, 1600, 1603, 1608, 1611, 1612, 1613, 1614, 1615, 1616, 1618, 1619, 1623, 1624, 1628, 1635, 1637, 1638, 1642, 1643, 1644, 1646, 1648, 1649, 1650, 1651, 1652, 1654, 1656, 1657, 1658, 1662, 1663, 1664, 1667, 1670, 1677, 1679, 1694, 1697, 1698, 1701, 1703, 1709, 1711, 1713, 1715, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1738], "lazili": [3, 14, 689, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1314, 1676], "threadpool": 3, "comparison": [3, 18, 20, 42, 895, 910, 911, 1116, 1680, 1701, 1734, 1737], "appl": 3, "synchron": [3, 4, 18, 23, 26, 35, 40, 41, 607, 689, 690, 691, 697, 716, 755, 780, 924, 925, 926, 930, 931, 932, 933, 935, 936, 937, 938, 942, 943, 949, 952, 955, 956, 958, 959, 967, 1155, 1319, 1421, 1423, 1698, 1699, 1700, 1704, 1708, 1717, 1724], "focu": [3, 1459], "replic": [3, 17, 19, 848, 905, 1044, 1045, 1046, 1053, 1063, 1092, 1093, 1094, 1140, 1141, 1142, 1167, 1251, 1277, 1319, 1717], "particularli": [3, 17, 18, 37, 1052, 1053, 1123, 1676, 1699], "variat": [3, 24, 1679, 1701, 1720], "confound": 3, "quantifi": [3, 1165], "nois": [3, 1677, 1710], "median": [3, 24, 128, 1013, 1660, 1677, 1689], "robust": [3, 967, 1688, 1706], "deviat": [3, 24, 331, 1028, 1034, 1035, 1036, 1071, 1079, 1080, 1081, 1088, 1155, 1423, 1623, 1624, 1662, 1663, 1694], "merg": [3, 6, 8, 17, 20, 36, 1117, 1126], "repeat": [3, 24, 446, 686, 781, 958, 985, 1185, 1186, 1465, 1564, 1609, 1629, 1630, 1642, 1677, 1679, 1714, 1718, 1721], "autorang": 3, "exact": [3, 12, 17, 26, 37, 294, 604, 605, 606, 637, 638, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 997, 1048, 1086, 1224, 1319, 1334, 1335, 1336, 1460, 1604, 1694, 1700, 1708, 1738], "discuss": [3, 7, 8, 9, 24, 42, 1077, 1696, 1701, 1706, 1710, 1724, 1726, 1727], "docstr": [3, 12, 42, 895, 1116, 1674], "adapt": [3, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1054, 1172, 1173, 1174, 1175, 1176, 1177, 1359, 1360, 1431, 1432, 1443, 1445, 1452, 1699], "strategi": [3, 6, 17, 18, 20, 23, 28, 40, 630, 632, 908, 1024, 1319, 1458, 1678, 1703, 1720], "metadata": [3, 28, 29, 966, 1574, 1691, 1696, 1701, 1711, 1716, 1718, 1724, 1725, 1732], "field": [3, 6, 20, 23, 26, 28, 32, 33, 42, 622, 893, 895, 983, 1024, 1032, 1033, 1050, 1052, 1076, 1082, 1083, 1107, 1108, 1116, 1119, 1120, 1121, 1123, 1130, 1147, 1148, 1164, 1178, 1185, 1186, 1196, 1213, 1225, 1248, 1256, 1410, 1441, 1687, 1696, 1700, 1708, 1713, 1724, 1725, 1732], "displai": [3, 727, 740, 1224, 1281, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1674, 1680, 1686, 1713, 1732, 1734], "instruct": [3, 4, 10, 12, 19, 37, 41, 1676, 1679, 1709, 1713], "count": [3, 17, 24, 32, 42, 647, 685, 721, 834, 856, 857, 893, 932, 933, 1410, 1657, 1658, 1677, 1687, 1718, 1724, 1726], "wall": 3, "callgrind": 3, "analog": [3, 40, 42, 589, 763, 802, 804, 870, 944, 1086, 1446, 1629, 1642], "constructor": [3, 12, 17, 18, 23, 40, 42, 1024, 1121, 1126, 1127, 1144, 1169, 1170, 1319, 1415, 1485, 1506, 1676, 1679, 1680, 1691, 1699, 1700, 1706, 1724, 1727, 1729, 1730, 1733, 1739], "specif": [3, 5, 6, 7, 8, 12, 19, 20, 23, 24, 26, 33, 35, 37, 40, 42, 43, 465, 641, 691, 771, 801, 857, 892, 899, 904, 908, 910, 911, 997, 1063, 1088, 1316, 1317, 1391, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1443, 1444, 1445, 1446, 1447, 1581, 1674, 1676, 1678, 1679, 1681, 1683, 1687, 1690, 1692, 1696, 1699, 1704, 1708, 1710, 1713, 1715, 1716, 1718, 1719, 1720, 1722, 1724, 1726, 1732, 1733], "snippet": [3, 36, 1674, 1706, 1711], "loop": [3, 18, 42, 636, 728, 731, 733, 910, 1319, 1387, 1542, 1676, 1677, 1679, 1687, 1698, 1699, 1702, 1703, 1706, 1709, 1713, 1718, 1719, 1732], "callabl": [3, 17, 23, 24, 26, 33, 40, 41, 42, 74, 353, 728, 898, 906, 910, 966, 967, 1159, 1161, 1163, 1165, 1319, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1441, 1443, 1444, 1445, 1447, 1454, 1457, 1523, 1674, 1676, 1678, 1679, 1680, 1687, 1699, 1706, 1713, 1716, 1718, 1724, 1734, 1738], "present": [3, 8, 20, 35, 893, 985, 1024, 1086, 1126, 1410, 1674, 1686, 1688, 1689, 1690, 1695, 1696, 1699, 1701, 1703, 1706, 1713, 1716, 1725, 1727, 1730], "default_tim": 3, "string": [3, 11, 12, 20, 26, 32, 33, 35, 42, 555, 725, 726, 781, 895, 902, 905, 966, 1044, 1045, 1046, 1116, 1117, 1126, 1159, 1161, 1163, 1188, 1189, 1190, 1400, 1475, 1499, 1574, 1583, 1674, 1677, 1678, 1679, 1680, 1690, 1696, 1701, 1705, 1706, 1713, 1716, 1718, 1724, 1729, 1730, 1732, 1737, 1738], "summar": [3, 4, 36, 1590, 1679, 1727], "relu": [3, 18, 42, 725, 906, 1116, 1131, 1133, 1144, 1152, 1159, 1161, 1163, 1260, 1261, 1284, 1285, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1299, 1300, 1301, 1302, 1303, 1304, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1358, 1499, 1539, 1667, 1676, 1677, 1685, 1690, 1694, 1696, 1706, 1711, 1713, 1714, 1719, 1721, 1722], "readabl": [3, 11, 17, 33, 42, 727, 740, 1639, 1713, 1738], "supplement": 3, "disambigu": [3, 33, 42, 972], "ident": [3, 12, 17, 20, 24, 42, 637, 638, 768, 932, 933, 934, 935, 948, 960, 963, 967, 985, 1012, 1013, 1028, 1054, 1253, 1384, 1386, 1477, 1499, 1524, 1531, 1664, 1670, 1680, 1694, 1709, 1710, 1716, 1721, 1727], "our": [3, 6, 7, 19, 31, 34, 35, 36, 38, 42, 626, 801, 1032, 1696, 1701, 1703, 1708, 1713, 1716, 1719, 1725], "easi": [3, 17, 19, 35, 1676, 1696, 1702, 1705, 1706, 1708, 1716, 1719, 1724, 1725], "differenti": [3, 24, 105, 307, 541, 619, 621, 622, 624, 625, 627, 630, 631, 632, 633, 634, 635, 636, 637, 638, 673, 728, 909, 941, 942, 953, 985, 1038, 1039, 1059, 1215, 1249, 1319, 1389, 1446, 1487, 1660, 1701, 1702, 1703, 1713, 1724, 1733], "distinguish": [3, 1719, 1727], "princip": [3, 941, 1465], "signal": [3, 10, 26, 35, 797, 798, 799, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 892, 957, 1021, 1022, 1023, 1025, 1026, 1027, 1029, 1030, 1031, 1044, 1045, 1046, 1064, 1065, 1084, 1085, 1104, 1109, 1110, 1111, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1180, 1188, 1191, 1208, 1209, 1231, 1234, 1235, 1237, 1238, 1239, 1331, 1332, 1333, 1359, 1360, 1375, 1376, 1625, 1688, 1708, 1718, 1724], "form": [3, 6, 8, 10, 17, 20, 24, 34, 35, 36, 42, 667, 768, 780, 809, 811, 895, 934, 937, 942, 953, 958, 1022, 1023, 1026, 1027, 1039, 1064, 1065, 1068, 1086, 1116, 1131, 1167, 1168, 1197, 1208, 1209, 1212, 1224, 1251, 1281, 1353, 1372, 1378, 1389, 1446, 1463, 1641, 1674, 1676, 1680, 1691, 1696, 1701, 1706, 1713, 1716, 1719, 1732], "equivil": 3, "treat": [3, 24, 34, 42, 276, 424, 637, 638, 725, 947, 950, 952, 964, 966, 976, 977, 978, 979, 998, 1015, 1060, 1070, 1088, 1120, 1121, 1122, 1123, 1126, 1144, 1149, 1205, 1319, 1421, 1452, 1571, 1625, 1635, 1642, 1678, 1679, 1689, 1696, 1724, 1730, 1737], "distinct": [3, 930, 931, 975, 1633, 1679, 1701, 1711, 1724, 1725], "performac": 3, "workload": [3, 7, 17, 20, 728, 1699, 1705, 1709, 1724], "good": [3, 6, 7, 12, 40, 42, 43, 1124, 1674, 1683, 1688, 1701, 1705, 1706, 1713, 1716, 1717, 1719], "intrins": [3, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1720, 1721], "contrast": [3, 24, 26, 1446, 1694, 1696], "blocked_autorang": 3, "callback": [3, 18, 35, 41, 42, 1319, 1687, 1705, 1718, 1724], "min_run_tim": 3, "minimum": [3, 12, 18, 26, 35, 36, 591, 592, 605, 647, 760, 828, 855, 856, 857, 999, 1039, 1075, 1165, 1364, 1450, 1451, 1458, 1502, 1503, 1504, 1507, 1611, 1612, 1613, 1614, 1615, 1616, 1677, 1694, 1696, 1703, 1714, 1722, 1730], "At": [3, 5, 6, 13, 17, 815, 1044, 1045, 1046, 1047, 1048, 1049, 1084, 1085, 1685, 1691, 1698, 1703, 1719, 1724, 1728], "high": [3, 4, 6, 7, 9, 13, 18, 20, 24, 26, 32, 34, 36, 42, 74, 691, 1039, 1162, 1553, 1554, 1585, 1677, 1687, 1688, 1703, 1704, 1706, 1707, 1715, 1719, 1720, 1724, 1727, 1732, 1733, 1734], "pseudo": [3, 43], "total_tim": 3, "block_siz": 3, "choic": [3, 7, 8, 20, 910, 958, 1117, 1126, 1549, 1698, 1713, 1722], "block": [3, 6, 7, 17, 20, 23, 35, 37, 41, 42, 536, 537, 655, 689, 739, 915, 967, 1044, 1045, 1046, 1047, 1048, 1049, 1063, 1092, 1093, 1094, 1095, 1096, 1097, 1119, 1167, 1207, 1280, 1319, 1429, 1611, 1612, 1613, 1676, 1678, 1679, 1687, 1688, 1692, 1696, 1699, 1700, 1703, 1713, 1719, 1724, 1727], "qualiti": [3, 6, 18], "balanc": [3, 19, 43], "compet": 3, "statist": [3, 18, 20, 24, 731, 733, 734, 735, 737, 739, 740, 741, 745, 746, 747, 758, 972, 1034, 1035, 1036, 1071, 1079, 1080, 1081, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1155, 1484, 1485, 1502, 1503, 1504, 1506, 1507, 1687, 1696, 1702, 1715, 1717, 1719, 1722], "amort": 3, "invoc": [3, 5, 42, 898, 910, 1523, 1676, 1679, 1699, 1701, 1705, 1713, 1724, 1726], "less": [3, 6, 12, 17, 18, 20, 24, 26, 37, 318, 534, 630, 632, 637, 638, 670, 686, 735, 751, 781, 825, 829, 834, 919, 931, 967, 984, 985, 1024, 1077, 1130, 1147, 1153, 1413, 1562, 1633, 1650, 1652, 1674, 1677, 1679, 1699, 1701, 1708, 1709, 1717, 1719], "bias": [3, 18, 1034, 1035, 1036, 1068, 1069, 1071, 1079, 1080, 1081, 1086, 1087, 1088, 1131, 1133, 1155, 1327, 1353], "syncron": [3, 1564], "trivial": [3, 26, 28, 666, 780, 1328, 1384, 1713, 1726], "low": [3, 6, 18, 24, 451, 633, 691, 840, 1039, 1465, 1549, 1553, 1554, 1571, 1630, 1677, 1687, 1688, 1699, 1718, 1727, 1734, 1738], "digit": [3, 1590, 1674, 1686, 1705, 1709], "microsecond": [3, 1699], "bia": [3, 8, 20, 40, 895, 904, 1024, 1037, 1044, 1045, 1046, 1047, 1048, 1049, 1068, 1069, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1103, 1116, 1122, 1131, 1132, 1133, 1183, 1184, 1188, 1189, 1190, 1191, 1192, 1193, 1214, 1223, 1227, 1230, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1309, 1310, 1311, 1312, 1313, 1314, 1319, 1323, 1324, 1325, 1326, 1327, 1328, 1331, 1332, 1333, 1334, 1335, 1336, 1342, 1344, 1345, 1346, 1347, 1349, 1353, 1354, 1357, 1358, 1365, 1366, 1367, 1374, 1384, 1385, 1399, 1401, 1403, 1416, 1419, 1546, 1677, 1685, 1701, 1706, 1711, 1719, 1732], "period": [3, 8, 23, 35, 645, 654, 727, 740, 741, 758, 801, 852, 853, 914, 1461, 1677, 1687, 1708], "until": [3, 6, 17, 18, 20, 23, 26, 35, 40, 41, 42, 439, 689, 690, 691, 719, 834, 915, 967, 1213, 1314, 1319, 1449, 1455, 1642, 1688, 1694, 1699, 1702, 1713, 1718, 1724, 1726], "overal": [3, 8, 17, 20, 35, 637, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 1162, 1696, 1698, 1699, 1708, 1720], "main": [3, 17, 18, 19, 20, 21, 24, 26, 27, 28, 33, 35, 36, 37, 38, 42, 215, 448, 767, 768, 769, 770, 771, 957, 1215, 1609, 1649, 1650, 1651, 1652, 1674, 1676, 1687, 1688, 1690, 1695, 1696, 1699, 1700, 1701, 1712, 1724, 1725, 1732, 1733], "repetit": [3, 1564, 1642], "collect_callgrind": 3, "collect_baselin": 3, "retain_out_fil": 3, "modulo": [3, 24, 829, 1562], "determin": [3, 7, 10, 12, 14, 16, 17, 18, 20, 24, 26, 33, 35, 40, 42, 630, 632, 637, 638, 645, 654, 661, 666, 729, 783, 802, 812, 836, 852, 853, 856, 857, 908, 928, 940, 951, 954, 975, 990, 1060, 1064, 1065, 1086, 1125, 1131, 1205, 1208, 1209, 1224, 1257, 1281, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1427, 1458, 1505, 1508, 1552, 1554, 1556, 1582, 1625, 1673, 1679, 1680, 1690, 1699, 1700, 1701, 1706, 1713, 1716, 1719, 1724, 1726, 1730, 1732, 1734], "itself": [3, 5, 6, 7, 19, 20, 21, 40, 42, 588, 594, 609, 686, 895, 906, 910, 1116, 1149, 1268, 1319, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1407, 1676, 1688, 1706, 1710, 1716, 1724, 1731], "jitter": 3, "interpret": [3, 17, 19, 20, 23, 24, 26, 35, 37, 610, 636, 738, 802, 803, 804, 809, 811, 812, 813, 814, 834, 845, 857, 895, 900, 906, 910, 947, 1056, 1213, 1224, 1225, 1281, 1372, 1378, 1582, 1588, 1674, 1678, 1679, 1688, 1698, 1699, 1713, 1727, 1729, 1731], "ideal": [3, 34, 36, 910, 1690], "analysi": [3, 18, 42, 914, 1465, 1680, 1706, 1737], "valgrind": 3, "degrad": [3, 12, 1698, 1701], "due": [3, 4, 5, 6, 18, 20, 24, 34, 42, 439, 610, 630, 631, 636, 682, 907, 930, 931, 958, 985, 1056, 1070, 1159, 1168, 1224, 1415, 1630, 1676, 1699, 1703, 1706, 1710, 1713, 1719, 1720, 1724, 1726], "amelior": 3, "suffici": [3, 12, 18, 24, 27, 35, 1674, 1730], "obtain": [3, 17, 20, 24, 28, 41, 42, 448, 642, 840, 993, 1039, 1123, 1197, 1319, 1465, 1549, 1630, 1679, 1688, 1689, 1698, 1710, 1713, 1715, 1718, 1719], "callgrind_control": 3, "callgrind_annot": 3, "boundari": [3, 42, 660, 848, 1041, 1042, 1043, 1137, 1138, 1139, 1140, 1141, 1142, 1168, 1171, 1224, 1281, 1372, 1378, 1452, 1458, 1578, 1677, 1716, 1717, 1724], "caller": [3, 26, 35, 42, 895, 1116, 1163, 1318, 1696, 1699, 1724, 1726], "structur": [3, 5, 8, 17, 18, 20, 25, 26, 28, 36, 42, 832, 910, 1116, 1396, 1400, 1465, 1540, 1630, 1667, 1678, 1680, 1687, 1699, 1700, 1701, 1708, 1711, 1712, 1713, 1715, 1716, 1724, 1727, 1732, 1733, 1734, 1735, 1737], "restrict": [3, 7, 17, 24, 40, 1052, 1122, 1678, 1679, 1680, 1690, 1696, 1699, 1703, 1717, 1719, 1734], "builtin": [3, 19, 20, 42, 907, 966, 1558, 1676, 1678, 1680, 1724, 1726], "surpris": [3, 7, 40, 1674, 1703, 1709], "serial": [3, 13, 17, 20, 23, 35, 895, 904, 905, 966, 1116, 1314, 1574, 1674, 1675, 1677, 1686, 1690, 1696, 1699, 1705, 1706, 1708, 1716, 1719, 1725], "subsequ": [3, 6, 12, 13, 20, 42, 690, 895, 906, 910, 1044, 1045, 1046, 1047, 1048, 1049, 1116, 1144, 1318, 1710, 1713, 1724], "deseri": [3, 966, 1314, 1674, 1686], "globalsbridg": 3, "care": [3, 6, 12, 20, 24, 40, 41, 42, 802, 804, 1116, 1633, 1688, 1698, 1699, 1700, 1701, 1702, 1706, 1708, 1711, 1724, 1727], "reli": [3, 8, 12, 17, 18, 26, 28, 42, 105, 622, 637, 1053, 1696, 1698, 1700, 1701, 1710, 1711, 1731], "pickl": [3, 17, 18, 20, 895, 966, 1116, 1574, 1688, 1711, 1716], "transfer": [3, 17, 20, 1688, 1699, 1704, 1706, 1716, 1724], "properli": [3, 6, 17, 18, 23, 26, 35, 40, 41, 802, 803, 804, 812, 813, 814, 998, 1117, 1118, 1126, 1127, 1319, 1674, 1701, 1703, 1706, 1708, 1711, 1724, 1725, 1730], "profil": [3, 4, 32, 42, 908, 1316, 1317, 1318, 1590, 1675, 1724], "drive": [3, 8, 20, 1696], "callgrindstat": 3, "facil": [3, 966, 1688, 1713], "analyz": [3, 4, 42, 1700, 1701], "manipul": [3, 41, 899, 1695, 1702, 1706, 1717, 1722], "1000000": [3, 1430], "mirror": [3, 94], "semant": [3, 8, 14, 20, 35, 36, 42, 105, 604, 605, 606, 622, 636, 658, 691, 739, 899, 905, 964, 1257, 1658, 1667, 1675, 1678, 1679, 1683, 1691, 1706, 1713], "doc": [3, 4, 8, 13, 35, 36, 913, 1160, 1161, 1162, 1163, 1323, 1324, 1325, 1326, 1338, 1339, 1349, 1354, 1355, 1356, 1357, 1358, 1522, 1660, 1667, 1680, 1688, 1697, 1701, 1706, 1710, 1713, 1714, 1716, 1732], "number_per_run": 3, "raw_tim": 3, "task_spec": 3, "serializ": [3, 18, 1676], "__repr__": [3, 1701], "consum": [3, 17, 25, 41, 781, 1688, 1699, 1708, 1713, 1732], "extrapol": 3, "sinc": [3, 6, 17, 18, 19, 20, 24, 28, 37, 40, 42, 270, 485, 534, 666, 731, 733, 735, 780, 821, 822, 823, 892, 895, 900, 905, 908, 985, 1032, 1059, 1112, 1113, 1114, 1116, 1168, 1178, 1213, 1215, 1281, 1314, 1316, 1340, 1378, 1400, 1422, 1450, 1451, 1452, 1458, 1633, 1676, 1677, 1678, 1679, 1685, 1687, 1695, 1696, 1699, 1701, 1702, 1703, 1705, 1706, 1711, 1712, 1713, 1716, 1717, 1718, 1719, 1723, 1724, 1725, 1726, 1728, 1730, 1731, 1733], "properti": [3, 17, 21, 24, 27, 32, 35, 40, 42, 610, 642, 712, 797, 798, 800, 802, 803, 804, 812, 813, 814, 893, 895, 1028, 1149, 1268, 1314, 1320, 1321, 1322, 1410, 1679, 1683, 1687, 1696, 1699, 1703, 1715, 1718, 1724, 1727, 1729, 1730, 1733, 1735, 1738, 1739], "significant_figur": 3, "figur": [3, 6, 7, 42, 1698, 1700, 1713, 1717, 1726, 1732], "intend": [3, 35, 42, 620, 628, 693, 914, 1178, 1316, 1317, 1318, 1433, 1434, 1679, 1691, 1694, 1696, 1706, 1716], "interquartil": 3, "mitig": 3, "tail": [3, 17, 33], "z": [3, 9, 19, 24, 40, 568, 607, 628, 667, 668, 677, 781, 785, 998, 1069, 1213, 1389, 1420, 1421, 1469, 1502, 1566, 1567, 1676, 1677, 1678, 1690, 1696, 1698, 1699, 1703, 1704, 1713, 1716, 1722, 1724, 1726], "645": 3, "conjunct": [3, 17, 20, 23, 40, 1178, 1213, 1319, 1485, 1506, 1722], "trim_sigfig": 3, "human": [3, 11, 33, 727, 740, 1694, 1713, 1738], "raw": [3, 42, 834, 953, 1052, 1699, 1716], "built_with_debug_symbol": 3, "baseline_inclusive_stat": 3, "baseline_exclusive_stat": 3, "stmt_inclusive_stat": 3, "stmt_exclusive_stat": 3, "stmt_callgrind_out": 3, "done": [3, 13, 17, 20, 24, 26, 33, 40, 41, 42, 448, 637, 798, 800, 803, 804, 806, 807, 810, 811, 813, 814, 816, 818, 910, 985, 993, 1034, 1035, 1036, 1053, 1056, 1079, 1080, 1081, 1098, 1099, 1100, 1101, 1126, 1155, 1161, 1163, 1319, 1620, 1679, 1683, 1685, 1688, 1698, 1699, 1700, 1702, 1706, 1709, 1713, 1717, 1719, 1720, 1724, 1726], "functioncount": 3, "stat": [3, 745, 746, 747, 1155, 1319, 1518, 1519, 1687, 1736], "as_standard": 3, "strip": [3, 1215, 1319, 1676], "prefix": [3, 20, 35, 40, 895, 1116, 1319, 1341, 1350, 1500, 1674, 1696, 1713, 1716, 1736], "stumbl": 3, "path": [3, 4, 7, 12, 19, 20, 33, 35, 38, 40, 42, 639, 640, 895, 1116, 1132, 1163, 1327, 1674, 1678, 1696, 1699, 1701, 1704, 1711, 1716, 1718, 1736], "filepath": 3, "dif": 3, "compon": [3, 6, 8, 13, 20, 24, 42, 637, 801, 802, 804, 812, 813, 814, 1159, 1160, 1161, 1162, 1163, 1314, 1465, 1625, 1665, 1666, 1680, 1696, 1700, 1705, 1706, 1717], "locat": [3, 12, 19, 20, 24, 32, 105, 109, 209, 465, 658, 660, 698, 759, 760, 916, 966, 994, 999, 1002, 1007, 1053, 1063, 1150, 1167, 1178, 1213, 1277, 1280, 1319, 1389, 1476, 1578, 1607, 1610, 1660, 1674, 1676, 1686, 1699, 1713, 1716, 1718, 1724, 1726, 1727, 1732, 1736], "someth": [3, 6, 42, 630, 632, 781, 895, 910, 1116, 1681, 1687, 1688, 1689, 1696, 1704, 1712, 1713, 1724, 1738], "resembl": [3, 13], "23234231": 3, "first_build_dir": 3, "foo": [3, 12, 20, 32, 33, 41, 42, 893, 898, 902, 905, 906, 909, 910, 1417, 1485, 1506, 1538, 1540, 1674, 1676, 1678, 1679, 1683, 1701, 1706, 1713, 1716, 1734], "9823794": 3, "bar": [3, 6, 32, 42, 686, 898, 905, 1538, 1540, 1674, 1676, 1678, 1686, 1706, 1713, 1716, 1734], "53453": 3, "src": [3, 20, 42, 151, 183, 268, 276, 424, 464, 465, 466, 467, 468, 469, 471, 489, 771, 1007, 1159, 1162, 1163, 1575, 1576, 1577, 1581, 1600, 1635, 1677, 1716], "function_that_actually_chang": 3, "second_build_dir": 3, "cancel": [3, 892], "site": [3, 6, 19], "denois": 3, "explat": 3, "delta": [3, 24, 1068, 1076, 1077, 1086, 1147, 1222, 1353, 1431, 1623, 1624, 1646, 1662, 1663, 1677, 1694], "inclus": [3, 24, 43, 465, 855, 857, 965, 981, 988, 1553, 1554, 1622, 1723, 1734], "diff": [3, 6, 1676, 1677], "One": [3, 7, 12, 19, 20, 42, 655, 886, 1168, 1250, 1384, 1387, 1452, 1459, 1553, 1554, 1656, 1667, 1676, 1678, 1679, 1690, 1697, 1698, 1701, 1705, 1717, 1726, 1732], "reason": [3, 7, 8, 17, 20, 802, 804, 895, 910, 911, 930, 931, 958, 997, 1032, 1056, 1116, 1215, 1318, 1389, 1523, 1574, 1676, 1678, 1679, 1696, 1700, 1709, 1711, 1713, 1724, 1730, 1738], "unit": [3, 10, 12, 24, 26, 36, 40, 42, 780, 799, 817, 1028, 1038, 1058, 1061, 1066, 1067, 1068, 1069, 1134, 1135, 1145, 1178, 1202, 1206, 1211, 1212, 1258, 1265, 1353, 1354, 1393, 1394, 1398, 1401, 1403, 1406, 1648, 1698, 1703, 1716], "next": [3, 17, 20, 24, 35, 40, 42, 510, 899, 1020, 1069, 1087, 1133, 1225, 1319, 1353, 1412, 1688, 1695, 1696, 1698, 1706, 1708, 1717, 1718, 1724, 1725, 1730, 1732], "logic": [3, 5, 12, 17, 38, 40, 42, 648, 650, 651, 653, 798, 800, 803, 804, 806, 807, 810, 811, 813, 814, 816, 818, 899, 976, 977, 978, 979, 990, 1319, 1474, 1568, 1679, 1680, 1699, 1701, 1703, 1719], "question": [3, 9, 17, 42, 1675, 1696], "why": [3, 6, 17, 42, 781, 899], "involv": [3, 6, 8, 10, 17, 40, 42, 1319, 1679, 1689, 1691, 1696, 1699, 1700, 1702, 1706, 1713, 1724, 1725, 1726, 1727], "look": [3, 4, 6, 7, 8, 13, 19, 20, 24, 34, 35, 42, 630, 632, 895, 990, 1024, 1116, 1204, 1402, 1611, 1612, 1613, 1615, 1616, 1667, 1676, 1678, 1689, 1695, 1696, 1699, 1705, 1706, 1708, 1712, 1713, 1716, 1719, 1724, 1725], "autom": [3, 7, 42, 1676, 1719], "easili": [3, 6, 7, 10, 18, 20, 1123, 1213, 1251, 1571, 1703, 1706, 1711, 1715, 1723, 1726, 1732], "exclus": [3, 17, 20, 24, 26, 35, 42, 857, 1319, 1553, 1554, 1557, 1696, 1734], "basi": [3, 8, 9, 24, 967, 1452, 1705, 1719, 1724], "thought": [3, 32, 42, 799, 801, 817], "tupl": [3, 5, 12, 17, 32, 35, 42, 274, 400, 402, 449, 472, 488, 510, 534, 590, 591, 592, 608, 609, 616, 617, 618, 619, 630, 631, 632, 633, 634, 635, 637, 638, 659, 685, 696, 697, 700, 710, 728, 759, 760, 778, 780, 782, 784, 798, 800, 801, 803, 804, 806, 807, 808, 810, 811, 813, 814, 816, 818, 821, 831, 835, 840, 856, 858, 895, 901, 906, 910, 911, 916, 925, 930, 931, 936, 937, 938, 939, 940, 941, 942, 943, 947, 951, 953, 954, 956, 958, 961, 964, 982, 983, 985, 987, 994, 996, 998, 999, 1002, 1004, 1012, 1015, 1022, 1023, 1026, 1027, 1029, 1030, 1031, 1039, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1053, 1063, 1064, 1065, 1085, 1092, 1093, 1094, 1095, 1096, 1097, 1110, 1111, 1112, 1113, 1114, 1116, 1137, 1138, 1139, 1140, 1141, 1142, 1166, 1167, 1168, 1169, 1170, 1171, 1173, 1174, 1176, 1177, 1180, 1181, 1182, 1188, 1189, 1190, 1191, 1192, 1193, 1208, 1209, 1224, 1237, 1238, 1239, 1251, 1281, 1282, 1283, 1317, 1318, 1359, 1360, 1361, 1362, 1365, 1366, 1367, 1372, 1378, 1379, 1380, 1389, 1400, 1413, 1417, 1421, 1422, 1426, 1433, 1434, 1435, 1437, 1443, 1445, 1447, 1466, 1475, 1551, 1553, 1555, 1565, 1569, 1570, 1603, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1623, 1624, 1628, 1629, 1633, 1639, 1640, 1641, 1642, 1643, 1648, 1655, 1656, 1657, 1658, 1662, 1663, 1667, 1668, 1670, 1672, 1676, 1677, 1680, 1688, 1696, 1699, 1701, 1706, 1711, 1713, 1716, 1719, 1724, 1727, 1732, 1734, 1737, 1738], "path_and_function_nam": 3, "children": [3, 28, 40, 42, 895, 1116, 1481, 1688, 1706, 1716, 1726], "identifi": [3, 6, 20, 26, 29, 32, 35, 36, 37, 42, 857, 966, 1155, 1680, 1688, 1697, 1705, 1706, 1716, 1724, 1725, 1726, 1732], "hot": [3, 24, 1215, 1250, 1703], "spot": 3, "_data": 3, "truncate_row": 3, "_linewidth": 3, "subtract": [3, 268, 514, 834, 1215, 1611, 1612, 1613, 1615, 1616, 1626, 1677, 1727], "index": [3, 13, 17, 18, 24, 33, 42, 146, 163, 236, 267, 268, 269, 270, 271, 272, 274, 276, 277, 424, 425, 464, 465, 466, 467, 468, 469, 470, 471, 590, 591, 607, 660, 702, 705, 759, 760, 801, 837, 866, 867, 868, 869, 893, 911, 916, 924, 942, 960, 974, 982, 985, 989, 994, 997, 998, 999, 1002, 1007, 1013, 1024, 1039, 1052, 1059, 1060, 1117, 1118, 1123, 1126, 1127, 1165, 1167, 1204, 1205, 1250, 1395, 1397, 1404, 1405, 1410, 1421, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1476, 1575, 1576, 1577, 1578, 1580, 1581, 1600, 1608, 1609, 1611, 1612, 1613, 1615, 1616, 1625, 1635, 1656, 1659, 1660, 1667, 1675, 1676, 1677, 1679, 1688, 1689, 1690, 1691, 1696, 1699, 1700, 1704, 1710, 1714, 1726, 1727, 1730, 1731, 1732, 1733, 1734], "cpython": [3, 19, 42], "known": [3, 6, 8, 16, 20, 23, 29, 910, 911, 966, 1044, 1045, 1046, 1047, 1048, 1049, 1063, 1086, 1131, 1145, 1147, 1167, 1224, 1265, 1314, 1639, 1677, 1681, 1687, 1688, 1694, 1696, 1698, 1710, 1713, 1726, 1728], "quit": [3, 6, 42, 1679, 1701, 1702, 1716, 1724], "noisi": 3, "higher": [3, 6, 7, 18, 20, 40, 105, 622, 623, 636, 728, 772, 855, 872, 1014, 1052, 1108, 1123, 1476, 1630, 1667, 1699, 1701, 1703, 1705, 1719, 1720, 1724, 1730], "filter": [3, 8, 494, 892, 914, 1044, 1045, 1046, 1047, 1048, 1049, 1188, 1189, 1190, 1191, 1192, 1193, 1365, 1366, 1367, 1625, 1679, 1716], "transform": [3, 17, 40, 667, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 892, 904, 1037, 1071, 1079, 1080, 1081, 1088, 1103, 1144, 1160, 1161, 1162, 1163, 1178, 1184, 1213, 1230, 1249, 1314, 1374, 1482, 1520, 1521, 1536, 1537, 1625, 1717, 1719, 1732], "rather": [3, 5, 7, 8, 12, 20, 26, 28, 37, 42, 388, 641, 666, 780, 893, 896, 1178, 1213, 1224, 1281, 1372, 1378, 1385, 1590, 1676, 1679, 1690, 1691, 1697, 1699, 1701, 1713, 1716, 1719, 1724, 1732], "unicod": [3, 1680], "dictionari": [3, 12, 17, 18, 24, 42, 739, 895, 896, 902, 906, 910, 911, 967, 1059, 1060, 1116, 1117, 1126, 1204, 1400, 1482, 1500, 1520, 1521, 1522, 1537, 1540, 1543, 1678, 1680, 1701, 1706, 1713, 1715, 1724, 1732, 1736, 1738], "lookup": [3, 24, 1059, 1204, 1676, 1680, 1698, 1725], "map": [3, 12, 20, 24, 26, 32, 33, 35, 36, 40, 42, 579, 615, 657, 848, 857, 902, 905, 966, 967, 1047, 1048, 1049, 1055, 1056, 1057, 1061, 1063, 1112, 1113, 1114, 1117, 1126, 1199, 1200, 1201, 1206, 1328, 1384, 1400, 1429, 1476, 1482, 1484, 1499, 1521, 1522, 1536, 1537, 1540, 1543, 1545, 1657, 1658, 1667, 1680, 1690, 1692, 1696, 1700, 1701, 1707, 1712, 1716, 1719, 1722, 1724, 1725, 1726, 1729, 1734, 1738], "agnost": [3, 35, 1213, 1690], "reliabl": 3, "warrant": 3, "except": [3, 5, 6, 8, 12, 20, 21, 24, 26, 27, 28, 32, 36, 41, 42, 388, 568, 579, 588, 590, 591, 594, 615, 637, 638, 663, 670, 674, 698, 700, 727, 740, 772, 778, 781, 827, 828, 858, 902, 912, 916, 950, 966, 982, 994, 996, 997, 999, 1002, 1012, 1015, 1068, 1086, 1131, 1168, 1250, 1319, 1353, 1385, 1410, 1415, 1416, 1422, 1473, 1564, 1604, 1621, 1628, 1646, 1667, 1668, 1675, 1676, 1678, 1679, 1680, 1681, 1688, 1699, 1701, 1706, 1712, 1716, 1717, 1724, 1726, 1727, 1730, 1734], "filter_fn": 3, "map_fn": 3, "coalesc": [3, 278, 283, 494, 565, 697, 1610, 1656, 1677, 1700, 1727], "h": [4, 9, 12, 19, 440, 924, 931, 934, 944, 958, 1022, 1023, 1030, 1031, 1035, 1036, 1040, 1045, 1046, 1048, 1056, 1057, 1059, 1061, 1068, 1069, 1080, 1081, 1086, 1087, 1088, 1099, 1100, 1110, 1111, 1128, 1129, 1131, 1133, 1150, 1166, 1169, 1170, 1178, 1213, 1248, 1254, 1255, 1334, 1335, 1336, 1353, 1384, 1385, 1416, 1629, 1677, 1689, 1690, 1696, 1699, 1700, 1702, 1703, 1713, 1731, 1732, 1733], "finit": [4, 24, 637, 638, 884, 885, 930, 931, 941, 942, 958, 985, 1007, 1011, 1032, 1629, 1701, 1703, 1734], "natur": [4, 6, 7, 10, 20, 24, 637, 638, 923, 928, 954, 968, 970, 975, 1024, 1163, 1703, 1727, 1728], "against": [4, 12, 20, 26, 35, 595, 637, 638, 809, 810, 811, 815, 816, 818, 837, 886, 895, 910, 911, 1116, 1122, 1674, 1679, 1716, 1737], "cprofil": 4, "mode": [4, 7, 17, 18, 20, 24, 35, 42, 176, 177, 619, 621, 623, 624, 625, 630, 631, 632, 633, 637, 716, 755, 756, 785, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 843, 870, 878, 879, 893, 895, 896, 899, 910, 912, 953, 998, 1034, 1035, 1036, 1044, 1045, 1046, 1060, 1071, 1079, 1080, 1081, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1116, 1132, 1155, 1168, 1169, 1188, 1189, 1190, 1205, 1213, 1224, 1251, 1281, 1282, 1283, 1339, 1340, 1365, 1366, 1367, 1372, 1378, 1379, 1380, 1385, 1389, 1420, 1452, 1459, 1475, 1505, 1508, 1538, 1539, 1540, 1541, 1584, 1586, 1587, 1660, 1677, 1685, 1689, 1694, 1699, 1700, 1702, 1706, 1718, 1720, 1721, 1722, 1724, 1738], "correct": [4, 6, 18, 20, 21, 24, 35, 160, 161, 164, 176, 531, 555, 556, 626, 638, 686, 802, 804, 812, 813, 814, 869, 893, 896, 910, 911, 930, 1053, 1070, 1082, 1314, 1319, 1410, 1589, 1623, 1624, 1662, 1663, 1676, 1677, 1678, 1689, 1690, 1699, 1701, 1703, 1729], "launch": [4, 12, 17, 22, 26, 27, 28, 33, 34, 35, 38, 41, 690, 1319, 1696, 1698, 1699, 1724], "spent": [4, 20, 642, 1458, 1698, 1706], "appear": [4, 18, 20, 24, 42, 728, 781, 822, 823, 966, 1002, 1004, 1318, 1320, 1564, 1592, 1667, 1676, 1679, 1689, 1690, 1701, 1706, 1713, 1716], "extrem": [4, 1319, 1696, 1713], "expens": [4, 17, 24, 1384, 1699, 1703, 1705, 1718, 1724, 1733], "bound": [4, 13, 18, 434, 660, 671, 795, 796, 895, 1029, 1030, 1031, 1109, 1110, 1111, 1116, 1134, 1213, 1459, 1557, 1578, 1679, 1680, 1694, 1716, 1719, 1728], "greater": [4, 20, 35, 247, 568, 665, 666, 671, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 839, 851, 949, 1032, 1164, 1213, 1224, 1250, 1281, 1385, 1416, 1660, 1677, 1696, 1699, 1710, 1728], "spend": [4, 6, 967], "sens": [4, 24, 35, 42, 1400, 1657, 1658, 1679, 1696], "respons": [4, 6, 8, 20, 23, 24, 26, 32, 37, 40, 41, 690, 1104, 1231, 1319, 1696, 1699, 1701, 1706, 1724], "Of": [4, 1421, 1674, 1700, 1701], "cours": [4, 42, 1674, 1700, 1701, 1724], "realiti": 4, "complic": [4, 18, 42, 1683, 1690, 1697, 1716, 1724, 1726], "depend": [4, 5, 12, 17, 19, 20, 23, 24, 26, 35, 36, 37, 40, 42, 270, 608, 741, 758, 802, 804, 812, 813, 814, 906, 910, 930, 931, 958, 985, 990, 1032, 1033, 1050, 1052, 1060, 1063, 1076, 1082, 1083, 1107, 1108, 1119, 1120, 1121, 1123, 1130, 1147, 1148, 1164, 1167, 1168, 1178, 1185, 1186, 1196, 1205, 1213, 1225, 1248, 1256, 1281, 1314, 1319, 1378, 1389, 1390, 1396, 1452, 1463, 1465, 1549, 1565, 1611, 1612, 1613, 1615, 1616, 1629, 1648, 1670, 1674, 1676, 1678, 1679, 1688, 1696, 1698, 1699, 1701, 1703, 1706, 1713, 1718, 1719, 1724, 1727, 1733, 1734], "could": [4, 6, 7, 17, 20, 24, 26, 35, 40, 41, 42, 721, 802, 804, 812, 813, 814, 892, 925, 966, 985, 1451, 1606, 1657, 1678, 1679, 1688, 1696, 1699, 1700, 1712, 1713, 1716, 1719, 1720, 1724, 1725, 1726, 1727, 1731, 1732], "account": [4, 33, 42, 1319, 1694, 1698, 1727], "heavili": [4, 1436, 1698, 1701, 1716], "similarli": [4, 6, 41, 42, 667, 801, 895, 950, 1116, 1318, 1353, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1407, 1479, 1537, 1649, 1650, 1651, 1652, 1678, 1701, 1702, 1703, 1709, 1713, 1727], "platform": [4, 7, 8, 12, 20, 27, 28, 32, 941, 942, 953, 1475, 1629, 1685, 1704, 1709, 1710, 1719], "startup": 4, "slower": [4, 12, 20, 606, 631, 821, 822, 823, 924, 931, 1232, 1384, 1701, 1710, 1728], "multi": [4, 26, 35, 690, 729, 748, 781, 801, 857, 895, 1033, 1053, 1068, 1086, 1116, 1119, 1120, 1121, 1122, 1131, 1159, 1161, 1168, 1319, 1353, 1676, 1679, 1698, 1699, 1706, 1710, 1724, 1727, 1730, 1733, 1735], "rerun": [5, 20, 1699], "segment": [5, 739, 834, 1147, 1716], "persist": [5, 15, 40, 895, 1068, 1086, 1116, 1131, 1353, 1706, 1711, 1712], "rng": [5, 17, 714, 752, 1579, 1699, 1710, 1723], "advanc": [5, 13, 17, 18, 26, 1159, 1161, 1163, 1421, 1683, 1690, 1699, 1704, 1708, 1731, 1732], "juggl": 5, "dropout": [5, 42, 895, 1028, 1055, 1056, 1057, 1061, 1068, 1086, 1116, 1122, 1131, 1132, 1159, 1161, 1163, 1179, 1199, 1200, 1201, 1206, 1327, 1328, 1353, 1677, 1685, 1690, 1696, 1699, 1714, 1721], "restor": [5, 23, 40, 42, 43, 826, 965, 981, 1569, 1706, 1711], "moder": 5, "hit": [5, 7, 12, 1319, 1674, 1699], "preserve_rng_st": 5, "checkpoint_sequenti": 5, "omit": [5, 12, 20, 36, 815, 816, 818, 1070, 1130, 1712, 1713, 1724, 1734], "save": [5, 6, 10, 13, 18, 19, 20, 23, 40, 448, 619, 620, 628, 894, 895, 900, 902, 910, 912, 966, 1116, 1319, 1448, 1454, 1457, 1460, 1500, 1519, 1676, 1677, 1686, 1690, 1701, 1706, 1708, 1710, 1716, 1718, 1727, 1732, 1736], "anticip": 5, "belong": [5, 20, 23, 24, 32, 42, 660, 691, 1448, 1674, 1699, 1715, 1738], "use_reentr": 5, "intermedi": [5, 12, 25, 42, 657, 832, 985, 1060, 1159, 1161, 1163, 1205, 1676, 1679, 1699, 1702, 1709, 1737], "entir": [5, 6, 12, 17, 20, 26, 36, 42, 592, 637, 638, 848, 1055, 1056, 1057, 1061, 1079, 1080, 1081, 1088, 1199, 1200, 1201, 1206, 1395, 1397, 1419, 1679, 1691, 1696, 1699, 1701, 1702, 1705, 1706, 1713, 1716, 1719, 1724, 1726], "recomput": [5, 628, 1168, 1224, 1419, 1715], "no_grad": [5, 785, 870, 895, 1059, 1116, 1122, 1163, 1540, 1694, 1696, 1706, 1735], "manner": [5, 7, 26, 465, 630, 632, 1690, 1691, 1692, 1697], "gradient": [5, 10, 17, 18, 20, 23, 24, 40, 105, 176, 177, 245, 290, 440, 447, 465, 590, 591, 610, 619, 621, 622, 624, 625, 626, 627, 628, 630, 631, 632, 633, 634, 635, 636, 637, 638, 647, 673, 785, 837, 870, 895, 930, 931, 934, 941, 942, 958, 967, 985, 987, 994, 997, 999, 1032, 1039, 1047, 1048, 1049, 1052, 1053, 1059, 1060, 1070, 1084, 1085, 1116, 1123, 1147, 1196, 1197, 1204, 1205, 1215, 1224, 1232, 1234, 1235, 1248, 1281, 1282, 1283, 1318, 1319, 1320, 1381, 1382, 1384, 1389, 1420, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1450, 1451, 1587, 1610, 1629, 1667, 1676, 1677, 1690, 1694, 1699, 1700, 1701, 1702, 1703, 1706, 1709, 1715, 1724, 1725, 1727], "calcul": [5, 17, 20, 32, 664, 686, 768, 772, 785, 886, 892, 950, 972, 973, 975, 1029, 1030, 1031, 1034, 1035, 1036, 1039, 1047, 1048, 1049, 1063, 1070, 1071, 1079, 1080, 1081, 1088, 1155, 1167, 1168, 1180, 1181, 1182, 1210, 1213, 1224, 1253, 1361, 1362, 1385, 1396, 1416, 1420, 1422, 1452, 1484, 1487, 1501, 1502, 1506, 1564, 1587, 1623, 1624, 1633, 1650, 1652, 1662, 1663, 1696, 1697, 1700, 1703, 1709, 1712, 1719], "consist": [5, 17, 20, 24, 35, 36, 40, 42, 637, 667, 668, 895, 924, 930, 931, 933, 935, 936, 937, 938, 962, 964, 1116, 1163, 1386, 1389, 1475, 1629, 1633, 1676, 1679, 1690, 1691, 1706, 1710, 1713, 1715, 1727], "ex": [5, 27, 1319, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446, 1687], "anyth": [5, 6, 25, 28, 41, 906, 1505, 1508, 1676, 1683, 1706, 1716], "detect": [5, 12, 17, 20, 21, 26, 28, 40, 630, 631, 632, 633, 634, 635, 899, 1319, 1660, 1688, 1691, 1699, 1703, 1713, 1716, 1724], "circumv": 5, "least": [5, 7, 18, 24, 34, 35, 40, 215, 357, 592, 647, 768, 770, 771, 781, 822, 823, 848, 856, 857, 892, 917, 940, 967, 983, 990, 1011, 1024, 1319, 1411, 1674, 1679, 1690, 1694, 1696, 1697, 1699, 1702, 1717, 1720, 1726, 1727, 1728, 1729, 1734], "know": [5, 6, 7, 12, 21, 25, 42, 439, 626, 631, 832, 905, 1319, 1676, 1679, 1695, 1696, 1699, 1703, 1713, 1716, 1724, 1725, 1726], "lstm": [5, 1087, 1356, 1677, 1699, 1713, 1714, 1719, 1721, 1722, 1732], "hidden": [5, 1068, 1069, 1086, 1087, 1131, 1133, 1320, 1353, 1699, 1732], "correctli": [5, 17, 19, 20, 35, 439, 895, 910, 1116, 1232, 1676, 1678, 1679, 1687, 1690, 1695, 1696, 1701, 1708, 1710, 1719, 1724], "entrant": 5, "futur": [5, 7, 8, 18, 20, 26, 35, 36, 40, 42, 245, 276, 469, 582, 628, 666, 667, 679, 680, 687, 688, 689, 690, 691, 717, 718, 725, 726, 728, 780, 841, 895, 898, 904, 905, 908, 913, 925, 936, 938, 939, 940, 943, 956, 983, 985, 986, 993, 998, 1056, 1082, 1116, 1122, 1215, 1237, 1238, 1239, 1315, 1319, 1381, 1416, 1422, 1436, 1475, 1540, 1558, 1625, 1629, 1633, 1648, 1675, 1676, 1677, 1678, 1679, 1680, 1685, 1687, 1690, 1691, 1698, 1699, 1701, 1711, 1713, 1715, 1716, 1717, 1718, 1719, 1721, 1724, 1727, 1733, 1734], "sequenti": [5, 17, 23, 895, 904, 1062, 1116, 1155, 1166, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1386, 1400, 1460, 1667, 1676, 1688, 1699, 1706, 1713, 1717, 1719, 1737], "compris": [5, 36], "chunk": [5, 17, 20, 663, 700, 1053, 1319, 1617, 1676, 1677, 1689, 1714, 1717, 1724, 1731], "input_var": [5, 1053], "acceler": [6, 18, 1034, 1035, 1036, 1155, 1430, 1538, 1704], "packag": [6, 7, 10, 14, 18, 24, 41, 1213, 1319, 1674, 1675, 1701, 1706, 1715, 1724, 1732, 1735], "deep": [6, 8, 42, 1034, 1035, 1036, 1058, 1155, 1446, 1675, 1694, 1706, 1719], "neural": [6, 7, 13, 42, 1028, 1039, 1054, 1061, 1070, 1082, 1115, 1116, 1123, 1128, 1129, 1143, 1145, 1159, 1161, 1163, 1243, 1265, 1387, 1444, 1452, 1458, 1676, 1678, 1679, 1694, 1699, 1709, 1713], "tape": 6, "system": [6, 7, 12, 13, 14, 19, 36, 42, 669, 902, 926, 937, 938, 939, 940, 941, 942, 944, 955, 956, 957, 961, 966, 986, 1159, 1161, 1163, 1319, 1387, 1389, 1586, 1648, 1680, 1687, 1696, 1698, 1699, 1705, 1706, 1712, 1716, 1724], "organ": [6, 1700, 1705, 1716], "govern": [6, 7, 19, 1675], "technic": [6, 8, 35, 42, 895, 1116, 1318, 1696, 1702, 1716], "md": [6, 42, 1538, 1716], "healthi": [6, 26, 35], "team": [6, 20, 1711, 1717], "commun": [6, 7, 8, 21, 23, 26, 35, 37, 40, 1319, 1696, 1700, 1724, 1725], "project": [6, 19, 781, 998, 1086, 1122, 1389, 1465, 1674, 1704], "ve": [6, 42, 899, 1688, 1696, 1725, 1732], "come": [6, 7, 8, 17, 24, 25, 32, 35, 781, 832, 966, 1055, 1056, 1057, 1061, 1082, 1683, 1685, 1705, 1716, 1724, 1726], "peopl": [6, 1696, 1719], "scratch": [6, 1696], "itch": 6, "acquaint": 6, "tip": [6, 1699], "tracker": [6, 967], "confirm": [6, 1674, 1676, 1701, 1713, 1724, 1726], "contributor": [6, 7, 8], "tend": [6, 632, 1660], "bootcamp": 6, "1hr": 6, "although": [6, 7, 24, 42, 691, 1047, 1048, 1049, 1116, 1124, 1319, 1675, 1679, 1695, 1701, 1717, 1719], "join": [6, 18, 20, 23, 35, 36, 41, 42, 1319, 1674, 1675, 1680, 1688, 1696, 1700, 1708, 1733], "dev": [6, 9, 27, 32], "interest": [6, 8, 1667, 1696, 1703, 1706], "happi": 6, "research": [6, 7, 8, 1319, 1674, 1696, 1703, 1711], "partner": 6, "speed": [6, 7, 12, 23, 886, 899, 904, 958, 1024, 1629, 1696, 1698, 1699, 1700, 1701, 1702, 1704, 1709, 1719, 1724], "reach": [6, 7, 8, 17, 18, 20, 21, 26, 35, 967, 1319, 1449, 1452, 1455, 1456, 1708, 1717, 1720, 1724], "design": [6, 8, 17, 24, 32, 35, 637, 638, 895, 914, 1116, 1636, 1667, 1674, 1675, 1687, 1699, 1701, 1704, 1706, 1716], "comment": [6, 42, 1679, 1680, 1701, 1732], "crack": 6, "usual": [6, 12, 17, 18, 35, 36, 42, 434, 622, 630, 632, 636, 1055, 1056, 1057, 1061, 1076, 1079, 1080, 1081, 1082, 1314, 1319, 1523, 1667, 1676, 1679, 1691, 1695, 1698, 1699, 1702, 1705, 1720, 1722, 1724, 1732, 1738], "idea": [6, 781, 1024, 1319, 1699, 1705, 1725], "big": [6, 1433, 1434, 1437, 1443, 1444, 1611, 1612, 1613, 1614, 1615, 1616, 1719], "post": [6, 7, 21, 23, 895, 1116, 1536, 1540, 1683, 1702, 1712], "standard": [6, 12, 18, 24, 28, 29, 33, 42, 307, 331, 541, 801, 1028, 1034, 1035, 1036, 1071, 1079, 1080, 1081, 1082, 1088, 1155, 1161, 1163, 1423, 1465, 1555, 1623, 1624, 1678, 1680, 1694, 1698, 1708, 1709, 1713, 1716, 1728], "lot": [6, 12, 17, 1688, 1696, 1699, 1703, 1708, 1716, 1717, 1723, 1725, 1727, 1732], "boil": 6, "mostli": [6, 24, 893, 1319, 1699, 1738], "evid": 6, "peer": [6, 20, 23, 35, 40, 695, 1319, 1699, 1724], "paper": [6, 8, 18, 19, 24, 1024, 1028, 1034, 1035, 1036, 1038, 1047, 1048, 1049, 1054, 1055, 1056, 1057, 1058, 1061, 1064, 1065, 1071, 1074, 1079, 1080, 1081, 1088, 1122, 1128, 1129, 1134, 1143, 1147, 1155, 1159, 1161, 1163, 1164, 1165, 1208, 1209, 1218, 1433, 1434, 1445, 1452, 1458, 1703, 1717], "framework": [6, 7, 8, 24, 32, 41, 693, 1319, 1384, 1446, 1590, 1675, 1707, 1717, 1719, 1725, 1726], "bit": [6, 42, 43, 285, 411, 649, 652, 679, 680, 834, 875, 1354, 1356, 1358, 1501, 1502, 1503, 1504, 1507, 1509, 1537, 1566, 1567, 1579, 1596, 1699, 1706, 1709, 1712, 1719, 1722, 1723, 1727, 1730, 1733, 1739], "accept": [6, 8, 20, 40, 105, 465, 619, 620, 621, 622, 627, 636, 666, 725, 728, 833, 857, 895, 899, 1052, 1116, 1123, 1144, 1396, 1410, 1411, 1415, 1487, 1582, 1679, 1690, 1699, 1701, 1713, 1715, 1724, 1730, 1732], "overwhelm": [6, 1724], "newli": [6, 40, 42, 795, 796, 1059, 1060, 1544, 1545, 1683], "publish": [6, 8, 27, 32, 35, 967], "ground": [6, 8, 1052, 1196, 1732], "break": [6, 24, 40, 42, 622, 895, 940, 1116, 1571, 1590, 1675, 1680, 1715], "becom": [6, 7, 8, 17, 20, 24, 42, 245, 606, 848, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1068, 1086, 1101, 1121, 1131, 1144, 1196, 1213, 1314, 1353, 1450, 1603, 1633, 1646, 1696, 1700, 1713, 1716, 1718, 1724], "fall": [6, 12, 637, 857, 908, 966, 1077, 1147, 1222, 1266, 1674, 1713, 1719], "pr": [6, 1465, 1630], "refactor": [6, 42, 1712, 1719], "coordin": [6, 20, 24, 26, 535, 538, 614, 848, 857, 998, 1469, 1614, 1650, 1652, 1696, 1727, 1732], "pace": 6, "master": [6, 38, 1159, 1674, 1706, 1724], "fast": [6, 7, 17, 20, 637, 1058, 1079, 1080, 1081, 1147, 1163, 1458, 1549, 1571, 1585, 1698, 1699, 1701, 1704, 1724, 1727, 1730, 1731], "definit": [6, 7, 17, 21, 24, 31, 42, 667, 668, 669, 686, 725, 829, 915, 924, 925, 967, 1082, 1225, 1269, 1422, 1562, 1646, 1674, 1676, 1678, 1680, 1695, 1696, 1701, 1703, 1716, 1719, 1732, 1734], "fundament": [6, 1678, 1706, 1724], "cut": 6, "guidanc": [6, 8, 13, 1717], "stage": [6, 18, 23, 32, 40, 41, 1675, 1691, 1717, 1726], "piec": [6, 1691, 1725], "advic": 6, "readi": [6, 12, 41, 645, 654, 852, 853, 1319, 1540, 1541, 1676, 1700, 1724, 1725], "wip": [6, 1540], "ignor": [6, 20, 23, 27, 33, 40, 42, 105, 451, 494, 581, 584, 585, 586, 604, 622, 636, 644, 666, 686, 729, 730, 748, 749, 802, 804, 812, 813, 814, 840, 855, 895, 906, 912, 915, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 941, 942, 943, 944, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 963, 964, 987, 1012, 1013, 1014, 1029, 1030, 1031, 1032, 1033, 1050, 1052, 1060, 1068, 1070, 1076, 1082, 1083, 1086, 1107, 1108, 1109, 1110, 1111, 1116, 1119, 1120, 1121, 1122, 1123, 1130, 1131, 1147, 1148, 1159, 1164, 1185, 1186, 1196, 1205, 1225, 1248, 1256, 1319, 1328, 1422, 1452, 1459, 1463, 1537, 1590, 1607, 1608, 1625, 1629, 1648, 1676, 1679, 1680, 1690, 1696, 1701, 1713, 1734], "ci": 6, "folk": 6, "who": [6, 7, 8, 10, 35, 1696, 1716], "regularli": 6, "queue": [6, 26, 37, 1688, 1732], "everyth": [6, 17, 24, 1676, 1688, 1716], "happen": [6, 8, 20, 23, 24, 26, 28, 35, 40, 42, 559, 1155, 1319, 1384, 1449, 1455, 1456, 1461, 1481, 1499, 1629, 1675, 1687, 1688, 1696, 1699, 1700, 1701, 1702, 1707, 1708, 1712, 1713, 1719, 1724, 1731], "subsystem": [6, 10], "patch": [6, 1063, 1167], "feel": [6, 1691], "person": [6, 8], "ll": [6, 42, 667, 728, 924, 983, 1068, 1069, 1086, 1087, 1353, 1502, 1503, 1696, 1699, 1701, 1708, 1713, 1719, 1725], "round": [6, 17, 20, 460, 595, 682, 684, 775, 802, 803, 804, 808, 812, 813, 814, 829, 940, 953, 1168, 1224, 1475, 1476, 1484, 1487, 1502, 1562, 1599, 1677, 1679, 1689, 1699, 1714, 1719, 1722, 1727, 1728], "trip": [6, 42, 802, 803, 804, 808, 812, 813, 814], "noth": [6, 12, 26, 42, 719, 1389, 1460, 1676, 1678, 1726], "els": [6, 17, 20, 24, 26, 27, 35, 42, 534, 555, 647, 906, 912, 1082, 1155, 1250, 1353, 1433, 1434, 1443, 1444, 1445, 1446, 1566, 1567, 1633, 1676, 1678, 1680, 1681, 1688, 1699, 1701, 1706, 1707, 1713, 1715, 1716, 1729], "accompani": 6, "solut": [6, 7, 939, 940, 944, 952, 955, 957, 961, 983, 1032, 1319, 1648, 1676, 1677, 1694, 1695, 1702, 1708], "think": [6, 8, 42, 1676, 1678, 1696, 1726], "confid": [6, 1732], "ahead": [6, 1675, 1719], "search": [6, 10, 18, 660, 1074, 1218, 1319, 1501, 1549, 1578, 1676, 1689, 1690, 1716], "repo": [6, 8, 1452, 1674, 1712], "unabl": [6, 1713, 1715], "similar": [6, 8, 17, 20, 24, 32, 41, 42, 445, 467, 607, 657, 662, 675, 827, 828, 895, 1050, 1051, 1063, 1076, 1079, 1080, 1081, 1116, 1164, 1195, 1296, 1297, 1298, 1299, 1300, 1301, 1304, 1323, 1324, 1325, 1326, 1338, 1339, 1349, 1357, 1410, 1423, 1469, 1487, 1564, 1571, 1606, 1636, 1642, 1658, 1678, 1679, 1688, 1689, 1696, 1698, 1701, 1703, 1713, 1716, 1717, 1719, 1724, 1725, 1727, 1728, 1733, 1739], "reproduc": [6, 17, 268, 276, 467, 469, 647, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1205, 1213, 1224, 1251, 1281, 1282, 1283, 1314, 1660, 1674, 1675, 1715, 1716], "problemat": [6, 17, 42, 1676, 1709, 1720], "insight": 6, "individu": [6, 8, 12, 17, 18, 20, 23, 40, 42, 197, 667, 747, 799, 817, 895, 1039, 1116, 1155, 1319, 1520, 1521, 1679, 1689, 1695, 1701, 1705, 1709, 1710, 1713, 1722, 1724, 1734], "intent": [6, 33, 35, 1582, 1716], "lock": [6, 17, 19, 20, 23, 24, 1696, 1699, 1708, 1716, 1725], "strike": 6, "convers": [6, 411, 531, 661, 880, 1410, 1680, 1704, 1713, 1719, 1720], "medium": [6, 1585], "prioriti": [6, 9, 20, 691, 1678], "entranc": [6, 1699], "great": [6, 1696, 1703], "deal": [6, 7, 26, 37, 1641, 1688, 1702, 1724], "welcom": 6, "aim": 6, "rare": [6, 1695, 1713, 1738], "typo": 6, "send": [6, 17, 20, 26, 721, 1314, 1319, 1688, 1700, 1708, 1712, 1718, 1724, 1725, 1726, 1735, 1737], "consider": [6, 614, 892, 1060, 1319, 1679, 1698], "forum": [6, 8, 1702, 1708], "attent": [6, 1122, 1159, 1161, 1163, 1328, 1712, 1731], "share": [6, 9, 12, 17, 19, 21, 23, 24, 25, 35, 36, 40, 176, 266, 295, 388, 411, 436, 472, 475, 568, 609, 610, 626, 637, 638, 688, 689, 717, 721, 832, 833, 834, 865, 942, 1016, 1053, 1319, 1387, 1423, 1560, 1574, 1620, 1639, 1645, 1659, 1677, 1695, 1696, 1698, 1708, 1711, 1712, 1713, 1724, 1727, 1729, 1731, 1736], "resolv": [6, 7, 8, 24, 42, 895, 1047, 1048, 1049, 1063, 1113, 1116, 1678, 1679, 1680, 1712, 1716, 1729, 1738], "challeng": [6, 20, 1725], "feedback": [6, 18, 40, 1319, 1667, 1675], "direct": [6, 8, 10, 20, 822, 823, 895, 1068, 1086, 1116, 1131, 1353, 1419, 1445, 1465, 1549, 1570, 1696, 1699, 1701, 1706, 1724], "yourself": [6, 688, 1701, 1706, 1708, 1738], "problem": [6, 17, 20, 35, 910, 940, 952, 967, 983, 1052, 1123, 1178, 1688, 1696, 1699, 1702, 1703, 1708, 1712, 1717, 1719, 1720, 1726], "area": [6, 8, 1224, 1706, 1728], "appreci": 6, "strive": 6, "respond": [6, 20], "quickli": [6, 7, 18, 35], "ey": [6, 24, 146, 163, 668, 915, 924, 935, 946, 949, 952, 953, 960, 961, 993, 1384, 1475, 1607, 1667, 1677, 1681, 1701, 1714], "everyon": [6, 26, 35], "touch": [6, 33, 42], "versu": [6, 1120], "write": [6, 7, 8, 20, 26, 28, 32, 33, 34, 35, 40, 209, 465, 592, 658, 833, 872, 905, 925, 936, 937, 938, 942, 943, 956, 1280, 1574, 1648, 1660, 1667, 1678, 1687, 1690, 1699, 1702, 1703, 1715, 1716, 1727, 1732], "blog": [6, 7, 1683, 1719], "around": [6, 8, 10, 20, 24, 40, 41, 42, 105, 575, 622, 636, 688, 689, 690, 691, 756, 827, 828, 895, 1319, 1571, 1676, 1688, 1696, 1699, 1713, 1724], "internet": 6, "grow": [6, 7, 42, 1727], "market": [6, 8], "benefit": [6, 7, 20, 42, 1459, 1688, 1699, 1719], "opinion": [6, 7], "isn": [6, 17, 42, 411, 892, 1696, 1699, 1701, 1724, 1734], "categor": [6, 28, 1215, 1680, 1720, 1724], "aspect": [6, 20, 42, 1701, 1706], "seem": [6, 1713], "unusu": 6, "claim": [6, 1458, 1703], "wast": [6, 1699], "someon": [6, 8, 893, 1690], "too": [6, 8, 12, 18, 35, 42, 940, 958, 1013, 1039, 1052, 1116, 1197, 1320, 1679, 1698, 1702, 1703, 1708, 1709, 1710, 1712, 1716, 1717, 1726, 1727], "advisori": 6, "fashion": [6, 17, 20, 37, 467, 972, 1400, 1676], "dai": 6, "rough": [6, 8], "consensu": [6, 8], "corpor": 6, "wrote": [6, 7], "implicitli": [6, 20, 28, 40, 42, 763, 840, 848, 910, 911, 966, 1029, 1030, 1031, 1109, 1110, 1111, 1582, 1646, 1676, 1678, 1679, 1696], "lifetim": [6, 1724], "immedi": [6, 7, 8, 35, 36, 40, 41, 895, 898, 1116, 1679, 1706, 1711, 1724, 1726], "sai": [6, 42, 448, 895, 1116, 1676, 1695, 1696, 1702, 1716, 1725, 1726, 1727], "bugfix": 6, "Or": [6, 26, 42, 671, 1707, 1713, 1727], "motiv": [6, 7, 42, 1328, 1706, 1725], "ye": [6, 1713, 1727], "knuth": 6, "bewar": 6, "mere": 6, "proven": [6, 1054, 1319], "ok": [6, 19, 28, 33, 900, 1726], "sometim": [6, 42, 633, 910, 1063, 1167, 1191, 1192, 1193, 1389, 1675, 1679, 1688, 1696, 1699, 1702, 1706, 1708, 1716, 1730, 1733, 1738], "obvious": 6, "broken": [6, 17, 739, 1713], "contrari": [6, 1698], "accident": 6, "put": [6, 8, 17, 26, 40, 41, 42, 274, 801, 966, 1071, 1452, 1674, 1677, 1688, 1699, 1708, 1716, 1725, 1726], "Is": [6, 178, 287, 291, 293, 297, 298, 447, 456, 1122, 1159, 1161, 1163, 1328], "difficulti": [6, 1694], "scale": [6, 17, 24, 26, 34, 36, 40, 52, 426, 428, 568, 580, 584, 585, 586, 644, 795, 796, 799, 817, 981, 1028, 1054, 1059, 1060, 1061, 1077, 1088, 1143, 1168, 1169, 1170, 1204, 1205, 1206, 1222, 1224, 1263, 1268, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1352, 1363, 1365, 1366, 1367, 1368, 1370, 1373, 1374, 1431, 1452, 1484, 1487, 1501, 1502, 1503, 1504, 1507, 1544, 1545, 1546, 1547, 1548, 1607, 1608, 1626, 1675, 1677, 1690, 1694, 1699, 1702, 1706, 1719, 1720, 1721, 1722, 1728], "nonlinearli": 6, "sign": [6, 24, 296, 480, 614, 681, 768, 817, 829, 834, 928, 953, 954, 975, 1108, 1445, 1562, 1593, 1596, 1677, 1689, 1714, 1722, 1727, 1730, 1733, 1734], "split": [6, 17, 20, 42, 568, 663, 670, 739, 778, 858, 1053, 1067, 1068, 1086, 1122, 1131, 1188, 1189, 1190, 1191, 1192, 1193, 1212, 1319, 1365, 1366, 1367, 1640, 1668, 1676, 1677, 1689, 1699, 1714, 1716, 1717, 1719, 1724, 1727, 1731], "shippabl": 6, "complet": [6, 12, 17, 20, 26, 27, 33, 35, 37, 41, 439, 689, 690, 691, 757, 898, 906, 908, 913, 925, 953, 1178, 1319, 1386, 1417, 1475, 1675, 1678, 1679, 1680, 1688, 1695, 1696, 1699, 1704, 1710, 1716, 1717, 1724, 1725], "subtl": [6, 1079, 1080, 1081, 1701], "nuanc": 6, "extra": [6, 12, 17, 18, 20, 23, 24, 40, 42, 781, 895, 902, 905, 940, 966, 1116, 1123, 1384, 1429, 1625, 1633, 1667, 1678, 1690, 1696, 1698, 1700, 1701, 1702, 1705, 1716, 1718, 1727, 1734], "understand": [6, 7, 8, 20, 26, 27, 952, 1683, 1694, 1696, 1699, 1704, 1711, 1718, 1732], "hack": 6, "answer": [6, 9, 42, 1033, 1402, 1485, 1506], "regress": [6, 1032, 1710], "scrutini": 6, "undertak": 6, "rest": [6, 17, 18, 36, 42, 834, 960, 961, 1499, 1640, 1690, 1706, 1710, 1716, 1717, 1719, 1724], "stai": [6, 23, 94, 1053, 1699, 1708, 1719, 1724], "chanc": [6, 24], "unrel": [6, 1695, 1701, 1716], "aid": [6, 42, 1696], "troubleshoot": [6, 20], "mayb": 6, "rebas": 6, "latest": [6, 20, 23, 24, 1396, 1674, 1704, 1713], "statu": [6, 8, 26, 985, 1675, 1680, 1688, 1719], "hud": 6, "risk": [6, 7, 40, 1386, 1389, 1667], "configur": [6, 11, 17, 18, 19, 20, 26, 27, 32, 35, 36, 37, 40, 739, 1319, 1410, 1477, 1478, 1482, 1499, 1505, 1508, 1520, 1521, 1522, 1537, 1538, 1539, 1540, 1541, 1586, 1660, 1687, 1699, 1700, 1710, 1712, 1716, 1722, 1724, 1732, 1734], "riski": 6, "had": [6, 42, 910, 1314, 1642, 1696], "beforehand": [6, 41], "hei": 6, "commit": [6, 8, 12, 1674, 1675, 1709, 1710], "my": [6, 17, 1053, 1705, 1713], "branch": [6, 42, 1674, 1678, 1679, 1699], "member": [6, 8, 17, 20, 26, 35, 36, 42, 895, 1070, 1116, 1210, 1676, 1678, 1679, 1687, 1702, 1718, 1724, 1734, 1735], "sphinx": 6, "folder": [6, 8, 12, 17, 19, 42, 1674, 1716, 1732], "io": [6, 17, 781, 902, 905, 966, 1086, 1087, 1574, 1712, 1719], "tree": [6, 28, 1116, 1159, 1716, 1726], "doxygen": 6, "special": [6, 10, 28, 42, 637, 773, 788, 789, 790, 792, 793, 802, 804, 862, 863, 864, 908, 966, 980, 1010, 1053, 1122, 1163, 1320, 1321, 1322, 1334, 1335, 1336, 1421, 1470, 1505, 1508, 1594, 1598, 1671, 1675, 1680, 1690, 1696, 1699, 1701, 1703, 1705, 1713, 1716, 1719, 1731, 1732], "server": [6, 17, 20, 36, 899, 1699, 1716, 1719, 1724], "cppdoc": [6, 13], "cpp": [6, 12, 19, 20, 1007, 1700], "accomplish": [6, 1706], "holist": 6, "concept": [6, 19, 42, 1683, 1706, 1730], "galleri": 6, "restructur": [6, 1716], "text": [6, 24, 108, 109, 128, 560, 568, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 589, 593, 595, 611, 612, 613, 614, 615, 644, 645, 646, 649, 652, 654, 656, 665, 671, 680, 681, 683, 684, 686, 775, 780, 795, 796, 825, 826, 830, 831, 839, 851, 852, 853, 854, 861, 884, 892, 915, 918, 919, 920, 923, 924, 931, 934, 940, 944, 949, 952, 958, 965, 974, 981, 982, 983, 984, 985, 1006, 1007, 1017, 1018, 1021, 1022, 1023, 1025, 1026, 1027, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1055, 1056, 1057, 1058, 1059, 1061, 1062, 1063, 1064, 1065, 1066, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1101, 1102, 1103, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1119, 1120, 1121, 1122, 1123, 1124, 1128, 1129, 1130, 1131, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1145, 1146, 1147, 1148, 1149, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1180, 1181, 1182, 1184, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1195, 1196, 1199, 1200, 1201, 1206, 1209, 1211, 1212, 1213, 1217, 1218, 1228, 1233, 1237, 1238, 1239, 1243, 1248, 1251, 1256, 1257, 1259, 1263, 1264, 1265, 1268, 1269, 1270, 1272, 1273, 1274, 1338, 1339, 1349, 1351, 1353, 1357, 1361, 1362, 1363, 1365, 1366, 1367, 1373, 1377, 1382, 1384, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446, 1452, 1468, 1469, 1472, 1475, 1502, 1503, 1555, 1558, 1561, 1573, 1593, 1595, 1597, 1599, 1607, 1608, 1618, 1625, 1626, 1629, 1633, 1637, 1638, 1670, 1691, 1694, 1703, 1713, 1716, 1722, 1728, 1732, 1734], "rst": 6, "rebuild": [6, 18, 1714], "circleci": 6, "shard": [6, 17, 23, 40], "worker": [6, 12, 17, 18, 20, 21, 23, 26, 27, 28, 29, 35, 37, 38, 40, 1319, 1679, 1710, 1717, 1718, 1724, 1725, 1726], "40": [6, 848, 967, 1037, 1079, 1384, 1385, 1408, 1409, 1416, 1419, 1636], "minut": [6, 9, 20, 1732], "netlifi": 6, "noplot": 6, "render": [6, 20, 1732], "notebook": 6, "rebuilt": [6, 18, 23], "deploi": [6, 26, 35, 1675, 1705, 1711, 1716], "action": [6, 20, 24, 26, 29, 42, 1699, 1716, 1718, 1726], "document": [7, 9, 17, 19, 20, 40, 42, 603, 604, 605, 606, 661, 689, 690, 691, 739, 840, 843, 844, 876, 883, 895, 1014, 1024, 1059, 1060, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1116, 1323, 1324, 1325, 1326, 1338, 1339, 1349, 1354, 1355, 1356, 1357, 1358, 1386, 1395, 1404, 1422, 1474, 1538, 1568, 1584, 1660, 1674, 1676, 1678, 1679, 1688, 1689, 1690, 1692, 1695, 1701, 1702, 1706, 1710, 1711, 1713, 1714, 1715, 1716, 1719, 1720, 1721, 1724, 1731, 1735], "develop": [7, 8, 9, 12, 18, 19, 20, 42, 1667, 1678, 1679, 1701, 1705, 1706, 1710, 1716, 1719, 1720, 1724, 1727], "meant": [7, 21, 35, 37, 1410, 1695, 1724], "rule": [7, 8, 12, 20, 24, 42, 105, 622, 660, 661, 763, 944, 955, 1034, 1035, 1036, 1079, 1080, 1081, 1155, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446, 1539, 1578, 1646, 1676, 1678, 1689, 1696, 1697, 1701, 1703, 1730, 1734], "concern": [7, 17, 1688, 1699, 1713], "disagr": 7, "contribut": [7, 8, 641, 856, 857, 1052, 1059, 1060, 1123, 1196, 1204, 1205, 1248, 1319, 1675, 1717], "maintainership": [7, 8], "escal": [7, 8], "hacker": 7, "poster": 7, "amaz": 7, "ml": 7, "obsess": 7, "soumith": [7, 9], "goe": [7, 42, 834, 1028, 1702], "depth": [7, 8, 743, 744, 908, 1031, 1046, 1049, 1111, 1168, 1224, 1281, 1372, 1378, 1706], "primari": [7, 8, 42, 904, 1680, 1727], "goal": [7, 32, 42, 998, 1696, 1703, 1726], "secondari": 7, "abil": [7, 1574, 1705, 1716], "flexibl": [7, 18, 40, 951, 1319, 1699, 1701, 1706], "abstract": [7, 17, 18, 19, 21, 24, 26, 35, 37, 1391, 1679, 1700, 1719, 1724], "remain": [7, 24, 35, 42, 983, 1004, 1059, 1060, 1204, 1205, 1314, 1319, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1407, 1476, 1565, 1687, 1688, 1695, 1702, 1706], "critic": [7, 35, 1385, 1416, 1687, 1698, 1699], "concret": [7, 24, 38, 42, 1168, 1251, 1281, 1378, 1485, 1506, 1523, 1676, 1679, 1699, 1701, 1708], "jump": [7, 510, 1730], "regim": 7, "ei": 7, "tradeoff": [7, 18, 1719, 1725], "temptat": 7, "impos": [7, 37, 1688, 1695], "strict": [7, 630, 631, 632, 633, 634, 635, 895, 910, 911, 1116, 1716, 1727, 1732, 1734], "upfront": 7, "simplifi": [7, 18, 41, 902, 1106, 1385, 1696, 1703, 1706, 1715, 1725], "worth": [7, 8, 17, 18, 38, 1674, 1731], "friction": 7, "compel": 7, "rel": [7, 8, 12, 18, 24, 42, 589, 606, 637, 638, 686, 884, 949, 952, 1164, 1165, 1178, 1213, 1459, 1687, 1698, 1699, 1705, 1716, 1734], "narrow": [7, 388, 964, 1677, 1679, 1689, 1714, 1731], "subproblem": 7, "fragment": [7, 708, 1699], "ecosystem": [7, 1705, 1707], "limit": [7, 8, 17, 40, 751, 908, 1039, 1059, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1319, 1400, 1675, 1679, 1688, 1690, 1696, 1699, 1700, 1706, 1709, 1710, 1711, 1716, 1719, 1722, 1724, 1725, 1734], "incomprehens": 7, "seamlessli": [7, 1691], "softwar": [7, 930, 931, 958, 1660, 1699, 1704], "experi": [7, 8, 10, 18, 1145, 1265, 1319, 1667, 1701, 1732], "rich": [7, 1679], "denomin": [7, 582, 1034, 1035, 1036, 1071, 1079, 1080, 1081, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1155, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1447, 1546], "subset": [7, 17, 20, 23, 36, 40, 906, 1676, 1678, 1679, 1701, 1713, 1722], "borrow": 7, "zen": 7, "implicit": [7, 840, 848, 1029, 1030, 1031, 1044, 1045, 1046, 1047, 1048, 1049, 1063, 1109, 1110, 1111, 1167, 1180, 1181, 1182, 1188, 1189, 1190, 1237, 1238, 1239, 1361, 1362, 1365, 1366, 1367, 1463, 1677, 1679, 1680, 1713, 1716, 1731], "concis": [7, 28, 1724], "interchang": [7, 24, 1444, 1678, 1704], "everydai": 7, "english": 7, "movement": [7, 1731], "worri": [7, 1724], "placement": [7, 26, 1314, 1538, 1719, 1724], "favor": [7, 20, 667, 750, 754, 780, 895, 949, 952, 983, 985, 986, 993, 1075, 1116, 1169, 1170, 1281, 1282, 1283, 1315, 1378, 1379, 1380, 1475, 1629, 1633, 1648], "practition": 7, "debugg": [7, 900, 1703], "get": [7, 10, 12, 17, 20, 21, 35, 36, 37, 38, 40, 41, 42, 43, 105, 290, 581, 622, 625, 660, 710, 711, 712, 729, 767, 842, 870, 910, 962, 1059, 1060, 1084, 1085, 1112, 1113, 1114, 1126, 1143, 1319, 1320, 1327, 1385, 1411, 1416, 1447, 1477, 1478, 1563, 1578, 1674, 1676, 1679, 1687, 1688, 1689, 1696, 1699, 1701, 1702, 1703, 1705, 1706, 1707, 1716, 1719, 1724, 1726, 1727, 1731, 1732, 1733, 1738], "plug": 7, "ir": [7, 42, 898, 899, 1068, 1069, 1353, 1676, 1679, 1713], "classic": [7, 1696], "sort": [7, 23, 26, 42, 542, 561, 606, 607, 627, 781, 855, 1005, 1024, 1411, 1412, 1421, 1476, 1578, 1643, 1657, 1677, 1679, 1701, 1702, 1714, 1727], "distribut": [7, 10, 17, 18, 21, 26, 27, 28, 29, 32, 33, 34, 35, 37, 38, 40, 41, 128, 213, 241, 331, 407, 434, 560, 590, 591, 646, 755, 1007, 1024, 1028, 1052, 1053, 1054, 1055, 1056, 1057, 1061, 1066, 1070, 1082, 1130, 1134, 1155, 1196, 1198, 1199, 1200, 1201, 1206, 1210, 1211, 1215, 1225, 1256, 1319, 1423, 1468, 1501, 1549, 1551, 1552, 1553, 1554, 1555, 1556, 1675, 1679, 1690, 1694, 1695, 1699, 1717, 1718, 1720, 1726, 1728, 1732, 1735], "tldr": 7, "resourc": [7, 12, 17, 26, 31, 35, 42, 1679, 1688, 1727], "characterist": [7, 1630, 1706], "uniformli": [7, 24, 1553, 1554, 1734], "leak": [7, 622, 628, 1679, 1688, 1696], "smart": [7, 1701, 1716, 1724], "featur": [7, 8, 10, 13, 19, 20, 23, 36, 40, 41, 630, 632, 636, 755, 906, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1034, 1049, 1054, 1055, 1056, 1057, 1061, 1064, 1065, 1068, 1069, 1079, 1086, 1087, 1122, 1131, 1133, 1150, 1159, 1161, 1163, 1164, 1165, 1166, 1181, 1182, 1199, 1200, 1201, 1206, 1208, 1209, 1319, 1353, 1361, 1362, 1465, 1660, 1675, 1676, 1678, 1679, 1680, 1683, 1690, 1691, 1701, 1702, 1703, 1710, 1713, 1718, 1719, 1724, 1727, 1732], "anywai": [7, 1696], "obviou": [7, 1702, 1726], "extens": [7, 12, 20, 24, 966, 967, 1574, 1593, 1691, 1695, 1711, 1716, 1727], "unavoid": 7, "latenc": [7, 32, 1698, 1699], "caveat": [7, 1314, 1415, 1688, 1699, 1706, 1711], "valuabl": 7, "certainli": 7, "heterogen": [7, 1678], "cluster": [7, 34, 35, 36, 1024, 1732], "focus": [7, 1678, 1679, 1701], "beaten": 7, "space": [7, 8, 17, 24, 763, 799, 801, 803, 804, 810, 817, 848, 857, 910, 911, 965, 981, 1024, 1044, 1045, 1046, 1047, 1048, 1049, 1063, 1082, 1092, 1093, 1094, 1095, 1096, 1097, 1110, 1111, 1167, 1188, 1189, 1190, 1191, 1192, 1193, 1225, 1365, 1366, 1367, 1646, 1677, 1692, 1696, 1703, 1706, 1711], "innov": 7, "ultim": [7, 8, 12, 28, 37], "evidenc": 7, "potenti": [7, 8, 20, 35, 37, 40, 146, 163, 904, 940, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1319, 1660, 1678, 1688, 1696, 1699, 1716, 1731], "began": 7, "bind": [7, 12, 42, 719, 1679, 1680, 1716], "monolith": 7, "deepli": 7, "integr": [7, 17, 29, 109, 646, 648, 649, 650, 651, 652, 653, 686, 763, 856, 895, 918, 962, 963, 1116, 1549, 1561, 1646, 1701, 1705, 1706, 1715, 1717, 1719, 1728, 1730, 1734], "numpi": [7, 17, 19, 401, 445, 588, 589, 594, 607, 609, 610, 626, 775, 777, 778, 781, 799, 820, 821, 822, 823, 827, 828, 833, 858, 925, 926, 936, 947, 949, 950, 951, 952, 953, 958, 959, 962, 964, 998, 1003, 1469, 1561, 1564, 1571, 1582, 1590, 1611, 1612, 1613, 1614, 1615, 1616, 1629, 1631, 1632, 1636, 1639, 1640, 1642, 1664, 1668, 1697, 1701, 1710, 1712, 1716, 1730, 1731, 1732, 1733, 1734, 1739], "scipi": [7, 664, 941, 942, 1253, 1469, 1716, 1728, 1732], "scikit": [7, 1224], "favorit": 7, "cython": 7, "numba": 7, "reinvent": 7, "wheel": [7, 10, 1712], "year": 7, "rewrot": 7, "frontend": [7, 13, 42], "familiar": [7, 13, 42, 738, 1676, 1696, 1716, 1719, 1725, 1726], "perhap": 7, "importantli": 7, "huge": [7, 1630, 1687], "scientif": [7, 1590], "pareto": 7, "close": [7, 13, 20, 35, 42, 660, 721, 884, 930, 931, 957, 958, 985, 1147, 1165, 1578, 1629, 1648, 1687, 1696, 1701, 1716, 1719, 1724, 1732, 1734], "curv": [7, 1732], "torchdynamo": 7, "frame": [7, 892, 1625, 1702, 1732], "capabl": [7, 12, 13, 20, 710, 1549, 1683, 1699, 1704, 1705, 1707, 1735], "torch_funct": [7, 1701], "torch_dispatch": 7, "torch": [7, 8, 10, 13, 15, 18, 21, 23, 26, 27, 28, 29, 32, 33, 35, 37, 38, 40, 43, 623, 688, 689, 690, 691, 692, 705, 707, 717, 785, 870, 893, 894, 895, 909, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1386, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1410, 1420, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1549, 1587, 1675, 1676, 1677, 1678, 1689, 1690, 1695, 1696, 1697, 1698, 1700, 1702, 1703, 1705, 1706, 1707, 1708, 1709, 1710, 1712, 1714, 1717, 1719, 1720, 1721, 1724, 1725, 1726, 1731], "fx": [7, 1340, 1538, 1539, 1540, 1675, 1720, 1721, 1722], "tracer": [7, 910, 1713, 1732, 1737], "functorch": [7, 623, 630, 632, 633, 1667], "anchor": [7, 42, 1164, 1165, 1278, 1279, 1677], "hackabl": 7, "todai": [7, 1719], "open": [7, 8, 12, 24, 35, 639, 831, 902, 966, 1676, 1688, 1691, 1704, 1712, 1713, 1716, 1719, 1724, 1728], "evolv": [7, 1700], "ai": [7, 1713, 1728], "adopt": [8, 20, 1304, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1323, 1324, 1325, 1326, 1338, 1339, 1349, 1354, 1355, 1356, 1357, 1358, 1667], "hierarch": [8, 1732], "pull": [8, 9, 13, 42, 105, 622, 1716], "request": [8, 9, 10, 20, 37, 610, 739, 967, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1674, 1691, 1695, 1696, 1698, 1699, 1716, 1724, 1725, 1726, 1728], "overseen": 8, "catch": [8, 19, 28, 1676, 1696, 1703], "maker": 8, "strong": 8, "toward": [8, 775, 856, 857, 967, 1020, 1319, 1455, 1562, 1570, 1571, 1717], "philosophi": [8, 1675], "beyond": [8, 18, 1052, 1433, 1434, 1443, 1569, 1702, 1706], "encourag": [8, 26, 1691, 1719, 1734], "propos": [8, 1430, 1450, 1451, 1703, 1715, 1725], "review": [8, 9, 18, 1716], "willing": 8, "invest": 8, "anyon": 8, "ownership": [8, 42], "codebas": 8, "strictli": [8, 17, 105, 146, 163, 622, 857, 895, 899, 1116, 1696, 1728], "busi": 8, "compani": 8, "bui": 8, "addition": [8, 17, 18, 20, 24, 40, 105, 465, 568, 622, 899, 958, 1024, 1079, 1080, 1081, 1702, 1735], "membership": [8, 26, 34, 35, 1680], "That": [8, 26, 33, 36, 42, 965, 981, 983, 1660, 1685, 1701, 1702, 1711, 1716, 1724], "seat": 8, "reserv": [8, 32, 739, 1680, 1699, 1706], "emploi": [8, 1446, 1706, 1716, 1717], "repositori": [8, 42, 1674, 1701, 1708], "directori": [8, 12, 19, 20, 33, 1674, 1686, 1705, 1716, 1718, 1732], "approv": 8, "procedur": [8, 910, 911, 967, 1724], "vote": 8, "disput": 8, "made": [8, 23, 36, 42, 628, 638, 1116, 1161, 1163, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1443, 1444, 1445, 1446, 1447, 1559, 1678, 1712, 1716, 1732, 1734, 1738], "public": [8, 9, 19, 1701, 1738], "explan": [8, 28, 895, 1116, 1701, 1706], "relev": [8, 21, 26, 35, 41, 388, 958, 1680, 1695, 1696, 1716, 1719], "resolut": [8, 1128, 1129, 1178, 1213, 1254, 1255, 1646, 1680, 1716, 1739], "conclus": 8, "publicli": [8, 1738], "vision": [8, 904, 1052, 1196, 1674], "roadmap": [8, 9], "parti": [8, 35, 1674, 1676, 1699, 1706, 1716], "particip": [8, 17, 20, 21, 23, 35, 36, 1319, 1725], "codeown": 8, "permiss": [8, 1701], "privileg": 8, "administr": 8, "Their": [8, 772], "articul": 8, "cohes": 8, "negoti": [8, 1724], "contenti": 8, "broad": [8, 1706], "stakehold": 8, "power": [8, 34, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 824, 918, 948, 962, 1084, 1085, 1234, 1235, 1385, 1416, 1430, 1472, 1563, 1661, 1680, 1699], "veto": 8, "admin": 8, "amongst": 8, "commonli": [8, 24, 40, 998, 1679, 1681, 1695, 1696, 1715, 1719, 1730], "merit": 8, "demonstr": [8, 36, 42, 1039, 1676, 1706, 1711, 1717, 1724], "expertis": 8, "align": [8, 18, 781, 848, 950, 1031, 1039, 1052, 1068, 1082, 1086, 1110, 1111, 1131, 1168, 1196, 1197, 1224, 1225, 1281, 1372, 1378, 1384, 1422, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446, 1450, 1502, 1646, 1689, 1696, 1703, 1722, 1728], "continu": [8, 17, 20, 24, 38, 42, 560, 631, 848, 930, 931, 958, 1038, 1039, 1319, 1501, 1680, 1696, 1711, 1718, 1735], "light": [8, 1732], "criteria": [8, 967], "mainten": [8, 35, 36], "emeritu": [8, 9], "inact": [8, 739, 1699], "posit": [8, 17, 24, 42, 43, 357, 424, 495, 637, 645, 647, 654, 667, 668, 669, 797, 798, 799, 800, 801, 809, 811, 815, 817, 834, 852, 853, 887, 890, 895, 898, 924, 925, 936, 938, 949, 952, 953, 967, 988, 1004, 1011, 1033, 1044, 1045, 1046, 1051, 1053, 1060, 1070, 1077, 1116, 1122, 1152, 1159, 1164, 1165, 1178, 1186, 1205, 1210, 1213, 1278, 1279, 1316, 1317, 1318, 1328, 1536, 1542, 1569, 1571, 1607, 1609, 1649, 1650, 1651, 1652, 1659, 1674, 1677, 1689, 1690, 1701, 1703, 1713, 1717, 1723, 1727, 1728, 1734, 1738, 1739], "month": 8, "spam": 8, "desk": 8, "reject": 8, "draw": [8, 17, 109, 646, 1007, 1549, 1732], "nomine": 8, "ask": [8, 20, 1674, 1675, 1703], "item": [8, 17, 541, 1052, 1117, 1126, 1389, 1499, 1590, 1674, 1676, 1677, 1678, 1679, 1689, 1699, 1713, 1714, 1716, 1724, 1732, 1733], "breadth": 8, "testimoni": 8, "neg": [8, 10, 12, 17, 20, 24, 37, 42, 43, 394, 396, 411, 593, 647, 681, 684, 691, 705, 710, 711, 739, 750, 797, 798, 799, 800, 801, 802, 816, 817, 818, 824, 834, 885, 887, 889, 948, 975, 988, 1007, 1011, 1024, 1033, 1061, 1070, 1102, 1109, 1110, 1111, 1119, 1123, 1130, 1147, 1164, 1165, 1206, 1210, 1213, 1215, 1224, 1228, 1237, 1238, 1239, 1248, 1256, 1278, 1279, 1281, 1348, 1373, 1469, 1567, 1571, 1596, 1599, 1608, 1641, 1649, 1650, 1651, 1652, 1659, 1676, 1677, 1689, 1694, 1696, 1713, 1714, 1723, 1727, 1728], "interact": [8, 13, 17, 19, 42, 690, 719, 870, 1680, 1716, 1732], "final": [8, 19, 20, 23, 24, 26, 35, 581, 584, 585, 644, 662, 675, 781, 820, 848, 966, 985, 990, 1068, 1070, 1086, 1131, 1144, 1314, 1353, 1607, 1646, 1676, 1678, 1679, 1680, 1689, 1701, 1703, 1706, 1709, 1711, 1713, 1716, 1725, 1726], "declin": 8, "exclud": [8, 18, 35, 857, 1060, 1205, 1253, 1649, 1650, 1651, 1652, 1716, 1725], "conflict": [8, 18, 36, 1716], "lack": [8, 10, 930, 931, 958], "unfit": 8, "conduct": [8, 1319, 1465, 1630, 1724], "filial": 8, "romant": 8, "strength": 8, "candid": [8, 641, 1677, 1716], "letter": [8, 781], "befit": 8, "candidaci": 8, "behind": [8, 1675, 1711, 1725], "75": [8, 856, 1104, 1213, 1231, 1430, 1476, 1677, 1728], "choos": [8, 13, 42, 641, 940, 953, 958, 1032, 1694, 1695, 1698, 1716, 1720, 1732], "unforeseen": 8, "circumst": [8, 35, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1188, 1189, 1190, 1191, 1192, 1193, 1197], "perman": [8, 42, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1407, 1726], "unavail": [8, 1678], "rank": [8, 17, 18, 20, 21, 23, 24, 26, 33, 35, 36, 38, 40, 940, 941, 942, 949, 983, 985, 993, 1108, 1155, 1319, 1389, 1465, 1630, 1677, 1700, 1708, 1713, 1717, 1724, 1725], "elect": 8, "invit": [8, 1674], "convinc": 8, "approach": [8, 18, 20, 42, 664, 1667, 1676, 1688, 1696, 1699, 1703, 1719, 1724, 1727], "interview": 8, "talk": [8, 37, 1705, 1727], "gather": [8, 20, 35, 40, 465, 1636, 1660, 1667, 1677, 1701, 1702, 1705, 1714, 1716], "read": [8, 17, 20, 25, 26, 28, 35, 36, 42, 401, 741, 763, 832, 833, 834, 902, 966, 1459, 1689, 1690, 1696, 1697, 1699, 1705, 1709, 1716, 1719, 1724], "attend": [8, 1122, 1159, 1328], "confer": [8, 1070], "pipelin": [8, 42, 1675, 1724], "world": [8, 20, 23, 26, 33, 35, 36, 40, 1155, 1319, 1696, 1716, 1719], "cover": [8, 42, 755, 781, 1109, 1237, 1238, 1239, 1679, 1681, 1690, 1701, 1703, 1705, 1706, 1724], "push": [8, 27, 744, 960, 1667], "notifi": [8, 21, 36, 1726], "expert": 8, "strongli": [8, 20, 26, 36, 1055, 1056, 1057, 1061, 1625, 1674], "failur": [8, 20, 24, 26, 27, 28, 32, 33, 34, 35, 38, 637, 638, 910, 911, 1679, 1688, 1717, 1724, 1726, 1734], "revert": [8, 24, 40, 1152, 1270, 1726], "substanti": [8, 18], "syntact": [8, 28, 42], "incompat": [8, 12, 657, 892, 1697, 1716], "q": [8, 18, 24, 385, 432, 840, 915, 931, 934, 953, 997, 1014, 1082, 1122, 1351, 1384, 1463, 1465, 1475, 1476, 1630, 1676, 1677, 1703, 1710, 1713, 1728], "partli": [8, 1679], "domain": [8, 24, 28, 579, 615, 795, 796, 797, 798, 800, 801, 802, 803, 804, 809, 811, 812, 813, 814, 848, 1429, 1713, 1719], "absolut": [8, 10, 12, 42, 47, 576, 589, 637, 638, 829, 884, 923, 928, 949, 952, 954, 975, 1077, 1083, 1147, 1222, 1226, 1266, 1394, 1395, 1397, 1398, 1400, 1403, 1404, 1405, 1406, 1422, 1469, 1562, 1593, 1677, 1706, 1728, 1733, 1734], "health": 8, "success": [8, 24, 26, 32, 42, 925, 936, 938, 985, 1396, 1611, 1612, 1613, 1615, 1616, 1706, 1713, 1727], "am": 8, "grant": 8, "purchas": 8, "board": 8, "driven": 8, "clearli": [8, 1716], "sponsorship": 8, "foundat": 8, "ptf": 8, "independ": [8, 17, 19, 20, 35, 40, 41, 108, 109, 630, 631, 632, 633, 634, 635, 691, 848, 857, 953, 1054, 1055, 1056, 1057, 1061, 1199, 1200, 1201, 1206, 1224, 1281, 1372, 1378, 1419, 1475, 1676, 1695, 1696, 1699, 1711, 1716], "minor": [8, 710, 925, 941], "committ": 8, "prior": [8, 18, 20, 26, 629, 967, 1161, 1163, 1400, 1697, 1699, 1701, 1715, 1719], "guidelin": [8, 1400, 1716, 1719, 1720], "facebook": 8, "infrastructur": [8, 27, 1716], "employe": 8, "expand": [8, 24, 210, 445, 608, 629, 637, 638, 659, 947, 948, 998, 1166, 1257, 1656, 1674, 1677, 1689, 1690, 1697, 1713, 1714, 1716, 1717, 1731], "deliv": [8, 1718], "offici": [8, 20, 1024], "showcas": [8, 1112, 1699, 1708], "whenev": [8, 610, 1384, 1385, 1687, 1688, 1722, 1725, 1726, 1738], "triag": 9, "fix": [9, 17, 20, 24, 26, 35, 42, 217, 908, 940, 1059, 1060, 1204, 1205, 1224, 1319, 1486, 1676, 1677, 1687, 1694, 1695, 1699, 1702, 1708, 1712, 1713, 1715], "land": 9, "meet": [9, 34, 924, 1699], "plu": [9, 12, 630, 834, 941, 1727], "quarterli": 9, "chintala": 9, "edward": 9, "yang": [9, 967], "ezyang": [9, 1731], "greg": 9, "chanan": 9, "gchanan": 9, "dmytro": 9, "dzhulgakov": 9, "joel": [9, 1465, 1630], "schlosser": 9, "jbschlosser": 9, "alban": 9, "desmaison": 9, "alband": 9, "sam": 9, "gross": 9, "colesburi": 9, "adam": [9, 21, 23, 24, 40, 1434, 1435, 1437, 1447, 1715], "paszk": 9, "apaszk": 9, "ilqar": 9, "ramazanli": 9, "iramazanli": 9, "vincent": 9, "quennevil": 9, "belair": 9, "vincentqb": 9, "jeffrei": 9, "wan": 9, "soulitz": 9, "elia": 9, "ellison": 9, "eellison": 9, "michael": 9, "suo": 9, "yanan": 9, "cao": 9, "gmagogsfm": 9, "jame": 9, "reed": 9, "jamesr66a": 9, "zach": 9, "devito": 9, "zdevito": 9, "fritz": 9, "obermey": 9, "fritzo": 9, "neeraj": 9, "pradhan": 9, "neerajprad": 9, "alican": 9, "bozkurt": 9, "alicanb": 9, "vishwak": 9, "srinivasan": 9, "vishwakftw": 9, "shen": 9, "li": [9, 1014, 1476, 1699], "mrshenli": 9, "pritam": 9, "damania": 9, "pritamdamania87": 9, "yanli": 9, "zhao": 9, "zhaojuanmao": 9, "rohan": 9, "varma": 9, "wanchao": 9, "liang": 9, "wanchaol": 9, "junji": 9, "wang": [9, 24], "fduwjj": 9, "howard": 9, "huang": 9, "tristan": 9, "rice": 9, "d4l3k": 9, "kiuk": 9, "chung": 9, "kiukchung": 9, "alisson": 9, "azzolini": 9, "aazzolini": 9, "ke": 9, "wen": 9, "kwen2501": 9, "pieter": 9, "noordhui": 9, "pietern": 9, "mingzh": 9, "mingzhe09088": 9, "omkar": 9, "salpekar": 9, "osalpekar": 9, "vitali": 9, "fedyunin": 9, "vitalyfedyunin": 9, "simon": 9, "ssnl": 9, "mike": 9, "ruberri": 9, "mruberri": 9, "mario": 9, "lezcano": 9, "ivan": 9, "yashchuk": 9, "ivanyashchuk": 9, "peter": 9, "bell": 9, "peterbell10": 9, "xiaoqiang": 9, "zheng": 9, "xq": 9, "christian": 9, "puhrsch": 9, "cpuhrsch": 9, "ilia": 9, "cherniavskii": 9, "cher": 9, "natalia": 9, "gimelshein": 9, "ngimel": 9, "piotr": 9, "bialecki": 9, "ptrblck": 9, "jianhui": 9, "bai": 9, "bddppq": 9, "yinghai": 9, "peng": 9, "sun": 9, "sunway513": 9, "jithun": 9, "nair": 9, "jithunnair": 9, "jeff": 9, "daili": 9, "jeffdaili": 9, "nikita": 9, "shulga": 9, "malfet": 9, "eli": 9, "uriega": 9, "seemether": 9, "mikei": 9, "dagits": 9, "zhuoji": 9, "zhou": 9, "zhouzhuoji": 9, "karl": 9, "ostmo": 9, "kostmo": 9, "adnan": 9, "aziz": 9, "adnanaziz": 9, "ck": 9, "luk": 9, "ckluk": 9, "taylor": [9, 848], "robi": 9, "robieta": 9, "xu": [9, 40], "xuzhao9": 9, "geeta": 9, "chauhan": 9, "chauhang": 9, "victor": 9, "bittorf": 9, "bitfort": 9, "gisl": 9, "dankel": 9, "gdankel": 9, "Will": [9, 20, 40, 42, 1614, 1678, 1690, 1713], "feng": 9, "yf225": 9, "brian": 9, "hirsh": 9, "bdhirsh": 9, "sebastian": 9, "messmer": 9, "smessmer": 9, "bowen": 9, "bao": 9, "bowenbao": 9, "aaron": 9, "bockov": 9, "abock": 9, "gari": 9, "miguel": 9, "garymm": 9, "lara": 9, "haidar": 9, "hdr": 9, "fang": 9, "houseroad": 9, "negin": 9, "raoof": 9, "neginraoof": 9, "spandan": 9, "tiwari": 9, "spandantiwari": 9, "david": [9, 1024], "reiss": 9, "dreiss": 9, "raziel": 9, "guevara": 9, "linbin": 9, "yu": 9, "linbinyu": 9, "kobzarev": 9, "ivankobzarev": 9, "tao": 9, "xta0": 9, "raghuraman": 9, "krishnamoorthi": 9, "raghuramank100": 9, "jerri": 9, "zhang": 9, "jerryzh168": 9, "zafar": 9, "takhirov": 9, "supriya": 9, "rao": 9, "supriyar": 9, "guoliang": 9, "hua": 9, "nbcsm": 9, "teng": 9, "gao": 9, "gaoteng": 9, "git": [9, 1718], "johnson": 9, "peterjc123": [9, 1712], "kulin": 9, "seth": 9, "kulinseth": 9, "alfredo": 9, "mendoza": 9, "avmgithub": 9, "svetlana": 9, "karslioglu": 9, "svekar": 9, "jack": 9, "jackcaog": 9, "daniel": [9, 24], "sohn": 9, "jysohn23": 9, "cain": 9, "zcain117": 9, "hirsch": 9, "gregori": 9, "ail": 9, "ailzhang": 9, "libenzi": 9, "dlibenzi": 9, "alex": 9, "suhan": 9, "asuhan": 9, "manoj": 9, "mycpuorg": 9, "vamshi": 9, "dantu": 9, "vdantu": 9, "dhanasekar": 9, "karuppasami": 9, "dhanainm": 9, "francisco": 9, "massa": 9, "fmassa": 9, "vasili": 9, "vrynioti": 9, "datumbox": 9, "parmeet": 9, "singh": 9, "bhatia": 9, "steven": 9, "liu": 9, "hudeven": 9, "guanheng": 9, "georg": 9, "zhangguanheng66": 9, "moto": 9, "hira": 9, "mthrok": 9, "qb": 9, "wenlei": 9, "xie": 9, "wenleix": 9, "11": [10, 12, 20, 276, 465, 666, 670, 691, 728, 778, 858, 915, 951, 965, 981, 1024, 1040, 1065, 1113, 1209, 1422, 1423, 1603, 1640, 1668, 1676, 1680, 1690, 1699, 1712, 1713, 1714, 1727, 1728], "6": [10, 12, 17, 18, 20, 24, 33, 42, 268, 270, 272, 276, 387, 424, 440, 451, 465, 469, 510, 534, 559, 580, 581, 586, 592, 630, 631, 633, 634, 635, 647, 655, 660, 666, 669, 670, 674, 686, 741, 758, 759, 763, 764, 775, 778, 779, 797, 805, 810, 811, 815, 816, 818, 820, 821, 824, 831, 848, 858, 860, 861, 884, 905, 916, 920, 931, 940, 947, 951, 952, 953, 960, 961, 965, 967, 998, 1002, 1015, 1016, 1029, 1040, 1043, 1048, 1051, 1059, 1060, 1069, 1070, 1071, 1073, 1074, 1112, 1113, 1117, 1125, 1133, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1159, 1160, 1162, 1167, 1180, 1210, 1217, 1218, 1250, 1259, 1314, 1334, 1335, 1336, 1338, 1339, 1351, 1354, 1356, 1358, 1412, 1413, 1415, 1421, 1422, 1423, 1431, 1445, 1464, 1465, 1468, 1475, 1476, 1549, 1550, 1553, 1559, 1569, 1570, 1574, 1578, 1600, 1603, 1606, 1609, 1611, 1612, 1617, 1628, 1630, 1631, 1632, 1635, 1640, 1641, 1642, 1643, 1644, 1646, 1649, 1651, 1655, 1660, 1668, 1669, 1676, 1679, 1680, 1691, 1694, 1696, 1701, 1706, 1711, 1713, 1724, 1725, 1727, 1728, 1730, 1733, 1734, 1738], "download": [10, 1686, 1712, 1732], "pip": [10, 1712, 1732], "express": [10, 42, 274, 781, 893, 896, 1625, 1680, 1685, 1696, 1701, 1738], "bj": 10, "j": [10, 20, 24, 268, 270, 276, 465, 467, 469, 587, 624, 630, 632, 677, 780, 781, 797, 798, 805, 811, 815, 816, 837, 892, 895, 930, 931, 942, 958, 967, 974, 982, 985, 990, 1055, 1056, 1057, 1061, 1116, 1119, 1199, 1200, 1201, 1206, 1469, 1476, 1608, 1625, 1629, 1633, 1664, 1678, 1694, 1696, 1701, 1703, 1711], "imaginari": [10, 266, 637, 677, 682, 780, 802, 804, 812, 813, 814, 865, 885, 887, 888, 891, 1625, 1665, 1666, 1680, 1696, 1703, 1734], "satisfi": [10, 15, 18, 24, 568, 589, 631, 637, 638, 660, 797, 798, 800, 802, 804, 812, 813, 814, 829, 908, 934, 960, 961, 1024, 1039, 1063, 1068, 1086, 1131, 1353, 1400, 1415, 1562, 1578, 1625, 1679, 1696, 1699, 1703, 1715, 1717, 1727, 1730], "equat": [10, 669, 781, 840, 852, 938, 939, 940, 941, 942, 944, 955, 957, 1032, 1648, 1677, 1696, 1703, 1728], "frequent": [10, 1024, 1675, 1709, 1711], "mathemat": [10, 42, 630, 631, 632, 633, 634, 635, 829, 848, 1032, 1034, 1035, 1036, 1079, 1080, 1081, 1082, 1155, 1232, 1269, 1319, 1422, 1562, 1607, 1679, 1696, 1709, 1728, 1735], "topic": [10, 1705, 1706], "tradition": 10, "torchaudio": [10, 1675], "mimick": [10, 780], "vector": [10, 18, 19, 24, 40, 209, 268, 270, 276, 584, 585, 586, 614, 622, 624, 630, 631, 632, 633, 634, 635, 636, 657, 658, 664, 675, 682, 686, 687, 761, 762, 767, 769, 840, 927, 934, 942, 950, 951, 955, 958, 962, 963, 964, 985, 990, 998, 1007, 1009, 1033, 1034, 1035, 1036, 1039, 1053, 1059, 1060, 1063, 1071, 1079, 1080, 1081, 1125, 1155, 1164, 1167, 1186, 1204, 1205, 1213, 1215, 1249, 1253, 1280, 1381, 1383, 1385, 1389, 1418, 1422, 1464, 1465, 1609, 1629, 1633, 1661, 1664, 1667, 1696, 1703, 1719, 1727, 1732], "assembl": [10, 17], "lapack": [10, 668, 840, 925, 936, 937, 938, 940, 943, 956, 1475, 1629], "cubla": [10, 701, 1660, 1710], "spectral": [10, 914, 930, 958, 1385, 1408, 1416], "fft": [10, 1675, 1699], "4621": 10, "0303j": 10, "2438": [10, 1204], "5874j": 10, "7706": 10, "1421j": 10, "2110": 10, "1918j": 10, "complex128": [10, 130, 677, 824, 833, 874, 895, 924, 925, 930, 931, 932, 933, 934, 935, 1044, 1045, 1046, 1116, 1188, 1189, 1190, 1469, 1582, 1729, 1730, 1733, 1734], "complex64": [10, 133, 677, 798, 800, 801, 806, 807, 833, 874, 926, 949, 952, 1044, 1045, 1046, 1188, 1189, 1190, 1469, 1582, 1729, 1730, 1733, 1734], "apart": [10, 1679, 1696], "linspac": [10, 647, 671, 802, 812, 998, 1677, 1681, 1714], "logspac": [10, 1677, 1681], "arang": [10, 17, 20, 25, 465, 559, 586, 587, 588, 592, 594, 658, 670, 674, 763, 778, 797, 801, 809, 815, 817, 821, 822, 823, 824, 831, 832, 858, 915, 916, 920, 923, 947, 950, 951, 964, 1137, 1138, 1139, 1140, 1141, 1168, 1169, 1170, 1250, 1422, 1423, 1464, 1472, 1476, 1558, 1565, 1570, 1590, 1609, 1617, 1628, 1640, 1641, 1643, 1644, 1646, 1668, 1677, 1691, 1711, 1714, 1728, 1732, 1733], "switch": [10, 17, 41, 42, 937, 938, 939, 1056, 1213, 1251, 1381, 1574, 1660, 1688, 1696, 1706, 1715], "view_as_r": [10, 1625, 1677, 1731], "6125": 10, "1681": 10, "3773": 10, "3487": 10, "0861": 10, "7981": 10, "1681j": 10, "3487j": 10, "7981j": 10, "mul_": [10, 1677, 1689, 1691, 1727], "2250": [10, 951, 1422], "7546": [10, 669], "1722": 10, "x1": [10, 664, 942, 1051, 1108, 1164, 1165, 1195, 1252, 1677], "3j": [10, 20, 593, 679, 680, 1566, 1567, 1582], "4j": [10, 20, 1593], "0000": [10, 24, 465, 534, 595, 630, 632, 647, 667, 671, 682, 761, 767, 768, 769, 795, 796, 799, 801, 802, 808, 809, 812, 817, 829, 830, 831, 848, 854, 857, 861, 920, 923, 924, 925, 937, 938, 941, 946, 947, 951, 953, 965, 981, 983, 1012, 1059, 1060, 1168, 1169, 1171, 1204, 1205, 1385, 1422, 1469, 1475, 1547, 1548, 1549, 1558, 1562, 1563, 1586, 1593, 1595, 1607, 1648, 1649, 1651, 1670, 1699, 1727, 1728, 1733], "6569": [10, 861], "5708": [10, 764], "7854": 10, "complex_tensor": 10, "pt": [10, 18, 19, 900, 902, 905, 912, 966, 1574, 1676, 1706, 1711, 1716], "conjug": [10, 285, 411, 587, 637, 669, 679, 680, 780, 875, 924, 925, 931, 934, 937, 944, 958, 963, 967, 1384, 1463, 1566, 1625, 1629, 1664, 1703, 1715, 1733], "wirting": [10, 637, 1703], "deriv": [10, 20, 105, 622, 636, 637, 638, 848, 892, 952, 985, 1314, 1331, 1332, 1333, 1334, 1335, 1336, 1374, 1485, 1506, 1678, 1701, 1703, 1724, 1728], "steepest": [10, 1696], "descent": [10, 24, 1430, 1446, 1450, 1451, 1696, 1706], "box": [10, 20, 36, 1667, 1690, 1696, 1700], "fulli": [10, 12, 17, 20, 23, 42, 895, 1112, 1113, 1114, 1116, 1679, 1701, 1716, 1719], "quantiz": [10, 42, 174, 281, 293, 425, 426, 427, 428, 429, 431, 641, 765, 795, 796, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1675, 1713, 1730, 1733, 1734, 1736, 1737], "parallel_info": [11, 1698], "cppextens": 12, "setuptool": 12, "bare": 12, "buildextens": 12, "ext_modul": 12, "extra_compile_arg": [12, 1712], "cmdclass": 12, "build_ext": 12, "cudaextens": 12, "cuda_extens": 12, "extension_kernel": 12, "cu": 12, "cxx": 12, "nvcc": [12, 713], "o2": 12, "compil": [12, 13, 42, 709, 713, 725, 726, 893, 896, 899, 900, 906, 907, 908, 910, 911, 912, 1676, 1678, 1679, 1680, 1681, 1695, 1698, 1705, 1712, 1713], "arch": 12, "card": [12, 1712], "visibl": [12, 20, 32, 708, 751, 1117, 1118, 1126, 1127], "ptx": 12, "road": 12, "recompil": [12, 42, 908], "cc": [12, 20], "newest": 12, "torch_cuda_arch_list": 12, "build_my_extens": 12, "7": [12, 17, 18, 20, 24, 42, 215, 268, 270, 272, 276, 387, 424, 465, 510, 559, 568, 580, 592, 633, 635, 652, 655, 660, 666, 670, 674, 763, 775, 777, 778, 782, 797, 820, 821, 824, 827, 831, 848, 858, 872, 916, 920, 930, 935, 937, 938, 941, 942, 946, 947, 951, 958, 1015, 1016, 1022, 1023, 1026, 1027, 1029, 1040, 1059, 1104, 1112, 1113, 1137, 1138, 1139, 1140, 1141, 1167, 1180, 1251, 1338, 1339, 1402, 1407, 1415, 1422, 1549, 1553, 1559, 1569, 1570, 1571, 1578, 1590, 1593, 1595, 1596, 1603, 1609, 1611, 1612, 1617, 1629, 1631, 1632, 1633, 1635, 1640, 1641, 1644, 1646, 1655, 1664, 1668, 1676, 1680, 1690, 1691, 1697, 1699, 1701, 1709, 1711, 1713, 1714, 1719, 1727, 1730, 1731, 1732, 1733, 1734], "older": [12, 1699, 1711, 1716], "modestli": [12, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447], "imag": [12, 17, 677, 1022, 1026, 1027, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1063, 1064, 1065, 1080, 1088, 1123, 1128, 1129, 1150, 1167, 1169, 1170, 1178, 1189, 1190, 1192, 1193, 1207, 1208, 1213, 1224, 1280, 1281, 1334, 1335, 1336, 1540, 1541, 1567, 1677, 1691, 1703, 1717, 1731, 1732], "pars": [12, 20, 38, 639, 1679, 1716, 1724], "window": [12, 17, 20, 42, 306, 506, 645, 654, 852, 853, 892, 914, 1029, 1030, 1031, 1064, 1065, 1084, 1085, 1109, 1110, 1111, 1112, 1113, 1114, 1180, 1208, 1209, 1237, 1238, 1239, 1547, 1548, 1625, 1675, 1677, 1687, 1699], "workaround": [12, 17, 42, 899, 1674, 1710, 1713, 1719], "pure": [12, 13, 898, 1676], "sigmoidalphablendforwardcuda": 12, "69460": 12, "facebookresearch": 12, "pytorch3d": 12, "cb170ac024a949f1f9614ffe6af1c38d972f7d48": 12, "relocat": 12, "link": [12, 13, 19, 24, 42, 1044, 1045, 1046, 1047, 1048, 1049, 1063, 1109, 1110, 1111, 1167, 1215, 1690, 1705, 1706, 1727], "refer": [12, 17, 18, 20, 21, 23, 24, 27, 30, 31, 35, 36, 41, 209, 603, 608, 622, 658, 721, 726, 784, 834, 843, 844, 876, 883, 895, 898, 906, 913, 926, 947, 951, 964, 967, 1039, 1070, 1116, 1165, 1178, 1186, 1195, 1196, 1213, 1280, 1319, 1327, 1328, 1349, 1357, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1465, 1538, 1549, 1584, 1630, 1660, 1674, 1677, 1688, 1689, 1691, 1692, 1695, 1696, 1699, 1700, 1701, 1702, 1703, 1706, 1708, 1710, 1715, 1720, 1724, 1725, 1730, 1731, 1732, 1735], "symbol": [12, 16, 19, 575, 909, 963, 1086, 1131, 1429, 1648, 1664, 1679, 1714], "rdc": 12, "dc": 12, "anymor": [12, 20, 176], "dlto": 12, "dlink": 12, "protent": 12, "perf": [12, 1719], "lib": [12, 19, 1712], "nvshmem": 12, "ninja": [12, 1712], "dlink_librari": 12, "dlink_lib": 12, "std": [12, 19, 26, 33, 43, 331, 407, 795, 796, 827, 828, 829, 1423, 1469, 1562, 1624, 1658, 1677, 1689, 1694, 1705, 1712, 1714], "14": [12, 20, 276, 469, 669, 725, 726, 763, 778, 858, 947, 953, 983, 1011, 1040, 1113, 1475, 1549, 1603, 1640, 1641, 1646, 1668, 1674, 1676, 1680, 1714, 1727, 1731, 1732], "mix": [12, 18, 24, 40, 1319, 1675, 1696, 1698, 1719, 1727], "use_ninja": 12, "greatli": [12, 42, 1699], "fallback": [12, 20, 35, 908, 958, 1695], "distutil": 12, "max_job": 12, "extra_cflag": 12, "extra_cuda_cflag": 12, "extra_ldflag": 12, "extra_include_path": 12, "build_directori": 12, "with_cuda": [12, 1712], "is_python_modul": 12, "is_standalon": 12, "keep_intermedi": 12, "torch_extens": 12, "temporari": [12, 42, 1320, 1505, 1508, 1696, 1702, 1734], "overridden": [12, 42, 619, 620, 621, 725, 1116, 1679, 1696, 1701, 1709, 1717, 1738], "torch_extensions_dir": 12, "subfold": 12, "o3": 12, "cuh": 12, "Such": [12, 17, 18, 41, 1633, 1661, 1727], "lib64": 12, "cudart": [12, 1712], "fine": [12, 20, 23, 25, 832, 910, 1319, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1443, 1444, 1445, 1446, 1447, 1537, 1674, 1688, 1696, 1699, 1701, 1713, 1716, 1717, 1719], "cuda_hom": 12, "safest": 12, "pybind11": [12, 13, 1678], "linker": 12, "workspac": 12, "turn": [12, 17, 19, 42, 603, 883, 910, 1160, 1162, 1696, 1709, 1710, 1713, 1718, 1719, 1725, 1727], "header": [12, 19, 33, 1712, 1734], "automat": [12, 18, 20, 35, 36, 42, 105, 541, 619, 621, 719, 857, 904, 910, 998, 1162, 1320, 1561, 1590, 1674, 1675, 1678, 1679, 1686, 1689, 1690, 1696, 1697, 1699, 1701, 1706, 1708, 1713, 1714, 1716, 1717, 1719, 1720, 1724, 1732, 1733], "construct": [12, 13, 17, 20, 23, 24, 35, 40, 42, 105, 401, 608, 609, 622, 636, 677, 767, 784, 857, 895, 906, 910, 911, 918, 925, 965, 966, 981, 998, 1059, 1060, 1116, 1314, 1319, 1321, 1322, 1410, 1415, 1465, 1469, 1506, 1582, 1611, 1612, 1613, 1614, 1615, 1616, 1630, 1639, 1642, 1667, 1676, 1687, 1691, 1699, 1700, 1706, 1708, 1711, 1716, 1719, 1724, 1726, 1730, 1732, 1733, 1734], "plain": [12, 1033, 1117, 1126, 1384, 1613, 1701, 1727], "standalon": [12, 34, 35, 36, 906, 910, 1676], "torch_lib_path": 12, "load_inlin": 12, "cpp_sourc": 12, "cuda_sourc": 12, "with_pytorch_error_handl": 12, "behav": [12, 13, 20, 41, 42, 268, 276, 445, 467, 469, 910, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1523, 1678, 1679, 1696, 1706, 1710, 1716, 1724], "exactli": [12, 18, 20, 24, 37, 637, 638, 670, 696, 700, 781, 827, 828, 892, 895, 936, 1060, 1063, 1116, 1144, 1147, 1205, 1215, 1319, 1422, 1689, 1696, 1699, 1700, 1701, 1703, 1704, 1713, 1716, 1717], "filenam": [12, 17, 42, 894, 902, 905, 1674, 1677, 1686, 1696, 1716, 1729, 1732], "typic": [12, 17, 18, 20, 24, 25, 26, 28, 35, 36, 37, 40, 42, 686, 688, 824, 832, 895, 915, 918, 1050, 1076, 1116, 1314, 1319, 1611, 1612, 1613, 1615, 1616, 1674, 1675, 1676, 1679, 1696, 1698, 1699, 1709, 1710, 1711, 1713, 1715, 1717, 1719, 1724, 1727, 1731, 1739], "inlin": [12, 41, 725, 895, 899, 910, 1698], "concaten": [12, 17, 40, 632, 663, 674, 698, 779, 860, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1060, 1086, 1197, 1205, 1381, 1389, 1622, 1669, 1680, 1713, 1727], "prepend": [12, 17, 20, 23, 42, 184, 772, 895, 990, 1116, 1642, 1677, 1697], "furthermor": [12, 19, 33, 930, 931, 958, 985, 1054, 1667, 1689, 1690, 1710, 1722, 1724], "cuda_runtim": 12, "se": 12, "warn": [12, 18, 19, 20, 23, 630, 636, 741, 755, 758, 876, 910, 952, 998, 1386, 1389, 1584, 1592, 1660, 1674, 1687, 1697, 1701, 1713, 1716, 1723], "macro": [12, 1704], "pybind": 12, "_safe_foo": 12, "redirect": [12, 26, 33], "obscur": 12, "sin_add": 12, "sin": [12, 483, 611, 725, 853, 946, 998, 1469, 1677, 1689, 1714, 1727, 1728, 1732], "inline_extens": 12, "include_path": 12, "get_compiler_abi_compatibility_and_vers": 12, "abi": [12, 13], "alongsid": [12, 895, 1116], "shell": 12, "torchvers": 12, "verify_ninja_avail": 12, "is_ninja_avail": 12, "export": [13, 19, 20, 25, 38, 640, 689, 898, 900, 906, 912, 1411, 1412, 1676, 1678, 1679, 1701, 1713, 1718, 1724], "product": [13, 20, 24, 35, 105, 581, 584, 585, 586, 622, 624, 631, 633, 634, 635, 636, 644, 656, 662, 666, 682, 687, 741, 758, 761, 777, 781, 872, 915, 927, 934, 960, 961, 963, 990, 998, 1001, 1009, 1068, 1069, 1086, 1087, 1212, 1353, 1384, 1463, 1464, 1473, 1641, 1656, 1664, 1667, 1676, 1689, 1696, 1703, 1705, 1706, 1709, 1716, 1727], "embed": [13, 19, 42, 624, 771, 1024, 1050, 1060, 1076, 1088, 1122, 1165, 1205, 1328, 1339, 1581, 1677, 1698, 1714, 1719, 1721, 1724, 1732], "modif": [13, 40, 42, 176, 626, 833, 834, 895, 1116, 1319, 1373, 1706, 1716, 1719], "submodul": [13, 40, 42, 895, 899, 905, 906, 1053, 1116, 1117, 1118, 1144, 1481, 1482, 1499, 1520, 1521, 1522, 1537, 1676, 1678, 1679, 1685, 1706, 1711, 1716, 1719, 1724], "preprocess": [13, 448, 895], "augment": [13, 1680, 1734], "walk": [13, 42, 1683, 1701, 1716, 1725, 1726, 1731], "interfac": [13, 18, 25, 27, 32, 35, 834, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1323, 1324, 1325, 1326, 1338, 1339, 1349, 1354, 1355, 1356, 1357, 1358, 1538, 1584, 1625, 1660, 1679, 1687, 1701, 1705, 1715, 1722, 1727, 1732], "opencv": [13, 1213, 1224], "struct": [13, 1685, 1705], "explain": [13, 40, 1674, 1679, 1695, 1699], "reshap": [13, 24, 450, 451, 465, 494, 568, 587, 674, 763, 778, 779, 820, 858, 915, 947, 951, 960, 961, 964, 1063, 1137, 1138, 1139, 1140, 1141, 1167, 1385, 1416, 1422, 1609, 1610, 1617, 1640, 1641, 1646, 1668, 1669, 1677, 1690, 1713, 1714, 1721, 1731, 1732], "classat_1_1_tensor": 13, "tensor_index": 13, "crucial": [13, 1683], "cpp_autograd": 13, "workflow": [13, 1674, 1701, 1719, 1720], "undesir": [13, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1701], "overview": [13, 20, 32, 1319, 1688, 1696, 1703, 1706, 1717, 1719, 1724], "cpp_frontend": 13, "library_root": 13, "libtorch": [13, 19], "linux": [13, 19, 20, 1674], "gcc": 13, "pre": [13, 20, 23, 42, 636, 895, 1116, 1317, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1443, 1444, 1445, 1446, 1447, 1449, 1455, 1674, 1676, 1679, 1685, 1698, 1706, 1713, 1717, 1733], "cxx11": 13, "condit": [15, 42, 568, 571, 575, 589, 631, 637, 638, 892, 910, 924, 926, 934, 940, 941, 942, 953, 958, 1068, 1086, 1122, 1131, 1163, 1353, 1412, 1415, 1648, 1670, 1676, 1677, 1678, 1680, 1691, 1696, 1701, 1717, 1732], "cudnn": [15, 16, 904, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1068, 1086, 1131, 1132, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1353, 1585, 1677, 1699, 1710], "float16": [15, 18, 252, 581, 584, 644, 656, 833, 877, 895, 990, 1001, 1044, 1045, 1046, 1047, 1048, 1049, 1068, 1069, 1086, 1087, 1103, 1116, 1131, 1353, 1505, 1508, 1532, 1533, 1537, 1571, 1695, 1706, 1719, 1721, 1729, 1730, 1733, 1734, 1739], "v100": [15, 1068, 1086, 1131, 1353, 1699], "packedsequ": [15, 1068, 1086, 1131, 1353, 1411, 1412, 1413], "rnn": [16, 1068, 1069, 1086, 1087, 1133, 1320, 1327, 1353, 1354, 1355, 1356, 1358, 1387, 1410, 1537, 1681, 1702, 1706, 1721, 1732], "enforc": [16, 18, 41, 620, 895, 1086, 1116, 1131, 1679, 1706, 1731], "cuda_launch_block": [16, 1086, 1131, 1699], "colon": [16, 1086, 1131, 1724], "cublas_workspace_config": [16, 1086, 1131, 1660, 1710], "16": [16, 20, 276, 568, 778, 797, 824, 848, 858, 895, 906, 918, 924, 930, 931, 935, 951, 983, 1028, 1030, 1031, 1039, 1040, 1043, 1044, 1045, 1046, 1048, 1049, 1054, 1055, 1056, 1057, 1061, 1064, 1065, 1084, 1085, 1086, 1104, 1109, 1110, 1111, 1113, 1114, 1116, 1123, 1131, 1142, 1159, 1188, 1190, 1191, 1193, 1197, 1208, 1209, 1331, 1332, 1333, 1334, 1335, 1336, 1365, 1425, 1472, 1603, 1660, 1664, 1668, 1676, 1680, 1694, 1706, 1709, 1711, 1713, 1714, 1717, 1724, 1727, 1728, 1730, 1732, 1733], "4096": [16, 1086, 1131, 1660, 1699, 1713], "heart": 17, "dataload": [17, 448, 1319, 1451, 1452, 1458, 1699, 1702, 1712, 1715, 1732], "batch_siz": [17, 24, 1410, 1412, 1413, 1667, 1677, 1702, 1710, 1713, 1732], "shuffl": [17, 1732], "batch_sampl": 17, "num_work": [17, 26, 1710, 1712], "drop_last": 17, "timeout": [17, 20, 35, 1688, 1724], "worker_init_fn": [17, 1702, 1710], "prefetch_factor": 17, "persistent_work": 17, "__getitem__": [17, 1660], "__len__": [17, 42, 1677], "protocol": [17, 25, 35, 37, 610, 832, 834, 1574, 1701, 1712, 1713, 1724, 1738], "sampl": [17, 24, 42, 43, 108, 109, 331, 407, 434, 560, 646, 686, 728, 741, 758, 799, 817, 848, 911, 985, 1007, 1028, 1032, 1033, 1037, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1052, 1054, 1055, 1056, 1057, 1059, 1060, 1061, 1070, 1076, 1079, 1080, 1081, 1082, 1083, 1101, 1103, 1107, 1108, 1119, 1120, 1121, 1123, 1130, 1134, 1147, 1148, 1155, 1164, 1178, 1185, 1186, 1196, 1198, 1199, 1200, 1201, 1204, 1205, 1206, 1210, 1213, 1215, 1223, 1224, 1225, 1248, 1256, 1319, 1372, 1385, 1423, 1451, 1465, 1468, 1549, 1551, 1553, 1555, 1557, 1607, 1623, 1624, 1662, 1663, 1687, 1694, 1695, 1699, 1705, 1706, 1716, 1719, 1720, 1732], "idx": [17, 42, 627, 895, 1024, 1059, 1116, 1385, 1677, 1690], "th": [17, 109, 268, 270, 276, 630, 632, 646, 666, 767, 772, 869, 892, 916, 934, 942, 948, 985, 1007, 1055, 1056, 1057, 1061, 1068, 1076, 1086, 1131, 1199, 1200, 1201, 1206, 1353, 1476, 1625, 1701, 1712, 1728, 1730], "iterabledataset": [17, 1705], "__iter__": [17, 1680], "suitabl": [17, 24, 660, 914, 1447, 1578, 1709, 1718, 1720, 1732], "improb": 17, "fetch": [17, 41, 42, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1724], "stream": [17, 20, 26, 33, 41, 105, 439, 622, 636, 688, 689, 690, 692, 693, 694, 700, 703, 704, 717, 723, 754, 757, 1564, 1677, 1679, 1713, 1724], "databas": 17, "remot": [17, 20, 23, 26, 1319, 1717, 1724, 1725], "real": [17, 24, 42, 581, 582, 583, 584, 585, 587, 593, 637, 644, 669, 677, 682, 728, 780, 797, 798, 800, 802, 803, 804, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 885, 887, 888, 891, 892, 915, 924, 925, 926, 928, 930, 931, 932, 933, 934, 937, 938, 939, 944, 947, 949, 951, 952, 953, 954, 958, 959, 963, 964, 965, 975, 981, 1083, 1125, 1128, 1129, 1165, 1384, 1625, 1629, 1633, 1664, 1665, 1666, 1674, 1677, 1679, 1696, 1699, 1716, 1719, 1724, 1726, 1731, 1733, 1734, 1738], "replica": [17, 18, 20, 23, 33, 1053, 1319, 1700], "duplic": [17, 270, 274, 424, 645, 654, 675, 852, 853, 895, 1116, 1657, 1658, 1727], "yield": [17, 18, 40, 42, 768, 770, 895, 941, 942, 1116, 1670, 1679, 1680, 1717, 1719, 1728], "stochast": [17, 24, 1064, 1065, 1208, 1209, 1430, 1432, 1433, 1435, 1446, 1450, 1451, 1706], "decent": 17, "randomli": [17, 638, 1028, 1054, 1055, 1056, 1057, 1061, 1134, 1198, 1199, 1200, 1201, 1206, 1338, 1339, 1349, 1357, 1397, 1705, 1706], "permut": [17, 781, 941, 942, 961, 985, 987, 1557, 1677, 1690, 1714, 1721, 1731, 1733], "mini": [17, 1034, 1035, 1036, 1059, 1060, 1071, 1076, 1079, 1080, 1081, 1088, 1108, 1119, 1121, 1155, 1164, 1204, 1205, 1224, 1281, 1372, 1378, 1717], "neither": [17, 20, 625, 628, 763, 824, 1122, 1163, 1422, 1646, 1701, 1724], "nor": [17, 20, 26, 40, 628, 930, 931, 958, 1122, 1163, 1319, 1422, 1474, 1629, 1701, 1713], "notion": [17, 637, 1034, 1035, 1036, 1079, 1080, 1081, 1155], "collat": 17, "minibatch": [17, 985, 1024, 1032, 1033, 1050, 1052, 1076, 1082, 1083, 1107, 1108, 1119, 1120, 1121, 1123, 1130, 1147, 1148, 1164, 1168, 1180, 1181, 1182, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1196, 1225, 1237, 1238, 1239, 1248, 1256, 1361, 1362, 1365, 1366, 1367, 1717], "loader": [17, 19, 1715], "essenti": [17, 20, 26, 42, 985, 1690, 1699, 1712, 1727], "dummi": [17, 23, 1701, 1738], "infinit": [17, 887, 967, 1032, 1039, 1197, 1469, 1701, 1724], "drop": [17, 42, 728, 900, 953, 958, 1028, 1625, 1676, 1690, 1708], "roughli": [17, 1082, 1700], "dataset_it": 17, "pad": [17, 18, 534, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 892, 1029, 1030, 1031, 1039, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1059, 1060, 1063, 1092, 1093, 1094, 1095, 1096, 1097, 1109, 1110, 1111, 1112, 1113, 1114, 1119, 1120, 1122, 1137, 1138, 1139, 1140, 1141, 1142, 1162, 1163, 1167, 1171, 1180, 1181, 1182, 1188, 1189, 1190, 1191, 1192, 1193, 1204, 1205, 1207, 1213, 1224, 1237, 1238, 1239, 1240, 1241, 1242, 1280, 1281, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1309, 1310, 1311, 1323, 1324, 1328, 1331, 1332, 1333, 1334, 1335, 1336, 1361, 1362, 1365, 1366, 1367, 1372, 1375, 1376, 1378, 1411, 1413, 1414, 1547, 1548, 1625, 1677, 1702, 1713, 1714, 1719, 1732], "max": [17, 20, 26, 28, 35, 40, 42, 71, 140, 141, 142, 143, 255, 534, 590, 591, 592, 604, 647, 664, 671, 672, 759, 795, 796, 855, 906, 926, 940, 947, 949, 951, 952, 964, 983, 993, 1025, 1026, 1027, 1038, 1039, 1050, 1051, 1060, 1064, 1065, 1070, 1075, 1076, 1084, 1085, 1102, 1104, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1119, 1120, 1121, 1124, 1135, 1136, 1143, 1164, 1165, 1167, 1175, 1176, 1177, 1187, 1195, 1205, 1208, 1209, 1224, 1228, 1237, 1238, 1239, 1249, 1253, 1257, 1259, 1263, 1281, 1351, 1363, 1364, 1373, 1375, 1376, 1381, 1413, 1433, 1434, 1435, 1445, 1450, 1451, 1459, 1487, 1501, 1502, 1503, 1504, 1507, 1547, 1548, 1660, 1676, 1677, 1687, 1697, 1699, 1702, 1714, 1719, 1722, 1739], "length": [17, 18, 20, 24, 215, 268, 270, 276, 306, 387, 388, 622, 636, 675, 700, 780, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 834, 869, 892, 910, 914, 1016, 1033, 1034, 1039, 1044, 1053, 1060, 1063, 1068, 1084, 1086, 1122, 1131, 1159, 1167, 1186, 1188, 1189, 1190, 1197, 1205, 1224, 1328, 1353, 1410, 1411, 1412, 1413, 1414, 1499, 1549, 1609, 1611, 1612, 1613, 1615, 1616, 1625, 1646, 1667, 1677, 1679, 1690, 1697, 1702, 1734], "certain": [17, 18, 20, 32, 33, 41, 42, 581, 584, 644, 656, 708, 768, 870, 892, 895, 902, 966, 990, 1001, 1044, 1045, 1046, 1047, 1048, 1049, 1069, 1087, 1103, 1116, 1122, 1167, 1214, 1225, 1227, 1328, 1421, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1679, 1690, 1696, 1697, 1699, 1701, 1705, 1706, 1709, 1713, 1717, 1718, 1724, 1725, 1727], "cheaper": [17, 41], "bulk": 17, "convert": [17, 20, 24, 25, 42, 105, 531, 536, 537, 538, 539, 540, 609, 610, 662, 675, 764, 801, 832, 895, 964, 1116, 1126, 1127, 1155, 1162, 1314, 1321, 1322, 1328, 1383, 1418, 1428, 1429, 1477, 1478, 1479, 1520, 1521, 1536, 1537, 1538, 1544, 1545, 1550, 1676, 1677, 1678, 1679, 1691, 1701, 1704, 1713, 1719, 1722, 1732, 1734, 1737], "arrai": [17, 26, 401, 609, 610, 647, 682, 686, 781, 833, 834, 966, 983, 998, 1063, 1068, 1069, 1086, 1087, 1207, 1353, 1502, 1503, 1564, 1590, 1611, 1612, 1613, 1615, 1616, 1639, 1646, 1661, 1676, 1680, 1706, 1727, 1729, 1733, 1734], "untouch": 17, "slightli": [17, 20, 24, 40, 1422, 1465, 1630, 1674, 1699, 1703, 1709, 1716], "default_col": 17, "channel": [17, 425, 426, 427, 795, 892, 1034, 1035, 1036, 1040, 1044, 1045, 1046, 1047, 1048, 1049, 1054, 1055, 1056, 1057, 1061, 1063, 1071, 1079, 1080, 1081, 1088, 1092, 1093, 1094, 1095, 1096, 1097, 1104, 1124, 1150, 1155, 1167, 1168, 1169, 1170, 1183, 1199, 1200, 1201, 1206, 1223, 1224, 1231, 1257, 1281, 1372, 1378, 1395, 1396, 1397, 1404, 1405, 1419, 1504, 1507, 1544, 1690, 1692, 1694, 1696, 1719, 1720, 1722, 1732], "class_index": 17, "namedtupl": [17, 42, 625, 759, 760, 780, 840, 895, 906, 916, 936, 983, 987, 994, 997, 999, 1002, 1013, 1024, 1116, 1465, 1475, 1603, 1629, 1633, 1643, 1648, 1676, 1678, 1679, 1719], "situat": [17, 24, 37, 42, 682, 1389, 1688, 1701, 1708, 1716, 1719, 1726, 1738], "gil": [17, 20, 23, 1696, 1699, 1724], "integ": [17, 20, 24, 35, 244, 400, 402, 495, 510, 516, 580, 581, 582, 583, 584, 585, 595, 644, 645, 654, 665, 681, 690, 691, 705, 710, 711, 739, 775, 778, 781, 782, 824, 825, 826, 827, 828, 829, 834, 835, 838, 852, 853, 856, 857, 858, 905, 908, 917, 918, 925, 936, 938, 948, 967, 1006, 1024, 1039, 1044, 1045, 1046, 1088, 1172, 1173, 1174, 1175, 1176, 1177, 1283, 1359, 1360, 1378, 1380, 1410, 1423, 1426, 1454, 1457, 1460, 1465, 1544, 1545, 1551, 1553, 1554, 1555, 1557, 1562, 1571, 1582, 1617, 1626, 1630, 1640, 1641, 1654, 1668, 1672, 1678, 1679, 1680, 1689, 1703, 1717, 1720, 1722, 1727, 1728, 1730, 1733, 1734, 1739], "among": [17, 18, 20, 23, 24, 35, 696, 697, 700, 857, 1053, 1423, 1679], "descriptor": [17, 1164, 1165, 1680, 1713], "parent": [17, 28, 33, 37, 1116, 1477, 1478, 1480, 1688, 1712, 1716, 1726, 1732], "simplest": [17, 26, 42, 1029, 1030, 1031, 1044, 1045, 1046, 1109, 1110, 1111, 1387, 1537, 1701, 1706, 1719, 1726, 1727], "refcount": [17, 1688, 1708], "panda": 17, "pyarrow": 17, "13246": 17, "enumer": [17, 24, 42, 895, 1116, 1118, 1127, 1451, 1677, 1678, 1695, 1699, 1712, 1713, 1732], "get_worker_info": [17, 1724], "id": [17, 20, 23, 26, 35, 36, 40, 42, 688, 718, 1155, 1239, 1277, 1319, 1367, 1485, 1506, 1679, 1705, 1716, 1723, 1724, 1725, 1729], "seed": [17, 43, 720, 729, 730, 749, 871, 988, 1465, 1549, 1630, 1677, 1702, 1710, 1723], "naiv": [17, 1717], "shut": [17, 1724], "garbag": [17, 1726], "subtleti": [17, 1053, 1701, 1702], "multiprocess": [17, 20, 21, 22, 26, 28, 36, 1053, 1319, 1675, 1690, 1700, 1725], "unix": [17, 33, 1688], "fork": [17, 33, 913, 1319, 1679, 1698, 1702, 1705, 1708, 1712, 1723, 1724, 1726], "child": [17, 26, 28, 40, 895, 1116, 1396, 1480, 1481, 1688, 1706, 1712, 1726], "address": [17, 20, 35, 38, 171, 637, 638, 694, 1688, 1699, 1724, 1725], "maco": [17, 20, 1688, 1707], "spawn": [17, 18, 21, 26, 27, 33, 37, 898, 1319, 1695, 1700, 1708, 1712, 1725], "__name__": [17, 18, 20, 27, 28, 36, 1700, 1701, 1708, 1712, 1716, 1725], "__main__": [17, 18, 20, 27, 28, 36, 1697, 1700, 1708, 1712, 1725], "bytecod": [17, 1716], "base_se": 17, "worker_id": [17, 37, 1710], "therebi": [17, 24, 1719], "mandatorili": 17, "upon": [17, 21, 26, 28, 42, 1319, 1386, 1389, 1688, 1696, 1699, 1713, 1719, 1726], "faq": [17, 1053, 1413, 1675], "initial_se": [17, 43, 1710, 1723], "host": [17, 20, 26, 28, 34, 35, 36, 37, 151, 164, 531, 555, 607, 780, 895, 1116, 1319, 1389, 1421, 1699, 1717, 1724, 1725, 1729], "recogn": [17, 1679, 1724], "simplecustombatch": 17, "transposed_data": 17, "zip": [17, 1674, 1677, 1678, 1686, 1699, 1705, 1727], "tgt": [17, 1159, 1160, 1161], "collate_wrapp": 17, "float32": [17, 18, 222, 531, 568, 610, 677, 795, 796, 833, 842, 844, 877, 1020, 1033, 1168, 1169, 1170, 1180, 1469, 1474, 1501, 1502, 1503, 1504, 1507, 1508, 1511, 1526, 1532, 1535, 1549, 1553, 1568, 1582, 1583, 1585, 1614, 1665, 1691, 1695, 1699, 1713, 1721, 1728, 1729, 1730, 1733, 1734, 1739], "tensordataset": 17, "batch_ndx": 17, "is_pin": [17, 1410, 1677, 1689, 1729], "multiprocessing_context": 17, "pin_memory_devic": 17, "reshuffl": 17, "mutual": [17, 20, 26], "subprocess": [17, 20, 33, 35, 37, 1702, 1708], "incomplet": [17, 630, 1681, 1728], "divis": [17, 568, 582, 670, 775, 826, 829, 905, 938, 1044, 1045, 1046, 1047, 1048, 1049, 1051, 1071, 1083, 1107, 1125, 1188, 1189, 1190, 1191, 1192, 1193, 1195, 1249, 1365, 1366, 1367, 1562, 1617, 1640, 1679, 1695, 1699], "smaller": [17, 42, 451, 495, 686, 1319, 1459, 1474, 1617, 1633, 1699, 1711, 1716, 1739], "randomsampl": 17, "prefetch": 17, "shutdown": [17, 35, 1724, 1725], "unpickl": [17, 20, 966, 1716], "practic": [17, 20, 24, 40, 1675, 1676, 1688, 1690, 1696, 1701, 1703, 1706, 1711, 1716, 1724], "len": [17, 20, 42, 495, 590, 591, 800, 804, 807, 811, 814, 818, 899, 961, 982, 996, 1012, 1015, 1053, 1251, 1395, 1397, 1413, 1451, 1458, 1614, 1617, 1628, 1661, 1676, 1677, 1679, 1701, 1714, 1727, 1732], "proper": [17, 26, 41, 42, 771, 1581, 1678, 1696, 1699, 1701, 1712], "guess": 17, "trust": [17, 20, 966, 1674, 1716], "inaccur": [17, 18], "kwd": 17, "overwrit": [17, 20, 42, 1117, 1126, 1679, 1696], "myiterabledataset": 17, "assert": [17, 18, 24, 42, 575, 893, 898, 899, 904, 1678, 1680, 1701, 1706, 1716, 1719, 1734], "worker_info": 17, "iter_start": 17, "iter_end": 17, "per_work": 17, "math": [17, 42, 791, 944, 946, 1066, 1211, 1225, 1465, 1549, 1630, 1676, 1678, 1679, 1709, 1727, 1728, 1734], "ceil": [17, 132, 1029, 1030, 1031, 1084, 1085, 1109, 1110, 1111, 1180, 1181, 1182, 1237, 1238, 1239, 1361, 1362, 1547, 1548, 1571, 1677, 1689, 1699, 1714, 1727], "min": [17, 20, 28, 35, 42, 71, 140, 141, 142, 143, 255, 590, 591, 592, 605, 671, 672, 725, 760, 795, 796, 855, 926, 940, 941, 947, 951, 953, 958, 964, 985, 1007, 1038, 1075, 1102, 1104, 1124, 1136, 1143, 1187, 1224, 1228, 1257, 1259, 1263, 1281, 1351, 1363, 1364, 1373, 1445, 1450, 1451, 1459, 1463, 1465, 1475, 1487, 1501, 1502, 1503, 1504, 1507, 1629, 1649, 1650, 1651, 1652, 1677, 1687, 1689, 1713, 1714, 1719, 1722, 1724, 1739], "ds": 17, "mult": 17, "20": [17, 20, 23, 24, 276, 580, 848, 893, 896, 906, 917, 951, 1006, 1028, 1030, 1031, 1034, 1035, 1036, 1037, 1039, 1043, 1044, 1045, 1046, 1048, 1049, 1054, 1055, 1056, 1057, 1061, 1064, 1065, 1068, 1069, 1071, 1078, 1079, 1080, 1081, 1084, 1085, 1086, 1087, 1088, 1103, 1109, 1110, 1111, 1113, 1114, 1116, 1131, 1133, 1144, 1152, 1155, 1158, 1159, 1160, 1161, 1188, 1190, 1191, 1193, 1197, 1208, 1209, 1215, 1270, 1304, 1312, 1313, 1327, 1331, 1332, 1333, 1334, 1335, 1336, 1339, 1349, 1353, 1354, 1355, 1356, 1357, 1358, 1365, 1384, 1385, 1409, 1416, 1419, 1436, 1451, 1545, 1636, 1676, 1677, 1691, 1700, 1701, 1709, 1715, 1724, 1727], "overall_start": 17, "overall_end": 17, "concatdataset": 17, "chaindataset": 17, "chain": [17, 18, 24, 41, 42, 105, 622, 666, 950, 1060, 1144, 1448, 1460, 1679, 1696, 1699, 1701, 1703, 1706, 1715], "fly": [17, 725, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1696], "whole": [17, 19, 20, 892, 895, 1116, 1144, 1155, 1319, 1667, 1696, 1708, 1709, 1716], "outer": [17, 586, 630, 781, 841, 1677, 1679, 1714], "left": [17, 42, 413, 451, 595, 645, 649, 654, 655, 660, 665, 781, 801, 808, 822, 825, 826, 830, 852, 853, 857, 892, 893, 900, 914, 935, 944, 948, 952, 955, 956, 957, 958, 960, 972, 973, 1007, 1024, 1029, 1030, 1031, 1032, 1033, 1044, 1045, 1046, 1063, 1070, 1083, 1084, 1085, 1104, 1105, 1106, 1107, 1109, 1110, 1111, 1119, 1120, 1121, 1125, 1126, 1164, 1167, 1168, 1169, 1170, 1213, 1233, 1251, 1382, 1450, 1451, 1463, 1499, 1502, 1558, 1571, 1578, 1625, 1641, 1646, 1661, 1676, 1677, 1679, 1701, 1706, 1722, 1728], "unchang": [17, 451, 465, 467, 820, 895, 1116, 1159, 1328, 1499, 1563, 1620, 1695, 1709, 1719], "byte": [17, 20, 24, 35, 197, 508, 610, 693, 731, 733, 735, 737, 834, 894, 966, 1122, 1328, 1428, 1436, 1678, 1679, 1680, 1689, 1716, 1727, 1729], "k": [17, 20, 24, 36, 42, 241, 308, 458, 465, 467, 469, 542, 568, 669, 767, 781, 837, 857, 916, 924, 926, 930, 931, 932, 933, 934, 935, 939, 940, 941, 944, 946, 953, 955, 957, 958, 967, 983, 986, 990, 1029, 1031, 1037, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1064, 1065, 1068, 1069, 1086, 1087, 1101, 1103, 1104, 1109, 1111, 1122, 1123, 1131, 1133, 1196, 1208, 1209, 1231, 1248, 1353, 1384, 1463, 1465, 1475, 1570, 1607, 1608, 1609, 1611, 1612, 1613, 1615, 1616, 1625, 1643, 1648, 1677, 1678, 1694, 1699, 1701, 1712, 1727, 1728, 1730], "v_i": [17, 934], "v_1": [17, 1125], "v_2": [17, 1125], "v1_i": 17, "v2_i": 17, "v1_1": 17, "v1_2": 17, "v2_1": 17, "v2_2": 17, "default_convert": 17, "NOT": [17, 20, 26, 35, 36, 37, 42, 650, 977, 1056, 1319, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1407, 1696, 1726, 1727], "np": [17, 664, 775, 821, 822, 823, 1253, 1469, 1710, 1713, 1732, 1733, 1734], "fraction": [17, 751, 824, 830, 1047, 1048, 1049, 1064, 1065, 1122, 1163, 1208, 1209, 1394, 1395, 1397, 1398, 1400, 1403, 1404, 1405, 1406, 1476, 1694], "random_split": 17, "floor": [17, 226, 775, 826, 905, 1029, 1030, 1031, 1084, 1085, 1109, 1110, 1111, 1180, 1181, 1182, 1237, 1238, 1239, 1361, 1362, 1547, 1548, 1562, 1571, 1625, 1677, 1679, 1689, 1711, 1714, 1727], "frac": [17, 24, 234, 331, 582, 595, 645, 654, 682, 686, 775, 826, 848, 852, 853, 914, 926, 930, 931, 934, 946, 958, 965, 981, 1024, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1040, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1054, 1063, 1068, 1069, 1070, 1071, 1079, 1080, 1081, 1082, 1084, 1085, 1086, 1087, 1088, 1101, 1103, 1104, 1105, 1106, 1109, 1110, 1111, 1119, 1120, 1121, 1123, 1131, 1133, 1134, 1146, 1148, 1149, 1151, 1152, 1154, 1155, 1156, 1167, 1182, 1188, 1189, 1190, 1191, 1192, 1193, 1233, 1249, 1251, 1253, 1264, 1268, 1270, 1272, 1273, 1353, 1365, 1366, 1367, 1431, 1432, 1435, 1437, 1443, 1450, 1451, 1546, 1558, 1561, 1573, 1593, 1608, 1625, 1629, 1646, 1677, 1689, 1694, 1696, 1703, 1728], "remaind": [17, 40, 442, 829, 848, 1677, 1714], "robin": [17, 20], "manual_se": [17, 43, 1677, 1689, 1706, 1710, 1723], "42": [17, 654, 1006, 1485, 1506, 1699, 1706], "30": [17, 20, 24, 26, 35, 398, 568, 848, 917, 1037, 1039, 1043, 1103, 1167, 1188, 1197, 1304, 1312, 1313, 1314, 1349, 1357, 1454, 1456, 1461, 1545, 1636, 1701, 1713, 1715, 1724], "data_sourc": 17, "sequentialsampl": 17, "num_sampl": [17, 375, 1007, 1677], "drawn": [17, 128, 213, 241, 1007, 1423, 1549, 1553, 1554, 1694, 1734, 1735], "subsetrandomsampl": 17, "weightedrandomsampl": 17, "probabl": [17, 109, 646, 856, 972, 1007, 1024, 1028, 1032, 1039, 1052, 1054, 1055, 1056, 1057, 1061, 1068, 1070, 1086, 1122, 1123, 1131, 1185, 1196, 1197, 1198, 1199, 1200, 1201, 1206, 1215, 1225, 1248, 1353, 1688, 1701, 1712, 1713, 1728, 1732], "row": [17, 18, 24, 163, 268, 270, 276, 537, 540, 588, 594, 607, 630, 632, 664, 682, 686, 763, 780, 794, 822, 823, 857, 916, 942, 950, 953, 958, 982, 983, 985, 994, 996, 997, 999, 1002, 1007, 1013, 1014, 1015, 1204, 1205, 1253, 1384, 1421, 1473, 1476, 1563, 1609, 1610, 1611, 1612, 1613, 1615, 1616, 1628, 1643, 1646, 1650, 1652, 1661, 1667, 1669, 1677, 1703, 1727, 1732], "05": [17, 23, 42, 68, 299, 589, 637, 638, 668, 795, 884, 910, 911, 981, 1034, 1035, 1036, 1071, 1079, 1080, 1081, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1155, 1159, 1161, 1163, 1183, 1214, 1223, 1227, 1296, 1297, 1298, 1299, 1300, 1301, 1307, 1308, 1319, 1329, 1330, 1342, 1344, 1345, 1346, 1347, 1449, 1455, 1456, 1461, 1676, 1677, 1715, 1725, 1734], "batchsampl": 17, "distributedsampl": 17, "num_replica": 17, "world_siz": [17, 18, 20, 21, 23, 26, 35, 36, 38, 40, 1319, 1700, 1717, 1724, 1725], "evenli": [17, 590, 591, 778, 858, 965, 981, 1668], "set_epoch": 17, "begin": [17, 18, 20, 21, 27, 35, 42, 448, 595, 645, 681, 688, 731, 733, 801, 848, 854, 915, 950, 962, 983, 1031, 1032, 1033, 1050, 1052, 1058, 1068, 1069, 1072, 1073, 1074, 1075, 1076, 1077, 1083, 1086, 1087, 1102, 1107, 1110, 1111, 1123, 1124, 1131, 1134, 1147, 1153, 1158, 1165, 1196, 1217, 1218, 1319, 1353, 1377, 1384, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446, 1450, 1452, 1458, 1502, 1503, 1590, 1593, 1625, 1646, 1657, 1670, 1679, 1695, 1696, 1699, 1701, 1703, 1705, 1710, 1713, 1722, 1728], "is_distribut": [17, 1677], "start_epoch": 17, "n_epoch": 17, "vanilla": 18, "allreduc": [18, 20, 1319, 1699, 1700], "besid": [18, 20, 1699, 1700, 1732], "register_comm_hook": [18, 23, 40, 1319], "mainli": [18, 24, 1039, 1197, 1500, 1509, 1736], "bucket": [18, 23, 1024, 1319, 1677, 1700, 1714], "gradbucket": [18, 1319], "flatten": [18, 40, 42, 604, 605, 769, 857, 951, 964, 1167, 1422, 1476, 1559, 1564, 1569, 1656, 1657, 1658, 1677, 1689, 1690, 1694, 1713, 1714, 1721, 1731], "decompos": [18, 42, 831, 939, 1696], "get_per_parameter_tensor": 18, "wise": [18, 20, 24, 582, 583, 593, 614, 680, 781, 786, 827, 828, 838, 839, 851, 860, 917, 919, 976, 977, 978, 979, 984, 995, 998, 1000, 1017, 1038, 1049, 1056, 1058, 1072, 1073, 1074, 1075, 1077, 1102, 1105, 1115, 1124, 1134, 1135, 1136, 1143, 1145, 1146, 1147, 1152, 1154, 1156, 1157, 1187, 1202, 1211, 1212, 1216, 1217, 1218, 1219, 1222, 1226, 1228, 1233, 1243, 1244, 1257, 1258, 1259, 1263, 1264, 1265, 1266, 1270, 1272, 1273, 1274, 1351, 1363, 1364, 1373, 1377, 1609, 1669, 1698, 1701, 1727, 1728, 1731], "_distributed_c10d": [18, 20], "1d": [18, 24, 675, 682, 686, 763, 777, 856, 857, 872, 950, 951, 998, 1014, 1021, 1025, 1029, 1039, 1044, 1047, 1052, 1055, 1056, 1060, 1084, 1108, 1109, 1121, 1123, 1168, 1172, 1175, 1178, 1180, 1188, 1191, 1199, 1205, 1234, 1237, 1286, 1289, 1331, 1334, 1365, 1375, 1476, 1544, 1547, 1646, 1664], "is_last": 18, "set_buff": 18, "stateless": [18, 1692, 1706], "ddp_comm_hook": [18, 23], "default_hook": 18, "allreduce_hook": 18, "process_group": [18, 21, 23, 40, 1155, 1319], "aggreg": [18, 20, 28, 40, 1060, 1205, 1319, 1400, 1687, 1717], "henc": [18, 23, 26, 34, 35, 38, 40, 41, 646, 834, 1112, 1113, 1114, 1168, 1614, 1696, 1699, 1700, 1724, 1726, 1727], "purpos": [18, 20, 42, 424, 451, 637, 904, 990, 1039, 1122, 1316, 1317, 1318, 1590, 1687, 1691, 1696, 1716, 1725], "unaffect": [18, 451, 452, 1070], "ddp_model": [18, 20, 1319, 1700], "fp16_compress_hook": 18, "compress": [18, 40, 163, 539, 540, 803, 804, 813, 814, 1319, 1611, 1612, 1613, 1615, 1616], "decompress": [18, 1674, 1686], "bf16_compress_hook": 18, "nccl": [18, 21, 36, 40, 1319, 1704], "brain": [18, 1730, 1733], "wrapper": [18, 20, 24, 40, 41, 42, 575, 688, 689, 690, 691, 754, 756, 827, 828, 895, 1053, 1350, 1479, 1485, 1506, 1676, 1678, 1679, 1687, 1688, 1699, 1713, 1717], "fp16_compress_wrapp": 18, "powersgdst": 18, "matrix_approximation_rank": 18, "start_powersgd_it": 18, "powersgd_hook": 18, "bf16_compress_wrapp": 18, "en": [18, 781, 1704, 1732, 1739], "wikipedia": [18, 1250, 1696, 1703, 1739], "wiki": [18, 1739], "bfloat16_float": 18, "point_format": 18, "vogel": 18, "et": [18, 24, 40, 1039, 1128, 1129, 1164, 1165, 1446, 1630, 1694], "al": [18, 24, 40, 1039, 1128, 1129, 1164, 1165, 1446, 1630, 1694], "neurip": [18, 24], "2019": [18, 24, 739], "bandwidth": [18, 20, 34, 36, 1719, 1724], "hyperparamet": [18, 42, 1732], "1000": [18, 796, 801, 827, 828, 1024, 1059, 1165, 1544, 1571, 1590, 1639, 1696, 1711, 1713, 1732], "min_compression_r": 18, "use_error_feedback": 18, "warm_start": 18, "orthogonalization_epsilon": 18, "random_se": 18, "compression_stats_logging_frequ": 18, "10000": [18, 589, 1458, 1571, 1702, 1706, 1727, 1732], "batch_tensors_with_same_shap": 18, "tune": [18, 20, 23, 739, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1443, 1444, 1445, 1446, 1447, 1696, 1699, 1707, 1719], "stronger": 18, "futher": 18, "threshold": [18, 42, 949, 952, 993, 1077, 1147, 1152, 1270, 1276, 1459, 1590, 1677, 1695, 1699, 1714, 1732], "expoenti": 18, "grid": [18, 801, 998, 1178, 1213, 1677, 1699, 1732], "satisfactori": 18, "nlp": [18, 1079, 1080, 1081, 1088], "appendix": 18, "defer": [18, 40, 1699, 1717], "hybrid": [18, 173, 493, 859], "scheme": [18, 35, 431, 1487, 1501, 1502, 1503, 1504, 1507, 1509, 1706], "sensit": [18, 1077, 1147, 1713, 1716, 1725], "earli": [18, 26, 41, 1055, 1056, 1057, 1061, 1667, 1675, 1719, 1720, 1736, 1737], "suboptim": [18, 1727], "trajectori": 18, "irrecover": 18, "impact": [18, 20, 739, 1585, 1685, 1687, 1696, 1719, 1731], "warm": [18, 23, 728, 1450, 1451, 1699, 1718], "num_row": 18, "num_col": 18, "1e": [18, 42, 68, 299, 589, 637, 638, 667, 668, 884, 910, 911, 961, 1034, 1035, 1036, 1051, 1070, 1071, 1079, 1080, 1081, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1102, 1125, 1130, 1155, 1159, 1161, 1163, 1164, 1183, 1195, 1210, 1214, 1215, 1223, 1227, 1249, 1252, 1256, 1278, 1296, 1297, 1298, 1299, 1300, 1301, 1307, 1308, 1329, 1330, 1342, 1344, 1345, 1346, 1347, 1348, 1385, 1416, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1443, 1444, 1445, 1447, 1459, 1467, 1586, 1676, 1677, 1701, 1706, 1715, 1728, 1734], "orthogon": [18, 931, 934, 953, 958, 967, 1463, 1475, 1694, 1696, 1706, 1727], "div": [18, 190, 776, 826, 829, 1024, 1128, 1129, 1562, 1653, 1677, 1683, 1689, 1714, 1727, 1730], "0s": [18, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447], "batch": [18, 24, 36, 38, 42, 581, 636, 637, 638, 644, 656, 657, 664, 667, 668, 669, 687, 768, 770, 781, 924, 925, 926, 927, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 962, 963, 964, 967, 975, 985, 986, 990, 1032, 1033, 1034, 1035, 1036, 1039, 1044, 1045, 1050, 1052, 1053, 1055, 1056, 1057, 1059, 1060, 1061, 1063, 1068, 1069, 1070, 1071, 1076, 1077, 1079, 1080, 1081, 1082, 1083, 1086, 1087, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1107, 1108, 1119, 1120, 1121, 1122, 1123, 1125, 1128, 1129, 1130, 1131, 1133, 1147, 1148, 1155, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1167, 1178, 1183, 1185, 1186, 1196, 1197, 1199, 1200, 1201, 1204, 1205, 1206, 1207, 1210, 1223, 1224, 1225, 1248, 1256, 1280, 1281, 1286, 1287, 1288, 1289, 1290, 1291, 1314, 1319, 1328, 1353, 1372, 1378, 1384, 1410, 1411, 1413, 1414, 1451, 1452, 1458, 1463, 1465, 1475, 1546, 1611, 1612, 1613, 1615, 1616, 1620, 1625, 1629, 1630, 1633, 1648, 1649, 1651, 1664, 1667, 1689, 1690, 1695, 1699, 1702, 1706, 1708, 1717, 1719, 1724, 1727, 1732, 1733], "epsilon": [18, 42, 595, 949, 952, 993, 1034, 1035, 1036, 1051, 1071, 1079, 1080, 1081, 1088, 1155, 1195, 1249, 1385, 1416, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1501, 1502, 1503, 1504, 1507, 1546, 1677, 1728], "bucket_cap_mb": [18, 1319, 1700], "footprint": [18, 1319, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447], "bottleneck": [18, 1675, 1706], "memor": 18, "compens": 18, "apex": 18, "uncompress": 18, "p": [18, 24, 40, 42, 109, 188, 241, 379, 380, 406, 443, 444, 560, 581, 584, 644, 646, 656, 664, 774, 915, 926, 932, 933, 941, 942, 985, 987, 990, 1001, 1010, 1028, 1054, 1055, 1056, 1057, 1059, 1060, 1061, 1082, 1084, 1085, 1121, 1125, 1127, 1164, 1165, 1179, 1198, 1199, 1200, 1201, 1204, 1205, 1206, 1234, 1235, 1245, 1249, 1252, 1253, 1278, 1381, 1387, 1389, 1395, 1404, 1422, 1446, 1563, 1606, 1677, 1678, 1695, 1696, 1699, 1703, 1708, 1718, 1728], "pq": 18, "ps": [18, 1702], "mq": [18, 1719, 1737], "qs": 18, "tp": 18, "speedup": [18, 40, 1122, 1163], "awai": [18, 42, 1213, 1690, 1696], "config": [18, 19, 40, 42, 1538, 1540, 1712], "comm": [18, 20, 1700], "handler": [18, 20, 28, 1396, 1687, 1705, 1716, 1738], "batched_powersgd_hook": 18, "destroi": [18, 35, 1053, 1696, 1724], "squar": [18, 24, 501, 686, 767, 769, 780, 892, 926, 928, 930, 931, 932, 935, 936, 940, 942, 944, 946, 948, 952, 954, 955, 957, 958, 962, 975, 983, 985, 1022, 1026, 1030, 1031, 1045, 1046, 1048, 1049, 1064, 1065, 1077, 1085, 1107, 1110, 1111, 1114, 1147, 1159, 1180, 1189, 1192, 1208, 1209, 1213, 1222, 1224, 1244, 1266, 1281, 1332, 1333, 1334, 1335, 1372, 1378, 1384, 1431, 1433, 1434, 1435, 1437, 1443, 1444, 1447, 1573, 1618, 1648, 1661, 1677, 1714, 1727], "truncat": [18, 534, 826, 1654, 1694, 1702, 1709], "impli": [18, 35, 1688, 1696, 1713, 1717, 1722, 1724], "debugging_hook": 18, "noop_hook": 18, "noop": [18, 1319], "headroom": 18, "desynchron": [18, 20], "trainer": [18, 26, 28, 33, 36, 37, 1319, 1724], "restart": [18, 26, 34, 36, 38, 1450, 1451, 1688, 1732], "__setstate__": 18, "__getstate__": 18, "reload": [18, 23, 1674], "os": [18, 20, 21, 36, 38, 42, 966, 1319, 1574, 1674, 1688, 1696, 1699, 1700, 1712, 1716, 1717, 1724], "sy": [18, 19, 27, 36, 38, 1674, 1716], "tempfil": 18, "simplemodel": 18, "24": [18, 20, 24, 649, 953, 1104, 1178, 1415, 1475, 1641, 1676, 1694, 1698, 1728], "fc2": [18, 1314, 1717], "12": [18, 20, 40, 276, 469, 568, 581, 666, 670, 778, 797, 858, 899, 914, 940, 953, 983, 1024, 1040, 1048, 1063, 1064, 1065, 1113, 1128, 1129, 1150, 1159, 1167, 1208, 1209, 1249, 1254, 1255, 1334, 1335, 1336, 1338, 1339, 1385, 1416, 1464, 1475, 1590, 1603, 1640, 1656, 1668, 1674, 1676, 1677, 1680, 1699, 1707, 1711, 1713, 1714, 1727], "master_addr": [18, 20, 26, 36, 38, 1700, 1717, 1724, 1725], "localhost": [18, 20, 35, 36, 1700, 1717, 1724, 1725], "master_port": [18, 20, 26, 36, 38, 1700, 1717, 1724, 1725], "12355": 18, "init_process_group": [18, 20, 21, 23, 26, 36, 38, 1319, 1699, 1700, 1724], "cleanup": 18, "destroy_process_group": 18, "run_demo": 18, "demo_fn": 18, "mp": [18, 20, 21, 37, 1319, 1675, 1700, 1708, 1719, 1725, 1729, 1737], "nproc": [18, 20, 33, 1688, 1700, 1725], "demo_seri": 18, "gettempdir": 18, "device_id": [18, 20, 21, 23, 36, 40, 966, 1053, 1155, 1277, 1319, 1700], "powersgd_st": 18, "lr": [18, 21, 23, 40, 1314, 1319, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1699, 1700, 1706, 1715, 1725, 1732], "001": [18, 637, 638, 904, 1433, 1434, 1443, 1447, 1700], "comm_hook": 18, "comm_hook_st": 18, "hook_stat": 18, "barrier": [18, 26, 35], "map_loc": [18, 899, 902, 966, 1319, 1674, 1686, 1716], "n_gpu": 18, "device_count": [18, 20], "got": [18, 20, 621, 1701], "thank": [18, 24, 1701, 1717], "author": [18, 35, 36, 1549, 1667, 1695], "thij": 18, "par": 18, "arxiv": [19, 24, 1086, 1134, 1135, 1162, 1419, 1465, 1630, 1696], "prototyp": [19, 20, 630, 632, 636, 637, 638, 904, 1667, 1675, 1687, 1690, 1691, 1706, 1711, 1722, 1724, 1730, 1736, 1737], "x86": [19, 1586, 1719], "yet": [19, 21, 26, 41, 42, 689, 755, 898, 900, 912, 1002, 1319, 1391, 1395, 1397, 1675, 1678, 1679, 1690, 1699, 1713, 1724, 1726, 1728, 1730], "use_deploi": 19, "cmake_prefix_path": 19, "conda_prefix": 19, "dirnam": [19, 1674], "conda": [19, 1675, 1712, 1713], "packageexport": [19, 1716], "torchvis": [19, 42, 1674, 1675, 1676, 1678, 1713, 1716, 1719, 1732, 1736], "instanti": [19, 20, 23, 34, 35, 36, 42, 785, 870, 1060, 1205, 1386, 1410, 1415, 1420, 1523, 1674, 1676, 1678, 1679, 1701, 1706, 1729], "resnet": [19, 1674, 1676, 1678, 1706, 1716, 1732, 1736], "resnet18": [19, 42, 1674, 1676, 1678, 1686, 1716], "my_packag": [19, 1716], "extern": [19, 25, 690, 832, 910, 1687, 1698], "pil": [19, 1213, 1224], "save_pickl": [19, 1716], "pkl": [19, 1716], "mark": [19, 35, 41, 42, 626, 627, 1319, 1676, 1678, 1696, 1700, 1701, 1706, 1716, 1725, 1733], "path_to_extern_python_packag": 19, "anaconda": [19, 1712], "python3": [19, 1679], "csrc": [19, 1712], "path_environ": 19, "iostream": 19, "argc": 19, "const": [19, 1070, 1705], "char": [19, 834, 1689, 1729], "argv": [19, 27, 38], "cerr": [19, 1705], "app": 19, "shared_ptr": 19, "make_shar": 19, "pathenviron": 19, "getenv": [19, 1705], "interpretermanag": 19, "loadpackag": 19, "replicatedobj": 19, "loadpickl": 19, "c10": [19, 35, 1705], "msg": [19, 742, 744, 1734], "cout": 19, "introduc": [19, 24, 967, 1068, 1086, 1131, 1224, 1353, 1569, 1674, 1679, 1697, 1700, 1707, 1713, 1716, 1717, 1718, 1724, 1733], "libtorch_deployinterpret": 19, "deploy_interpreter_path": 19, "deploy_src_path": 19, "soon": [19, 35, 1696, 1719, 1724, 1726], "cmakelist": 19, "txt": [19, 902, 905, 1716], "cmake_minimum_requir": 19, "19": [19, 580, 669, 1113, 1339, 1676, 1713, 1727], "fatal_error": 19, "deploy_tutori": 19, "find_packag": 19, "fmt": 19, "add_librari": 19, "torch_deploy_intern": 19, "deploy_dir": 19, "elf_fil": 19, "target_link_librari": 19, "privat": [19, 35, 1699, 1701, 1716], "crypt": 19, "pthread": 19, "dl": 19, "ffi": [19, 1712], "lzma": 19, "readlin": [19, 902, 966, 1716], "nsl": 19, "ncursesw": 19, "panelw": 19, "shm": 19, "caffe2_interface_librari": 19, "torch_deploi": 19, "add_execut": 19, "wl": 19, "rdynam": 19, "torch_librari": 19, "unset": [19, 42, 1709], "archiv": [19, 1705], "laid": 19, "mkdir": 19, "cd": [19, 1712, 1716, 1718], "cmake": [19, 1712], "dcmake_prefix_path": 19, "ddeploy_interpreter_path": 19, "ddeploy_dir": 19, "ivalu": [19, 1429, 1705], "push_back": 19, "224": [19, 42, 1540, 1676, 1678, 1713], "totensor": [19, 1732], "slice": [19, 559, 590, 591, 1034, 1035, 1036, 1149, 1151, 1155, 1268, 1269, 1563, 1580, 1581, 1600, 1608, 1655, 1676, 1680, 1691, 1713, 1714, 1727, 1728, 1731, 1733], "dim": [19, 24, 42, 67, 69, 70, 71, 73, 89, 90, 91, 139, 159, 162, 165, 166, 167, 168, 169, 170, 184, 215, 219, 236, 267, 268, 269, 270, 271, 272, 276, 277, 308, 334, 346, 362, 364, 365, 366, 369, 383, 384, 385, 386, 389, 390, 406, 415, 423, 432, 443, 444, 446, 457, 458, 464, 465, 466, 467, 468, 469, 470, 471, 488, 489, 492, 494, 497, 502, 503, 505, 510, 515, 524, 529, 542, 557, 558, 561, 562, 563, 564, 566, 568, 588, 590, 591, 592, 594, 604, 605, 606, 632, 633, 635, 663, 670, 678, 685, 687, 698, 700, 759, 760, 761, 762, 763, 772, 778, 797, 798, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 818, 820, 821, 837, 848, 858, 866, 867, 868, 869, 872, 916, 926, 927, 947, 951, 961, 963, 964, 974, 982, 994, 996, 997, 999, 1002, 1004, 1005, 1012, 1013, 1014, 1015, 1016, 1024, 1051, 1052, 1053, 1056, 1060, 1062, 1067, 1087, 1106, 1122, 1123, 1124, 1149, 1151, 1163, 1165, 1166, 1195, 1196, 1212, 1215, 1224, 1232, 1237, 1238, 1239, 1249, 1251, 1253, 1257, 1268, 1269, 1277, 1319, 1385, 1391, 1395, 1397, 1404, 1405, 1416, 1419, 1422, 1466, 1473, 1476, 1563, 1564, 1569, 1570, 1575, 1576, 1577, 1580, 1581, 1600, 1603, 1605, 1608, 1610, 1617, 1620, 1622, 1623, 1624, 1625, 1628, 1636, 1640, 1641, 1642, 1643, 1646, 1647, 1655, 1656, 1657, 1658, 1659, 1662, 1663, 1668, 1676, 1677, 1690, 1691, 1702, 1711, 1713, 1714, 1727, 1728, 1730, 1736], "notabl": [19, 1679], "brief": [20, 1319, 1688, 1724], "introduct": [20, 717, 1319, 1676, 1680, 1689, 1697, 1706, 1713, 1724, 1732], "mpi": [20, 1319], "gloo": [20, 36, 1319, 1700, 1704, 1724], "recv": [20, 1319, 1725], "broadcast": [20, 23, 24, 40, 52, 151, 353, 355, 357, 465, 467, 469, 516, 580, 581, 582, 583, 584, 585, 586, 592, 614, 644, 649, 652, 656, 657, 658, 659, 681, 697, 774, 775, 781, 786, 826, 827, 828, 829, 837, 839, 851, 861, 919, 920, 927, 940, 944, 949, 950, 952, 955, 963, 984, 989, 990, 1001, 1006, 1009, 1017, 1020, 1051, 1070, 1122, 1195, 1257, 1319, 1328, 1464, 1472, 1562, 1564, 1626, 1641, 1646, 1670, 1675, 1679, 1689, 1690, 1700, 1713, 1728], "all_reduc": [20, 37, 1319], "all_gath": 20, "scatter": [20, 23, 40, 465, 467, 469, 1053, 1677, 1702, 1714, 1724], "reduce_scatt": 20, "all_to_al": 20, "v1": [20, 40, 963, 1464, 1674, 1700, 1724], "init_method": [20, 1319, 1724], "adher": [20, 1679], "schema": [20, 1676, 1677, 1679, 1683, 1713], "some_fil": 20, "machine_nam": 20, "share_folder_nam": 20, "tcpstore": [20, 35], "past": [20, 42, 741, 758, 1319, 1702], "thumb": 20, "infiniband": [20, 1319, 1724], "interconnect": 20, "gpudirect": 20, "ethernet": 20, "node": [20, 23, 26, 28, 34, 35, 42, 728, 909, 1039, 1053, 1319, 1429, 1480, 1685, 1699, 1713, 1716, 1717, 1724, 1725, 1726, 1737], "encount": [20, 41, 42, 1319, 1676, 1679, 1681, 1698, 1709, 1716], "ip": [20, 35], "ib": 20, "upcom": [20, 1695], "nccl_socket_ifnam": 20, "eth0": 20, "gloo_socket_ifnam": 20, "comma": [20, 781, 1679], "eth1": 20, "eth2": 20, "eth3": 20, "imper": 20, "nccl_debug": 20, "info": [20, 26, 29, 33, 689, 690, 691, 925, 936, 938, 939, 943, 956, 985, 1675, 1677, 1701, 1713, 1716], "nccl_debug_subsi": 20, "coll": 20, "hang": [20, 21, 23, 1319, 1700], "topolog": [20, 26, 42, 1713], "effort": [20, 1724], "socket": [20, 1688, 1724], "nccl_socket_nthread": 20, "nccl_nsocks_perthread": 20, "cloud": [20, 1732], "aw": [20, 27, 686], "gcp": 20, "primit": [20, 23, 35, 40, 1676, 1678, 1680, 1698, 1707, 1713, 1724], "kind": [20, 29, 42, 914, 1320, 1474, 1674, 1683, 1701, 1708, 1713, 1716, 1719, 1728, 1730], "connect": [20, 35, 1044, 1045, 1046, 1047, 1048, 1049, 1092, 1093, 1094, 1095, 1096, 1097, 1144, 1688, 1724], "advantag": [20, 35, 36, 1033, 1077, 1702, 1724, 1727], "redund": [20, 40, 797, 798, 800, 802, 816, 818, 1625], "averag": [20, 23, 641, 643, 686, 895, 1021, 1022, 1023, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1050, 1052, 1060, 1070, 1076, 1082, 1083, 1084, 1085, 1089, 1090, 1091, 1107, 1108, 1116, 1119, 1120, 1121, 1122, 1123, 1130, 1147, 1148, 1155, 1164, 1172, 1173, 1174, 1180, 1181, 1182, 1185, 1186, 1196, 1210, 1225, 1234, 1235, 1248, 1256, 1319, 1328, 1359, 1360, 1361, 1362, 1430, 1431, 1433, 1434, 1435, 1437, 1443, 1444, 1447, 1503, 1504, 1646, 1700, 1718], "elimin": [20, 42, 562, 1657, 1658, 1710], "thrash": 20, "recurr": [20, 910, 1039, 1053, 1068, 1069, 1086, 1131, 1353, 1354, 1387, 1413, 1444, 1699], "use_distribut": 20, "datetim": [20, 1687], "timedelta": [20, 1687], "1800": 20, "group_nam": [20, 32], "pg_option": 20, "url": [20, 35, 640, 1674, 1686, 1724], "discov": [20, 1724], "encod": [20, 26, 32, 35, 42, 942, 966, 1032, 1033, 1159, 1160, 1161, 1162, 1163, 1319, 1611, 1612, 1613, 1615, 1616, 1676, 1679, 1680, 1701, 1711, 1716, 1725, 1727], "ucc": 20, "lowercas": 20, "deadlock": [20, 1319], "job": [20, 26, 28, 29, 31, 32, 34, 35, 36, 37, 1319, 1452, 1458, 1705, 1718, 1732], "exchang": [20, 35, 690, 768, 1699, 1713], "nccl_blocking_wait": 20, "nccl_async_error_handl": [20, 1699], "throw": [20, 21, 40, 41, 42, 145, 173, 278, 283, 493, 495, 565, 880, 895, 935, 985, 1116, 1319, 1321, 1322, 1413, 1422, 1471, 1660, 1691, 1696, 1710, 1724, 1733], "abort": [20, 1699], "crash": [20, 28, 35, 1688, 1696, 1724, 1726, 1732], "caught": [20, 1319, 1688], "littl": [20, 1701, 1726], "progress": [20, 23, 26, 36, 38, 689, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1443, 1444, 1445, 1446, 1447, 1661, 1674, 1686], "watch": 20, "dog": 20, "deprec": [20, 26, 35, 36, 361, 555, 636, 666, 667, 732, 736, 780, 841, 892, 895, 949, 952, 983, 985, 986, 993, 1032, 1033, 1050, 1052, 1075, 1076, 1082, 1083, 1107, 1108, 1116, 1119, 1120, 1121, 1123, 1130, 1147, 1148, 1164, 1169, 1170, 1185, 1186, 1196, 1225, 1248, 1256, 1281, 1282, 1283, 1315, 1319, 1378, 1379, 1380, 1416, 1422, 1475, 1558, 1625, 1629, 1633, 1648, 1676, 1681, 1688, 1697, 1718, 1729, 1733], "processgroupopt": 20, "processgroupnccl": [20, 1700], "is_high_priority_stream": 20, "is_initi": 20, "is_mpi_avail": 20, "is_nccl_avail": 20, "is_torchelastic_launch": 20, "elast": [20, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 1675], "aka": [20, 641, 1077, 1696, 1730], "torchelast": [20, 22, 26, 27, 28, 29, 32, 34, 35, 36, 37, 38], "torchelastic_run_id": [20, 36], "proxi": [20, 1719], "rendezv": [20, 22, 26, 32, 34, 38, 1700, 1724], "null": [20, 27, 29, 32], "discoveri": [20, 35, 1716], "reachabl": 20, "multicast": 20, "23456": 20, "clean": [20, 26, 42, 721, 1674, 1688, 1716], "fcntl": 20, "nf": 20, "init": [20, 26, 28, 40, 895, 1116, 1124, 1143, 1415, 1675, 1679, 1681, 1696, 1701, 1705, 1706], "brand": 20, "succe": [20, 35, 1701, 1712], "previou": [20, 35, 42, 506, 717, 826, 848, 905, 965, 981, 1068, 1086, 1131, 1319, 1353, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1549, 1625, 1685, 1696, 1699, 1706, 1712, 1719, 1726], "unexpect": [20, 25, 42, 687, 832, 834, 895, 1116, 1620, 1676, 1696, 1701, 1709], "auto": [20, 1032, 1033, 1679, 1713, 1732], "unsuccess": 20, "mnt": 20, "sharedfil": 20, "port": [20, 26, 34, 35, 36, 1704], "enum": [20, 1713, 1719, 1724], "backend_str": 20, "uppercas": 20, "classmethod": [20, 35, 689, 1059, 1060, 1155, 1325, 1331, 1332, 1333, 1338, 1339, 1349, 1357, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1428, 1485, 1506, 1679, 1680, 1701, 1719, 1724, 1729, 1738], "register_backend": [20, 1724], "func": [20, 42, 627, 628, 629, 630, 631, 632, 633, 634, 635, 637, 638, 870, 898, 910, 911, 913, 1213, 1667, 1679, 1695, 1701, 1724, 1726, 1738], "3rd": [20, 35, 568, 1459, 1697], "processgroup": [20, 23, 40, 1319], "four": [20, 940, 1045, 1701, 1703, 1724, 1726], "get_backend": [20, 35], "get_rank": [20, 1155], "uniqu": [20, 26, 32, 35, 36, 37, 465, 469, 886, 930, 931, 935, 941, 942, 944, 953, 955, 957, 958, 997, 1004, 1629, 1658, 1674, 1676, 1686, 1701, 1716, 1718, 1724, 1725, 1726, 1727, 1732], "get_world_s": 20, "filestor": [20, 35], "hashstor": 20, "client": [20, 23, 35, 1716], "insert": [20, 24, 41, 42, 1117, 1118, 1126, 1319, 1340, 1480, 1540, 1578, 1581, 1590, 1600, 1622, 1659, 1676, 1685, 1699, 1714, 1719], "establish": [20, 35, 1696], "host_nam": 20, "hostnam": [20, 26, 35, 1718], "listen": 20, "is_mast": 20, "300": [20, 26, 972, 1033, 1414, 1715], "wait_for_work": 20, "server_stor": 20, "127": [20, 1490, 1491, 1493, 1494, 1513, 1514, 1527, 1528, 1529, 1530, 1531, 1690, 1719, 1732], "1234": [20, 35, 872], "client_stor": 20, "first_kei": 20, "first_valu": 20, "underli": [20, 23, 24, 26, 40, 42, 52, 266, 281, 331, 355, 357, 426, 427, 428, 429, 436, 451, 472, 475, 507, 508, 509, 534, 608, 689, 865, 869, 895, 966, 1016, 1256, 1341, 1350, 1560, 1645, 1659, 1676, 1679, 1691, 1699, 1702, 1704, 1717, 1724, 1731], "hashmap": 20, "file_nam": [20, 1674, 1686, 1716], "store1": 20, "store2": 20, "prefixstor": 20, "old": [20, 25, 42, 832, 1056, 1427, 1459, 1574, 1673, 1676, 1696, 1699, 1701, 1712, 1732], "whose": [20, 24, 40, 42, 494, 624, 666, 681, 768, 781, 786, 834, 839, 848, 851, 857, 895, 911, 919, 965, 981, 984, 1017, 1116, 1319, 1423, 1469, 1538, 1593, 1642, 1679, 1696, 1701, 1703, 1716, 1732, 1734], "quantiti": [20, 930, 931, 958, 1082, 1394, 1395, 1397, 1398, 1400, 1403, 1404, 1405, 1406, 1459, 1703], "compare_set": 20, "arg2": 20, "expected_valu": 20, "desired_valu": 20, "second_valu": 20, "overload": [20, 42, 568, 1678, 1679, 1683], "bad_kei": 20, "num_kei": 20, "written": [20, 28, 40, 640, 741, 1053, 1446, 1676, 1678, 1685, 1696, 1700, 1701, 1706, 1711, 1713, 1716, 1729, 1732], "destruct": [20, 1687, 1724, 1726], "delete_kei": 20, "successfulli": [20, 26, 32, 901, 1586, 1688, 1706, 1711, 1724], "set_timeout": 20, "grain": [20, 1537, 1696, 1713], "plai": 20, "new_group": [20, 40, 1155], "opaqu": [20, 25, 688, 717, 718, 832], "pattern": [20, 725, 1053, 1413, 1540, 1607, 1676, 1679, 1696, 1699, 1701, 1702, 1704, 1711, 1720, 1721], "concurr": [20, 23, 1698, 1699, 1724, 1725], "enqueu": [20, 41, 690, 691, 692, 1699, 1725], "dst": [20, 1674, 1716], "destin": [20, 29, 32, 40, 164, 370, 371, 555, 698, 699, 837, 895, 983, 1003, 1004, 1116, 1677, 1724, 1725, 1729], "unspecifi": [20, 434, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1400, 1403, 1404, 1502, 1503, 1504, 1507, 1608, 1727, 1732], "sender": [20, 1726], "isend": 20, "irecv": 20, "is_complet": 20, "finish": [20, 26, 32, 33, 35, 37, 41, 1699, 1700, 1712, 1718, 1724, 1726], "async_op": 20, "onto": [20, 40, 744, 902, 905, 966, 1389, 1674, 1688, 1699, 1702, 1706], "get_futur": [20, 1319], "regard": [20, 1047, 1048, 1049, 1059, 1060, 1204, 1205, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1676, 1726], "wait_stream": [20, 690, 691, 1699], "default_stream": 20, "add_": [20, 176, 1677, 1689, 1697, 1727], "101": [20, 1024], "overwrot": 20, "sent": [20, 721, 1679, 1688, 1708, 1724, 1725, 1726], "broadcast_object_list": 20, "object_list": 20, "picklabl": [20, 1716], "current_devic": [20, 703, 704, 710, 711, 727, 731, 733, 734, 735, 737, 739, 740, 741, 745, 746, 747, 757, 758, 1730], "responsibl": 20, "set_devic": [20, 40, 1319, 1724, 1730], "insecur": [20, 966], "malici": [20, 966, 1716], "reduceop": 20, "bitwis": [20, 648, 650, 651, 653, 1680, 1709, 1720], "int64": [20, 146, 163, 268, 276, 347, 595, 647, 660, 782, 795, 796, 833, 1196, 1410, 1553, 1557, 1558, 1578, 1611, 1612, 1613, 1615, 1616, 1699, 1727, 1729, 1730, 1733, 1739], "1j": [20, 593, 679, 680, 891, 1566, 1567, 1664, 1696, 1703, 1711], "2j": [20, 593, 679, 680, 1566, 1567, 1593, 1664, 1696], "tensor_list": 20, "all_gather_object": 20, "obj": [20, 42, 610, 707, 881, 882, 901, 906, 1574, 1677, 1712, 1716], "pickabl": 20, "popul": [20, 24, 33, 40, 41, 42, 290, 447, 455, 456, 997, 1013, 1699], "gather_object": 20, "gather_list": 20, "object_gather_list": 20, "scatter_list": 20, "scatter_object_list": 20, "scatter_object_output_list": 20, "scatter_object_input_list": 20, "output_list": 20, "input_list": 20, "output_tensor_list": 20, "input_tensor_list": 20, "13": [20, 605, 670, 778, 782, 826, 848, 858, 899, 985, 1040, 1064, 1065, 1113, 1150, 1208, 1209, 1603, 1633, 1640, 1668, 1676, 1680, 1713, 1714, 1727], "15": [20, 42, 568, 778, 838, 848, 858, 917, 931, 1040, 1113, 1114, 1414, 1467, 1603, 1644, 1668, 1676, 1677, 1680, 1713, 1714, 1727], "17": [20, 580, 892, 947, 1113, 1603, 1676, 1713, 1727], "18": [20, 276, 398, 580, 782, 848, 892, 967, 983, 1113, 1676, 1713, 1727], "21": [20, 24, 580, 666, 763, 953, 1475, 1646, 1676, 1727], "22": [20, 24, 276, 568, 967, 1314, 1414, 1676, 1710, 1727], "23": [20, 465, 967, 1676, 1727], "31": [20, 652, 1031, 1111, 1314, 1713], "33": [20, 895, 1044, 1045, 1046, 1048, 1049, 1114, 1116, 1188, 1190, 1191, 1193, 1331, 1332, 1333, 1334, 1335, 1336, 1365, 1676, 1713], "34": 20, "35": [20, 953, 1035, 1036, 1080, 1081, 1155, 1475], "36": [20, 276, 824, 848], "input_split": 20, "output_split": 20, "5j": 20, "6j": 20, "7j": 20, "8j": 20, "9j": 20, "10j": 20, "11j": 20, "12j": 20, "13j": 20, "14j": 20, "15j": 20, "16j": 20, "monitored_barri": 20, "wait_all_rank": 20, "purpose": 20, "band": 20, "bor": 20, "bxor": 20, "all_reduce_multigpu": 20, "reduce_op": 20, "mention": [20, 1674, 1678, 1679, 1690, 1699, 1706, 1713, 1727, 1731], "broadcast_multigpu": 20, "reduce_multigpu": 20, "all_gather_multigpu": 20, "reduce_scatter_multigpu": 20, "distributed_test": 20, "dev_idx": 20, "src_tensor": 20, "resid": [20, 40, 41, 151, 244, 292, 966, 1319, 1699, 1717, 1724], "dst_tensor": 20, "cpp_extens": [20, 1675, 1701], "cpp_c10d_extens": 20, "c10d": [20, 26, 34, 36, 38, 1319, 1700], "torchrun": [20, 22, 27, 34, 38], "benefiti": 20, "nproc_per_nod": [20, 27, 34, 36], "num_gpus_you_hav": 20, "your_training_script": [20, 34, 36], "arg3": 20, "192": [20, 568, 1713], "168": 20, "nnode": [20, 34, 36], "node_rank": 20, "offer": [20, 40, 1319, 1660, 1699, 1704, 1716], "local_rank": [20, 26, 28, 33, 36, 38, 1155], "local_process_rank": 20, "argpars": [20, 36, 1699], "parser": [20, 36, 1699], "argumentpars": [20, 36, 1699], "add_argu": [20, 36, 1699], "parse_arg": [20, 27, 36, 38, 1699, 1713], "suppos": [20, 42, 892, 1460, 1633, 1727], "output_devic": [20, 23, 36, 1053, 1155, 1277, 1319], "use_env": [20, 36, 38], "adjust": [20, 23, 24, 40, 1698, 1720], "launcher": [20, 36], "filesystem": [20, 1674, 1716], "12042": 20, "wrong": [20, 42, 626, 893, 896, 1700, 1708, 1712, 1713, 1715], "imagenet": [20, 1694], "inconsist": [20, 40, 595, 1558, 1701], "suit": [20, 1676, 1678, 1679, 1713, 1720, 1724], "faulti": 20, "acknowledg": [20, 1726], "group_gloo": 20, "29501": 20, "monitoredbarri": 20, "ms": [20, 32], "transport": [20, 1724], "598": 20, "2401": 20, "db00": 20, "eef0": 20, "1100": 20, "3560": [20, 1623, 1624, 1662, 1663], "1c05": 20, "25d": 20, "8594": 20, "torch_cpp_log_level": 20, "twolinlayernet": 20, "ddp": [20, 21, 23, 40, 1155, 1319, 1675, 1699, 1700, 1724], "i0607": 20, "739390": 20, "515217": 20, "logger": [20, 1736, 1737], "173": 20, "broadcast_buff": [20, 1319], "bucket_cap_byt": 20, "26214400": 20, "find_unused_paramet": [20, 1319, 1700], "gradient_as_bucket_view": [20, 1319], "is_multi_device_modul": 20, "num_parameter_tensor": 20, "total_parameter_size_byt": 20, "440": 20, "backend_nam": 20, "bucket_s": 20, "cuda_visible_devic": [20, 750, 1319, 1699], "module_nam": [20, 42, 1716], "nccl_ib_timeout": 20, "nccl_nthread": 20, "58": 20, "085681": 20, "544067": 20, "344": 20, "unused_parameter_s": 20, "40838608": 20, "5983335": 20, "4326421": 20, "comp": [20, 24], "4207652": 20, "085693": 20, "544066": 20, "42850427": 20, "3885553": 20, "2357981": 20, "2234674": 20, "enhanc": [20, 40, 1319], "unus": [20, 23, 42, 721, 735, 900, 906, 1078, 1319, 1676, 1678, 1679, 1699, 1700, 1704, 1716], "constraint": [20, 631, 717, 728, 1319, 1385, 1410, 1679, 1691, 1703, 1706, 1727], "qualifi": [20, 32, 42, 895, 1116, 1716], "went": [20, 42], "wasn": [20, 966, 1676], "va": 20, "lue": 20, "indirectli": 20, "outstand": [20, 1724], "stuck": [20, 26, 37], "uninform": 20, "root": [20, 28, 35, 36, 40, 42, 932, 933, 1444, 1573, 1618, 1685, 1696, 1716, 1724, 1725, 1727], "nontrivi": [20, 1699], "reveal": [20, 1700], "default_pg": 20, "opt": [20, 23, 906, 1448, 1449, 1455, 1460, 1676, 1703], "verifi": [20, 42, 637, 763, 1646, 1674, 1676, 1686, 1701, 1703, 1713, 1717], "longtensor": [20, 89, 90, 91, 270, 272, 274, 405, 424, 465, 467, 469, 604, 605, 837, 869, 916, 1007, 1059, 1060, 1119, 1204, 1205, 1250, 1421, 1578, 1603, 1614, 1635, 1643, 1670, 1730, 1733], "set_debug_level": 20, "set_debug_level_from_env": 20, "get_debug_level": 20, "torch_show_cpp_stacktrac": 20, "facilit": [21, 24, 690, 768, 1582, 1674, 1676, 1679, 1710], "uneven": [21, 23, 1319], "outlin": [21, 1717, 1725], "joinabl": [21, 23, 1319], "joinhook": 21, "throw_on_early_termin": [21, 1319], "hook": [21, 23, 40, 440, 628, 728, 895, 1053, 1116, 1315, 1316, 1317, 1318, 1319, 1341, 1350, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1407, 1416, 1419, 1675, 1692, 1700, 1701, 1705, 1716, 1719], "shadow": [21, 23, 1319, 1736, 1737], "notify_join_context": 21, "zeroredundancyoptim": [21, 23, 1319], "01": [21, 23, 37, 782, 824, 1102, 1228, 1229, 1314, 1348, 1373, 1430, 1432, 1434, 1444, 1445, 1452, 1458, 1503, 1504, 1544, 1677, 1694, 1705, 1715], "vacuou": 21, "inherit": [21, 1402, 1676, 1678, 1701, 1706, 1708], "join_hook": [21, 23, 1319], "join_devic": 21, "join_process_group": 21, "repeatedli": [21, 1699, 1727], "main_hook": 21, "post_hook": 21, "is_last_join": 21, "fault": [22, 26, 34, 35, 834], "toler": [22, 26, 34, 35, 42, 589, 637, 638, 884, 910, 911, 949, 952, 967, 993, 1436, 1676, 1734], "quickstart": 22, "agent": [22, 27, 28, 29, 32, 34, 36, 37, 1724], "expir": 22, "metric": [22, 731, 733, 739, 1459, 1687, 1706, 1718, 1732], "kubernet": 22, "distributedoptim": [23, 1319, 1724, 1725], "rref": [23, 1319, 1679, 1717, 1725], "optimizer_class": 23, "params_rref": 23, "get_gradi": [23, 1724, 1725], "multithread": [23, 1699], "dist_autograd": [23, 1319, 1724, 1725], "rpc": [23, 41, 1319, 1675, 1679, 1717, 1725, 1726], "context_id": [23, 1319, 1724, 1725], "rref1": [23, 1724, 1725], "worker1": [23, 41, 1319, 1724, 1725], "rref2": [23, 1724, 1725], "to_her": [23, 1319, 1724, 1725, 1726], "dist_optim": [23, 1319, 1725], "postlocalsgdoptim": 23, "afer": 23, "localsgd": 23, "model_averag": 23, "post_localsgd_hook": 23, "postlocalsgdst": 23, "subgroup": 23, "start_localsgd_it": 23, "warmup_step": 23, "local_optim": 23, "periodicmodelaverag": 23, "intra": [23, 1698, 1700, 1717], "unnecessari": [23, 1415, 1679, 1699, 1701, 1711, 1716, 1731], "parameters_as_bucket_view": 23, "overlap_with_ddp": 23, "peak": [23, 731, 733, 739, 745, 746, 747, 1319, 1452, 1458, 1717], "consumpt": [23, 1420, 1727, 1732], "greedi": 23, "partit": [23, 40, 1024, 1646, 1717, 1725, 1726], "registr": [23, 41, 725, 1319, 1386, 1389, 1683, 1716], "offset": [23, 26, 180, 181, 182, 183, 294, 472, 508, 608, 768, 769, 770, 771, 834, 929, 1060, 1205, 1319, 1339, 1544, 1545, 1609, 1650, 1652, 1677, 1679], "intact": [23, 1724], "ddp_zero_hook": 23, "disjointli": 23, "trail": [23, 534, 1412, 1414, 1694, 1697, 1701], "wari": 23, "static_graph": [23, 1319], "third": [23, 24, 779, 781, 985, 1024, 1031, 1046, 1049, 1111, 1458, 1676, 1699, 1706, 1716, 1718], "add_param_group": [23, 1389, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1443, 1444, 1445, 1446, 1447], "param_group": [23, 40, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1440, 1443, 1444, 1445, 1446, 1447, 1454, 1457], "frozen": [23, 899, 904, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1443, 1444, 1445, 1446, 1447, 1680, 1712], "trainabl": [23, 728, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1443, 1444, 1445, 1446, 1447, 1701], "consolidate_state_dict": 23, "consolid": [23, 40, 1717], "pertain": 23, "preced": [23, 26, 1317, 1458, 1680, 1698, 1715, 1719], "parameteriz": 24, "tensorflow": [24, 1444, 1696, 1732], "backpropag": [24, 638, 1445, 1475, 1702], "random": [24, 26, 35, 36, 42, 43, 109, 646, 714, 715, 720, 729, 730, 748, 749, 752, 753, 847, 871, 967, 988, 1028, 1039, 1061, 1068, 1086, 1134, 1206, 1256, 1261, 1314, 1353, 1385, 1391, 1397, 1398, 1405, 1406, 1423, 1465, 1549, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1579, 1591, 1630, 1674, 1675, 1677, 1694, 1703, 1709, 1713, 1732], "surrog": 24, "likelihood": [24, 1024, 1070, 1123, 1130, 1210, 1248, 1256], "ratio": [24, 26, 568, 1064, 1065, 1208, 1209, 1677], "reinforc": [24, 1145, 1265], "seen": [24, 42, 176, 663, 998, 1047, 1048, 1049, 1147, 1237, 1238, 1239, 1459, 1676, 1696, 1699, 1713], "polici": [24, 26, 28, 40, 1452, 1458], "reparameter": [24, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1407, 1408, 1409, 1419], "trick": [24, 633, 1033, 1215, 1696, 1703, 1705], "autoencod": 24, "whilst": [24, 1699], "densiti": [24, 256, 856, 857, 1677, 1728], "log_prob": [24, 1024, 1039, 1197, 1677], "theta": [24, 1178, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446, 1677], "alpha": [24, 52, 53, 54, 55, 60, 61, 62, 63, 64, 65, 106, 107, 267, 268, 504, 511, 512, 513, 514, 580, 581, 584, 585, 586, 644, 725, 726, 852, 866, 1028, 1038, 1058, 1104, 1143, 1179, 1187, 1202, 1203, 1213, 1231, 1263, 1337, 1363, 1368, 1430, 1444, 1604, 1607, 1621, 1626, 1627, 1677, 1696, 1701, 1713], "partial": [24, 26, 35, 40, 42, 728, 770, 848, 941, 942, 943, 986, 1112, 1113, 1114, 1240, 1241, 1242, 1319, 1396, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1511, 1512, 1513, 1514, 1515, 1517, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1609, 1679, 1680, 1690, 1696, 1701, 1703, 1713, 1721, 1726, 1734], "pi": [24, 128, 331, 593, 654, 852, 853, 946, 1066, 1130, 1211, 1256, 1450, 1451, 1469, 1625, 1678, 1679, 1716, 1728], "reward": 24, "ascent": 24, "prob": [24, 1677], "policy_network": 24, "next_stat": 24, "rsampl": 24, "parameter": [24, 331, 407, 901, 1692, 1727], "has_rsampl": 24, "batch_shap": 24, "event_shap": 24, "validate_arg": 24, "arg_constraint": 24, "cdf": 24, "cumul": [24, 759, 760, 761, 762, 763, 974, 1034, 1035, 1036, 1066, 1089, 1090, 1091, 1155, 1211], "mass": 24, "enumerate_support": 24, "discret": [24, 39, 434, 797, 798, 799, 800, 802, 803, 804, 805, 806, 807, 810, 811, 816, 818, 1215, 1732, 1735], "cardin": [24, 998], "univari": 24, "singleton": [24, 209, 1088, 1659, 1697], "cartesian": [24, 662, 998, 1469], "itertool": [24, 662, 675], "_instanc": 24, "icdf": 24, "perplex": 24, "sample_shap": 24, "sample_n": 24, "set_default_validate_arg": 24, "mimic": [24, 1458], "stddev": 24, "varianc": [24, 686, 1034, 1035, 1036, 1061, 1070, 1079, 1080, 1081, 1089, 1090, 1091, 1098, 1099, 1100, 1155, 1206, 1210, 1443, 1444, 1546, 1555, 1556, 1662, 1663, 1694, 1706], "exp_famili": 24, "famili": 24, "p_": [24, 666, 987, 1446], "langl": 24, "rangl": 24, "denot": [24, 42, 686, 915, 934, 940, 953, 963, 1044, 1045, 1082, 1386, 1389, 1446, 1611, 1612, 1613, 1615, 1616, 1664, 1703, 1722, 1725, 1727], "carrier": 24, "analyt": [24, 637, 638], "bregman": 24, "courtesi": 24, "frank": 24, "nielsen": 24, "richard": 24, "nock": 24, "logit": [24, 345, 1033, 1186, 1196, 1215, 1677, 1728], "70": [24, 953, 1475, 1691], "odd": [24, 802, 803, 804, 812, 813, 814, 1188, 1189, 1190], "lower_bound": 24, "upper_bound": 24, "has_enumerate_support": 24, "param_shap": 24, "concentration1": 24, "concentration0": 24, "concentr": 24, "1046": 24, "1st": [24, 1697], "2nd": [24, 568, 1124, 1150, 1251, 1697], "greaterthan": 24, "total_count": 24, "71": 24, "trial": 24, "integergreaterthan": 24, "ldot": [24, 926, 934, 965, 981, 998, 1088, 1109, 1110, 1111, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446], "dimension": [24, 465, 467, 616, 617, 618, 655, 662, 674, 768, 770, 771, 781, 797, 798, 800, 801, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 815, 816, 818, 820, 822, 823, 834, 848, 857, 858, 859, 927, 932, 933, 934, 935, 960, 965, 981, 990, 998, 1024, 1041, 1042, 1043, 1052, 1053, 1059, 1060, 1088, 1106, 1123, 1137, 1138, 1139, 1140, 1141, 1142, 1149, 1151, 1155, 1171, 1196, 1248, 1251, 1282, 1283, 1384, 1421, 1549, 1611, 1612, 1613, 1614, 1615, 1616, 1625, 1636, 1639, 1640, 1646, 1679, 1694, 1697, 1703, 1727, 1729, 1730, 1733, 1735], "unnorm": [24, 1052, 1186, 1196, 1215], "likewis": 24, "25": [24, 448, 538, 539, 540, 664, 856, 962, 967, 1062, 1119, 1121, 1124, 1314, 1319, 1414, 1436, 1458, 1476, 1661, 1676, 1728], "independentconstraint": 24, "simplex": 24, "loc": [24, 966], "lorentz": 24, "3214": 24, "width": [24, 855, 856, 857, 1030, 1031, 1045, 1046, 1048, 1049, 1085, 1110, 1111, 1123, 1150, 1168, 1224, 1281, 1372, 1378, 1537, 1690], "df": 24, "chi": 24, "continuous_bernoulli": 24, "lim": [24, 892], "499": 24, "501": 24, "2538": [24, 926], "pervas": 24, "loaiza": 24, "ganem": 24, "cunningham": 24, "jp": 24, "ab": [24, 45, 46, 577, 664, 781, 926, 947, 948, 950, 951, 964, 967, 1086, 1135, 1162, 1165, 1167, 1253, 1419, 1422, 1459, 1465, 1469, 1677, 1679, 1689, 1690, 1699, 1706, 1714, 1727, 1733], "1907": 24, "06845": 24, "8954": 24, "greaterthaneq": 24, "df1": 24, "df2": 24, "fisher": 24, "snedecor": 24, "2453": 24, "degre": [24, 686, 764, 895, 932, 933, 1116, 1125, 1164, 1319, 1550, 1570, 1677, 1703], "freedom": [24, 686, 1703], "0124": 24, "half_cauchi": 24, "half_norm": 24, "base_distribut": 24, "reinterpreted_batch_ndim": 24, "reinterpret": [24, 451], "diagon": [24, 179, 215, 547, 548, 549, 550, 655, 682, 686, 767, 768, 769, 771, 780, 781, 794, 840, 924, 936, 938, 941, 953, 957, 1253, 1609, 1644, 1648, 1649, 1650, 1651, 1652, 1677, 1701, 1714, 1731], "multivari": [24, 1728], "mvn": 24, "scale_tril": 24, "diag": [24, 780, 930, 931, 958, 1465, 1609, 1629, 1630, 1633, 1677], "diagn": 24, "1729": [24, 1706], "lkj_choleski": 24, "lkj": 24, "matric": [24, 215, 581, 584, 644, 656, 657, 666, 667, 668, 669, 768, 840, 915, 924, 925, 926, 928, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 944, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 957, 958, 959, 967, 975, 983, 985, 987, 1001, 1067, 1178, 1212, 1384, 1389, 1463, 1465, 1475, 1590, 1604, 1606, 1607, 1629, 1630, 1633, 1648, 1649, 1651, 1677, 1689, 1703, 1727, 1733], "eta": [24, 1430, 1432, 1445], "propot": 24, "det": [24, 932, 933, 954, 975, 1677], "lkjcorr": 24, "onion": 24, "l": [24, 645, 654, 660, 667, 668, 780, 781, 852, 853, 895, 914, 924, 925, 930, 931, 932, 933, 937, 941, 942, 985, 987, 1029, 1032, 1033, 1034, 1044, 1052, 1055, 1056, 1063, 1068, 1076, 1077, 1079, 1082, 1083, 1086, 1098, 1107, 1109, 1116, 1118, 1122, 1123, 1131, 1147, 1164, 1165, 1167, 1328, 1353, 1395, 1404, 1412, 1414, 1436, 1578, 1633, 1677, 1679, 1696, 1732], "3x3": [24, 763, 1646], "3516": 24, "9361": 24, "1899": [24, 999], "4748": 24, "8593": 24, "vine": 24, "lewandowski": 24, "dorota": 24, "kurowicka": 24, "harri": 24, "joe": 24, "corrcholeski": 24, "log_norm": 24, "lowrank_multivariate_norm": 24, "cov_factor": 24, "cov_diag": 24, "covari": [24, 657, 682, 686, 1034, 1035, 1036, 1155, 1465], "covariance_matrix": 24, "2102": 24, "5429": [24, 1648], "woodburi": 24, "lemma": 24, "formula": [24, 43, 619, 621, 645, 654, 781, 852, 853, 920, 987, 988, 1130, 1181, 1182, 1269, 1361, 1362, 1446, 1545, 1701, 1703, 1718, 1723], "capacit": 24, "precision_matrix": 24, "mixture_same_famili": 24, "mixture_distribut": 24, "component_distribut": 24, "rightmost": [24, 657, 856, 857, 1679], "gaussian": [24, 1066, 1070, 1145, 1210, 1211, 1265, 1728], "gmm": 24, "modl": 24, "bivari": 24, "categori": [24, 28, 1007, 1679, 1681, 1713, 1720, 1730], "innermost": [24, 848, 857, 1578], "1338": 24, "multivariate_norm": 24, "mathbf": [24, 915, 1385, 1416, 1419, 1445], "sigma": [24, 128, 331, 1033, 1067, 1068, 1069, 1086, 1087, 1145, 1146, 1212, 1265, 1353, 1385, 1416, 1677], "triangular": [24, 667, 668, 669, 924, 925, 931, 933, 941, 942, 949, 952, 953, 955, 957, 1253, 1452, 1475, 1633, 1648, 1649, 1650, 1651, 1652], "decomposit": [24, 42, 667, 840, 924, 925, 930, 931, 932, 933, 934, 936, 941, 942, 943, 944, 949, 953, 954, 958, 959, 983, 985, 987, 1384, 1463, 1465, 1469, 1475, 1629, 1630], "positivedefinit": 24, "lowercholeski": 24, "negative_binomi": 24, "stop": [24, 26, 35, 36, 595, 721, 893, 967, 1039, 1410, 1459, 1558, 1676, 1679, 1724], "halfopeninterv": 24, "mu": [24, 331, 1444, 1446], "one_hot_categor": 24, "onehot": 24, "5623": 24, "nonneg": [24, 1165, 1465, 1630, 1728], "pmf": 24, "mathrm": [24, 646, 932, 933, 934, 935, 946, 1034, 1035, 1036, 1071, 1079, 1080, 1081, 1088, 1130, 1155, 1384, 1433, 1434, 1435, 1445, 1546, 1728], "relaxed_bernoulli": 24, "temperatur": [24, 1215], "parametr": [24, 1386, 1393, 1416, 1417, 1692, 1701], "relax": [24, 910, 911, 1389, 1719, 1734], "reparametriz": 24, "99": [24, 906, 1444, 1676], "2951": [24, 996], "3442": 24, "8918": 24, "9021": 24, "maddison": 24, "2017": [24, 1159, 1161, 1163, 1610, 1712], "reparametr": [24, 1215, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1401], "jang": 24, "relaxed_categor": 24, "1294": [24, 667], "2324": [24, 895, 1116], "3859": 24, "2523": 24, "student": 24, "transformed_distribut": 24, "composit": [24, 942, 1384, 1676, 1679, 1706], "basedistribut": 24, "dx": [24, 763, 1032, 1646, 1677, 1728], "dy": 24, "logist": [24, 1145, 1148, 1265, 1728], "sigmoidtransform": 24, "affinetransform": 24, "invert": [24, 42, 669, 886, 926, 935, 936, 942, 948, 955, 957, 960, 961, 975, 1112, 1113, 1114, 1648, 1677, 1724], "3418": 24, "upper": [24, 136, 137, 138, 520, 546, 655, 660, 667, 668, 669, 671, 795, 796, 855, 856, 924, 925, 931, 933, 941, 942, 953, 957, 1134, 1253, 1261, 1262, 1452, 1458, 1475, 1557, 1578, 1633, 1648, 1651, 1652, 1677, 1694, 1728, 1734], "von_mis": 24, "circular": [24, 1044, 1045, 1046, 1092, 1093, 1094, 1251], "von": 24, "mise": 24, "unconstrain": [24, 1389], "angl": [24, 614, 764, 928, 954, 975, 1102, 1348, 1469, 1550, 1593, 1677, 1727], "9777": 24, "radian": [24, 593, 614, 764, 1550, 1677], "nichola": 24, "simul": [24, 1484, 1486, 1719, 1722], "1979": 24, "152": [24, 568], "157": 24, "4784": [24, 1001], "symmetr": [24, 645, 654, 667, 668, 669, 802, 803, 804, 809, 811, 815, 816, 818, 852, 853, 914, 924, 925, 930, 931, 933, 937, 938, 939, 946, 949, 952, 958, 967, 993, 1384, 1389, 1458, 1487, 1502, 1633, 1677, 1719, 1722], "x_ij": 24, "zhenxun": 24, "yunan": 24, "wu": [24, 967], "haitao": 24, "chu": 24, "max_try_correct": 24, "algorithn": 24, "bartlett": [24, 645], "singular": [24, 926, 940, 941, 947, 949, 951, 952, 958, 959, 967, 975, 985, 993, 1385, 1389, 1465, 1629, 1630], "sigular": 24, "accordingli": [24, 40, 42, 388, 904, 1086, 1389, 1691, 1724], "kl_diverg": 24, "kullback": [24, 1082, 1225], "leibler": [24, 1082, 1225], "notimplementederror": [24, 1716, 1734], "register_kl": 24, "type_p": 24, "type_q": 24, "pairwis": [24, 1076, 1125, 1164], "kl_normal_norm": 24, "ambigu": [24, 42, 880, 1047, 1048, 1049, 1063, 1112, 1113, 1114, 1168, 1679], "runtimewarn": 24, "basep": 24, "derivedq": 24, "kl_version1": 24, "derivedp": 24, "baseq": 24, "kl_version2": 24, "tie": 24, "abstransform": 24, "cache_s": 24, "event_dim": 24, "pointwis": [24, 972, 973, 1082, 1689, 1697], "affin": [24, 425, 426, 427, 428, 429, 1034, 1035, 1036, 1071, 1079, 1080, 1081, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1155, 1178, 1342, 1344, 1345, 1346, 1487, 1699, 1706], "cattransform": 24, "tseq": 24, "functor": [24, 725, 726], "submatrix": 24, "x0": 24, "t0": [24, 848, 1430, 1678], "exptransform": 24, "identity_transform": 24, "composetransform": 24, "compos": [24, 42, 667, 669, 895, 1021, 1022, 1023, 1025, 1026, 1027, 1029, 1030, 1031, 1044, 1045, 1046, 1047, 1048, 1049, 1064, 1065, 1084, 1085, 1104, 1109, 1110, 1111, 1116, 1164, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1180, 1188, 1189, 1190, 1191, 1192, 1193, 1208, 1209, 1231, 1234, 1235, 1237, 1238, 1239, 1331, 1332, 1333, 1334, 1335, 1336, 1359, 1360, 1365, 1366, 1367, 1375, 1376, 1547, 1548, 1667, 1676, 1679, 1689, 1706, 1713, 1716, 1732], "corrcholeskytransform": 24, "uncontrain": 24, "euclidean": [24, 664, 1249], "x_i": [24, 671, 759, 760, 761, 762, 963, 970, 1106, 1125, 1149, 1151, 1164, 1233, 1268, 1472, 1608, 1646, 1664, 1728], "stickbreakingtransform": 24, "r_i": 24, "tanh": [24, 528, 615, 1066, 1068, 1069, 1086, 1087, 1115, 1131, 1133, 1157, 1211, 1243, 1274, 1353, 1358, 1677, 1689, 1690, 1694, 1714, 1721, 1727], "unsign": [24, 1722, 1730, 1733, 1734], "z_i": 24, "s_i": 24, "y_i": [24, 671, 759, 760, 761, 762, 963, 970, 1164, 1646, 1664, 1703], "sqrt": [24, 42, 331, 499, 682, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 861, 914, 998, 1034, 1035, 1036, 1037, 1044, 1045, 1046, 1047, 1048, 1049, 1066, 1068, 1069, 1071, 1079, 1080, 1081, 1084, 1085, 1086, 1087, 1088, 1101, 1103, 1131, 1133, 1155, 1211, 1353, 1389, 1431, 1432, 1433, 1434, 1437, 1443, 1444, 1546, 1573, 1677, 1689, 1694, 1695, 1696, 1714, 1727, 1728, 1734], "cumulativedistributiontransform": 24, "copula": 24, "base_dist": 24, "independenttransform": 24, "base_transform": 24, "log_abs_det_jacobian": 24, "lowercholeskytransform": 24, "powertransform": 24, "expon": [24, 223, 224, 235, 421, 422, 824, 831, 918, 948, 1024, 1104, 1249, 1472, 1549, 1677, 1730, 1733], "reshapetransform": 24, "in_shap": 24, "out_shap": 24, "softplustransform": 24, "tanhtransform": 24, "softmaxtransform": 24, "biject": 24, "hmc": 24, "act": [24, 26, 33, 1033, 1117, 1118, 1127, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1401, 1403, 1404, 1405, 1406, 1407, 1537, 1660, 1699, 1706, 1710], "stacktransform": 24, "stick": 24, "aris": [24, 42, 1696], "primarili": [24, 41, 388, 1505, 1687, 1719], "taken": [24, 40, 41, 42, 595, 802, 804, 827, 828, 1039, 1052, 1060, 1123, 1197, 1205, 1590, 1609, 1633, 1694, 1698, 1699, 1701, 1702, 1705, 1711, 1713, 1716, 1718], "memoiz": 24, "_call": 24, "_invers": 24, "codomain": [24, 1696], "iff": [24, 1713], "weaker": 24, "pseudoinvers": [24, 935, 952, 960], "monoton": [24, 660, 1115, 1243, 1578], "decreas": [24, 739, 940, 1055, 1056, 1057, 1061, 1129, 1411, 1412, 1445, 1452, 1459, 1685, 1710, 1730], "forward_shap": 24, "inverse_shap": 24, "corr_choleski": 24, "greater_than": 24, "greater_than_eq": 24, "integer_interv": 24, "less_than": 24, "lower_choleski": 24, "lower_triangular": 24, "nonnegative_integ": 24, "one_hot": [24, 1677, 1714], "positive_integ": 24, "positive_semidefinit": 24, "positive_definit": 24, "real_vector": 24, "unit_interv": 24, "is_discret": 24, "constrain": [24, 1152, 1679, 1706], "alia": [24, 29, 46, 47, 66, 142, 143, 361, 389, 390, 397, 577, 596, 597, 598, 599, 600, 601, 602, 619, 672, 678, 766, 773, 776, 788, 789, 790, 792, 793, 819, 841, 849, 850, 862, 863, 864, 873, 893, 895, 921, 922, 929, 945, 949, 952, 980, 991, 992, 1003, 1008, 1010, 1019, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1116, 1224, 1322, 1410, 1424, 1462, 1467, 1470, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1572, 1594, 1598, 1601, 1627, 1631, 1632, 1647, 1653, 1671, 1679, 1714, 1728, 1729, 1733], "_cat": 24, "dependent_properti": 24, "_dependentproperti": 24, "_greaterthan": 24, "_greaterthaneq": 24, "_independentconstraint": 24, "_integerinterv": 24, "_interv": 24, "half_open_interv": 24, "_halfopeninterv": 24, "_lessthan": 24, "_multinomi": 24, "_stack": 24, "constraintregistri": 24, "biject_to": 24, "transform_to": 24, "overparameter": 24, "rotat": [24, 1570, 1629], "hamiltonian": 24, "mont": 24, "carlo": 24, "invari": [24, 1410, 1614, 1726, 1727], "potential_energi": 24, "cheap": [24, 1024], "svi": 24, "fewer": [24, 588, 590, 591, 594, 915, 916, 982, 994, 996, 997, 999, 1002, 1012, 1015, 1070, 1195, 1473, 1610, 1628, 1642, 1697, 1711, 1734], "my_constraint": 24, "my_transform": 24, "myconstraintclass": 24, "my_factori": 24, "isinst": [24, 42, 882, 893, 1677, 1679, 1696, 1701, 1706, 1716, 1727], "mytransform": 24, "param1": [24, 1706], "param2": [24, 1706], "constraint_registri": 24, "my_registri": 24, "construct_transform": 24, "myconstraint": 24, "from_dlpack": [25, 610], "ext_tensor": [25, 832], "immut": [25, 832, 1679], "__dlpack__": [25, 832], "capsul": [25, 610, 832], "ndarrai": [25, 411, 609, 832, 833, 1611, 1612, 1613, 1614, 1615, 1616, 1639, 1713, 1732, 1734], "pycapsul": [25, 832], "to_dlpack": [25, 832], "t2": [25, 582, 583, 610, 832, 848, 1319, 1724, 1725], "style": [25, 42, 607, 775, 832, 1421, 1676, 1678, 1679, 1713, 1716, 1732], "dltensor": [25, 832], "0x7f6017d14300": [25, 832], "t3": [25, 832, 1725], "legaci": [25, 36, 1215, 1718, 1730], "idiomat": 25, "inde": [25, 1676, 1716, 1726], "plane": [26, 35, 768, 1021, 1022, 1023, 1025, 1026, 1027, 1029, 1030, 1031, 1044, 1045, 1046, 1047, 1048, 1049, 1064, 1065, 1084, 1085, 1088, 1104, 1109, 1110, 1111, 1172, 1173, 1174, 1175, 1176, 1177, 1180, 1181, 1182, 1188, 1189, 1190, 1191, 1192, 1193, 1208, 1209, 1231, 1234, 1235, 1237, 1238, 1239, 1331, 1332, 1333, 1334, 1335, 1336, 1359, 1360, 1361, 1362, 1365, 1366, 1367, 1375, 1376, 1419, 1547, 1548, 1570], "monitor": [26, 36, 37, 689, 1459, 1675, 1699, 1704], "unhealthi": 26, "tear": 26, "react": 26, "decentr": 26, "decis": [26, 35, 37, 42, 910, 1695], "diagram": [26, 35, 895, 1116, 1719, 1726], "role": [26, 27, 35, 36], "elasticag": 26, "deploy": [26, 35, 1675], "quad": [26, 1032, 1033, 1052, 1083, 1107, 1123, 1165], "group_result": 26, "is_fail": [26, 27], "exit_cod": 26, "return_valu": [26, 27, 33], "get_worker_group": 26, "workergroup": [26, 36], "mutabl": [26, 910, 1676, 1716, 1732], "implementor": 26, "defens": 26, "retri": [26, 28, 37, 739, 1724, 1726], "max_restart": [26, 27, 34, 36], "workerspec": [26, 27, 36, 37], "local_world_s": [26, 27, 36], "rdzv_handler": [26, 27, 35], "fn": [26, 27, 28, 32, 37, 40, 42, 895, 896, 907, 912, 1116, 1676, 1678, 1679, 1683, 1688, 1705, 1724], "entrypoint": [26, 28, 33, 36, 1688], "monitor_interv": [26, 27], "tee": [26, 33], "blueprint": 26, "spec": [26, 27, 37, 1721], "homogen": [26, 36], "rdzv": 26, "chose": [26, 1695], "consol": [26, 29, 32, 33, 36, 1732], "get_entrypoint_nam": 26, "__qualname__": 26, "workerst": 26, "unknown": [26, 1321, 1322, 1713, 1726], "unrecover": 26, "interrup": 26, "succeed": [26, 35, 985], "termin": [26, 35, 37, 42, 1436, 1688, 1724], "interrupt": [26, 1688], "temporarili": [26, 1696, 1713, 1718], "schedul": [26, 28, 34, 41, 1444, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1705, 1718], "uncaught": [26, 28], "unhandl": 26, "recov": [26, 624, 802, 954, 987, 1319, 1410, 1625, 1695, 1702, 1703, 1720], "is_run": 26, "global_rank": 26, "role_rank": [26, 36], "role_world_s": [26, 36], "pid": [26, 28, 36, 37, 1155, 1702, 1718], "local_elastic_ag": 26, "localelasticag": [26, 27, 37], "start_method": [26, 27, 33, 37, 1688], "exit_barrier_timeout": 26, "log_dir": [26, 33, 1687, 1732], "inter": [26, 28, 845, 1588, 1698, 1700, 1717, 1724], "safeti": [26, 1676, 1679, 1690], "advis": [26, 568, 595, 1708], "shared_queu": 26, "get_context": [26, 37, 1708], "nproc_per_process": 26, "foobar": [26, 28, 32, 33], "other_param": [26, 37], "usr": [26, 33, 35], "bin": [26, 33, 35, 255, 256, 647, 855, 856, 857, 1501, 1677, 1679, 1732], "trainer_arg": 26, "simpleelasticag": 26, "scaffold": 26, "_assign_worker_rank": 26, "group_rank": [26, 36], "group_world_s": 26, "_exit_barri": 26, "guard": [26, 1708, 1716, 1738], "_initialize_work": 26, "worker_group": 26, "fresh": [26, 771, 1581, 1600, 1674], "start_work": 26, "_stop_work": 26, "optimist": 26, "deleg": 26, "_monitor_work": 26, "_rendezv": 26, "_restart_work": 26, "_shutdown": 26, "death_sig": 26, "sigterm": 26, "_start_work": 26, "gracefulli": [26, 36, 925], "runresult": 26, "meaning": [26, 28, 29], "canon": [26, 28, 1676], "meaningless": 26, "intention": [26, 777, 1664, 1704, 1724], "ship": [27, 1698, 1724], "programmat": [27, 42, 1706], "my_launch": 27, "rendezvoushandl": [27, 35, 36], "trainer_entrypoint_fn": 27, "fn_arg": 27, "run_result": 27, "tricki": [27, 1696, 1706, 1726], "myrendezvoushandl": 27, "elastic_ag": 27, "servic": [27, 1700], "metrichandl": [27, 32], "mymetrichandl": 27, "metric_data": [27, 32], "metricdata": 27, "sink": [27, 32, 1687], "eventhandl": 27, "cloudwatch": 27, "nulleventhandl": 27, "myeventhandl": 27, "sub": [28, 40, 41, 512, 534, 906, 910, 911, 994, 997, 999, 1128, 1129, 1159, 1160, 1162, 1499, 1563, 1627, 1640, 1674, 1676, 1677, 1689, 1696, 1713, 1714, 1727, 1730], "invalid": [28, 33, 895, 1007, 1116, 1695, 1696, 1713, 1716, 1717], "infra": 28, "start_process": [28, 33, 1688], "torchelastic_error_fil": 28, "smallest": [28, 665, 916, 926, 947, 951, 967, 1474, 1643, 1734, 1739], "timestamp": [28, 29, 32, 36, 1687, 1732], "error_handl": 28, "sugar": [28, 1678], "get_error_handl": 28, "childfailederror": 28, "get_first_failur": 28, "dump_error_fil": 28, "error_fil": [28, 33], "exitcod": [28, 36], "nanni": 28, "accur": [28, 689, 848, 970, 1058, 1549, 1646, 1699, 1709, 1725], "diagnost": [28, 1676], "torchelastic_ag": 28, "trainer_0": 28, "trainer_1": 28, "json": [28, 33, 1705, 1718], "trainer_n": 28, "errorhandl": 28, "record_except": 28, "processfailur": 28, "test_ev": 29, "eventsourc": 29, "get_logging_handl": 29, "millisecond": [29, 32, 689, 1687], "eventmetadatavalu": 29, "union": [29, 36, 40, 42, 906, 1166, 1389, 1677, 1678, 1679, 1713, 1716, 1734], "readm": [30, 31, 1538], "telemetri": 32, "timeseri": 32, "metric_group": 32, "metric_nam": 32, "assumpt": [32, 36, 637, 1039, 1070, 1696, 1700, 1703, 1724, 1725, 1727], "sensibl": 32, "vs": [32, 42, 892, 908, 1565, 1676, 1678, 1712], "my_modul": [32, 40, 42, 1676, 1716], "nullmetricshandl": 32, "consolemetricshandl": 32, "my_method": 32, "put_metr": 32, "calculate_lat": 32, "succinctli": 32, "baz": [32, 42, 1716, 1734], "leaf_modul": 32, "classnam": [32, 1679], "threw": 32, "my_app": 32, "consolemetrichandl": 32, "toi": 32, "stdout": [32, 33, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1461, 1713], "stdoutmetrichandl": 32, "ts": 32, "1574213883": 32, "4182858": 32, "my_metr": 32, "1574213940": 32, "5237644": 32, "nullmetrichandl": 32, "class_nam": [32, 42], "def_nam": 32, "leaf": [32, 105, 177, 290, 401, 455, 456, 609, 622, 1480, 1481, 1520, 1522, 1639, 1695, 1696, 1737], "metric_valu": 32, "metric_group_nam": 32, "popen": 33, "stderr": [33, 1674, 1686, 1713], "err": 33, "echo": 33, "hello": [33, 1678, 1716], "pcontext": 33, "multiprocesscontext": 33, "subprocesscontext": 33, "keyset": 33, "bitmask": 33, "mask": [33, 354, 355, 356, 357, 358, 494, 989, 1028, 1039, 1061, 1122, 1159, 1160, 1161, 1162, 1163, 1206, 1328, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1677, 1689, 1690], "miss": [33, 895, 1050, 1079, 1080, 1081, 1116, 1712, 1713, 1727], "bar0": 33, "bar1": 33, "file1": 33, "file2": 33, "caution": 33, "short": [33, 42, 781, 892, 1039, 1086, 1087, 1197, 1327, 1356, 1590, 1625, 1678, 1689, 1696, 1697, 1706, 1724, 1729, 1730, 1733], "ing": 33, "cmd": [33, 36], "forkserv": [33, 1319, 1688, 1708], "tee_stdout": 33, "tee_stderr": 33, "processcontext": [33, 1688], "superset": [33, 36], "runprocsresult": 33, "num_nod": [34, 36], "trainers_per_nod": 34, "num_allowed_failur": 34, "rdzv_id": [34, 36], "job_id": [34, 35, 36], "rdzv_backend": [34, 36, 38], "rdzv_endpoint": [34, 36, 38], "host_node_addr": [34, 36], "min_siz": [34, 36], "num_allowed_failures_or_membership_chang": 34, "node1": [34, 36], "29400": [34, 36], "sidecar": [34, 35], "agre": [35, 953, 1726], "resum": [35, 1452, 1458, 1459, 1724, 1726, 1732], "retryabl": 35, "late": 35, "announc": 35, "previous": [35, 40, 42, 176, 593, 902, 1667, 1676, 1697, 1699, 1706, 1716, 1717, 1723, 1724, 1728], "lose": [35, 38, 146, 163, 1690], "train_loop": [35, 1541], "queri": [35, 42, 689, 690, 691, 741, 758, 895, 1116, 1122, 1328, 1388, 1677, 1699, 1716], "arriv": [35, 36, 1724, 1726], "dynamicrendezvoushandl": 35, "rendezvousbackend": 35, "c10drendezvousbackend": 35, "etcdrendezvousbackend": 35, "supersed": 35, "etcdrendezvoushandl": 35, "my_run_id": 35, "from_backend": 35, "run_id": [35, 36], "min_nod": 35, "max_nod": 35, "rendezvousparamet": 35, "endpoint": [35, 36], "admit": [35, 36, 1699], "get_as_bool": 35, "get_as_int": 35, "rendezvoushandlerregistri": 35, "create_handl": 35, "creator": [35, 1696, 1724, 1726], "creater": 35, "get_run_id": 35, "is_clos": 35, "set_clos": 35, "next_rendezv": 35, "rendezvousclosederror": 35, "rendezvousconnectionerror": 35, "rendezvousstateerror": 35, "rendezvoustimeouterror": 35, "num_nodes_wait": 35, "rendezvouserror": 35, "dynamic_rendezv": 35, "join_timeout": 35, "600": 35, "last_call_timeout": 35, "close_timeout": 35, "get_stat": [35, 43], "fenc": 35, "token": [35, 688, 717, 718, 1674, 1680], "set_stat": [35, 43], "condition": [35, 1587], "rendezvoustimeout": 35, "last_cal": 35, "heartbeat": 35, "keep_al": 35, "c10d_rendezvous_backend": 35, "create_backend": 35, "store_typ": 35, "tcp": [35, 36, 1724], "read_timeout": 35, "60": [35, 37, 1070, 1461, 1636, 1641, 1687, 1724], "is_host": 35, "cname": 35, "fqdn": [35, 36], "etcd_rendezvous_backend": 35, "ssl_cert": 35, "ssl": 35, "certif": 35, "ssl_cert_kei": 35, "ca_cert": 35, "rool": 35, "key_prefix": 35, "ttl": 35, "hour": 35, "etcd_rendezv": 35, "rdzv_impl": 35, "etcdrendezv": 35, "etcd_address": 35, "min_work": 35, "max_work": 35, "noqa": 35, "w605": 35, "2379": [35, 994], "etcd_prefix": 35, "p2p": 35, "etcdstor": 35, "etcd_stor": 35, "etcd_client": 35, "etcd_store_prefix": 35, "piggyback": 35, "num": [35, 1007, 1068, 1071, 1086, 1122, 1131, 1159, 1338, 1339, 1353], "atom": [35, 42, 1680], "lookuperror": 35, "override_timeout": 35, "etcdserv": 35, "cumbersom": [35, 1679], "highli": [35, 1024, 1319, 1674, 1707, 1713, 1734], "etcd_serv": 35, "data_dir": 35, "v3": [35, 36], "substitut": [35, 42, 907, 1696, 1730], "torchelastic_etcd_binary_path": 35, "get_client": 35, "etcd_binary_path": 35, "entry_point": 36, "migrat": [36, 998, 1719], "train_script": 36, "aforment": 36, "suffic": [36, 42], "compliant": [36, 38], "num_train": 36, "wors": [36, 1660], "port_k": 36, "assgin": 36, "etcd": 36, "v2": [36, 963, 1464], "revis": 36, "physic": [36, 799, 817, 1680, 1698], "localworkergroup": 36, "max_nnod": 36, "torchelastic_restart_count": 36, "far": [36, 904, 1213], "torchelastic_max_restart": 36, "python_exec": 36, "Not": [36, 1015, 1676, 1678, 1679, 1680, 1701, 1719, 1724], "gang": 36, "departur": 36, "surviv": 36, "kill": [36, 37, 1688, 1702], "frequenc": [36, 647, 686, 797, 798, 799, 800, 801, 802, 803, 804, 809, 811, 812, 813, 814, 815, 816, 817, 818, 1024, 1059, 1060, 1204, 1205, 1452, 1625], "ness": 36, "load_checkpoint": [36, 38], "checkpoint_path": [36, 38], "dataset": [36, 38, 1024, 1033, 1082, 1483, 1702, 1705, 1712, 1715, 1719, 1720, 1732], "train_step": 36, "should_checkpoint": 36, "save_checkpoint": [36, 38], "acquir": [37, 42, 1706, 1726, 1727], "deadlin": 37, "message_queu": 37, "localtimerserv": 37, "max_interv": 37, "trainer_func": 37, "localtimercli": 37, "expiri": 37, "timer_cli": 37, "countdown": 37, "timefram": [37, 1724], "elig": [37, 1726], "reap": 37, "timerserv": 37, "mp_queue": 37, "daemon": [37, 1688], "timercli": 37, "timerrequest": 37, "scope_id": 37, "expiration_tim": 37, "acquisit": 37, "whatev": [37, 42, 401, 1319, 1648, 1679], "request_queu": 37, "entiti": [37, 42], "clear_tim": 37, "get_expired_tim": 37, "register_tim": 37, "timer_request": 37, "expositori": 38, "worst": [38, 1701], "total_num_epoch": 38, "visit": [38, 1713], "fsdp": [40, 1675], "sharding_strategi": 40, "cpu_offload": 40, "auto_wrap_polici": 40, "backward_prefetch": 40, "mixed_precis": 40, "ignored_modul": 40, "param_init_fn": 40, "sync_module_st": 40, "forward_prefetch": 40, "inspir": [40, 1436, 1701], "deepspe": 40, "shorten": 40, "sharded_modul": 40, "0001": [40, 42, 761, 939, 1104, 1231, 1430, 1459, 1677, 1715], "dev_id": 40, "no_sync": [40, 1319], "offload": 40, "ping": 40, "77724": 40, "shardingstrategi": 40, "full_shard": 40, "cpuoffload": 40, "offload_param": 40, "size_based_auto_wrap_polici": 40, "100m": 40, "transformer_auto_wrap_polici": 40, "architectur": [40, 42, 709, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 1052, 1159, 1196, 1586, 1699, 1709, 1719], "unwrapped_param": 40, "subgraph": [40, 1696, 1700, 1713, 1716, 1737], "custom_auto_wrap_polici": 40, "customiz": [40, 1680, 1736], "min_num_param": 40, "1e8": 40, "my_auto_wrap_polici": 40, "functool": [40, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1511, 1512, 1513, 1514, 1515, 1517, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1701, 1721, 1734], "1e5": 40, "backwardprefetch": 40, "pro": [40, 1712, 1732], "con": 40, "mixedprecis": 40, "batchnorm": [40, 895, 904, 1116, 1155, 1284, 1285, 1319, 1685, 1696, 1706, 1715, 1717, 1719, 1721, 1722], "granular": [40, 908, 1695], "meta": [40, 291, 1683, 1724, 1732, 1734], "is_meta": 40, "reset_paramet": 40, "reset_paramt": 40, "torchdistx": 40, "deferred_init": 40, "materialize_modul": 40, "mymodul": [40, 42, 899, 900, 901, 905, 906, 912, 1117, 1118, 1126, 1127, 1676, 1678, 1679, 1702, 1711, 1724], "my_init_fn": 40, "fsdp_model": 40, "thrown": [40, 41, 244, 568, 608, 610, 739, 778, 858, 895, 925, 934, 936, 938, 941, 942, 953, 1116, 1381, 1668, 1716, 1728], "fullstatedictconfig": 40, "summon_full_param": 40, "norm_typ": [40, 1059, 1060, 1084, 1085, 1204, 1205, 1234, 1235, 1338, 1339, 1381, 1677], "infin": [40, 684, 885, 887, 889, 890, 1011, 1032, 1109, 1110, 1111, 1237, 1238, 1239, 1381, 1435, 1599, 1608, 1727, 1728], "fsdp_modul": 40, "root_onli": 40, "full_optim_state_dict": 40, "optim_input": 40, "rank0_onli": 40, "convent": [40, 42, 290, 781, 799, 801, 1034, 1035, 1036, 1079, 1080, 1081, 1155, 1574, 1674, 1686, 1696, 1703, 1706, 1711], "unflatten": [40, 1677, 1689, 1690, 1731], "alias": [40, 624, 1224, 1678, 1679, 1683, 1701], "unshard": 40, "oom": [40, 1702], "state_dict_typ": 40, "statedicttyp": 40, "local_state_dict": 40, "full_state_dict": 40, "full_dict": 40, "odict_kei": [40, 1403], "local_dict": 40, "flat_param": 40, "flatten_params_wrapp": 40, "named_buff": [40, 895, 1116, 1706, 1711], "intercept": [40, 42], "occurr": [40, 893, 997, 1410, 1657, 1658], "named_paramet": [40, 895, 899, 1116, 1706, 1711], "params_with_grad": 40, "gossipgrad": [40, 1319], "no_shard": 40, "rekey_optim_state_dict": 40, "optim_state_dict": 40, "optim_state_key_typ": 40, "loadabl": [40, 1674], "wrapped_model": 40, "wrapped_optim": 40, "full_osd": 40, "nonwrapped_model": 40, "nonwrapped_optim": 40, "rekeyed_osd": 40, "optimstatekeytyp": 40, "param_id": 40, "osd": 40, "param_nam": 40, "sharded_osd": 40, "shard_full_optim_state_dict": 40, "scatter_full_optim_state_dict": 40, "new_model": 40, "new_optim": 40, "latter": [40, 582, 895, 1086, 1116, 1123, 1481, 1706, 1708, 1710], "remap": [40, 43, 899, 902, 966, 988, 1674, 1686, 1723], "sharded_state_dict": 40, "shardedtensor": 40, "full_state_dict_config": 40, "offload_to_cpu": 40, "state_dict_config": 40, "descend": [40, 42, 91, 492, 606, 895, 958, 959, 1116, 1603, 1629, 1677], "transpar": [40, 1700, 1717, 1724, 1726], "writeback": 40, "summon": 40, "storag": [40, 176, 266, 294, 297, 298, 388, 411, 436, 451, 472, 475, 508, 509, 536, 537, 539, 540, 608, 624, 626, 707, 771, 865, 869, 881, 895, 902, 966, 989, 1016, 1053, 1116, 1560, 1574, 1581, 1600, 1604, 1606, 1620, 1639, 1645, 1674, 1675, 1677, 1686, 1688, 1696, 1699, 1708, 1711, 1716, 1724, 1727, 1730, 1731, 1733], "portion": [40, 830, 1053, 1147, 1253, 1319, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1447, 1633, 1720, 1727], "discard": [40, 892, 952, 1387, 1674, 1678, 1687], "redundantli": [40, 1695], "materi": [40, 629, 679, 1321, 1322, 1566, 1567, 1701], "encapsul": [41, 42, 1724], "rpc_async": [41, 1679, 1724, 1726], "add_done_callback": 41, "fut": [41, 898, 1319, 1698, 1724], "carefulli": [41, 1716], "set_result": [41, 1319, 1724], "haven": [41, 1706], "usabl": [41, 1679, 1713], "set_except": 41, "attach": [41, 42, 94, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1314, 1323, 1324, 1325, 1326, 1520, 1522, 1543, 1674, 1676, 1678, 1689, 1701, 1719, 1725, 1736], "baseexcept": 41, "valueerror": [41, 893, 1389, 1390, 1410, 1413, 1428, 1701, 1717, 1734], "slow_set_futur": 41, "sleep": 41, "cb1": 41, "cb2": 41, "dedic": [41, 1699], "pool": [41, 688, 717, 718, 728, 739, 1021, 1022, 1023, 1025, 1026, 1027, 1029, 1030, 1031, 1064, 1065, 1084, 1085, 1109, 1110, 1111, 1112, 1113, 1114, 1117, 1172, 1173, 1174, 1175, 1176, 1177, 1180, 1181, 1182, 1208, 1209, 1234, 1235, 1237, 1238, 1239, 1359, 1360, 1361, 1362, 1375, 1376, 1547, 1548, 1698, 1699, 1701, 1706, 1708, 1721, 1724], "didn": [41, 1701, 1712, 1715], "cb_fut": 41, "chain_cb_fut": 41, "cb": [41, 1724], "held": [41, 688, 708, 735, 1695], "collect_al": 41, "fut0": 41, "fut1": [41, 1724], "fut_list": 41, "wait_al": 41, "toolkit": 42, "clamp": [42, 141, 142, 672, 901, 1032, 1070, 1213, 1224, 1281, 1484, 1487, 1677, 1685, 1689, 1713, 1714, 1719, 1721, 1722, 1728, 1734], "symbolic_trac": 42, "placehold": [42, 1078, 1699], "get_attr": 42, "call_funct": 42, "call_modul": 42, "call_method": 42, "feed": [42, 1676, 1702, 1706, 1736], "fake": [42, 795, 796, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1323, 1324, 1325, 1484, 1485, 1495, 1497, 1520, 1541, 1716, 1719, 1722], "theses": 42, "callsit": 42, "constitut": 42, "isol": [42, 1314, 1688, 1717], "tracer_class": 42, "gm": 42, "bring": [42, 802, 1178, 1213, 1717], "treatment": 42, "topk": [42, 1677, 1689, 1714], "print_tabular": 42, "opcod": [42, 1716], "linear_weight": 42, "add_1": 42, "linear_1": 42, "relu_1": 42, "sum_1": 42, "topk_1": 42, "pose": [42, 1725], "explor": [42, 1674, 1696, 1706, 1716], "edit": [42, 1716, 1731], "lint": 42, "inserting_aft": 42, "new_nod": 42, "replace_all_uses_with": 42, "tediou": 42, "unwieldi": 42, "conv": [42, 895, 904, 910, 911, 1044, 1045, 1046, 1047, 1048, 1049, 1116, 1117, 1123, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1499, 1539, 1540, 1685, 1694, 1699, 1709, 1713, 1719, 1720, 1721, 1722], "fusion": [42, 897, 903, 908, 909, 910, 911, 1499, 1539, 1540, 1685, 1706, 1719], "machineri": [42, 1701], "imagin": [42, 1724], "requisit": 42, "relu_decomposit": 42, "decomposition_rul": 42, "constitu": [42, 1691], "new_graph": 42, "graphappendingtrac": 42, "proxy_arg": 42, "output_proxi": 42, "extract": [42, 1059, 1063, 1167, 1204, 1280, 1518, 1724, 1737], "node_copi": 42, "vmap": [42, 630, 632, 636, 637, 638], "ari": [42, 1713], "unari": [42, 1159, 1161, 1163, 1680, 1689, 1727], "organiz": 42, "shapeprop": 42, "mod": [42, 898, 899, 904, 911, 1305, 1306, 1325, 1331, 1332, 1333, 1338, 1339, 1349, 1357, 1417, 1495, 1496, 1497, 1498, 1500, 1518, 1519, 1543, 1678, 1679, 1716, 1736], "named_modul": [42, 895, 1116, 1706], "args_it": 42, "load_arg": 42, "map_arg": 42, "fetch_attr": 42, "target_atom": 42, "attr_itr": 42, "hasattr": [42, 1677, 1701, 1719], "referenc": [42, 690, 895, 1116, 1648, 1678, 1696, 1713, 1714, 1724], "nonexist": [42, 1678, 1679], "getattr": [42, 1677], "elif": [42, 901, 1082, 1678, 1679, 1704, 1713], "self_obj": 42, "encompass": 42, "prove": [42, 1688], "disprov": 42, "led": 42, "auxiliari": [42, 1674, 1705], "nondeterminist": [42, 268, 270, 276, 467, 469, 647, 916, 1039, 1044, 1045, 1046, 1047, 1048, 1049, 1188, 1189, 1190, 1191, 1192, 1193, 1197, 1205, 1213, 1224, 1251, 1281, 1282, 1283, 1584, 1660], "unord": [42, 1117, 1126], "nondetermin": [42, 638, 1710], "dedupl": 42, "straightforward": [42, 1691, 1706], "transformed_resnet18": 42, "input_imag": 42, "margin": [42, 1050, 1076, 1108, 1119, 1121, 1164, 1165, 1194, 1221, 1236, 1245, 1278, 1279, 1677, 1732], "commut": 42, "allclos": [42, 637, 638, 725, 803, 804, 810, 811, 942, 944, 955, 957, 960, 961, 987, 1389, 1475, 1633, 1677], "toolbox": 42, "tradit": 42, "techniqu": [42, 1054, 1391, 1646, 1692, 1706, 1717, 1719], "luckili": 42, "my_pass": 42, "my_module_transform": 42, "input_valu": 42, "prompt": [42, 1674, 1712], "set_trac": [42, 900, 906, 912, 1676], "examin": [42, 1706, 1713, 1718], "undergon": 42, "subclassm": 42, "untrac": 42, "pre_trac": 42, "post_trac": 42, "sake": 42, "tabular": 42, "transform_graph": 42, "session": 42, "press": 42, "luck": 42, "input_nod": 42, "stepwis": 42, "breakpoint": [42, 1679], "excel": 42, "onlin": [42, 1432], "realpython": 42, "pycharm": 42, "vscode": 42, "graphic": [42, 1712], "parlanc": 42, "func_to_trac": 42, "dyn": 42, "155": 42, "__bool__": [42, 1677, 1679], "to_bool": 42, "85": [42, 1458], "traceerror": [42, 1719], "hyper": [42, 1147, 1678, 1732], "do_activ": 42, "512": [42, 1159, 1160, 1161, 1162, 1163, 1699], "Its": [42, 686, 698, 895, 942, 960, 961, 987, 1116, 1422, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1440, 1443, 1444, 1445, 1446, 1447, 1664, 1679, 1700], "without_activ": 42, "with_activ": 42, "traced_without_activ": 42, "traced_with_activ": 42, "concrete_arg": 42, "truli": [42, 1713], "__torch_function__": [42, 1738], "161": 42, "len_1": 42, "sqrt_1": 42, "truediv": 42, "mycustomtrac": 42, "traced_graph": 42, "runnabl": [42, 1695, 1713, 1732], "myspecialsubmodul": 42, "submod": 42, "neg_1": 42, "is_leaf_modul": [42, 1737], "sparse_coo_tensor": [42, 494, 532, 1610, 1677, 1681, 1727], "traceabl": [42, 575, 1676, 1719], "ones_lik": [42, 1677, 1699, 1706, 1714], "zeros_lik": [42, 627, 629, 1677, 1681, 1699, 1714, 1727], "viabl": [42, 1699], "torch_randn": 42, "gotcha": 42, "bake": [42, 899, 904], "dropoutrepro": 42, "assert_allclos": 42, "assertionerror": [42, 1327, 1734], "greatest": [42, 838, 1011, 1734], "6207983493804932": 42, "dropoutrepro2": 42, "presenc": [42, 904, 1012, 1716], "pytre": 42, "overspeci": 42, "ph": 42, "shouldn": [42, 688, 1716, 1727, 1731], "v": [42, 440, 494, 624, 631, 633, 634, 635, 660, 780, 930, 934, 958, 962, 967, 1122, 1164, 1165, 1204, 1249, 1419, 1444, 1446, 1465, 1610, 1614, 1629, 1630, 1633, 1667, 1677, 1678, 1679, 1687, 1696, 1703, 1713, 1716, 1727, 1732], "fn_or_nam": 42, "callfunct": 42, "my_custom_funct": 42, "fn_to_be_trac": 42, "reassign": [42, 1699], "regener": 42, "add_submodul": 42, "subpath": 42, "get_submodul": [42, 895, 1116], "delete_all_unused_submodul": 42, "delete_submodul": 42, "nested_str": 42, "date": [42, 1716], "fxmodul": 42, "pathlik": [42, 966, 1574, 1716], "owning_modul": 42, "tracer_cl": 42, "tracer_extra": 42, "seri": [42, 1039, 1079, 1710, 1738], "the_funct": 42, "type_expr": 42, "create_nod": 42, "method_nam": 42, "0th": 42, "inserting_befor": 42, "influenc": 42, "eliminate_dead_cod": 42, "dead": 42, "attr_1": 42, "is_impur": 42, "bad": [42, 1688, 1713, 1716, 1719], "sound": [42, 1144, 1683, 1732], "erase_nod": 42, "to_eras": 42, "eras": 42, "qualified_nam": 42, "graph_copi": 42, "val_map": 42, "return_output_nod": 42, "companion": 42, "__exit__": [42, 1679, 1680, 1716], "arg_transform": 42, "value_remap": 42, "doubli": 42, "mutat": [42, 899, 1482, 1520, 1521, 1536, 1537, 1716, 1733], "on_generate_cod": 42, "make_transform": 42, "transformcodefunc": 42, "insert_pdb": 42, "bodi": [42, 906, 1676, 1678, 1679, 1680], "current_tran": 42, "stuff": 42, "default_valu": 42, "_not_": 42, "tabul": 42, "process_input": 42, "process_output": 42, "python_cod": 42, "root_modul": [42, 1721], "pythoncod": 42, "set_codegen": 42, "codegen": 42, "return_typ": [42, 592, 759, 760, 857, 916, 954, 994, 997, 999, 1002, 1013, 1603, 1643, 1648], "printout": [42, 727, 740], "all_input_nod": 42, "format_nod": 42, "placeholder_nam": 42, "maybe_return_typenam": 42, "__str__": [42, 1677, 1679], "autogener": 42, "impur": 42, "normalized_argu": 42, "arg_typ": 42, "kwarg_typ": 42, "normalize_to_only_use_kwarg": 42, "vararg": 42, "argskwargspair": 42, "bx": 42, "ax": [42, 926, 940, 944, 955, 956, 957, 983, 986, 998, 1124, 1134, 1648, 1713], "prev": [42, 1445], "replace_with": 42, "delete_user_cb": 42, "replace_input_with": 42, "old_input": 42, "new_input": 42, "stack_trac": 42, "create_proxi": 42, "record_stack_trac": 42, "update_arg": 42, "update_kwarg": 42, "autowrap_modul": 42, "autowrap_funct": 42, "create_arg": 42, "prepar": [42, 904, 1482, 1521, 1523, 1536, 1538, 1540, 1541, 1542, 1680, 1713, 1736, 1737], "create_args_for_root": 42, "root_fn": 42, "is_modul": 42, "introspect": 42, "disallow": [42, 1716, 1724, 1730], "proxy_factory_fn": 42, "module_qualified_nam": [42, 1737], "path_of_modul": 42, "kept": [42, 592, 1034, 1035, 1036, 1079, 1080, 1081, 1155, 1224, 1281, 1372, 1378, 1679, 1688, 1719], "some_hyperparamet": 42, "indexed_item": 42, "proxied_valu": 42, "garbage_collect_valu": 42, "run_nod": 42, "swap": [42, 568, 985, 1164, 1165, 1278, 1279, 1477, 1478, 1479, 1482, 1543, 1645, 1677, 1680, 1719, 1727, 1736], "vice": [42, 411, 555, 833, 834, 1108, 1696, 1722, 1729], "versa": [42, 411, 555, 833, 834, 1108, 1696, 1722, 1729], "negsigmswapinterpret": 42, "call_self": 42, "args_tail": 42, "fetch_args_kwargs_from_env": 42, "qualfii": 42, "map_nodes_to_valu": 42, "initial_env": 42, "enable_io_process": 42, "negsigmswapxform": 42, "nodes_map": 42, "subgraph_rewrit": 42, "w1": 42, "w2": 42, "m1": [42, 1665, 1666], "m2": [42, 1415, 1665, 1666, 1719], "traced_modul": [42, 1711], "despit": [42, 910, 911, 1703], "stack_1": 42, "stack_2": 42, "sum_2": 42, "max_1": 42, "max_2": 42, "add_2": 42, "g_cpu": 43, "g_cuda": 43, "bytetensor": [43, 714, 715, 752, 753, 847, 1159, 1328, 1591, 1723, 1730, 1733], "2147483647": 43, "0x8000_0000_0000_0000": [43, 988, 1723], "0xffff_ffff_ffff_ffff": [43, 988, 1723], "random_devic": 43, "1516516984916": 43, "new_stat": [43, 752, 753, 1591, 1723], "void": [43, 726, 1705], "g_cpu_oth": 43, "abs_": [47, 1677, 1689, 1733], "acosh": [51, 77, 597, 1677, 1689], "batch1": [54, 55, 106, 107, 581, 644, 1677], "batch2": [54, 55, 106, 107, 124, 581, 644, 1677], "tensor1": [56, 57, 58, 59, 582, 583, 990, 1568, 1677], "tensor2": [56, 57, 58, 59, 269, 359, 582, 583, 990, 1568, 1677], "mat1": [60, 61, 504, 584, 859, 915, 1001, 1604, 1606, 1607, 1621, 1677], "mat2": [60, 61, 368, 504, 584, 656, 859, 915, 1001, 1604, 1606, 1607, 1621, 1677], "mat": [62, 63, 491, 585, 1009, 1549, 1602, 1604, 1621, 1677, 1732], "vec": [62, 63, 378, 585, 1009, 1418, 1677, 1727], "vec1": [64, 65, 586, 1677], "vec2": [64, 65, 243, 414, 586, 841, 1464, 1677], "keepdim": [67, 69, 70, 71, 73, 89, 90, 308, 346, 362, 364, 365, 366, 369, 383, 384, 385, 386, 406, 423, 432, 505, 515, 566, 588, 590, 591, 592, 594, 604, 605, 916, 947, 951, 964, 982, 994, 996, 997, 999, 1002, 1012, 1013, 1014, 1015, 1125, 1252, 1422, 1473, 1476, 1623, 1624, 1628, 1662, 1663, 1677, 1689, 1728], "rtol": [68, 299, 589, 637, 638, 884, 949, 952, 1676, 1677, 1734], "atol": [68, 299, 589, 637, 638, 884, 949, 952, 961, 1676, 1677, 1701, 1734], "08": [68, 299, 589, 654, 884, 941, 1051, 1130, 1195, 1256, 1433, 1434, 1435, 1437, 1443, 1444, 1447, 1459, 1677], "equal_nan": [68, 299, 589, 884, 1677, 1734], "arcco": [76, 1677, 1734], "acosh_": [78, 1677, 1689], "arccosh": [78, 1677], "arcsin": [80, 611, 1677, 1727], "arcsinh": [82, 1677], "atan2_": [85, 1677, 1689], "arctan2": [85, 1677], "arctan": [86, 1677], "arctanh": [88, 1677], "storage_offset": [93, 472, 568, 608, 1677], "cl": [94, 1701, 1719, 1724, 1738], "pointer": [94, 701, 1132, 1699, 1700, 1705, 1724, 1726], "asinh": [98, 599, 1677, 1689, 1727], "atan": [102, 600, 1677, 1689, 1714, 1727], "atanh": [104, 602, 1677, 1689, 1727], "w": [105, 619, 621, 622, 628, 636, 637, 638, 645, 654, 686, 837, 852, 853, 892, 934, 1022, 1023, 1030, 1031, 1035, 1036, 1040, 1045, 1046, 1052, 1056, 1057, 1059, 1060, 1061, 1080, 1081, 1088, 1099, 1100, 1110, 1111, 1121, 1122, 1123, 1128, 1129, 1150, 1166, 1167, 1169, 1170, 1178, 1204, 1205, 1213, 1248, 1254, 1255, 1385, 1416, 1419, 1677, 1689, 1690, 1694, 1696, 1701, 1703, 1716, 1732], "layout": [105, 146, 163, 297, 298, 411, 494, 533, 534, 535, 568, 595, 622, 624, 645, 654, 699, 782, 783, 784, 794, 799, 817, 835, 836, 852, 853, 914, 965, 981, 1426, 1427, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1606, 1607, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1650, 1652, 1672, 1673, 1674, 1676, 1677, 1678, 1681, 1699, 1716, 1727, 1732, 1733, 1734], "grad_fn": [105, 290, 610, 622, 630, 631, 632, 633, 634, 635, 1385, 1606, 1696, 1706, 1711], "60521": [105, 622], "issuecom": [105, 622], "867061780": [105, 622], "freed": [105, 622, 636, 694, 739, 1688, 1699, 1704, 1724], "nearli": [105, 622, 636, 1465, 1708, 1724], "attr": [105, 622, 918, 998, 1571], "texttt": [108, 109, 589, 884, 1024, 1734], "bernoulli": [109, 1028, 1054, 1055, 1056, 1057, 1061, 1068, 1086, 1198, 1199, 1200, 1201, 1206, 1353, 1677, 1689, 1714, 1735], "memory_format": [110, 125, 127, 130, 133, 134, 135, 144, 150, 161, 164, 194, 222, 252, 280, 286, 347, 451, 452, 476, 531, 673, 782, 783, 836, 895, 1116, 1319, 1427, 1552, 1554, 1556, 1673, 1677], "preserve_format": [110, 125, 127, 130, 133, 134, 135, 144, 161, 164, 194, 222, 252, 280, 347, 476, 531, 673, 783, 836, 1427, 1552, 1554, 1556, 1673, 1730], "minlength": [111, 647, 1677], "bitwise_and": [113, 1677], "bitwise_left_shift": [115, 1677], "bitwise_not": [117, 1677, 1689, 1714], "bitwise_or": [119, 1677], "bitwise_right_shift": [121, 1677], "bitwise_xor": [123, 1677], "uint8": [127, 197, 568, 588, 594, 833, 1400, 1474, 1544, 1545, 1568, 1719, 1729, 1730, 1732, 1733, 1739], "cauchi": [128, 1696, 1703, 1735], "dfrac": [128, 331, 560, 1051, 1195, 1385, 1416, 1419], "complex32": [134, 1044, 1045, 1046, 1188, 1189, 1190, 1733, 1734], "int8": [135, 401, 648, 649, 650, 651, 652, 653, 833, 976, 977, 978, 979, 1313, 1719, 1722, 1729, 1730, 1733, 1739], "input2": [138, 412, 413, 469, 669, 1037, 1050, 1051, 1108, 1125, 1184, 1194, 1195, 1236, 1353, 1677, 1695, 1713], "clamp_": [143, 1677, 1689], "uncoalesc": [145, 283, 1614], "coo": [145, 278, 283, 565, 859, 1604, 1606, 1611, 1612, 1613, 1614, 1615, 1616, 1730, 1734], "inttensor": [146, 163, 869, 985, 986, 1059, 1730, 1733], "csr": [146, 163, 298, 536, 537, 540, 1060, 1604, 1606, 1607, 1613, 1616, 1734], "sparse_csr": [146, 163, 1607, 1609, 1613, 1616, 1727], "nnz": [146, 494, 535, 637, 1606, 1607, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1727], "int32": [146, 163, 268, 276, 280, 400, 568, 660, 783, 795, 831, 833, 834, 925, 936, 937, 938, 956, 985, 1039, 1474, 1578, 1719, 1727, 1729, 1730, 1733, 1739], "mkl": [146, 163, 1698, 1712, 1727], "routin": [146, 163, 606, 668, 967, 1603, 1629], "downcast": [146, 163], "to_sparse_csr": [146, 163, 536, 537, 1607, 1677, 1727], "conj_phys": [149, 679, 1677, 1727], "contiguous_format": [150, 286, 451, 452, 782, 1319, 1730], "non_block": [151, 164, 531, 555, 895, 1116, 1410, 1677, 1699, 1729], "copysign": [153, 1677], "co": [156, 578, 654, 725, 852, 853, 946, 1050, 1051, 1054, 1450, 1451, 1458, 1469, 1611, 1612, 1613, 1615, 1616, 1677, 1689, 1714, 1715, 1732, 1734], "fweight": [160, 686, 1677], "aweight": [160, 686, 1677], "sparse_dim": [173, 388, 495, 496, 1604, 1606, 1610, 1614, 1677, 1727], "resize_": [176, 452, 916, 1676, 1677, 1678, 1689, 1721, 1729], "resize_as_": [176, 1677, 1689, 1727], "set_": [176, 451, 1677], "transpose_": [176, 1677, 1727], "zero_": [176, 940, 1204, 1677, 1689, 1690, 1706, 1727], "copy_": [176, 1168, 1676, 1677, 1689, 1699, 1729], "dim1": [180, 182, 183, 519, 544, 545, 768, 770, 771, 929, 1632, 1645, 1677], "dim2": [180, 182, 183, 768, 770, 771, 929, 1677], "digamma": [186, 1677, 1689, 1728], "rounding_mod": [189, 190, 191, 192, 775, 776, 826, 829, 1562, 1653, 1677], "split_size_or_sect": [195, 257, 570, 1617], "eigenvector": [196, 520, 780, 930, 931, 967, 1633, 1677], "eq": [199, 1677, 1689, 1714], "erf": [202, 1677, 1689, 1714, 1727, 1728], "erfc": [204, 1677, 1689, 1728], "front": [209, 967, 1119, 1690], "lambd": [213, 253, 1072, 1153, 1216, 1271, 1430, 1677], "exponenti": [213, 791, 946, 972, 973, 974, 982, 1038, 1058, 1202, 1679, 1715, 1728, 1735], "fill_valu": [215, 399, 835, 836, 1039, 1677, 1699], "tall": [215, 953, 958, 1701], "start_dim": [218, 820, 1062, 1677], "end_dim": [218, 820, 1062, 1677], "float_pow": [224, 1677], "floor_divid": [228, 775, 1677, 1714, 1727], "divisor": [231, 232, 441, 442, 775, 826, 829, 838, 1030, 1031, 1063, 1167, 1181, 1182, 1361, 1362, 1562, 1653], "fmod": [232, 1562, 1677, 1714], "mantissa": [235, 434, 831, 918, 1677, 1699, 1709], "gcd": [238, 1677], "ge": [240, 850, 989, 1073, 1074, 1217, 1218, 1677, 1689, 1714], "geometr": [241, 1213, 1224, 1281, 1372, 1378, 1661, 1735], "ordin": [244, 1611, 1612, 1613, 1615, 1616, 1730], "greater_equ": [249, 1677], "gt": [251, 849, 1677, 1689, 1703, 1714], "hypot": [259, 1677], "i0": [261, 914, 1677, 1728], "igamma": [263, 1677], "igammac": [265, 1677], "3100": [266, 436, 865, 1560], "3553j": [266, 436, 865, 1560], "5445": [266, 436, 865, 1560], "7896j": [266, 436, 865, 1560], "6492": [266, 436, 865, 1560], "0633j": [266, 436, 865, 1560], "0638": [266, 436, 865, 1560], "8119j": [266, 436, 865, 1560], "3553": [266, 865], "7896": [266, 865], "0633": [266, 865, 941, 1691], "8119": [266, 865], "index_add_": [267, 627, 866, 867, 1677, 1710], "index_copy_": [269, 1677], "index_fill_": [271, 1677, 1689], "index_put_": [273, 1677], "include_self": [276, 468, 469, 868, 1577, 1677], "identit": 276, "amax": [276, 469, 591, 592, 1677, 1714], "amin": [276, 469, 590, 592, 1677, 1714], "fill_": [276, 895, 920, 1116, 1563, 1677, 1689, 1706, 1729], "72": [276, 568, 848], "uint8_t": [281, 1428], "retain_grad": [290, 1677], "requires_grad_": [290, 401, 895, 1039, 1116, 1197, 1606, 1639, 1677, 1689, 1696, 1733], "n_fft": [306, 506, 892, 1625, 1677], "hop_length": [306, 506, 892, 1625, 1677], "win_length": [306, 506, 892, 1625, 1677], "center": [306, 506, 801, 892, 1178, 1213, 1224, 1281, 1372, 1378, 1444, 1465, 1625, 1677, 1696, 1732], "onesid": [306, 506, 892, 1625, 1677], "return_complex": [306, 506, 892, 1625, 1677], "tolist": [307, 1679, 1729], "lcm": [310, 1677], "ldexp": [312, 831, 1677], "le": [314, 922, 1073, 1074, 1217, 1218, 1677, 1689, 1714, 1734], "lerp": [316, 1677, 1714], "lt": [317, 350, 921, 1676, 1677, 1689, 1714], "less_equ": [320, 1677], "lgamma": [322, 1677], "ln": [331, 923, 1728], "logical_and": [337, 1677, 1714], "logical_not": [339, 1677, 1689], "logical_or": [341, 1677, 1714], "logical_xor": [343, 1677, 1714], "pivot": [351, 937, 938, 939, 940, 941, 942, 943, 944, 985, 986, 987, 1475, 1677], "get_info": [351, 985], "lu_data": [352, 986, 987, 1677], "lu_pivot": [352, 986, 987, 1677], "masked_fill_": [354, 1677, 1689, 1690], "booltensor": [355, 357, 989, 1159, 1328, 1670, 1730, 1733], "masked_scatter_": [356, 1677], "mvlgamma": [380, 1677], "posinf": [381, 382, 1011, 1677], "neginf": [381, 382, 1011, 1677], "nan_to_num": [382, 1677, 1714], "interpol": [385, 432, 920, 1014, 1168, 1169, 1170, 1178, 1213, 1281, 1282, 1283, 1378, 1379, 1380, 1476, 1501, 1660, 1677, 1721], "dimems": 388, "ne": [392, 1385, 1416, 1424, 1677, 1689, 1714], "numel": [397, 674, 686, 812, 880, 1677, 1689, 1696, 1714, 1727], "uniniti": [398, 451, 782, 783, 1314, 1321, 1322, 1415], "8182e": 398, "5765e": 398, "41": [398, 784, 953, 1314, 1415, 1475], "0545e": 398, "0949e": 398, "4842e": [398, 784], "0000e": [398, 784, 824, 972, 981, 1011, 1415], "00": [398, 784, 824, 972, 981, 1011, 1415, 1676], "141592": [399, 835], "1416": [399, 764, 835, 1639], "from_numpi": [401, 609, 610, 1639], "array_lik": [401, 609, 1611, 1612, 1613, 1614, 1615, 1616, 1639], "nextaft": [404, 1677], "fro": [406, 926, 947, 951, 964, 1395, 1404, 1422, 1677], "not_equ": [409, 1677], "reflect": [411, 472, 506, 833, 834, 892, 1044, 1045, 1046, 1092, 1093, 1094, 1137, 1138, 1139, 1213, 1251, 1417, 1460, 1625, 1676, 1677, 1702, 1731], "resolve_conj": [411, 679, 1677], "resolve_neg": [411, 1677], "shorthand": [411, 914], "input3": [413, 1677], "transpos": [413, 545, 546, 568, 587, 669, 781, 924, 925, 931, 934, 937, 944, 955, 958, 983, 1047, 1048, 1049, 1167, 1191, 1192, 1193, 1334, 1335, 1336, 1384, 1413, 1463, 1629, 1631, 1632, 1633, 1634, 1648, 1677, 1689, 1696, 1709, 1713, 1714, 1721, 1727, 1731, 1733], "polygamma": [419, 1677, 1728], "q_per_channel_axi": [426, 427, 1677], "zero_point": [427, 429, 795, 796, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1351, 1352, 1363, 1365, 1366, 1367, 1368, 1370, 1373, 1374, 1484, 1487, 1501, 1502, 1503, 1504, 1507, 1544, 1545, 1546, 1547, 1548, 1677, 1719, 1720, 1721], "qtensor": [431, 1677], "uniform": [434, 560, 646, 1052, 1134, 1196, 1551, 1552, 1694, 1735], "queu": [439, 692, 1699], "life": [439, 690], "cycl": [439, 622, 690, 1452, 1458, 1696, 1718], "unexpectedli": [439, 1733], "maxnorm": [443, 444, 1563, 1677], "tile": [445, 1677], "repeat_interleav": [445, 1660, 1677, 1714, 1721], "output_s": [446, 534, 1021, 1022, 1023, 1025, 1026, 1027, 1048, 1063, 1064, 1065, 1112, 1113, 1114, 1167, 1172, 1173, 1174, 1175, 1176, 1177, 1207, 1208, 1209, 1240, 1241, 1242, 1334, 1335, 1336, 1359, 1360, 1564, 1677], "is_leaf": [447, 1677, 1689], "saved_weight": 448, "loaded_weight": 448, "5503": 448, "4926": [448, 1706], "1158": 448, "8303": 448, "1007": 448, "9853": 448, "2316": 448, "6606": 448, "resiz": [451, 452, 475, 495, 496, 833, 834, 1168, 1213, 1224, 1677, 1689, 1729], "shift": [457, 649, 652, 801, 808, 1028, 1034, 1035, 1036, 1061, 1155, 1206, 1569, 1677, 1680], "decim": [459, 460, 1571, 1677, 1709, 1739], "scatter_": [464, 467, 1575, 1677], "arbitrarili": [465, 898, 1178, 1667, 1679, 1696], "indici": 465, "scatter_add_": [465, 466, 1576, 1660, 1677], "axi": [465, 467, 469, 779, 795, 821, 837, 860, 1504, 1507, 1544, 1564, 1569, 1570, 1669, 1677, 1713, 1717, 1719], "4600": 465, "2300": 465, "scatter_reduce_": [468, 1577, 1677], "scatter_reduc": [469, 1677], "sgn": [474, 830, 1595, 1677, 1689, 1727], "int16": [476, 833, 977, 1729, 1730, 1733, 1739], "dense_dim": [493, 495, 496, 1614, 1677, 1727], "nse": [494, 1727], "randint": [494, 647, 686, 824, 1002, 1039, 1165, 1196, 1197, 1610, 1677, 1681, 1690, 1732, 1735], "6550": 494, "2397": 494, "1611": 494, "0779": [494, 931, 1472, 1670], "2326": 494, "0558": 494, "4711": 494, "9678": 494, "5138": 494, "0411": 494, "9417": 494, "5158": 494, "0793": 494, "0036": [494, 994], "2569": 494, "1055": 494, "sparse_coo": [494, 535, 1606, 1609, 1610, 1614, 1727, 1730], "split_siz": [497, 1617, 1677], "squeez": [503, 588, 590, 591, 592, 594, 916, 982, 994, 996, 997, 999, 1002, 1012, 1015, 1195, 1473, 1610, 1628, 1677, 1689, 1713, 1714, 1721, 1731], "unbias": [505, 566, 686, 1034, 1035, 1036, 1071, 1079, 1080, 1081, 1088, 1155, 1623, 1624, 1662, 1663, 1677], "pad_mod": [506, 1625, 1677], "compute_uv": [517, 958, 959, 1629, 1677], "axis0": [518, 1631, 1677], "axis1": [518, 1631, 1677], "dim0": [519, 544, 545, 1632, 1645, 1677], "indices_or_sect": [529, 778, 858, 1640, 1668], "rep": 530, "5044": 531, "0005": [531, 1456, 1461], "3310": 531, "0584": [531, 1629], "cuda0": [531, 1699, 1704, 1733], "mkldnn": [533, 904], "nt": [534, 1691], "nested_tensor": [534, 1677, 1691], "6862": 534, "1282": 534, "1031": 534, "0464": 534, "3276": 534, "9967": 534, "0054": 534, "8972": 534, "9174": 534, "4995": 534, "8546": 534, "7194": 534, "2918": 534, "1846": 534, "2773": [534, 948], "8793": 534, "5183": 534, "6447": 534, "8009": 534, "8468": 534, "9832": 534, "5272": 534, "pt_infer": 534, "pt_larg": 534, "pt_small": 534, "nestedtensor": [534, 1122, 1163, 1691], "sparsedim": 535, "blocksiz": [536, 537, 1611, 1612, 1613, 1677, 1727], "bsc": [536, 1611, 1613, 1734], "sparse_bsc": [536, 1611, 1613, 1727], "row_indic": [536, 1611, 1615, 1677, 1727, 1734], "bsr": [537, 1612, 1613, 1734], "sparse_bsr": [537, 1612, 1613, 1727], "col_indic": [537, 1607, 1609, 1612, 1613, 1616, 1677, 1727, 1734], "_nnz": [538, 539, 540], "csc": [539, 1613, 1615, 1734], "012766935862600803": 541, "5415473580360413": 541, "08909505605697632": 541, "7729271650314331": 541, "largest": [542, 647, 825, 926, 947, 949, 951, 952, 967, 1250, 1385, 1643, 1677, 1678, 1679, 1739], "unitriangular": [546, 957, 1648, 1677], "tril": [548, 1677, 1714], "triu": [550, 1389, 1648, 1677, 1713, 1714], "trunc": [554, 582, 775, 819, 826, 829, 1571, 1677, 1689, 1727], "sizedim": 559, "return_invers": [561, 562, 1657, 1658, 1677], "return_count": [561, 562, 1657, 1658, 1677], "unsqueez": [564, 801, 915, 955, 1059, 1135, 1389, 1642, 1677, 1701, 1714, 1721, 1727, 1731, 1732], "subspac": [568, 958, 1122, 1465, 1629, 1630], "span": [568, 743, 744, 1052, 1629, 1724], "foral": 568, "unclear": 568, "proportion": [568, 1168, 1281, 1378], "met": [568, 934, 941, 942, 953, 967, 1122, 1163], "9482": [568, 872], "0310": 568, "4999": 568, "5316": 568, "1520": 568, "7472": 568, "5617": 568, "8649": 568, "4724": [568, 1706], "0334": 568, "2976": 568, "8499": 568, "2109": 568, "9913": 568, "9607": 568, "6123": 568, "1064483442": 568, "1124191867": 568, "1069546515": 568, "1089989247": 568, "1105482831": 568, "1061112040": 568, "1057999968": 568, "1084397505": 568, "1071760287": 568, "1123489973": 568, "1097310419": 568, "1084649136": 568, "1101533110": 568, "1073668768": 568, "1082790149": 568, "1088634448": 568, "1000000000": 568, "0047": 568, "0310j": 568, "5316j": 568, "7472j": 568, "8649j": 568, "0334j": 568, "8499j": 568, "9913j": 568, "6123j": 568, "202": 568, "154": [568, 1712], "59": [568, 1650, 1652], "182": 568, "243": [568, 892, 1629], "253": 568, "188": 568, "185": 568, "252": [568, 1712], "191": 568, "63": [568, 1712, 1719], "240": 568, "227": 568, "165": 568, "190": 568, "128": [568, 1037, 1051, 1078, 1103, 1125, 1164, 1165, 1195, 1304, 1312, 1313, 1349, 1357, 1490, 1491, 1493, 1494, 1501, 1502, 1528, 1529, 1531, 1690, 1691, 1719, 1721, 1722, 1724, 1730, 1733], "146": 568, "203": 568, "106": 568, "205": 568, "112": 568, "206": 568, "189": 568, "95": [568, 1454, 1457, 1458], "147": 568, "89": [568, 1550], "43": 568, "246": 568, "87": 568, "235": 568, "226": 568, "254": [568, 1712], "111": 568, "117": 568, "177": 568, "28": [568, 763, 1339, 1646, 1713], "xlogi": [573, 1677, 1728], "cosin": [578, 579, 683, 684, 1050, 1051, 1195, 1450, 1451, 1458, 1715], "3348": 578, "5889": 578, "2005": 578, "1584": 578, "2294": [578, 996], "2004": 578, "3690": 578, "7298": [578, 1561], "hyperbol": [579, 612, 615, 684, 1156, 1599, 1638], "uniform_": [579, 615, 646, 1677, 1689, 1694, 1701, 1728, 1735], "3192": 579, "9915": 579, "9674": 579, "7151": 579, "7791": 579, "3120": [579, 681], "2979": 579, "1341": 579, "_i": [580, 581, 582, 583, 584, 644, 646, 649, 652, 656, 671, 775, 826, 918, 920, 1006, 1164, 1468, 1472, 1558, 1593, 1626, 1670, 1728], "promot": [580, 649, 652, 661, 725, 775, 824, 826, 827, 828, 829, 1006, 1055, 1056, 1057, 1061, 1195, 1474, 1561, 1562, 1568, 1582, 1626, 1679, 1730, 1734], "0202": 580, "0985": 580, "3506": [580, 985], "6056": 580, "3944": 580, "9732": 580, "3497": 580, "6245": [580, 926], "4022": [580, 762, 1629], "3743": 580, "7724": 580, "5811": 580, "8017": 580, "7695": 580, "3930": 580, "3672": [580, 687, 927], "1450": [580, 1610], "6971": 580, "0736": [580, 1706], "0994": 580, "3216": 580, "7845": 580, "1610": 580, "1868": 580, "4090": 580, "9902": [580, 687, 927], "3667": [580, 681], "3925": 580, "6147": 580, "sum_": [581, 892, 946, 963, 1029, 1030, 1031, 1044, 1045, 1046, 1052, 1084, 1085, 1104, 1119, 1123, 1125, 1625, 1641, 1646, 1664, 1728], "mathbin": [581, 584, 585, 644, 656, 1607], "doubletensor": [581, 582, 583, 584, 585, 644, 1583, 1730, 1733], "tensorfloat32": [581, 584, 644, 656, 990, 1001, 1044, 1045, 1046, 1047, 1048, 1049, 1103, 1188, 1189, 1190, 1191, 1192, 1193, 1230, 1585, 1699, 1709], "rocm": [581, 584, 644, 656, 990, 1001, 1044, 1045, 1046, 1047, 1048, 1049, 1069, 1087, 1103, 1675], "6311": 581, "0503": 581, "9768": [581, 1706], "0362": 581, "1653": 581, "8185": 581, "4255": [581, 1006], "6760": 581, "9453": 581, "5743": 581, "8202": 581, "3691": 581, "0943": 581, "1109": [581, 1070], "4730": [581, 1641], "histor": [582, 739, 1056, 1698, 1706, 1711], "t1": [582, 583, 610, 848, 1319, 1678, 1724, 1725], "2312": [582, 1610], "6496": 582, "1312": 582, "0428": 582, "4292": 582, "1030": 582, "5369": 582, "9829": 582, "0430": 582, "8635": 583, "6391": 583, "6174": 583, "7617": 583, "5879": 583, "7388": 583, "8353": 583, "6249": 583, "6511": 583, "8716": 584, "4671": 584, "3746": 584, "7573": 584, "9555": 584, "8681": 584, "3768": 585, "5565": 585, "otim": [586, 915, 1067, 1212], "conj": [587, 680, 797, 798, 800, 802, 809, 811, 815, 816, 818, 924, 925, 931, 933, 952, 1566, 1567, 1677, 1703, 1733], "mh": [587, 667, 931, 1629, 1677, 1731, 1733], "lvert": [589, 884, 1164, 1249, 1734], "rvert": [589, 884, 1734], "leq": [589, 645, 646, 681, 799, 801, 884, 915, 919, 934, 940, 1039, 1058, 1119, 1121, 1123, 1197, 1248, 1251, 1625, 1694, 1728], "elementwis": [589, 681, 699, 725, 726, 824, 826, 1020, 1079, 1080, 1081, 1153, 1271, 1661, 1679, 1703, 1728], "07": [589, 667, 668, 784, 932, 935, 940, 952, 953, 959, 982, 986, 1384, 1436, 1501, 1502, 1503, 1504, 1507, 1629], "09": [589, 1436, 1448], "8177": 590, "4878": 590, "2491": 590, "9130": 590, "7158": 590, "1775": 590, "0992": 590, "4817": 590, "0053": 590, "0164": 590, "3738": 590, "0507": 590, "9700": 590, "1106": 590, "0318": 590, "0816": [590, 985], "6451": 591, "4866": 591, "2987": 591, "3312": 591, "5744": 591, "2980": [591, 1691], "8397": 591, "2713": 591, "9128": 591, "9214": 591, "7268": 591, "2995": 591, "9023": [591, 925], "4853": 591, "9075": 591, "6165": 591, "180": [593, 764, 1550], "14159": [593, 1639], "135": 593, "45": [593, 1035, 1036, 1080, 1081, 1155, 1415, 1713], "lceil": [595, 665], "rceil": [595, 665], "gap": [595, 1558, 1675, 1719], "adjac": [595, 655, 1055, 1056, 1057, 1061, 1558], "set_default_tensor_typ": [595, 645, 654, 782, 784, 794, 799, 817, 835, 842, 852, 853, 914, 965, 981, 1426, 1551, 1553, 1555, 1557, 1558, 1611, 1612, 1613, 1614, 1615, 1616, 1650, 1652, 1672], "get_default_dtyp": [595, 965, 981, 1558, 1729, 1730, 1739], "5000": [595, 616, 617, 618, 647, 671, 799, 801, 802, 809, 812, 817, 827, 829, 830, 831, 848, 854, 857, 920, 946, 965, 1012, 1014, 1041, 1042, 1060, 1168, 1476, 1547, 1548, 1549, 1558, 1562, 1728, 1733], "maxim": [604, 994, 1112, 1113, 1114, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1444, 1445, 1446, 1447, 1727], "3398": 604, "2663": [604, 1699], "2686": 604, "2450": 604, "7401": 604, "8805": 604, "3402": 604, "1936": 604, "4907": [604, 982], "3948": [604, 681], "0691": 604, "3132": 604, "6092": 604, "5419": 604, "2993": [604, 1628], "3195": 604, "1139": 605, "2254": 605, "1381": [605, 1628], "3687": 605, "0100": [605, 948, 1544], "1975": [605, 1691], "0102": 605, "4732": 605, "9240": 605, "1207": [605, 1006], "7506": 605, "0213": 605, "7809": 605, "2960": 605, "9384": 605, "1438": 605, "ascend": [606, 801, 931, 933, 962, 1005, 1578, 1603, 1633, 1657], "0785": 606, "5267": 606, "8521": 606, "4065": 606, "1598": 606, "0788": 606, "0745": 606, "2700": 606, "2208": 606, "0722": 606, "7064": 606, "2564": 606, "0669": 606, "2318": 606, "8229": 606, "9280": 606, "lexicograph": [607, 1421, 1679, 1727], "9039": 608, "6291": 608, "0795": [608, 1476, 1706], "1586": 608, "1939": 608, "4900": 608, "1909": 608, "7503": 608, "9355": 608, "histori": [609, 610, 1436, 1639, 1701, 1702, 1725], "requeset": 609, "dlpack": [610, 832, 1675], "frombuff": 610, "data_ptr": [610, 1689, 1729, 1731], "addbackward0": [610, 1706, 1711], "__array_interface__": 610, "5962": 611, "4985": 611, "4396": 611, "4525": [611, 1691], "6387": 611, "4552": 611, "sine": [612, 1597, 1599], "1606": 612, "4267": 612, "0899": 612, "0250": 612, "1599": 612, "1534": 612, "9435": 612, "8990": [612, 775], "arctang": [613, 614], "2341": 613, "2539": 613, "6256": 613, "6448": 613, "2299": 613, "2487": 613, "5591": [613, 634], "5727": 613, "quadrant": 614, "9041": [614, 664], "0196": [614, 664], "3108": [614, 664], "4423": [614, 664], "9833": 614, "0811": 614, "9743": 614, "4151": 614, "tangent": [615, 624, 625, 1156, 1637, 1638], "9385": 615, "2968": 615, "8591": 615, "1871": 615, "7253": 615, "3060": 615, "2899": 615, "1893": 615, "4584": 616, "7583": 616, "2086": [617, 775], "5165": 617, "1757": 617, "5194": [617, 1597], "8079": 618, "7460": [618, 951, 1422], "1647": 618, "4734": 618, "5689": 618, "vjp": [619, 620, 1667, 1701], "needs_input_grad": [619, 1701], "save_for_forward": 620, "jvp": [620, 623, 624, 625, 1701], "grad_input": [621, 627, 629, 895, 1116, 1318, 1701, 1706], "grad_tensor": [622, 636, 1677, 1699], "grad_vari": 622, "forward_ad": 623, "dual": [623, 624, 625, 1420], "x_t": [623, 625, 1034, 1035, 1036, 1068, 1079, 1080, 1081, 1086, 1131, 1155, 1353, 1431], "make_du": [623, 625], "your_fn": 623, "unpack_du": [623, 624], "grad_aft": 623, "dual_level": [624, 625], "primal": 625, "x_npy": 626, "once_differenti": [626, 627, 628, 629, 1701], "g1": [627, 629, 1699, 1726], "g2": [627, 629, 1699, 1726], "oppos": 628, "weren": 628, "grad_out": [628, 1677, 1703], "gx": 628, "gy": 628, "gz": 628, "simplefunc": 629, "induc": [629, 1213, 1251, 1694], "outer_jacobian_strategi": 630, "disconnect": [630, 631, 632, 633, 634, 635], "said": [630, 631, 632, 633, 634, 635], "cliff": [630, 632, 636], "_debug_only_display_vmap_fallback_warn": [630, 636], "pow_reduc": [630, 631, 634], "2265": 630, "8221": 630, "9456": [630, 646], "2550": 630, "viewbackward": [630, 632], "pow_adder_reduc": [630, 631, 634], "func_output": [631, 633, 634, 635], "1448": 631, "0239": 631, "6456": 631, "4988": 631, "4310": 631, "sumbackward0": [631, 634], "mulbackward0": [631, 634, 635], "3030": 631, "significantli": [631, 1319, 1585], "vhp": 631, "jacrev": 632, "jacfwd": 632, "batched_grad": 632, "exp_reduc": [632, 633, 635], "4917": 632, "4352": 632, "4369": 632, "3799": 632, "exp_add": 632, "8052": 632, "3963": 632, "3090": 633, "6742": 633, "9114": 633, "2106": 633, "sumbackward1": [633, 635], "squeezebackward1": 633, "adder": [633, 635], "2399": 633, "5005": 633, "0689": 634, "2431": 634, "0989": 634, "4456": 634, "8053": [634, 1573], "7817": 635, "2458": 635, "7830": 635, "7782": 635, "4458": 635, "3962": 635, "3042": [635, 952], "6354": 635, "1288": 635, "0652": 635, "5483": 635, "5035": 635, "2046": [635, 681], "1292": 635, "1432": 635, "3059": 635, "3225": 635, "6652": 635, "7753": 635, "0152": 635, "4225": 635, "3340": 635, "only_input": 636, "allow_unus": [636, 1677], "is_grads_batch": 636, "require_grad": [636, 1679, 1696], "ep": [637, 638, 904, 980, 993, 1020, 1034, 1035, 1036, 1051, 1070, 1071, 1079, 1080, 1081, 1088, 1089, 1090, 1091, 1098, 1099, 1100, 1125, 1130, 1155, 1159, 1161, 1163, 1164, 1183, 1195, 1210, 1214, 1215, 1223, 1227, 1249, 1252, 1256, 1278, 1296, 1297, 1298, 1299, 1300, 1301, 1307, 1308, 1329, 1330, 1342, 1344, 1345, 1346, 1347, 1385, 1416, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1447, 1459, 1501, 1502, 1503, 1504, 1507, 1546, 1677, 1701, 1703, 1728, 1739], "06": [637, 638, 935, 940, 941, 952, 953, 958, 1070, 1125, 1164, 1167, 1210, 1252, 1278, 1431, 1445, 1629, 1677, 1734], "raise_except": [637, 638], "check_sparse_nnz": 637, "nondet_tol": [637, 638], "check_undefined_grad": [637, 638], "check_grad_dtyp": [637, 638], "check_batched_grad": [637, 638], "check_batched_forward_grad": 637, "check_forward_ad": 637, "check_backward_ad": 637, "fast_mod": [637, 638, 1703], "perturb": [637, 638, 1703], "sparsetensor": [637, 1614], "gradgradcheck": [637, 1701], "gen_non_contig_grad_output": 638, "check_fwd_over_rev": 638, "check_rev_over_rev": 638, "noncontigu": [638, 725, 1734], "inaccuraci": 638, "eventlist": [640, 641], "chrome": [640, 1718], "group_by_stack_n": [641, 1718], "roof": 641, "functioneventavg": [641, 643], "window_length": [645, 654, 852, 853, 914, 1677], "2n": 645, "trim": [645, 654, 797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 852, 853, 892], "_length": [645, 654, 852, 853, 892, 1039, 1625], "sim": [646, 1130, 1256, 1468, 1555], "pseudorandom": [646, 1007, 1423, 1465, 1468, 1551, 1553, 1555, 1557, 1630], "1737": 646, "0950": [646, 1607], "3609": 646, "7148": 646, "0289": [646, 1649], "2676": 646, "8937": 646, "7202": 646, "2500": [647, 799, 801, 802, 812, 817, 965, 1168, 1549], "7500": [647, 802, 812, 831, 848, 950, 965, 1168, 1549], "AND": [648, 976, 1679, 1696], "arithmet": [649, 652, 666, 950, 1568, 1680, 1687, 1689, 1690, 1709, 1719, 1730], "OR": [651, 978, 1679], "xor": [653, 979, 1679], "blackman": 654, "arrang": 655, "corner": [655, 1168, 1178, 1213, 1224, 1281, 1372, 1378], "broadcast_tensor": [657, 1677, 1714], "out_int32": [660, 1578, 1677], "formal": [660, 1578, 1690], "eg": [660, 1571, 1578, 1704], "tensor_a": [662, 675], "tensor_b": 662, "understood": 663, "6580": 663, "0969": 663, "4614": 663, "1034": [663, 781], "5790": 663, "1497": 663, "x2": [664, 942, 1108, 1164, 1165, 1195, 1252, 1677], "compute_mod": 664, "use_mm_for_euclid_dist_if_necessari": 664, "distanc": [664, 892, 930, 931, 958, 1016, 1076, 1125, 1164, 1165, 1253, 1452, 1625, 1629], "infti": [664, 892, 946, 1032, 1084, 1085, 1147, 1253, 1443, 1728], "use_mm_for_euclid_dist": 664, "donot_use_mm_for_euclid_dist": 664, "spatial": [664, 801, 1035, 1063, 1088, 1128, 1129, 1150, 1167, 1168, 1169, 1170, 1178, 1213, 1224, 1253, 1254, 1255, 1281, 1282, 1283, 1372, 1378, 1379, 1380], "minkowski": [664, 1253], "ham": [664, 852, 1253], "closest": [664, 1253], "xn": [664, 1253], "4821": [664, 667], "059": 664, "0590": 664, "1763": [664, 1561], "4713": [664, 1561], "6986": [664, 1561], "3702": [664, 1561], "1193": [664, 985], "0959": 664, "7138": 664, "8322": 664, "2830": [664, 1651], "3791": 664, "6341": 665, "4208": 665, "0900": 665, "5826": 665, "lowest": [666, 1011, 1394, 1395, 1403, 1404, 1553, 1554, 1701, 1734], "clr": [666, 1452], "3375": 666, "9790": 666, "1119": 666, "6577": 666, "5609": [666, 1204], "5095": 666, "2614": 666, "4038": 666, "3378": [666, 1651], "4982": 666, "2457": [666, 999], "2561": 666, "4684": 666, "7163": 666, "9647": 666, "8917": [666, 975], "3213": [666, 971], "2284": [666, 760], "8615": 666, "2816": 666, "u": [667, 668, 669, 931, 933, 937, 941, 942, 958, 985, 987, 1037, 1044, 1045, 1046, 1047, 1048, 1049, 1068, 1069, 1086, 1087, 1101, 1103, 1131, 1133, 1134, 1155, 1166, 1353, 1389, 1465, 1629, 1630, 1633, 1677, 1694, 1696, 1716], "tu": 667, "mt": [667, 668, 924, 931, 933, 937, 938, 939, 944, 953, 1475, 1629, 1633, 1677, 1731, 1733], "4112": 667, "7486": 667, "4551": 667, "3544": 667, "6724": 667, "5528": 667, "0592": [667, 1706], "9371": 667, "5487": 667, "7023": 667, "03": [667, 668, 972], "3842e": 667, "dpotri": 668, "spotri": 668, "uu": 668, "9935": 668, "6353": 668, "5806": 668, "8769": 668, "7183": [668, 946, 1706], "6618": 668, "9314": 668, "2251": [668, 687, 927, 969], "0889": 668, "4439": 668, "2122": 668, "1412": 668, "5894e": 668, "semidefinit": 669, "7747": 669, "9549": 669, "3086": 669, "4114": 669, "8733": 669, "6355": 669, "9891": 669, "1974": 669, "4706": 669, "4115": 669, "6225": 669, "1625": 669, "6097": 669, "8398": 669, "2387": [669, 682], "3771": [669, 941], "4173": 669, "1626": [669, 687, 927], "tensor_split": [670, 778, 858, 1668, 1677, 1714, 1731], "dimes": 670, "min_valu": [671, 1075], "max_valu": [671, 1075, 1677], "_valu": [671, 1024, 1382, 1614, 1701, 1727], "7120": 671, "1734": [671, 869], "0478": [671, 1670], "0922": 671, "3333": [671, 848, 857, 1168, 1169, 1639], "horizont": [674, 858, 860, 1717], "hstack": [674, 1677, 1727], "with_replac": [675, 1677], "combinations_with_replac": 675, "_glibcxx_use_cxx11_abi": 676, "flip": [679, 822, 823, 962, 1677, 1714], "lazi": [679, 907, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1314, 1447], "writeabl": [679, 680], "is_conj": [679, 1566, 1677], "geq": [681, 839, 926, 934, 983, 1052, 1102, 1123, 1124, 1134, 1196, 1248, 1384, 1694, 1728], "signbit": [681, 1677, 1727], "2557": 681, "0026": 681, "5387": 681, "4740": 681, "9244": 681, "7079": 681, "2778": 681, "0249": [681, 970], "5719": 681, "0059": 681, "2600": 681, "4475": 681, "9567": [681, 930, 1628], "5757": 681, "1751": 681, "0742": 681, "2998": 681, "1054": 681, "2373": 681, "3190": [681, 1699], "1128": [681, 952, 1086], "pearson": 682, "coeffici": [682, 852, 1431, 1433, 1434, 1435, 1437, 1443, 1447, 1648], "r_": [682, 1641], "ij": [682, 781, 974, 982, 998, 1119], "c_": [682, 1044, 1045, 1046, 1047, 1048, 1049, 1086, 1128, 1129], "ii": [682, 781, 1086, 1087], "jj": 682, "hermitian": [682, 797, 798, 800, 802, 803, 804, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 924, 925, 930, 931, 933, 937, 938, 939, 949, 952, 958, 993, 1633, 1677], "cov": [682, 1677], "2678": [682, 1059], "0908": 682, "3766": 682, "2780": 682, "5812": 682, "1535": [682, 1059], "2350": 682, "3582": 682, "4309": 683, "2706": 683, "8562": 683, "9796": 683, "1395": 683, "2957": 683, "6553": 683, "5574": 683, "1632": 684, "1835": 684, "6979": 684, "7325": [684, 770], "0133": 684, "7860": 684, "2536": 684, "2805": 684, "sleef": [684, 1599], "_w": 686, "x_": [686, 791, 968, 969, 971, 974, 982, 1033, 1052, 1106, 1123, 1149, 1151, 1268, 1502, 1503, 1608, 1646, 1696, 1722, 1728], "y_": [686, 791, 968, 969, 971, 1033, 1052, 1082, 1646, 1696, 1728], "w_i": [686, 934], "mu_x": 686, "mu_i": [686, 1437], "whichev": [686, 1213, 1476, 1699], "w_ix_": 686, "bessel": [686, 914, 1623, 1624, 1662, 1663, 1728], "corrcoef": [686, 1677], "6667": [686, 857, 1168, 1169, 1563, 1711], "fw": 686, "4282": 686, "0255": [686, 767], "4144": [686, 1699], "4169": 686, "3956": [687, 927], "1455": [687, 927, 1712], "6895": [687, 927], "5849": [687, 927], "3599": [687, 927], "7180": [687, 927], "0521": [687, 927], "1339": [687, 927], "0225": [687, 927], "0257": [687, 927], "4725": [687, 927], "1479": [687, 927], "7005": [687, 927], "9757": [687, 927], "3904": [687, 927], "3726": [687, 927], "1836": [687, 927], "9688": [687, 927], "7153": [687, 927, 1728], "2159": [687, 927], "0844": [687, 927], "5281": [687, 927], "6120": [687, 927], "4490": [687, 927], "5687": [687, 927], "9792": [687, 761, 927], "8304": [687, 927], "3037": [687, 927, 1706], "5650": [687, 927], "2329": [687, 927], "9883": [687, 927], "0551": [687, 927], "capture_begin": [688, 1699], "make_graphed_cal": [688, 1699], "graph_pool_handl": [688, 717], "other_graph_inst": [688, 717], "hint": [688, 717, 896, 1676, 1678, 1679, 1699], "capture_end": [688, 1699], "replai": [688, 717, 1699], "enable_tim": [689, 1699], "interprocess": 689, "marker": 689, "elapsed_tim": [689, 1699], "end_ev": [689, 1699], "elaps": [689, 1687], "from_ipc_handl": 689, "reconstruct": [689, 985, 1032, 1033, 1703, 1711, 1716], "ipc": [689, 721], "ipc_handl": 689, "current_stream": [689, 1699], "proceed": [689, 1070, 1725, 1726], "cudaeventsynchron": 689, "submit": [689, 690, 691, 1699, 1710], "cudastreamwaitev": [689, 690, 691], "stream_ptr": 690, "cudastream_t": 690, "incorrectli": [690, 826], "record_ev": [690, 691], "cudastreamsynchron": [690, 691], "wait_ev": [690, 691], "interoper": 693, "caching_allocator_delet": 693, "mem_ptr": 694, "caching_allocator_alloc": 694, "peer_devic": 695, "buffer_s": 697, "10485760": 697, "chunk_siz": 700, "cublashandle_t": 701, "unoccupi": 708, "smi": [708, 735, 741, 758, 1699, 1702, 1704], "_cudadeviceproperti": 712, "gencod": 713, "eagerli": [714, 720, 1699], "cuda_graph": 717, "cudagraph": [717, 1699], "ordinari": [719, 1319, 1695], "code_str": [725, 726], "templat": [725, 726, 1715], "temp": 725, "dir": [725, 1674, 1679, 1716], "boardcast": 725, "typenam": [725, 726], "my_kernel": [725, 726], "jitted_fn": [725, 726], "create_jit_fn": [725, 726], "mulitpl": 725, "util_fn": 725, "val": [725, 901, 1677, 1679, 1694], "gelu": [725, 1145, 1159, 1161, 1163, 1265, 1677, 1714], "my_gelu": 725, "my_lib": [725, 1683, 1712], "impl": [725, 1683], "num_output": 726, "sample_arg": 728, "num_warmup_it": 728, "datadistributedparallel": 728, "silent": [729, 730, 748, 749, 869, 910, 1116, 1699, 1713], "insuffici": 729, "manual_seed_al": 729, "occupi": [731, 734, 735, 745, 1104, 1231, 1699, 1704, 1739], "reset_peak_memory_stat": [731, 733, 745, 746], "max_memory_reserv": [732, 1699, 1704], "cudamemgetinfo": 734, "memory_reserv": [736, 1699, 1704], "snapshot": [738, 1679, 1699, 1704], "large_pool": 739, "small_pool": 739, "allocated_byt": 739, "cudamalloc": 739, "reserved_byt": 739, "active_byt": 739, "inactive_split": 739, "inactive_split_byt": 739, "octob": 739, "1mb": 739, "num_alloc_retri": 739, "num_oom": 739, "frament": 739, "assist": [739, 1700], "max_split_s": 739, "oversize_alloc": 739, "oversize_seg": 739, "abbrevi": 740, "percent": [741, 758], "instantan": 742, "ascii": [742, 744, 966, 1679], "pop": [743, 1117, 1126, 1714, 1717], "max_memory_alloc": [745, 1699, 1704], "max_memory_cach": 746, "memory_stat": [747, 1699, 1704], "seed_al": 748, "environment": 750, "total_memori": 751, "debug_mod": [755, 1584], "streamcontext": 756, "And": [759, 760, 916, 994, 999, 1039, 1482, 1506, 1696, 1701, 1712, 1713, 1719], "x_1": [759, 760, 761, 762, 962, 1037, 1050, 1051, 1184, 1195, 1646], "x_2": [759, 760, 761, 762, 962, 1037, 1050, 1051, 1184, 1195], "x_3": [759, 760, 761, 762, 962], "3449": 759, "5447": 759, "0685": 759, "5104": [759, 1699], "1706": 759, "2259": 759, "4696": 759, "3284": 759, "9946": 759, "8209": [759, 762], "6628": 760, "0975": 760, "2680": [760, 1698], "3298": [760, 767], "4220": 760, "3885": 760, "1762": 760, "9165": 760, "6684": [760, 872], "overflow": [761, 762, 996, 1012, 1015, 1232, 1268, 1269, 1473, 1571, 1605, 1608, 1628, 1650, 1652, 1699, 1709, 1728], "6001": 761, "2069": 761, "1919": 761, "6727": [761, 774], "0062": 761, "4126": 761, "2129": 761, "4206": 761, "1968": [761, 1728], "1241": 761, "0238": 761, "0233": [761, 1550], "0157": 761, "0158": [761, 1629], "0065": 761, "0014": [761, 1728], "0006": 761, "8286": 762, "4890": 762, "5155": 762, "8443": 762, "1865": 762, "1752": [762, 770], "0595": 762, "1850": 762, "1571": [762, 1706, 1711], "4243": 762, "3175": 762, "8020": [762, 1473], "0423": 762, "2289": 762, "0537": 762, "0058": 762, "9780": 762, "trapezoid": [763, 1647, 1677], "360": 764, "2832": 764, "fp32": [765, 1319, 1374, 1699, 1709, 1719, 1720, 1722], "diagflat": [767, 1677], "5950": 767, "0872": 767, "4264": 767, "1064": [767, 1706], "8795": 767, "2429": 767, "1374": 767, "1029": 767, "6482": 767, "6300": 767, "5410": 768, "2934": 768, "1788": [768, 1728], "5684": 768, "0845": [768, 1599, 1706], "3986": 768, "2956": [769, 927], "9068": 769, "1695": 769, "2094": [769, 1699], "3018": 769, "1516": 769, "9342": 769, "diag_emb": [770, 930, 931, 958, 1629, 1633, 1677], "0854": 770, "1431": 770, "8536": 770, "0905": 770, "0360": [770, 1006], "6927": 770, "3735": 770, "4945": 770, "2631": [770, 1005, 1699], "3755": 770, "5977": 770, "8172": 770, "1065": [770, 1706], "0401": 770, "2235": [770, 1628], "7938": 770, "3081": 770, "6166": 770, "2335": 770, "0500": 770, "7336": 770, "3836": 770, "1015": 770, "emb": [771, 1581, 1600], "5393": 774, "8675": 774, "5916": 774, "6321": 774, "0967": 774, "0511": 774, "6295": 774, "8360": 774, "6973": 774, "6537": 774, "dividend": [775, 826, 829, 1562, 1653], "true_divid": [775, 1677, 1714], "3810": [775, 856], "2774": 775, "2972": 775, "3719": 775, "4637": 775, "7620": 775, "5548": 775, "5944": 775, "7438": 775, "9274": 775, "3711": 775, "9353": 775, "4605": 775, "2917": 775, "1815": [775, 975], "0111": 775, "9805": 775, "5923": 775, "1062": 775, "4581": [775, 934], "7759": 775, "2344": [775, 1633], "1830": 775, "0313": 775, "1908": 775, "4757": 775, "8032": 775, "2930": 775, "8113": 775, "2308": 775, "4620": [775, 1670], "6051": 775, "5676": 775, "2639": 775, "2260": 775, "4509": [775, 948], "1322": 775, "9764": 775, "9564": 775, "3484": 775, "2278": 775, "1068": [775, 869], "4678": 775, "3938": [775, 1634], "depthwis": [778, 779, 1044, 1045, 1046], "atleast_3d": [779, 1677], "eigenvalu": [780, 924, 930, 931, 932, 933, 946, 949, 952, 957, 958, 967, 993, 1465, 1633, 1677], "l_complex": 780, "eigval": [780, 930, 1677], "v_complex": 780, "operand": [781, 1679, 1680, 1701, 1727, 1730], "notat": [781, 1082, 1590, 1680, 1706, 1733], "einstein": 781, "summat": [781, 892, 974, 982, 1727], "subscript": [781, 1680], "jk": 781, "ik": [781, 967], "za": 781, "subcript": 781, "alphabet": [781, 1197, 1724], "arrow": [781, 1726], "ki": 781, "ellipsi": [781, 1679, 1680, 1690], "fourth": 781, "whitespac": [781, 1680], "opt_einsum": 781, "readthedoc": 781, "sublist": 781, "52": 781, "op1": [781, 1679], "sublist1": 781, "op2": [781, 1679], "sublist2": 781, "subslist_out": 781, "2104": 781, "7952": 781, "2433": 781, "4545": 781, "1156": 781, "2897": [781, 1706], "3918": 781, "4963": 781, "3744": 781, "9381": 781, "2685": 781, "6070": 781, "7208": 781, "8058": 781, "4419": 781, "0936": 781, "1713": 781, "4291": 781, "5802": 781, "7350": [781, 1728], "5704": 781, "4290": 781, "9323": 781, "4480": 781, "bs": 781, "bij": 781, "bjk": 781, "bik": 781, "0564": 781, "5904": 781, "2023": 781, "1271": 781, "6706": [781, 1476], "8097": 781, "8025": 781, "1183": 781, "2239": [781, 954], "3107": 781, "5756": 781, "2354": 781, "4558": 781, "3460": 781, "5087": 781, "8530": [781, 1041], "8153": 781, "8787": 781, "3839": [781, 1666], "2112": [781, 1649], "3728": 781, "1131": [781, 1473], "0921": 781, "8305": 781, "ji": 781, "bn": [781, 904, 1286, 1287, 1288, 1289, 1290, 1291, 1499, 1539, 1711, 1715, 1719, 1720], "anm": 781, "bm": 781, "ba": 781, "3430": [781, 975], "2405": 781, "4494": 781, "3311": 781, "5201": 781, "0356": 781, "4064e": 782, "8000e": 782, "3493e": 782, "5751e": 782, "1428e": 782, "5955e": 782, "9683e": 784, "1239e": 784, "0705e": 784, "set_grad_en": [785, 1677, 1735], "parenthesi": [785, 870, 1420], "doubler": [785, 1420], "elsewher": [786, 794, 839, 851, 885, 887, 888, 891, 919, 984, 1017, 1607, 1674], "quant_min": [795, 796, 1484, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1501, 1502, 1503, 1504, 1507, 1513, 1514, 1524, 1527, 1528, 1529, 1530, 1531, 1677, 1719, 1721], "quant_max": [795, 796, 1484, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1501, 1502, 1503, 1504, 1507, 1513, 1514, 1524, 1527, 1528, 1529, 1530, 1531, 1677, 1719, 1721], "quant": [795, 796, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1323, 1324, 1325, 1479, 1520, 1541, 1719, 1720], "_max": [795, 796, 1719], "_min": [795, 796, 1719], "nearbi": [795, 796], "_int": [795, 796], "_point": [795, 796], "fake_quant": [795, 796, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1524, 1528, 1529, 1531, 1721, 1737], "2525": 795, "0466": 795, "3491": [795, 948], "2168": [795, 1641], "5906": [795, 1728], "6258": 795, "6444": 795, "0542": 795, "0475": [795, 1728], "0486": 795, "255": [795, 796, 834, 1213, 1224, 1281, 1487, 1488, 1489, 1492, 1524, 1528, 1529, 1719, 1721, 1732], "3405": 795, "6134": [795, 999], "6323": 795, "0552": 796, "9730": 796, "3973": 796, "0780": 796, "4000": [796, 799, 808, 817, 1168, 1546], "6000": [796, 1159, 1161, 1163, 1168, 1546, 1593], "fourier": [797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 892, 1625], "rfft": [797, 802, 812, 816, 817, 818], "compact": [797, 798, 800, 937, 939, 942, 1701, 1713, 1719], "chalf": [797, 798, 800, 802, 803, 804, 805, 806, 807, 812, 813, 814, 1677, 1733], "sm53": [797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818], "ortho": [797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 967], "orthonorm": [797, 798, 800, 802, 803, 804, 805, 806, 807, 809, 810, 811, 812, 813, 814, 815, 816, 818, 958, 1384, 1629, 1633], "ifft": [797, 801, 802, 806, 807, 809, 810, 811, 812, 813, 814], "fftn": [798, 801, 807, 810, 818], "rfft2": [798, 813], "ifft2": [798, 810], "two_fft": [798, 800, 810, 816, 818], "assert_clos": [798, 800, 801, 806, 807, 812, 813, 814, 816, 818, 1676, 1734], "check_strid": [798, 800, 801, 806, 807, 812, 813, 814, 816, 818, 1734], "nyquist": [799, 801, 809, 811, 815, 816, 817, 818], "i_1": [800, 818, 915], "i_n": [800, 818, 915, 1641, 1667], "rfftn": [800, 804, 810, 814, 816], "ifftn": [800, 806, 811], "reorder": [801, 950], "rearrang": [801, 808, 1040, 1128, 1129, 1254, 1255, 1690], "fftfreq": [801, 808, 817], "9000": [801, 1639], "8000": [801, 1012, 1168, 1476], "uncent": 801, "ifftshift": 801, "x_center": 801, "x_uncent": 801, "fft_uncent": 801, "fft_center": 801, "x_centered_2": 801, "ihfft": [802, 810, 811], "irfft": [802, 814, 815], "symmetri": [802, 804, 1625], "opposit": [802, 804, 1629], "transformed_dim_s": [802, 812], "0000j": [802, 809, 812, 924, 925, 930, 931, 933, 1469, 1593], "1250": [802, 1005], "1720j": 802, "0406j": 802, "2809": 802, "6250": [802, 812, 831, 1168], "9691": 802, "hfftn": [803, 811], "last_dim_s": [803, 804, 813, 814], "ihfft2": 803, "roundtrip": [803, 804, 812, 813, 814], "herimitian": 804, "ihfftn": [804, 810], "irfftn": [804, 813, 818], "fft2": [806, 816], "two_ifft": [806, 807, 811], "fftshift": 808, "hfft": 809, "6882j": 809, "1625j": 809, "hfft2": 810, "8602j": 812, "2031j": 812, "1562": 812, "3511": 812, "7812": 812, "2114": 812, "irfft2": 816, "wider": [824, 1676, 1679, 1715], "49": [824, 950, 1698], "2500e": 824, "1000e": 824, "7656e": 824, "04": [824, 972], "lfloor": [825, 830, 1024, 1029, 1030, 1031, 1044, 1045, 1046, 1063, 1084, 1085, 1109, 1110, 1111, 1167, 1168, 1169, 1170, 1182, 1251, 1558, 1625], "rfloor": [825, 830, 1024, 1029, 1030, 1031, 1044, 1045, 1046, 1063, 1084, 1085, 1109, 1110, 1111, 1167, 1168, 1169, 1170, 1182, 1251, 1558, 1625], "8166": [825, 1623, 1624, 1662, 1663], "5308": 825, "2530": 825, "2091": 825, "7000": [827, 1060, 1595], "3000": [828, 1059, 1595, 1699], "entrywis": [829, 1562], "modulu": [829, 954, 1562], "operatornam": [830, 930, 931, 932, 933, 950, 958, 1032, 1033, 1039, 1076, 1077, 1083, 1107, 1147, 1165, 1595], "8750": [831, 1168], "sparse_grad": [837, 1677], "tau": [840, 934, 1215, 1432, 1446, 1462, 1463, 1677], "elementari": [840, 1696, 1703], "reflector": [840, 1384, 1463], "household": [840, 934, 1384, 1463], "householder_product": [840, 1384, 1462], "gel": [840, 940], "set_default_dtyp": 842, "set_deterministic_debug_mod": [843, 1660], "set_float32_matmul_precis": 844, "edge_ord": [848, 1677], "mathbb": [848, 924, 926, 930, 931, 932, 933, 934, 935, 940, 941, 944, 946, 953, 955, 957, 958, 1052, 1123, 1384], "rightarrow": 848, "central": [848, 1703, 1705], "closer": [848, 1165, 1476, 1706], "interior": 848, "theorem": 848, "h_r": 848, "neighbor": [848, 892, 1168, 1170, 1625], "x_r": 848, "approx": [848, 1630, 1703], "h_l": 848, "edg": [848, 856, 857, 1224, 1281, 1372, 1378, 1725], "outermost": 848, "80": [848, 950, 1456, 1590, 1699, 1715], "translat": [848, 1696, 1726], "halv": 848, "coord": 848, "54": [852, 1078], "46": 852, "hann_window": [852, 1625, 1677, 1681, 1714], "hann": 853, "histogram": [855, 857, 1501, 1677, 1732], "hist": [856, 857, 1677], "bin_edg": [856, 857, 1677], "9524": 856, "leftmost": 857, "volum": 857, "leg": 861, "triangl": [861, 1732], "hypotenus": 861, "4031": 861, "gammainc": [863, 1728], "gammaincc": [864, 1728], "index_reduce_": [868, 1677], "realloc": 869, "1427": 869, "0231": 869, "5414": 869, "0009": 869, "4664": [869, 1641], "2647": 869, "1228": 869, "6571": 869, "7230": 869, "6004": 869, "inferencemod": [870, 1696], "bump": 870, "_version": 870, "multidimension": [872, 1079], "8173": 872, "0874": 872, "1784": 872, "3279": 872, "7894": 872, "4682": 872, "7159": 872, "1506": 872, "4034": 872, "3657": 872, "0387": 872, "9892": 872, "1774": 872, "3261": 872, "3917": 872, "4537": [872, 1314], "7493": 872, "1724": 872, "2291": 872, "5749": 872, "2267": 872, "7920": 872, "3607": 872, "3701": 872, "3666": 872, "5850": [872, 925], "7242": 872, "9837": 872, "1560": 872, "2907": 872, "6785": 872, "5671": [872, 926], "5452": 872, "6912": 872, "5509": 872, "1782": 872, "9843": 872, "7366": 872, "5672": [872, 1423], "5115": 872, "4864": 872, "2476": 872, "4337": 872, "6347": 872, "1748": 872, "3567": [872, 925], "6558": 872, "2469": [872, 1706], "5787": [872, 975], "typecheck": 882, "mypi": [882, 1678, 1679], "warn_alwai": 883, "set_warn_alwai": 883, "nonfinit": 884, "test_el": [886, 1677], "assume_uniqu": [886, 1677], "0j": [891, 1664], "nola": 892, "envelop": 892, "hop": [892, 1625], "shorter": [892, 1713, 1724], "griffin": 892, "ieee": [892, 1070, 1709], "tran": 892, "assp": 892, "vol": [892, 1070], "pp": [892, 1070], "236": 892, "apr": 892, "1984": 892, "fft_size": 892, "n_frame": 892, "slide": [892, 1029, 1030, 1031, 1063, 1109, 1110, 1111, 1167, 1207, 1237, 1238, 1239, 1280, 1547, 1548, 1625], "signal_length": 892, "scriptmodul": [893, 894, 899, 902, 905, 906, 910, 911, 1676, 1678, 1685, 1713], "implic": [893, 910, 1724], "attributemodul": 893, "names_ag": 893, "9223372036854775807": [893, 1410, 1687], "get_debug_st": 894, "graphexecutorst": 894, "_extra_fil": [894, 895, 902, 905, 1705], "save_to_buff": 894, "add_modul": [895, 1116], "init_weight": [895, 1116, 1706], "in_featur": [895, 1024, 1101, 1103, 1116, 1304, 1312, 1313, 1314, 1325, 1326, 1349, 1357, 1384, 1385, 1415, 1416, 1419, 1706], "out_featur": [895, 1037, 1101, 1103, 1116, 1304, 1312, 1313, 1314, 1325, 1326, 1349, 1357, 1384, 1385, 1415, 1416, 1419, 1706], "buf": [895, 1116], "20l": [895, 1116], "1l": [895, 1116], "5l": [895, 1116], "pretti": [895, 1590, 1676], "syntax": [895, 1676, 1679, 1716], "code_with_const": 895, "constmap": 895, "cn": [895, 1086, 1327, 1355], "extra_repr": [895, 1116, 1701], "get_buff": [895, 1116], "attributeerror": [895, 1116, 1701, 1719], "get_extra_st": [895, 1116], "set_extra_st": [895, 1116], "pickleabl": [895, 1116], "get_paramet": [895, 1116], "net_b": [895, 1116], "net_c": [895, 1116], "kernel_s": [895, 904, 1029, 1030, 1031, 1044, 1045, 1046, 1047, 1048, 1049, 1063, 1064, 1065, 1084, 1085, 1092, 1093, 1094, 1095, 1096, 1097, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1167, 1180, 1181, 1182, 1191, 1192, 1193, 1207, 1208, 1209, 1234, 1235, 1237, 1238, 1239, 1240, 1241, 1242, 1280, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1309, 1310, 1311, 1323, 1324, 1331, 1332, 1333, 1334, 1335, 1336, 1361, 1362, 1375, 1376, 1547, 1548, 1677, 1732], "transit": [895, 998, 1116, 1676], "inlined_graph": 895, "ipu": [895, 1116], "missing_kei": [895, 1116], "unexpected_kei": [895, 1116], "running_var": [895, 1034, 1035, 1036, 1079, 1080, 1081, 1089, 1090, 1091, 1098, 1099, 1100, 1116, 1155, 1183, 1223, 1677, 1711], "named_children": [895, 1116, 1706], "conv4": [895, 1116], "conv5": [895, 1116], "memo": [895, 1116], "remove_dupl": [895, 1116], "register_backward_hook": [895, 1116, 1318], "register_full_backward_hook": [895, 1116, 1706], "removablehandl": [895, 1116, 1315, 1316, 1317, 1318, 1716], "register_buff": [895, 1116, 1676, 1678, 1701, 1706], "running_mean": [895, 1034, 1035, 1036, 1079, 1080, 1081, 1089, 1090, 1091, 1098, 1099, 1100, 1116, 1155, 1183, 1223, 1677, 1706, 1711], "num_featur": [895, 1034, 1035, 1036, 1079, 1080, 1081, 1089, 1090, 1091, 1098, 1099, 1100, 1116, 1155, 1215, 1307, 1308, 1329, 1330, 1344, 1345, 1346, 1706], "register_forward_hook": [895, 1116, 1316, 1706], "register_forward_pre_hook": [895, 1053, 1116, 1317, 1706], "register_load_state_dict_post_hook": [895, 1116], "incompatible_kei": [895, 1116], "clearn": [895, 1116], "register_modul": [895, 1116], "register_paramet": [895, 1116, 1701, 1706], "finetun": [895, 1116], "gan": [895, 1116, 1385, 1416], "share_memori": [895, 1116, 1708], "share_memory_": [895, 1116, 1688, 1729], "keep_var": [895, 1116], "ordereddict": [895, 1116, 1117, 1126, 1144, 1314, 1400, 1677, 1706, 1711, 1734], "channels_last": [895, 1116, 1319, 1730], "4d": [895, 1035, 1063, 1080, 1116, 1168, 1207, 1224, 1251, 1281, 1546], "1913": [895, 1116], "3420": [895, 1116], "5113": [895, 1116, 1641], "2325": [895, 927, 1116], "gpu1": [895, 1116], "1914": [895, 1116], "5112": [895, 1116, 1699], "3741": [895, 1116], "2382": [895, 1006, 1116], "5593": [895, 1116], "4443": [895, 1116], "6122": [895, 1116], "1150": [895, 1116], "to_empti": [895, 1116], "dst_type": [895, 1116], "xpu": [895, 1116], "set_to_non": [895, 1116, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447, 1699], "the_typ": 896, "the_valu": 896, "script_bar": 898, "addmod": 898, "preserved_attr": [899, 1539], "optimize_numer": 899, "optimize_for_infer": 899, "run_frozen_optim": 899, "scripted_modul": [899, 906, 1711], "frozen_modul": 899, "modified_tensor": 899, "mymodule2": 899, "dump_alias_db": 899, "pdb": [900, 906, 912, 1676, 1678], "training_method": 900, "target_typ": 901, "refin": [901, 1690], "testcod": [901, 1678], "key1": 901, "val1": 901, "key2": 901, "val2": 901, "scriptfunct": [902, 906, 907, 910, 1713], "seek": [902, 966, 1716, 1719], "bytesio": [902, 905, 966, 1574, 1719], "rb": [902, 966], "extra_fil": [902, 905], "other_method": 904, "lesser": [904, 1696, 1698], "extent": [904, 1698], "in_channel": [904, 1044, 1045, 1046, 1047, 1048, 1049, 1092, 1093, 1094, 1095, 1096, 1097, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1309, 1310, 1311, 1323, 1324, 1331, 1332, 1333, 1334, 1335, 1336], "out_channel": [904, 1044, 1045, 1046, 1047, 1048, 1049, 1092, 1093, 1094, 1095, 1096, 1097, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1309, 1310, 1311, 1323, 1324, 1331, 1332, 1333, 1334, 1335, 1336], "batchnorm2d": [904, 1053, 1090, 1183, 1297, 1300, 1302, 1307, 1499, 1685, 1696, 1706, 1719, 1721], "frozen_mod": 904, "batch_norm": [904, 1284, 1285, 1677, 1714], "offlin": 905, "_frames_up": 906, "_rcb": 906, "example_input": [906, 910, 1540, 1541, 1719], "scriptdict": 906, "scriptlist": 906, "test_sum": 906, "scripted_fn": [906, 1676], "conv1": [906, 1116, 1144, 1499, 1676, 1719, 1732], "conv2": [906, 1116, 1144, 1676, 1719], "some_entry_point": 906, "python_only_fn": 906, "testnnmodul": 906, "pdt_model": 906, "scripted_model": [906, 1716], "fuse": [908, 909, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1487, 1499, 1538, 1539, 1685, 1689, 1713, 1719, 1720, 1721, 1722], "un": [908, 1039, 1719], "unfus": 908, "nb": 908, "fuser": [908, 1676], "check_trac": [910, 911], "check_input": [910, 911, 1676], "check_toler": [910, 911], "_force_outplac": [910, 911], "_module_class": [910, 911], "_compilation_unit": [910, 911], "compilationunit": [910, 911], "trace_modul": [910, 1676, 1679], "untrack": 910, "checker": [910, 911, 1679, 1713], "diverg": [910, 911, 1082, 1225, 1679], "traced_foo": [910, 1676], "example_weight": [910, 911], "example_forward_input": [910, 911], "method2": 911, "example_method2_input": 911, "weighted_kernel_sum": 911, "use_memory_effici": 912, "memory_effici": 912, "scriptabl": 912, "kaiser": [914, 1159, 1161, 1163], "i_0": [914, 915, 1641, 1728], "zeroth": [914, 1728], "out_i": 914, "kroneck": 915, "a_0": 915, "a_1": 915, "a_n": 915, "b_0": 915, "b_1": 915, "b_n": 915, "k_0": [915, 1641], "k_1": 915, "k_n": 915, "j_0": 915, "j_1": 915, "j_n": 915, "k_t": 915, "i_t": [915, 1086, 1445], "b_t": 915, "j_t": 915, "bmatrix": 915, "a_": [915, 987, 1104, 1641], "cdot": [915, 940, 952, 1032, 1033, 1051, 1052, 1074, 1082, 1119, 1120, 1121, 1122, 1123, 1159, 1195, 1218, 1469, 1625, 1728, 1734], "vdot": [915, 962, 963, 1677], "ddot": [915, 962], "kth": 916, "full_lik": [920, 1677, 1681, 1714], "logarithm": [923, 928, 954, 968, 969, 970, 971, 972, 973, 974, 975, 981, 1039, 1197, 1232, 1605, 1728], "gamma": [923, 1034, 1035, 1036, 1071, 1079, 1080, 1081, 1088, 1155, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1446, 1448, 1452, 1453, 1456, 1460, 1461, 1546, 1677, 1715, 1728], "5724": [923, 1728], "1208": [923, 1728], "mathrlap": [924, 930, 931, 932, 933, 941, 944, 953, 955, 957, 958, 1384], "qquad": [924, 926, 930, 931, 932, 933, 934, 941, 944, 953, 955, 957, 958, 1384], "resp": [924, 928, 931, 933, 957, 958, 975], "5266": 924, "9586": 924, "0626j": 924, "4160": 924, "5895": 924, "2322": 924, "2976j": 924, "4928": [924, 1641], "4692e": 924, "8747e": 924, "check_error": [925, 936, 938, 943, 956, 1677], "opportun": [925, 1676, 1725], "performantli": 925, "3792": 925, "9831j": 925, "8757": 925, "5425": 925, "6374j": 925, "kappa": 926, "_p": [926, 1125], "frobeniu": [926, 940, 947, 951, 1422], "nuc": [926, 947, 951, 964, 1395, 1404, 1422], "nuclear": [926, 947, 951, 1422], "sigma_1": [926, 940, 949, 952], "sigma_n": 926, "kappa_2": 926, "kappa_": 926, "4142": [926, 951, 1422, 1469], "1623": [926, 947], "2426": [926, 951, 1422], "7071": 926, "5917": 926, "9941": 927, "5132": 927, "5681": 927, "4653": 927, "4507": 927, "4119": 927, "6163": 927, "1073": 927, "3957": 927, "9666": [927, 1204], "0840": 927, "3357": 927, "2139": 927, "slogdet": [928, 975, 1677], "0934": 928, "1990": [928, 975], "4099": [928, 975], "7386": [928, 975], "diagonaliz": [930, 932], "neq": [930, 931, 934, 958, 1017, 1119, 1121, 1431, 1432, 1433, 1435, 1437, 1443, 1444, 1446, 1450, 1629, 1633], "phi": [930, 931, 958, 1066, 1211, 1629], "shall": [930, 931, 958, 1386, 1390], "lambda_i": [930, 931, 946, 1633], "min_": [930, 931, 940, 958, 1364, 1629, 1633], "lambda_j": [930, 931, 1633], "9828": [930, 1649, 1706], "3889j": 930, "4617": 930, "3010j": 930, "1662": 930, "7435j": 930, "6139": 930, "0562j": 930, "1226": [930, 932], "5738j": [930, 932], "7537": [930, 932], "1286j": [930, 932], "9218": 930, "1882": 930, "2220j": 930, "0270": 930, "3867j": 930, "7119e": 930, "2841e": 930, "uplo": [931, 933, 1633, 1677], "unitari": [931, 934, 953, 958, 1384, 1463], "eigvalsh": [931, 949, 1633], "9228": [931, 933], "2029": [931, 933], "0862j": [931, 933], "3464": [931, 933], "3277": [931, 933], "9415": [931, 933], "0846": 931, "9964": 931, "9170": 931, "3898j": 931, "0331j": 931, "1062e": 931, "5423e": 931, "polynomi": [932, 933], "_n": [932, 933, 935, 1384, 1701], "cointain": [932, 933, 940], "4576e": [932, 959], "5797": 933, "4629": 933, "1605": 933, "3780": 933, "1113": [933, 1706], "7381": 933, "compont": 934, "h_1h_2": 934, "h_k": 934, "h_i": [934, 1150], "_m": [934, 1384], "tau_i": 934, "8034": 934, "4184j": 934, "2588": 934, "0174j": 934, "6853": 934, "7953j": 934, "0790": 934, "5620j": 934, "6989j": 934, "5360": 934, "1193j": 934, "3877": 934, "6691j": 934, "3512": 934, "3024j": 934, "4766": 934, "5783j": 934, "0361": [934, 1706], "6587j": 934, "6396": [934, 1706], "1612j": 934, "3693": 934, "4481j": 934, "aa": 935, "pinv": [935, 940, 1467], "moor": [935, 952], "penros": [935, 952], "ainv": [935, 936, 956, 960], "1921e": 935, "9073e": [935, 1167], "5107e": 935, "ldl": [937, 939], "indefinit": 937, "ld": [937, 938, 939, 1677], "sytrf": [937, 938], "ldl_solv": 937, "ldl_factor_ex": [937, 939], "2079": [937, 938, 1728], "2414": [937, 938], "9428": [937, 938], "4554": [937, 938], "3264": [937, 938], "3823": [937, 938], "5884": [937, 938], "9595": [937, 938], "2695": [937, 938, 1633], "8513": [937, 938], "1633": [937, 938], "ldl_factor": 938, "argumen": 939, "rcond": [940, 952, 1467, 1677], "_f": 940, "gelsi": 940, "gelsd": 940, "gelss": 940, "mind": [940, 958, 1059, 1696, 1703], "tridiagon": 940, "sigma_i": [940, 958, 1629], "residu": [940, 967, 983, 1677, 1706], "singular_valu": [940, 1677], "lh": 940, "rh": [940, 986], "0862e": 940, "7220e": 940, "almost": [941, 942, 1712], "5007": 941, "9755": 941, "0489": 941, "9644": [941, 996], "9605e": 941, "0376e": 941, "lu_factor_ex": [942, 985], "lu_unpack": [942, 985, 1677], "b1": 942, "b2": [942, 1699, 1704], "a_factor": 942, "getrf": [943, 956], "adjoint": [944, 1677, 1731, 1733], "xa": [944, 955, 956, 957, 1103, 1230, 1374], "3891": 946, "8660": 946, "ord": [947, 951, 964, 1422, 1677, 1679], "la": [947, 951, 964, 1706], "2829": 947, "2627": 947, "0756": 948, "4980": 948, "6617": 948, "4994": 948, "9980": 948, "2731": 948, "8001": 948, "2640": 948, "4571": 948, "5511": 948, "0163": [948, 996], "5292": 948, "4899": 948, "0822": 948, "varepsilon": [949, 952], "finfo": [949, 952, 1020, 1501, 1502, 1503, 1504, 1507, 1734], "tol": [949, 967, 993, 1677], "fewest": 950, "wherea": [950, 1012, 1629, 1679, 1734], "nd": [950, 1709], "50": [950, 1002, 1030, 1031, 1039, 1044, 1045, 1046, 1048, 1049, 1064, 1065, 1084, 1085, 1109, 1110, 1111, 1166, 1190, 1191, 1193, 1197, 1208, 1209, 1332, 1334, 1335, 1336, 1365, 1445, 1506, 1636, 1691], "bc": [950, 1715], "75000": 950, "26": [950, 1451], "148": 950, "vector_norm": [951, 1422], "matrix_norm": [951, 964, 1385, 1422], "clearer": 951, "3485": 951, "8570e": 951, "8480": 951, "2361": [951, 1422, 1423], "7417": [951, 1422], "computation": [952, 1703], "5495": [952, 1005], "0979": 952, "4092": 952, "4132": 952, "1143": 952, "3662": 952, "6374": 952, "9294": 952, "3269": [952, 1706], "5745": 952, "0382": [952, 1006], "5922": 952, "6759": 952, "0600": 952, "1933": 952, "2090": 952, "0903": 952, "0817": 952, "4752": [952, 1628], "7124": 952, "1631": 952, "2272": 952, "1356": 952, "3933": 952, "5023": 952, "0308": 952, "1725": 952, "5216": 952, "apinv": 952, "5633e": 952, "0830e": 952, "wide": [953, 958, 1384, 1698, 1701, 1706], "linearli": [953, 1168, 1281, 1378, 1455, 1475, 1702, 1715, 1722], "autodiff": 953, "51": [953, 1114, 1475], "167": [953, 1475], "68": [953, 1475, 1676, 1678], "8571": [953, 1475], "3943": [953, 1475], "3314": [953, 1475], "4286": [953, 1475], "9029": [953, 1475], "0343": [953, 1475], "2857": [953, 1475], "1714": [953, 1475, 1706], "9429": [953, 1475], "175": [953, 1475], "q2": 953, "r2": [953, 1155], "6099e": 953, "2158e": 953, "logabsdet": [954, 1677], "0032": 954, "1219": [954, 1561], "6690": 954, "1161": 954, "4053": 954, "6218": [954, 1638], "9273": 954, "0082": 954, "7576": 954, "logdet": [954, 1677, 1714], "linalg_slogdet": [954, 1677], "2776": 954, "solve_triangular": [955, 1648], "expand_a": [955, 1677, 1701, 1714, 1731], "rectangular": [957, 958, 987, 1694], "triu_": [957, 1677], "tril_": [957, 1677], "full_matric": [958, 959, 1389, 1629, 1677], "vh": [958, 1389, 1629, 1677], "gesvdj": [958, 959, 1629], "jacobi": 958, "gesvda": [958, 959], "gesvd": [958, 959, 1629], "u_k": 958, "v_k": 958, "sigma_j": [958, 1629], "eigendecomposit": 958, "consequ": [958, 1086, 1629, 1679, 1696, 1699, 1710], "0486e": 958, "0957e": 958, "5139": 959, "1087": 959, "1066": 959, "ind": [960, 961, 1677], "tensorsolv": 960, "ndim": [960, 961, 1689, 1727, 1733], "atensorinv": 960, "movedim": [961, 1003, 1677, 1714, 1731], "tensorinv": 961, "vandermond": [962, 1661], "pmatrix": 962, "x_n": [962, 1032, 1033, 1076, 1077, 1083, 1107, 1147, 1646, 1696], "125": [962, 1134, 1661, 1677], "overlin": [963, 1664], "3223": 963, "2815": 963, "1944": [963, 1706], "multidimenson": 964, "counterpart": [964, 1319, 1536, 1543, 1679, 1685, 1735, 1736], "4345": 964, "pickle_modul": [966, 1574], "pickle_load_arg": 966, "register_packag": 966, "untrust": [966, 1716], "tamper": [966, 1716], "ram": [966, 1699], "surg": 966, "decod": [966, 1159, 1160, 1161, 1319, 1716], "utf": [966, 1713, 1716], "unicodedecodeerror": 966, "codec": 966, "0x": 966, "latin1": 966, "byte_arrai": 966, "niter": [967, 1465, 1630], "ortho_iparam": 967, "ortho_fparam": 967, "ortho_bparam": 967, "andrew": 967, "knyazev": 967, "knyazev2001": 967, "stathopoulosetal2002": 967, "converg": [967, 1147, 1384, 1433, 1434, 1458, 1695, 1706, 1709], "promptli": 967, "interperet": 967, "precondition": 967, "eigenpair": 967, "criterion": [967, 1032, 1033, 1050, 1052, 1077, 1083, 1107, 1108, 1119, 1120, 1121, 1147, 1148, 1164, 1165, 1196, 1451, 1549, 1702], "fep": 967, "eigenproblem": 967, "iparam": 967, "fparam": 967, "bparam": 967, "ivar": 967, "fvar": 967, "bvar": 967, "tvar": 967, "istep": 967, "converged_count": 967, "rerr": 967, "force_stop": 967, "2001": 967, "precondit": 967, "eigensolv": 967, "siam": 967, "sci": 967, "517": 967, "541": 967, "epub": 967, "doi": [967, 1070], "1137": 967, "s1064827500366124": 967, "andrea": 967, "stathopoulo": 967, "kesheng": 967, "2002": 967, "2165": 967, "2182": 967, "s1064827500370883": 967, "duerschetal2018": 967, "jed": 967, "duersch": 967, "meiyu": 967, "shao": 967, "chao": 967, "ming": 967, "gu": 967, "2018": [967, 1473], "c655": 967, "c676": 967, "17m1129830": 967, "log_": [968, 969, 970, 971, 1677, 1689], "7767": 968, "3234": 968, "2156": 968, "2411": 968, "5739": 968, "5637": 968, "4640": 968, "1952": 968, "4226": 968, "5204": [968, 1551], "5224": 969, "9354": 969, "7257": 969, "1301": 969, "2820": 969, "0290": 969, "1392": 969, "8857": 969, "6476": 969, "0090": [970, 1018, 1471, 1728], "9923": [970, 1606], "5372": 970, "2492": 970, "8653": 970, "7055": 970, "7705": 970, "2225": 970, "8419": 971, "8003": [971, 1710], "9971": 971, "5287": 971, "0490": 971, "2483": 971, "0042": 971, "9196": 971, "3504": [971, 1641], "exce": [972, 1699], "logsumexp": [972, 1677, 1689, 1714, 1728], "3069": 972, "6867": 972, "8731": 972, "30000": 972, "1269e": 972, "log_2": 973, "logaddexp": [973, 1677], "limits_": 974, "42296738": 974, "04462666": 974, "86278635": 974, "94622083": 974, "05277811": 974, "39202815": 974, "83525007": 974, "84492621": 974, "06084887": 974, "06844475": 974, "2611": [975, 1638], "9254": 975, "6213": [975, 1706], "6843": 975, "3242": 975, "9665": 975, "4539": 975, "0887": [975, 1728], "1336": 975, "4025": 975, "7089": [975, 1059], "9032": 975, "3031": 975, "2589": 981, "1135": 981, "5481": [981, 996, 1706], "9566": 981, "sum_j": [982, 1106, 1149, 1151, 1268, 1608, 1728], "0593": [982, 1706], "5696": 982, "6859e": 982, "min_x": 983, "_2": [983, 1051, 1195, 1385, 1416], "llll": 983, "irrespect": [983, 1633, 1699], "9635": [983, 1728], "8501": 983, "9332": 983, "2418": 983, "compute_pivot": 985, "transposit": [985, 1727], "perm": 985, "a_lu": 985, "5558": 985, "1684": 985, "1551": 985, "1940": 985, "6189": 985, "5497": 985, "4526": 985, "2526": 985, "3285": 985, "7988": 985, "7175": 985, "9701": 985, "2634": 985, "9255": 985, "3459": 985, "00000e": 986, "8312": 986, "unpack_data": [987, 1677], "unpack_pivot": [987, 1677], "l_": [987, 1021, 1025, 1029, 1033, 1044, 1045, 1046, 1047, 1084, 1109], "u_": [987, 1431, 1435], "3552": [989, 1205], "3825": 989, "8297": 989, "3477": 989, "2035": 989, "2252": [989, 1728], "5002": 989, "6248": [989, 999], "1307": 989, "0608": [989, 1603], "1244": 989, "0139": 989, "renam": [993, 1677, 1689, 1690], "6763": 994, "7445": 994, "2369": 994, "argmax": [994, 1024, 1109, 1237, 1238, 1239, 1636, 1677, 1714], "max_indic": 994, "2360": 994, "2942": 994, "1222": [994, 1706], "8475": 994, "1949": 994, "1127": 994, "6702": 994, "5717": 994, "9207": 994, "1297": 994, "8768": 994, "6172": 994, "6060": 994, "2432": 994, "3288": 996, "3367": 996, "nanmean": [996, 1677], "3841": 996, "6320": 996, "4254": 996, "7384": 996, "0131": 996, "6549": 996, "4279": 996, "3350": 996, "7694": 996, "5600": [996, 1168], "0842": 996, "9580": 996, "3623": 996, "2343": [996, 1691], "5085": 996, "4599": 996, "1807": 996, "5219": 997, "5212": 997, "2202": 997, "2505": 997, "3982": 997, "9948": 997, "3518": 997, "3131": 997, "3180": [997, 1727], "6993": 997, "0436": 997, "0438": 997, "2270": 997, "2751": 997, "7303": 997, "2192": 997, "3321": 997, "2488": 997, "0778": 997, "9510": 997, "7048": 997, "4742": [997, 1654, 1728], "7125": [997, 1610], "plot": [998, 1698, 1732], "t_0": [998, 1451], "t_": [998, 1065, 1209, 1450, 1451, 1677, 1727], "s_0": 998, "s_": [998, 1022, 1023, 1062, 1166], "g_0": 998, "g_": [998, 1435, 1445, 1446], "g_i": 998, "t_i": 998, "0d": [998, 1108], "xy": 998, "50276": 998, "cartesian_prod": [998, 1677], "grid_x": 998, "grid_i": 998, "dstack": [998, 1677, 1727], "matplotlib": [998, 1732], "pyplot": [998, 1732], "plt": 998, "xs": [998, 1387], "ys": 998, "3d": [998, 1023, 1027, 1031, 1034, 1036, 1046, 1049, 1056, 1057, 1063, 1065, 1079, 1081, 1111, 1122, 1168, 1174, 1177, 1178, 1182, 1190, 1193, 1201, 1207, 1209, 1224, 1239, 1251, 1281, 1285, 1288, 1291, 1328, 1333, 1336, 1360, 1362, 1367, 1372, 1709, 1719, 1732], "plot_surfac": 998, "mpl_toolkit": 998, "mplot3d": 998, "art3d": 998, "poly3dcollect": 998, "0x7f8f30d40100": 998, "6750": 999, "0857": [999, 1651], "7197": [999, 1670], "argmin": [999, 1677, 1714], "min_indic": [999, 1677], "1334": 999, "2803": 999, "4644": 999, "2635": [999, 1706], "3651": 999, "0384": 999, "0128": 999, "7015": 999, "1153": 999, "9849": 999, "1458": [999, 1728], "5788": 999, "4851": 1001, "5037": 1001, "3633": 1001, "0760": 1001, "6705": 1001, "3362": [1003, 1004], "8437": [1003, 1004], "9627": [1003, 1004], "1727": [1003, 1004], "5173": [1003, 1004], "1398": [1003, 1004], "1321": 1005, "4370": 1005, "1289": 1005, "0527": 1005, "2275": 1005, "3077": [1005, 1619], "0881": 1005, "1259": 1005, "0284": 1005, "2015": [1006, 1694, 1706], "6087": 1006, "1494": 1006, "5491": 1006, "260": 1006, "8663": 1006, "3137": 1006, "0700": 1006, "8378": 1006, "5146": 1006, "1216": 1006, "5244": 1006, "5767": 1006, "1363": 1006, "5877": 1006, "5083": 1006, "1614": 1006, "1645": 1006, "7021": 1006, "0085": 1006, "0367": 1006, "1567": 1006, "4312": 1006, "1019": 1006, "4394": 1006, "8753": 1006, "_sampl": 1007, "thtensorrandom": 1007, "320": [1007, 1142], "0404": 1009, "6361": 1009, "multigammaln": [1010, 1728], "4028e": 1011, "38": 1011, "1400e": 1011, "isnan": [1012, 1677, 1714, 1727], "midpoint": [1014, 1476], "nearest": [1014, 1168, 1170, 1213, 1224, 1281, 1283, 1372, 1378, 1380, 1476, 1571, 1699], "2262": [1018, 1471], "0682": [1018, 1471], "2866": [1018, 1471], "3940": [1018, 1471], "_size": [1021, 1022, 1023, 1025, 1026, 1027, 1029, 1030, 1031, 1044, 1045, 1046, 1047, 1048, 1049, 1063, 1064, 1065, 1068, 1069, 1084, 1085, 1086, 1087, 1109, 1110, 1111, 1112, 1113, 1114, 1131, 1133, 1167, 1209, 1353], "64": [1021, 1022, 1023, 1025, 1026, 1027, 1033, 1144, 1579, 1691, 1712, 1713, 1719, 1723, 1727, 1730, 1732, 1733], "h_": [1022, 1023, 1026, 1027, 1030, 1031, 1037, 1042, 1043, 1045, 1046, 1048, 1049, 1064, 1065, 1068, 1069, 1085, 1086, 1103, 1110, 1111, 1112, 1113, 1114, 1128, 1129, 1131, 1133, 1138, 1139, 1141, 1142, 1168, 1169, 1170, 1171, 1184, 1209, 1213, 1353], "w_": [1022, 1023, 1026, 1027, 1030, 1031, 1033, 1041, 1042, 1043, 1045, 1046, 1048, 1049, 1052, 1064, 1065, 1068, 1069, 1085, 1086, 1087, 1110, 1111, 1113, 1114, 1123, 1128, 1129, 1131, 1133, 1137, 1138, 1139, 1140, 1141, 1142, 1168, 1169, 1170, 1171, 1209, 1213, 1353], "5x7": [1022, 1026], "7x7": [1022, 1026], "10x7": [1022, 1026], "cube": [1023, 1027, 1549], "d_": [1023, 1027, 1031, 1043, 1046, 1049, 1111, 1114, 1139, 1142, 1168, 1213, 1649, 1650, 1651, 1652], "5x7x9": [1023, 1027], "7x7x7": [1023, 1027], "7x9x8": [1023, 1027], "n_class": 1024, "cutoff": [1024, 1694], "div_valu": 1024, "head_bia": 1024, "edouard": 1024, "grave": [1024, 1039], "armand": 1024, "joulin": 1024, "moustapha": 1024, "ciss\u00e9": 1024, "grangier": 1024, "herv\u00e9": 1024, "j\u00e9gou": 1024, "imbalanc": 1024, "zipf": 1024, "law": 1024, "head": [1024, 1122, 1159, 1161, 1163, 1328], "102": 1024, "1001": 1024, "1002": 1024, "_featur": [1024, 1037, 1101, 1103, 1184, 1230, 1349, 1357, 1374], "_class": 1024, "output1": [1024, 1353, 1695, 1713], "output2": [1024, 1353], "predict": [1024, 1033, 1070, 1196, 1715, 1732], "highest": [1024, 1553, 1554, 1585, 1720, 1734], "return_indic": [1025, 1026, 1027, 1064, 1065, 1109, 1110, 1111, 1112, 1113, 1114, 1175, 1176, 1177, 1208, 1209, 1237, 1238, 1239, 1375, 1376, 1677], "maxunpool1d": [1025, 1109, 1240], "maxunpool2d": [1026, 1064, 1110, 1241], "maxunpool3d": [1027, 1065, 1111, 1242], "selu": [1028, 1061, 1206, 1677, 1694, 1714], "ceil_mod": [1029, 1030, 1031, 1084, 1085, 1109, 1110, 1111, 1180, 1181, 1182, 1234, 1235, 1237, 1238, 1239, 1361, 1362, 1375, 1376, 1547, 1548, 1677], "count_include_pad": [1029, 1030, 1031, 1180, 1181, 1182, 1361, 1362, 1677], "n_i": [1029, 1030, 1031, 1044, 1045, 1046, 1109, 1110, 1111, 1164, 1165], "c_j": [1029, 1030, 1031, 1109, 1110, 1111], "divisor_overrid": [1030, 1031, 1181, 1182, 1361, 1362, 1677], "kh": [1030, 1031, 1064, 1065, 1110, 1111, 1181, 1182, 1189, 1190, 1192, 1193, 1208, 1209, 1238, 1239, 1361, 1362, 1366, 1367], "kw": [1030, 1031, 1064, 1065, 1110, 1111, 1180, 1181, 1182, 1188, 1189, 1190, 1191, 1192, 1193, 1208, 1209, 1237, 1238, 1239, 1361, 1362, 1366, 1367], "height": [1030, 1031, 1045, 1046, 1048, 1049, 1085, 1110, 1111, 1123, 1150, 1168, 1224, 1281, 1372, 1378, 1690], "kd": [1031, 1111, 1362, 1367], "size_averag": [1032, 1033, 1050, 1052, 1076, 1082, 1083, 1107, 1108, 1119, 1120, 1121, 1123, 1130, 1147, 1148, 1164, 1185, 1186, 1194, 1196, 1221, 1225, 1226, 1236, 1244, 1245, 1246, 1247, 1248, 1256, 1266, 1267, 1278, 1677], "unreduc": [1032, 1033, 1052, 1077, 1083, 1107, 1123, 1147, 1165], "ell": [1032, 1033, 1052, 1076, 1077, 1083, 1107, 1123, 1147, 1165], "l_1": [1032, 1033, 1052, 1076, 1077, 1083, 1107, 1123, 1147, 1165], "l_n": [1032, 1033, 1052, 1076, 1077, 1083, 1107, 1123, 1147, 1165], "w_n": [1032, 1033], "y_n": [1032, 1033, 1052, 1076, 1077, 1083, 1107, 1123, 1147, 1646, 1696], "lim_": [1032, 1696], "secondli": 1032, "nonlinear": [1032, 1050, 1076, 1131, 1133, 1143, 1358, 1694, 1727], "straight": [1032, 1215], "rescal": [1032, 1033, 1052, 1120, 1121, 1123, 1149, 1151, 1185, 1186, 1196, 1248, 1389, 1416], "nbatch": [1032, 1033], "meantim": [1032, 1033, 1050, 1052, 1076, 1083, 1107, 1108, 1119, 1120, 1121, 1123, 1130, 1147, 1148, 1164, 1185, 1186, 1196, 1225, 1248, 1256], "random_": [1032, 1033, 1052, 1123, 1186, 1677, 1689, 1735], "pos_weight": [1033, 1186, 1677], "recal": [1033, 1701, 1732], "classif": [1033, 1039, 1052, 1119, 1121, 1123, 1148, 1197, 1675, 1694, 1720], "ell_c": 1033, "l_c": 1033, "p_c": 1033, "2014": 1033, "momentum": [1034, 1035, 1036, 1079, 1080, 1081, 1089, 1090, 1091, 1098, 1099, 1100, 1155, 1183, 1223, 1296, 1297, 1298, 1299, 1300, 1301, 1307, 1308, 1329, 1330, 1344, 1345, 1346, 1437, 1444, 1446, 1452, 1458, 1459, 1677, 1706, 1715], "track_running_stat": [1034, 1035, 1036, 1079, 1080, 1081, 1089, 1090, 1091, 1098, 1099, 1100, 1155, 1344, 1345, 1346, 1711], "learnabl": [1034, 1035, 1036, 1037, 1044, 1045, 1046, 1047, 1048, 1049, 1059, 1060, 1068, 1069, 1071, 1079, 1080, 1081, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1103, 1124, 1131, 1133, 1155, 1205, 1257, 1331, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1349, 1353, 1357, 1706], "hat": [1034, 1035, 1036, 1079, 1080, 1081, 1155], "terminolog": [1034, 1035, 1036, 1155], "tempor": [1034, 1036, 1039, 1155, 1168, 1197, 1224, 1281], "5d": [1036, 1081, 1168, 1213, 1224, 1251, 1281], "volumetr": [1036, 1155, 1168, 1213, 1224, 1281, 1282, 1283], "spatio": [1036, 1155], "in1_featur": 1037, "in2_featur": 1037, "input1": [1037, 1050, 1051, 1108, 1125, 1184, 1194, 1195, 1236, 1353, 1677, 1695, 1713], "in1": [1037, 1184], "in2": [1037, 1184], "mathcal": [1037, 1044, 1045, 1046, 1047, 1048, 1049, 1059, 1060, 1068, 1069, 1086, 1087, 1101, 1103, 1131, 1133, 1134, 1155, 1353, 1555, 1694, 1703], "formul": [1038, 1058, 1072, 1106, 1152, 1153, 1232, 1249, 1363, 1703, 1727], "blank": [1039, 1197, 1677, 1680], "zero_infin": [1039, 1197, 1677], "connectionist": [1039, 1197], "unseg": 1039, "longest": [1039, 1411, 1413, 1414, 1702], "input_length": [1039, 1197, 1677, 1702], "target_length": [1039, 1197, 1677], "s_n": 1039, "target_n": 1039, "unbatch": [1039, 1052, 1063, 1068, 1079, 1086, 1122, 1131, 1159, 1207], "s_min": 1039, "www": [1039, 1165, 1732], "cs": 1039, "toronto": 1039, "edu": [1039, 1549], "icml_2006": 1039, "pdf": [1039, 1134, 1696], "256": [1039, 1472, 1713], "background": [1039, 1047, 1213, 1251, 1708, 1724], "channel_shuffl": [1040, 1677], "_left": [1041, 1042, 1043, 1137, 1138, 1139, 1140, 1141, 1142, 1171, 1251], "_right": [1041, 1042, 1043, 1137, 1138, 1139, 1140, 1141, 1142, 1171, 1251], "0491": 1041, "7152": 1041, "0749": 1041, "3287": 1041, "8966": 1041, "1466": 1041, "2771": 1041, "6616": 1041, "4523": 1041, "1255": 1041, "6372": [1041, 1629], "1182": 1041, "8652": 1041, "_top": [1042, 1043, 1138, 1139, 1141, 1142, 1171, 1251], "_bottom": [1042, 1043, 1138, 1139, 1141, 1142, 1171, 1251], "6585": 1042, "4320": [1042, 1634], "8701": 1042, "4649": 1042, "_front": [1043, 1139, 1142, 1251], "_back": [1043, 1139, 1142, 1251], "dilat": [1044, 1045, 1046, 1047, 1048, 1049, 1063, 1092, 1093, 1094, 1095, 1096, 1097, 1109, 1110, 1111, 1167, 1188, 1189, 1190, 1191, 1192, 1193, 1207, 1237, 1238, 1239, 1280, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1309, 1310, 1311, 1323, 1324, 1331, 1332, 1333, 1334, 1335, 1336, 1365, 1366, 1367, 1375, 1376, 1547, 1548, 1677, 1713], "padding_mod": [1044, 1045, 1046, 1047, 1048, 1049, 1092, 1093, 1094, 1095, 1096, 1097, 1213, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1309, 1310, 1311, 1323, 1324, 1331, 1332, 1333, 1334, 1335, 1336, 1365, 1366, 1367, 1677], "_j": [1044, 1045], "star": [1044, 1045, 1046, 1679], "\u00e0": [1044, 1045, 1046, 1047, 1048, 1049, 1063, 1167], "trou": [1044, 1045, 1046, 1047, 1048, 1049, 1063, 1167], "harder": [1044, 1045, 1046, 1047, 1048, 1049, 1063, 1110, 1111, 1167], "nice": [1044, 1045, 1046, 1047, 1048, 1049, 1063, 1109, 1110, 1111, 1167, 1690, 1696, 1716], "convolv": [1044, 1045, 1046, 1047, 1048, 1049, 1092, 1093, 1094, 1095, 1096, 1097, 1188, 1189, 1190, 1191, 1192, 1193, 1365, 1366, 1367], "_channel": [1044, 1045, 1046, 1047, 1048, 1049, 1071, 1180, 1181, 1182, 1188, 1189, 1190, 1191, 1192, 1193, 1237, 1238, 1239, 1361, 1362, 1365, 1366, 1367, 1724], "pixel": [1045, 1052, 1055, 1056, 1057, 1061, 1123, 1128, 1129, 1168, 1178, 1213, 1224, 1281, 1283, 1372, 1378, 1380], "prod_": [1045, 1046, 1048, 1049, 1062, 1166, 1437], "unequ": [1045, 1046, 1048, 1049, 1332, 1333, 1334, 1335, 1336], "out_j": 1046, "six": 1046, "output_pad": [1047, 1048, 1049, 1095, 1096, 1097, 1191, 1192, 1193, 1334, 1335, 1336, 1677], "deconvolut": [1047, 1048, 1049, 1191, 1192, 1193], "_pad": [1047, 1048, 1049], "downsampl": [1048, 1168, 1178, 1213, 1224, 1334, 1335, 1336], "upsampl": [1048, 1169, 1170, 1178, 1213, 1224, 1282, 1283, 1334, 1335, 1336, 1372, 1379, 1380, 1501], "dissimilar": [1050, 1076], "semi": [1050, 1076, 1694], "supervis": [1050, 1076], "vert": [1051, 1125, 1195], "ast_1": [1051, 1067], "ast_2": [1051, 1067], "ignore_index": [1052, 1123, 1196, 1248, 1677], "label_smooth": [1052, 1196, 1677], "unbalanc": [1052, 1123], "score": [1052, 1186, 1196, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1400, 1403, 1404], "d_1": [1052, 1123, 1196, 1248], "d_2": [1052, 1123, 1196, 1248], "d_k": [1052, 1123, 1196, 1248], "_index": [1052, 1123], "logsoftmax": [1052, 1123, 1149, 1232], "nllloss": [1052, 1149, 1248, 1268, 1660], "blend": 1052, "smooth": [1052, 1077, 1147, 1152, 1196, 1444], "w_c": 1052, "truth": [1052, 1196, 1732], "rethink": [1052, 1196], "incept": [1052, 1196], "shallow": [1053, 1164, 1165], "spectral_norm": [1053, 1408], "neuron": 1054, "detector": 1054, "ed": [1055, 1056, 1696, 1716, 1738], "dropout1d": [1056, 1677], "num_embed": [1059, 1060, 1205, 1338, 1339], "embedding_dim": [1059, 1060, 1088, 1204, 1205, 1338, 1339], "padding_idx": [1059, 1060, 1204, 1205, 1338, 1677], "scale_grad_by_freq": [1059, 1060, 1204, 1205, 1338, 1339, 1677], "_weight": [1059, 1060, 1338, 1339], "_dim": [1059, 1338, 1339], "sparseadam": 1059, "adagrad": [1059, 1724], "0251": 1059, "6902": [1059, 1473], "7172": 1059, "6431": 1059, "0748": 1059, "6969": 1059, "4970": 1059, "3448": 1059, "9685": 1059, "3677": 1059, "7265": 1059, "1685": 1059, "4362": 1059, "4004": [1059, 1610], "9400": 1059, "9124": 1059, "3616": 1059, "1151": 1059, "0309": 1059, "9315": 1059, "1655": [1059, 1699], "9897": 1059, "0635": 1059, "7895": 1059, "0364": 1059, "6778": 1059, "5803": 1059, "from_pretrain": [1059, 1060], "pretrain": [1059, 1060, 1674, 1696, 1713], "include_last_offset": [1060, 1205, 1339, 1677], "bag": [1060, 1205], "per_sample_weight": [1060, 1205, 1677], "embedding_sum": 1060, "8861": 1060, "4350": 1060, "0523": 1060, "1306": 1060, "5798": 1060, "0044": 1060, "7082": [1060, 1205], "2145": [1060, 1205], "6251": [1060, 1205], "6500": 1060, "satur": [1061, 1206], "alphadropout": [1061, 1179], "160": [1062, 1715], "unfold": [1063, 1677, 1714, 1731], "prod_d": [1063, 1167], "neighborhood": [1063, 1167], "col2im": [1063, 1677], "fold_param": [1063, 1167], "input_on": [1063, 1167], "output_ratio": [1064, 1065, 1208, 1209, 1677], "_random_sampl": [1064, 1065, 1677], "maxpool": [1064, 1065, 1208, 1209, 1713], "ben": [1064, 1065, 1208, 1209], "graham": [1064, 1065, 1208, 1209], "oh": [1064, 1065, 1208, 1209], "ow": [1064, 1065, 1208, 1209], "_ratio": [1064, 1065, 1209], "13x12": [1064, 1208], "kt": [1065, 1182, 1190, 1193, 1209, 1239], "ot": [1065, 1209], "cubic": [1065, 1209, 1213, 1336], "13x12x11": [1065, 1209], "044715": [1066, 1211], "gate": [1067, 1068, 1069, 1086, 1145, 1212, 1265, 1353, 1354], "r_t": [1068, 1353, 1443], "b_": [1068, 1069, 1086, 1087, 1104, 1131, 1133, 1353, 1641], "hr": [1068, 1069, 1086, 1353, 1703], "z_t": [1068, 1353], "iz": [1068, 1069, 1353], "hz": [1068, 1069, 1353, 1732], "n_t": [1068, 1353], "hn": [1068, 1069, 1086, 1131, 1327, 1353, 1355], "h_t": [1068, 1086, 1131, 1353], "hadamard": [1068, 1069, 1086, 1087, 1353], "multilay": [1068, 1086, 1353], "_t": [1068, 1086, 1353, 1444, 1446, 1701], "hidden_s": [1068, 1069, 1086, 1087, 1131, 1132, 1133, 1327, 1353, 1354, 1358, 1677], "num_lay": [1068, 1086, 1131, 1132, 1160, 1162, 1327, 1353, 1677, 1706], "b_ih": [1068, 1069, 1086, 1087, 1131, 1133, 1353, 1677], "b_hh": [1068, 1069, 1086, 1087, 1131, 1133, 1353, 1677], "batch_first": [1068, 1086, 1122, 1131, 1132, 1159, 1161, 1163, 1327, 1328, 1353, 1411, 1413, 1414, 1677, 1702], "cell": [1068, 1069, 1086, 1087, 1131, 1133, 1354, 1356, 1358], "bidirect": [1068, 1086, 1131, 1132, 1327, 1353, 1677], "h_0": [1068, 1086, 1087, 1131, 1353], "pack_padded_sequ": [1068, 1086, 1131, 1353, 1410, 1412, 1413, 1702], "pack_sequ": [1068, 1086, 1131, 1413], "_layer": [1068, 1086, 1131, 1353], "h_n": [1068, 1086, 1131, 1353], "weight_ih_l": [1068, 1086, 1131, 1353], "w_ir": [1068, 1353], "w_iz": [1068, 1353], "w_in": [1068, 1353], "num_direct": [1068, 1086, 1131, 1353], "weight_hh_l": [1068, 1086, 1131, 1353], "w_hr": [1068, 1353], "w_hz": [1068, 1353], "w_hn": [1068, 1353], "bias_ih_l": [1068, 1086, 1131, 1353], "b_ir": [1068, 1353], "b_iz": [1068, 1353], "b_in": [1068, 1353], "bias_hh_l": [1068, 1086, 1131, 1353], "b_hr": [1068, 1353], "b_hz": [1068, 1353], "b_hn": [1068, 1353], "seq_len": [1068, 1086, 1131, 1353], "h0": [1068, 1086, 1131, 1327, 1353, 1355], "gru": [1069, 1354, 1677, 1699, 1714, 1719], "weight_ih": [1069, 1087, 1133, 1327], "weight_hh": [1069, 1087, 1133, 1327], "bias_ih": [1069, 1087, 1133], "bias_hh": [1069, 1087, 1133], "hx": [1069, 1087, 1133, 1354, 1356, 1358, 1677], "homoscedast": [1070, 1210], "heteroscedast": [1070, 1210], "nix": 1070, "weigend": 1070, "1994": 1070, "icnn": 1070, "94": 1070, "orlando": 1070, "fl": 1070, "usa": [1070, 1732], "374138": 1070, "num_group": [1071, 1214, 1342, 1677], "num_channel": [1071, 1342, 1690], "instancenorm": [1071, 1721], "layernorm": [1071, 1079, 1080, 1081, 1159, 1163, 1227, 1721], "shrinkag": [1072, 1153, 1216, 1271], "mobilenetv3": [1074, 1218], "min_val": [1075, 1219, 1220, 1371, 1677], "max_val": [1075, 1219, 1220, 1371, 1677], "_val": 1075, "l1": [1076, 1077, 1147, 1222, 1266, 1394, 1403, 1706, 1711], "l1loss": [1077, 1147, 1226], "mseloss": [1077, 1147, 1244, 1699, 1700], "outlier": [1077, 1147, 1719, 1720], "l2": [1077, 1107, 1147, 1430, 1431, 1432, 1433, 1435, 1437, 1443, 1444, 1446, 1695], "huber": [1077, 1147], "smoothl1loss": [1077, 1266], "insensit": 1078, "unused_argument1": 1078, "unused_argument2": 1078, "ingredi": [1079, 1080, 1081], "styliz": [1079, 1080, 1081], "rgb": [1080, 1081, 1732], "color": [1081, 1678, 1679, 1732], "log_target": [1082, 1225, 1677], "pred": [1082, 1319, 1707, 1715, 1724], "kl": [1082, 1225], "summaris": 1082, "loss_pointwis": 1082, "batchmean": [1082, 1225], "kl_loss": 1082, "mae": 1083, "proport": [1084, 1085, 1122, 1163], "hi": [1086, 1087, 1676, 1678, 1703], "f_t": [1086, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446], "hf": [1086, 1087], "g_t": [1086, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446], "ig": [1086, 1087], "hg": [1086, 1087], "o_t": 1086, "ho": [1086, 1087], "c_t": 1086, "odot": 1086, "forget": [1086, 1678, 1679], "proj_siz": [1086, 1132], "1402": 1086, "c_0": [1086, 1087], "proj": 1086, "c_n": 1086, "w_ii": 1086, "w_if": 1086, "w_ig": 1086, "w_io": 1086, "w_hi": 1086, "w_hf": 1086, "w_hg": 1086, "w_ho": 1086, "b_ii": 1086, "b_if": 1086, "b_ig": 1086, "b_io": 1086, "b_hi": 1086, "b_hf": 1086, "b_hg": 1086, "b_ho": 1086, "weight_hr_l": 1086, "_revers": 1086, "c0": [1086, 1327, 1355], "h_1": 1087, "c_1": 1087, "time_step": 1087, "cx": [1087, 1356, 1677], "normalized_shap": [1088, 1227, 1347, 1677], "elementwise_affin": [1088, 1347], "_shape": 1088, "sentence_length": 1088, "batchnorm1d": [1089, 1155, 1183, 1296, 1299, 1711, 1721], "lazymodulemixin": [1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101], "cls_to_becom": [1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1322], "batchnorm3d": [1091, 1155, 1183, 1298, 1301, 1303, 1308, 1721], "convtranspose1d": [1095, 1191, 1660, 1721], "convtranspose2d": [1096, 1192, 1334, 1660, 1721], "convtranspose3d": [1097, 1193, 1660, 1721], "instancenorm1d": [1098, 1223, 1721], "instancenorm2d": [1099, 1223, 1721], "instancenorm3d": [1100, 1223, 1721], "uninitializedparamet": [1101, 1314], "negative_slop": [1102, 1228, 1229, 1348, 1373, 1677, 1694], "_slope": [1102, 1228, 1373, 1694], "slope": [1102, 1147, 1348, 1373, 1694], "neighbour": [1104, 1224, 1283, 1380], "lrn": 1104, "signal_2d": 1104, "signal_4d": 1104, "output_2d": 1104, "output_4d": 1104, "x_j": [1106, 1149, 1151, 1268, 1608, 1703, 1728], "max_": [1109, 1110, 1111, 1364, 1385, 1416], "maxpool1d": [1112, 1237, 1240, 1375, 1721], "accommod": [1112, 1113, 1114], "unpool": [1112, 1113, 1114], "maxpool2d": [1113, 1117, 1238, 1241, 1376, 1713, 1721], "maxpool3d": [1114, 1239, 1242, 1660, 1721], "unpooled_output": 1114, "lrelu": [1117, 1706], "leakyrelu": [1117, 1228, 1373, 1706, 1721], "hing": [1119, 1121], "8500": 1119, "sum_i": [1120, 1121, 1148], "nelement": [1120, 1148], "3250": 1121, "embed_dim": [1122, 1328], "num_head": [1122, 1328, 1677], "add_bias_kv": [1122, 1328], "add_zero_attn": [1122, 1328, 1677], "kdim": [1122, 1328], "vdim": [1122, 1328], "jointli": 1122, "multihead": [1122, 1161], "concat": [1122, 1677], "head_1": 1122, "head_h": 1122, "head_i": 1122, "qw_i": 1122, "kw_i": 1122, "vw_i": 1122, "loosen": 1122, "inference_mod": [1122, 1163], "key_padding_mask": [1122, 1328, 1677], "attn_mask": [1122, 1328, 1677], "attn_output_weight": [1122, 1328], "multihead_attn": 1122, "attn_output": [1122, 1328], "need_weight": [1122, 1328, 1677], "average_attn_weight": [1122, 1328, 1677], "e_q": 1122, "e_k": 1122, "e_v": 1122, "_head": [1122, 1159], "attn_weight": [1122, 1328], "nll": 1123, "crossentropyloss": [1123, 1196], "num_paramet": 1124, "nchannel": 1124, "decai": [1124, 1430, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1446, 1449, 1453, 1455, 1456, 1459, 1461, 1715], "legitim": [1124, 1213], "fromkei": 1126, "popitem": 1126, "setdefault": 1126, "upscale_factor": [1128, 1254, 1677], "upscal": 1128, "video": [1128, 1129, 1690, 1732], "shi": [1128, 1129], "2016": [1128, 1129, 1165], "_factor": [1128, 1129, 1168, 1169, 1170], "pixel_shuffl": [1128, 1677, 1714], "downscale_factor": [1129, 1255, 1677], "pixelshuffl": [1129, 1254, 1255], "downscal": 1129, "pixel_unshuffl": [1129, 1677, 1714], "log_input": [1130, 1256, 1677], "poisson": [1130, 1256, 1677], "stirl": [1130, 1256], "elman": [1131, 1133, 1358], "ih": [1131, 1133, 1181, 1182, 1189, 1190, 1192, 1193, 1238, 1239, 1361, 1362, 1366, 1367], "hh": [1131, 1133], "flatten_paramet": 1132, "3333333333333333": [1134, 1449, 1455, 1677], "leaki": [1134, 1261, 1694], "rectifi": [1134, 1135, 1258, 1694], "liner": 1134, "empir": 1134, "1505": 1134, "00853": 1134, "crelu": 1135, "1603": 1135, "05201": 1135, "480": 1142, "6732632423543772848170429916717": [1143, 1263], "0507009873554804934193349852946": [1143, 1263], "kaiming_norm": 1143, "kaiming_normal_": [1143, 1681, 1694], "initialis": 1143, "calculate_gain": [1143, 1681, 1694], "modulelist": [1144, 1706], "cascad": 1144, "relu1": [1144, 1314, 1499], "relu2": [1144, 1314], "swish": [1145, 1265], "coin": [1145, 1265], "explod": 1147, "cnn": [1147, 1719], "ross": 1147, "girshick": 1147, "quadrat": [1147, 1702], "huberloss": [1147, 1222], "vari": [1147, 1410, 1501, 1687, 1715, 1719, 1720, 1727], "lie": [1149, 1151, 1268, 1608, 1728, 1732], "unspecif": 1149, "w_j": 1150, "soft": [1153, 1215, 1271], "softshrinkag": 1153, "convert_sync_batchnorm": 1155, "r1": 1155, "sync_bn_network": 1155, "ddp_sync_bn_network": 1155, "sync_bn_modul": 1155, "d_model": [1159, 1160, 1161, 1162, 1163], "nhead": [1159, 1160, 1161, 1162, 1163], "num_encoder_lay": 1159, "num_decoder_lay": 1159, "dim_feedforward": [1159, 1161, 1163], "2048": [1159, 1161, 1163, 1501, 1699], "custom_encod": 1159, "custom_decod": 1159, "layer_norm_ep": [1159, 1161, 1163], "norm_first": [1159, 1161, 1163], "ashish": [1159, 1161, 1163], "vaswani": [1159, 1161, 1163], "noam": [1159, 1161, 1163], "shazeer": [1159, 1161, 1163], "niki": [1159, 1161, 1163], "parmar": [1159, 1161, 1163], "jakob": [1159, 1161, 1163], "uszkoreit": [1159, 1161, 1163], "llion": [1159, 1161, 1163], "jone": [1159, 1161, 1163], "aidan": [1159, 1161, 1163], "gomez": [1159, 1161, 1163], "lukasz": [1159, 1161, 1163], "illia": [1159, 1161, 1163], "polosukhin": [1159, 1161, 1163], "6010": [1159, 1161, 1163], "multiheadattent": [1159, 1161, 1163, 1719], "feedforward": [1159, 1161, 1163, 1694], "transformer_model": 1159, "word_language_model": 1159, "src_mask": [1159, 1163], "tgt_mask": [1159, 1160, 1161], "memory_mask": [1159, 1160, 1161], "src_key_padding_mask": [1159, 1162, 1163], "tgt_key_padding_mask": [1159, 1160, 1161], "memory_key_padding_mask": [1159, 1160, 1161], "_mask": [1159, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1407], "unmask": [1159, 1328], "_key_padding_mask": 1159, "generate_square_subsequent_mask": 1159, "sz": 1159, "decoder_lay": [1160, 1161], "transformerdecoderlay": 1160, "transformer_decod": 1160, "attn": [1161, 1163], "respectivali": [1161, 1163], "encoder_lay": [1162, 1163], "enable_nested_tensor": 1162, "mask_check": 1162, "bert": 1162, "1810": 1162, "04805": 1162, "transformerencoderlay": 1162, "transformer_encod": 1162, "triplet": [1164, 1165], "x3": 1164, "balnta": [1164, 1165], "riba": [1164, 1165], "a_i": [1164, 1165], "p_i": [1164, 1165], "rm": [1164, 1165], "bf": [1164, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446], "rvert_p": [1164, 1249], "tripletmarginwithdistanceloss": [1164, 1279], "triplet_loss": [1164, 1165], "distance_funct": [1165, 1279], "l_i": 1165, "tripletmarginloss": [1165, 1278], "l_p": [1165, 1249], "pairwisedist": [1165, 1252], "penal": [1165, 1706], "distant": 1165, "anchor_id": 1165, "positive_id": 1165, "negative_id": 1165, "l_infin": 1165, "bmva": 1165, "bmvc": 1165, "paper119": 1165, "unflattened_s": 1166, "namedtensor": 1166, "namedshap": 1166, "u_1": 1166, "u_n": 1166, "u_i": 1166, "im2col": [1167, 1677, 1714], "fold": [1167, 1630, 1677, 1685, 1713, 1722, 1727], "2x3": 1167, "3x4": 1167, "inp_unf": 1167, "out_unf": 1167, "scale_factor": [1168, 1169, 1170, 1224, 1281, 1282, 1283, 1372, 1378, 1379, 1380, 1677], "align_corn": [1168, 1169, 1178, 1213, 1224, 1281, 1282, 1372, 1378, 1379, 1677], "recompute_scale_factor": [1168, 1224], "bicub": [1168, 1213, 1224, 1281, 1660], "trilinear": [1168, 1213, 1224, 1281, 1660], "input_3x3": 1168, "4375": 1168, "8125": 1168, "9375": 1168, "2400": [1168, 1641], "1200": [1168, 1571, 1699], "8800": 1168, "4400": [1168, 1641], "7200": 1168, "0400": 1168, "2800": [1168, 1593], "3600": 1168, "5200": 1168, "6400": 1168, "1678": 1171, "4418": 1171, "9466": [1171, 1728], "9604": 1171, "4219": 1171, "5241": 1171, "9162": 1171, "5436": [1171, 1641], "6446": 1171, "adaptiveavgpool1d": [1172, 1721], "adaptiveavgpool2d": [1173, 1359, 1660, 1721], "adaptiveavgpool3d": [1174, 1360, 1660, 1721], "tripl": [1174, 1177], "adaptivemaxpool1d": 1175, "adaptivemaxpool2d": [1176, 1660], "adaptivemaxpool3d": 1177, "ill": 1178, "avgpool1d": [1180, 1721], "iw": [1180, 1181, 1182, 1188, 1189, 1190, 1191, 1192, 1193, 1237, 1238, 1239, 1361, 1362, 1365, 1366, 1367], "sw": [1180, 1181, 1182, 1188, 1189, 1190, 1191, 1192, 1193, 1237, 1238, 1239, 1361, 1362, 1365, 1366, 1367], "padw": [1180, 1181, 1182, 1188, 1189, 1190, 1191, 1192, 1193, 1361, 1362, 1365, 1366, 1367], "sh": [1181, 1182, 1189, 1190, 1192, 1193, 1238, 1239, 1361, 1362, 1366, 1367], "avgpool2d": [1181, 1361, 1721], "padh": [1181, 1182, 1189, 1190, 1192, 1193, 1361, 1362, 1366, 1367], "st": [1182, 1190, 1193, 1239], "avgpool3d": [1182, 1660, 1721], "iT": [1182, 1190, 1193], "padt": [1182, 1190, 1193], "dw": [1188, 1189, 1190, 1191, 1192, 1193, 1365, 1366, 1367], "dh": [1189, 1190, 1192, 1193, 1366, 1367], "dt": [1190, 1193, 1728], "out_padw": [1191, 1192, 1193], "out_padh": [1192, 1193], "out_padt": 1193, "cosineembeddingloss": 1194, "ctcloss": [1197, 1660], "charact": [1197, 1590, 1676, 1679, 1690, 1713, 1724], "elu": [1203, 1677, 1713, 1714, 1721], "embedding_matrix": [1204, 1205], "8490": 1204, "9625": 1204, "6753": 1204, "7761": 1204, "6108": 1204, "6246": 1204, "9751": 1204, "3618": 1204, "4161": 1204, "2419": 1204, "7383": 1204, "0237": 1204, "7794": 1204, "0528": 1204, "3385": 1204, "8612": 1204, "1867": 1204, "5384": 1204, "8720": 1204, "6262": 1204, "7471": 1204, "embeddingbag": [1205, 1660, 1719, 1721, 1733], "3397": 1205, "5545": 1205, "5893": 1205, "4386": 1205, "5882": 1205, "featurealphadropout": 1206, "gaussiannllloss": 1210, "border": 1213, "affine_grid": [1213, 1677], "extrema": 1213, "overshoot": [1213, 1224, 1281], "groupnorm": 1214, "gumbel": 1215, "y_hard": 1215, "y_soft": 1215, "hardtanh": [1220, 1677, 1685, 1714, 1721], "hingeembeddingloss": 1221, "use_input_stat": [1223, 1677], "antialia": 1224, "anti": 1224, "pillow": [1224, 1732], "buggi": 1224, "inter_nearest": 1224, "kldivloss": 1225, "batchsiz": [1225, 1611, 1612, 1613, 1615, 1616, 1727], "leaky_relu": [1229, 1677, 1694, 1714, 1721], "localresponsenorm": 1231, "_stacklevel": [1232, 1268, 1269, 1677], "lppool1d": 1234, "lppool2d": 1235, "marginrankingloss": 1236, "max_unpool1d": [1237, 1677], "multimarginloss": 1245, "multilabelmarginloss": 1246, "multilabelsoftmarginloss": 1247, "n_0": 1249, "n_": 1249, "n_k": 1249, "everywher": [1250, 1625], "constantpad2d": 1251, "reflectionpad2d": [1251, 1660], "replicationpad2d": [1251, 1660], "t4d": 1251, "p1d": 1251, "p2d": 1251, "p3d": 1251, "pixelunshuffl": 1255, "poissonnllloss": 1256, "rrelu": [1262, 1677, 1714], "softmarginloss": 1267, "module_kwarg": 1277, "upsample_trilinear": 1282, "fo": 1282, "spatia": 1283, "qat": [1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1323, 1324, 1325, 1326, 1719, 1720, 1721], "freeze_bn": [1296, 1297, 1298, 1299, 1300, 1301], "qconfig": [1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1323, 1324, 1325, 1326, 1477, 1478, 1480, 1481, 1482, 1520, 1521, 1522, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1537, 1538, 1540, 1541], "fakequant": [1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1323, 1324, 1325, 1326, 1487, 1488, 1492, 1493, 1494, 1524, 1528, 1531], "weight_fake_qu": [1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1323, 1324], "qint8": [1312, 1313, 1349, 1354, 1357, 1358, 1365, 1366, 1367, 1374, 1484, 1490, 1491, 1493, 1494, 1502, 1515, 1517, 1523, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1535, 1537, 1538, 1544, 1545, 1719, 1721, 1722, 1729, 1733, 1734], "mixin": 1314, "dry": 1314, "lazymlp": 1314, "lazylinear": 1314, "lazy_mlp": 1314, "mlp": [1314, 1719], "8832e": 1314, "5636e": 1314, "1598e": 1314, "5637e": 1314, "8788e": 1314, "0042e": 1314, "0019": 1314, "lazymodul": 1314, "full_mlp": 1314, "3837": [1314, 1473], "0907": 1314, "6708": 1314, "5223": 1314, "9028": 1314, "2851": 1314, "6813": 1314, "5766": 1314, "8678": 1314, "1320": 1314, "2938": 1314, "0679": [1314, 1651], "2793": [1314, 1423], "1088": 1314, "1795": 1314, "2301": 1314, "2807": 1314, "2479": 1314, "1091": 1314, "has_uninitialized_param": 1314, "initialize_paramet": 1314, "register_module_full_backward_hook": [1315, 1706], "check_reduct": 1319, "my_model": [1319, 1676], "optimizer_param": 1319, "loss_func": [1319, 1724], "consume_prefix_in_state_dict_if_pres": 1319, "nccl2": 1319, "redunct": 1319, "dictat": [1319, 1679], "megabyt": 1319, "mb": [1319, 1699], "travers": [1319, 1500, 1518, 1700, 1701, 1725, 1736, 1737], "preemptiv": [1319, 1520, 1521], "detach_": [1319, 1677, 1689, 1721, 1727], "reentrant": 1319, "iteraton": 1319, "ddp_logging_data": 1319, "can_set_static_graph": 1319, "model_ddp": 1319, "_get_ddp_logging_data": 1319, "pg": 1319, "divide_by_initial_world_s": 1319, "syncbatchnorm": 1319, "exhaust": 1319, "deplet": 1319, "pariti": 1319, "discrep": [1319, 1549, 1703], "another_input": 1319, "predivid": 1319, "encode_and_decod": 1319, "encoded_tensor": 1319, "decoded_tensor": 1319, "uniti": [1321, 1322], "highlight": [1323, 1324, 1679], "from_float": [1325, 1331, 1332, 1333, 1338, 1339, 1349, 1357, 1482, 1505, 1508, 1520, 1719], "qparams_dict": [1325, 1331, 1332, 1333, 1357], "ao": [1325, 1331, 1332, 1333, 1338, 1339, 1349, 1357, 1484, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1511, 1512, 1513, 1514, 1515, 1517, 1519, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1538, 1539, 1540, 1541, 1719, 1720, 1721], "_lstmlayer": 1327, "nnqa": 1327, "dequant": [1328, 1477, 1479, 1484, 1486, 1540, 1677, 1714, 1720, 1722, 1734, 1736], "mha": 1328, "conver": 1328, "quint8": [1331, 1332, 1333, 1334, 1335, 1336, 1338, 1339, 1349, 1365, 1366, 1367, 1374, 1484, 1488, 1489, 1492, 1501, 1502, 1503, 1504, 1507, 1509, 1511, 1512, 1524, 1526, 1528, 1529, 1534, 1535, 1538, 1544, 1545, 1546, 1547, 1548, 1719, 1721, 1722, 1729, 1733, 1734], "q_input": [1331, 1332, 1333, 1334, 1335, 1336, 1365, 1366, 1367], "quantize_per_tensor": [1331, 1332, 1333, 1334, 1335, 1336, 1349, 1350, 1351, 1365, 1366, 1367, 1546, 1547, 1548, 1677, 1714, 1719], "56": 1333, "qnnpack": [1334, 1335, 1349, 1357, 1719, 1721], "nnq": [1334, 1335, 1336, 1477, 1478, 1479, 1543, 1719], "fbgemm": [1335, 1336, 1349, 1357, 1540, 1541, 1719, 1720, 1721], "overwritten": [1338, 1339, 1349, 1357, 1482, 1523, 1696, 1734], "_embed": [1338, 1339], "embedding_bag": [1339, 1677, 1714], "floatfunct": [1340, 1719], "activation_post_process": [1340, 1484, 1719], "add_relu": [1340, 1341, 1350, 1736], "add_scalar": [1340, 1341, 1350, 1732, 1736], "mul_scalar": [1340, 1341, 1350, 1736], "collector": 1341, "f_add": 1341, "bias_": [1349, 1357], "from_refer": [1349, 1357], "ref_qlinear": [1349, 1357], "output_scal": [1349, 1352, 1546, 1677], "output_zero_point": [1349, 1352, 1546, 1677], "q_add": 1350, "qint32": [1350, 1351, 1544, 1545, 1719, 1722, 1729, 1733, 1734], "x_0": [1351, 1646], "_direct": 1353, "sd": [1362, 1367], "padd": [1362, 1367], "qf": [1365, 1366, 1367], "dtype_input": [1365, 1366, 1367], "dtype_filt": [1365, 1366, 1367], "q_filter": [1365, 1366, 1367], "dd": 1367, "quaintiz": 1373, "error_if_nonfinit": 1381, "clip_valu": 1382, "orthogonal_map": 1384, "use_trivi": 1384, "qq": 1384, "matrix_exp": [1384, 1677], "caylei": 1384, "thin": [1384, 1475], "manifold": 1384, "register_parametr": [1384, 1385, 1386, 1387, 1416, 1692], "orth_linear": 1384, "parametrizedlinear": [1384, 1385], "moduledict": [1384, 1385, 1678, 1706], "parametrizationlist": [1384, 1385, 1389], "_orthogon": 1384, "9332e": 1384, "n_power_iter": [1385, 1416], "sn": [1385, 1416], "discrimin": [1385, 1416], "adversari": [1385, 1416], "lipschitz": 1385, "reimplement": [1385, 1416], "_spectralnorm": 1385, "convtranspos": [1385, 1416], "snm": 1385, "copybackward": 1385, "unsaf": [1386, 1389, 1677, 1699, 1716], "original0": [1386, 1389], "original1": [1386, 1389], "tensor_nam": [1386, 1388, 1389, 1390], "parmetr": 1386, "right_invers": [1386, 1389], "out_rnn": 1387, "rnn_cell": 1387, "simplic": [1389, 1725], "inbuilt": 1389, "unparametr": 1389, "rankon": 1389, "surject": 1389, "s0_sqrt": 1389, "linear_rank_on": 1389, "leave_parametr": 1390, "unparametris": 1390, "prune": [1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398], "skeleton": 1391, "compute_mask": [1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398], "importance_scor": [1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1400, 1403, 1404], "apply_mask": [1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398], "pruned_tensor": [1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398], "default_mask": [1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398], "_orig": [1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1403, 1404, 1405, 1406, 1407], "undon": [1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1407], "unprun": [1394, 1395, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406], "indexerror": [1395, 1397], "basepruningmethod": [1396, 1402], "add_pruning_method": 1396, "pruning_typ": [1396, 1400], "unstructur": [1396, 1400], "ravel": [1396, 1677], "nonmask": 1396, "bias_mask": [1399, 1401], "pruning_method": 1400, "typeerror": [1400, 1701, 1717, 1734, 1738], "parameters_to_prun": 1400, "l1unstructur": 1400, "parameters_to_vector": 1400, "forward_pre_hook": [1402, 1706], "random_unstructur": [1402, 1407], "weight_orig": 1403, "weight_mask": [1403, 1406], "columns_prun": 1405, "weight_norm": 1409, "sorted_indic": [1410, 1413], "unsorted_indic": [1410, 1413], "abc": [1410, 1679], "axbc": 1410, "throughout": [1410, 1703, 1706, 1719], "conform": [1410, 1706], "is_cuda": [1410, 1689, 1729], "enforce_sort": [1411, 1412, 1413], "unsort": [1411, 1412, 1578], "shortest": 1411, "onnx": [1411, 1412, 1428, 1429, 1675, 1690], "uncondition": [1411, 1674, 1701, 1738], "pad_sequ": [1412, 1677], "padding_valu": [1413, 1414, 1677], "total_length": [1413, 1702], "seq_unpack": 1413, "lens_unpack": 1413, "module_cl": [1415, 1724], "5846e": 1415, "29": [1415, 1713], "8307e": 1415, "5250e": 1415, "1210e": 1415, "4677e": 1415, "5915e": 1415, "4013e": 1415, "weight_u": 1416, "parameters_and_buff": 1417, "submodule_nam": 1417, "parameter_nam": 1417, "decoupl": [1419, 1434], "weight_g": [1419, 1677], "weight_v": 1419, "1602": 1419, "07868": 1419, "as_tupl": [1421, 1670], "complexfloat": 1422, "0425": 1423, "7969": 1423, "2925": 1423, "7229": 1423, "2134": 1423, "0505": 1423, "1408": 1423, "0563": 1423, "0566": 1423, "0732": [1423, 1641], "0687": 1423, "1177": 1423, "2303": 1423, "1552": 1423, "6148": 1423, "6535": 1423, "8318": 1423, "3987": 1423, "9544": [1423, 1550], "6048": 1423, "7909": 1423, "120": [1425, 1732], "from_nam": 1428, "onnx_typ": 1428, "tensorprotodatatyp": 1428, "scalartyp": 1428, "from_dtyp": 1428, "onnx_compat": 1428, "scalar_nam": 1428, "torch_nam": 1428, "params_dict": 1429, "cur_nod": [1429, 1713], "onnx_block": 1429, "weight_decai": [1430, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1446, 1706], "foreach": [1430, 1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446], "1e6": 1430, "reevalu": [1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1441, 1443, 1444, 1445, 1447, 1715], "altogeth": [1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1442, 1443, 1444, 1445, 1446, 1447], "rho": 1431, "110mm": [1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446], "4pt": [1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446], "textbf": [1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446], "theta_0": [1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446], "v_0": [1431, 1433, 1434, 1437, 1443, 1444], "leftarrow": [1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446], "u_0": [1431, 1435], "hspace": [1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446], "5mm": [1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446], "nabla_": [1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446], "theta_": [1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446], "10mm": [1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446], "v_t": [1431, 1433, 1434, 1437, 1443, 1444], "v_": [1431, 1433, 1434, 1437, 1443, 1444, 1446], "2_t": [1431, 1432, 1433, 1434, 1437, 1443, 1444], "21mm": 1431, "u_t": [1431, 1435], "theta_t": [1431, 1432, 1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446], "lr_decai": 1432, "initial_accumulator_valu": 1432, "12mm": [1432, 1443], "_sum_0": 1432, "tild": [1432, 1444], "_sum_t": 1432, "_sum_": 1432, "subgradi": 1432, "999": [1433, 1434, 1435, 1437, 1443, 1447, 1711], "amsgrad": [1433, 1434], "beta_1": [1433, 1434, 1435, 1437, 1443], "beta_2": [1433, 1434, 1435, 1437, 1443], "13mm": [1433, 1434, 1435, 1437, 1443, 1444, 1445, 1446], "textit": [1433, 1434, 1446], "m_0": [1433, 1434, 1435, 1437, 1443], "widehat": [1433, 1434, 1437, 1443], "m_t": [1433, 1434, 1435, 1437, 1443], "m_": [1433, 1434, 1435, 1437, 1443], "impair": [1433, 1434], "ungraph": [1433, 1434], "002": [1435, 1437], "t_1": 1435, "2e": [1435, 1437], "max_it": 1436, "max_ev": 1436, "tolerance_grad": 1436, "tolerance_chang": 1436, "history_s": 1436, "line_search_fn": 1436, "bfg": 1436, "minfunc": 1436, "intens": [1436, 1709], "param_byt": 1436, "strong_wolf": 1436, "momentum_decai": 1437, "004": 1437, "gamma_t": 1437, "psi": [1437, 1728], "mu_t": 1437, "96": 1437, "mu_": 1437, "11mm": 1437, "incorpor": [1437, 1719], "nesterov": [1437, 1446], "4e": 1437, "weightdecai": 1443, "18mm": 1443, "rho_": 1443, "6mm": 1443, "rho_t": 1443, "t_2": 1443, "l_t": 1443, "_0": [1444, 1716], "av": 1444, "8mm": 1444, "3mm": 1444, "lectur": 1444, "hinton": 1444, "step_siz": [1445, 1461], "resili": [1445, 1709], "eta_": [1445, 1450, 1451], "etaplu": 1445, "etaminu": 1445, "gamma_": [1445, 1728], "0_": 1445, "eta_0": 1445, "i_": [1445, 1641], "15mm": [1445, 1446], "eta_t": [1445, 1450, 1451], "etapli": 1445, "dampen": 1446, "subtli": 1446, "sutskev": 1446, "veloc": 1446, "lr_schedul": [1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1715], "chainabl": [1448, 1458], "081": 1448, "729": [1448, 1460], "6561": [1448, 1665], "59049": 1448, "scheduler1": [1448, 1460, 1715], "constantlr": [1448, 1460], "total_it": [1448, 1449, 1455, 1460], "scheduler2": [1448, 1460, 1715], "exponentiallr": [1448, 1460, 1715], "get_last_lr": [1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461], "print_lr": [1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461], "is_verbos": [1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461], "__dict__": [1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461], "last_epoch": [1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461], "mileston": [1449, 1455, 1456, 1460, 1715], "simultan": [1449, 1450, 1455, 1456, 1461, 1696, 1724], "025": [1449, 1455], "t_max": [1450, 1715], "eta_min": [1450, 1451], "anneal": [1450, 1451, 1458, 1715], "cur": [1450, 1451], "sgdr": [1450, 1451], "2k": 1450, "sole": 1450, "t_mult": 1451, "interleav": 1451, "base_lr": [1452, 1458], "max_lr": [1452, 1458], "step_size_up": 1452, "step_size_down": 1452, "scale_fn": 1452, "scale_mod": 1452, "cycle_momentum": [1452, 1458], "base_momentum": [1452, 1458], "max_momentum": [1452, 1458], "cyclic": 1452, "forth": [1452, 1661, 1674, 1718], "amplitud": [1452, 1458], "triangular2": 1452, "exp_rang": 1452, "bckenstler": 1452, "data_load": [1452, 1458, 1540, 1541, 1708], "train_batch": [1452, 1458], "get_lr": 1452, "lr_lambda": [1454, 1457], "lambda1": 1454, "lambda2": 1454, "start_factor": 1455, "end_factor": 1455, "03125": 1455, "0375": 1455, "04375": 1455, "005": [1456, 1461], "lmbda": 1457, "total_step": 1458, "steps_per_epoch": 1458, "pct_start": 1458, "anneal_strategi": [1458, 1715], "div_factor": 1458, "final_div_factor": 1458, "three_phas": 1458, "1cycl": 1458, "fastai": 1458, "unpublish": 1458, "percentag": 1458, "initial_lr": 1458, "min_lr": [1458, 1459], "1e4": 1458, "annihil": 1458, "patienc": 1459, "threshold_mod": 1459, "cooldown": 1459, "stagnat": 1459, "new_lr": 1459, "hasn": [1459, 1687, 1716], "optimum": 1459, "dynamic_threshold": 1459, "val_loss": 1459, "81": 1460, "mn": 1463, "pca": [1465, 1727], "overestim": [1465, 1630], "nathan": [1465, 1630], "halko": [1465, 1630], "gunnar": [1465, 1630], "martinsson": [1465, 1630], "tropp": [1465, 1630], "probabilist": [1465, 1630], "0909": [1465, 1630], "4061": [1465, 1630], "na": [1465, 1630], "2009": [1465, 1630], "cmath": [1469, 1677], "4142j": 1469, "4331": 1472, "2475": [1472, 1628], "6834": 1472, "2791": 1472, "1875": 1472, "5561": 1472, "4670": 1472, "5428": 1473, "5854": 1473, "5261": [1473, 1629], "1857": 1473, "2498": 1473, "1646": [1473, 1699], "0705": 1473, "0629": 1473, "2962": 1473, "0821": 1473, "1831": 1473, "type1": [1474, 1677], "type2": [1474, 1677], "propabl": 1475, "2117": 1476, "9765": 1476, "1707": 1476, "4884": 1476, "5661": 1476, "5795": 1476, "5280": 1476, "9206": 1476, "stub": [1477, 1478, 1716], "calibr": [1477, 1478, 1482, 1520, 1521, 1536, 1538, 1540, 1541, 1695, 1719, 1720, 1722], "quantstub": [1479, 1719], "dequantstub": [1479, 1719], "add_observer_": 1480, "qconfig_propagation_list": 1480, "non_leaf_module_list": 1480, "custom_module_class_map": [1480, 1543], "forward_hook": [1480, 1706], "quantwrapp": 1481, "remove_qconfig": 1482, "is_refer": [1482, 1538], "convert_custom_config_dict": [1482, 1719], "from_observ": [1482, 1719], "observed_to_quantized_custom_module_class": [1482, 1719], "observedcustommodul": [1482, 1520, 1538, 1540, 1719], "quantizedcustommodul": [1482, 1538], "calib_data": 1483, "movingaverageminmaxobserv": [1484, 1487, 1488, 1489, 1491, 1494, 1504, 1524, 1528, 1529, 1531], "observer_kwarg": [1484, 1487], "x_out": [1484, 1487], "fake_quant_en": 1484, "observer_en": 1484, "emul": [1484, 1680, 1701], "calculate_qparam": [1485, 1501, 1502, 1506], "with_arg": [1485, 1506, 1523], "_callable_arg": [1485, 1506], "_with_arg": [1485, 1506], "foo_build": [1485, 1506], "foo_instance1": [1485, 1506], "foo_instance2": [1485, 1506], "qscheme": [1487, 1488, 1490, 1491, 1492, 1493, 1494, 1501, 1502, 1503, 1504, 1507, 1509, 1512, 1515, 1517, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1534, 1535, 1677, 1719, 1722, 1734], "per_tensor_affin": [1488, 1492, 1501, 1502, 1503, 1524, 1528, 1545, 1546, 1547, 1548, 1719, 1722], "reduce_rang": [1488, 1492, 1493, 1494, 1501, 1502, 1503, 1504, 1507, 1509, 1524, 1528, 1531, 1677, 1719, 1720], "fusedmovingavgobsfakequant": [1489, 1490, 1491, 1529], "movingaverageperchannelminmaxobserv": [1490, 1493], "per_channel_symmetr": [1490, 1493, 1515, 1527, 1535, 1719, 1722], "per_tensor_symmetr": [1491, 1494, 1517, 1525, 1526, 1528, 1529, 1530, 1531, 1719, 1722], "histogramobserv": [1492, 1513], "ch_axi": [1493, 1504, 1507, 1512, 1534, 1677], "modules_to_fus": 1499, "fuser_func": 1499, "fuse_known_modul": 1499, "fuse_custom_config_dict": 1499, "convmodul": 1499, "bnmodul": 1499, "convbnmodul": 1499, "fuser_method": [1499, 1721], "additional_fuser_method_map": 1499, "fuse_conv_bn": 1499, "bn1": 1499, "fused_m": 1499, "target_dict": [1500, 1736], "upsample_r": 1501, "factory_kwarg": [1501, 1502, 1507], "1920928955078125e": [1501, 1502, 1503, 1504, 1507], "minmaxobserv": [1501, 1503, 1507, 1514, 1517, 1523, 1525, 1526, 1527, 1530, 1722], "q_": [1502, 1722], "x_orig": 1502, "reset_min_max_v": [1502, 1507], "averaging_const": [1503, 1504, 1677], "per_channel_affin": [1504, 1507, 1544, 1719, 1722], "custom_op_nam": [1505, 1508], "with_callable_arg": 1506, "_with_callable_arg": 1506, "cur_tim": 1506, "get_time_func": 1506, "dan": 1506, "creation_tim": 1506, "compute_dtyp": [1508, 1511, 1526, 1532, 1535], "recordingobserv": [1510, 1525], "placeholderobserv": [1511, 1516, 1526, 1532, 1533, 1534, 1535], "perchannelminmaxobserv": [1512, 1515, 1527, 1534, 1535], "per_channel_affine_float_qparam": [1512, 1534], "obs_dict": 1519, "get_observer_state_dict": 1519, "allow_list": [1520, 1736], "observer_non_leaf_module_list": 1520, "prepare_custom_config_dict": [1520, 1522, 1719], "float_to_observed_custom_module_class": [1520, 1719], "custommodul": [1520, 1719], "propagate_qconfig_": 1522, "qconfig_dict": 1522, "prepare_fx": [1522, 1538, 1541, 1719, 1737], "my_qconfig": 1523, "default_observ": 1523, "run_arg": [1536, 1542], "qconfig_spec": 1537, "quantize_fx": [1538, 1539, 1540, 1541, 1719, 1737], "graph_modul": 1538, "convert_custom_config": [1538, 1719], "_remove_qconfig": 1538, "qconfig_map": [1538, 1540, 1541, 1719], "backend_config_dict": [1538, 1539, 1540, 1541, 1719], "graphmodul": [1538, 1540, 1541], "convertcustomconfig": 1538, "custom_config": [1538, 1539, 1540], "set_observed_to_quantized_map": 1538, "set_preserved_attribut": [1538, 1539, 1540], "attr1": [1538, 1540, 1713], "attr2": [1538, 1540, 1713], "prepare_qat_fx": [1538, 1719], "qconfigmap": [1538, 1540, 1541, 1719], "set_glob": [1538, 1540, 1541, 1719], "qconfig_from_prepar": 1538, "set_object_typ": [1538, 1540], "set_module_nam": [1538, 1540], "weight_onli": [1538, 1719], "backend_config": 1538, "prepared_model": [1538, 1540, 1541], "quantized_model": 1538, "fuse_custom_config": 1539, "fusion_pattern": 1539, "fusecustomconfig": 1539, "prepare_custom_config": [1540, 1541, 1719], "_equalization_config": 1540, "global_qconfig": 1540, "qconfig1": 1540, "set_module_name_regex": 1540, "qconfig2": 1540, "qconfig3": 1540, "module1": [1540, 1699], "module2": [1540, 1699], "set_module_name_object_type_ord": 1540, "module3": [1540, 1699], "preparecustomconfig": 1540, "set_standalone_module_nam": 1540, "child_prepare_custom_config": 1540, "set_standalone_module_class": 1540, "mystandalonemodul": 1540, "set_float_to_observed_map": 1540, "floatcustommodul": 1540, "set_non_traceable_module_nam": 1540, "set_non_traceable_module_class": 1540, "nontraceablemodule1": 1540, "nontraceablemodule2": 1540, "set_input_quantized_index": 1540, "set_output_quantized_index": 1540, "operaetor": 1540, "get_default_qconfig": [1540, 1719], "float_model": [1540, 1541, 1736], "sample_inference_data": 1540, "get_default_qat_qconfig": [1541, 1719], "train_data": 1541, "quantization_schem": [1544, 1545, 1546, 1547, 1548], "int_repr": [1544, 1545, 1677], "nchw": [1546, 1732], "qx": [1546, 1547, 1548], "00001": 1546, "opttion": 1547, "max_pool1d": [1547, 1677, 1714, 1721], "max_pool2d": [1548, 1677, 1714, 1721], "quasirandom": 1549, "scrambl": 1549, "sobol": 1549, "quasi": 1549, "21201": 1549, "web": 1549, "unsw": 1549, "au": [1549, 1716], "fkuo": 1549, "art": 1549, "owen": 1549, "niederreit": 1549, "xing": 1549, "journal": 1549, "466": 1549, "489": 1549, "decemb": 1549, "1998": 1549, "zh": 1549, "vychisl": 1549, "phy": 1549, "784": 1549, "802": 1549, "1967": 1549, "soboleng": 1549, "draw_base2": 1549, "base2": 1549, "fast_forward": 1549, "142": 1550, "283": 1550, "570": 1550, "359": 1550, "9894": 1550, "2503": 1551, "3525": 1551, "5673": 1551, "8237": 1551, "5781": 1551, "6879": 1551, "3816": 1551, "7249": 1551, "0998": 1551, "1436": 1555, "9966": 1555, "3426": 1555, "6366": 1555, "5954": 1555, "8929": 1555, "0923": 1555, "1719": 1555, "4709": 1555, "1996": 1555, "4595": 1561, "4314": 1561, "flat": [1564, 1677, 1691, 1713], "n1": 1564, "n2": 1564, "n3": 1564, "negat": [1567, 1679], "is_neg": [1567, 1677], "ti": 1571, "equidist": 1571, "inexact": 1571, "1234567": 1571, "1230": 1571, "vstack": [1572, 1677, 1727], "0370": 1573, "2970": 1573, "5420": 1573, "9105": 1573, "8351": 1573, "pickle_protocol": [1574, 1716], "default_protocol": 1574, "_use_new_zipfile_seri": 1574, "zipfil": [1574, 1716], "sorted_sequ": [1578, 1677], "sorter": [1578, 1677], "sorted_sequence_1d": 1578, "complaint": 1582, "bfloat16_3x": 1585, "denorm": [1586, 1709], "sse3": 1586, "323": 1586, "88131e": 1586, "324": 1586, "is_train": [1587, 1735], "interop": 1588, "intraop": 1589, "edgeitem": 1590, "linewidth": 1590, "sci_mod": 1590, "shamelessli": 1590, "repr": [1590, 1679], "sane": 1590, "_tensor_str": 1590, "_formatt": 1590, "12345": 1590, "excess": 1592, "24j": 1593, "8000j": 1593, "9600j": 1593, "4472": [1593, 1706], "8944j": 1593, "expit": [1594, 1728], "5461": [1597, 1706], "1347": 1597, "7266": 1597, "2746": 1597, "1343": 1597, "4032": 1597, "2711": 1597, "5380": 1599, "8632": 1599, "1265": 1599, "9399": 1599, "5644": 1599, "9744": 1599, "1268": 1599, "2162": 1603, "6719": 1603, "3332": 1603, "5793": [1603, 1706], "0061": 1603, "6058": 1603, "9497": 1603, "5071": 1603, "3343": 1603, "9553": 1603, "0960": 1603, "derivati": [1604, 1606], "to_spars": [1606, 1677, 1710], "5901": 1606, "0183": 1606, "6146": 1606, "8061": 1606, "0112": [1606, 1618], "6302": 1606, "6479": 1606, "7874": 1606, "2056": 1606, "5641": 1606, "1716": 1606, "3323": 1606, "8723": 1606, "8951": 1606, "7904": 1606, "sparseaddmmbackward": 1606, "1394": 1606, "6415": [1606, 1633], "1639": [1606, 1699], "sparsiti": [1607, 1694, 1727], "spy": 1607, "crow_indic": [1607, 1609, 1612, 1613, 1616, 1677, 1727, 1734], "2847": 1607, "7805": 1607, "1900": [1607, 1710], "to_dens": [1607, 1609, 1677, 1727], "1423": 1607, "3903": 1607, "x_k": 1608, "sparse_csc": [1609, 1613, 1615, 1727], "6438": 1610, "6467": 1610, "3411": 1610, "0918": 1610, "5348": 1610, "0634": 1610, "0494": 1610, "0646": 1610, "1844": 1610, "1276": 1610, "1874": 1610, "6334": 1610, "9682": 1610, "5340": 1610, "7483": 1610, "4512": 1610, "4073": 1610, "8901": 1610, "3183": 1610, "7539": 1610, "6596": 1610, "ccol_indic": [1611, 1615, 1677, 1727, 1734], "ncolblock": [1611, 1727], "array_list": [1611, 1612, 1613, 1615, 1616], "dimenson": [1611, 1612, 1615, 1616], "nrow": [1611, 1612, 1613, 1615, 1616, 1727], "ncol": [1611, 1612, 1613, 1615, 1616, 1727], "denses": [1611, 1612, 1613, 1615, 1616, 1727], "nrowblock": [1612, 1727], "compressed_indic": [1613, 1677, 1727], "plain_indic": [1613, 1677, 1727], "compressed_dim_s": [1613, 1727], "rdinat": 1614, "_indic": [1614, 1727], "0755": [1618, 1619], "0226": [1618, 1619], "0831": [1618, 1619], "4806": [1618, 1619], "2883": 1618, "6933": 1618, "0457": 1619, "0069": 1619, "2310": 1619, "3802": [1623, 1624, 1662, 1663], "4188": [1623, 1624], "8509": [1624, 1663], "librosa": 1625, "omega": 1625, "win": [1625, 1696], "_fft": [1625, 1677], "1133": 1628, "2958": 1628, "5475": 1628, "0569": 1628, "0737": 1628, "3429": 1628, "9138": 1628, "9337": 1628, "6864": [1628, 1649], "1132": 1628, "7892": 1628, "1003": 1628, "5688": 1628, "3637": 1628, "9906": 1628, "5197": 1628, "4598": 1628, "3708": 1628, "6217": 1628, "435": 1628, "1335": 1628, "3135": 1628, "gesdd": 1629, "conquer": 1629, "gesvdjbatch": 1629, "fortran": 1629, "\u00b9": 1629, "2364": 1629, "7752": 1629, "7201": 1629, "7394": 1629, "0504": 1629, "3371": 1629, "5296": 1629, "3550": 1629, "5569": 1629, "2445": 1629, "1414": 1629, "4027": 1629, "0287": 1629, "5434": 1629, "1946": 1629, "8833": 1629, "3679": 1629, "4296": 1629, "2890": 1629, "6604": 1629, "2717": 1629, "2618": 1629, "4234": 1629, "2481": 1629, "4733": 1629, "3289": [1629, 1711], "0315": 1629, "7806": 1629, "0199": 1629, "8766": 1629, "4809": 1629, "5080": [1629, 1706], "4054": 1629, "7600": 1629, "8611": 1629, "2594": 1629, "4373": 1629, "6531e": 1629, "a_big": [1629, 1633], "6503e": 1629, "swapax": [1632, 1677, 1731], "thereof": 1633, "7827": [1633, 1691], "4559": 1633, "7123": 1633, "8330": 1633, "4250": 1633, "8636": 1633, "2100": 1633, "1798": 1633, "7112": 1633, "5785": 1633, "1988": 1633, "6227": 1633, "1036": 1633, "1453": 1633, "7012": 1633, "7497": [1633, 1665], "3163": 1633, "2477": 1633, "1050": 1633, "1643": 1633, "9034": 1633, "0291": 1633, "3508": [1633, 1706], "1817": 1633, "2417": 1633, "3071": 1633, "5081": 1633, "6534": 1633, "4026": 1633, "5176": 1633, "1223": 1633, "0220": 1633, "3295": 1633, "7798": 1633, "4850": 1633, "5773": 1633, "5840": 1633, "1337": 1633, "0447": 1633, "6381": 1633, "0193": 1633, "4230": 1633, "1995": 1634, "4608": 1634, "7702": 1634, "4875": 1634, "9158": 1634, "5872": 1634, "6929": 1634, "6932": 1634, "argsort": [1636, 1677, 1714], "take_along_axi": 1636, "max_idx": 1636, "sorted_idx": 1636, "2027": 1637, "7687": 1637, "4412": 1637, "3856": 1637, "5930": 1637, "9859": 1637, "4722": 1637, "3366": 1637, "8986": 1638, "7279": 1638, "1745": 1638, "7156": 1638, "8257": 1638, "2553": 1638, "as_tensor": [1639, 1677, 1701, 1714, 1732, 1733, 1734], "11111": 1639, "222222": 1639, "3333333": 1639, "1111": 1639, "2222": 1639, "array_split": 1640, "contract": [1641, 1690, 1716], "i_d": 1641, "k_": 1641, "4532": 1641, "4874": 1641, "5018": 1641, "4796": [1641, 1710], "5162": 1641, "5306": 1641, "2922": 1641, "7556": 1641, "2741": 1641, "3161": 1641, "0704": 1641, "0187": 1641, "4079": 1641, "3126": 1641, "8744": 1641, "8223": 1641, "9445": 1641, "4117": 1641, "7780": 1641, "7193": 1641, "4867": 1641, "3204": 1641, "5513": 1641, "4737": [1641, 1666], "2850": 1641, "2573": 1641, "5997": 1641, "0028": 1645, "9893": 1645, "5809": 1645, "1669": 1645, "7299": 1645, "4942": [1645, 1706], "y_0": 1646, "y_1": 1646, "x_diff": 1646, "y_diff": 1646, "riemann": [1646, 1696, 1703, 1728], "badli": 1648, "cloned_coeffici": 1648, "1527": 1648, "0753": 1648, "7986": 1648, "0210": 1648, "3513": 1648, "5492": 1648, "7403": 1648, "0243": 1648, "7841": 1648, "9046": 1648, "5405": 1648, "9320": 1648, "9270": 1648, "2826": 1648, "lbrace": [1649, 1650, 1651, 1652], "rbrace": [1649, 1650, 1651, 1652], "0813": 1649, "8619": 1649, "7105": 1649, "0935": 1649, "1380": 1649, "3409": [1649, 1710], "2219": 1649, "5653": 1649, "2521": 1649, "2345": 1649, "2544": 1649, "3461": 1649, "4785": 1649, "4477": 1649, "6049": 1649, "6368": 1649, "8775": 1649, "7145": 1649, "1502": 1649, "2716": 1649, "1243": 1649, "5413": 1649, "3615": 1649, "0614": 1649, "7344": 1649, "3164": 1649, "7648": 1649, "4024": 1649, "0978": 1649, "col": [1650, 1652, 1677], "2309": 1651, "5207": 1651, "0049": 1651, "2072": 1651, "0680": 1651, "6602": 1651, "3480": 1651, "5211": 1651, "4573": 1651, "5876": 1651, "0794": [1651, 1728], "8373": 1651, "6654": 1651, "2604": 1651, "5235": 1651, "2447": 1651, "9556": 1651, "2919": 1651, "1768": 1651, "4333": 1651, "3146": [1651, 1706], "6576": 1651, "0432": 1651, "9348": [1651, 1728], "4410": 1651, "9888": 1651, "3337": 1651, "6556": 1651, "4798": 1651, "5466": 1654, "8008": 1654, "9079": 1654, "unique_consecut": [1657, 1677], "inverse_indic": [1657, 1658], "warn_onli": 1660, "alon": [1660, 1678, 1716], "put_": [1660, 1677], "index_add": [1660, 1677, 1714], "index_select": [1660, 1677, 1714, 1727], "fractionalmaxpool2d": 1660, "fractionalmaxpool3d": 1660, "reflectionpad1d": 1660, "reflectionpad3d": 1660, "replicationpad1d": 1660, "replicationpad3d": 1660, "histc": [1660, 1677], "bincount": [1660, 1677], "kthvalu": [1660, 1677, 1689], "cublasapi_reproduc": [1660, 1710], "avg_pool3d_backward_cuda": 1660, "alexandr": 1661, "theophil": 1661, "1754": [1662, 1663], "vecdot": 1664, "mi": [1665, 1666], "6116": 1665, "5772": [1665, 1728], "4606": 1665, "9120": 1665, "0786": 1665, "6623": 1665, "5772j": 1665, "9120j": 1665, "7497j": 1665, "6623j": 1665, "3839j": 1666, "2098": 1666, "6699j": 1666, "3470": 1666, "9451j": 1666, "5174": 1666, "3136j": 1666, "6699": 1666, "9451": 1666, "3136": 1666, "in_dim": 1667, "out_dim": [1667, 1677, 1690], "lift": [1667, 1690, 1714], "contact": 1667, "unsuccessfulli": 1667, "rummag": 1667, "batched_dot": 1667, "hide": 1667, "simpler": [1667, 1676, 1696, 1701, 1703, 1706], "feature_s": 1667, "feature_vec": 1667, "imposs": [1667, 1695], "jacobian_row": 1667, "unbind": [1667, 1677, 1689, 1714, 1731], "get_vjp": 1667, "autobatch": 1667, "vertic": [1668, 1669, 1717, 1732], "atleast_2d": [1669, 1677], "3139": 1670, "3898": 1670, "1657": 1670, "0383": 1670, "8785": 1670, "1089": 1670, "hubconf": 1674, "entrypoint_nam": 1674, "_resnet18": 1674, "smoother": 1674, "underscor": [1674, 1690, 1724, 1733], "load_state_dict_from_url": [1674, 1686], "2gb": 1674, "relative_path_to_checkpoint": 1674, "pth": [1674, 1686, 1711], "__file__": [1674, 1712, 1716], "5c106cde": [1674, 1686], "force_reload": 1674, "skip_valid": 1674, "trust_repo": 1674, "repo_own": 1674, "repo_nam": 1674, "ref": 1674, "torchhub": 1674, "owner": [1674, 1701, 1724, 1725], "github_token": 1674, "repo_or_dir": 1674, "mute": 1674, "resnet50": [1674, 1732], "download_url_to_fil": 1674, "hash_prefix": 1674, "temporary_fil": 1674, "sha256": [1674, 1686], "s3": [1674, 1686, 1712], "amazonaw": [1674, 1686, 1712], "model_dir": [1674, 1686], "check_hash": [1674, 1686], "hub_dir": [1674, 1686], "get_dir": [1674, 1686], "ext": [1674, 1686], "eight": [1674, 1686], "hash": [1674, 1677, 1679, 1686], "succinct": 1674, "set_dir": 1674, "path_to_hub_dir": 1674, "torch_hom": 1674, "xdg_cache_hom": [1674, 1699], "reiniti": 1674, "path_importer_cach": 1674, "subpackag": [1674, 1716], "offend": 1674, "classifi": [1675, 1679, 1713, 1715, 1719, 1732], "pypi": 1675, "hip": 1675, "javadoc": 1675, "amp": [1675, 1695], "hub": [1675, 1686], "mobile_optim": 1675, "model_zoo": 1675, "tensorboard": [1675, 1687, 1718], "__config__": [1675, 1698], "torchdata": 1675, "torchrec": 1675, "torchserv": 1675, "torchtext": 1675, "xla": 1675, "optimiz": 1676, "disadvantag": 1676, "gentl": 1676, "beam": 1676, "traced_bar": 1676, "myscriptmodul": 1676, "103": [1676, 1678], "939": [1676, 1678], "116": [1676, 1678], "779": [1676, 1678], "123": [1676, 1678], "my_script_modul": [1676, 1678], "ins": 1676, "unsupport": [1676, 1680, 1690, 1724], "pytorch_jit": 1676, "traced_fn": 1676, "disable_jit_exampl": 1676, "printer": 1676, "rv": 1676, "rv0": 1676, "rv1": 1676, "ssa": 1676, "prim": [1676, 1713], "listconstruct": 1676, "block0": 1676, "block1": 1676, "loop_in_traced_fn": 1676, "input_tupl": 1676, "fill_row_zero": 1676, "tracerwarn": 1676, "disjoint": 1676, "nr": 1676, "09115803241729736": 1676, "6782537698745728": 1676, "cpu_model": 1676, "gpu_model": 1676, "sample_input_cpu": 1676, "sample_input_gpu": 1676, "traced_cpu": 1676, "traced_gpu": 1676, "use_gpu": 1676, "wit": 1676, "__constants__": [1676, 1678], "my_module_inst": 1676, "redeclar": 1676, "nn_module_inst": 1676, "my_scripted_model": 1676, "pep": [1676, 1678, 1713], "526": [1676, 1678, 1713], "script_method": 1676, "implicitly_compiled_method": 1676, "another_forward": 1676, "unused_method": 1676, "some_fn": 1676, "ever": [1676, 1729], "some_fn2": 1676, "some_fn3": 1676, "some_fn4": 1676, "my_dict": [1676, 1678], "my_int": [1676, 1678], "my_const": 1676, "typing_extens": [1676, 1678], "polyfil": 1676, "make_dict": 1676, "coupl": [1676, 1705, 1725], "nnc": 1676, "nvfuser": 1676, "throughput": [1676, 1698], "__and__": 1677, "__iand__": 1677, "__ilshift__": 1677, "__ior__": 1677, "__irshift__": 1677, "__ixor__": 1677, "__lshift__": 1677, "__or__": 1677, "__rshift__": 1677, "__xor__": 1677, "absolute_": 1677, "acos_": [1677, 1689], "addbmm_": 1677, "addcdiv_": 1677, "addcmul_": 1677, "addmv_": [1677, 1689], "addr_": 1677, "align_a": [1677, 1689, 1690], "align_to": [1677, 1689, 1690], "ellipsis_idx": 1677, "aminmax": [1677, 1714], "arccos_": 1677, "arccosh_": 1677, "arcsin_": [1677, 1727], "arcsinh_": 1677, "arctan2_": 1677, "arctan_": 1677, "arctanh_": 1677, "argwher": 1677, "as_strid": [1677, 1714, 1731], "as_strided_": 1677, "as_strided_scatt": 1677, "asin_": [1677, 1689, 1727], "asinh_": [1677, 1689], "atan_": [1677, 1689], "atanh_": [1677, 1689], "baddbmm_": 1677, "bernoulli_": [1677, 1689, 1735], "bitwise_and_": 1677, "bitwise_left_shift_": 1677, "bitwise_not_": [1677, 1689], "bitwise_or_": 1677, "bitwise_right_shift_": 1677, "bitwise_xor_": 1677, "broadcast_to": 1677, "cauchy_": [1677, 1689, 1735], "ceil_": [1677, 1689], "clamp_max": [1677, 1714], "clamp_max_": 1677, "clamp_min": [1677, 1714], "clamp_min_": 1677, "clip_": 1677, "conj_physical_": 1677, "copysign_": 1677, "cos_": [1677, 1689], "cosh_": [1677, 1689], "count_nonzero": 1677, "cummax": 1677, "cummin": 1677, "cumprod_": 1677, "cumsum_": 1677, "deg2rad": [1677, 1689, 1727], "deg2rad_": [1677, 1689, 1727], "outdim": 1677, "diagonal_scatt": 1677, "digamma_": [1677, 1689], "div_": [1677, 1689, 1727], "divide_": 1677, "dsplit": 1677, "element_s": [1677, 1689, 1729], "eq_": 1677, "erf_": [1677, 1689], "erfc_": [1677, 1689], "erfinv_": [1677, 1689], "exp2": [1677, 1728, 1732], "exp2_": 1677, "exp_": [1677, 1689], "expm1_": [1677, 1689], "exponential_": [1677, 1689, 1735], "fill_diagonal_": 1677, "fix_": 1677, "fliplr": 1677, "flipud": 1677, "float_power_": 1677, "floor_": [1677, 1689], "floor_divide_": [1677, 1727], "fmax": 1677, "fmin": 1677, "fmod_": 1677, "frac_": [1677, 1689], "frexp": 1677, "gcd_": 1677, "ge_": 1677, "geometric_": [1677, 1735], "ger": 1677, "get_devic": [1677, 1689, 1727, 1729, 1730], "greater_": 1677, "greater_equal_": 1677, "gt_": 1677, "hardshrink": [1677, 1714], "heavisid": 1677, "heaviside_": 1677, "hsplit": [1677, 1731], "hypot_": 1677, "i0_": 1677, "igamma_": 1677, "igammac_": 1677, "index_fil": [1677, 1689, 1714], "index_reduc": 1677, "is_coalesc": [1677, 1727], "is_complex": [1677, 1727, 1730], "is_contigu": [1677, 1689, 1731], "is_floating_point": [1677, 1689, 1714, 1727, 1730], "is_infer": 1677, "is_nonzero": [1677, 1727], "is_same_s": [1677, 1727], "is_set_to": 1677, "is_sign": [1677, 1689, 1727], "isclos": 1677, "isfinit": [1677, 1714], "isinf": [1677, 1714, 1727], "isneginf": [1677, 1727], "isposinf": [1677, 1727], "isreal": 1677, "istft": 1677, "kron": 1677, "lcm_": 1677, "ldexp_": 1677, "le_": 1677, "lerp_": 1677, "less_": 1677, "less_equal_": 1677, "lgamma_": 1677, "log10_": [1677, 1689], "log1p_": [1677, 1689, 1727], "log2_": [1677, 1689], "log_normal_": [1677, 1689, 1735], "logaddexp2": 1677, "logcumsumexp": 1677, "logical_and_": 1677, "logical_not_": [1677, 1689], "logical_or_": 1677, "logical_xor_": 1677, "logit_": 1677, "lt_": 1677, "masked_fil": [1677, 1689, 1714], "masked_scatt": [1677, 1714], "masked_select": [1677, 1689, 1714], "matrix_pow": 1677, "moveaxi": 1677, "msort": 1677, "multinomi": [1677, 1714], "multiply_": 1677, "mvlgamma_": 1677, "nan_to_num_": 1677, "nanmedian": [1677, 1689], "nansum": 1677, "narrow_copi": [1677, 1727], "ne_": 1677, "neg_": [1677, 1689, 1727], "negative_": [1677, 1727], "new_empti": [1677, 1714], "new_empty_strid": 1677, "new_ful": [1677, 1699, 1714], "new_on": [1677, 1714], "new_zero": [1677, 1714], "nextafter_": 1677, "normal_": [1677, 1689, 1694, 1699, 1735], "not_equal_": 1677, "output_nr": 1677, "polygamma_": 1677, "pow_": [1677, 1689], "q_per_channel_scal": 1677, "q_per_channel_zero_point": 1677, "q_scale": 1677, "q_zero_point": 1677, "rad2deg": [1677, 1689, 1727], "rad2deg_": [1677, 1689, 1727], "reciprocal_": [1677, 1689], "record_stream": [1677, 1699], "refine_nam": [1677, 1689, 1690], "relu_": [1677, 1721], "remainder_": 1677, "rename_": [1677, 1689, 1690], "renorm_": 1677, "reshape_a": [1677, 1714, 1731], "resize_a": 1677, "the_templ": 1677, "resize_as_sparse_": 1677, "retains_grad": 1677, "roll": [1677, 1714], "rot90": 1677, "round_": [1677, 1689], "rsqrt_": [1677, 1689], "select_scatt": 1677, "sgn_": [1677, 1689], "sigmoid_": [1677, 1689, 1721], "sign_": [1677, 1689], "sin_": [1677, 1689], "sinc_": 1677, "sinh_": [1677, 1689], "slice_scatt": 1677, "smm": [1677, 1727], "sparse_mask": 1677, "sparse_resize_": 1677, "sparse_resize_and_clear_": 1677, "split_with_s": [1677, 1714, 1731], "sqrt_": [1677, 1689], "square_": 1677, "squeeze_": [1677, 1721], "sspaddmm": [1677, 1727], "sub_": [1677, 1689, 1727], "subtract_": 1677, "sum_to_s": 1677, "swapaxes_": 1677, "swapdim": [1677, 1731], "swapdims_": 1677, "take_along_dim": 1677, "tan_": [1677, 1689], "tanh_": [1677, 1689, 1721], "tensor_indices_or_sect": 1677, "to_mkldnn": 1677, "to_padded_tensor": 1677, "to_sparse_bsc": 1677, "to_sparse_bsr": [1677, 1727], "to_sparse_csc": [1677, 1727], "true_divide_": 1677, "trunc_": [1677, 1689], "type_a": [1677, 1689, 1714], "unsafe_chunk": [1677, 1714], "unsafe_split": [1677, 1714], "unsafe_split_with_s": [1677, 1714], "unsqueeze_": [1677, 1721], "view_a": [1677, 1714, 1731], "vsplit": [1677, 1731], "xlogy_": 1677, "adaptive_avg_pool2d": [1677, 1701, 1714, 1721], "adaptive_max_pool1d_with_indic": [1677, 1701], "adaptive_max_pool2d_with_indic": 1677, "adaptive_max_pool3d_with_indic": 1677, "alpha_dropout": [1677, 1714], "assert_int_or_pair": 1677, "arg_nam": 1677, "nonetyp": [1677, 1679], "binary_cross_entropi": 1677, "binary_cross_entropy_with_logit": [1677, 1714], "celu": [1677, 1714], "dropout2d": 1677, "dropout3d": 1677, "feature_alpha_dropout": [1677, 1714], "fractional_max_pool2d_with_indic": 1677, "fractional_max_pool3d_with_indic": 1677, "gaussian_nll_loss": 1677, "glu": [1677, 1714], "gumbel_softmax": 1677, "hardsigmoid": [1677, 1714, 1721], "hardswish": [1677, 1714, 1721], "huber_loss": 1677, "instance_norm": [1677, 1714, 1721], "local_response_norm": 1677, "lp_pool1d": 1677, "lp_pool2d": 1677, "max_pool1d_with_indic": [1677, 1714], "max_pool2d_with_indic": [1677, 1714], "max_pool3d_with_indic": [1677, 1714], "mish": [1677, 1714], "multi_head_attention_forward": 1677, "embed_dim_to_check": 1677, "in_proj_weight": 1677, "in_proj_bia": 1677, "bias_k": 1677, "bias_v": 1677, "dropout_p": 1677, "out_proj_weight": 1677, "out_proj_bia": 1677, "use_separate_proj_weight": 1677, "q_proj_weight": 1677, "k_proj_weight": 1677, "v_proj_weight": 1677, "static_k": 1677, "static_v": 1677, "multilabel_soft_margin_loss": 1677, "relu6": [1677, 1714, 1721], "silu": [1677, 1714], "softsign": 1677, "tanhshrink": 1677, "adaptive_avg_pool1d": [1677, 1701, 1714, 1721], "adaptive_max_pool1d": [1677, 1701, 1714], "affine_grid_gener": 1677, "alias_copi": 1677, "align_tensor": 1677, "alpha_dropout_": [1677, 1714], "as_strided_copi": 1677, "atleast_1d": 1677, "avg_pool1d": [1677, 1714, 1721], "bartlett_window": [1677, 1681], "cudnn_en": 1677, "batch_norm_backward_elemt": 1677, "invstd": 1677, "mean_di": 1677, "mean_dy_xmu": 1677, "batch_norm_backward_reduc": 1677, "input_g": 1677, "bias_g": 1677, "batch_norm_elemt": 1677, "batch_norm_gather_stat": 1677, "batch_norm_gather_stats_with_count": 1677, "batch_norm_stat": 1677, "batch_norm_update_stat": 1677, "binomi": 1677, "blackman_window": [1677, 1681], "block_diag": 1677, "can_cast": 1677, "ccol_indices_copi": 1677, "celu_": 1677, "choose_qparams_optim": 1677, "n_bin": 1677, "bit_width": 1677, "col_indices_copi": 1677, "column_stack": 1677, "constant_pad_nd": [1677, 1714], "conv_tbc": [1677, 1714], "crow_indices_copi": 1677, "cudnn_affine_grid_gener": 1677, "cudnn_batch_norm": 1677, "exponential_average_factor": 1677, "cudnn_convolut": 1677, "cudnn_convolution_add_relu": 1677, "cudnn_convolution_relu": 1677, "cudnn_convolution_transpos": 1677, "cudnn_grid_sampl": 1677, "cudnn_is_accept": 1677, "cumulative_trapezoid": 1677, "detach_copi": 1677, "diagonal_copi": 1677, "dropout_": [1677, 1685, 1714], "einsum": [1677, 1714], "embedding_renorm_": 1677, "empty_lik": [1677, 1681, 1689, 1714, 1727], "empty_quant": 1677, "empty_strid": [1677, 1681], "anyenumtyp": 1677, "expand_copi": 1677, "fake_quantize_per_channel_affin": [1677, 1714], "fbgemm_linear_fp16_weight": 1677, "packed_weight": 1677, "fbgemm_linear_fp16_weight_fp32_activ": 1677, "fbgemm_linear_int8_weight": 1677, "col_offset": 1677, "weight_scal": 1677, "weight_zero_point": 1677, "fbgemm_linear_int8_weight_fp32_activ": 1677, "fbgemm_linear_quantize_weight": 1677, "fbgemm_pack_gemm_matrix_fp16": 1677, "fbgemm_pack_quantized_matrix": 1677, "feature_alpha_dropout_": [1677, 1714], "feature_dropout": [1677, 1714], "feature_dropout_": [1677, 1714], "frobenius_norm": [1677, 1714], "from_fil": [1677, 1729], "fused_moving_avg_obs_fake_qu": 1677, "observer_on": 1677, "fake_quant_on": 1677, "running_min": 1677, "running_max": 1677, "per_row_fake_qu": 1677, "symmetric_qu": 1677, "interpolation_mod": 1677, "has_bias": 1677, "gru_cel": 1677, "w_ih": 1677, "w_hh": 1677, "hamming_window": [1677, 1681], "histogramdd": 1677, "hspmm": [1677, 1727], "indices_copi": 1677, "is_grad_en": 1677, "is_vulkan_avail": 1677, "isin": 1677, "kaiser_window": 1677, "lstm_cell": [1677, 1714], "meshgrid": [1677, 1714], "miopen_batch_norm": 1677, "miopen_convolut": 1677, "miopen_convolution_transpos": 1677, "miopen_depthwise_convolut": 1677, "miopen_rnn": 1677, "weight_stride0": 1677, "dropout_st": 1677, "mkldnn_adaptive_avg_pool2d": 1677, "mkldnn_convolut": 1677, "mkldnn_linear_backward_weight": 1677, "bias_defin": 1677, "mkldnn_max_pool2d": 1677, "mkldnn_max_pool3d": 1677, "native_batch_norm": 1677, "save_mean": 1677, "save_invstd": 1677, "native_channel_shuffl": 1677, "native_dropout": [1677, 1714], "native_group_norm": 1677, "hxw": 1677, "native_layer_norm": [1677, 1714], "native_norm": [1677, 1727], "norm_except_dim": 1677, "nuclear_norm": 1677, "pairwise_dist": [1677, 1714], "permute_copi": 1677, "promote_typ": [1677, 1734], "quantize_per_channel": [1677, 1719], "quantize_per_tensor_dynam": [1677, 1719], "quantized_batch_norm": 1677, "quantized_gru_cel": 1677, "packed_ih": 1677, "packed_hh": 1677, "col_offsets_ih": 1677, "col_offsets_hh": 1677, "scale_ih": 1677, "scale_hh": 1677, "zero_point_ih": 1677, "zero_point_hh": 1677, "quantized_lstm_cel": 1677, "quantized_max_pool1d": 1677, "quantized_max_pool2d": 1677, "quantized_rnn_relu_cel": 1677, "quantized_rnn_tanh_cel": 1677, "rand_lik": [1677, 1681, 1699, 1714, 1735], "randint_lik": [1677, 1681, 1735], "randn_lik": [1677, 1681, 1714, 1735], "randperm": [1677, 1681, 1735], "result_typ": 1677, "scalar1": 1677, "scalar2": 1677, "rnn_relu": [1677, 1714], "rnn_relu_cel": 1677, "rnn_tanh": [1677, 1714], "rnn_tanh_cel": 1677, "row_indices_copi": 1677, "row_stack": 1677, "rrelu_": 1677, "rsub": [1677, 1714], "scalar_tensor": [1677, 1714], "searchsort": 1677, "segment_reduc": 1677, "select_copi": 1677, "selu_": 1677, "slice_copi": 1677, "sparse_bsc_tensor": [1677, 1727], "sparse_bsr_tensor": [1677, 1727], "sparse_compressed_tensor": [1677, 1727], "sparse_csc_tensor": [1677, 1727], "sparse_csr_tensor": [1677, 1727], "split_copi": 1677, "split_with_sizes_copi": 1677, "squeeze_copi": 1677, "std_mean": [1677, 1689, 1714], "t_copi": 1677, "threshold_": 1677, "transpose_copi": 1677, "trapz": 1677, "tril_indic": [1677, 1681], "triu_indic": [1677, 1681], "unbind_copi": 1677, "unfold_copi": 1677, "unsqueeze_copi": 1677, "values_copi": 1677, "vander": [1677, 1681], "var_mean": [1677, 1689, 1714], "view_as_complex_copi": 1677, "view_as_real_copi": 1677, "view_copi": [1677, 1735], "_nn": 1677, "adaptive_max_pool2d": [1677, 1714], "avg_pool2d": [1677, 1714, 1721], "conv_depthwise3d": 1677, "cross_entropy_loss": [1677, 1714], "input_scal": 1677, "elu_": 1677, "flatten_dense_tensor": 1677, "random_sampl": 1677, "gelu_": 1677, "hardsigmoid_": [1677, 1721], "hardswish_": 1677, "hardtanh_": [1677, 1721], "leaky_relu_": 1677, "log_sigmoid": [1677, 1714], "mish_": 1677, "mkldnn_linear": 1677, "mkldnn_reorder_conv2d_weight": 1677, "mkldnn_reorder_conv3d_weight": 1677, "nll_loss2d": [1677, 1714], "nll_loss_nd": [1677, 1714], "reflection_pad3d": [1677, 1714], "relu6_": 1677, "rrelu_with_nois": 1677, "rrelu_with_noise_": 1677, "silu_": 1677, "slow_conv3d": 1677, "slow_conv_dilated2d": 1677, "slow_conv_dilated3d": 1677, "slow_conv_transpose2d": 1677, "slow_conv_transpose3d": 1677, "softshrink": [1677, 1714], "thnn_conv2d": 1677, "unflatten_dense_tensor": 1677, "upsample_bicubic2d": [1677, 1714], "scales_h": 1677, "scales_w": 1677, "upsample_bilinear2d": [1677, 1714], "upsample_linear1d": [1677, 1714], "upsample_nearest1d": [1677, 1714], "upsample_nearest2d": [1677, 1714], "upsample_nearest3d": [1677, 1714], "scales_d": 1677, "upsample_trilinear3d": [1677, 1714], "fft_fftfreq": 1677, "fft_fftshift": 1677, "fft_hfft2": 1677, "fft_hfftn": 1677, "fft_ifftshift": 1677, "fft_ihfft2": 1677, "fft_ihfftn": 1677, "fft_rfftfreq": 1677, "_linalg": 1677, "linalg_cross": [1677, 1714], "linalg_det": [1677, 1714], "linalg_diagon": 1677, "eigvec": 1677, "linalg_ldl_factor": 1677, "linalg_ldl_factor_ex": 1677, "linalg_ldl_solv": 1677, "linalg_lu": 1677, "linalg_lu_factor": 1677, "linalg_lu_factor_ex": 1677, "linalg_lu_solv": 1677, "linalg_matmul": 1677, "linalg_matrix_exp": 1677, "linalg_matrix_pow": 1677, "linalg_multi_dot": 1677, "linalg_norm": [1677, 1714], "linalg_pinv": 1677, "linalg_solve_ex": 1677, "linalg_solve_triangular": 1677, "linalg_vand": 1677, "linalg_vecdot": 1677, "linalg_vector_norm": [1677, 1714], "_spars": 1677, "sparse_sampled_addmm": 1677, "_special": 1677, "special_airy_ai": 1677, "special_bessel_j0": 1677, "special_bessel_j1": 1677, "special_bessel_y0": 1677, "special_bessel_y1": 1677, "special_chebyshev_polynomial_t": 1677, "special_chebyshev_polynomial_u": 1677, "special_chebyshev_polynomial_v": 1677, "special_chebyshev_polynomial_w": 1677, "special_digamma": 1677, "special_entr": 1677, "special_erf": 1677, "special_erfc": 1677, "special_erfcx": 1677, "special_erfinv": 1677, "special_exp2": 1677, "special_expit": 1677, "special_expm1": 1677, "special_gammainc": 1677, "special_gammaincc": 1677, "special_gammaln": 1677, "special_hermite_polynomial_h": 1677, "special_i0": 1677, "special_i1": 1677, "special_laguerre_polynomial_l": 1677, "special_legendre_polynomial_p": 1677, "special_log1p": 1677, "special_log_ndtr": 1677, "special_log_softmax": 1677, "special_logit": 1677, "special_logsumexp": 1677, "special_modified_bessel_i0": 1677, "special_modified_bessel_i1": 1677, "special_modified_bessel_k0": 1677, "special_modified_bessel_k1": 1677, "special_multigammaln": 1677, "special_ndtr": 1677, "special_ndtri": 1677, "special_polygamma": 1677, "special_psi": 1677, "special_round": 1677, "special_scaled_modified_bessel_k0": 1677, "special_scaled_modified_bessel_k1": 1677, "special_shifted_chebyshev_polynomial_t": 1677, "special_shifted_chebyshev_polynomial_u": 1677, "special_shifted_chebyshev_polynomial_v": 1677, "special_shifted_chebyshev_polynomial_w": 1677, "special_sinc": 1677, "special_softmax": 1677, "special_spherical_bessel_j0": 1677, "special_xlog1pi": 1677, "special_xlog": 1677, "special_zeta": 1677, "tval": 1677, "is_accept": 1677, "rect": 1677, "grad_mod": 1677, "liter": [1677, 1680, 1690, 1716], "magic": [1677, 1680], "__complex__": 1677, "__float__": 1677, "__int__": 1677, "hex": [1677, 1679], "__hex__": 1677, "oct": 1677, "__oct__": 1677, "elem": 1677, "divmod": [1677, 1679], "chr": [1677, 1679], "int_float": 1677, "float_int": 1677, "fab": 1677, "int_int": 1677, "float_float": 1677, "complex_complex": 1677, "int_complex": 1677, "complex_int": 1677, "float_complex": 1677, "complex_float": [1677, 1729], "scalar_scalar": 1677, "int_to_int": 1677, "modf": 1677, "mathremaind": 1677, "programm": [1678, 1679], "stand": [1678, 1716, 1726], "tn": 1678, "subtyp": 1678, "an_error": 1678, "noreturn": [1678, 1679], "classvar": [1678, 1679], "anystr": [1678, 1679], "nomin": 1678, "newtyp": [1678, 1679], "tup": [1678, 1679], "emptydatastructur": 1678, "my_list": 1678, "aug_add_x": 1678, "inc": [1678, 1679], "__new__": [1678, 1680], "assign_x": [1678, 1679], "polymorph": 1678, "sum_pair": 1678, "red": [1678, 1679], "green": [1678, 1679], "enum_fn": [1678, 1679], "my_variable_nam": 1678, "top_level_method": 1678, "told": 1678, "other_help": 1678, "ten": [1678, 1716, 1732], "my_paramet": 1678, "my_submodul": 1678, "tuple_or_list": 1678, "a_tupl": 1678, "unrol": [1678, 1679, 1713], "de": [1678, 1716, 1719], "is_script": [1678, 1679], "unsupported_linear_op": 1678, "is_trac": [1678, 1679], "univers": 1678, "a_dict": 1678, "some_dict": 1678, "delimit": [1679, 1680], "tstype": 1679, "tsmoduletyp": 1679, "tsalltyp": 1679, "tsmetatyp": 1679, "tsprimitivetyp": 1679, "tsstructuraltyp": 1679, "tsnominaltyp": 1679, "myclass": [1679, 1716], "printabl": [1679, 1716], "sortabl": 1679, "nevertheless": [1679, 1726], "inc_first_el": 1679, "cpufloattyp": 1679, "tstupl": 1679, "tsnamedtupl": 1679, "tslist": 1679, "tsdict": 1679, "tsoption": 1679, "tsunion": 1679, "tsfutur": 1679, "tsrref": 1679, "keytyp": 1679, "tensortyp": 1679, "mytupl": 1679, "scripted_inc": 1679, "_annotatednamedtupl": 1679, "_namedtupleannot": 1679, "_unannotatednamedtupl": 1679, "mistak": [1679, 1702], "nameerror": 1679, "remedi": 1679, "tsbuiltinclass": 1679, "tscustomclass": 1679, "tsenum": 1679, "tstensor": 1679, "subtensor": [1679, 1701, 1738], "subwithtorchfunct": 1679, "script_g": 1679, "tsclassdef": 1679, "methoddefinit": 1679, "__torch__": [1679, 1713], "class2": 1679, "tsenumdef": 1679, "tsenumtyp": 1679, "memberidentifi": 1679, "intenum": 1679, "intflag": 1679, "basecolor": 1679, "compli": [1679, 1716], "classbodydefinit": 1679, "moduleobj": 1679, "testmodul": 1679, "mymodel": [1679, 1695, 1708], "dosometh": 1679, "strateg": 1679, "congruent": 1679, "unannot": 1679, "python3annot": 1679, "paramannot": 1679, "returnannot": 1679, "funcormethodbodi": 1679, "mypyannot": 1679, "localvarannot": 1679, "setval": 1679, "moduletyp": [1679, 1716], "classidentifi": 1679, "instanceattridentifi": 1679, "offset_": 1679, "tsstructualtyp": 1679, "grammar": 1679, "chapter": [1679, 1703], "floattyp": 1679, "inttyp": 1679, "stringtyp": 1679, "devicetyp": 1679, "bullet": 1679, "tupletyp": 1679, "listtyp": 1679, "enclosur": 1679, "parenth_form": 1679, "list_displai": 1679, "dict_displai": 1679, "legal": 1679, "identif": 1679, "stringliter": 1679, "floatnumb": 1679, "expression_list": 1679, "list_comprehens": 1679, "comp_for": 1679, "target_list": 1679, "or_expr": 1679, "key_datum_list": 1679, "dict_comprehens": 1679, "key_datum": 1679, "comprehens": [1679, 1680, 1690, 1699, 1704, 1719], "ongo": [1679, 1713, 1719, 1724], "enclos": 1679, "datum": [1679, 1737], "attributeref": 1679, "slice_list": 1679, "slice_item": 1679, "proper_slic": 1679, "argument_list": 1679, "desugar": 1679, "u_expr": 1679, "tightli": [1679, 1706], "m_expr": 1679, "a_expr": 1679, "shift_expr": 1679, "and_expr": 1679, "xor_expr": 1679, "comp_oper": 1679, "__lt__": 1679, "__contains__": 1679, "or_test": 1679, "and_test": 1679, "not_test": 1679, "conditional_express": 1679, "starred_item": 1679, "expression_stmt": 1679, "starred_express": 1679, "assignment_express": 1679, "assignment_stmt": 1679, "augmented_assignment_stmt": 1679, "augtarget": 1679, "augop": 1679, "annotated_assignment_stmt": 1679, "raise_stmt": 1679, "assert_stmt": 1679, "return_stmt": 1679, "del_stmt": 1679, "pass_stmt": 1679, "print_stmt": 1679, "break_stmt": 1679, "continue_stmt": 1679, "if_stmt": 1679, "while_stmt": 1679, "for_stmt": 1679, "with_stmt": 1679, "with_item": 1679, "__enter__": 1679, "suppress": [1679, 1723], "tuple_stmt": 1679, "getattr_stmt": 1679, "hasattr_stmt": 1679, "zip_stmt": 1679, "iterable1": 1679, "iterable2": 1679, "enumerate_stmt": 1679, "_log": 1679, "add_stat_valu": 1679, "sugaredvalu": 1679, "unrecogn": 1679, "honor": 1679, "__abs__": 1679, "bytearrai": 1679, "delattr": 1679, "exec": 1679, "__index__": 1679, "frozenset": 1679, "isint": 1679, "issubclass": [1679, 1701], "ndigit": 1679, "setattr": 1679, "__import__": [1679, 1716], "notimpl": [1679, 1680, 1701], "rpc_sync": [1679, 1724, 1725, 1726], "deatil": 1679, "synonym": 1679, "_fork": [1679, 1698], "_wait": [1679, 1698], "lexic": 1680, "indent": 1680, "coroutin": 1680, "__del__": [1680, 1696], "__bytes__": 1680, "__format__": 1680, "__hash__": 1680, "__slots__": 1680, "metaclass": 1680, "mro": 1680, "__r": 1680, "__": 1680, "await": [1680, 1724], "nonloc": 1680, "bytesliter": 1680, "imagnumb": 1680, "parenthes": 1680, "ifs": 1680, "compound": 1680, "exc_typ": 1680, "exc_valu": 1680, "eye_": [1681, 1694], "dirac_": [1681, 1694], "orthogonal_": [1681, 1694, 1706], "adaptivelogsoftmaxwithloss": 1681, "enable_grad": [1681, 1735], "overload_nam": 1683, "handi": [1683, 1696, 1699], "spotti": 1683, "googl": 1683, "colab": [1683, 1716], "ns": [1683, 1720], "dispatch_kei": 1683, "keynam": 1683, "alias_analysi": 1683, "conserv": [1683, 1699], "op_nam": 1683, "opoverload": 1683, "div_cpu": 1683, "mobil": [1685, 1719], "optimize_for_mobil": 1685, "blocklist": [1685, 1716], "mobileoptimizertyp": 1685, "conv_bn_fus": 1685, "correspondingli": 1685, "prepack": 1685, "insert_fold_prepack_op": 1685, "rewrit": [1685, 1696, 1703, 1713], "xnnpack": [1685, 1719], "arm": [1685, 1719], "remove_dropout": 1685, "hoist": 1685, "hoist_conv_packed_param": 1685, "freeze_modul": 1685, "script_modul": 1685, "optimization_blocklist": 1685, "preserved_method": 1685, "vulkan": 1685, "metal": [1685, 1707], "load_url": 1686, "infrequ": 1687, "window_s": 1687, "max_sampl": 1687, "cap": 1687, "_monitor": 1687, "data_value_t": 1687, "eventhandlerhandl": 1687, "register_event_handl": 1687, "unregist": 1687, "unregister_event_handl": 1687, "log_ev": 1687, "tensorboardeventhandl": 1687, "writer": [1687, 1706, 1732], "summarywrit": [1687, 1732], "shared_memori": 1688, "abruptli": 1688, "get_all_sharing_strategi": 1688, "get_sharing_strategi": 1688, "set_sharing_strategi": 1688, "new_strategi": 1688, "di": 1688, "abnorm": [1688, 1708], "fatal": [1688, 1708], "forev": [1688, 1700], "asap": 1688, "queue_2": 1688, "x_clone": 1688, "segfault": 1688, "shm_open": 1688, "mmap": 1688, "prone": [1688, 1708], "destructor": [1688, 1726], "seriou": [1688, 1699], "torch_shm_manag": 1688, "unnot": 1688, "spawncontext": 1688, "has_nam": 1689, "is_shar": [1689, 1729], "is_spars": [1689, 1727, 1729], "is_sparse_csr": [1689, 1729], "is_tensor": [1689, 1727], "unifies_names_from_input_tensor": 1689, "ndimens": 1689, "position": [1689, 1690], "unnam": [1689, 1690], "misalign": 1689, "inher": 1689, "collaps": 1689, "disappear": 1689, "img": [1690, 1732], "renamed_img": 1690, "coexist": 1690, "wildcard": [1690, 1716], "unifi": 1690, "somewher": [1690, 1705], "scale_channel": 1690, "more_img": 1690, "named_tensor": 1690, "named_img": 1690, "flat_img": 1690, "named_flat_img": 1690, "unflattened_img": 1690, "unflattened_named_img": 1690, "grad_loss": 1690, "8107": 1690, "6357": 1690, "0783": 1690, "untest": 1690, "rename_map": 1690, "greedili": 1690, "unment": 1690, "49152": 1690, "datastructur": 1691, "irregular": 1691, "indistinguish": 1691, "2286": 1691, "4842": 1691, "6745": [1691, 1728], "0658": 1691, "1247": 1691, "4078": 1691, "8083": 1691, "2871": 1691, "5559": 1691, "9885": 1691, "4074": 1691, "4855": 1691, "0733": 1691, "8285": 1691, "6858": 1691, "7030": 1691, "3481": 1691, "0236": 1691, "bitwidth": [1692, 1706, 1719], "asymmetr": [1692, 1719, 1722], "gain": 1694, "sacrific": [1694, 1699], "normalis": 1694, "constant_": 1694, "ones_": 1694, "zeros_": 1694, "dirac": 1694, "xavier_uniform_": 1694, "glorot": 1694, "bengio": 1694, "2010": 1694, "fan": 1694, "_in": 1694, "_out": [1694, 1696, 1703], "xavier_normal_": [1694, 1706], "kaiming_uniform_": 1694, "fan_in": 1694, "delv": 1694, "surpass": 1694, "he": 1694, "_mode": 1694, "fan_out": 1694, "trunc_normal_": 1694, "redrawn": 1694, "sax": 1694, "2013": 1694, "sparse_": 1694, "marten": 1694, "walkthrough": 1695, "clip_grad_value_": 1695, "optimizer2": 1695, "batch_per_it": 1695, "iters_to_accumul": 1695, "num_proc": 1695, "grad_param": 1695, "grad_norm": 1695, "scaled_grad_param": 1695, "inv_scal": 1695, "proce": [1695, 1699, 1724], "optimizer0": 1695, "optimizer1": 1695, "output0": 1695, "model0": 1695, "model1": 1695, "loss0": 1695, "loss1": 1695, "hundr": [1695, 1705], "imped": 1695, "poor": [1695, 1696, 1706], "dp_model": 1695, "alter": [1695, 1701], "imported_funct": 1695, "mymm": 1695, "anywher": 1695, "myfloat32func": 1695, "fwd_output": 1695, "cleaner": 1696, "acycl": 1696, "mapsto": 1696, "educ": 1696, "_save": 1696, "_saved_self": 1696, "_saved_result": 1696, "convex": 1696, "concav": 1696, "togglabl": 1696, "intial": 1696, "drawback": 1696, "rfc": [1696, 1725], "0011": 1696, "dirti": 1696, "hogwild": 1696, "train_fn": 1696, "race": 1696, "graphtask": 1696, "copyslic": 1696, "mutex": 1696, "jax": 1696, "gotten": 1696, "curiou": 1696, "\u2102": 1696, "yj": 1696, "holomorph": 1696, "fulfil": [1696, 1716], "theori": 1696, "homomorph": 1696, "mathematician": 1696, "im": 1696, "studi": [1696, 1718], "beauti": 1696, "somewhat": [1696, 1699, 1727], "counterintuit": 1696, "0906": 1696, "4835": 1696, "audio": [1696, 1732], "\u211d": 1696, "z_": [1696, 1728], "z_n": 1696, "_output": 1696, "vj": 1696, "selfdeletingtempfil": 1696, "tmp_dir": 1696, "uuid": 1696, "uuid4": 1696, "temp_fil": 1696, "forbidden": 1696, "savedtensor": 1696, "_raw_saved_": 1696, "_raw_saved_self": 1696, "save_on_disk_threshold": 1696, "tensor_or_sctf": 1696, "_saved_oth": 1696, "4th": 1697, "backcompat": 1697, "broadcast_warn": 1697, "userwarn": 1697, "compute_z": 1698, "w_z": 1698, "w_y": 1698, "openmp": [1698, 1712], "tbb": 1698, "aten_thread": 1698, "omp": 1698, "mkl_thread": 1698, "bla": 1698, "mkldnn_cpu_runtim": 1698, "use_mkldnn": 1698, "use_tbb": 1698, "use_openmp": 1698, "ON": [1698, 1705], "set_num_interop_thread": 1698, "get_num_interop_thread": 1698, "set_num_thread": 1698, "get_num_thread": 1698, "omp_num_thread": 1698, "mkl_num_thread": 1698, "1024": [1698, 1699], "xeon": 1698, "e5": 1698, "oversubscript": 1698, "spread": 1699, "cuda2": [1699, 1704], "a_ful": 1699, "10240": 1699, "b_full": 1699, "ab_ful": 1699, "7277": 1699, "ab_tf32": 1699, "016": 1699, "ga100": 1699, "1747": 1699, "relative_error": 1699, "0022": 1699, "ab_fp32": 1699, "0031": 1699, "000039": 1699, "7x": 1699, "toggl": 1699, "globalcontext": 1699, "setallowtf32cubla": 1699, "setallowtf32cudnn": 1699, "bench_gemm_transform": 1699, "allow_fp16_reduc": 1699, "4048": 1699, "1634": 1699, "4056": 1699, "1670": 1699, "1661": 1699, "4080": 1699, "1664": 1699, "1658": 1699, "1651": 1699, "4104": 1699, "1677": 1699, "1674": 1699, "4128": 1699, "1796": [1699, 1706], "2519": 1699, "5096": 1699, "2144": 1699, "2149": 1699, "2766": 1699, "5120": 1699, "2142": 1699, "9728": 1699, "3875": 1699, "5779": 1699, "16384": 1699, "6182": 1699, "9656": 1699, "setallowfp16reductioncubla": 1699, "invis": 1699, "start_ev": 1699, "elapsed_time_m": 1699, "bypass": 1699, "exploit": 1699, "paragraph": [1699, 1703], "initial_grad": 1699, "memory_alloc": [1699, 1704], "empty_cach": [1699, 1704], "memory_snapshot": [1699, 1704], "memcheck": 1699, "pytorch_no_cuda_memory_cach": [1699, 1704], "pytorch_cuda_alloc_conf": 1699, "option2": 1699, "value2": 1699, "max_split_size_mb": 1699, "borderlin": 1699, "substati": 1699, "unlimit": 1699, "memory_summari": 1699, "resort": [1699, 1703, 1716], "roundup_power2_divis": 1699, "cudacachingalloc": 1699, "ineffici": [1699, 1719], "1280": 1699, "1536": 1699, "1792": 1699, "garbage_collection_threshold": 1699, "reclaim": 1699, "release_cached_block": 1699, "unfavor": 1699, "lru": 1699, "geometri": 1699, "1023": 1699, "zeta": [1699, 1728], "varieti": [1699, 1725], "home": 1699, "use_pytorch_kernel_cach": 1699, "pytorch_kernel_cache_path": 1699, "store_tru": 1699, "disable_cuda": 1699, "train_load": 1699, "new_": [1699, 1733], "x_cpu": 1699, "x_gpu": 1699, "x_cpu_long": 1699, "y_cpu": 1699, "y_gpu": 1699, "y_cpu_long": 1699, "new_tensor": 1699, "overus": 1699, "principl": 1699, "cudagraphlaunch": 1699, "elid": 1699, "suspect": 1699, "versatil": 1699, "static_input": 1699, "static_output": 1699, "realist": 1699, "sophist": [1699, 1715], "violat": 1699, "prohibit": [1699, 1711], "virtual": 1699, "d_in": 1699, "d_out": 1699, "640": 1699, "static_target": 1699, "y_pred": 1699, "static_y_pr": 1699, "static_loss": 1699, "real_input": 1699, "real_target": 1699, "refil": 1699, "autocast": 1699, "dag": 1699, "rejoin": 1699, "cuda_work": 1699, "nsight": 1699, "reorgan": 1699, "graphabl": 1699, "illeg": 1699, "needlessli": 1699, "econom": 1699, "static_out_1": 1699, "g1_workload": 1699, "static_in_1": 1699, "static_out_2": 1699, "g2_workload": 1699, "static_in_2": 1699, "real_data_1": 1699, "real_data_2": 1699, "occasion": [1699, 1727], "29500": [1700, 1717, 1724, 1725], "dive": [1700, 1703, 1716], "prerequisit": 1700, "grad0": 1700, "grad1": 1700, "bucket1": 1700, "bucket0": 1700, "hurt": 1700, "kick": [1700, 1724, 1725], "earliest": 1700, "unreadi": 1700, "absent": 1700, "fire": [1700, 1705], "perspect": [1700, 1709, 1725], "hpp": 1700, "processgroupgloo": 1700, "processgroupmpi": 1700, "_sync_param": 1700, "autograd_hook": 1700, "prepare_for_backward": 1700, "mark_dirti": 1701, "mark_non_differenti": 1701, "set_materialize_grad": 1701, "differenc": 1701, "linearfunct": 1701, "grad_weight": 1701, "grad_bia": 1701, "mulconst": 1701, "input_featur": 1701, "output_featur": 1701, "duck": [1701, 1716], "__array_function__": 1701, "nep": 1701, "0018": 1701, "scalartensor": 1701, "diagonaltensor": 1701, "handled_funct": 1701, "mandat": 1701, "ensure_tensor": 1701, "metadatatensor": 1701, "__add__": 1701, "subtensor2": 1701, "othersubtensor": 1701, "loggingtensor": 1701, "_metadata": 1701, "ndata": 1701, "ret": [1701, 1713, 1724], "ministri": 1701, "silli": 1701, "superclass": 1701, "troublesom": 1701, "face": [1701, 1716, 1732], "_get_overridable_funct": 1701, "overriden": 1701, "get_overridable_funct": [1701, 1738], "func_dict": 1701, "nn_func": 1701, "labori": 1701, "_get_testing_overrid": 1701, "get_testing_overrid": [1701, 1738], "override_dict": 1701, "dummy_add": 1701, "get_ignored_funct": [1701, 1738], "rapidli": 1702, "fortun": 1702, "abridg": 1702, "total_loss": 1702, "extrud": 1702, "phenomenon": 1702, "plenti": 1702, "bptt": 1702, "repackag": 1702, "nm": 1702, "blow": 1702, "rememb": [1702, 1708], "elf": 1702, "grep": 1702, "run_model": 1702, "recoveri": 1702, "claus": 1702, "data_parallel": 1702, "pad_packed_sequ": 1702, "padded_input": 1702, "packed_input": 1702, "packed_output": 1702, "my_lstm": 1702, "dp_m": 1702, "padding_input": 1702, "ur": 1703, "ui": [1703, 1732], "rewritten": 1703, "j_f": 1703, "stori": 1703, "gist": 1703, "calculu": 1703, "cw": 1703, "bigger": 1703, "articl": 1703, "blob": [1703, 1705, 1732], "58eb23378f2a376565a66ac32c93a316c45b6131": 1703, "l99": 1703, "l105": 1703, "ds_dx": 1703, "compute_gradi": 1703, "ds_dy": 1703, "conj_w_d": 1703, "w_d": 1703, "d_idx": 1703, "albeit": 1703, "wonder": 1703, "amd": 1704, "dialect": 1704, "portabl": 1704, "rocmdoc": 1704, "programming_guid": 1704, "hip_api_guid": 1704, "cuda_vers": 1704, "cudaruntimegetvers": 1704, "cudadrivergetvers": 1704, "hip_vers": 1704, "hipruntimegetvers": 1704, "hipdrivergetvers": 1704, "11000": 1704, "use_rocm": 1704, "rocm_vers": 1704, "40300": 1704, "addglobalcallback": 1705, "recordfunct": 1705, "threadlocaldebuginfo": 1705, "debuginfoguard": 1705, "recordfunctioncallback": 1705, "onfunctionent": 1705, "onfunctionexit": 1705, "needsinput": 1705, "samplingprob": 1705, "enablerecordfunct": 1705, "endl": 1705, "broader": [1705, 1735], "inject": 1705, "setapiusagehandl": 1705, "setapiusagelogg": 1705, "event_nam": 1705, "c10_log_api_usage_onc": 1705, "my_api": 1705, "_log_api_usage_onc": 1705, "bundl": 1705, "artifact": [1705, 1716], "akin": 1705, "jpeg": 1705, "camera": [1705, 1732], "setexportmoduleextrafileshook": 1705, "extrafilesmap": 1705, "producer_info": 1705, "getsourc": 1705, "precompil": 1705, "pyc": 1705, "loos": 1705, "elabor": 1706, "tpu": 1706, "mylinear": 1706, "sample_input": 1706, "0413": 1706, "2057": 1706, "0597": 1706, "8247": 1706, "1045": 1706, "4299": 1706, "5457": 1706, "4793": 1706, "3634": 1706, "8525": 1706, "6749": 1706, "l0": [1706, 1711], "deeper": [1706, 1716], "bignet": 1706, "big_net": 1706, "dynamicnet": 1706, "dynamic_net": 1706, "2051": 1706, "7601": 1706, "1963": 1706, "4354": 1706, "6598": 1706, "4446": 1706, "4628": 1706, "8774": 1706, "6848": 1706, "5458": 1706, "4647": 1706, "5310": 1706, "0609": 1706, "0940": 1706, "1266": 1706, "0623": 1706, "0806": 1706, "0550": 1706, "5317": 1706, "5562": 1706, "4028": 1706, "6942": 1706, "0140": 1706, "0329": 1706, "1160": 1706, "0434": 1706, "3889": 1706, "1613": 1706, "6340": 1706, "3887": 1706, "9979": 1706, "0767": 1706, "3526": 1706, "8756": 1706, "5847": 1706, "6016": 1706, "1608": 1706, "0829": 1706, "6338": 1706, "9239": 1706, "6943": 1706, "5034": 1706, "0268": 1706, "4489": 1706, "9403": 1706, "2509": 1706, "5052": 1706, "3088": 1706, "4951": 1706, "3381": 1706, "5166": 1706, "boilerpl": [1706, 1716], "beginn": 1706, "examples_nn": 1706, "polynomial_modul": 1706, "teach": 1706, "0013": [1706, 1728], "0030": 1706, "0008": 1706, "modalmodul": 1706, "6614": 1706, "2669": 1706, "0617": 1706, "4519": 1706, "two_layer_net_optim": 1706, "blitz": 1706, "neural_networks_tutori": 1706, "autograd_tutori": 1706, "new_net": 1706, "runningmean": 1706, "1041": 1706, "0647": 1706, "1515": 1706, "m_load": 1706, "unserialized_th": 1706, "statefulmodul": 1706, "param3": 1706, "param_list": 1706, "parameterlist": 1706, "param_dict": 1706, "parameterdict": 1706, "buffer1": 1706, "buffer2": 1706, "buffer3": 1706, "0322": 1706, "9066": 1706, "1409": 1706, "4852": 1706, "6949": 1706, "2911": 1706, "1044": 1706, "4202": 1706, "1953": 1706, "5299": 1706, "8747": 1706, "6289": 1706, "4898": 1706, "6434": 1706, "5187": 1706, "0346": 1706, "4077": 1706, "4324": 1706, "7022": 1706, "3915": 1706, "6176": 1706, "6062": 1706, "5992": 1706, "4452": 1706, "2843": 1706, "3710": 1706, "3947": 1706, "saving_loading_model": 1706, "what_is_state_dict": 1706, "skip_init": 1706, "skip_param_init": 1706, "analag": 1706, "register_module_forward_pre_hook": 1706, "register_module_forward_hook": 1706, "backward_hook": 1706, "new_grad_input": 1706, "gi": 1706, "5059": 1706, "8158": 1706, "2390": 1706, "0043": 1706, "addmmbackward": 1706, "forward_pre_hook_handl": 1706, "5752": 1706, "7421": 1706, "0838": 1706, "forward_hook_handl": 1706, "0980": 1706, "4666": 1706, "6538": 1706, "0256": 1706, "4497": 1706, "5046": 1706, "combat": 1706, "unaccept": 1706, "benefici": 1706, "shader": 1707, "mps_devic": 1707, "yourfavoritenet": 1707, "a3c": 1708, "set_start_method": 1708, "aforement": 1708, "simplequeu": 1708, "cope": 1708, "eleg": 1708, "num_process": 1708, "modern": 1709, "754": 1709, "diment": 1709, "1e20": 1709, "4142e": 1709, "benign": 1709, "v_dot2": 1709, "mfma": 1709, "fp64": 1709, "rocbla": 1709, "miopen": 1709, "rocblas_internal_fp16_alt_impl": 1709, "miopen_debug_convolution_attrib_fp16_alt_impl": 1709, "_convbackend": 1709, "slownd": 1709, "slownd_transpos": 1709, "slownd_dil": 1709, "slownd_dilated_transpos": 1709, "convbackend": 1709, "miopendepthwis": 1709, "miopentranspos": 1709, "svd_lowrank": [1710, 1727], "22modul": 1710, "20determin": 1710, "index_add_cuda_": 1710, "1509": 1710, "8027": 1710, "0333": 1710, "1444": 1710, "rese": 1710, "seed_work": 1710, "worker_se": 1710, "train_dataset": 1710, "tensor_dict": 1711, "loaded_numb": 1711, "loaded_even": 1711, "scene": [1711, 1732], "loaded_smal": 1711, "num_batches_track": 1711, "bn_state_dict": 1711, "new_bn": 1711, "out0": 1711, "out0_relu": 1711, "1400": 1711, "4563": 1711, "0271": 1711, "4406": 1711, "2827": 1711, "4588": 1711, "2031": 1711, "0300": 1711, "1316": 1711, "6533": 1711, "3413": 1711, "1112": 1711, "m_state_dict": 1711, "new_m": 1711, "recursivescriptmodul": 1711, "original_nam": 1711, "controlflowmodul": 1711, "controlflowmodule_trac": 1711, "3793": 1711, "controlflowmodule_script": 1711, "rem": 1712, "7z": 1712, "curl": 1712, "ossci": 1712, "mkl_2020": 1712, "aoa": 1712, "omkl": 1712, "cuda_prefix": 1712, "cuda102": 1712, "magma_2": 1712, "4_": 1712, "omagma": 1712, "cmake_include_path": 1712, "magma_hom": 1712, "studio": 1712, "cmake_gener": 1712, "create_extens": 1712, "_ext": 1712, "define_macro": 1712, "relative_to": 1712, "c99": 1712, "x86_x64": 1712, "packagesnotfounderror": 1712, "noarch": 1712, "continuum": 1712, "pkg": 1712, "msys2": 1712, "importerror": [1712, 1716], "dll": 1712, "vc2017": 1712, "redistribut": 1712, "vc": 1712, "vs2017_runtim": 1712, "mkl_fft": 1712, "intel_openmp": 1712, "vs2017": 1712, "pai": [1712, 1731], "openbla": 1712, "upstream": 1712, "forg": [1712, 1713], "emerg": 1712, "bootstrap": 1712, "forgotten": 1712, "idiom": 1712, "freeze_support": 1712, "forkingpickl": 1712, "brokenpipeerror": 1712, "errno": 1712, "couldn": [1712, 1713], "torch_14808_1591070686": 1712, "thalloc": 1712, "tdr": 1712, "thcudacheck": 1712, "storageshar": 1712, "dummy_input": 1713, "input_nam": 1713, "actual_input_1": 1713, "learned_": 1713, "output_nam": 1713, "learned_0": 1713, "learned_1": 1713, "learned_2": 1713, "learned_3": 1713, "learned_14": 1713, "learned_15": 1713, "kernel_shap": 1713, "9216": 1713, "transb": 1713, "check_model": 1713, "printable_graph": 1713, "onnxruntim": 1713, "ort": 1713, "ort_sess": 1713, "inferencesess": 1713, "astyp": 1713, "seq_length": 1713, "real_seq_length": 1713, "experienc": 1713, "opset_vers": [1713, 1714], "new_data": 1713, "input_0": 1713, "input_1": 1713, "symbolic_opset": 1713, "symbolic_opset9": 1713, "_variablefunct": 1713, "pyi": 1713, "checkout": 1713, "symboliccontext": 1713, "symbolic_help": 1713, "_scalar": 1713, "_if_scalar_type_a": 1713, "___torch_mangle_0": 1713, "alpha_f": 1713, "myrelu": 1713, "value_t": 1713, "settyp": 1713, "test_aten_embedding_2": 1713, "test_oper": 1713, "myclip": 1713, "symbolic_python_op": 1713, "requiresgrad": 1713, "sym_help": 1713, "_is_valu": 1713, "_unimpl": 1713, "register_custom_op_symbol": 1713, "mylogexp": 1713, "operator_export_typ": 1713, "onnx_fallthrough": 1713, "onnx_aten_fallback": 1713, "symbolic_foo_forward": 1713, "custom_domain": 1713, "attr1_f": 1713, "attr2_i": 1713, "custom_op": 1713, "foo_forward": 1713, "foomodel": 1713, "foomodul": 1713, "example_input1": 1713, "opset": 1713, "custom_opset": 1713, "caffe2": [1713, 1732], "onnx_util": 1713, "torch_script_graph": 1713, "unconvertible_op": 1713, "dynamic_ax": 1713, "export_param": 1713, "trainingmod": 1713, "operatorexporttyp": 1713, "do_constant_fold": 1713, "keep_initializers_as_input": 1713, "export_modules_as_funct": 1713, "OF": 1713, "WITH": 1713, "input_i": 1713, "input_z": 1713, "pb": 1713, "fileno": 1713, "untrain": 1713, "doc_str": 1713, "onnx_aten": 1713, "build_caffe2": 1713, "summodul": 1713, "dim_valu": 1713, "my_custom_axis_nam": 1713, "dim_param": 1713, "sum_dynamic_axes_1": 1713, "predefin": 1713, "checkererror": 1713, "export_to_pretty_str": 1713, "export_typ": 1713, "google_print": 1713, "add_node_nam": 1713, "nodeproto": 1713, "protobuf": 1713, "debugstr": 1713, "symbolic_nam": 1713, "symbolic_fn": 1713, "contrib": 1713, "select_model_mode_for_export": 1713, "is_in_onnx_export": 1713, "middl": 1713, "is_onnx_log_en": 1713, "enable_log": 1713, "disable_log": 1713, "set_log_stream": 1713, "stream_nam": 1713, "newlin": 1713, "build_onnx_supported_aten_op_csv_t": 1714, "__derive_index": 1714, "__interpol": 1714, "__range_length": 1714, "_cast_byt": 1714, "_cast_char": 1714, "_cast_doubl": 1714, "_cast_float": 1714, "_cast_half": 1714, "_cast_int": 1714, "_cast_long": 1714, "_cast_short": 1714, "_dim_arang": 1714, "_log_softmax": 1714, "_pack_padded_sequ": 1714, "_pad_circular": 1714, "_pad_packed_sequ": 1714, "_reshape_from_tensor": 1714, "_sample_dirichlet": 1714, "_set_item": 1714, "_shape_as_tensor": 1714, "_standard_gamma": 1714, "_uniqu": 1714, "_unique2": 1714, "_weight_norm": 1714, "embedding_renorm": 1714, "floordiv": [1714, 1721], "nonzero_numpi": 1714, "numpy_t": 1714, "unique_dim": 1714, "var1": 1715, "var2": 1715, "lbfg": 1715, "reducelronplateau": 1715, "multisteplr": 1715, "upgrad": 1715, "swa_util": 1715, "averagedmodel": 1715, "swalr": 1715, "update_bn": 1715, "optima": 1715, "swa_model": 1715, "update_paramet": 1715, "swa_schedul": 1715, "anneal_epoch": 1715, "swa_lr": 1715, "avg_fn": 1715, "ema_model": 1715, "ema_avg": 1715, "averaged_model_paramet": 1715, "model_paramet": 1715, "num_averag": 1715, "cosineannealinglr": 1715, "swa_start": 1715, "test_input": 1715, "secur": 1716, "unpackag": 1716, "exercis": 1716, "unzip": 1716, "freeli": 1716, "94304870911616": 1716, "94304900784016": 1716, "extern_modul": 1716, "model_1": 1716, "myzip": 1716, "file_byt": 1716, "writestr": 1716, "new_file_byt": 1716, "vim": 1716, "vimrc": 1716, "bufreadcmd": 1716, "brows": 1716, "amatch": 1716, "vi": 1716, "packageimport": 1716, "queryabl": 1716, "glob": 1716, "pe": 1716, "has_fil": 1716, "importer_file_structur": 1716, "package_a": 1716, "get_rdep": 1716, "all_path": 1716, "dependency_graph_str": 1716, "save_text": 1716, "save_binari": 1716, "my_resourc": 1716, "config_stuff": 1716, "raw_data": 1716, "my_byt": 1716, "complementari": [1716, 1728], "load_pickl": 1716, "load_text": 1716, "load_binari": 1716, "my_tensor": 1716, "__reduce_package__": 1716, "__reduce__": 1716, "my_str": 1716, "time_import": 1716, "time_export": 1716, "pickler": 1716, "persistent_id": 1716, "persistent_load": 1716, "generated_module_nam": 1716, "get_unique_id": 1716, "clock_gettim": 1716, "unpackage_foo": 1716, "depickl": 1716, "foo_1": 1716, "foo_2": 1716, "foo_packag": 1716, "foo_collect": 1716, "foo1": 1716, "foo2": 1716, "imported_foo": 1716, "_1": 1716, "9857706": 1716, "650140837": 1716, "652698385": 1716, "__torch_package__": 1716, "is_in_packag": 1716, "userexcept": 1716, "unpackageableexcept": 1716, "loaded_modul": 1716, "my_pacakg": 1716, "import_modul": 1716, "save_source_str": 1716, "save_modul": 1716, "textwrap": 1716, "dedent": 1716, "my_funct": 1716, "is_packag": 1716, "importlib": 1716, "my_pickl": 1716, "get_my_resourc": 1716, "read_text": 1716, "torch_package_import": 1716, "equivali": 1716, "get_my_pickl": 1716, "is_from_packag": 1716, "stdlib": 1716, "my_test": 1716, "f2": [1716, 1717], "sys_import": 1716, "script_model": 1716, "mixed_model": 1716, "python_model_with_scripted_submodul": 1716, "loaded_script": 1716, "loaded_mix": 1716, "convention": 1716, "94286146172688": 1716, "94286146172784": 1716, "consult": 1716, "essai": 1716, "another_packag": 1716, "pickletool": 1716, "ast": 1716, "deni": 1716, "my_export": 1716, "my_interned_modul": 1716, "package_export": 1716, "my_externed_modul": 1716, "my_mocked_modul": 1716, "unwant": [1716, 1732], "hodg": 1716, "podg": 1716, "bazel": 1716, "buck": 1716, "my_class_inst": 1716, "imported_myclass": 1716, "import_myclass": 1716, "okai": 1716, "torch_package_0": 1716, "handle_me_this_wai": 1716, "inadvert": 1716, "pun": 1716, "packagingerror": 1716, "dependency_graph": 1716, "emptymatcherror": 1716, "allow_empti": 1716, "_sysimport": 1716, "hermet": 1716, "scan": 1716, "passs": 1716, "orderedimport": 1716, "add_depend": 1716, "graphviz": 1716, "lang": 1716, "denied_modul": 1716, "my_subpackag": 1716, "digraph": 1716, "externed_modul": 1716, "interned_modul": 1716, "mocked_modul": 1716, "register_extern_hook": 1716, "register_intern_hook": 1716, "register_mock_hook": 1716, "stanard": 1716, "myobject": 1716, "save_source_fil": 1716, "file_or_directori": 1716, "my_subsubpackag": 1716, "file_or_buff": 1716, "module_allow": 1716, "inlud": 1716, "python_vers": 1716, "is_dir": 1716, "gpipe": 1717, "suffer": 1717, "allevi": 1717, "microbatch": 1717, "bubbl": 1717, "except_last": 1717, "deferred_batch_norm": 1717, "torchgpip": 1717, "withdevic": 1717, "micro": 1717, "fc": [1717, 1719], "init_rpc": [1717, 1724, 1725], "output_rref": 1717, "pipelinin": 1717, "local_valu": 1717, "fairli": 1717, "fed": [1717, 1732], "nochunk": 1717, "resnext": 1717, "till": 1717, "skippabl": 1717, "perfectli": 1717, "1to3": 1717, "layer1": 1717, "f1": 1717, "layer2": 1717, "layer3": 1717, "skip_1to3": 1717, "f3": 1717, "alic": 1717, "bob": 1717, "carol": 1717, "stashstashpop": 1717, "f_alic": 1717, "f_bob": 1717, "verify_skipp": 1717, "unmatch": [1717, 1737], "fairscal": 1717, "_kinetoprofil": 1718, "profileract": 1718, "add_metadata": 1718, "add_metadata_json": 1718, "unaggreg": 1718, "export_chrome_trac": 1718, "export_stack": 1718, "self_cuda_time_tot": 1718, "flamegraph": 1718, "brendangregg": 1718, "pl": 1718, "titl": 1718, "countnam": 1718, "perf_viz": 1718, "svg": 1718, "on_trace_readi": 1718, "record_and_sav": 1718, "tensorboard_trace_handl": 1718, "dir_nam": 1718, "logdir": [1718, 1732], "plugin": [1718, 1732], "code_to_profil": 1718, "row_limit": 1718, "trace_handl": 1718, "test_trace_": 1718, "step_num": 1718, "code_iteration_to_profil": 1718, "skip_first": 1718, "worker_nam": [1718, 1724], "use_gzip": 1718, "4x": 1719, "quantizt": 1719, "broadli": 1719, "domin": 1719, "previous_layer_fp32": 1719, "linear_fp32": 1719, "activation_fp32": 1719, "next_layer_fp32": 1719, "linear_weight_fp32": 1719, "linear_int8_w_fp32_inp": 1719, "linear_weight_int8": 1719, "ptdq": 1719, "model_fp32": 1719, "model_int8": 1719, "quantize_dynam": 1719, "input_fp32": 1719, "ptq": [1719, 1720, 1722], "previous_layer_int8": 1719, "linear_with_activation_int8": 1719, "next_layer_int8": 1719, "ptsq": 1719, "assymetr": 1719, "minmax": 1719, "l2norm": 1719, "model_fp32_fus": 1719, "fuse_modul": [1719, 1720], "model_fp32_prepar": 1719, "fake_qu": 1719, "fq": 1719, "prepare_qat": 1719, "training_loop": 1719, "requant": 1719, "linear1": 1719, "custom_qconfig": 1719, "fxptq": 1719, "model_fp": 1719, "usermodel": 1719, "deepcopi": [1719, 1737], "model_to_quant": 1719, "default_dynamic_qconfig": 1719, "model_prepar": 1719, "model_quant": 1719, "convert_fx": [1719, 1737], "model_fus": 1719, "fuse_fx": 1719, "per_channel_scal": 1719, "per_channel_zero_point": 1719, "quantized_tensor": 1719, "qengin": 1719, "dyanmic": 1719, "in4": 1719, "aciv": 1719, "activatio": 1719, "nand": 1719, "tensorrt": 1719, "requri": 1719, "avx2": 1719, "fx2trt": 1719, "float_modul": [1719, 1736], "staticquantcustommodul": 1719, "observed_modul": 1719, "default_qconfig": [1719, 1737], "some_oper": 1719, "e2": 1719, "thnn_conv2d_forward": 1719, "quantizedcpu": 1719, "some_qconfig": 1719, "linearpackedparam": 1719, "_modul": 1719, "prepare_orig": 1719, "quantized_orig": 1719, "scripted_quant": 1719, "errror": 1720, "fp32_op": 1720, "int8_op": 1720, "cooperlak": 1720, "audit": 1720, "op_fp32": 1720, "op_int8": 1720, "_numeric_suit": 1720, "_numeric_suite_fx": 1720, "dtype_config": 1721, "input_dtyp": 1721, "output_dtyp": 1721, "observation_typ": 1721, "observationtyp": 1721, "output_share_observer_with_input": 1721, "0x7f8b81f71d20": 1721, "0x7f8aec5837a0": 1721, "0x7f8aec583830": 1721, "weight_dtyp": 1721, "bias_dtyp": 1721, "num_tensor_args_to_observation_typ": 1721, "output_use_different_observer_as_input": 1721, "0x7f8aec5863b0": 1721, "reverse_sequential_wrapper2": 1721, "0x7f8ae9ce1830": 1721, "fused_modul": 1721, "bnrelu2d": 1721, "0x7f8ae9ce18c0": 1721, "0x7f8ae9ce1950": 1721, "bnrelu3d": 1721, "0x7f8ae9ce19e0": 1721, "reference_quantized_module_for_root": 1721, "_refer": 1721, "qat_modul": 1721, "0x7f8ae9cd8dd0": 1721, "convrelu1d": 1721, "0x7f8ae9cd8e60": 1721, "reverse2": 1721, "0x7f8ae9cd8ef0": 1721, "convbn1d": 1721, "reverse3": 1721, "0x7f8ae9cd8f80": 1721, "convbnrelu1d": 1721, "0x7f8ae9ce1050": 1721, "0x7f8ae9ce1170": 1721, "convrelu2d": 1721, "0x7f8ae9ce1200": 1721, "0x7f8ae9ce1290": 1721, "convbn2d": 1721, "0x7f8ae9ce1320": 1721, "convbnrelu2d": 1721, "0x7f8ae9ce13b0": 1721, "0x7f8ae9ce14d0": 1721, "convrelu3d": 1721, "0x7f8ae9ce1560": 1721, "0x7f8ae9ce15f0": 1721, "convbn3d": 1721, "0x7f8ae9ce1680": 1721, "convbnrelu3d": 1721, "0x7f8ae9ce1710": 1721, "conv_fus": 1721, "0x7f8ae9ce10e0": 1721, "0x7f8ae9ce1440": 1721, "0x7f8ae9ce17a0": 1721, "0x7f8aec5838c0": 1721, "0x7f8aec586680": 1721, "quint4x2": [1721, 1729, 1733, 1734], "embedding_op": 1721, "_input_output_observ": 1721, "is_dynam": 1721, "_overwrite_output_fake_quant": 1721, "fixedqparamsfakequant": 1721, "fixedqparamsobserv": 1721, "00390625": 1721, "_overwrite_output_observ": 1721, "0x7f8aec58c050": 1721, "0x7f8aec58c320": 1721, "0x7f8aec586710": 1721, "0x7f8aec58c830": 1721, "0x7f8aec4977a0": 1721, "0x7f8aec58cd40": 1721, "0x7f8aec5868c0": 1721, "0x7f8b894fea70": 1721, "linearrelu": 1721, "0x7f8ae9cd8680": 1721, "0x7f8ae9cd8d40": 1721, "linearbn1d": 1721, "linear_fus": 1721, "linear_relu": 1721, "0x7f8aec5865f0": 1721, "0078125": 1721, "custom_module_config": 1722, "decrib": 1722, "fork_rng": 1723, "_caller": 1723, "_devices_kw": 1723, "slowli": 1723, "unind": 1723, "get_rng_stat": 1723, "set_rng_stat": 1723, "optimizi": 1724, "shortcom": 1724, "stitch": 1724, "rpc_backend_opt": 1724, "trainer3": 1724, "parameterserver2": 1724, "dash": [1724, 1726], "backendtyp": 1724, "rpcbackendopt": 1724, "rpcagent": 1724, "transmit": 1724, "calle": [1724, 1726], "workerinfo": 1724, "_set_rpc_timeout": 1724, "5678": 1724, "worker0": 1724, "my_script_add": 1724, "wire": 1724, "fut2": 1724, "confirmed_by_own": 1724, "grace": 1724, "pend": [1724, 1732], "userrref": [1724, 1726], "async_execut": 1724, "paus": 1724, "outmost": 1724, "async_add_chain": 1724, "worker2": 1724, "script_add": 1724, "async_add": 1724, "asyncexecutionclass": 1724, "static_async_add": 1724, "class_async_add": 1724, "ret_fut": 1724, "bound_async_add": 1724, "leverag": 1724, "rpc_timeout": 1724, "pipe": 1724, "incid": [1724, 1726], "nvlink": 1724, "multiplex": 1724, "tensorpiperpcbackendopt": 1724, "num_worker_thread": 1724, "device_map": 1724, "_transport": 1724, "tensorpipeag": 1724, "set_device_map": 1724, "idempot": [1724, 1726], "intermitt": 1724, "remote_modul": 1724, "propog": 1724, "forward_async": 1724, "remote_devic": 1724, "workernam": 1724, "trainer0": 1724, "ps0": 1724, "remote_linear_modul": 1724, "get_module_rref": 1724, "remote_paramet": 1724, "conjuct": 1724, "my_add": [1725, 1738], "t4": 1725, "t5": 1725, "autograd_message_id": 1725, "autograd_context_id": 1725, "bracket": 1725, "send1": 1725, "kickoff": 1725, "recv2": 1725, "heard": 1725, "send2": 1725, "recv1": 1725, "dist_autograd_simpl": 1725, "random_tensor": 1725, "_run_process": 1725, "dst_rank": 1725, "dst_name": 1725, "run_process": 1725, "rrefid": 1726, "ownerrref": 1726, "transient": 1726, "udf": 1726, "deliveri": 1726, "delai": 1726, "knowledg": 1726, "danger": 1726, "ancestor": 1726, "trickier": 1726, "wouldn": 1726, "forkid": 1726, "ack": 1726, "solid": 1726, "gc": 1726, "followup": 1726, "relai": 1727, "vast": 1727, "processor": 1727, "spare": 1727, "lil": 1727, "adject": 1727, "000": 1727, "400": 1727, "permit": 1727, "s2": 1727, "plain_dim_s": 1727, "lp64": 1727, "artif": 1727, "280": 1727, "310": 1727, "deduc": 1727, "sp": 1727, "9078": 1727, "conception": 1727, "lobpcg": 1727, "geneig": 1727, "pca_lowrank": 1727, "airy_ai": 1728, "airi": 1728, "onward": 1728, "entr": 1728, "3466": 1728, "int_": 1728, "8427": 1728, "erfcx": 1728, "0561": 1728, "4769": 1728, "9213": 1728, "8858": 1728, "7683": 1728, "7481": 1728, "2920": 1728, "minu": 1728, "int_0": 1728, "weakli": 1728, "gammaln": 1728, "a1": 1728, "a2": 1728, "3528": 1728, "5665": 1728, "6472": 1728, "4335": 1728, "2650": 1728, "2661": 1728, "2796": 1728, "8808": 1728, "3019": 1728, "4658": 1728, "3085": 1728, "2430": 1728, "2070": 1728, "i1": 1728, "5652": 1728, "9534": 1728, "7595": 1728, "2153": 1728, "log_ndtr": 1728, "_ndtr": 1728, "6077": 1728, "7832": 1728, "841": 1728, "6931": 1728, "1728": 1728, "023": 1728, "_softmax": 1728, "9331": 1728, "6486": 1728, "1523": 1728, "6516": 1728, "6352": 1728, "6131": 1728, "7169": 1728, "6261": 1728, "displaystyl": 1728, "6835": 1728, "8474": 1728, "1929": 1728, "7162": 1728, "4180": 1728, "3928": 1728, "4007": 1728, "7586": 1728, "0311": 1728, "3901": 1728, "5049": 1728, "ndtr": 1728, "0228": 1728, "1587": 1728, "8413": 1728, "9772": 1728, "9987": 1728, "ndtri": 1728, "2p": 1728, "64493": 1728, "4041": 1728, "8288": 1728, "4939": 1728, "97": 1728, "4091": 1728, "8863": 1728, "771": 1728, "scaled_modified_bessel_k0": 1728, "scaled_modified_bessel_k1": 1728, "2948": 1728, "0267": 1728, "1566": 1728, "9186": 1728, "8631": 1728, "0259": 1728, "1300": 1728, "spherical_bessel_j0": 1728, "spheric": 1728, "xlog1pi": 1728, "3863": 1728, "1972": 1728, "6094": 1728, "2189": 1728, "8283": 1728, "7726": 1728, "0986": 1728, "1589": 1728, "hurwitz": 1728, "6449": 1728, "0823": 1728, "floatstorag": 1729, "intstorag": 1729, "typedstorag": 1729, "untypedstorag": 1729, "untyp": 1729, "wrap_storag": 1729, "complex_doubl": 1729, "from_buff": 1729, "sizeof": 1729, "nbyte": 1729, "pickle_storage_typ": 1729, "coppi": 1729, "doublestorag": 1729, "halfstorag": 1729, "longstorag": 1729, "shortstorag": 1729, "charstorag": 1729, "bytestorag": 1729, "boolstorag": 1729, "bfloat16storag": 1729, "complexdoublestorag": 1729, "complexfloatstorag": 1729, "quint8storag": 1729, "qint8storag": 1729, "qint32storag": 1729, "quint4x2storag": 1729, "quint2x4storag": 1729, "quint2x4": [1729, 1734], "twelv": 1730, "halftensor": [1730, 1733], "bfloat16tensor": [1730, 1733], "chartensor": [1730, 1733], "shorttensor": [1730, 1733], "binary16": [1730, 1733], "significand": [1730, 1733], "float_tensor": 1730, "double_tensor": 1730, "complex_float_tensor": 1730, "complex_double_tensor": 1730, "int_tensor": 1730, "long_tensor": 1730, "uint_tensor": 1730, "bool_tensor": 1730, "long_zerodim": 1730, "int_zerodim": 1730, "cuda1": 1730, "nhwc": [1730, 1732], "blogpost": 1731, "trainset": 1732, "mnist": 1732, "mnist_train": 1732, "trainload": 1732, "grayscal": 1732, "make_grid": 1732, "add_imag": 1732, "add_graph": 1732, "clutter": 1732, "n_iter": 1732, "purge_step": 1732, "max_queu": 1732, "flush_sec": 1732, "filename_suffix": 1732, "current_datetime_hostnam": 1732, "exp1": 1732, "suffix": [1732, 1733], "global_step": 1732, "purg": 1732, "event_file_writ": 1732, "eventfilewrit": 1732, "may04_22": 1732, "54_": 1732, "macbook": 1732, "my_experi": 1732, "lr_0": 1732, "1_batch_16": 1732, "locallr_0": 1732, "scalar_valu": 1732, "walltim": 1732, "new_styl": 1732, "double_precis": 1732, "blobnam": 1732, "simple_valu": 1732, "2x": 1732, "main_tag": 1732, "tag_scalar_dict": 1732, "run_14h": 1732, "xsinx": 1732, "xcosx": 1732, "tanx": 1732, "add_histogram": 1732, "max_bin": 1732, "fd": 1732, "img_tensor": 1732, "dataformat": 1732, "chw": 1732, "hwc": 1732, "hw": 1732, "wh": 1732, "3xhxw": 1732, "img_hwc": 1732, "my_imag": 1732, "my_image_hwc": 1732, "img_batch": 1732, "my_image_batch": 1732, "add_figur": 1732, "add_video": 1732, "vid_tensor": 1732, "fp": 1732, "moviepi": 1732, "add_audio": 1732, "snd_tensor": 1732, "sample_r": 1732, "44100": 1732, "add_text": 1732, "text_str": 1732, "input_to_model": 1732, "use_strict_trac": 1732, "add_embed": 1732, "label_img": 1732, "metadata_head": 1732, "projector": 1732, "kwlist": 1732, "add_pr_curv": 1732, "num_threshold": 1732, "pr_curv": 1732, "add_custom_scalar": 1732, "chart": 1732, "categorynam": 1732, "chartnam": 1732, "listofproperti": 1732, "multilin": 1732, "taiwan": 1732, "twse": 1732, "0050": 1732, "2330": 1732, "dow": 1732, "aaa": 1732, "bbb": 1732, "ccc": 1732, "nasdaq": 1732, "add_mesh": 1732, "config_dict": 1732, "mesh": 1732, "js": 1732, "threej": 1732, "vertex": 1732, "number_of_vertic": 1732, "vertices_tensor": 1732, "colors_tensor": 1732, "faces_tensor": 1732, "my_mesh": 1732, "add_hparam": 1732, "hparam_dict": 1732, "metric_dict": 1732, "hparam_domain_discret": 1732, "run_nam": 1732, "hparam": 1732, "bsize": 1732, "tini": [1733, 1734, 1739], "_like": 1733, "allow_subclass": 1734, "check_devic": 1734, "check_dtyp": 1734, "check_layout": 1734, "6e": 1734, "3e": 1734, "assert_equ": 1734, "tolranc": 1734, "000000000000001e": 1734, "1e0": 1734, "argh": 1734, "nfooter": 1734, "66": 1734, "footer": 1734, "make_tensor": 1734, "exclude_zero": 1734, "1205": 1734, "2282": 1734, "6380": 1734, "default_gener": 1735, "click": 1735, "inplace_view": 1735, "nondeterministic_bitwis": 1735, "nondeterministic_seed": 1735, "dynamic_output_shap": 1735, "compare_weight": 1736, "float_dict": 1736, "quantized_dict": 1736, "wt_compare_dict": 1736, "qmodel": 1736, "compute_error": 1736, "weight_dict": 1736, "get_logger_dict": 1736, "shadowlogg": 1736, "outputlogg": [1736, 1737], "q_modul": 1736, "logger_cl": [1736, 1737], "prepare_model_with_stub": 1736, "module_swap_list": 1736, "q_model": 1736, "ob_dict": 1736, "compare_model_stub": 1736, "quantizablebasicblock": 1736, "get_matching_activ": 1736, "act_dict": 1736, "prepare_model_output": 1736, "compare_model_output": 1736, "act_compare_dict": 1736, "weight_comparison": 1737, "extract_weight": 1737, "sqnr": 1737, "extend_logger_results_with_comparison": 1737, "compute_sqnr": 1737, "mp_n": 1737, "mq_n": 1737, "add_logg": 1737, "act_comparison": 1737, "extract_logger_info": 1737, "mp_shadows_mq": 1737, "add_shadow_logg": 1737, "shadow_act_comparison": 1737, "extract_shadow_logger_info": 1737, "ref_node_nam": 1737, "prev_node_nam": 1737, "model_nam": 1737, "ref_nam": 1737, "prev_node_target_typ": 1737, "ref_node_target_typ": 1737, "results_typ": 1737, "index_within_arg": 1737, "index_of_arg": 1737, "fqn": 1737, "nstracer": 1737, "skipped_module_nam": 1737, "skipped_module_class": 1737, "model_name_a": 1737, "model_a": 1737, "model_name_b": 1737, "model_b": 1737, "base_name_to_sets_of_related_op": 1737, "unmatchable_types_map": 1737, "op_to_type_to_weight_extraction_fn": 1737, "nsresultstyp": 1737, "name_a": 1737, "name_b": 1737, "should_log_input": 1737, "model_a_with_logg": 1737, "model_b_with_logg": 1737, "model_name_to_use_for_layer_nam": 1737, "node_type_to_io_type_map": 1737, "model_a_shadows_b": 1737, "model_name_1": 1737, "model_name_2": 1737, "comparison_fn": 1737, "comparison_nam": 1737, "compute_normalized_l2_error": 1737, "compute_cosine_similar": 1737, "as_subclass": 1738, "resolve_nam": 1738, "handle_torch_funct": 1738, "public_api": 1738, "relevant_arg": 1738, "has_torch_function_unari": 1738, "has_torch_funct": 1738, "is_tensor_lik": 1738, "agument": 1738, "notatensor": 1738, "tensorlik": 1738, "is_tensor_method_or_properti": 1738, "__get__": 1738, "__module__": 1738, "slot": 1738, "wrap_torch_funct": 1738, "smallest_norm": 1739, "subnorm": 1739, "denormal_numb": 1739}, "objects": {"": [[1735, 0, 0, "-", "torch"], [1676, 6, 1, "-", "PYTORCH_JIT"]], "torch": [[1729, 1, 1, "", "BFloat16Storage"], [1729, 1, 1, "", "BoolStorage"], [1729, 1, 1, "", "ByteStorage"], [1729, 1, 1, "", "CharStorage"], [1729, 1, 1, "", "ComplexDoubleStorage"], [1729, 1, 1, "", "ComplexFloatStorage"], [1729, 1, 1, "", "DoubleStorage"], [1729, 1, 1, "", "FloatStorage"], [43, 1, 1, "", "Generator"], [1729, 1, 1, "", "HalfStorage"], [1729, 1, 1, "", "IntStorage"], [1729, 1, 1, "", "LongStorage"], [1729, 1, 1, "", "QInt32Storage"], [1729, 1, 1, "", "QInt8Storage"], [1729, 1, 1, "", "QUInt2x4Storage"], [1729, 1, 1, "", "QUInt4x2Storage"], [1729, 1, 1, "", "QUInt8Storage"], [1729, 1, 1, "", "ShortStorage"], [1735, 1, 1, "", "Tag"], [1733, 1, 1, "", "Tensor"], [1729, 1, 1, "", "TypedStorage"], [1729, 1, 1, "", "UntypedStorage"], [11, 0, 0, "-", "__config__"], [575, 5, 1, "", "_assert"], [576, 5, 1, "", "abs"], [577, 5, 1, "", "absolute"], [578, 5, 1, "", "acos"], [579, 5, 1, "", "acosh"], [580, 5, 1, "", "add"], [581, 5, 1, "", "addbmm"], [582, 5, 1, "", "addcdiv"], [583, 5, 1, "", "addcmul"], [584, 5, 1, "", "addmm"], [585, 5, 1, "", "addmv"], [586, 5, 1, "", "addr"], [587, 5, 1, "", "adjoint"], [588, 5, 1, "", "all"], [589, 5, 1, "", "allclose"], [590, 5, 1, "", "amax"], [591, 5, 1, "", "amin"], [592, 5, 1, "", "aminmax"], [0, 0, 0, "-", "amp"], [593, 5, 1, "", "angle"], [594, 5, 1, "", "any"], [1719, 0, 0, "-", "ao"], [595, 5, 1, "", "arange"], [596, 5, 1, "", "arccos"], [597, 5, 1, "", "arccosh"], [598, 5, 1, "", "arcsin"], [599, 5, 1, "", "arcsinh"], [600, 5, 1, "", "arctan"], [601, 5, 1, "", "arctan2"], [602, 5, 1, "", "arctanh"], [603, 5, 1, "", "are_deterministic_algorithms_enabled"], [604, 5, 1, "", "argmax"], [605, 5, 1, "", "argmin"], [606, 5, 1, "", "argsort"], [607, 5, 1, "", "argwhere"], [608, 5, 1, "", "as_strided"], [609, 5, 1, "", "as_tensor"], [610, 5, 1, "", "asarray"], [611, 5, 1, "", "asin"], [612, 5, 1, "", "asinh"], [613, 5, 1, "", "atan"], [614, 5, 1, "", "atan2"], [615, 5, 1, "", "atanh"], [616, 5, 1, "", "atleast_1d"], [617, 5, 1, "", "atleast_2d"], [618, 5, 1, "", "atleast_3d"], [0, 1, 1, "", "autocast"], [1, 0, 0, "-", "autograd"], [2, 0, 0, "-", "backends"], [644, 5, 1, "", "baddbmm"], [645, 5, 1, "", "bartlett_window"], [646, 5, 1, "", "bernoulli"], [647, 5, 1, "", "bincount"], [648, 5, 1, "", "bitwise_and"], [649, 5, 1, "", "bitwise_left_shift"], [650, 5, 1, "", "bitwise_not"], [651, 5, 1, "", "bitwise_or"], [652, 5, 1, "", "bitwise_right_shift"], [653, 5, 1, "", "bitwise_xor"], [654, 5, 1, "", "blackman_window"], [655, 5, 1, "", "block_diag"], [656, 5, 1, "", "bmm"], [657, 5, 1, "", "broadcast_shapes"], [658, 5, 1, "", "broadcast_tensors"], [659, 5, 1, "", "broadcast_to"], [660, 5, 1, "", "bucketize"], [661, 5, 1, "", "can_cast"], [662, 5, 1, "", "cartesian_prod"], [663, 5, 1, "", "cat"], [664, 5, 1, "", "cdist"], [665, 5, 1, "", "ceil"], [666, 5, 1, "", "chain_matmul"], [667, 5, 1, "", "cholesky"], [668, 5, 1, "", "cholesky_inverse"], [669, 5, 1, "", "cholesky_solve"], [670, 5, 1, "", "chunk"], [671, 5, 1, "", "clamp"], [672, 5, 1, "", "clip"], [673, 5, 1, "", "clone"], [674, 5, 1, "", "column_stack"], [675, 5, 1, "", "combinations"], [676, 5, 1, "", "compiled_with_cxx11_abi"], [677, 5, 1, "", "complex"], [678, 5, 1, "", "concat"], [679, 5, 1, "", "conj"], [680, 5, 1, "", "conj_physical"], [1735, 0, 0, "-", "contrib"], [681, 5, 1, "", "copysign"], [682, 5, 1, "", "corrcoef"], [683, 5, 1, "", "cos"], [684, 5, 1, "", "cosh"], [685, 5, 1, "", "count_nonzero"], [686, 5, 1, "", "cov"], [0, 0, 0, "-", "cpu"], [687, 5, 1, "", "cross"], [14, 0, 0, "-", "cuda"], [759, 5, 1, "", "cummax"], [760, 5, 1, "", "cummin"], [761, 5, 1, "", "cumprod"], [762, 5, 1, "", "cumsum"], [763, 5, 1, "", "cumulative_trapezoid"], [764, 5, 1, "", "deg2rad"], [765, 5, 1, "", "dequantize"], [766, 5, 1, "", "det"], [1730, 1, 1, "", "device"], [767, 5, 1, "", "diag"], [768, 5, 1, "", "diag_embed"], [769, 5, 1, "", "diagflat"], [770, 5, 1, "", "diagonal"], [771, 5, 1, "", "diagonal_scatter"], [772, 5, 1, "", "diff"], [773, 5, 1, "", "digamma"], [774, 5, 1, "", "dist"], [20, 0, 0, "-", "distributed"], [24, 0, 0, "-", "distributions"], [775, 5, 1, "", "div"], [776, 5, 1, "", "divide"], [777, 5, 1, "", "dot"], [778, 5, 1, "", "dsplit"], [779, 5, 1, "", "dstack"], [1730, 1, 1, "", "dtype"], [780, 5, 1, "", "eig"], [781, 5, 1, "", "einsum"], [782, 5, 1, "", "empty"], [783, 5, 1, "", "empty_like"], [784, 5, 1, "", "empty_strided"], [785, 1, 1, "", "enable_grad"], [786, 5, 1, "", "eq"], [787, 5, 1, "", "equal"], [788, 5, 1, "", "erf"], [789, 5, 1, "", "erfc"], [790, 5, 1, "", "erfinv"], [791, 5, 1, "", "exp"], [792, 5, 1, "", "exp2"], [793, 5, 1, "", "expm1"], [794, 5, 1, "", "eye"], [795, 5, 1, "", "fake_quantize_per_channel_affine"], [796, 5, 1, "", "fake_quantize_per_tensor_affine"], [39, 0, 0, "-", "fft"], [819, 5, 1, "", "fix"], [820, 5, 1, "", "flatten"], [821, 5, 1, "", "flip"], [822, 5, 1, "", "fliplr"], [823, 5, 1, "", "flipud"], [824, 5, 1, "", "float_power"], [825, 5, 1, "", "floor"], [826, 5, 1, "", "floor_divide"], [827, 5, 1, "", "fmax"], [828, 5, 1, "", "fmin"], [829, 5, 1, "", "fmod"], [830, 5, 1, "", "frac"], [831, 5, 1, "", "frexp"], [832, 5, 1, "", "from_dlpack"], [833, 5, 1, "", "from_numpy"], [834, 5, 1, "", "frombuffer"], [835, 5, 1, "", "full"], [836, 5, 1, "", "full_like"], [41, 0, 0, "-", "futures"], [42, 0, 0, "-", "fx"], [837, 5, 1, "", "gather"], [838, 5, 1, "", "gcd"], [839, 5, 1, "", "ge"], [840, 5, 1, "", "geqrf"], [841, 5, 1, "", "ger"], [842, 5, 1, "", "get_default_dtype"], [843, 5, 1, "", "get_deterministic_debug_mode"], [844, 5, 1, "", "get_float32_matmul_precision"], [845, 5, 1, "", "get_num_interop_threads"], [846, 5, 1, "", "get_num_threads"], [847, 5, 1, "", "get_rng_state"], [848, 5, 1, "", "gradient"], [849, 5, 1, "", "greater"], [850, 5, 1, "", "greater_equal"], [851, 5, 1, "", "gt"], [852, 5, 1, "", "hamming_window"], [853, 5, 1, "", "hann_window"], [854, 5, 1, "", "heaviside"], [855, 5, 1, "", "histc"], [856, 5, 1, "", "histogram"], [857, 5, 1, "", "histogramdd"], [858, 5, 1, "", "hsplit"], [859, 5, 1, "", "hspmm"], [860, 5, 1, "", "hstack"], [1674, 0, 0, "-", "hub"], [861, 5, 1, "", "hypot"], [862, 5, 1, "", "i0"], [863, 5, 1, "", "igamma"], [864, 5, 1, "", "igammac"], [865, 5, 1, "", "imag"], [866, 5, 1, "", "index_add"], [867, 5, 1, "", "index_copy"], [868, 5, 1, "", "index_reduce"], [869, 5, 1, "", "index_select"], [870, 1, 1, "", "inference_mode"], [871, 5, 1, "", "initial_seed"], [872, 5, 1, "", "inner"], [873, 5, 1, "", "inverse"], [874, 5, 1, "", "is_complex"], [875, 5, 1, "", "is_conj"], [876, 5, 1, "", "is_deterministic_algorithms_warn_only_enabled"], [877, 5, 1, "", "is_floating_point"], [878, 5, 1, "", "is_grad_enabled"], [879, 5, 1, "", "is_inference_mode_enabled"], [880, 5, 1, "", "is_nonzero"], [881, 5, 1, "", "is_storage"], [882, 5, 1, "", "is_tensor"], [883, 5, 1, "", "is_warn_always_enabled"], [884, 5, 1, "", "isclose"], [885, 5, 1, "", "isfinite"], [886, 5, 1, "", "isin"], [887, 5, 1, "", "isinf"], [888, 5, 1, "", "isnan"], [889, 5, 1, "", "isneginf"], [890, 5, 1, "", "isposinf"], [891, 5, 1, "", "isreal"], [892, 5, 1, "", "istft"], [1676, 0, 0, "-", "jit"], [914, 5, 1, "", "kaiser_window"], [915, 5, 1, "", "kron"], [916, 5, 1, "", "kthvalue"], [1730, 1, 1, "", "layout"], [917, 5, 1, "", "lcm"], [918, 5, 1, "", "ldexp"], [919, 5, 1, "", "le"], [920, 5, 1, "", "lerp"], [921, 5, 1, "", "less"], [922, 5, 1, "", "less_equal"], [923, 5, 1, "", "lgamma"], [1684, 0, 0, "-", "linalg"], [965, 5, 1, "", "linspace"], [966, 5, 1, "", "load"], [967, 5, 1, "", "lobpcg"], [968, 5, 1, "", "log"], [969, 5, 1, "", "log10"], [970, 5, 1, "", "log1p"], [971, 5, 1, "", "log2"], [972, 5, 1, "", "logaddexp"], [973, 5, 1, "", "logaddexp2"], [974, 5, 1, "", "logcumsumexp"], [975, 5, 1, "", "logdet"], [976, 5, 1, "", "logical_and"], [977, 5, 1, "", "logical_not"], [978, 5, 1, "", "logical_or"], [979, 5, 1, "", "logical_xor"], [980, 5, 1, "", "logit"], [981, 5, 1, "", "logspace"], [982, 5, 1, "", "logsumexp"], [983, 5, 1, "", "lstsq"], [984, 5, 1, "", "lt"], [985, 5, 1, "", "lu"], [986, 5, 1, "", "lu_solve"], [987, 5, 1, "", "lu_unpack"], [988, 5, 1, "", "manual_seed"], [989, 5, 1, "", "masked_select"], [990, 5, 1, "", "matmul"], [991, 5, 1, "", "matrix_exp"], [992, 5, 1, "", "matrix_power"], [993, 5, 1, "", "matrix_rank"], [994, 5, 1, "", "max"], [995, 5, 1, "", "maximum"], [996, 5, 1, "", "mean"], [997, 5, 1, "", "median"], [1730, 1, 1, "", "memory_format"], [998, 5, 1, "", "meshgrid"], [999, 5, 1, "", "min"], [1000, 5, 1, "", "minimum"], [1001, 5, 1, "", "mm"], [1002, 5, 1, "", "mode"], [1687, 0, 0, "-", "monitor"], [1003, 5, 1, "", "moveaxis"], [1004, 5, 1, "", "movedim"], [1005, 5, 1, "", "msort"], [1006, 5, 1, "", "mul"], [1007, 5, 1, "", "multinomial"], [1008, 5, 1, "", "multiply"], [1688, 0, 0, "-", "multiprocessing"], [1009, 5, 1, "", "mv"], [1010, 5, 1, "", "mvlgamma"], [1011, 5, 1, "", "nan_to_num"], [1012, 5, 1, "", "nanmean"], [1013, 5, 1, "", "nanmedian"], [1014, 5, 1, "", "nanquantile"], [1015, 5, 1, "", "nansum"], [1016, 5, 1, "", "narrow"], [1017, 5, 1, "", "ne"], [1018, 5, 1, "", "neg"], [1019, 5, 1, "", "negative"], [1691, 0, 0, "-", "nested"], [1020, 5, 1, "", "nextafter"], [1692, 0, 0, "-", "nn"], [1420, 1, 1, "", "no_grad"], [1421, 5, 1, "", "nonzero"], [1422, 5, 1, "", "norm"], [1423, 5, 1, "", "normal"], [1424, 5, 1, "", "not_equal"], [1425, 5, 1, "", "numel"], [1426, 5, 1, "", "ones"], [1427, 5, 1, "", "ones_like"], [1713, 0, 0, "-", "onnx"], [1715, 0, 0, "-", "optim"], [1462, 5, 1, "", "orgqr"], [1463, 5, 1, "", "ormqr"], [1464, 5, 1, "", "outer"], [1716, 0, 0, "-", "package"], [1465, 5, 1, "", "pca_lowrank"], [1466, 5, 1, "", "permute"], [1467, 5, 1, "", "pinverse"], [1468, 5, 1, "", "poisson"], [1469, 5, 1, "", "polar"], [1470, 5, 1, "", "polygamma"], [1471, 5, 1, "", "positive"], [1472, 5, 1, "", "pow"], [1473, 5, 1, "", "prod"], [1718, 0, 0, "-", "profiler"], [1474, 5, 1, "", "promote_types"], [1475, 5, 1, "", "qr"], [1476, 5, 1, "", "quantile"], [1719, 0, 0, "-", "quantization"], [1544, 5, 1, "", "quantize_per_channel"], [1545, 5, 1, "", "quantize_per_tensor"], [1546, 5, 1, "", "quantized_batch_norm"], [1547, 5, 1, "", "quantized_max_pool1d"], [1548, 5, 1, "", "quantized_max_pool2d"], [1550, 5, 1, "", "rad2deg"], [1551, 5, 1, "", "rand"], [1552, 5, 1, "", "rand_like"], [1553, 5, 1, "", "randint"], [1554, 5, 1, "", "randint_like"], [1555, 5, 1, "", "randn"], [1556, 5, 1, "", "randn_like"], [1723, 0, 0, "-", "random"], [1557, 5, 1, "", "randperm"], [1558, 5, 1, "", "range"], [1559, 5, 1, "", "ravel"], [1560, 5, 1, "", "real"], [1561, 5, 1, "", "reciprocal"], [1562, 5, 1, "", "remainder"], [1563, 5, 1, "", "renorm"], [1564, 5, 1, "", "repeat_interleave"], [1565, 5, 1, "", "reshape"], [1566, 5, 1, "", "resolve_conj"], [1567, 5, 1, "", "resolve_neg"], [1568, 5, 1, "", "result_type"], [1569, 5, 1, "", "roll"], [1570, 5, 1, "", "rot90"], [1571, 5, 1, "", "round"], [1572, 5, 1, "", "row_stack"], [1573, 5, 1, "", "rsqrt"], [1574, 5, 1, "", "save"], [1575, 5, 1, "", "scatter"], [1576, 5, 1, "", "scatter_add"], [1577, 5, 1, "", "scatter_reduce"], [1578, 5, 1, "", "searchsorted"], [1579, 5, 1, "", "seed"], [1580, 5, 1, "", "select"], [1581, 5, 1, "", "select_scatter"], [1582, 5, 1, "", "set_default_dtype"], [1583, 5, 1, "", "set_default_tensor_type"], [1584, 5, 1, "", "set_deterministic_debug_mode"], [1585, 5, 1, "", "set_float32_matmul_precision"], [1586, 5, 1, "", "set_flush_denormal"], [1587, 1, 1, "", "set_grad_enabled"], [1588, 5, 1, "", "set_num_interop_threads"], [1589, 5, 1, "", "set_num_threads"], [1590, 5, 1, "", "set_printoptions"], [1591, 5, 1, "", "set_rng_state"], [1592, 5, 1, "", "set_warn_always"], [1593, 5, 1, "", "sgn"], [1594, 5, 1, "", "sigmoid"], [1595, 5, 1, "", "sign"], [1596, 5, 1, "", "signbit"], [1597, 5, 1, "", "sin"], [1598, 5, 1, "", "sinc"], [1599, 5, 1, "", "sinh"], [1600, 5, 1, "", "slice_scatter"], [1601, 5, 1, "", "slogdet"], [1602, 5, 1, "", "smm"], [1603, 5, 1, "", "sort"], [1727, 0, 0, "-", "sparse"], [1611, 5, 1, "", "sparse_bsc_tensor"], [1612, 5, 1, "", "sparse_bsr_tensor"], [1613, 5, 1, "", "sparse_compressed_tensor"], [1614, 5, 1, "", "sparse_coo_tensor"], [1615, 5, 1, "", "sparse_csc_tensor"], [1616, 5, 1, "", "sparse_csr_tensor"], [1728, 0, 0, "-", "special"], [1617, 5, 1, "", "split"], [1618, 5, 1, "", "sqrt"], [1619, 5, 1, "", "square"], [1620, 5, 1, "", "squeeze"], [1621, 5, 1, "", "sspaddmm"], [1622, 5, 1, "", "stack"], [1623, 5, 1, "", "std"], [1624, 5, 1, "", "std_mean"], [1625, 5, 1, "", "stft"], [1626, 5, 1, "", "sub"], [1627, 5, 1, "", "subtract"], [1628, 5, 1, "", "sum"], [1629, 5, 1, "", "svd"], [1630, 5, 1, "", "svd_lowrank"], [1631, 5, 1, "", "swapaxes"], [1632, 5, 1, "", "swapdims"], [1633, 5, 1, "", "symeig"], [1634, 5, 1, "", "t"], [1635, 5, 1, "", "take"], [1636, 5, 1, "", "take_along_dim"], [1637, 5, 1, "", "tan"], [1638, 5, 1, "", "tanh"], [1639, 5, 1, "", "tensor"], [1640, 5, 1, "", "tensor_split"], [1641, 5, 1, "", "tensordot"], [1734, 0, 0, "-", "testing"], [1642, 5, 1, "", "tile"], [1643, 5, 1, "", "topk"], [1644, 5, 1, "", "trace"], [1645, 5, 1, "", "transpose"], [1646, 5, 1, "", "trapezoid"], [1647, 5, 1, "", "trapz"], [1648, 5, 1, "", "triangular_solve"], [1649, 5, 1, "", "tril"], [1650, 5, 1, "", "tril_indices"], [1651, 5, 1, "", "triu"], [1652, 5, 1, "", "triu_indices"], [1653, 5, 1, "", "true_divide"], [1654, 5, 1, "", "trunc"], [1655, 5, 1, "", "unbind"], [1656, 5, 1, "", "unflatten"], [1657, 5, 1, "", "unique"], [1658, 5, 1, "", "unique_consecutive"], [1659, 5, 1, "", "unsqueeze"], [1660, 5, 1, "", "use_deterministic_algorithms"], [1735, 0, 0, "-", "utils"], [1661, 5, 1, "", "vander"], [1662, 5, 1, "", "var"], [1663, 5, 1, "", "var_mean"], [1664, 5, 1, "", "vdot"], [1665, 5, 1, "", "view_as_complex"], [1666, 5, 1, "", "view_as_real"], [1667, 5, 1, "", "vmap"], [1668, 5, 1, "", "vsplit"], [1669, 5, 1, "", "vstack"], [1670, 5, 1, "", "where"], [1671, 5, 1, "", "xlogy"], [1672, 5, 1, "", "zeros"], [1673, 5, 1, "", "zeros_like"]], "torch.BFloat16Storage": [[1729, 2, 1, "", "dtype"]], "torch.BoolStorage": [[1729, 2, 1, "", "dtype"]], "torch.ByteStorage": [[1729, 2, 1, "", "dtype"]], "torch.CharStorage": [[1729, 2, 1, "", "dtype"]], "torch.ComplexDoubleStorage": [[1729, 2, 1, "", "dtype"]], "torch.ComplexFloatStorage": [[1729, 2, 1, "", "dtype"]], "torch.DoubleStorage": [[1729, 2, 1, "", "dtype"]], "torch.FloatStorage": [[1729, 2, 1, "", "dtype"]], "torch.Generator": [[43, 2, 1, "", "device"], [43, 3, 1, "", "get_state"], [43, 3, 1, "", "initial_seed"], [43, 3, 1, "", "manual_seed"], [43, 3, 1, "", "seed"], [43, 3, 1, "", "set_state"]], "torch.HalfStorage": [[1729, 2, 1, "", "dtype"]], "torch.IntStorage": [[1729, 2, 1, "", "dtype"]], "torch.LongStorage": [[1729, 2, 1, "", "dtype"]], "torch.QInt32Storage": [[1729, 2, 1, "", "dtype"]], "torch.QInt8Storage": [[1729, 2, 1, "", "dtype"]], "torch.QUInt2x4Storage": [[1729, 2, 1, "", "dtype"]], "torch.QUInt4x2Storage": [[1729, 2, 1, "", "dtype"]], "torch.QUInt8Storage": [[1729, 2, 1, "", "dtype"]], "torch.ShortStorage": [[1729, 2, 1, "", "dtype"]], "torch.Tag": [[1735, 4, 1, "", "name"]], "torch.Tensor": [[1733, 2, 1, "", "H"], [1733, 2, 1, "", "T"], [44, 3, 1, "", "abs"], [45, 3, 1, "", "abs_"], [46, 3, 1, "", "absolute"], [47, 3, 1, "", "absolute_"], [48, 3, 1, "", "acos"], [49, 3, 1, "", "acos_"], [50, 3, 1, "", "acosh"], [51, 3, 1, "", "acosh_"], [52, 3, 1, "", "add"], [53, 3, 1, "", "add_"], [54, 3, 1, "", "addbmm"], [55, 3, 1, "", "addbmm_"], [56, 3, 1, "", "addcdiv"], [57, 3, 1, "", "addcdiv_"], [58, 3, 1, "", "addcmul"], [59, 3, 1, "", "addcmul_"], [60, 3, 1, "", "addmm"], [61, 3, 1, "", "addmm_"], [62, 3, 1, "", "addmv"], [63, 3, 1, "", "addmv_"], [64, 3, 1, "", "addr"], [65, 3, 1, "", "addr_"], [66, 3, 1, "", "adjoint"], [1690, 3, 1, "", "align_as"], [1690, 3, 1, "", "align_to"], [67, 3, 1, "", "all"], [68, 3, 1, "", "allclose"], [69, 3, 1, "", "amax"], [70, 3, 1, "", "amin"], [71, 3, 1, "", "aminmax"], [72, 3, 1, "", "angle"], [73, 3, 1, "", "any"], [74, 3, 1, "", "apply_"], [75, 3, 1, "", "arccos"], [76, 3, 1, "", "arccos_"], [77, 3, 1, "", "arccosh"], [78, 3, 1, "", "arccosh_"], [79, 3, 1, "", "arcsin"], [80, 3, 1, "", "arcsin_"], [81, 3, 1, "", "arcsinh"], [82, 3, 1, "", "arcsinh_"], [83, 3, 1, "", "arctan"], [84, 3, 1, "", "arctan2"], [85, 3, 1, "", "arctan2_"], [86, 3, 1, "", "arctan_"], [87, 3, 1, "", "arctanh"], [88, 3, 1, "", "arctanh_"], [89, 3, 1, "", "argmax"], [90, 3, 1, "", "argmin"], [91, 3, 1, "", "argsort"], [92, 3, 1, "", "argwhere"], [93, 3, 1, "", "as_strided"], [94, 3, 1, "", "as_subclass"], [95, 3, 1, "", "asin"], [96, 3, 1, "", "asin_"], [97, 3, 1, "", "asinh"], [98, 3, 1, "", "asinh_"], [99, 3, 1, "", "atan"], [100, 3, 1, "", "atan2"], [101, 3, 1, "", "atan2_"], [102, 3, 1, "", "atan_"], [103, 3, 1, "", "atanh"], [104, 3, 1, "", "atanh_"], [105, 3, 1, "", "backward"], [106, 3, 1, "", "baddbmm"], [107, 3, 1, "", "baddbmm_"], [108, 3, 1, "", "bernoulli"], [109, 3, 1, "", "bernoulli_"], [110, 3, 1, "", "bfloat16"], [111, 3, 1, "", "bincount"], [112, 3, 1, "", "bitwise_and"], [113, 3, 1, "", "bitwise_and_"], [114, 3, 1, "", "bitwise_left_shift"], [115, 3, 1, "", "bitwise_left_shift_"], [116, 3, 1, "", "bitwise_not"], [117, 3, 1, "", "bitwise_not_"], [118, 3, 1, "", "bitwise_or"], [119, 3, 1, "", "bitwise_or_"], [120, 3, 1, "", "bitwise_right_shift"], [121, 3, 1, "", "bitwise_right_shift_"], [122, 3, 1, "", "bitwise_xor"], [123, 3, 1, "", "bitwise_xor_"], [124, 3, 1, "", "bmm"], [125, 3, 1, "", "bool"], [126, 3, 1, "", "broadcast_to"], [127, 3, 1, "", "byte"], [128, 3, 1, "", "cauchy_"], [129, 3, 1, "", "ccol_indices"], [130, 3, 1, "", "cdouble"], [131, 3, 1, "", "ceil"], [132, 3, 1, "", "ceil_"], [133, 3, 1, "", "cfloat"], [134, 3, 1, "", "chalf"], [135, 3, 1, "", "char"], [136, 3, 1, "", "cholesky"], [137, 3, 1, "", "cholesky_inverse"], [138, 3, 1, "", "cholesky_solve"], [139, 3, 1, "", "chunk"], [140, 3, 1, "", "clamp"], [141, 3, 1, "", "clamp_"], [142, 3, 1, "", "clip"], [143, 3, 1, "", "clip_"], [144, 3, 1, "", "clone"], [145, 3, 1, "", "coalesce"], [146, 3, 1, "", "col_indices"], [147, 3, 1, "", "conj"], [148, 3, 1, "", "conj_physical"], [149, 3, 1, "", "conj_physical_"], [150, 3, 1, "", "contiguous"], [151, 3, 1, "", "copy_"], [152, 3, 1, "", "copysign"], [153, 3, 1, "", "copysign_"], [154, 3, 1, "", "corrcoef"], [155, 3, 1, "", "cos"], [156, 3, 1, "", "cos_"], [157, 3, 1, "", "cosh"], [158, 3, 1, "", "cosh_"], [159, 3, 1, "", "count_nonzero"], [160, 3, 1, "", "cov"], [161, 3, 1, "", "cpu"], [162, 3, 1, "", "cross"], [163, 3, 1, "", "crow_indices"], [164, 3, 1, "", "cuda"], [165, 3, 1, "", "cummax"], [166, 3, 1, "", "cummin"], [167, 3, 1, "", "cumprod"], [168, 3, 1, "", "cumprod_"], [169, 3, 1, "", "cumsum"], [170, 3, 1, "", "cumsum_"], [171, 3, 1, "", "data_ptr"], [172, 3, 1, "", "deg2rad"], [173, 3, 1, "", "dense_dim"], [174, 3, 1, "", "dequantize"], [175, 3, 1, "", "det"], [176, 3, 1, "", "detach"], [177, 3, 1, "", "detach_"], [178, 2, 1, "", "device"], [179, 3, 1, "", "diag"], [180, 3, 1, "", "diag_embed"], [181, 3, 1, "", "diagflat"], [182, 3, 1, "", "diagonal"], [183, 3, 1, "", "diagonal_scatter"], [184, 3, 1, "", "diff"], [185, 3, 1, "", "digamma"], [186, 3, 1, "", "digamma_"], [187, 3, 1, "", "dim"], [188, 3, 1, "", "dist"], [189, 3, 1, "", "div"], [190, 3, 1, "", "div_"], [191, 3, 1, "", "divide"], [192, 3, 1, "", "divide_"], [193, 3, 1, "", "dot"], [194, 3, 1, "", "double"], [195, 3, 1, "", "dsplit"], [196, 3, 1, "", "eig"], [197, 3, 1, "", "element_size"], [198, 3, 1, "", "eq"], [199, 3, 1, "", "eq_"], [200, 3, 1, "", "equal"], [201, 3, 1, "", "erf"], [202, 3, 1, "", "erf_"], [203, 3, 1, "", "erfc"], [204, 3, 1, "", "erfc_"], [205, 3, 1, "", "erfinv"], [206, 3, 1, "", "erfinv_"], [207, 3, 1, "", "exp"], [208, 3, 1, "", "exp_"], [209, 3, 1, "", "expand"], [210, 3, 1, "", "expand_as"], [211, 3, 1, "", "expm1"], [212, 3, 1, "", "expm1_"], [213, 3, 1, "", "exponential_"], [214, 3, 1, "", "fill_"], [215, 3, 1, "", "fill_diagonal_"], [216, 3, 1, "", "fix"], [217, 3, 1, "", "fix_"], [218, 3, 1, "", "flatten"], [219, 3, 1, "", "flip"], [220, 3, 1, "", "fliplr"], [221, 3, 1, "", "flipud"], [222, 3, 1, "", "float"], [223, 3, 1, "", "float_power"], [224, 3, 1, "", "float_power_"], [225, 3, 1, "", "floor"], [226, 3, 1, "", "floor_"], [227, 3, 1, "", "floor_divide"], [228, 3, 1, "", "floor_divide_"], [229, 3, 1, "", "fmax"], [230, 3, 1, "", "fmin"], [231, 3, 1, "", "fmod"], [232, 3, 1, "", "fmod_"], [233, 3, 1, "", "frac"], [234, 3, 1, "", "frac_"], [235, 3, 1, "", "frexp"], [236, 3, 1, "", "gather"], [237, 3, 1, "", "gcd"], [238, 3, 1, "", "gcd_"], [239, 3, 1, "", "ge"], [240, 3, 1, "", "ge_"], [241, 3, 1, "", "geometric_"], [242, 3, 1, "", "geqrf"], [243, 3, 1, "", "ger"], [244, 3, 1, "", "get_device"], [245, 2, 1, "", "grad"], [246, 3, 1, "", "greater"], [247, 3, 1, "", "greater_"], [248, 3, 1, "", "greater_equal"], [249, 3, 1, "", "greater_equal_"], [250, 3, 1, "", "gt"], [251, 3, 1, "", "gt_"], [252, 3, 1, "", "half"], [253, 3, 1, "", "hardshrink"], [254, 3, 1, "", "heaviside"], [255, 3, 1, "", "histc"], [256, 3, 1, "", "histogram"], [257, 3, 1, "", "hsplit"], [258, 3, 1, "", "hypot"], [259, 3, 1, "", "hypot_"], [260, 3, 1, "", "i0"], [261, 3, 1, "", "i0_"], [262, 3, 1, "", "igamma"], [263, 3, 1, "", "igamma_"], [264, 3, 1, "", "igammac"], [265, 3, 1, "", "igammac_"], [266, 2, 1, "", "imag"], [267, 3, 1, "", "index_add"], [268, 3, 1, "", "index_add_"], [269, 3, 1, "", "index_copy"], [270, 3, 1, "", "index_copy_"], [271, 3, 1, "", "index_fill"], [272, 3, 1, "", "index_fill_"], [273, 3, 1, "", "index_put"], [274, 3, 1, "", "index_put_"], [275, 3, 1, "", "index_reduce"], [276, 3, 1, "", "index_reduce_"], [277, 3, 1, "", "index_select"], [278, 3, 1, "", "indices"], [279, 3, 1, "", "inner"], [280, 3, 1, "", "int"], [281, 3, 1, "", "int_repr"], [282, 3, 1, "", "inverse"], [283, 3, 1, "", "is_coalesced"], [284, 3, 1, "", "is_complex"], [285, 3, 1, "", "is_conj"], [286, 3, 1, "", "is_contiguous"], [287, 2, 1, "", "is_cuda"], [288, 3, 1, "", "is_floating_point"], [289, 3, 1, "", "is_inference"], [290, 2, 1, "", "is_leaf"], [291, 2, 1, "", "is_meta"], [292, 3, 1, "", "is_pinned"], [293, 2, 1, "", "is_quantized"], [294, 3, 1, "", "is_set_to"], [295, 3, 1, "", "is_shared"], [296, 3, 1, "", "is_signed"], [297, 2, 1, "", "is_sparse"], [298, 2, 1, "", "is_sparse_csr"], [299, 3, 1, "", "isclose"], [300, 3, 1, "", "isfinite"], [301, 3, 1, "", "isinf"], [302, 3, 1, "", "isnan"], [303, 3, 1, "", "isneginf"], [304, 3, 1, "", "isposinf"], [305, 3, 1, "", "isreal"], [306, 3, 1, "", "istft"], [307, 3, 1, "", "item"], [308, 3, 1, "", "kthvalue"], [309, 3, 1, "", "lcm"], [310, 3, 1, "", "lcm_"], [311, 3, 1, "", "ldexp"], [312, 3, 1, "", "ldexp_"], [313, 3, 1, "", "le"], [314, 3, 1, "", "le_"], [315, 3, 1, "", "lerp"], [316, 3, 1, "", "lerp_"], [317, 3, 1, "", "less"], [318, 3, 1, "", "less_"], [319, 3, 1, "", "less_equal"], [320, 3, 1, "", "less_equal_"], [321, 3, 1, "", "lgamma"], [322, 3, 1, "", "lgamma_"], [323, 3, 1, "", "log"], [324, 3, 1, "", "log10"], [325, 3, 1, "", "log10_"], [326, 3, 1, "", "log1p"], [327, 3, 1, "", "log1p_"], [328, 3, 1, "", "log2"], [329, 3, 1, "", "log2_"], [330, 3, 1, "", "log_"], [331, 3, 1, "", "log_normal_"], [332, 3, 1, "", "logaddexp"], [333, 3, 1, "", "logaddexp2"], [334, 3, 1, "", "logcumsumexp"], [335, 3, 1, "", "logdet"], [336, 3, 1, "", "logical_and"], [337, 3, 1, "", "logical_and_"], [338, 3, 1, "", "logical_not"], [339, 3, 1, "", "logical_not_"], [340, 3, 1, "", "logical_or"], [341, 3, 1, "", "logical_or_"], [342, 3, 1, "", "logical_xor"], [343, 3, 1, "", "logical_xor_"], [344, 3, 1, "", "logit"], [345, 3, 1, "", "logit_"], [346, 3, 1, "", "logsumexp"], [347, 3, 1, "", "long"], [348, 3, 1, "", "lstsq"], [349, 3, 1, "", "lt"], [350, 3, 1, "", "lt_"], [351, 3, 1, "", "lu"], [352, 3, 1, "", "lu_solve"], [1733, 2, 1, "", "mH"], [1733, 2, 1, "", "mT"], [353, 3, 1, "", "map_"], [354, 3, 1, "", "masked_fill"], [355, 3, 1, "", "masked_fill_"], [356, 3, 1, "", "masked_scatter"], [357, 3, 1, "", "masked_scatter_"], [358, 3, 1, "", "masked_select"], [359, 3, 1, "", "matmul"], [360, 3, 1, "", "matrix_exp"], [361, 3, 1, "", "matrix_power"], [362, 3, 1, "", "max"], [363, 3, 1, "", "maximum"], [364, 3, 1, "", "mean"], [365, 3, 1, "", "median"], [366, 3, 1, "", "min"], [367, 3, 1, "", "minimum"], [368, 3, 1, "", "mm"], [369, 3, 1, "", "mode"], [370, 3, 1, "", "moveaxis"], [371, 3, 1, "", "movedim"], [372, 3, 1, "", "msort"], [373, 3, 1, "", "mul"], [374, 3, 1, "", "mul_"], [375, 3, 1, "", "multinomial"], [376, 3, 1, "", "multiply"], [377, 3, 1, "", "multiply_"], [378, 3, 1, "", "mv"], [379, 3, 1, "", "mvlgamma"], [380, 3, 1, "", "mvlgamma_"], [1690, 2, 1, "", "names"], [381, 3, 1, "", "nan_to_num"], [382, 3, 1, "", "nan_to_num_"], [383, 3, 1, "", "nanmean"], [384, 3, 1, "", "nanmedian"], [385, 3, 1, "", "nanquantile"], [386, 3, 1, "", "nansum"], [387, 3, 1, "", "narrow"], [388, 3, 1, "", "narrow_copy"], [389, 2, 1, "", "ndim"], [390, 3, 1, "", "ndimension"], [391, 3, 1, "", "ne"], [392, 3, 1, "", "ne_"], [393, 3, 1, "", "neg"], [394, 3, 1, "", "neg_"], [395, 3, 1, "", "negative"], [396, 3, 1, "", "negative_"], [397, 3, 1, "", "nelement"], [398, 3, 1, "", "new_empty"], [399, 3, 1, "", "new_full"], [400, 3, 1, "", "new_ones"], [401, 3, 1, "", "new_tensor"], [402, 3, 1, "", "new_zeros"], [403, 3, 1, "", "nextafter"], [404, 3, 1, "", "nextafter_"], [405, 3, 1, "", "nonzero"], [406, 3, 1, "", "norm"], [407, 3, 1, "", "normal_"], [408, 3, 1, "", "not_equal"], [409, 3, 1, "", "not_equal_"], [410, 3, 1, "", "numel"], [411, 3, 1, "", "numpy"], [412, 3, 1, "", "orgqr"], [413, 3, 1, "", "ormqr"], [414, 3, 1, "", "outer"], [415, 3, 1, "", "permute"], [416, 3, 1, "", "pin_memory"], [417, 3, 1, "", "pinverse"], [418, 3, 1, "", "polygamma"], [419, 3, 1, "", "polygamma_"], [420, 3, 1, "", "positive"], [421, 3, 1, "", "pow"], [422, 3, 1, "", "pow_"], [423, 3, 1, "", "prod"], [424, 3, 1, "", "put_"], [425, 3, 1, "", "q_per_channel_axis"], [426, 3, 1, "", "q_per_channel_scales"], [427, 3, 1, "", "q_per_channel_zero_points"], [428, 3, 1, "", "q_scale"], [429, 3, 1, "", "q_zero_point"], [430, 3, 1, "", "qr"], [431, 3, 1, "", "qscheme"], [432, 3, 1, "", "quantile"], [433, 3, 1, "", "rad2deg"], [434, 3, 1, "", "random_"], [435, 3, 1, "", "ravel"], [436, 2, 1, "", "real"], [437, 3, 1, "", "reciprocal"], [438, 3, 1, "", "reciprocal_"], [439, 3, 1, "", "record_stream"], [1690, 3, 1, "", "refine_names"], [440, 3, 1, "", "register_hook"], [441, 3, 1, "", "remainder"], [442, 3, 1, "", "remainder_"], [1690, 3, 1, "", "rename"], [1690, 3, 1, "", "rename_"], [443, 3, 1, "", "renorm"], [444, 3, 1, "", "renorm_"], [445, 3, 1, "", "repeat"], [446, 3, 1, "", "repeat_interleave"], [447, 2, 1, "", "requires_grad"], [448, 3, 1, "", "requires_grad_"], [449, 3, 1, "", "reshape"], [450, 3, 1, "", "reshape_as"], [451, 3, 1, "", "resize_"], [452, 3, 1, "", "resize_as_"], [453, 3, 1, "", "resolve_conj"], [454, 3, 1, "", "resolve_neg"], [455, 3, 1, "", "retain_grad"], [456, 2, 1, "", "retains_grad"], [457, 3, 1, "", "roll"], [458, 3, 1, "", "rot90"], [459, 3, 1, "", "round"], [460, 3, 1, "", "round_"], [461, 3, 1, "", "row_indices"], [462, 3, 1, "", "rsqrt"], [463, 3, 1, "", "rsqrt_"], [464, 3, 1, "", "scatter"], [465, 3, 1, "", "scatter_"], [466, 3, 1, "", "scatter_add"], [467, 3, 1, "", "scatter_add_"], [468, 3, 1, "", "scatter_reduce"], [469, 3, 1, "", "scatter_reduce_"], [470, 3, 1, "", "select"], [471, 3, 1, "", "select_scatter"], [472, 3, 1, "", "set_"], [473, 3, 1, "", "sgn"], [474, 3, 1, "", "sgn_"], [475, 3, 1, "", "share_memory_"], [476, 3, 1, "", "short"], [477, 3, 1, "", "sigmoid"], [478, 3, 1, "", "sigmoid_"], [479, 3, 1, "", "sign"], [480, 3, 1, "", "sign_"], [481, 3, 1, "", "signbit"], [482, 3, 1, "", "sin"], [483, 3, 1, "", "sin_"], [484, 3, 1, "", "sinc"], [485, 3, 1, "", "sinc_"], [486, 3, 1, "", "sinh"], [487, 3, 1, "", "sinh_"], [488, 3, 1, "", "size"], [489, 3, 1, "", "slice_scatter"], [490, 3, 1, "", "slogdet"], [491, 3, 1, "", "smm"], [492, 3, 1, "", "sort"], [493, 3, 1, "", "sparse_dim"], [494, 3, 1, "", "sparse_mask"], [495, 3, 1, "", "sparse_resize_"], [496, 3, 1, "", "sparse_resize_and_clear_"], [497, 3, 1, "", "split"], [498, 3, 1, "", "sqrt"], [499, 3, 1, "", "sqrt_"], [500, 3, 1, "", "square"], [501, 3, 1, "", "square_"], [502, 3, 1, "", "squeeze"], [503, 3, 1, "", "squeeze_"], [504, 3, 1, "", "sspaddmm"], [505, 3, 1, "", "std"], [506, 3, 1, "", "stft"], [507, 3, 1, "", "storage"], [508, 3, 1, "", "storage_offset"], [509, 3, 1, "", "storage_type"], [510, 3, 1, "", "stride"], [511, 3, 1, "", "sub"], [512, 3, 1, "", "sub_"], [513, 3, 1, "", "subtract"], [514, 3, 1, "", "subtract_"], [515, 3, 1, "", "sum"], [516, 3, 1, "", "sum_to_size"], [517, 3, 1, "", "svd"], [518, 3, 1, "", "swapaxes"], [519, 3, 1, "", "swapdims"], [520, 3, 1, "", "symeig"], [521, 3, 1, "", "t"], [522, 3, 1, "", "t_"], [523, 3, 1, "", "take"], [524, 3, 1, "", "take_along_dim"], [525, 3, 1, "", "tan"], [526, 3, 1, "", "tan_"], [527, 3, 1, "", "tanh"], [528, 3, 1, "", "tanh_"], [529, 3, 1, "", "tensor_split"], [530, 3, 1, "", "tile"], [531, 3, 1, "", "to"], [532, 3, 1, "", "to_dense"], [533, 3, 1, "", "to_mkldnn"], [534, 3, 1, "", "to_padded_tensor"], [535, 3, 1, "", "to_sparse"], [536, 3, 1, "", "to_sparse_bsc"], [537, 3, 1, "", "to_sparse_bsr"], [538, 3, 1, "", "to_sparse_coo"], [539, 3, 1, "", "to_sparse_csc"], [540, 3, 1, "", "to_sparse_csr"], [541, 3, 1, "", "tolist"], [542, 3, 1, "", "topk"], [543, 3, 1, "", "trace"], [544, 3, 1, "", "transpose"], [545, 3, 1, "", "transpose_"], [546, 3, 1, "", "triangular_solve"], [547, 3, 1, "", "tril"], [548, 3, 1, "", "tril_"], [549, 3, 1, "", "triu"], [550, 3, 1, "", "triu_"], [551, 3, 1, "", "true_divide"], [552, 3, 1, "", "true_divide_"], [553, 3, 1, "", "trunc"], [554, 3, 1, "", "trunc_"], [555, 3, 1, "", "type"], [556, 3, 1, "", "type_as"], [557, 3, 1, "", "unbind"], [558, 3, 1, "", "unflatten"], [559, 3, 1, "", "unfold"], [560, 3, 1, "", "uniform_"], [561, 3, 1, "", "unique"], [562, 3, 1, "", "unique_consecutive"], [563, 3, 1, "", "unsqueeze"], [564, 3, 1, "", "unsqueeze_"], [565, 3, 1, "", "values"], [566, 3, 1, "", "var"], [567, 3, 1, "", "vdot"], [568, 3, 1, "", "view"], [569, 3, 1, "", "view_as"], [570, 3, 1, "", "vsplit"], [571, 3, 1, "", "where"], [572, 3, 1, "", "xlogy"], [573, 3, 1, "", "xlogy_"], [574, 3, 1, "", "zero_"]], "torch.TypedStorage": [[1729, 3, 1, "", "bfloat16"], [1729, 3, 1, "", "bool"], [1729, 3, 1, "", "byte"], [1729, 3, 1, "", "char"], [1729, 3, 1, "", "clone"], [1729, 3, 1, "", "complex_double"], [1729, 3, 1, "", "complex_float"], [1729, 3, 1, "", "copy_"], [1729, 3, 1, "", "cpu"], [1729, 3, 1, "", "cuda"], [1729, 3, 1, "", "data_ptr"], [1729, 4, 1, "", "device"], [1729, 3, 1, "", "double"], [1729, 2, 1, "", "dtype"], [1729, 3, 1, "", "element_size"], [1729, 3, 1, "", "fill_"], [1729, 3, 1, "", "float"], [1729, 3, 1, "", "from_buffer"], [1729, 3, 1, "", "from_file"], [1729, 3, 1, "", "get_device"], [1729, 3, 1, "", "half"], [1729, 3, 1, "", "int"], [1729, 4, 1, "", "is_cuda"], [1729, 3, 1, "", "is_pinned"], [1729, 3, 1, "", "is_shared"], [1729, 2, 1, "", "is_sparse"], [1729, 3, 1, "", "long"], [1729, 3, 1, "", "nbytes"], [1729, 3, 1, "", "pickle_storage_type"], [1729, 3, 1, "", "pin_memory"], [1729, 3, 1, "", "resize_"], [1729, 3, 1, "", "share_memory_"], [1729, 3, 1, "", "short"], [1729, 3, 1, "", "size"], [1729, 3, 1, "", "tolist"], [1729, 3, 1, "", "type"], [1729, 3, 1, "", "untyped"]], "torch.UntypedStorage": [[1729, 3, 1, "", "bfloat16"], [1729, 3, 1, "", "bool"], [1729, 3, 1, "", "byte"], [1729, 3, 1, "", "char"], [1729, 3, 1, "", "clone"], [1729, 3, 1, "", "complex_double"], [1729, 3, 1, "", "complex_float"], [1729, 3, 1, "", "copy_"], [1729, 3, 1, "", "cpu"], [1729, 3, 1, "", "cuda"], [1729, 3, 1, "", "data_ptr"], [1729, 2, 1, "", "device"], [1729, 3, 1, "", "double"], [1729, 3, 1, "", "element_size"], [1729, 3, 1, "", "fill_"], [1729, 3, 1, "", "float"], [1729, 3, 1, "", "from_buffer"], [1729, 3, 1, "", "from_file"], [1729, 3, 1, "", "get_device"], [1729, 3, 1, "", "half"], [1729, 3, 1, "", "int"], [1729, 4, 1, "", "is_cuda"], [1729, 3, 1, "", "is_pinned"], [1729, 3, 1, "", "is_shared"], [1729, 2, 1, "", "is_sparse"], [1729, 2, 1, "", "is_sparse_csr"], [1729, 3, 1, "", "long"], [1729, 3, 1, "", "mps"], [1729, 3, 1, "", "nbytes"], [1729, 3, 1, "", "new"], [1729, 3, 1, "", "pin_memory"], [1729, 3, 1, "", "resize_"], [1729, 3, 1, "", "share_memory_"], [1729, 3, 1, "", "short"], [1729, 3, 1, "", "size"], [1729, 3, 1, "", "tolist"], [1729, 3, 1, "", "type"], [1729, 3, 1, "", "untyped"]], "torch.__config__": [[11, 5, 1, "", "parallel_info"], [11, 5, 1, "", "show"]], "torch.ao": [[1719, 0, 0, "-", "nn"], [1719, 0, 0, "-", "ns"], [1719, 0, 0, "-", "quantization"], [1719, 0, 0, "-", "sparsity"]], "torch.ao.nn": [[1719, 0, 0, "-", "sparse"]], "torch.ao.nn.sparse": [[1719, 0, 0, "-", "quantized"]], "torch.ao.nn.sparse.quantized": [[1719, 0, 0, "-", "dynamic"]], "torch.ao.ns": [[1736, 0, 0, "-", "_numeric_suite"], [1737, 0, 0, "-", "_numeric_suite_fx"], [1719, 0, 0, "-", "fx"]], "torch.ao.ns._numeric_suite": [[1736, 1, 1, "", "Logger"], [1736, 1, 1, "", "OutputLogger"], [1736, 1, 1, "", "Shadow"], [1736, 1, 1, "", "ShadowLogger"], [1736, 5, 1, "", "compare_model_outputs"], [1736, 5, 1, "", "compare_model_stub"], [1736, 5, 1, "", "compare_weights"], [1736, 5, 1, "", "get_logger_dict"], [1736, 5, 1, "", "get_matching_activations"], [1736, 5, 1, "", "prepare_model_outputs"], [1736, 5, 1, "", "prepare_model_with_stubs"]], "torch.ao.ns._numeric_suite.Logger": [[1736, 3, 1, "", "forward"]], "torch.ao.ns._numeric_suite.OutputLogger": [[1736, 3, 1, "", "forward"]], "torch.ao.ns._numeric_suite.Shadow": [[1736, 3, 1, "", "add"], [1736, 3, 1, "", "add_relu"], [1736, 3, 1, "", "add_scalar"], [1736, 3, 1, "", "cat"], [1736, 3, 1, "", "forward"], [1736, 3, 1, "", "mul"], [1736, 3, 1, "", "mul_scalar"]], "torch.ao.ns._numeric_suite.ShadowLogger": [[1736, 3, 1, "", "forward"]], "torch.ao.ns._numeric_suite_fx": [[1737, 1, 1, "", "NSTracer"], [1737, 1, 1, "", "OutputLogger"], [1737, 5, 1, "", "add_loggers"], [1737, 5, 1, "", "add_shadow_loggers"], [1737, 5, 1, "", "extend_logger_results_with_comparison"], [1737, 5, 1, "", "extract_logger_info"], [1737, 5, 1, "", "extract_shadow_logger_info"], [1737, 5, 1, "", "extract_weights"]], "torch.ao.ns._numeric_suite_fx.NSTracer": [[1737, 3, 1, "", "is_leaf_module"]], "torch.ao.ns._numeric_suite_fx.OutputLogger": [[1737, 3, 1, "", "forward"]], "torch.ao.ns.fx.utils": [[1737, 5, 1, "", "compute_cosine_similarity"], [1737, 5, 1, "", "compute_normalized_l2_error"], [1737, 5, 1, "", "compute_sqnr"]], "torch.ao.quantization": [[1719, 0, 0, "-", "backend_config"], [1719, 0, 0, "-", "fx"]], "torch.ao.sparsity": [[1719, 0, 0, "-", "scheduler"], [1719, 0, 0, "-", "sparsifier"]], "torch.autograd": [[1, 1, 1, "", "Function"], [622, 5, 1, "", "backward"], [1, 1, 1, "", "detect_anomaly"], [636, 5, 1, "", "grad"], [637, 5, 1, "", "gradcheck"], [638, 5, 1, "", "gradgradcheck"], [1, 1, 1, "", "set_detect_anomaly"]], "torch.autograd.Function": [[619, 3, 1, "", "backward"], [620, 3, 1, "", "forward"], [621, 3, 1, "", "jvp"]], "torch.autograd.forward_ad": [[623, 1, 1, "", "dual_level"], [624, 5, 1, "", "make_dual"], [625, 5, 1, "", "unpack_dual"]], "torch.autograd.function.FunctionCtx": [[626, 3, 1, "", "mark_dirty"], [627, 3, 1, "", "mark_non_differentiable"], [628, 3, 1, "", "save_for_backward"], [629, 3, 1, "", "set_materialize_grads"]], "torch.autograd.functional": [[630, 5, 1, "", "hessian"], [631, 5, 1, "", "hvp"], [632, 5, 1, "", "jacobian"], [633, 5, 1, "", "jvp"], [634, 5, 1, "", "vhp"], [635, 5, 1, "", "vjp"]], "torch.autograd.graph": [[1, 1, 1, "", "save_on_cpu"], [1, 1, 1, "", "saved_tensors_hooks"]], "torch.autograd.profiler": [[1, 1, 1, "", "emit_itt"], [1, 1, 1, "", "emit_nvtx"], [639, 5, 1, "", "load_nvprof"], [1, 1, 1, "", "profile"]], "torch.autograd.profiler.profile": [[640, 3, 1, "", "export_chrome_trace"], [641, 3, 1, "", "key_averages"], [642, 4, 1, "", "self_cpu_time_total"], [643, 3, 1, "", "total_average"]], "torch.backends": [[2, 0, 0, "-", "cuda"], [2, 0, 0, "-", "cudnn"], [2, 0, 0, "-", "mkl"], [2, 0, 0, "-", "mkldnn"], [2, 0, 0, "-", "mps"], [2, 0, 0, "-", "openmp"], [2, 0, 0, "-", "quantized"], [2, 0, 0, "-", "xeon"], [2, 0, 0, "-", "xnnpack"]], "torch.backends.cuda": [[2, 3, 1, "", "clear"], [2, 5, 1, "", "is_built"], [2, 2, 1, "", "max_size"], [2, 5, 1, "", "preferred_linalg_library"]], "torch.backends.cuda.torch.backends.cuda": [[2, 2, 1, "", "cufft_plan_cache"], [2, 2, 1, "", "size"]], "torch.backends.cuda.torch.backends.cuda.matmul": [[2, 2, 1, "", "allow_fp16_reduced_precision_reduction"], [2, 2, 1, "", "allow_tf32"]], "torch.backends.cudnn": [[2, 5, 1, "", "is_available"], [2, 5, 1, "", "version"]], "torch.backends.cudnn.torch.backends.cudnn": [[2, 2, 1, "", "allow_tf32"], [2, 2, 1, "", "benchmark"], [2, 2, 1, "", "benchmark_limit"], [2, 2, 1, "", "deterministic"], [2, 2, 1, "", "enabled"]], "torch.backends.mkl": [[2, 5, 1, "", "is_available"], [2, 1, 1, "", "verbose"]], "torch.backends.mkldnn": [[2, 5, 1, "", "is_available"], [2, 1, 1, "", "verbose"]], "torch.backends.mps": [[2, 5, 1, "", "is_available"], [2, 5, 1, "", "is_built"]], "torch.backends.openmp": [[2, 5, 1, "", "is_available"]], "torch.cpu": [[0, 0, 0, "-", "amp"]], "torch.cpu.amp": [[0, 1, 1, "", "autocast"]], "torch.cuda": [[688, 1, 1, "", "CUDAGraph"], [689, 1, 1, "", "Event"], [690, 1, 1, "", "ExternalStream"], [691, 1, 1, "", "Stream"], [692, 1, 1, "", "StreamContext"], [0, 0, 0, "-", "amp"], [693, 5, 1, "", "caching_allocator_alloc"], [694, 5, 1, "", "caching_allocator_delete"], [695, 5, 1, "", "can_device_access_peer"], [701, 5, 1, "", "current_blas_handle"], [702, 5, 1, "", "current_device"], [703, 5, 1, "", "current_stream"], [704, 5, 1, "", "default_stream"], [705, 1, 1, "", "device"], [706, 5, 1, "", "device_count"], [707, 1, 1, "", "device_of"], [708, 5, 1, "", "empty_cache"], [709, 5, 1, "", "get_arch_list"], [710, 5, 1, "", "get_device_capability"], [711, 5, 1, "", "get_device_name"], [712, 5, 1, "", "get_device_properties"], [713, 5, 1, "", "get_gencode_flags"], [714, 5, 1, "", "get_rng_state"], [715, 5, 1, "", "get_rng_state_all"], [716, 5, 1, "", "get_sync_debug_mode"], [717, 1, 1, "", "graph"], [718, 5, 1, "", "graph_pool_handle"], [719, 5, 1, "", "init"], [720, 5, 1, "", "initial_seed"], [721, 5, 1, "", "ipc_collect"], [722, 5, 1, "", "is_available"], [723, 5, 1, "", "is_current_stream_capturing"], [724, 5, 1, "", "is_initialized"], [727, 5, 1, "", "list_gpu_processes"], [728, 5, 1, "", "make_graphed_callables"], [729, 5, 1, "", "manual_seed"], [730, 5, 1, "", "manual_seed_all"], [731, 5, 1, "", "max_memory_allocated"], [732, 5, 1, "", "max_memory_cached"], [733, 5, 1, "", "max_memory_reserved"], [734, 5, 1, "", "mem_get_info"], [735, 5, 1, "", "memory_allocated"], [736, 5, 1, "", "memory_cached"], [737, 5, 1, "", "memory_reserved"], [738, 5, 1, "", "memory_snapshot"], [739, 5, 1, "", "memory_stats"], [740, 5, 1, "", "memory_summary"], [741, 5, 1, "", "memory_usage"], [745, 5, 1, "", "reset_max_memory_allocated"], [746, 5, 1, "", "reset_max_memory_cached"], [747, 5, 1, "", "reset_peak_memory_stats"], [748, 5, 1, "", "seed"], [749, 5, 1, "", "seed_all"], [750, 5, 1, "", "set_device"], [751, 5, 1, "", "set_per_process_memory_fraction"], [752, 5, 1, "", "set_rng_state"], [753, 5, 1, "", "set_rng_state_all"], [754, 5, 1, "", "set_stream"], [755, 5, 1, "", "set_sync_debug_mode"], [756, 5, 1, "", "stream"], [757, 5, 1, "", "synchronize"], [758, 5, 1, "", "utilization"]], "torch.cuda.CUDAGraph": [[688, 3, 1, "", "capture_begin"], [688, 3, 1, "", "capture_end"], [688, 3, 1, "", "pool"], [688, 3, 1, "", "replay"], [688, 3, 1, "", "reset"]], "torch.cuda.Event": [[689, 3, 1, "", "elapsed_time"], [689, 3, 1, "", "from_ipc_handle"], [689, 3, 1, "", "ipc_handle"], [689, 3, 1, "", "query"], [689, 3, 1, "", "record"], [689, 3, 1, "", "synchronize"], [689, 3, 1, "", "wait"]], "torch.cuda.ExternalStream": [[690, 3, 1, "", "query"], [690, 3, 1, "", "record_event"], [690, 3, 1, "", "synchronize"], [690, 3, 1, "", "wait_event"], [690, 3, 1, "", "wait_stream"]], "torch.cuda.Stream": [[691, 3, 1, "", "query"], [691, 3, 1, "", "record_event"], [691, 3, 1, "", "synchronize"], [691, 3, 1, "", "wait_event"], [691, 3, 1, "", "wait_stream"]], "torch.cuda.amp": [[0, 1, 1, "", "GradScaler"], [0, 1, 1, "", "autocast"], [0, 5, 1, "", "custom_bwd"], [0, 5, 1, "", "custom_fwd"]], "torch.cuda.amp.GradScaler": [[0, 3, 1, "", "get_backoff_factor"], [0, 3, 1, "", "get_growth_factor"], [0, 3, 1, "", "get_growth_interval"], [0, 3, 1, "", "get_scale"], [0, 3, 1, "", "is_enabled"], [0, 3, 1, "", "load_state_dict"], [0, 3, 1, "", "scale"], [0, 3, 1, "", "set_backoff_factor"], [0, 3, 1, "", "set_growth_factor"], [0, 3, 1, "", "set_growth_interval"], [0, 3, 1, "", "state_dict"], [0, 3, 1, "", "step"], [0, 3, 1, "", "unscale_"], [0, 3, 1, "", "update"]], "torch.cuda.comm": [[696, 5, 1, "", "broadcast"], [697, 5, 1, "", "broadcast_coalesced"], [698, 5, 1, "", "gather"], [699, 5, 1, "", "reduce_add"], [700, 5, 1, "", "scatter"]], "torch.cuda.jiterator": [[725, 5, 1, "", "_create_jit_fn"], [726, 5, 1, "", "_create_multi_output_jit_fn"]], "torch.cuda.nvtx": [[742, 5, 1, "", "mark"], [743, 5, 1, "", "range_pop"], [744, 5, 1, "", "range_push"]], "torch.distributed": [[20, 1, 1, "", "Backend"], [20, 1, 1, "", "FileStore"], [18, 1, 1, "", "GradBucket"], [20, 1, 1, "", "HashStore"], [20, 1, 1, "", "PrefixStore"], [20, 1, 1, "", "ReduceOp"], [20, 1, 1, "", "Store"], [20, 1, 1, "", "TCPStore"], [20, 0, 0, "-", "algorithms"], [20, 5, 1, "", "all_gather"], [20, 5, 1, "", "all_gather_multigpu"], [20, 5, 1, "", "all_gather_object"], [20, 5, 1, "", "all_reduce"], [20, 5, 1, "", "all_reduce_multigpu"], [20, 5, 1, "", "all_to_all"], [1724, 0, 0, "-", "autograd"], [20, 5, 1, "", "barrier"], [20, 5, 1, "", "broadcast"], [20, 5, 1, "", "broadcast_multigpu"], [20, 5, 1, "", "broadcast_object_list"], [20, 0, 0, "-", "elastic"], [40, 0, 0, "-", "fsdp"], [20, 5, 1, "", "gather"], [20, 5, 1, "", "gather_object"], [20, 5, 1, "", "get_backend"], [20, 5, 1, "", "get_rank"], [20, 5, 1, "", "get_world_size"], [20, 5, 1, "", "init_process_group"], [20, 5, 1, "", "irecv"], [20, 5, 1, "", "is_available"], [20, 5, 1, "", "is_initialized"], [20, 5, 1, "", "is_mpi_available"], [20, 5, 1, "", "is_nccl_available"], [20, 5, 1, "", "is_torchelastic_launched"], [20, 5, 1, "", "isend"], [20, 0, 0, "-", "launch"], [20, 0, 0, "-", "launcher"], [20, 5, 1, "", "monitored_barrier"], [20, 5, 1, "", "new_group"], [20, 0, 0, "-", "nn"], [23, 0, 0, "-", "optim"], [20, 0, 0, "-", "pipeline"], [20, 5, 1, "", "recv"], [20, 5, 1, "", "reduce"], [20, 5, 1, "", "reduce_multigpu"], [20, 1, 1, "", "reduce_op"], [20, 5, 1, "", "reduce_scatter"], [20, 5, 1, "", "reduce_scatter_multigpu"], [1724, 0, 0, "-", "rpc"], [36, 0, 0, "-", "run"], [20, 5, 1, "", "scatter"], [20, 5, 1, "", "scatter_object_list"], [20, 5, 1, "", "send"]], "torch.distributed.Backend": [[20, 3, 1, "", "register_backend"]], "torch.distributed.GradBucket": [[18, 5, 1, "", "buffer"], [18, 5, 1, "", "gradients"], [18, 5, 1, "", "index"], [18, 5, 1, "", "is_last"], [18, 5, 1, "", "parameters"], [18, 5, 1, "", "set_buffer"]], "torch.distributed.Store": [[20, 5, 1, "", "add"], [20, 5, 1, "", "compare_set"], [20, 5, 1, "", "delete_key"], [20, 5, 1, "", "get"], [20, 5, 1, "", "num_keys"], [20, 5, 1, "", "set"], [20, 5, 1, "", "set_timeout"], [20, 5, 1, "", "wait"]], "torch.distributed.algorithms": [[21, 1, 1, "", "Join"], [21, 1, 1, "", "JoinHook"], [21, 1, 1, "", "Joinable"], [20, 0, 0, "-", "ddp_comm_hooks"], [20, 0, 0, "-", "model_averaging"]], "torch.distributed.algorithms.Join": [[21, 3, 1, "", "notify_join_context"]], "torch.distributed.algorithms.JoinHook": [[21, 3, 1, "", "main_hook"], [21, 3, 1, "", "post_hook"]], "torch.distributed.algorithms.Joinable": [[21, 4, 1, "", "join_device"], [21, 3, 1, "", "join_hook"], [21, 4, 1, "", "join_process_group"]], "torch.distributed.algorithms.ddp_comm_hooks.debugging_hooks": [[18, 5, 1, "", "noop_hook"]], "torch.distributed.algorithms.ddp_comm_hooks.default_hooks": [[18, 5, 1, "", "allreduce_hook"], [18, 5, 1, "", "bf16_compress_hook"], [18, 5, 1, "", "bf16_compress_wrapper"], [18, 5, 1, "", "fp16_compress_hook"], [18, 5, 1, "", "fp16_compress_wrapper"]], "torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook": [[18, 1, 1, "", "PowerSGDState"], [18, 5, 1, "", "batched_powerSGD_hook"], [18, 5, 1, "", "powerSGD_hook"]], "torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState": [[18, 3, 1, "", "__getstate__"], [18, 3, 1, "", "__setstate__"]], "torch.distributed.autograd": [[1724, 5, 1, "", "backward"], [1724, 1, 1, "", "context"], [1724, 5, 1, "", "get_gradients"]], "torch.distributed.elastic": [[26, 0, 0, "-", "agent"], [29, 0, 0, "-", "events"], [32, 0, 0, "-", "metrics"], [33, 0, 0, "-", "multiprocessing"], [35, 0, 0, "-", "rendezvous"], [37, 0, 0, "-", "timer"], [20, 0, 0, "-", "utils"]], "torch.distributed.elastic.agent": [[26, 0, 0, "-", "server"]], "torch.distributed.elastic.agent.server": [[26, 1, 1, "", "ElasticAgent"], [26, 1, 1, "", "SimpleElasticAgent"], [26, 1, 1, "", "Worker"], [26, 1, 1, "", "WorkerGroup"], [26, 1, 1, "", "WorkerSpec"], [26, 1, 1, "", "WorkerState"]], "torch.distributed.elastic.agent.server.ElasticAgent": [[26, 3, 1, "", "get_worker_group"], [26, 3, 1, "", "run"]], "torch.distributed.elastic.agent.server.SimpleElasticAgent": [[26, 3, 1, "", "_assign_worker_ranks"], [26, 3, 1, "", "_exit_barrier"], [26, 3, 1, "", "_initialize_workers"], [26, 3, 1, "", "_monitor_workers"], [26, 3, 1, "", "_rendezvous"], [26, 3, 1, "", "_restart_workers"], [26, 3, 1, "", "_shutdown"], [26, 3, 1, "", "_start_workers"], [26, 3, 1, "", "_stop_workers"]], "torch.distributed.elastic.agent.server.WorkerSpec": [[26, 3, 1, "", "get_entrypoint_name"]], "torch.distributed.elastic.agent.server.WorkerState": [[26, 3, 1, "", "is_running"]], "torch.distributed.elastic.agent.server.api": [[26, 1, 1, "", "RunResult"]], "torch.distributed.elastic.agent.server.local_elastic_agent": [[26, 1, 1, "", "LocalElasticAgent"]], "torch.distributed.elastic.events.api": [[29, 1, 1, "", "Event"], [29, 2, 1, "", "EventMetadataValue"], [29, 1, 1, "", "EventSource"]], "torch.distributed.elastic.events": [[29, 5, 1, "", "get_logging_handler"], [29, 5, 1, "", "record"]], "torch.distributed.elastic.metrics.api": [[32, 1, 1, "", "ConsoleMetricHandler"], [32, 1, 1, "", "MetricHandler"], [32, 1, 1, "", "NullMetricHandler"]], "torch.distributed.elastic.metrics": [[32, 5, 1, "", "configure"], [32, 5, 1, "", "prof"], [32, 5, 1, "", "put_metric"]], "torch.distributed.elastic.multiprocessing.api": [[33, 1, 1, "", "MultiprocessContext"], [33, 1, 1, "", "PContext"], [33, 1, 1, "", "RunProcsResult"], [33, 1, 1, "", "SubprocessContext"]], "torch.distributed.elastic.multiprocessing": [[28, 0, 0, "-", "errors"], [33, 5, 1, "", "start_processes"]], "torch.distributed.elastic.multiprocessing.errors": [[28, 1, 1, "", "ChildFailedError"], [28, 1, 1, "", "ErrorHandler"], [28, 1, 1, "", "ProcessFailure"], [28, 5, 1, "", "record"]], "torch.distributed.elastic.rendezvous": [[35, 1, 1, "", "RendezvousClosedError"], [35, 1, 1, "", "RendezvousConnectionError"], [35, 1, 1, "", "RendezvousError"], [35, 1, 1, "", "RendezvousHandler"], [35, 1, 1, "", "RendezvousHandlerRegistry"], [35, 1, 1, "", "RendezvousParameters"], [35, 1, 1, "", "RendezvousStateError"], [35, 1, 1, "", "RendezvousTimeoutError"], [35, 0, 0, "-", "registry"]], "torch.distributed.elastic.rendezvous.RendezvousHandler": [[35, 3, 1, "", "get_backend"], [35, 3, 1, "", "get_run_id"], [35, 3, 1, "", "is_closed"], [35, 3, 1, "", "next_rendezvous"], [35, 3, 1, "", "num_nodes_waiting"], [35, 3, 1, "", "set_closed"], [35, 3, 1, "", "shutdown"]], "torch.distributed.elastic.rendezvous.RendezvousHandlerRegistry": [[35, 3, 1, "", "create_handler"], [35, 3, 1, "", "register"]], "torch.distributed.elastic.rendezvous.RendezvousParameters": [[35, 3, 1, "", "get"], [35, 3, 1, "", "get_as_bool"], [35, 3, 1, "", "get_as_int"]], "torch.distributed.elastic.rendezvous.c10d_rendezvous_backend": [[35, 1, 1, "", "C10dRendezvousBackend"], [35, 5, 1, "", "create_backend"]], "torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend": [[35, 3, 1, "", "get_state"], [35, 4, 1, "", "name"], [35, 3, 1, "", "set_state"]], "torch.distributed.elastic.rendezvous.dynamic_rendezvous": [[35, 1, 1, "", "DynamicRendezvousHandler"], [35, 1, 1, "", "RendezvousBackend"], [35, 1, 1, "", "RendezvousTimeout"], [35, 5, 1, "", "create_handler"]], "torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler": [[35, 3, 1, "", "from_backend"]], "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend": [[35, 3, 1, "", "get_state"], [35, 4, 1, "", "name"], [35, 3, 1, "", "set_state"]], "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout": [[35, 4, 1, "", "close"], [35, 4, 1, "", "heartbeat"], [35, 4, 1, "", "join"], [35, 4, 1, "", "last_call"]], "torch.distributed.elastic.rendezvous.etcd_rendezvous": [[35, 1, 1, "", "EtcdRendezvousHandler"]], "torch.distributed.elastic.rendezvous.etcd_rendezvous_backend": [[35, 1, 1, "", "EtcdRendezvousBackend"], [35, 5, 1, "", "create_backend"]], "torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend": [[35, 3, 1, "", "get_state"], [35, 4, 1, "", "name"], [35, 3, 1, "", "set_state"]], "torch.distributed.elastic.rendezvous.etcd_server": [[35, 1, 1, "", "EtcdServer"]], "torch.distributed.elastic.rendezvous.etcd_store": [[35, 1, 1, "", "EtcdStore"]], "torch.distributed.elastic.rendezvous.etcd_store.EtcdStore": [[35, 3, 1, "", "add"], [35, 3, 1, "", "check"], [35, 3, 1, "", "get"], [35, 3, 1, "", "set"], [35, 3, 1, "", "wait"]], "torch.distributed.elastic.timer": [[37, 1, 1, "", "LocalTimerClient"], [37, 1, 1, "", "LocalTimerServer"], [37, 1, 1, "", "TimerClient"], [37, 1, 1, "", "TimerRequest"], [37, 1, 1, "", "TimerServer"], [37, 5, 1, "", "configure"], [37, 5, 1, "", "expires"]], "torch.distributed.elastic.timer.TimerClient": [[37, 3, 1, "", "acquire"], [37, 3, 1, "", "release"]], "torch.distributed.elastic.timer.TimerServer": [[37, 3, 1, "", "clear_timers"], [37, 3, 1, "", "get_expired_timers"], [37, 3, 1, "", "register_timers"]], "torch.distributed.elastic.utils": [[20, 0, 0, "-", "data"]], "torch.distributed.fsdp": [[40, 1, 1, "", "FullyShardedDataParallel"]], "torch.distributed.fsdp.FullyShardedDataParallel": [[40, 3, 1, "", "apply"], [40, 3, 1, "", "clip_grad_norm_"], [40, 3, 1, "", "fsdp_modules"], [40, 3, 1, "", "full_optim_state_dict"], [40, 3, 1, "", "load_state_dict"], [40, 4, 1, "", "module"], [40, 3, 1, "", "named_buffers"], [40, 3, 1, "", "named_parameters"], [40, 3, 1, "", "no_sync"], [40, 4, 1, "", "params_with_grad"], [40, 3, 1, "", "register_comm_hook"], [40, 3, 1, "", "rekey_optim_state_dict"], [40, 3, 1, "", "scatter_full_optim_state_dict"], [40, 3, 1, "", "shard_full_optim_state_dict"], [40, 3, 1, "", "state_dict"], [40, 3, 1, "", "state_dict_type"], [40, 3, 1, "", "summon_full_params"]], "torch.distributed.nn": [[20, 0, 0, "-", "api"], [20, 0, 0, "-", "jit"]], "torch.distributed.nn.api.remote_module": [[1724, 1, 1, "", "RemoteModule"]], "torch.distributed.nn.api.remote_module.RemoteModule": [[1724, 3, 1, "", "get_module_rref"], [1724, 3, 1, "", "remote_parameters"]], "torch.distributed.nn.jit": [[20, 0, 0, "-", "templates"]], "torch.distributed.optim": [[23, 1, 1, "", "DistributedOptimizer"], [23, 1, 1, "", "PostLocalSGDOptimizer"], [23, 1, 1, "", "ZeroRedundancyOptimizer"]], "torch.distributed.optim.DistributedOptimizer": [[23, 3, 1, "", "step"]], "torch.distributed.optim.PostLocalSGDOptimizer": [[23, 3, 1, "", "load_state_dict"], [23, 3, 1, "", "state_dict"], [23, 3, 1, "", "step"]], "torch.distributed.optim.ZeroRedundancyOptimizer": [[23, 3, 1, "", "add_param_group"], [23, 3, 1, "", "consolidate_state_dict"], [23, 3, 1, "", "join_hook"], [23, 3, 1, "", "load_state_dict"], [23, 3, 1, "", "state_dict"], [23, 3, 1, "", "step"]], "torch.distributed.pipeline": [[20, 0, 0, "-", "sync"]], "torch.distributed.pipeline.sync": [[1717, 1, 1, "", "Pipe"], [20, 0, 0, "-", "skip"]], "torch.distributed.pipeline.sync.Pipe": [[1717, 3, 1, "", "forward"]], "torch.distributed.pipeline.sync.skip.skippable": [[1717, 1, 1, "", "pop"], [1717, 5, 1, "", "skippable"], [1717, 1, 1, "", "stash"], [1717, 5, 1, "", "verify_skippables"]], "torch.distributed.rpc": [[1724, 1, 1, "", "BackendType"], [1724, 1, 1, "", "RRef"], [1724, 1, 1, "", "RpcBackendOptions"], [1724, 1, 1, "", "TensorPipeRpcBackendOptions"], [1724, 1, 1, "", "WorkerInfo"], [1724, 5, 1, "", "get_worker_info"], [1724, 5, 1, "", "init_rpc"], [1724, 5, 1, "", "remote"], [1724, 5, 1, "", "rpc_async"], [1724, 5, 1, "", "rpc_sync"], [1724, 5, 1, "", "shutdown"]], "torch.distributed.rpc.RpcBackendOptions": [[1724, 4, 1, "", "init_method"], [1724, 4, 1, "", "rpc_timeout"]], "torch.distributed.rpc.TensorPipeRpcBackendOptions": [[1724, 4, 1, "", "device_maps"], [1724, 4, 1, "", "devices"], [1724, 4, 1, "", "init_method"], [1724, 4, 1, "", "num_worker_threads"], [1724, 4, 1, "", "rpc_timeout"], [1724, 3, 1, "", "set_device_map"], [1724, 3, 1, "", "set_devices"]], "torch.distributed.rpc.WorkerInfo": [[1724, 4, 1, "", "id"], [1724, 4, 1, "", "name"]], "torch.distributed.rpc.functions": [[1724, 5, 1, "", "async_execution"]], "torch.distributions.bernoulli": [[24, 1, 1, "", "Bernoulli"]], "torch.distributions.bernoulli.Bernoulli": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "enumerate_support"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_enumerate_support"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "logits"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 4, 1, "", "param_shape"], [24, 4, 1, "", "probs"], [24, 3, 1, "", "sample"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.beta": [[24, 1, 1, "", "Beta"]], "torch.distributions.beta.Beta": [[24, 2, 1, "", "arg_constraints"], [24, 4, 1, "", "concentration0"], [24, 4, 1, "", "concentration1"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 3, 1, "", "rsample"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.binomial": [[24, 1, 1, "", "Binomial"]], "torch.distributions.binomial.Binomial": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "enumerate_support"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_enumerate_support"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "logits"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 4, 1, "", "param_shape"], [24, 4, 1, "", "probs"], [24, 3, 1, "", "sample"], [24, 4, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.categorical": [[24, 1, 1, "", "Categorical"]], "torch.distributions.categorical.Categorical": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "enumerate_support"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_enumerate_support"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "logits"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 4, 1, "", "param_shape"], [24, 4, 1, "", "probs"], [24, 3, 1, "", "sample"], [24, 4, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.cauchy": [[24, 1, 1, "", "Cauchy"]], "torch.distributions.cauchy.Cauchy": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "cdf"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 3, 1, "", "icdf"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 3, 1, "", "rsample"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.chi2": [[24, 1, 1, "", "Chi2"]], "torch.distributions.chi2.Chi2": [[24, 2, 1, "", "arg_constraints"], [24, 4, 1, "", "df"], [24, 3, 1, "", "expand"]], "torch.distributions": [[24, 0, 0, "-", "constraint_registry"], [24, 0, 0, "-", "constraints"], [24, 0, 0, "-", "kl"], [24, 0, 0, "-", "transforms"]], "torch.distributions.constraint_registry": [[24, 1, 1, "", "ConstraintRegistry"]], "torch.distributions.constraint_registry.ConstraintRegistry": [[24, 3, 1, "", "register"]], "torch.distributions.constraints": [[24, 1, 1, "", "Constraint"], [24, 2, 1, "", "cat"], [24, 2, 1, "", "dependent_property"], [24, 2, 1, "", "greater_than"], [24, 2, 1, "", "greater_than_eq"], [24, 2, 1, "", "half_open_interval"], [24, 2, 1, "", "independent"], [24, 2, 1, "", "integer_interval"], [24, 2, 1, "", "interval"], [24, 2, 1, "", "less_than"], [24, 2, 1, "", "multinomial"], [24, 2, 1, "", "stack"]], "torch.distributions.constraints.Constraint": [[24, 3, 1, "", "check"]], "torch.distributions.continuous_bernoulli": [[24, 1, 1, "", "ContinuousBernoulli"]], "torch.distributions.continuous_bernoulli.ContinuousBernoulli": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "cdf"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 3, 1, "", "icdf"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "logits"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "param_shape"], [24, 4, 1, "", "probs"], [24, 3, 1, "", "rsample"], [24, 3, 1, "", "sample"], [24, 4, 1, "", "stddev"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.dirichlet": [[24, 1, 1, "", "Dirichlet"]], "torch.distributions.dirichlet.Dirichlet": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 3, 1, "", "rsample"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.distribution": [[24, 1, 1, "", "Distribution"]], "torch.distributions.distribution.Distribution": [[24, 4, 1, "", "arg_constraints"], [24, 4, 1, "", "batch_shape"], [24, 3, 1, "", "cdf"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "enumerate_support"], [24, 4, 1, "", "event_shape"], [24, 3, 1, "", "expand"], [24, 3, 1, "", "icdf"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 3, 1, "", "perplexity"], [24, 3, 1, "", "rsample"], [24, 3, 1, "", "sample"], [24, 3, 1, "", "sample_n"], [24, 3, 1, "", "set_default_validate_args"], [24, 4, 1, "", "stddev"], [24, 4, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.exp_family": [[24, 1, 1, "", "ExponentialFamily"]], "torch.distributions.exp_family.ExponentialFamily": [[24, 3, 1, "", "entropy"]], "torch.distributions.exponential": [[24, 1, 1, "", "Exponential"]], "torch.distributions.exponential.Exponential": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "cdf"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 3, 1, "", "icdf"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 3, 1, "", "rsample"], [24, 4, 1, "", "stddev"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.fishersnedecor": [[24, 1, 1, "", "FisherSnedecor"]], "torch.distributions.fishersnedecor.FisherSnedecor": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 3, 1, "", "rsample"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.gamma": [[24, 1, 1, "", "Gamma"]], "torch.distributions.gamma.Gamma": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 3, 1, "", "rsample"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.geometric": [[24, 1, 1, "", "Geometric"]], "torch.distributions.geometric.Geometric": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "logits"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 4, 1, "", "probs"], [24, 3, 1, "", "sample"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.gumbel": [[24, 1, 1, "", "Gumbel"]], "torch.distributions.gumbel.Gumbel": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 4, 1, "", "stddev"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.half_cauchy": [[24, 1, 1, "", "HalfCauchy"]], "torch.distributions.half_cauchy.HalfCauchy": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "cdf"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 3, 1, "", "icdf"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 4, 1, "", "scale"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.half_normal": [[24, 1, 1, "", "HalfNormal"]], "torch.distributions.half_normal.HalfNormal": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "cdf"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 3, 1, "", "icdf"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 4, 1, "", "scale"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.independent": [[24, 1, 1, "", "Independent"]], "torch.distributions.independent.Independent": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "enumerate_support"], [24, 3, 1, "", "expand"], [24, 4, 1, "", "has_enumerate_support"], [24, 4, 1, "", "has_rsample"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 3, 1, "", "rsample"], [24, 3, 1, "", "sample"], [24, 4, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.kl": [[24, 5, 1, "", "kl_divergence"], [24, 5, 1, "", "register_kl"]], "torch.distributions.kumaraswamy": [[24, 1, 1, "", "Kumaraswamy"]], "torch.distributions.kumaraswamy.Kumaraswamy": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.laplace": [[24, 1, 1, "", "Laplace"]], "torch.distributions.laplace.Laplace": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "cdf"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 3, 1, "", "icdf"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 3, 1, "", "rsample"], [24, 4, 1, "", "stddev"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.lkj_cholesky": [[24, 1, 1, "", "LKJCholesky"]], "torch.distributions.lkj_cholesky.LKJCholesky": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "expand"], [24, 3, 1, "", "log_prob"], [24, 3, 1, "", "sample"], [24, 2, 1, "", "support"]], "torch.distributions.log_normal": [[24, 1, 1, "", "LogNormal"]], "torch.distributions.log_normal.LogNormal": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 4, 1, "", "loc"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 4, 1, "", "scale"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.lowrank_multivariate_normal": [[24, 1, 1, "", "LowRankMultivariateNormal"]], "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal": [[24, 2, 1, "", "arg_constraints"], [24, 4, 1, "", "covariance_matrix"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 4, 1, "", "precision_matrix"], [24, 3, 1, "", "rsample"], [24, 4, 1, "", "scale_tril"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.mixture_same_family": [[24, 1, 1, "", "MixtureSameFamily"]], "torch.distributions.mixture_same_family.MixtureSameFamily": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "cdf"], [24, 4, 1, "", "component_distribution"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mixture_distribution"], [24, 3, 1, "", "sample"], [24, 4, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.multinomial": [[24, 1, 1, "", "Multinomial"]], "torch.distributions.multinomial.Multinomial": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "logits"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "param_shape"], [24, 4, 1, "", "probs"], [24, 3, 1, "", "sample"], [24, 4, 1, "", "support"], [24, 2, 1, "", "total_count"], [24, 4, 1, "", "variance"]], "torch.distributions.multivariate_normal": [[24, 1, 1, "", "MultivariateNormal"]], "torch.distributions.multivariate_normal.MultivariateNormal": [[24, 2, 1, "", "arg_constraints"], [24, 4, 1, "", "covariance_matrix"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 4, 1, "", "precision_matrix"], [24, 3, 1, "", "rsample"], [24, 4, 1, "", "scale_tril"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.negative_binomial": [[24, 1, 1, "", "NegativeBinomial"]], "torch.distributions.negative_binomial.NegativeBinomial": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "expand"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "logits"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 4, 1, "", "param_shape"], [24, 4, 1, "", "probs"], [24, 3, 1, "", "sample"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.normal": [[24, 1, 1, "", "Normal"]], "torch.distributions.normal.Normal": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "cdf"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 3, 1, "", "icdf"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 3, 1, "", "rsample"], [24, 3, 1, "", "sample"], [24, 4, 1, "", "stddev"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.one_hot_categorical": [[24, 1, 1, "", "OneHotCategorical"]], "torch.distributions.one_hot_categorical.OneHotCategorical": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "enumerate_support"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_enumerate_support"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "logits"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 4, 1, "", "param_shape"], [24, 4, 1, "", "probs"], [24, 3, 1, "", "sample"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.pareto": [[24, 1, 1, "", "Pareto"]], "torch.distributions.pareto.Pareto": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 4, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.poisson": [[24, 1, 1, "", "Poisson"]], "torch.distributions.poisson.Poisson": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "expand"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 3, 1, "", "sample"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.relaxed_bernoulli": [[24, 1, 1, "", "LogitRelaxedBernoulli"], [24, 1, 1, "", "RelaxedBernoulli"]], "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "expand"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "logits"], [24, 4, 1, "", "param_shape"], [24, 4, 1, "", "probs"], [24, 3, 1, "", "rsample"], [24, 2, 1, "", "support"]], "torch.distributions.relaxed_bernoulli.RelaxedBernoulli": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 4, 1, "", "logits"], [24, 4, 1, "", "probs"], [24, 2, 1, "", "support"], [24, 4, 1, "", "temperature"]], "torch.distributions.relaxed_categorical": [[24, 1, 1, "", "RelaxedOneHotCategorical"]], "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 4, 1, "", "logits"], [24, 4, 1, "", "probs"], [24, 2, 1, "", "support"], [24, 4, 1, "", "temperature"]], "torch.distributions.studentT": [[24, 1, 1, "", "StudentT"]], "torch.distributions.studentT.StudentT": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 3, 1, "", "rsample"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.transformed_distribution": [[24, 1, 1, "", "TransformedDistribution"]], "torch.distributions.transformed_distribution.TransformedDistribution": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "cdf"], [24, 3, 1, "", "expand"], [24, 4, 1, "", "has_rsample"], [24, 3, 1, "", "icdf"], [24, 3, 1, "", "log_prob"], [24, 3, 1, "", "rsample"], [24, 3, 1, "", "sample"], [24, 4, 1, "", "support"]], "torch.distributions.transforms": [[24, 1, 1, "", "AbsTransform"], [24, 1, 1, "", "AffineTransform"], [24, 1, 1, "", "CatTransform"], [24, 1, 1, "", "ComposeTransform"], [24, 1, 1, "", "CorrCholeskyTransform"], [24, 1, 1, "", "CumulativeDistributionTransform"], [24, 1, 1, "", "ExpTransform"], [24, 1, 1, "", "IndependentTransform"], [24, 1, 1, "", "LowerCholeskyTransform"], [24, 1, 1, "", "PowerTransform"], [24, 1, 1, "", "ReshapeTransform"], [24, 1, 1, "", "SigmoidTransform"], [24, 1, 1, "", "SoftmaxTransform"], [24, 1, 1, "", "SoftplusTransform"], [24, 1, 1, "", "StackTransform"], [24, 1, 1, "", "StickBreakingTransform"], [24, 1, 1, "", "TanhTransform"], [24, 1, 1, "", "Transform"]], "torch.distributions.transforms.Transform": [[24, 3, 1, "", "forward_shape"], [24, 4, 1, "", "inv"], [24, 3, 1, "", "inverse_shape"], [24, 3, 1, "", "log_abs_det_jacobian"], [24, 4, 1, "", "sign"]], "torch.distributions.uniform": [[24, 1, 1, "", "Uniform"]], "torch.distributions.uniform.Uniform": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "cdf"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 3, 1, "", "icdf"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 3, 1, "", "rsample"], [24, 4, 1, "", "stddev"], [24, 4, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.von_mises": [[24, 1, 1, "", "VonMises"]], "torch.distributions.von_mises.VonMises": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 3, 1, "", "sample"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.weibull": [[24, 1, 1, "", "Weibull"]], "torch.distributions.weibull.Weibull": [[24, 2, 1, "", "arg_constraints"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.distributions.wishart": [[24, 1, 1, "", "Wishart"]], "torch.distributions.wishart.Wishart": [[24, 2, 1, "", "arg_constraints"], [24, 4, 1, "", "covariance_matrix"], [24, 3, 1, "", "entropy"], [24, 3, 1, "", "expand"], [24, 2, 1, "", "has_rsample"], [24, 3, 1, "", "log_prob"], [24, 4, 1, "", "mean"], [24, 4, 1, "", "mode"], [24, 4, 1, "", "precision_matrix"], [24, 3, 1, "", "rsample"], [24, 4, 1, "", "scale_tril"], [24, 2, 1, "", "support"], [24, 4, 1, "", "variance"]], "torch.fft": [[797, 5, 1, "", "fft"], [798, 5, 1, "", "fft2"], [799, 5, 1, "", "fftfreq"], [800, 5, 1, "", "fftn"], [801, 5, 1, "", "fftshift"], [802, 5, 1, "", "hfft"], [803, 5, 1, "", "hfft2"], [804, 5, 1, "", "hfftn"], [805, 5, 1, "", "ifft"], [806, 5, 1, "", "ifft2"], [807, 5, 1, "", "ifftn"], [808, 5, 1, "", "ifftshift"], [809, 5, 1, "", "ihfft"], [810, 5, 1, "", "ihfft2"], [811, 5, 1, "", "ihfftn"], [812, 5, 1, "", "irfft"], [813, 5, 1, "", "irfft2"], [814, 5, 1, "", "irfftn"], [815, 5, 1, "", "rfft"], [816, 5, 1, "", "rfft2"], [817, 5, 1, "", "rfftfreq"], [818, 5, 1, "", "rfftn"]], "torch.futures": [[41, 1, 1, "", "Future"], [41, 5, 1, "", "collect_all"], [41, 5, 1, "", "wait_all"]], "torch.futures.Future": [[41, 3, 1, "", "add_done_callback"], [41, 3, 1, "", "done"], [41, 3, 1, "", "set_exception"], [41, 3, 1, "", "set_result"], [41, 3, 1, "", "then"], [41, 3, 1, "", "value"], [41, 3, 1, "", "wait"]], "torch.fx": [[42, 1, 1, "", "Graph"], [42, 1, 1, "", "GraphModule"], [42, 1, 1, "", "Interpreter"], [42, 1, 1, "", "Node"], [42, 1, 1, "", "Proxy"], [42, 1, 1, "", "Tracer"], [42, 1, 1, "", "Transformer"], [42, 0, 0, "-", "experimental"], [42, 0, 0, "-", "passes"], [42, 5, 1, "", "replace_pattern"], [42, 5, 1, "", "symbolic_trace"], [42, 5, 1, "", "wrap"]], "torch.fx.Graph": [[42, 3, 1, "", "__init__"], [42, 3, 1, "", "call_function"], [42, 3, 1, "", "call_method"], [42, 3, 1, "", "call_module"], [42, 3, 1, "", "create_node"], [42, 3, 1, "", "eliminate_dead_code"], [42, 3, 1, "", "erase_node"], [42, 3, 1, "", "get_attr"], [42, 3, 1, "", "graph_copy"], [42, 3, 1, "", "inserting_after"], [42, 3, 1, "", "inserting_before"], [42, 3, 1, "", "lint"], [42, 3, 1, "", "node_copy"], [42, 4, 1, "", "nodes"], [42, 3, 1, "", "on_generate_code"], [42, 3, 1, "", "output"], [42, 4, 1, "", "owning_module"], [42, 3, 1, "", "placeholder"], [42, 3, 1, "", "print_tabular"], [42, 3, 1, "", "process_inputs"], [42, 3, 1, "", "process_outputs"], [42, 3, 1, "", "python_code"], [42, 3, 1, "", "set_codegen"]], "torch.fx.GraphModule": [[42, 3, 1, "", "__init__"], [42, 3, 1, "", "add_submodule"], [42, 4, 1, "", "code"], [42, 3, 1, "", "delete_all_unused_submodules"], [42, 3, 1, "", "delete_submodule"], [42, 4, 1, "", "graph"], [42, 3, 1, "", "nested_str"], [42, 3, 1, "", "recompile"], [42, 3, 1, "", "to_folder"]], "torch.fx.Interpreter": [[42, 3, 1, "", "call_function"], [42, 3, 1, "", "call_method"], [42, 3, 1, "", "call_module"], [42, 3, 1, "", "fetch_args_kwargs_from_env"], [42, 3, 1, "", "fetch_attr"], [42, 3, 1, "", "get_attr"], [42, 3, 1, "", "map_nodes_to_values"], [42, 3, 1, "", "output"], [42, 3, 1, "", "placeholder"], [42, 3, 1, "", "run"], [42, 3, 1, "", "run_node"]], "torch.fx.Node": [[42, 4, 1, "", "all_input_nodes"], [42, 3, 1, "", "append"], [42, 4, 1, "", "args"], [42, 3, 1, "", "format_node"], [42, 3, 1, "", "is_impure"], [42, 4, 1, "", "kwargs"], [42, 4, 1, "", "next"], [42, 3, 1, "", "normalized_arguments"], [42, 3, 1, "", "prepend"], [42, 4, 1, "", "prev"], [42, 3, 1, "", "replace_all_uses_with"], [42, 3, 1, "", "replace_input_with"], [42, 4, 1, "", "stack_trace"], [42, 3, 1, "", "update_arg"], [42, 3, 1, "", "update_kwarg"]], "torch.fx.Tracer": [[42, 3, 1, "", "call_module"], [42, 3, 1, "", "create_arg"], [42, 3, 1, "", "create_args_for_root"], [42, 3, 1, "", "create_node"], [42, 3, 1, "", "create_proxy"], [42, 3, 1, "", "is_leaf_module"], [42, 3, 1, "", "iter"], [42, 3, 1, "", "keys"], [42, 3, 1, "", "path_of_module"], [42, 3, 1, "", "proxy"], [42, 3, 1, "", "to_bool"], [42, 3, 1, "", "trace"]], "torch.fx.Transformer": [[42, 3, 1, "", "call_function"], [42, 3, 1, "", "call_module"], [42, 3, 1, "", "get_attr"], [42, 3, 1, "", "placeholder"], [42, 3, 1, "", "transform"]], "torch.fx.experimental": [[42, 0, 0, "-", "migrate_gradual_types"], [42, 0, 0, "-", "unification"]], "torch.fx.experimental.unification": [[42, 0, 0, "-", "multipledispatch"]], "torch.fx.passes": [[42, 0, 0, "-", "backends"], [42, 0, 0, "-", "dialect"], [42, 0, 0, "-", "infra"], [42, 0, 0, "-", "tests"], [42, 0, 0, "-", "utils"]], "torch.fx.passes.dialect": [[42, 0, 0, "-", "common"]], "torch.hub": [[1674, 5, 1, "", "download_url_to_file"], [1674, 5, 1, "", "get_dir"], [1674, 5, 1, "", "help"], [1674, 5, 1, "", "list"], [1674, 5, 1, "", "load"], [1674, 5, 1, "", "load_state_dict_from_url"], [1674, 5, 1, "", "set_dir"]], "torch.jit": [[893, 1, 1, "", "Attribute"], [894, 1, 1, "", "ScriptFunction"], [895, 1, 1, "", "ScriptModule"], [896, 5, 1, "", "annotate"], [897, 5, 1, "", "enable_onednn_fusion"], [1676, 5, 1, "", "export"], [898, 5, 1, "", "fork"], [899, 5, 1, "", "freeze"], [900, 5, 1, "", "ignore"], [1678, 5, 1, "", "is_scripting"], [1678, 5, 1, "", "is_tracing"], [901, 5, 1, "", "isinstance"], [902, 5, 1, "", "load"], [1676, 0, 0, "-", "mobile"], [903, 5, 1, "", "onednn_fusion_enabled"], [904, 5, 1, "", "optimize_for_inference"], [905, 5, 1, "", "save"], [906, 5, 1, "", "script"], [907, 5, 1, "", "script_if_tracing"], [908, 5, 1, "", "set_fusion_strategy"], [909, 1, 1, "", "strict_fusion"], [1677, 0, 0, "-", "supported_ops"], [910, 5, 1, "", "trace"], [911, 5, 1, "", "trace_module"], [1681, 0, 0, "-", "unsupported_tensor_ops"], [912, 5, 1, "", "unused"], [913, 5, 1, "", "wait"]], "torch.jit.Attribute": [[893, 3, 1, "", "count"], [893, 3, 1, "", "index"], [893, 4, 1, "", "type"], [893, 4, 1, "", "value"]], "torch.jit.ScriptFunction": [[894, 3, 1, "", "get_debug_state"], [894, 3, 1, "", "save"], [894, 3, 1, "", "save_to_buffer"]], "torch.jit.ScriptModule": [[895, 3, 1, "", "add_module"], [895, 3, 1, "", "apply"], [895, 3, 1, "", "bfloat16"], [895, 3, 1, "", "buffers"], [895, 3, 1, "", "children"], [895, 4, 1, "", "code"], [895, 4, 1, "", "code_with_constants"], [895, 3, 1, "", "cpu"], [895, 3, 1, "", "cuda"], [895, 3, 1, "", "double"], [895, 3, 1, "", "eval"], [895, 3, 1, "", "extra_repr"], [895, 3, 1, "", "float"], [895, 3, 1, "", "get_buffer"], [895, 3, 1, "", "get_extra_state"], [895, 3, 1, "", "get_parameter"], [895, 3, 1, "", "get_submodule"], [895, 4, 1, "", "graph"], [895, 3, 1, "", "half"], [895, 4, 1, "", "inlined_graph"], [895, 3, 1, "", "ipu"], [895, 3, 1, "", "load_state_dict"], [895, 3, 1, "", "modules"], [895, 3, 1, "", "named_buffers"], [895, 3, 1, "", "named_children"], [895, 3, 1, "", "named_modules"], [895, 3, 1, "", "named_parameters"], [895, 3, 1, "", "parameters"], [895, 3, 1, "", "register_backward_hook"], [895, 3, 1, "", "register_buffer"], [895, 3, 1, "", "register_forward_hook"], [895, 3, 1, "", "register_forward_pre_hook"], [895, 3, 1, "", "register_full_backward_hook"], [895, 3, 1, "", "register_load_state_dict_post_hook"], [895, 3, 1, "", "register_module"], [895, 3, 1, "", "register_parameter"], [895, 3, 1, "", "requires_grad_"], [895, 3, 1, "", "save"], [895, 3, 1, "", "set_extra_state"], [895, 3, 1, "", "share_memory"], [895, 3, 1, "", "state_dict"], [895, 3, 1, "", "to"], [895, 3, 1, "", "to_empty"], [895, 3, 1, "", "train"], [895, 3, 1, "", "type"], [895, 3, 1, "", "xpu"], [895, 3, 1, "", "zero_grad"]], "torch.library": [[1683, 1, 1, "", "Library"]], "torch.library.Library": [[1683, 3, 1, "", "define"], [1683, 3, 1, "", "impl"]], "torch.linalg": [[924, 5, 1, "", "cholesky"], [925, 5, 1, "", "cholesky_ex"], [926, 5, 1, "", "cond"], [927, 5, 1, "", "cross"], [928, 5, 1, "", "det"], [929, 5, 1, "", "diagonal"], [930, 5, 1, "", "eig"], [931, 5, 1, "", "eigh"], [932, 5, 1, "", "eigvals"], [933, 5, 1, "", "eigvalsh"], [934, 5, 1, "", "householder_product"], [935, 5, 1, "", "inv"], [936, 5, 1, "", "inv_ex"], [937, 5, 1, "", "ldl_factor"], [938, 5, 1, "", "ldl_factor_ex"], [939, 5, 1, "", "ldl_solve"], [940, 5, 1, "", "lstsq"], [941, 5, 1, "", "lu"], [942, 5, 1, "", "lu_factor"], [943, 5, 1, "", "lu_factor_ex"], [944, 5, 1, "", "lu_solve"], [945, 5, 1, "", "matmul"], [946, 5, 1, "", "matrix_exp"], [947, 5, 1, "", "matrix_norm"], [948, 5, 1, "", "matrix_power"], [949, 5, 1, "", "matrix_rank"], [950, 5, 1, "", "multi_dot"], [951, 5, 1, "", "norm"], [952, 5, 1, "", "pinv"], [953, 5, 1, "", "qr"], [954, 5, 1, "", "slogdet"], [955, 5, 1, "", "solve"], [956, 5, 1, "", "solve_ex"], [957, 5, 1, "", "solve_triangular"], [958, 5, 1, "", "svd"], [959, 5, 1, "", "svdvals"], [960, 5, 1, "", "tensorinv"], [961, 5, 1, "", "tensorsolve"], [962, 5, 1, "", "vander"], [963, 5, 1, "", "vecdot"], [964, 5, 1, "", "vector_norm"]], "torch.monitor": [[1687, 1, 1, "", "Aggregation"], [1687, 1, 1, "", "Event"], [1687, 1, 1, "", "EventHandlerHandle"], [1687, 1, 1, "", "Stat"], [1687, 1, 1, "", "TensorboardEventHandler"], [1687, 1, 1, "", "data_value_t"], [1687, 5, 1, "", "log_event"], [1687, 5, 1, "", "register_event_handler"], [1687, 5, 1, "", "unregister_event_handler"]], "torch.monitor.Aggregation": [[1687, 4, 1, "", "name"]], "torch.monitor.Event": [[1687, 3, 1, "", "__init__"], [1687, 4, 1, "", "data"], [1687, 4, 1, "", "name"], [1687, 4, 1, "", "timestamp"]], "torch.monitor.Stat": [[1687, 3, 1, "", "__init__"], [1687, 3, 1, "", "add"], [1687, 4, 1, "", "count"], [1687, 3, 1, "", "get"], [1687, 4, 1, "", "name"]], "torch.monitor.TensorboardEventHandler": [[1687, 3, 1, "", "__init__"]], "torch.multiprocessing": [[1688, 1, 1, "", "SpawnContext"], [1688, 5, 1, "", "get_all_sharing_strategies"], [1688, 5, 1, "", "get_sharing_strategy"], [1688, 5, 1, "", "set_sharing_strategy"], [1688, 5, 1, "", "spawn"]], "torch.multiprocessing.SpawnContext": [[1688, 3, 1, "", "join"]], "torch.nn": [[1021, 1, 1, "", "AdaptiveAvgPool1d"], [1022, 1, 1, "", "AdaptiveAvgPool2d"], [1023, 1, 1, "", "AdaptiveAvgPool3d"], [1024, 1, 1, "", "AdaptiveLogSoftmaxWithLoss"], [1025, 1, 1, "", "AdaptiveMaxPool1d"], [1026, 1, 1, "", "AdaptiveMaxPool2d"], [1027, 1, 1, "", "AdaptiveMaxPool3d"], [1028, 1, 1, "", "AlphaDropout"], [1029, 1, 1, "", "AvgPool1d"], [1030, 1, 1, "", "AvgPool2d"], [1031, 1, 1, "", "AvgPool3d"], [1032, 1, 1, "", "BCELoss"], [1033, 1, 1, "", "BCEWithLogitsLoss"], [1034, 1, 1, "", "BatchNorm1d"], [1035, 1, 1, "", "BatchNorm2d"], [1036, 1, 1, "", "BatchNorm3d"], [1037, 1, 1, "", "Bilinear"], [1038, 1, 1, "", "CELU"], [1039, 1, 1, "", "CTCLoss"], [1040, 1, 1, "", "ChannelShuffle"], [1041, 1, 1, "", "ConstantPad1d"], [1042, 1, 1, "", "ConstantPad2d"], [1043, 1, 1, "", "ConstantPad3d"], [1044, 1, 1, "", "Conv1d"], [1045, 1, 1, "", "Conv2d"], [1046, 1, 1, "", "Conv3d"], [1047, 1, 1, "", "ConvTranspose1d"], [1048, 1, 1, "", "ConvTranspose2d"], [1049, 1, 1, "", "ConvTranspose3d"], [1050, 1, 1, "", "CosineEmbeddingLoss"], [1051, 1, 1, "", "CosineSimilarity"], [1052, 1, 1, "", "CrossEntropyLoss"], [1053, 1, 1, "", "DataParallel"], [1054, 1, 1, "", "Dropout"], [1055, 1, 1, "", "Dropout1d"], [1056, 1, 1, "", "Dropout2d"], [1057, 1, 1, "", "Dropout3d"], [1058, 1, 1, "", "ELU"], [1059, 1, 1, "", "Embedding"], [1060, 1, 1, "", "EmbeddingBag"], [1061, 1, 1, "", "FeatureAlphaDropout"], [1062, 1, 1, "", "Flatten"], [1063, 1, 1, "", "Fold"], [1064, 1, 1, "", "FractionalMaxPool2d"], [1065, 1, 1, "", "FractionalMaxPool3d"], [1066, 1, 1, "", "GELU"], [1067, 1, 1, "", "GLU"], [1068, 1, 1, "", "GRU"], [1069, 1, 1, "", "GRUCell"], [1070, 1, 1, "", "GaussianNLLLoss"], [1071, 1, 1, "", "GroupNorm"], [1072, 1, 1, "", "Hardshrink"], [1073, 1, 1, "", "Hardsigmoid"], [1074, 1, 1, "", "Hardswish"], [1075, 1, 1, "", "Hardtanh"], [1076, 1, 1, "", "HingeEmbeddingLoss"], [1077, 1, 1, "", "HuberLoss"], [1078, 1, 1, "", "Identity"], [1079, 1, 1, "", "InstanceNorm1d"], [1080, 1, 1, "", "InstanceNorm2d"], [1081, 1, 1, "", "InstanceNorm3d"], [1082, 1, 1, "", "KLDivLoss"], [1083, 1, 1, "", "L1Loss"], [1084, 1, 1, "", "LPPool1d"], [1085, 1, 1, "", "LPPool2d"], [1086, 1, 1, "", "LSTM"], [1087, 1, 1, "", "LSTMCell"], [1088, 1, 1, "", "LayerNorm"], [1089, 1, 1, "", "LazyBatchNorm1d"], [1090, 1, 1, "", "LazyBatchNorm2d"], [1091, 1, 1, "", "LazyBatchNorm3d"], [1092, 1, 1, "", "LazyConv1d"], [1093, 1, 1, "", "LazyConv2d"], [1094, 1, 1, "", "LazyConv3d"], [1095, 1, 1, "", "LazyConvTranspose1d"], [1096, 1, 1, "", "LazyConvTranspose2d"], [1097, 1, 1, "", "LazyConvTranspose3d"], [1098, 1, 1, "", "LazyInstanceNorm1d"], [1099, 1, 1, "", "LazyInstanceNorm2d"], [1100, 1, 1, "", "LazyInstanceNorm3d"], [1101, 1, 1, "", "LazyLinear"], [1102, 1, 1, "", "LeakyReLU"], [1103, 1, 1, "", "Linear"], [1104, 1, 1, "", "LocalResponseNorm"], [1105, 1, 1, "", "LogSigmoid"], [1106, 1, 1, "", "LogSoftmax"], [1107, 1, 1, "", "MSELoss"], [1108, 1, 1, "", "MarginRankingLoss"], [1109, 1, 1, "", "MaxPool1d"], [1110, 1, 1, "", "MaxPool2d"], [1111, 1, 1, "", "MaxPool3d"], [1112, 1, 1, "", "MaxUnpool1d"], [1113, 1, 1, "", "MaxUnpool2d"], [1114, 1, 1, "", "MaxUnpool3d"], [1115, 1, 1, "", "Mish"], [1116, 1, 1, "", "Module"], [1117, 1, 1, "", "ModuleDict"], [1118, 1, 1, "", "ModuleList"], [1119, 1, 1, "", "MultiLabelMarginLoss"], [1120, 1, 1, "", "MultiLabelSoftMarginLoss"], [1121, 1, 1, "", "MultiMarginLoss"], [1122, 1, 1, "", "MultiheadAttention"], [1123, 1, 1, "", "NLLLoss"], [1124, 1, 1, "", "PReLU"], [1125, 1, 1, "", "PairwiseDistance"], [1126, 1, 1, "", "ParameterDict"], [1127, 1, 1, "", "ParameterList"], [1128, 1, 1, "", "PixelShuffle"], [1129, 1, 1, "", "PixelUnshuffle"], [1130, 1, 1, "", "PoissonNLLLoss"], [1131, 1, 1, "", "RNN"], [1132, 1, 1, "", "RNNBase"], [1133, 1, 1, "", "RNNCell"], [1134, 1, 1, "", "RReLU"], [1135, 1, 1, "", "ReLU"], [1136, 1, 1, "", "ReLU6"], [1137, 1, 1, "", "ReflectionPad1d"], [1138, 1, 1, "", "ReflectionPad2d"], [1139, 1, 1, "", "ReflectionPad3d"], [1140, 1, 1, "", "ReplicationPad1d"], [1141, 1, 1, "", "ReplicationPad2d"], [1142, 1, 1, "", "ReplicationPad3d"], [1143, 1, 1, "", "SELU"], [1144, 1, 1, "", "Sequential"], [1145, 1, 1, "", "SiLU"], [1146, 1, 1, "", "Sigmoid"], [1147, 1, 1, "", "SmoothL1Loss"], [1148, 1, 1, "", "SoftMarginLoss"], [1149, 1, 1, "", "Softmax"], [1150, 1, 1, "", "Softmax2d"], [1151, 1, 1, "", "Softmin"], [1152, 1, 1, "", "Softplus"], [1153, 1, 1, "", "Softshrink"], [1154, 1, 1, "", "Softsign"], [1155, 1, 1, "", "SyncBatchNorm"], [1156, 1, 1, "", "Tanh"], [1157, 1, 1, "", "Tanhshrink"], [1158, 1, 1, "", "Threshold"], [1159, 1, 1, "", "Transformer"], [1160, 1, 1, "", "TransformerDecoder"], [1161, 1, 1, "", "TransformerDecoderLayer"], [1162, 1, 1, "", "TransformerEncoder"], [1163, 1, 1, "", "TransformerEncoderLayer"], [1164, 1, 1, "", "TripletMarginLoss"], [1165, 1, 1, "", "TripletMarginWithDistanceLoss"], [1166, 1, 1, "", "Unflatten"], [1167, 1, 1, "", "Unfold"], [1168, 1, 1, "", "Upsample"], [1169, 1, 1, "", "UpsamplingBilinear2d"], [1170, 1, 1, "", "UpsamplingNearest2d"], [1171, 1, 1, "", "ZeroPad2d"], [1692, 0, 0, "-", "backends"], [1722, 0, 0, "-", "intrinsic"], [1692, 0, 0, "-", "modules"], [1692, 0, 0, "-", "parallel"], [1722, 0, 0, "-", "qat"], [1722, 0, 0, "-", "quantizable"], [1722, 0, 0, "-", "quantized"], [1692, 0, 0, "-", "utils"]], "torch.nn.AdaptiveLogSoftmaxWithLoss": [[1024, 3, 1, "", "log_prob"], [1024, 3, 1, "", "predict"]], "torch.nn.Embedding": [[1059, 3, 1, "", "from_pretrained"]], "torch.nn.EmbeddingBag": [[1060, 3, 1, "", "forward"], [1060, 3, 1, "", "from_pretrained"]], "torch.nn.LazyBatchNorm1d": [[1089, 2, 1, "", "cls_to_become"]], "torch.nn.LazyBatchNorm2d": [[1090, 2, 1, "", "cls_to_become"]], "torch.nn.LazyBatchNorm3d": [[1091, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConv1d": [[1092, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConv2d": [[1093, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConv3d": [[1094, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConvTranspose1d": [[1095, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConvTranspose2d": [[1096, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConvTranspose3d": [[1097, 2, 1, "", "cls_to_become"]], "torch.nn.LazyInstanceNorm1d": [[1098, 2, 1, "", "cls_to_become"]], "torch.nn.LazyInstanceNorm2d": [[1099, 2, 1, "", "cls_to_become"]], "torch.nn.LazyInstanceNorm3d": [[1100, 2, 1, "", "cls_to_become"]], "torch.nn.LazyLinear": [[1101, 2, 1, "", "cls_to_become"]], "torch.nn.Module": [[1116, 3, 1, "", "add_module"], [1116, 3, 1, "", "apply"], [1116, 3, 1, "", "bfloat16"], [1116, 3, 1, "", "buffers"], [1116, 3, 1, "", "children"], [1116, 3, 1, "", "cpu"], [1116, 3, 1, "", "cuda"], [1116, 3, 1, "", "double"], [1116, 3, 1, "", "eval"], [1116, 3, 1, "", "extra_repr"], [1116, 3, 1, "", "float"], [1116, 3, 1, "", "forward"], [1116, 3, 1, "", "get_buffer"], [1116, 3, 1, "", "get_extra_state"], [1116, 3, 1, "", "get_parameter"], [1116, 3, 1, "", "get_submodule"], [1116, 3, 1, "", "half"], [1116, 3, 1, "", "ipu"], [1116, 3, 1, "", "load_state_dict"], [1116, 3, 1, "", "modules"], [1116, 3, 1, "", "named_buffers"], [1116, 3, 1, "", "named_children"], [1116, 3, 1, "", "named_modules"], [1116, 3, 1, "", "named_parameters"], [1116, 3, 1, "", "parameters"], [1116, 3, 1, "", "register_backward_hook"], [1116, 3, 1, "", "register_buffer"], [1116, 3, 1, "", "register_forward_hook"], [1116, 3, 1, "", "register_forward_pre_hook"], [1116, 3, 1, "", "register_full_backward_hook"], [1116, 3, 1, "", "register_load_state_dict_post_hook"], [1116, 3, 1, "", "register_module"], [1116, 3, 1, "", "register_parameter"], [1116, 3, 1, "", "requires_grad_"], [1116, 3, 1, "", "set_extra_state"], [1116, 3, 1, "", "share_memory"], [1116, 3, 1, "", "state_dict"], [1116, 3, 1, "", "to"], [1116, 3, 1, "", "to_empty"], [1116, 3, 1, "", "train"], [1116, 3, 1, "", "type"], [1116, 3, 1, "", "xpu"], [1116, 3, 1, "", "zero_grad"]], "torch.nn.ModuleDict": [[1117, 3, 1, "", "clear"], [1117, 3, 1, "", "items"], [1117, 3, 1, "", "keys"], [1117, 3, 1, "", "pop"], [1117, 3, 1, "", "update"], [1117, 3, 1, "", "values"]], "torch.nn.ModuleList": [[1118, 3, 1, "", "append"], [1118, 3, 1, "", "extend"], [1118, 3, 1, "", "insert"]], "torch.nn.MultiheadAttention": [[1122, 3, 1, "", "forward"]], "torch.nn.ParameterDict": [[1126, 3, 1, "", "clear"], [1126, 3, 1, "", "copy"], [1126, 3, 1, "", "fromkeys"], [1126, 3, 1, "", "get"], [1126, 3, 1, "", "items"], [1126, 3, 1, "", "keys"], [1126, 3, 1, "", "pop"], [1126, 3, 1, "", "popitem"], [1126, 3, 1, "", "setdefault"], [1126, 3, 1, "", "update"], [1126, 3, 1, "", "values"]], "torch.nn.ParameterList": [[1127, 3, 1, "", "append"], [1127, 3, 1, "", "extend"]], "torch.nn.RNNBase": [[1132, 3, 1, "", "flatten_parameters"]], "torch.nn.Sequential": [[1144, 3, 1, "", "append"]], "torch.nn.SyncBatchNorm": [[1155, 3, 1, "", "convert_sync_batchnorm"]], "torch.nn.Transformer": [[1159, 3, 1, "", "forward"], [1159, 3, 1, "", "generate_square_subsequent_mask"]], "torch.nn.TransformerDecoder": [[1160, 3, 1, "", "forward"]], "torch.nn.TransformerDecoderLayer": [[1161, 3, 1, "", "forward"]], "torch.nn.TransformerEncoder": [[1162, 3, 1, "", "forward"]], "torch.nn.TransformerEncoderLayer": [[1163, 3, 1, "", "forward"]], "torch.nn.functional": [[1172, 5, 1, "", "adaptive_avg_pool1d"], [1173, 5, 1, "", "adaptive_avg_pool2d"], [1174, 5, 1, "", "adaptive_avg_pool3d"], [1175, 5, 1, "", "adaptive_max_pool1d"], [1176, 5, 1, "", "adaptive_max_pool2d"], [1177, 5, 1, "", "adaptive_max_pool3d"], [1178, 5, 1, "", "affine_grid"], [1179, 5, 1, "", "alpha_dropout"], [1180, 5, 1, "", "avg_pool1d"], [1181, 5, 1, "", "avg_pool2d"], [1182, 5, 1, "", "avg_pool3d"], [1183, 5, 1, "", "batch_norm"], [1184, 5, 1, "", "bilinear"], [1185, 5, 1, "", "binary_cross_entropy"], [1186, 5, 1, "", "binary_cross_entropy_with_logits"], [1187, 5, 1, "", "celu"], [1188, 5, 1, "", "conv1d"], [1189, 5, 1, "", "conv2d"], [1190, 5, 1, "", "conv3d"], [1191, 5, 1, "", "conv_transpose1d"], [1192, 5, 1, "", "conv_transpose2d"], [1193, 5, 1, "", "conv_transpose3d"], [1194, 5, 1, "", "cosine_embedding_loss"], [1195, 5, 1, "", "cosine_similarity"], [1196, 5, 1, "", "cross_entropy"], [1197, 5, 1, "", "ctc_loss"], [1198, 5, 1, "", "dropout"], [1199, 5, 1, "", "dropout1d"], [1200, 5, 1, "", "dropout2d"], [1201, 5, 1, "", "dropout3d"], [1202, 5, 1, "", "elu"], [1203, 5, 1, "", "elu_"], [1204, 5, 1, "", "embedding"], [1205, 5, 1, "", "embedding_bag"], [1206, 5, 1, "", "feature_alpha_dropout"], [1207, 5, 1, "", "fold"], [1208, 5, 1, "", "fractional_max_pool2d"], [1209, 5, 1, "", "fractional_max_pool3d"], [1210, 5, 1, "", "gaussian_nll_loss"], [1211, 5, 1, "", "gelu"], [1212, 5, 1, "", "glu"], [1213, 5, 1, "", "grid_sample"], [1214, 5, 1, "", "group_norm"], [1215, 5, 1, "", "gumbel_softmax"], [1216, 5, 1, "", "hardshrink"], [1217, 5, 1, "", "hardsigmoid"], [1218, 5, 1, "", "hardswish"], [1219, 5, 1, "", "hardtanh"], [1220, 5, 1, "", "hardtanh_"], [1221, 5, 1, "", "hinge_embedding_loss"], [1222, 5, 1, "", "huber_loss"], [1223, 5, 1, "", "instance_norm"], [1224, 5, 1, "", "interpolate"], [1225, 5, 1, "", "kl_div"], [1226, 5, 1, "", "l1_loss"], [1227, 5, 1, "", "layer_norm"], [1228, 5, 1, "", "leaky_relu"], [1229, 5, 1, "", "leaky_relu_"], [1230, 5, 1, "", "linear"], [1231, 5, 1, "", "local_response_norm"], [1232, 5, 1, "", "log_softmax"], [1233, 5, 1, "", "logsigmoid"], [1234, 5, 1, "", "lp_pool1d"], [1235, 5, 1, "", "lp_pool2d"], [1236, 5, 1, "", "margin_ranking_loss"], [1237, 5, 1, "", "max_pool1d"], [1238, 5, 1, "", "max_pool2d"], [1239, 5, 1, "", "max_pool3d"], [1240, 5, 1, "", "max_unpool1d"], [1241, 5, 1, "", "max_unpool2d"], [1242, 5, 1, "", "max_unpool3d"], [1243, 5, 1, "", "mish"], [1244, 5, 1, "", "mse_loss"], [1245, 5, 1, "", "multi_margin_loss"], [1246, 5, 1, "", "multilabel_margin_loss"], [1247, 5, 1, "", "multilabel_soft_margin_loss"], [1248, 5, 1, "", "nll_loss"], [1249, 5, 1, "", "normalize"], [1250, 5, 1, "", "one_hot"], [1251, 5, 1, "", "pad"], [1252, 5, 1, "", "pairwise_distance"], [1253, 5, 1, "", "pdist"], [1254, 5, 1, "", "pixel_shuffle"], [1255, 5, 1, "", "pixel_unshuffle"], [1256, 5, 1, "", "poisson_nll_loss"], [1257, 5, 1, "", "prelu"], [1258, 5, 1, "", "relu"], [1259, 5, 1, "", "relu6"], [1260, 5, 1, "", "relu_"], [1261, 5, 1, "", "rrelu"], [1262, 5, 1, "", "rrelu_"], [1263, 5, 1, "", "selu"], [1264, 5, 1, "", "sigmoid"], [1265, 5, 1, "", "silu"], [1266, 5, 1, "", "smooth_l1_loss"], [1267, 5, 1, "", "soft_margin_loss"], [1268, 5, 1, "", "softmax"], [1269, 5, 1, "", "softmin"], [1270, 5, 1, "", "softplus"], [1271, 5, 1, "", "softshrink"], [1272, 5, 1, "", "softsign"], [1273, 5, 1, "", "tanh"], [1274, 5, 1, "", "tanhshrink"], [1275, 5, 1, "", "threshold"], [1276, 5, 1, "", "threshold_"], [1278, 5, 1, "", "triplet_margin_loss"], [1279, 5, 1, "", "triplet_margin_with_distance_loss"], [1280, 5, 1, "", "unfold"], [1281, 5, 1, "", "upsample"], [1282, 5, 1, "", "upsample_bilinear"], [1283, 5, 1, "", "upsample_nearest"]], "torch.nn.init": [[1694, 5, 1, "", "calculate_gain"], [1694, 5, 1, "", "constant_"], [1694, 5, 1, "", "dirac_"], [1694, 5, 1, "", "eye_"], [1694, 5, 1, "", "kaiming_normal_"], [1694, 5, 1, "", "kaiming_uniform_"], [1694, 5, 1, "", "normal_"], [1694, 5, 1, "", "ones_"], [1694, 5, 1, "", "orthogonal_"], [1694, 5, 1, "", "sparse_"], [1694, 5, 1, "", "trunc_normal_"], [1694, 5, 1, "", "uniform_"], [1694, 5, 1, "", "xavier_normal_"], [1694, 5, 1, "", "xavier_uniform_"], [1694, 5, 1, "", "zeros_"]], "torch.nn.intrinsic": [[1284, 1, 1, "", "BNReLU2d"], [1285, 1, 1, "", "BNReLU3d"], [1286, 1, 1, "", "ConvBn1d"], [1287, 1, 1, "", "ConvBn2d"], [1288, 1, 1, "", "ConvBn3d"], [1289, 1, 1, "", "ConvBnReLU1d"], [1290, 1, 1, "", "ConvBnReLU2d"], [1291, 1, 1, "", "ConvBnReLU3d"], [1292, 1, 1, "", "ConvReLU1d"], [1293, 1, 1, "", "ConvReLU2d"], [1294, 1, 1, "", "ConvReLU3d"], [1295, 1, 1, "", "LinearReLU"], [1722, 0, 0, "-", "modules"], [1722, 0, 0, "-", "qat"], [1722, 0, 0, "-", "quantized"]], "torch.nn.intrinsic.qat": [[1296, 1, 1, "", "ConvBn1d"], [1297, 1, 1, "", "ConvBn2d"], [1298, 1, 1, "", "ConvBn3d"], [1299, 1, 1, "", "ConvBnReLU1d"], [1300, 1, 1, "", "ConvBnReLU2d"], [1301, 1, 1, "", "ConvBnReLU3d"], [1302, 1, 1, "", "ConvReLU2d"], [1303, 1, 1, "", "ConvReLU3d"], [1304, 1, 1, "", "LinearReLU"], [1305, 1, 1, "", "freeze_bn_stats"], [1722, 0, 0, "-", "modules"], [1306, 1, 1, "", "update_bn_stats"]], "torch.nn.intrinsic.quantized": [[1307, 1, 1, "", "BNReLU2d"], [1308, 1, 1, "", "BNReLU3d"], [1309, 1, 1, "", "ConvReLU1d"], [1310, 1, 1, "", "ConvReLU2d"], [1311, 1, 1, "", "ConvReLU3d"], [1312, 1, 1, "", "LinearReLU"], [1722, 0, 0, "-", "dynamic"], [1722, 0, 0, "-", "modules"]], "torch.nn.intrinsic.quantized.dynamic": [[1313, 1, 1, "", "LinearReLU"], [1722, 0, 0, "-", "modules"]], "torch.nn.modules.lazy": [[1314, 1, 1, "", "LazyModuleMixin"]], "torch.nn.modules.lazy.LazyModuleMixin": [[1314, 3, 1, "", "has_uninitialized_params"], [1314, 3, 1, "", "initialize_parameters"]], "torch.nn.modules.module": [[1315, 5, 1, "", "register_module_backward_hook"], [1316, 5, 1, "", "register_module_forward_hook"], [1317, 5, 1, "", "register_module_forward_pre_hook"], [1318, 5, 1, "", "register_module_full_backward_hook"]], "torch.nn.parallel": [[1319, 1, 1, "", "DistributedDataParallel"], [1277, 5, 1, "", "data_parallel"]], "torch.nn.parallel.DistributedDataParallel": [[1319, 3, 1, "", "join"], [1319, 3, 1, "", "join_hook"], [1319, 3, 1, "", "no_sync"], [1319, 3, 1, "", "register_comm_hook"]], "torch.nn.parameter": [[1320, 1, 1, "", "Parameter"], [1321, 1, 1, "", "UninitializedBuffer"], [1322, 1, 1, "", "UninitializedParameter"]], "torch.nn.parameter.UninitializedParameter": [[1322, 2, 1, "", "cls_to_become"]], "torch.nn.qat": [[1323, 1, 1, "", "Conv2d"], [1324, 1, 1, "", "Conv3d"], [1325, 1, 1, "", "Linear"], [1722, 0, 0, "-", "dynamic"], [1722, 0, 0, "-", "modules"]], "torch.nn.qat.Linear": [[1325, 3, 1, "", "from_float"]], "torch.nn.qat.dynamic": [[1326, 1, 1, "", "Linear"], [1722, 0, 0, "-", "modules"]], "torch.nn.quantizable": [[1327, 1, 1, "", "LSTM"], [1328, 1, 1, "", "MultiheadAttention"], [1722, 0, 0, "-", "modules"]], "torch.nn.quantizable.MultiheadAttention": [[1328, 3, 1, "", "dequantize"], [1328, 3, 1, "", "forward"]], "torch.nn.quantized": [[1329, 1, 1, "", "BatchNorm2d"], [1330, 1, 1, "", "BatchNorm3d"], [1331, 1, 1, "", "Conv1d"], [1332, 1, 1, "", "Conv2d"], [1333, 1, 1, "", "Conv3d"], [1334, 1, 1, "", "ConvTranspose1d"], [1335, 1, 1, "", "ConvTranspose2d"], [1336, 1, 1, "", "ConvTranspose3d"], [1337, 1, 1, "", "ELU"], [1338, 1, 1, "", "Embedding"], [1339, 1, 1, "", "EmbeddingBag"], [1340, 1, 1, "", "FXFloatFunctional"], [1341, 1, 1, "", "FloatFunctional"], [1342, 1, 1, "", "GroupNorm"], [1343, 1, 1, "", "Hardswish"], [1344, 1, 1, "", "InstanceNorm1d"], [1345, 1, 1, "", "InstanceNorm2d"], [1346, 1, 1, "", "InstanceNorm3d"], [1347, 1, 1, "", "LayerNorm"], [1348, 1, 1, "", "LeakyReLU"], [1349, 1, 1, "", "Linear"], [1350, 1, 1, "", "QFunctional"], [1351, 1, 1, "", "ReLU6"], [1352, 1, 1, "", "Sigmoid"], [1722, 0, 0, "-", "dynamic"], [1722, 0, 0, "-", "functional"], [1722, 0, 0, "-", "modules"]], "torch.nn.quantized.Conv1d": [[1331, 3, 1, "", "from_float"]], "torch.nn.quantized.Conv2d": [[1332, 3, 1, "", "from_float"]], "torch.nn.quantized.Conv3d": [[1333, 3, 1, "", "from_float"]], "torch.nn.quantized.Embedding": [[1338, 3, 1, "", "from_float"]], "torch.nn.quantized.EmbeddingBag": [[1339, 3, 1, "", "from_float"]], "torch.nn.quantized.Linear": [[1349, 3, 1, "", "from_float"], [1349, 3, 1, "", "from_reference"]], "torch.nn.quantized.dynamic": [[1353, 1, 1, "", "GRU"], [1354, 1, 1, "", "GRUCell"], [1355, 1, 1, "", "LSTM"], [1356, 1, 1, "", "LSTMCell"], [1357, 1, 1, "", "Linear"], [1358, 1, 1, "", "RNNCell"], [1722, 0, 0, "-", "modules"]], "torch.nn.quantized.dynamic.Linear": [[1357, 3, 1, "", "from_float"], [1357, 3, 1, "", "from_reference"]], "torch.nn.quantized.functional": [[1359, 1, 1, "", "adaptive_avg_pool2d"], [1360, 1, 1, "", "adaptive_avg_pool3d"], [1361, 1, 1, "", "avg_pool2d"], [1362, 1, 1, "", "avg_pool3d"], [1363, 1, 1, "", "celu"], [1364, 1, 1, "", "clamp"], [1365, 1, 1, "", "conv1d"], [1366, 1, 1, "", "conv2d"], [1367, 1, 1, "", "conv3d"], [1368, 1, 1, "", "elu"], [1369, 1, 1, "", "hardsigmoid"], [1370, 1, 1, "", "hardswish"], [1371, 1, 1, "", "hardtanh"], [1372, 1, 1, "", "interpolate"], [1373, 1, 1, "", "leaky_relu"], [1374, 1, 1, "", "linear"], [1375, 1, 1, "", "max_pool1d"], [1376, 1, 1, "", "max_pool2d"], [1377, 1, 1, "", "threshold"], [1378, 1, 1, "", "upsample"], [1379, 1, 1, "", "upsample_bilinear"], [1380, 1, 1, "", "upsample_nearest"]], "torch.nn.utils": [[1381, 5, 1, "", "clip_grad_norm_"], [1382, 5, 1, "", "clip_grad_value_"], [1383, 5, 1, "", "parameters_to_vector"], [1408, 5, 1, "", "remove_spectral_norm"], [1409, 5, 1, "", "remove_weight_norm"], [1415, 5, 1, "", "skip_init"], [1416, 5, 1, "", "spectral_norm"], [1692, 0, 0, "-", "stateless"], [1418, 5, 1, "", "vector_to_parameters"], [1419, 5, 1, "", "weight_norm"]], "torch.nn.utils.parametrizations": [[1384, 5, 1, "", "orthogonal"], [1385, 5, 1, "", "spectral_norm"]], "torch.nn.utils.parametrize": [[1386, 1, 1, "", "ParametrizationList"], [1387, 5, 1, "", "cached"], [1388, 5, 1, "", "is_parametrized"], [1389, 5, 1, "", "register_parametrization"], [1390, 5, 1, "", "remove_parametrizations"]], "torch.nn.utils.parametrize.ParametrizationList": [[1386, 3, 1, "", "right_inverse"]], "torch.nn.utils.prune": [[1391, 1, 1, "", "BasePruningMethod"], [1392, 1, 1, "", "CustomFromMask"], [1393, 1, 1, "", "Identity"], [1394, 1, 1, "", "L1Unstructured"], [1395, 1, 1, "", "LnStructured"], [1396, 1, 1, "", "PruningContainer"], [1397, 1, 1, "", "RandomStructured"], [1398, 1, 1, "", "RandomUnstructured"], [1399, 5, 1, "", "custom_from_mask"], [1400, 5, 1, "", "global_unstructured"], [1401, 5, 1, "", "identity"], [1402, 5, 1, "", "is_pruned"], [1403, 5, 1, "", "l1_unstructured"], [1404, 5, 1, "", "ln_structured"], [1405, 5, 1, "", "random_structured"], [1406, 5, 1, "", "random_unstructured"], [1407, 5, 1, "", "remove"]], "torch.nn.utils.prune.BasePruningMethod": [[1391, 3, 1, "", "apply"], [1391, 3, 1, "", "apply_mask"], [1391, 3, 1, "", "compute_mask"], [1391, 3, 1, "", "prune"], [1391, 3, 1, "", "remove"]], "torch.nn.utils.prune.CustomFromMask": [[1392, 3, 1, "", "apply"], [1392, 3, 1, "", "apply_mask"], [1392, 3, 1, "", "prune"], [1392, 3, 1, "", "remove"]], "torch.nn.utils.prune.Identity": [[1393, 3, 1, "", "apply"], [1393, 3, 1, "", "apply_mask"], [1393, 3, 1, "", "prune"], [1393, 3, 1, "", "remove"]], "torch.nn.utils.prune.L1Unstructured": [[1394, 3, 1, "", "apply"], [1394, 3, 1, "", "apply_mask"], [1394, 3, 1, "", "prune"], [1394, 3, 1, "", "remove"]], "torch.nn.utils.prune.LnStructured": [[1395, 3, 1, "", "apply"], [1395, 3, 1, "", "apply_mask"], [1395, 3, 1, "", "compute_mask"], [1395, 3, 1, "", "prune"], [1395, 3, 1, "", "remove"]], "torch.nn.utils.prune.PruningContainer": [[1396, 3, 1, "", "add_pruning_method"], [1396, 3, 1, "", "apply"], [1396, 3, 1, "", "apply_mask"], [1396, 3, 1, "", "compute_mask"], [1396, 3, 1, "", "prune"], [1396, 3, 1, "", "remove"]], "torch.nn.utils.prune.RandomStructured": [[1397, 3, 1, "", "apply"], [1397, 3, 1, "", "apply_mask"], [1397, 3, 1, "", "compute_mask"], [1397, 3, 1, "", "prune"], [1397, 3, 1, "", "remove"]], "torch.nn.utils.prune.RandomUnstructured": [[1398, 3, 1, "", "apply"], [1398, 3, 1, "", "apply_mask"], [1398, 3, 1, "", "prune"], [1398, 3, 1, "", "remove"]], "torch.nn.utils.rnn": [[1410, 1, 1, "", "PackedSequence"], [1411, 5, 1, "", "pack_padded_sequence"], [1412, 5, 1, "", "pack_sequence"], [1413, 5, 1, "", "pad_packed_sequence"], [1414, 5, 1, "", "pad_sequence"]], "torch.nn.utils.rnn.PackedSequence": [[1410, 4, 1, "", "batch_sizes"], [1410, 3, 1, "", "count"], [1410, 4, 1, "", "data"], [1410, 3, 1, "", "index"], [1410, 4, 1, "", "is_cuda"], [1410, 3, 1, "", "is_pinned"], [1410, 4, 1, "", "sorted_indices"], [1410, 3, 1, "", "to"], [1410, 4, 1, "", "unsorted_indices"]], "torch.nn.utils.stateless": [[1417, 5, 1, "", "functional_call"]], "torch.onnx": [[1428, 1, 1, "", "JitScalarType"], [1429, 1, 1, "", "SymbolicContext"], [1713, 5, 1, "", "disable_log"], [1713, 5, 1, "", "enable_log"], [1713, 5, 1, "", "export"], [1713, 5, 1, "", "export_to_pretty_string"], [1713, 5, 1, "", "is_in_onnx_export"], [1713, 5, 1, "", "is_onnx_log_enabled"], [1713, 5, 1, "", "log"], [1713, 5, 1, "", "register_custom_op_symbolic"], [1713, 5, 1, "", "select_model_mode_for_export"], [1713, 5, 1, "", "set_log_stream"]], "torch.onnx.JitScalarType": [[1428, 3, 1, "", "dtype"], [1428, 3, 1, "", "from_dtype"], [1428, 3, 1, "", "from_name"], [1428, 3, 1, "", "onnx_compatible"], [1428, 3, 1, "", "onnx_type"], [1428, 3, 1, "", "scalar_name"], [1428, 3, 1, "", "torch_name"]], "torch.optim": [[1430, 1, 1, "", "ASGD"], [1431, 1, 1, "", "Adadelta"], [1432, 1, 1, "", "Adagrad"], [1433, 1, 1, "", "Adam"], [1434, 1, 1, "", "AdamW"], [1435, 1, 1, "", "Adamax"], [1436, 1, 1, "", "LBFGS"], [1437, 1, 1, "", "NAdam"], [1715, 1, 1, "", "Optimizer"], [1443, 1, 1, "", "RAdam"], [1444, 1, 1, "", "RMSprop"], [1445, 1, 1, "", "Rprop"], [1446, 1, 1, "", "SGD"], [1447, 1, 1, "", "SparseAdam"]], "torch.optim.ASGD": [[1430, 3, 1, "", "add_param_group"], [1430, 3, 1, "", "load_state_dict"], [1430, 3, 1, "", "state_dict"], [1430, 3, 1, "", "step"], [1430, 3, 1, "", "zero_grad"]], "torch.optim.Adadelta": [[1431, 3, 1, "", "add_param_group"], [1431, 3, 1, "", "load_state_dict"], [1431, 3, 1, "", "state_dict"], [1431, 3, 1, "", "step"], [1431, 3, 1, "", "zero_grad"]], "torch.optim.Adagrad": [[1432, 3, 1, "", "add_param_group"], [1432, 3, 1, "", "load_state_dict"], [1432, 3, 1, "", "state_dict"], [1432, 3, 1, "", "step"], [1432, 3, 1, "", "zero_grad"]], "torch.optim.Adam": [[1433, 3, 1, "", "add_param_group"], [1433, 3, 1, "", "load_state_dict"], [1433, 3, 1, "", "state_dict"], [1433, 3, 1, "", "step"], [1433, 3, 1, "", "zero_grad"]], "torch.optim.AdamW": [[1434, 3, 1, "", "add_param_group"], [1434, 3, 1, "", "load_state_dict"], [1434, 3, 1, "", "state_dict"], [1434, 3, 1, "", "step"], [1434, 3, 1, "", "zero_grad"]], "torch.optim.Adamax": [[1435, 3, 1, "", "add_param_group"], [1435, 3, 1, "", "load_state_dict"], [1435, 3, 1, "", "state_dict"], [1435, 3, 1, "", "step"], [1435, 3, 1, "", "zero_grad"]], "torch.optim.LBFGS": [[1436, 3, 1, "", "add_param_group"], [1436, 3, 1, "", "load_state_dict"], [1436, 3, 1, "", "state_dict"], [1436, 3, 1, "", "step"], [1436, 3, 1, "", "zero_grad"]], "torch.optim.NAdam": [[1437, 3, 1, "", "add_param_group"], [1437, 3, 1, "", "load_state_dict"], [1437, 3, 1, "", "state_dict"], [1437, 3, 1, "", "step"], [1437, 3, 1, "", "zero_grad"]], "torch.optim.Optimizer": [[1438, 3, 1, "", "add_param_group"], [1439, 3, 1, "", "load_state_dict"], [1440, 3, 1, "", "state_dict"], [1441, 3, 1, "", "step"], [1442, 3, 1, "", "zero_grad"]], "torch.optim.RAdam": [[1443, 3, 1, "", "add_param_group"], [1443, 3, 1, "", "load_state_dict"], [1443, 3, 1, "", "state_dict"], [1443, 3, 1, "", "step"], [1443, 3, 1, "", "zero_grad"]], "torch.optim.RMSprop": [[1444, 3, 1, "", "add_param_group"], [1444, 3, 1, "", "load_state_dict"], [1444, 3, 1, "", "state_dict"], [1444, 3, 1, "", "step"], [1444, 3, 1, "", "zero_grad"]], "torch.optim.Rprop": [[1445, 3, 1, "", "add_param_group"], [1445, 3, 1, "", "load_state_dict"], [1445, 3, 1, "", "state_dict"], [1445, 3, 1, "", "step"], [1445, 3, 1, "", "zero_grad"]], "torch.optim.SGD": [[1446, 3, 1, "", "add_param_group"], [1446, 3, 1, "", "load_state_dict"], [1446, 3, 1, "", "state_dict"], [1446, 3, 1, "", "zero_grad"]], "torch.optim.SparseAdam": [[1447, 3, 1, "", "add_param_group"], [1447, 3, 1, "", "load_state_dict"], [1447, 3, 1, "", "state_dict"], [1447, 3, 1, "", "step"], [1447, 3, 1, "", "zero_grad"]], "torch.optim.lr_scheduler": [[1448, 1, 1, "", "ChainedScheduler"], [1449, 1, 1, "", "ConstantLR"], [1450, 1, 1, "", "CosineAnnealingLR"], [1451, 1, 1, "", "CosineAnnealingWarmRestarts"], [1452, 1, 1, "", "CyclicLR"], [1453, 1, 1, "", "ExponentialLR"], [1454, 1, 1, "", "LambdaLR"], [1455, 1, 1, "", "LinearLR"], [1456, 1, 1, "", "MultiStepLR"], [1457, 1, 1, "", "MultiplicativeLR"], [1458, 1, 1, "", "OneCycleLR"], [1459, 1, 1, "", "ReduceLROnPlateau"], [1460, 1, 1, "", "SequentialLR"], [1461, 1, 1, "", "StepLR"]], "torch.optim.lr_scheduler.ChainedScheduler": [[1448, 3, 1, "", "get_last_lr"], [1448, 3, 1, "", "load_state_dict"], [1448, 3, 1, "", "print_lr"], [1448, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.ConstantLR": [[1449, 3, 1, "", "get_last_lr"], [1449, 3, 1, "", "load_state_dict"], [1449, 3, 1, "", "print_lr"], [1449, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.CosineAnnealingLR": [[1450, 3, 1, "", "get_last_lr"], [1450, 3, 1, "", "load_state_dict"], [1450, 3, 1, "", "print_lr"], [1450, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts": [[1451, 3, 1, "", "get_last_lr"], [1451, 3, 1, "", "load_state_dict"], [1451, 3, 1, "", "print_lr"], [1451, 3, 1, "", "state_dict"], [1451, 3, 1, "", "step"]], "torch.optim.lr_scheduler.CyclicLR": [[1452, 3, 1, "", "get_last_lr"], [1452, 3, 1, "", "get_lr"], [1452, 3, 1, "", "load_state_dict"], [1452, 3, 1, "", "print_lr"], [1452, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.ExponentialLR": [[1453, 3, 1, "", "get_last_lr"], [1453, 3, 1, "", "load_state_dict"], [1453, 3, 1, "", "print_lr"], [1453, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.LambdaLR": [[1454, 3, 1, "", "get_last_lr"], [1454, 3, 1, "", "load_state_dict"], [1454, 3, 1, "", "print_lr"], [1454, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.LinearLR": [[1455, 3, 1, "", "get_last_lr"], [1455, 3, 1, "", "load_state_dict"], [1455, 3, 1, "", "print_lr"], [1455, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.MultiStepLR": [[1456, 3, 1, "", "get_last_lr"], [1456, 3, 1, "", "load_state_dict"], [1456, 3, 1, "", "print_lr"], [1456, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.MultiplicativeLR": [[1457, 3, 1, "", "get_last_lr"], [1457, 3, 1, "", "load_state_dict"], [1457, 3, 1, "", "print_lr"], [1457, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.OneCycleLR": [[1458, 3, 1, "", "get_last_lr"], [1458, 3, 1, "", "load_state_dict"], [1458, 3, 1, "", "print_lr"], [1458, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.SequentialLR": [[1460, 3, 1, "", "get_last_lr"], [1460, 3, 1, "", "load_state_dict"], [1460, 3, 1, "", "print_lr"], [1460, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.StepLR": [[1461, 3, 1, "", "get_last_lr"], [1461, 3, 1, "", "load_state_dict"], [1461, 3, 1, "", "print_lr"], [1461, 3, 1, "", "state_dict"]], "torch.overrides": [[1738, 5, 1, "", "get_ignored_functions"], [1738, 5, 1, "", "get_overridable_functions"], [1738, 5, 1, "", "get_testing_overrides"], [1738, 5, 1, "", "handle_torch_function"], [1738, 5, 1, "", "has_torch_function"], [1738, 5, 1, "", "is_tensor_like"], [1738, 5, 1, "", "is_tensor_method_or_property"], [1738, 5, 1, "", "resolve_name"], [1738, 5, 1, "", "wrap_torch_function"]], "torch.package": [[1716, 1, 1, "", "Directory"], [1716, 1, 1, "", "EmptyMatchError"], [1716, 1, 1, "", "PackageExporter"], [1716, 1, 1, "", "PackageImporter"], [1716, 1, 1, "", "PackagingError"], [1716, 0, 0, "-", "analyze"]], "torch.package.Directory": [[1716, 3, 1, "", "has_file"]], "torch.package.PackageExporter": [[1716, 3, 1, "", "__init__"], [1716, 3, 1, "", "add_dependency"], [1716, 3, 1, "", "all_paths"], [1716, 3, 1, "", "close"], [1716, 3, 1, "", "denied_modules"], [1716, 3, 1, "", "deny"], [1716, 3, 1, "", "dependency_graph_string"], [1716, 3, 1, "", "extern"], [1716, 3, 1, "", "externed_modules"], [1716, 3, 1, "", "get_rdeps"], [1716, 3, 1, "", "get_unique_id"], [1716, 3, 1, "", "intern"], [1716, 3, 1, "", "interned_modules"], [1716, 3, 1, "", "mock"], [1716, 3, 1, "", "mocked_modules"], [1716, 3, 1, "", "register_extern_hook"], [1716, 3, 1, "", "register_intern_hook"], [1716, 3, 1, "", "register_mock_hook"], [1716, 3, 1, "", "save_binary"], [1716, 3, 1, "", "save_module"], [1716, 3, 1, "", "save_pickle"], [1716, 3, 1, "", "save_source_file"], [1716, 3, 1, "", "save_source_string"], [1716, 3, 1, "", "save_text"]], "torch.package.PackageImporter": [[1716, 3, 1, "", "__init__"], [1716, 3, 1, "", "file_structure"], [1716, 3, 1, "", "id"], [1716, 3, 1, "", "import_module"], [1716, 3, 1, "", "load_binary"], [1716, 3, 1, "", "load_pickle"], [1716, 3, 1, "", "load_text"], [1716, 3, 1, "", "python_version"]], "torch.profiler": [[1718, 1, 1, "", "ProfilerAction"], [1718, 1, 1, "", "ProfilerActivity"], [1718, 1, 1, "", "_KinetoProfile"], [1718, 1, 1, "", "profile"], [1718, 5, 1, "", "schedule"], [1718, 5, 1, "", "tensorboard_trace_handler"]], "torch.profiler.ProfilerActivity": [[1718, 4, 1, "", "name"]], "torch.profiler._KinetoProfile": [[1718, 3, 1, "", "add_metadata"], [1718, 3, 1, "", "add_metadata_json"], [1718, 3, 1, "", "events"], [1718, 3, 1, "", "export_chrome_trace"], [1718, 3, 1, "", "export_stacks"], [1718, 3, 1, "", "key_averages"]], "torch.profiler.profile": [[1718, 3, 1, "", "step"]], "torch.quantization": [[1477, 1, 1, "", "DeQuantStub"], [1478, 1, 1, "", "QuantStub"], [1479, 1, 1, "", "QuantWrapper"], [1480, 1, 1, "", "add_observer_"], [1481, 1, 1, "", "add_quant_dequant"], [1482, 1, 1, "", "convert"], [1483, 1, 1, "", "default_eval_fn"], [1499, 1, 1, "", "fuse_modules"], [1719, 0, 0, "-", "fx"], [1500, 1, 1, "", "get_observer_dict"], [1520, 1, 1, "", "prepare"], [1521, 1, 1, "", "prepare_qat"], [1522, 1, 1, "", "propagate_qconfig_"], [1536, 1, 1, "", "quantize"], [1537, 1, 1, "", "quantize_dynamic"], [1542, 1, 1, "", "quantize_qat"], [1543, 1, 1, "", "swap_module"]], "torch.quantization.fake_quantize": [[1484, 1, 1, "", "FakeQuantize"], [1485, 1, 1, "", "FakeQuantizeBase"], [1486, 1, 1, "", "FixedQParamsFakeQuantize"], [1487, 1, 1, "", "FusedMovingAvgObsFakeQuantize"], [1488, 2, 1, "", "default_fake_quant"], [1489, 2, 1, "", "default_fused_act_fake_quant"], [1490, 2, 1, "", "default_fused_per_channel_wt_fake_quant"], [1491, 2, 1, "", "default_fused_wt_fake_quant"], [1492, 2, 1, "", "default_histogram_fake_quant"], [1493, 2, 1, "", "default_per_channel_weight_fake_quant"], [1494, 2, 1, "", "default_weight_fake_quant"], [1495, 1, 1, "", "disable_fake_quant"], [1496, 1, 1, "", "disable_observer"], [1497, 1, 1, "", "enable_fake_quant"], [1498, 1, 1, "", "enable_observer"]], "torch.quantization.fake_quantize.FakeQuantizeBase": [[1485, 3, 1, "", "with_args"]], "torch.quantization.observer": [[1501, 1, 1, "", "HistogramObserver"], [1502, 1, 1, "", "MinMaxObserver"], [1503, 1, 1, "", "MovingAverageMinMaxObserver"], [1504, 1, 1, "", "MovingAveragePerChannelMinMaxObserver"], [1505, 1, 1, "", "NoopObserver"], [1506, 1, 1, "", "ObserverBase"], [1507, 1, 1, "", "PerChannelMinMaxObserver"], [1508, 1, 1, "", "PlaceholderObserver"], [1509, 1, 1, "", "RecordingObserver"], [1510, 2, 1, "", "default_debug_observer"], [1511, 2, 1, "", "default_dynamic_quant_observer"], [1512, 2, 1, "", "default_float_qparams_observer"], [1513, 2, 1, "", "default_histogram_observer"], [1514, 2, 1, "", "default_observer"], [1515, 2, 1, "", "default_per_channel_weight_observer"], [1516, 2, 1, "", "default_placeholder_observer"], [1517, 2, 1, "", "default_weight_observer"], [1518, 1, 1, "", "get_observer_state_dict"], [1519, 1, 1, "", "load_observer_state_dict"]], "torch.quantization.observer.MinMaxObserver": [[1502, 3, 1, "", "calculate_qparams"], [1502, 3, 1, "", "forward"], [1502, 3, 1, "", "reset_min_max_vals"]], "torch.quantization.observer.ObserverBase": [[1506, 3, 1, "", "with_args"], [1506, 3, 1, "", "with_callable_args"]], "torch.quantization.observer.PerChannelMinMaxObserver": [[1507, 3, 1, "", "reset_min_max_vals"]], "torch.quantization.qconfig": [[1523, 1, 1, "", "QConfig"], [1524, 2, 1, "", "default_activation_only_qconfig"], [1525, 2, 1, "", "default_debug_qconfig"], [1526, 2, 1, "", "default_dynamic_qconfig"], [1527, 2, 1, "", "default_per_channel_qconfig"], [1528, 2, 1, "", "default_qat_qconfig"], [1529, 2, 1, "", "default_qat_qconfig_v2"], [1530, 2, 1, "", "default_qconfig"], [1531, 2, 1, "", "default_weight_only_qconfig"], [1532, 2, 1, "", "float16_dynamic_qconfig"], [1533, 2, 1, "", "float16_static_qconfig"], [1534, 2, 1, "", "float_qparams_weight_only_qconfig"], [1535, 2, 1, "", "per_channel_dynamic_qconfig"]], "torch.quantization.quantize_fx": [[1538, 1, 1, "", "convert_fx"], [1539, 1, 1, "", "fuse_fx"], [1540, 1, 1, "", "prepare_fx"], [1541, 1, 1, "", "prepare_qat_fx"]], "torch.quasirandom": [[1549, 1, 1, "", "SobolEngine"]], "torch.quasirandom.SobolEngine": [[1549, 3, 1, "", "draw"], [1549, 3, 1, "", "draw_base2"], [1549, 3, 1, "", "fast_forward"], [1549, 3, 1, "", "reset"]], "torch.random": [[1723, 5, 1, "", "fork_rng"], [1723, 5, 1, "", "get_rng_state"], [1723, 5, 1, "", "initial_seed"], [1723, 5, 1, "", "manual_seed"], [1723, 5, 1, "", "seed"], [1723, 5, 1, "", "set_rng_state"]], "torch.sparse": [[1604, 5, 1, "", "addmm"], [1605, 5, 1, "", "log_softmax"], [1606, 5, 1, "", "mm"], [1607, 5, 1, "", "sampled_addmm"], [1608, 5, 1, "", "softmax"], [1609, 5, 1, "", "spdiags"], [1610, 5, 1, "", "sum"]], "torch.special": [[1728, 5, 1, "", "airy_ai"], [1728, 5, 1, "", "digamma"], [1728, 5, 1, "", "entr"], [1728, 5, 1, "", "erf"], [1728, 5, 1, "", "erfc"], [1728, 5, 1, "", "erfcx"], [1728, 5, 1, "", "erfinv"], [1728, 5, 1, "", "exp2"], [1728, 5, 1, "", "expit"], [1728, 5, 1, "", "expm1"], [1728, 5, 1, "", "gammainc"], [1728, 5, 1, "", "gammaincc"], [1728, 5, 1, "", "gammaln"], [1728, 5, 1, "", "i0"], [1728, 5, 1, "", "i0e"], [1728, 5, 1, "", "i1"], [1728, 5, 1, "", "i1e"], [1728, 5, 1, "", "log1p"], [1728, 5, 1, "", "log_ndtr"], [1728, 5, 1, "", "log_softmax"], [1728, 5, 1, "", "logit"], [1728, 5, 1, "", "logsumexp"], [1728, 5, 1, "", "multigammaln"], [1728, 5, 1, "", "ndtr"], [1728, 5, 1, "", "ndtri"], [1728, 5, 1, "", "polygamma"], [1728, 5, 1, "", "psi"], [1728, 5, 1, "", "round"], [1728, 5, 1, "", "scaled_modified_bessel_k0"], [1728, 5, 1, "", "scaled_modified_bessel_k1"], [1728, 5, 1, "", "sinc"], [1728, 5, 1, "", "softmax"], [1728, 5, 1, "", "spherical_bessel_j0"], [1728, 5, 1, "", "xlog1py"], [1728, 5, 1, "", "xlogy"], [1728, 5, 1, "", "zeta"]], "torch.testing": [[1734, 5, 1, "", "assert_close"], [1734, 5, 1, "", "make_tensor"]], "torch.torch": [[1735, 2, 1, "", "default_generator"], [1739, 1, 1, "", "finfo"], [1739, 1, 1, "", "iinfo"]], "torch.utils": [[1735, 0, 0, "-", "backcompat"], [3, 0, 0, "-", "benchmark"], [4, 0, 0, "-", "bottleneck"], [17, 0, 0, "-", "data"], [1735, 0, 0, "-", "hipify"], [1682, 0, 0, "-", "jit"], [1735, 0, 0, "-", "model_dump"], [1686, 0, 0, "-", "model_zoo"], [1732, 0, 0, "-", "tensorboard"]], "torch.utils.benchmark": [[3, 1, 1, "", "CallgrindStats"], [3, 1, 1, "", "FunctionCounts"], [3, 1, 1, "", "Measurement"], [3, 1, 1, "", "Timer"], [3, 0, 0, "-", "examples"], [3, 0, 0, "-", "op_fuzzers"], [3, 0, 0, "-", "utils"]], "torch.utils.benchmark.CallgrindStats": [[3, 3, 1, "", "as_standardized"], [3, 3, 1, "", "counts"], [3, 3, 1, "", "delta"], [3, 3, 1, "", "stats"]], "torch.utils.benchmark.FunctionCounts": [[3, 3, 1, "", "denoise"], [3, 3, 1, "", "filter"], [3, 3, 1, "", "transform"]], "torch.utils.benchmark.Measurement": [[3, 3, 1, "", "merge"], [3, 4, 1, "", "significant_figures"]], "torch.utils.benchmark.Timer": [[3, 3, 1, "", "blocked_autorange"], [3, 3, 1, "", "collect_callgrind"], [3, 3, 1, "", "timeit"]], "torch.utils.benchmark.utils": [[3, 0, 0, "-", "valgrind_wrapper"]], "torch.utils.checkpoint": [[5, 5, 1, "", "checkpoint"], [5, 5, 1, "", "checkpoint_sequential"]], "torch.utils.cpp_extension": [[12, 5, 1, "", "BuildExtension"], [12, 5, 1, "", "CUDAExtension"], [12, 5, 1, "", "CppExtension"], [12, 5, 1, "", "get_compiler_abi_compatibility_and_version"], [12, 5, 1, "", "include_paths"], [12, 5, 1, "", "is_ninja_available"], [12, 5, 1, "", "load"], [12, 5, 1, "", "load_inline"], [12, 5, 1, "", "verify_ninja_availability"]], "torch.utils.data": [[17, 1, 1, "", "BatchSampler"], [17, 1, 1, "", "ChainDataset"], [17, 1, 1, "", "ConcatDataset"], [17, 1, 1, "", "DataLoader"], [17, 1, 1, "", "Dataset"], [17, 1, 1, "", "IterableDataset"], [17, 1, 1, "", "RandomSampler"], [17, 1, 1, "", "Sampler"], [17, 1, 1, "", "SequentialSampler"], [17, 1, 1, "", "Subset"], [17, 1, 1, "", "SubsetRandomSampler"], [17, 1, 1, "", "TensorDataset"], [17, 1, 1, "", "WeightedRandomSampler"], [17, 0, 0, "-", "communication"], [17, 0, 0, "-", "datapipes"], [17, 5, 1, "", "default_collate"], [17, 5, 1, "", "default_convert"], [17, 5, 1, "", "get_worker_info"], [17, 5, 1, "", "random_split"]], "torch.utils.data.datapipes": [[17, 0, 0, "-", "dataframe"], [17, 0, 0, "-", "iter"], [17, 0, 0, "-", "map"], [17, 0, 0, "-", "utils"]], "torch.utils.data.distributed": [[17, 1, 1, "", "DistributedSampler"]], "torch.utils.dlpack": [[25, 5, 1, "", "from_dlpack"], [25, 5, 1, "", "to_dlpack"]], "torch.utils.mobile_optimizer": [[1685, 5, 1, "", "optimize_for_mobile"]], "torch.utils.model_zoo": [[1686, 5, 1, "", "load_url"]], "torch.utils.tensorboard.writer": [[1732, 1, 1, "", "SummaryWriter"]], "torch.utils.tensorboard.writer.SummaryWriter": [[1732, 3, 1, "", "__init__"], [1732, 3, 1, "", "add_audio"], [1732, 3, 1, "", "add_custom_scalars"], [1732, 3, 1, "", "add_embedding"], [1732, 3, 1, "", "add_figure"], [1732, 3, 1, "", "add_graph"], [1732, 3, 1, "", "add_histogram"], [1732, 3, 1, "", "add_hparams"], [1732, 3, 1, "", "add_image"], [1732, 3, 1, "", "add_images"], [1732, 3, 1, "", "add_mesh"], [1732, 3, 1, "", "add_pr_curve"], [1732, 3, 1, "", "add_scalar"], [1732, 3, 1, "", "add_scalars"], [1732, 3, 1, "", "add_text"], [1732, 3, 1, "", "add_video"], [1732, 3, 1, "", "close"], [1732, 3, 1, "", "flush"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:attribute", "3": "py:method", "4": "py:property", "5": "py:function", "6": "std:envvar"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "attribute", "Python attribute"], "3": ["py", "method", "Python method"], "4": ["py", "property", "Python property"], "5": ["py", "function", "Python function"], "6": ["std", "envvar", "environment variable"]}, "titleterms": {"automat": [0, 1, 17, 1676, 1695], "mix": [0, 1676, 1695], "precis": [0, 1695, 1699, 1709], "packag": [0, 1, 13, 19, 20, 1688, 1712, 1716], "torch": [0, 1, 2, 3, 4, 5, 9, 11, 12, 14, 17, 19, 20, 22, 24, 25, 36, 39, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 706, 708, 709, 710, 711, 712, 713, 714, 715, 716, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1315, 1316, 1317, 1318, 1381, 1382, 1383, 1384, 1385, 1387, 1388, 1389, 1390, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1438, 1439, 1440, 1441, 1442, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1544, 1545, 1546, 1547, 1548, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1679, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1691, 1692, 1693, 1694, 1699, 1701, 1704, 1711, 1713, 1715, 1716, 1718, 1722, 1723, 1727, 1728, 1729, 1730, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739], "amp": [0, 1699], "autocast": [0, 1695], "gradient": [0, 1, 848, 1695, 1696, 1735], "scale": [0, 1695, 1705], "op": [0, 1681, 1695, 1713, 1735], "refer": [0, 42, 1676, 1678, 1679, 1680, 1687, 1690, 1704, 1716, 1718, 1719, 1722, 1726, 1733], "elig": 0, "cuda": [0, 2, 9, 14, 164, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 706, 708, 709, 710, 711, 712, 713, 714, 715, 716, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 1688, 1695, 1699, 1702, 1704, 1708, 1710, 1712], "specif": [0, 17, 1727], "behavior": [0, 17, 1703], "can": [0, 1696, 1702], "float16": 0, "float32": 0, "promot": [0, 6], "widest": 0, "input": [0, 1689, 1695, 1703], "type": [0, 17, 555, 1678, 1679, 1701, 1713, 1716, 1733, 1739], "prefer": 0, "binary_cross_entropy_with_logit": [0, 1186], "over": [0, 7, 1678], "binary_cross_entropi": [0, 1185], "cpu": [0, 9, 161, 1696, 1698, 1719], "bfloat16": [0, 110], "differenti": [1, 1696], "autograd": [1, 9, 10, 13, 619, 620, 621, 622, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 1690, 1695, 1696, 1701, 1713, 1724, 1725], "forward": [1, 19, 620, 1701, 1725], "mode": [1, 36, 369, 1002, 1696, 1701, 1703, 1713, 1719, 1725], "function": [1, 20, 24, 39, 42, 619, 620, 621, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1676, 1677, 1678, 1679, 1681, 1684, 1689, 1692, 1693, 1695, 1696, 1703, 1713, 1722, 1727, 1728, 1738], "higher": 1, "level": [1, 9, 1722], "api": [1, 9, 13, 22, 29, 42, 1675, 1676, 1679, 1687, 1690, 1698, 1699, 1701, 1704, 1705, 1716, 1717, 1718, 1719, 1722], "local": [1, 1679, 1696, 1735], "disabl": [1, 17, 1676, 1696, 1735], "comput": [1, 1696, 1709, 1725, 1735], "default": [1, 17, 18, 1678, 1696, 1699, 1703, 1721], "layout": [1, 1730], "manual": 1, "In": [1, 7, 1696, 1697, 1735], "place": [1, 1689, 1696, 1697, 1713, 1735], "oper": [1, 9, 18, 20, 1678, 1679, 1684, 1689, 1690, 1696, 1701, 1705, 1712, 1713, 1714, 1719, 1727, 1733, 1735], "tensor": [1, 10, 13, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 1639, 1677, 1681, 1684, 1688, 1689, 1690, 1691, 1696, 1701, 1711, 1713, 1719, 1722, 1727, 1730, 1731, 1733, 1735], "correct": [1, 42, 1696], "check": [1, 42, 1676, 1696, 1704], "variabl": [1, 20, 36, 1676, 1678, 1679], "deprec": 1, "context": [1, 21, 33, 1725], "method": [1, 28, 29, 32, 37, 1677, 1678, 1681, 1691, 1713, 1722, 1727], "mixin": 1, "numer": [1, 1703, 1709, 1720], "profil": [1, 20, 639, 640, 641, 642, 643, 1705, 1706, 1718], "anomali": 1, "detect": 1, "save": [1, 905, 1574, 1674, 1696, 1705, 1711, 1719], "hook": [1, 18, 1696, 1706], "backend": [2, 20, 35, 36, 1676, 1704, 1707, 1719, 1721, 1724], "cudnn": 2, "mp": [2, 9, 1707], "mkl": 2, "mkldnn": [2, 9], "openmp": 2, "xeon": 2, "benchmark": [3, 1710], "util": [3, 4, 5, 9, 12, 17, 20, 25, 758, 1381, 1382, 1383, 1384, 1385, 1387, 1388, 1389, 1390, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1682, 1685, 1686, 1692, 1722, 1732, 1735, 1737], "bottleneck": 4, "checkpoint": [5, 18], "pytorch": [6, 7, 8, 9, 13, 20, 1675, 1676, 1677, 1681, 1696, 1699, 1701, 1710, 1711, 1713, 1717], "contribut": [6, 1713], "guid": 6, "process": [6, 8, 17, 33, 1695], "get": [6, 19, 22, 1713], "start": [6, 19, 22, 33], "propos": 6, "new": [6, 8], "featur": [6, 1705, 1706], "report": [6, 1702], "issu": [6, 1676], "implement": [6, 26, 35, 37, 1674, 1700, 1703, 1713, 1720, 1726], "fix": [6, 36, 216, 819], "bug": 6, "ad": [6, 1701, 1713], "tutori": [6, 9, 1716, 1717, 1724], "improv": [6, 1706], "document": [6, 22, 1675], "particip": 6, "onlin": 6, "discuss": 6, "submit": 6, "pull": 6, "request": 6, "open": 6, "review": 6, "code": [6, 42, 1676, 1699, 1716], "readabl": 6, "test": [6, 1679, 1701, 1716, 1734], "case": [6, 1676], "make": [6, 8], "codebas": 6, "more": [6, 1724], "robust": 6, "triag": 6, "about": [6, 1696, 1724], "sourc": [6, 1710, 1712, 1716], "develop": [6, 1675, 1713], "common": [6, 20, 42, 1705, 1719], "mistak": 6, "To": 6, "avoid": [6, 1708, 1710, 1713, 1716], "frequent": [6, 1676, 1702, 1713], "ask": [6, 1676, 1702, 1713], "question": [6, 1676, 1702, 1713], "On": [6, 18, 1678], "python": [6, 7, 19, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1710, 1713], "doc": [6, 9, 1704], "c": [6, 9, 13, 19, 1696, 1701, 1704, 1711], "build": [6, 9, 19, 1698, 1705, 1706, 1712], "overview": [6, 42, 1716, 1718], "design": [7, 1679, 1700, 1724, 1725, 1726], "philosophi": 7, "principl": [7, 8], "1": [7, 36, 1676], "usabl": 7, "perform": [7, 9, 1706, 1711], "2": [7, 1676, 1699, 1702], "simpl": [7, 1678, 1679, 1706, 1725], "easi": 7, "3": [7, 36], "first": [7, 1716], "best": [7, 1699, 1708, 1719], "class": [7, 28, 42, 1676, 1678, 1679, 1681, 1713, 1715, 1716, 1733], "languag": [7, 1675, 1676, 1678, 1679, 1680], "interoper": 7, "govern": [8, 9], "mechan": [8, 1696, 1703], "summari": [8, 1719], "modul": [8, 9, 42, 1116, 1315, 1316, 1317, 1318, 1676, 1677, 1678, 1679, 1681, 1692, 1696, 1701, 1706, 1711, 1716, 1719], "maintain": [8, 9], "core": [8, 9], "lead": [8, 9], "bdfl": [8, 9], "nomin": [8, 1679], "confirm": 8, "remov": [8, 1407, 1689], "The": [8, 42, 1679], "add": [8, 52, 580], "re": [8, 1716], "scope": 8, "project": 8, "decis": 8, "uncontroversi": 8, "chang": [8, 36], "controversi": 8, "faq": [8, 1712], "respons": 9, "nn": [9, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1315, 1316, 1317, 1318, 1381, 1382, 1383, 1384, 1385, 1387, 1388, 1389, 1390, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1678, 1679, 1692, 1693, 1694, 1696, 1699, 1701, 1711, 1722], "optim": [9, 23, 1438, 1439, 1440, 1441, 1442, 1695, 1696, 1715, 1724, 1725], "jit": [9, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 910, 911, 912, 913, 1676, 1679, 1682], "torchscript": [9, 13, 1676, 1677, 1678, 1679, 1681, 1698, 1705, 1706, 1716], "fx": [9, 42, 1706, 1719, 1737], "distribut": [9, 20, 22, 23, 24, 36, 1692, 1693, 1700, 1704, 1706, 1724, 1725], "rng": 9, "multiprocess": [9, 33, 1688, 1699, 1708, 1712], "dataload": [9, 1710], "linear": [9, 10, 1103, 1230, 1325, 1326, 1349, 1357, 1374, 1692, 1693, 1727], "algebra": [9, 10, 1727], "linalg": [9, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 1684], "fast": [9, 39, 1703, 1725], "fourier": [9, 39], "transform": [9, 24, 39, 42, 1159, 1692, 1706], "fft": [9, 39, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818], "simd": 9, "nvidia": [9, 14, 1709], "intel": 9, "amd": [9, 1709], "rocm": [9, 1704], "hip": [9, 1704], "ci": 9, "tool": [9, 14, 1720, 1727], "c10": 9, "dispatch": 9, "onnx": [9, 1713, 1714], "mobil": 9, "edg": [9, 1676, 1716], "model": [9, 13, 19, 1674, 1695, 1702, 1705, 1715, 1716, 1717, 1719, 1722], "compress": [9, 1727], "window": [9, 1712], "appl": 9, "m1": 9, "powerpc": 9, "librari": [9, 1675, 1683, 1710], "xla": 9, "torchserv": 9, "torchvis": 9, "torchtext": 9, "torchaudio": 9, "torchx": 9, "torchdata": 9, "complex": [10, 677, 1696, 1703], "number": [10, 14, 36, 1696, 1698, 1702, 1710], "creat": [10, 19, 1676, 1690], "transit": [10, 36], "from": [10, 36, 42, 1674, 1689, 1712, 1713, 1716], "old": 10, "represent": 10, "access": [10, 1678, 1716], "real": [10, 436, 1560, 1703], "imag": [10, 266, 865], "angl": [10, 72, 593], "ab": [10, 44, 576], "serial": [10, 1711, 1735], "__config__": 11, "cpp_extens": 12, "extend": [13, 26, 1701], "extens": [13, 14, 1701, 1705, 1712], "author": [13, 42], "random": [14, 17, 1702, 1710, 1723, 1735], "gener": [14, 21, 42, 43, 1697, 1710, 1719, 1720, 1735], "commun": [14, 18, 20, 1675], "collect": [14, 20], "stream": [14, 691, 756, 1699], "event": [14, 27, 29, 689], "graph": [14, 42, 717, 1676, 1696, 1699, 1719], "beta": [14, 24], "memori": [14, 17, 1699, 1702, 1704, 1706], "manag": [14, 21, 1688, 1699, 1704, 1716], "nvtx": [14, 742, 743, 744], "jiter": [14, 725, 726], "data": [17, 1679, 1700, 1702, 1713, 1720, 1733], "dataset": 17, "map": [17, 1704], "style": 17, "iter": [17, 1678], "load": [17, 19, 902, 966, 1674, 1711, 1716, 1719], "order": 17, "sampler": 17, "batch": [17, 1709, 1715], "non": [17, 42, 1692, 1693, 1696, 1699, 1716, 1719], "work": [17, 1695, 1702, 1727], "collate_fn": 17, "singl": [17, 36, 1695], "multi": [17, 20, 36, 1692, 1693], "platform": 17, "pin": [17, 1699], "ddp": 18, "how": [18, 1674, 1696, 1701, 1715, 1716], "us": [18, 20, 42, 1678, 1696, 1699, 1701, 1703, 1713, 1715, 1716, 1717, 1719], "what": [18, 1696, 1716], "doe": [18, 1696], "powersgd": 18, "state": [18, 1706, 1716], "debug": [18, 20, 42, 1676, 1719, 1720], "acknowledg": [18, 1717], "deploi": [19, 1706], "instal": [19, 1712], "run": [19, 1674], "applic": [19, 20], "execut": [19, 1679, 1699, 1716, 1717], "come": [20, 1696], "which": 20, "environ": [20, 36, 1705, 1716], "choos": 20, "network": [20, 1699, 1702, 1706], "interfac": [20, 1704], "other": [20, 1692, 1710, 1716, 1727, 1735], "nccl": [20, 1699], "basic": [20, 1679, 1690, 1724, 1733], "initi": [20, 1692, 1706, 1733], "tcp": 20, "share": [20, 1688, 1699, 1716, 1726], "file": [20, 1688, 1716], "system": [20, 1679, 1688], "post": [20, 1719], "kei": [20, 1712], "valu": [20, 565, 1678, 1679, 1709, 1721, 1726], "store": [20, 35], "group": 20, "point": [20, 1705], "synchron": [20, 757], "asynchron": [20, 1679, 1699, 1708], "gpu": [20, 1692, 1693, 1695, 1702, 1717], "third": 20, "parti": 20, "launch": [20, 36], "spawn": [20, 1688], "monitor": [20, 1687], "barrier": 20, "torch_distributed_debug": 20, "log": [20, 323, 968, 1705], "join": [21, 1735], "elast": [22, 26, 36], "usag": [22, 36, 1699, 1705, 1706, 1712], "advanc": [22, 1706], "plugin": 22, "probabl": 24, "score": 24, "pathwis": 24, "deriv": [24, 1696], "exponentialfamili": 24, "bernoulli": [24, 108, 646], "binomi": 24, "categor": 24, "cauchi": 24, "chi2": 24, "continuousbernoulli": 24, "dirichlet": 24, "exponenti": 24, "fishersnedecor": 24, "gamma": 24, "geometr": 24, "gumbel": 24, "halfcauchi": 24, "halfnorm": 24, "independ": 24, "kumaraswami": 24, "lkjcholeski": 24, "laplac": 24, "lognorm": 24, "lowrankmultivariatenorm": 24, "mixturesamefamili": 24, "multinomi": [24, 375, 1007], "multivariatenorm": 24, "negativebinomi": 24, "normal": [24, 1249, 1423, 1692, 1715], "onehotcategor": 24, "pareto": 24, "poisson": [24, 1468], "relaxedbernoulli": 24, "logitrelaxedbernoulli": 24, "relaxedonehotcategor": 24, "studentt": 24, "transformeddistribut": 24, "uniform": 24, "vonmis": 24, "weibul": 24, "wishart": 24, "kl": 24, "diverg": [24, 1681], "constraint": [24, 1699], "registri": [24, 35], "dlpack": 25, "agent": 26, "server": [26, 35, 37], "concept": 26, "custom": [27, 37, 42, 1679, 1695, 1701, 1706, 1713, 1715, 1716, 1719], "launcher": 27, "rendezv": [27, 35, 36], "handler": [27, 32, 35, 1702], "metric": [27, 32], "error": [28, 1702, 1712, 1719, 1720], "propag": [28, 1690], "object": [29, 1716], "exampl": [30, 42, 1695, 1700, 1701, 1713, 1725], "torchelast": 31, "kubernet": 31, "multipl": [33, 1695, 1699, 1701, 1717], "worker": [33, 36, 1702], "quickstart": 34, "except": [35, 1702], "dynam": [35, 42, 1719, 1722], "c10d": 35, "etcd": 35, "legaci": 35, "torchrun": 36, "node": [36, 1696], "stack": [36, 1622, 1719], "fault": 36, "toler": 36, "size": [36, 488, 1691], "failur": 36, "min": [36, 366, 999], "max": [36, 362, 994], "4": 36, "up": 36, "membership": [36, 1679], "note": [36, 1675, 1679, 1699, 1719, 1724], "definit": [36, 1679], "deploy": [36, 1705], "import": [36, 1674, 1712, 1716], "notic": [36, 1674], "expir": 37, "timer": 37, "client": 37, "write": [37, 42, 1696, 1701, 1713], "train": [38, 1695, 1706, 1708, 1719], "script": [38, 906, 1676, 1712, 1713], "helper": 39, "fullyshardeddataparallel": 40, "futur": 41, "A": [42, 1706], "quick": 42, "primer": 42, "manipul": [42, 1690], "direct": 42, "subgraph": 42, "rewrit": 42, "With": [42, 1681], "replace_pattern": 42, "proxi": 42, "retrac": 42, "interpret": [42, 1676], "pattern": [42, 1678, 1713, 1716], "introduct": [42, 1691, 1719, 1727], "pitfal": [42, 1713], "pdb": 42, "print": [42, 1678, 1679], "to_fold": 42, "graphmodul": 42, "avail": 42, "debugg": 42, "limit": [42, 1674, 1713], "symbol": [42, 1713, 1719], "trace": [42, 543, 910, 1644, 1676, 1713, 1719], "control": [42, 1710], "flow": [42, 1719], "static": [42, 1713, 1719], "tracer": [42, 1676], "leaf": 42, "miscellanea": 42, "abs_": 45, "absolut": [46, 577], "absolute_": 47, "aco": [48, 578], "acos_": 49, "acosh": [50, 579], "acosh_": 51, "add_": 53, "addbmm": [54, 581], "addbmm_": 55, "addcdiv": [56, 582], "addcdiv_": 57, "addcmul": [58, 583], "addcmul_": 59, "addmm": [60, 584, 1604], "addmm_": 61, "addmv": [62, 585], "addmv_": 63, "addr": [64, 586], "addr_": 65, "adjoint": [66, 587], "all": [67, 588, 1713, 1715], "allclos": [68, 589], "amax": [69, 590], "amin": [70, 591], "aminmax": [71, 592], "ani": [73, 594, 1679], "apply_": 74, "arcco": [75, 596], "arccos_": 76, "arccosh": [77, 597], "arccosh_": 78, "arcsin": [79, 598], "arcsin_": 80, "arcsinh": [81, 599], "arcsinh_": 82, "arctan": [83, 600], "arctan2": [84, 601], "arctan2_": 85, "arctan_": 86, "arctanh": [87, 602], "arctanh_": 88, "argmax": [89, 604], "argmin": [90, 605], "argsort": [91, 606], "argwher": [92, 607], "as_strid": [93, 608], "as_subclass": 94, "asin": [95, 611], "asin_": 96, "asinh": [97, 612], "asinh_": 98, "atan": [99, 613], "atan2": [100, 614], "atan2_": 101, "atan_": 102, "atanh": [103, 615], "atanh_": 104, "backward": [105, 619, 622, 1697, 1699, 1703, 1725], "baddbmm": [106, 644], "baddbmm_": 107, "bernoulli_": 109, "bincount": [111, 647], "bitwise_and": [112, 648], "bitwise_and_": 113, "bitwise_left_shift": [114, 649], "bitwise_left_shift_": 115, "bitwise_not": [116, 650], "bitwise_not_": 117, "bitwise_or": [118, 651], "bitwise_or_": 119, "bitwise_right_shift": [120, 652], "bitwise_right_shift_": 121, "bitwise_xor": [122, 653], "bitwise_xor_": 123, "bmm": [124, 656], "bool": 125, "broadcast_to": [126, 659], "byte": 127, "cauchy_": 128, "ccol_indic": 129, "cdoubl": 130, "ceil": [131, 665], "ceil_": 132, "cfloat": 133, "chalf": 134, "char": 135, "choleski": [136, 667, 924], "cholesky_invers": [137, 668], "cholesky_solv": [138, 669], "chunk": [139, 670], "clamp": [140, 671, 1364], "clamp_": 141, "clip": [142, 672, 1695], "clip_": 143, "clone": [144, 673], "coalesc": 145, "col_indic": 146, "conj": [147, 679], "conj_phys": [148, 680], "conj_physical_": 149, "contigu": 150, "copy_": 151, "copysign": [152, 681], "copysign_": 153, "corrcoef": [154, 682], "co": [155, 683], "cos_": 156, "cosh": [157, 684], "cosh_": 158, "count_nonzero": [159, 685], "cov": [160, 686], "cross": [162, 687, 927, 1696], "crow_indic": 163, "cummax": [165, 759], "cummin": [166, 760], "cumprod": [167, 761], "cumprod_": 168, "cumsum": [169, 762], "cumsum_": 170, "data_ptr": 171, "deg2rad": [172, 764], "dense_dim": 173, "dequant": [174, 765, 1719], "det": [175, 766, 928], "detach": 176, "detach_": 177, "devic": [178, 705, 1699, 1709, 1730], "diag": [179, 767], "diag_emb": [180, 768], "diagflat": [181, 769], "diagon": [182, 770, 929], "diagonal_scatt": [183, 771], "diff": [184, 772], "digamma": [185, 773], "digamma_": 186, "dim": [187, 1689], "dist": [188, 774], "div": [189, 775, 1711], "div_": 190, "divid": [191, 776], "divide_": 192, "dot": [193, 777], "doubl": 194, "dsplit": [195, 778], "eig": [196, 780, 930], "element_s": 197, "eq": [198, 786], "eq_": 199, "equal": [200, 787], "erf": [201, 788], "erf_": 202, "erfc": [203, 789], "erfc_": 204, "erfinv": [205, 790], "erfinv_": 206, "exp": [207, 791], "exp_": 208, "expand": 209, "expand_a": 210, "expm1": [211, 793], "expm1_": 212, "exponential_": 213, "fill_": 214, "fill_diagonal_": 215, "fix_": 217, "flatten": [218, 820, 1062], "flip": [219, 821], "fliplr": [220, 822], "flipud": [221, 823], "float": [222, 1711], "float_pow": [223, 824], "float_power_": 224, "floor": [225, 825], "floor_": 226, "floor_divid": [227, 826], "floor_divide_": 228, "fmax": [229, 827], "fmin": [230, 828], "fmod": [231, 829], "fmod_": 232, "frac": [233, 830], "frac_": 234, "frexp": [235, 831], "gather": [236, 698, 837], "gcd": [237, 838], "gcd_": 238, "ge": [239, 839], "ge_": 240, "geometric_": 241, "geqrf": [242, 840], "ger": [243, 841], "get_devic": 244, "grad": [245, 636, 1696, 1699], "greater": [246, 849], "greater_": 247, "greater_equ": [248, 850], "greater_equal_": 249, "gt": [250, 851], "gt_": 251, "half": 252, "hardshrink": [253, 1072, 1216], "heavisid": [254, 854], "histc": [255, 855], "histogram": [256, 856], "hsplit": [257, 858], "hypot": [258, 861], "hypot_": 259, "i0": [260, 862], "i0_": 261, "igamma": [262, 863], "igamma_": 263, "igammac": [264, 864], "igammac_": 265, "index_add": [267, 866], "index_add_": 268, "index_copi": [269, 867], "index_copy_": 270, "index_fil": 271, "index_fill_": 272, "index_put": 273, "index_put_": 274, "index_reduc": [275, 868], "index_reduce_": 276, "index_select": [277, 869], "indic": [278, 1675], "inner": [279, 872], "int": 280, "int_repr": 281, "invers": [282, 873, 1684], "is_coalesc": 283, "is_complex": [284, 874], "is_conj": [285, 875], "is_contigu": 286, "is_cuda": 287, "is_floating_point": [288, 877], "is_infer": 289, "is_leaf": 290, "is_meta": 291, "is_pin": 292, "is_quant": 293, "is_set_to": 294, "is_shar": 295, "is_sign": 296, "is_spars": 297, "is_sparse_csr": 298, "isclos": [299, 884], "isfinit": [300, 885], "isinf": [301, 887], "isnan": [302, 888], "isneginf": [303, 889], "isposinf": [304, 890], "isreal": [305, 891], "istft": [306, 892], "item": 307, "kthvalu": [308, 916], "lcm": [309, 917], "lcm_": 310, "ldexp": [311, 918], "ldexp_": 312, "le": [313, 919], "le_": 314, "lerp": [315, 920], "lerp_": 316, "less": [317, 921], "less_": 318, "less_equ": [319, 922], "less_equal_": 320, "lgamma": [321, 923], "lgamma_": 322, "log10": [324, 969], "log10_": 325, "log1p": [326, 970], "log1p_": 327, "log2": [328, 971], "log2_": 329, "log_": 330, "log_normal_": 331, "logaddexp": [332, 972], "logaddexp2": [333, 973], "logcumsumexp": [334, 974], "logdet": [335, 975], "logical_and": [336, 976], "logical_and_": 337, "logical_not": [338, 977], "logical_not_": 339, "logical_or": [340, 978], "logical_or_": 341, "logical_xor": [342, 979], "logical_xor_": 343, "logit": [344, 980], "logit_": 345, "logsumexp": [346, 982], "long": 347, "lstsq": [348, 940, 983], "lt": [349, 984], "lt_": 350, "lu": [351, 941, 985], "lu_solv": [352, 944, 986], "map_": 353, "masked_fil": 354, "masked_fill_": 355, "masked_scatt": 356, "masked_scatter_": 357, "masked_select": [358, 989], "matmul": [359, 945, 990], "matrix_exp": [360, 946, 991], "matrix_pow": [361, 948, 992], "maximum": [363, 995], "mean": [364, 996], "median": [365, 997], "minimum": [367, 1000], "mm": [368, 1001, 1606], "moveaxi": [370, 1003], "movedim": [371, 1004], "msort": [372, 1005], "mul": [373, 1006], "mul_": 374, "multipli": [376, 1008], "multiply_": 377, "mv": [378, 1009], "mvlgamma": [379, 1010], "mvlgamma_": 380, "nan_to_num": [381, 1011], "nan_to_num_": 382, "nanmean": [383, 1012], "nanmedian": [384, 1013], "nanquantil": [385, 1014], "nansum": [386, 1015], "narrow": [387, 1016], "narrow_copi": 388, "ndim": 389, "ndimens": 390, "ne": [391, 1017], "ne_": 392, "neg": [393, 395, 1018, 1019], "neg_": 394, "negative_": 396, "nelement": 397, "new_empti": 398, "new_ful": 399, "new_on": 400, "new_tensor": 401, "new_zero": 402, "nextaft": [403, 1020], "nextafter_": 404, "nonzero": [405, 1421], "norm": [406, 951, 1422], "normal_": 407, "not_equ": [408, 1424], "not_equal_": 409, "numel": [410, 1425], "numpi": [411, 1713], "orgqr": [412, 1462], "ormqr": [413, 1463], "outer": [414, 1464], "permut": [415, 1466, 1689], "pin_memori": 416, "pinvers": [417, 1467], "polygamma": [418, 1470], "polygamma_": 419, "posit": [420, 1471], "pow": [421, 1472], "pow_": 422, "prod": [423, 1473], "put_": 424, "q_per_channel_axi": 425, "q_per_channel_scal": 426, "q_per_channel_zero_point": 427, "q_scale": 428, "q_zero_point": 429, "qr": [430, 953, 1475], "qscheme": 431, "quantil": [432, 1476], "rad2deg": [433, 1550], "random_": 434, "ravel": [435, 1559], "reciproc": [437, 1561], "reciprocal_": 438, "record_stream": 439, "register_hook": 440, "remaind": [441, 1562], "remainder_": 442, "renorm": [443, 1563], "renorm_": 444, "repeat": 445, "repeat_interleav": [446, 1564], "requires_grad": [447, 1696], "requires_grad_": 448, "reshap": [449, 1565], "reshape_a": 450, "resize_": 451, "resize_as_": 452, "resolve_conj": [453, 1566], "resolve_neg": [454, 1567], "retain_grad": 455, "retains_grad": 456, "roll": [457, 1569], "rot90": [458, 1570], "round": [459, 1571], "round_": 460, "row_indic": 461, "rsqrt": [462, 1573], "rsqrt_": 463, "scatter": [464, 700, 1575], "scatter_": 465, "scatter_add": [466, 1576], "scatter_add_": 467, "scatter_reduc": [468, 1577], "scatter_reduce_": 469, "select": [470, 1580], "select_scatt": [471, 1581], "set_": 472, "sgn": [473, 1593], "sgn_": 474, "share_memory_": 475, "short": 476, "sigmoid": [477, 1146, 1264, 1352, 1594], "sigmoid_": 478, "sign": [479, 1595], "sign_": 480, "signbit": [481, 1596], "sin": [482, 1597], "sin_": 483, "sinc": [484, 1598], "sinc_": 485, "sinh": [486, 1599], "sinh_": 487, "slice_scatt": [489, 1600], "slogdet": [490, 954, 1601], "smm": [491, 1602], "sort": [492, 1603], "sparse_dim": 493, "sparse_mask": 494, "sparse_resize_": 495, "sparse_resize_and_clear_": 496, "split": [497, 1617], "sqrt": [498, 1618], "sqrt_": 499, "squar": [500, 1619], "square_": 501, "squeez": [502, 1620], "squeeze_": 503, "sspaddmm": [504, 1621], "std": [505, 1623], "stft": [506, 1625], "storag": [507, 1729], "storage_offset": 508, "storage_typ": 509, "stride": 510, "sub": [511, 1626], "sub_": 512, "subtract": [513, 1627], "subtract_": 514, "sum": [515, 1610, 1628, 1692], "sum_to_s": 516, "svd": [517, 958, 1629], "swapax": [518, 1631], "swapdim": [519, 1632], "symeig": [520, 1633], "t": [521, 1634, 1679, 1702], "t_": 522, "take": [523, 1635, 1715], "take_along_dim": [524, 1636], "tan": [525, 1637], "tan_": 526, "tanh": [527, 1156, 1273, 1638], "tanh_": 528, "tensor_split": [529, 1640], "tile": [530, 1642], "to_dens": 532, "to_mkldnn": 533, "to_padded_tensor": 534, "to_spars": 535, "to_sparse_bsc": 536, "to_sparse_bsr": 537, "to_sparse_coo": 538, "to_sparse_csc": 539, "to_sparse_csr": 540, "tolist": 541, "topk": [542, 1643], "transpos": [544, 1645], "transpose_": 545, "triangular_solv": [546, 1648], "tril": [547, 1649], "tril_": 548, "triu": [549, 1651], "triu_": 550, "true_divid": [551, 1653], "true_divide_": 552, "trunc": [553, 1654], "trunc_": 554, "type_a": 556, "unbind": [557, 1655, 1691], "unflatten": [558, 1166, 1656], "unfold": [559, 1167, 1280], "uniform_": 560, "uniqu": [561, 1657], "unique_consecut": [562, 1658], "unsqueez": [563, 1659], "unsqueeze_": 564, "var": [566, 1662], "vdot": [567, 1664], "view": [568, 1711, 1731], "view_a": 569, "vsplit": [570, 1668], "where": [571, 1670, 1674], "xlogi": [572, 1671], "xlogy_": 573, "zero_": 574, "_assert": 575, "arang": 595, "are_deterministic_algorithms_en": 603, "as_tensor": 609, "asarrai": 610, "atleast_1d": 616, "atleast_2d": 617, "atleast_3d": 618, "jvp": [621, 633], "dual_level": 623, "forward_ad": [624, 625], "make_du": 624, "unpack_du": 625, "functionctx": [626, 627, 628, 629], "mark_dirti": 626, "mark_non_differenti": 627, "save_for_backward": 628, "set_materialize_grad": 629, "hessian": 630, "hvp": 631, "jacobian": 632, "vhp": 634, "vjp": 635, "gradcheck": [637, 1703], "gradgradcheck": [638, 1703], "load_nvprof": 639, "export_chrome_trac": 640, "key_averag": 641, "self_cpu_time_tot": 642, "total_averag": 643, "bartlett_window": 645, "blackman_window": 654, "block_diag": 655, "broadcast_shap": 657, "broadcast_tensor": 658, "bucket": 660, "can_cast": 661, "cartesian_prod": 662, "cat": 663, "cdist": 664, "chain_matmul": 666, "column_stack": 674, "combin": 675, "compiled_with_cxx11_abi": 676, "concat": 678, "cudagraph": 688, "externalstream": 690, "streamcontext": 692, "caching_allocator_alloc": 693, "caching_allocator_delet": 694, "can_device_access_p": 695, "comm": [696, 697, 698, 699, 700], "broadcast": [696, 1697], "broadcast_coalesc": 697, "reduce_add": 699, "current_blas_handl": 701, "current_devic": 702, "current_stream": 703, "default_stream": 704, "device_count": 706, "device_of": 707, "empty_cach": 708, "get_arch_list": 709, "get_device_cap": 710, "get_device_nam": 711, "get_device_properti": 712, "get_gencode_flag": 713, "get_rng_stat": [714, 847], "get_rng_state_al": 715, "get_sync_debug_mod": 716, "graph_pool_handl": 718, "init": [719, 1694], "initial_se": [720, 871], "ipc_collect": 721, "is_avail": 722, "is_current_stream_captur": 723, "is_initi": 724, "_create_jit_fn": 725, "_create_multi_output_jit_fn": 726, "list_gpu_process": 727, "make_graphed_cal": 728, "manual_se": [729, 988], "manual_seed_al": 730, "max_memory_alloc": 731, "max_memory_cach": 732, "max_memory_reserv": 733, "mem_get_info": 734, "memory_alloc": 735, "memory_cach": 736, "memory_reserv": 737, "memory_snapshot": 738, "memory_stat": 739, "memory_summari": 740, "memory_usag": 741, "mark": 742, "range_pop": 743, "range_push": 744, "reset_max_memory_alloc": 745, "reset_max_memory_cach": 746, "reset_peak_memory_stat": 747, "seed": [748, 1579], "seed_al": 749, "set_devic": 750, "set_per_process_memory_fract": 751, "set_rng_stat": [752, 1591], "set_rng_state_al": 753, "set_stream": 754, "set_sync_debug_mod": 755, "cumulative_trapezoid": 763, "dstack": 779, "einsum": 781, "empti": 782, "empty_lik": 783, "empty_strid": 784, "enable_grad": 785, "exp2": 792, "ey": 794, "fake_quantize_per_channel_affin": 795, "fake_quantize_per_tensor_affin": 796, "fft2": 798, "fftfreq": 799, "fftn": 800, "fftshift": 801, "hfft": 802, "hfft2": 803, "hfftn": 804, "ifft": 805, "ifft2": 806, "ifftn": 807, "ifftshift": 808, "ihfft": 809, "ihfft2": 810, "ihfftn": 811, "irfft": 812, "irfft2": 813, "irfftn": 814, "rfft": 815, "rfft2": 816, "rfftfreq": 817, "rfftn": 818, "from_dlpack": 832, "from_numpi": 833, "frombuff": 834, "full": [835, 1711], "full_lik": 836, "get_default_dtyp": 842, "get_deterministic_debug_mod": 843, "get_float32_matmul_precis": 844, "get_num_interop_thread": 845, "get_num_thread": 846, "hamming_window": 852, "hann_window": 853, "histogramdd": 857, "hspmm": 859, "hstack": 860, "inference_mod": 870, "is_deterministic_algorithms_warn_only_en": 876, "is_grad_en": 878, "is_inference_mode_en": 879, "is_nonzero": 880, "is_storag": 881, "is_tensor": 882, "is_warn_always_en": 883, "isin": 886, "attribut": [893, 1676, 1678, 1679, 1681, 1730], "scriptfunct": 894, "scriptmodul": [895, 1711], "annot": [896, 1679], "enable_onednn_fus": 897, "fork": 898, "freez": 899, "ignor": 900, "isinst": 901, "onednn_fusion_en": 903, "optimize_for_infer": 904, "script_if_trac": 907, "set_fusion_strategi": 908, "strict_fus": 909, "trace_modul": 911, "unus": 912, "wait": 913, "kaiser_window": 914, "kron": 915, "cholesky_ex": 925, "cond": 926, "eigh": 931, "eigval": 932, "eigvalsh": 933, "householder_product": 934, "inv": 935, "inv_ex": 936, "ldl_factor": 937, "ldl_factor_ex": 938, "ldl_solv": 939, "lu_factor": 942, "lu_factor_ex": 943, "matrix_norm": 947, "matrix_rank": [949, 993], "multi_dot": 950, "pinv": 952, "solv": 955, "solve_ex": 956, "solve_triangular": 957, "svdval": 959, "tensorinv": 960, "tensorsolv": 961, "vander": [962, 1661], "vecdot": 963, "vector_norm": 964, "linspac": 965, "lobpcg": 967, "logspac": 981, "lu_unpack": 987, "meshgrid": 998, "adaptiveavgpool1d": 1021, "adaptiveavgpool2d": 1022, "adaptiveavgpool3d": 1023, "adaptivelogsoftmaxwithloss": 1024, "adaptivemaxpool1d": 1025, "adaptivemaxpool2d": 1026, "adaptivemaxpool3d": 1027, "alphadropout": 1028, "avgpool1d": 1029, "avgpool2d": 1030, "avgpool3d": 1031, "bceloss": 1032, "bcewithlogitsloss": 1033, "batchnorm1d": 1034, "batchnorm2d": [1035, 1329], "batchnorm3d": [1036, 1330], "bilinear": [1037, 1184], "celu": [1038, 1187, 1363], "ctcloss": 1039, "channelshuffl": 1040, "constantpad1d": 1041, "constantpad2d": 1042, "constantpad3d": 1043, "conv1d": [1044, 1188, 1331, 1365], "conv2d": [1045, 1189, 1323, 1332, 1366], "conv3d": [1046, 1190, 1324, 1333, 1367], "convtranspose1d": [1047, 1334], "convtranspose2d": [1048, 1335], "convtranspose3d": [1049, 1336], "cosineembeddingloss": 1050, "cosinesimilar": 1051, "crossentropyloss": 1052, "dataparallel": [1053, 1692, 1693, 1695, 1699], "dropout": [1054, 1198, 1692, 1693], "dropout1d": [1055, 1199], "dropout2d": [1056, 1200], "dropout3d": [1057, 1201], "elu": [1058, 1202, 1337, 1368], "embed": [1059, 1204, 1338], "embeddingbag": [1060, 1339], "featurealphadropout": 1061, "fold": [1063, 1207], "fractionalmaxpool2d": 1064, "fractionalmaxpool3d": 1065, "gelu": [1066, 1211], "glu": [1067, 1212], "gru": [1068, 1353], "grucel": [1069, 1354], "gaussiannllloss": 1070, "groupnorm": [1071, 1342], "hardsigmoid": [1073, 1217, 1369], "hardswish": [1074, 1218, 1343, 1370], "hardtanh": [1075, 1219, 1371], "hingeembeddingloss": 1076, "huberloss": 1077, "ident": [1078, 1393, 1401, 1679, 1702], "instancenorm1d": [1079, 1344], "instancenorm2d": [1080, 1345], "instancenorm3d": [1081, 1346], "kldivloss": 1082, "l1loss": 1083, "lppool1d": 1084, "lppool2d": 1085, "lstm": [1086, 1327, 1355, 1710], "lstmcell": [1087, 1356], "layernorm": [1088, 1347], "lazybatchnorm1d": 1089, "lazybatchnorm2d": 1090, "lazybatchnorm3d": 1091, "lazyconv1d": 1092, "lazyconv2d": 1093, "lazyconv3d": 1094, "lazyconvtranspose1d": 1095, "lazyconvtranspose2d": 1096, "lazyconvtranspose3d": 1097, "lazyinstancenorm1d": 1098, "lazyinstancenorm2d": 1099, "lazyinstancenorm3d": 1100, "lazylinear": 1101, "leakyrelu": [1102, 1348], "localresponsenorm": 1104, "logsigmoid": [1105, 1233], "logsoftmax": 1106, "mseloss": 1107, "marginrankingloss": 1108, "maxpool1d": 1109, "maxpool2d": 1110, "maxpool3d": 1111, "maxunpool1d": 1112, "maxunpool2d": 1113, "maxunpool3d": 1114, "mish": [1115, 1243], "moduledict": [1117, 1679], "modulelist": [1118, 1678, 1679], "multilabelmarginloss": 1119, "multilabelsoftmarginloss": 1120, "multimarginloss": 1121, "multiheadattent": [1122, 1328], "nllloss": 1123, "prelu": [1124, 1257], "pairwisedist": 1125, "parameterdict": 1126, "parameterlist": 1127, "pixelshuffl": 1128, "pixelunshuffl": 1129, "poissonnllloss": 1130, "rnn": [1131, 1411, 1412, 1413, 1414, 1710], "rnnbase": 1132, "rnncell": [1133, 1358], "rrelu": [1134, 1261], "relu": [1135, 1258], "relu6": [1136, 1259, 1351], "reflectionpad1d": 1137, "reflectionpad2d": 1138, "reflectionpad3d": 1139, "replicationpad1d": 1140, "replicationpad2d": 1141, "replicationpad3d": 1142, "selu": [1143, 1263], "sequenti": 1144, "silu": [1145, 1265], "smoothl1loss": 1147, "softmarginloss": 1148, "softmax": [1149, 1268, 1608], "softmax2d": 1150, "softmin": [1151, 1269], "softplu": [1152, 1270], "softshrink": [1153, 1271], "softsign": [1154, 1272], "syncbatchnorm": 1155, "tanhshrink": [1157, 1274], "threshold": [1158, 1275, 1377], "transformerdecod": 1160, "transformerdecoderlay": 1161, "transformerencod": 1162, "transformerencoderlay": 1163, "tripletmarginloss": 1164, "tripletmarginwithdistanceloss": 1165, "upsampl": [1168, 1281, 1378], "upsamplingbilinear2d": 1169, "upsamplingnearest2d": 1170, "zeropad2d": 1171, "adaptive_avg_pool1d": 1172, "adaptive_avg_pool2d": [1173, 1359], "adaptive_avg_pool3d": [1174, 1360], "adaptive_max_pool1d": 1175, "adaptive_max_pool2d": 1176, "adaptive_max_pool3d": 1177, "affine_grid": 1178, "alpha_dropout": 1179, "avg_pool1d": 1180, "avg_pool2d": [1181, 1361], "avg_pool3d": [1182, 1362], "batch_norm": 1183, "conv_transpose1d": 1191, "conv_transpose2d": 1192, "conv_transpose3d": 1193, "cosine_embedding_loss": 1194, "cosine_similar": 1195, "cross_entropi": 1196, "ctc_loss": 1197, "elu_": 1203, "embedding_bag": 1205, "feature_alpha_dropout": 1206, "fractional_max_pool2d": 1208, "fractional_max_pool3d": 1209, "gaussian_nll_loss": 1210, "grid_sampl": 1213, "group_norm": 1214, "gumbel_softmax": 1215, "hardtanh_": 1220, "hinge_embedding_loss": 1221, "huber_loss": 1222, "instance_norm": 1223, "interpol": [1224, 1372], "kl_div": 1225, "l1_loss": 1226, "layer_norm": 1227, "leaky_relu": [1228, 1373], "leaky_relu_": 1229, "local_response_norm": 1231, "log_softmax": [1232, 1605], "lp_pool1d": 1234, "lp_pool2d": 1235, "margin_ranking_loss": 1236, "max_pool1d": [1237, 1375], "max_pool2d": [1238, 1376], "max_pool3d": 1239, "max_unpool1d": 1240, "max_unpool2d": 1241, "max_unpool3d": 1242, "mse_loss": 1244, "multi_margin_loss": 1245, "multilabel_margin_loss": 1246, "multilabel_soft_margin_loss": 1247, "nll_loss": 1248, "one_hot": 1250, "pad": [1251, 1692], "pairwise_dist": 1252, "pdist": 1253, "pixel_shuffl": 1254, "pixel_unshuffl": 1255, "poisson_nll_loss": 1256, "relu_": 1260, "rrelu_": 1262, "smooth_l1_loss": 1266, "soft_margin_loss": 1267, "threshold_": 1276, "parallel": [1277, 1699, 1700, 1702, 1717, 1735], "data_parallel": [1277, 1693], "triplet_margin_loss": 1278, "triplet_margin_with_distance_loss": 1279, "upsample_bilinear": [1282, 1379], "upsample_nearest": [1283, 1380], "bnrelu2d": [1284, 1307], "bnrelu3d": [1285, 1308], "convbn1d": [1286, 1296], "convbn2d": [1287, 1297], "convbn3d": [1288, 1298], "convbnrelu1d": [1289, 1299], "convbnrelu2d": [1290, 1300], "convbnrelu3d": [1291, 1301], "convrelu1d": [1292, 1309], "convrelu2d": [1293, 1302, 1310], "convrelu3d": [1294, 1303, 1311], "linearrelu": [1295, 1304, 1312, 1313], "freeze_bn_stat": 1305, "update_bn_stat": 1306, "lazymodulemixin": 1314, "register_module_backward_hook": 1315, "register_module_forward_hook": 1316, "register_module_forward_pre_hook": 1317, "register_module_full_backward_hook": 1318, "distributeddataparallel": [1319, 1695, 1699, 1700], "paramet": [1320, 1678, 1715], "uninitializedbuff": 1321, "uninitializedparamet": 1322, "fxfloatfunct": 1340, "floatfunct": 1341, "qfunction": 1350, "clip_grad_norm_": 1381, "clip_grad_value_": 1382, "parameters_to_vector": 1383, "parametr": [1384, 1385, 1387, 1388, 1389, 1390, 1706], "orthogon": 1384, "spectral_norm": [1385, 1416], "parametrizationlist": 1386, "cach": [1387, 1674, 1699, 1704], "is_parametr": 1388, "register_parametr": 1389, "remove_parametr": 1390, "basepruningmethod": 1391, "customfrommask": 1392, "l1unstructur": 1394, "lnstructur": 1395, "pruningcontain": 1396, "randomstructur": 1397, "randomunstructur": 1398, "prune": [1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1706], "custom_from_mask": 1399, "global_unstructur": 1400, "is_prun": 1402, "l1_unstructur": 1403, "ln_structur": 1404, "random_structur": 1405, "random_unstructur": 1406, "remove_spectral_norm": 1408, "remove_weight_norm": 1409, "packedsequ": 1410, "pack_padded_sequ": 1411, "pack_sequ": 1412, "pad_packed_sequ": 1413, "pad_sequ": 1414, "skip_init": 1415, "stateless": 1417, "functional_cal": 1417, "vector_to_paramet": 1418, "weight_norm": 1419, "no_grad": 1420, "ones": 1426, "ones_lik": 1427, "jitscalartyp": 1428, "symboliccontext": 1429, "asgd": 1430, "adadelta": 1431, "adagrad": 1432, "adam": 1433, "adamw": 1434, "adamax": 1435, "lbfg": 1436, "nadam": 1437, "add_param_group": 1438, "load_state_dict": 1439, "state_dict": 1440, "step": [1441, 1715], "zero_grad": 1442, "radam": 1443, "rmsprop": 1444, "rprop": 1445, "sgd": 1446, "sparseadam": 1447, "chainedschedul": 1448, "constantlr": 1449, "cosineannealinglr": 1450, "cosineannealingwarmrestart": 1451, "cycliclr": 1452, "exponentiallr": 1453, "lambdalr": 1454, "linearlr": 1455, "multisteplr": 1456, "multiplicativelr": 1457, "onecyclelr": 1458, "reducelronplateau": 1459, "sequentiallr": 1460, "steplr": 1461, "pca_lowrank": 1465, "polar": 1469, "promote_typ": 1474, "dequantstub": 1477, "quantstub": 1478, "quantwrapp": 1479, "add_observ": 1480, "add_quant_dequ": 1481, "convert": 1482, "default_eval_fn": 1483, "fakequant": [1484, 1719], "fakequantizebas": 1485, "fixedqparamsfakequant": 1486, "fusedmovingavgobsfakequant": 1487, "default_fake_qu": 1488, "default_fused_act_fake_qu": 1489, "default_fused_per_channel_wt_fake_qu": 1490, "default_fused_wt_fake_qu": 1491, "default_histogram_fake_qu": 1492, "default_per_channel_weight_fake_qu": 1493, "default_weight_fake_qu": 1494, "disable_fake_qu": 1495, "disable_observ": 1496, "enable_fake_qu": 1497, "enable_observ": 1498, "fuse_modul": 1499, "get_observer_dict": 1500, "histogramobserv": 1501, "minmaxobserv": 1502, "movingaverageminmaxobserv": 1503, "movingaverageperchannelminmaxobserv": 1504, "noopobserv": 1505, "observerbas": 1506, "perchannelminmaxobserv": 1507, "placeholderobserv": 1508, "recordingobserv": 1509, "default_debug_observ": 1510, "default_dynamic_quant_observ": 1511, "default_float_qparams_observ": 1512, "default_histogram_observ": 1513, "default_observ": 1514, "default_per_channel_weight_observ": 1515, "default_placeholder_observ": 1516, "default_weight_observ": 1517, "get_observer_state_dict": 1518, "load_observer_state_dict": 1519, "prepar": [1520, 1719, 1722], "prepare_qat": 1521, "propagate_qconfig": 1522, "qconfig": [1523, 1719, 1722], "default_activation_only_qconfig": 1524, "default_debug_qconfig": 1525, "default_dynamic_qconfig": 1526, "default_per_channel_qconfig": 1527, "default_qat_qconfig": 1528, "default_qat_qconfig_v2": 1529, "default_qconfig": 1530, "default_weight_only_qconfig": 1531, "float16_dynamic_qconfig": 1532, "float16_static_qconfig": 1533, "float_qparams_weight_only_qconfig": 1534, "per_channel_dynamic_qconfig": 1535, "quantiz": [1536, 1692, 1706, 1719, 1720, 1721, 1722], "quantize_dynam": 1537, "convert_fx": 1538, "fuse_fx": 1539, "prepare_fx": 1540, "prepare_qat_fx": 1541, "quantize_qat": 1542, "swap_modul": 1543, "quantize_per_channel": 1544, "quantize_per_tensor": 1545, "quantized_batch_norm": 1546, "quantized_max_pool1d": 1547, "quantized_max_pool2d": 1548, "sobolengin": 1549, "rand": 1551, "rand_lik": 1552, "randint": 1553, "randint_lik": 1554, "randn": 1555, "randn_lik": 1556, "randperm": 1557, "rang": [1558, 1678], "result_typ": 1568, "row_stack": 1572, "searchsort": 1578, "set_default_dtyp": 1582, "set_default_tensor_typ": 1583, "set_deterministic_debug_mod": 1584, "set_float32_matmul_precis": 1585, "set_flush_denorm": 1586, "set_grad_en": 1587, "set_num_interop_thread": 1588, "set_num_thread": 1589, "set_printopt": 1590, "set_warn_alwai": 1592, "spars": [1604, 1605, 1606, 1607, 1608, 1609, 1610, 1692, 1693, 1727], "sampled_addmm": 1607, "spdiag": 1609, "sparse_bsc_tensor": 1611, "sparse_bsr_tensor": 1612, "sparse_compressed_tensor": 1613, "sparse_coo_tensor": 1614, "sparse_csc_tensor": 1615, "sparse_csr_tensor": 1616, "std_mean": 1624, "svd_lowrank": 1630, "tensordot": 1641, "trapezoid": 1646, "trapz": 1647, "tril_indic": 1650, "triu_indic": 1652, "use_deterministic_algorithm": 1660, "var_mean": 1663, "view_as_complex": 1665, "view_as_r": 1666, "vmap": 1667, "vstack": 1669, "zero": 1672, "zeros_lik": 1673, "hub": 1674, "publish": 1674, "an": [1674, 1713, 1715, 1716], "entrypoint": 1674, "ar": [1674, 1696, 1716], "my": [1674, 1696, 1702, 1716], "download": 1674, "logic": [1674, 1678], "known": [1674, 1676], "bind": 1675, "tabl": [1675, 1711], "built": [1676, 1677, 1679, 1713], "comparison": [1676, 1678, 1679, 1735], "inspect": 1676, "warn": 1676, "appendix": [1676, 1679], "migrat": 1676, "recurs": 1676, "constant": [1676, 1678], "fusion": 1676, "builtin": 1677, "support": [1677, 1679, 1689, 1690, 1713, 1714, 1719, 1727], "math": [1677, 1735], "unsupport": [1678, 1679, 1681, 1713], "construct": [1678, 1679, 1681, 1715, 1727], "option": [1678, 1698, 1712, 1715], "refin": [1678, 1679], "enum": [1678, 1679], "name": [1678, 1689, 1690], "tupl": [1678, 1679], "express": [1678, 1679], "liter": [1678, 1679], "list": [1678, 1679, 1713], "dict": 1678, "arithmet": [1678, 1679], "subscript": [1678, 1679], "slice": [1678, 1679, 1709, 1735], "call": [1678, 1679], "ternari": [1678, 1679], "cast": 1678, "statement": [1678, 1679], "assign": [1678, 1679], "match": [1678, 1690], "If": 1678, "while": [1678, 1679], "loop": 1678, "For": 1678, "break": [1678, 1679], "continu": [1678, 1679], "return": [1678, 1679, 1702, 1726], "resolut": [1678, 1679], "lookup": 1678, "defin": [1678, 1701], "terminolog": 1679, "meta": 1679, "primit": 1679, "structur": 1679, "special": [1679, 1728], "instanc": 1679, "when": [1679, 1701, 1713, 1719], "signatur": 1679, "expr": 1679, "convers": 1679, "atom": 1679, "identifi": 1679, "parenthes": 1679, "form": 1679, "dictionari": 1679, "displai": 1679, "primari": 1679, "power": 1679, "unari": 1679, "bitwis": 1679, "binari": 1679, "shift": 1679, "boolean": 1679, "condit": 1679, "augment": 1679, "rais": 1679, "assert": 1679, "del": 1679, "pass": [1679, 1699, 1708, 1719, 1725], "compound": 1679, "els": 1679, "getattr": 1679, "hasattr": 1679, "zip": [1679, 1716], "enumer": 1679, "rule": [1679, 1690], "remot": [1679, 1726], "procedur": 1679, "program": 1679, "coverag": [1680, 1689, 1701], "properti": [1681, 1684], "Not": 1681, "correctli": 1681, "bound": 1681, "schema": 1681, "between": [1681, 1716], "matrix": [1684, 1719], "decomposit": 1684, "solver": 1684, "product": 1684, "misc": 1684, "experiment": 1684, "mobile_optim": 1685, "model_zoo": 1686, "strategi": [1688, 1715], "descriptor": 1688, "file_descriptor": 1688, "file_system": 1688, "subprocess": 1688, "keep": [1689, 1716], "dimens": [1689, 1690], "unifi": 1689, "contract": 1689, "awai": 1689, "factori": 1689, "out": [1689, 1702], "variant": 1689, "semant": [1690, 1697, 1699, 1704, 1711], "infer": [1690, 1696, 1698, 1711], "explicit": 1690, "align": 1690, "current": 1690, "subsystem": 1690, "nest": 1691, "contain": 1692, "convolut": [1692, 1693, 1709, 1710], "layer": 1692, "pool": [1692, 1693], "activ": [1692, 1693], "weight": [1692, 1715], "nonlinear": 1692, "recurr": [1692, 1702], "distanc": [1692, 1693], "loss": [1692, 1693, 1695], "vision": [1692, 1693], "shuffl": 1692, "lazi": 1692, "typic": 1695, "unscal": 1695, "accumul": 1695, "penalti": 1695, "one": 1695, "per": [1695, 1715], "need": 1695, "particular": 1695, "dtype": [1695, 1711, 1722, 1730], "encod": 1696, "histori": 1696, "set": [1696, 1713], "No": 1696, "evalu": [1696, 1703], "eval": 1696, "multithread": 1696, "concurr": 1696, "determin": [1696, 1710], "retain": 1696, "thread": [1696, 1698], "safeti": 1696, "wirting": 1696, "calculu": 1696, "pictur": 1696, "conjug": 1696, "i": [1696, 1716], "own": 1696, "formula": 1696, "domain": 1696, "regist": 1696, "compat": 1697, "runtim": [1698, 1702], "tune": 1698, "tensorfloat": [1699, 1704, 1709], "32": [1699, 1704, 1709, 1712], "tf32": [1699, 1704, 1709], "amper": [1699, 1709], "reduc": [1699, 1709], "reduct": [1699, 1709, 1735], "fp16": [1699, 1709], "gemm": [1699, 1709], "bc": 1699, "cufft": 1699, "plan": [1699, 1704], "just": 1699, "time": 1699, "compil": 1699, "practic": [1699, 1708, 1719], "agnost": 1699, "buffer": [1699, 1708], "instead": 1699, "why": [1699, 1703, 1716], "whole": 1699, "captur": 1699, "partial": 1699, "9": 1699, "6": 1699, "across": [1699, 1711], "intern": [1700, 1716], "processgroup": 1700, "like": [1701, 1716], "subclass": 1701, "wrapper": 1701, "__torch_function__": 1701, "overrid": [1701, 1738], "isn": 1702, "freed": 1702, "properli": 1702, "alloc": 1702, "loader": 1702, "doesn": 1702, "notat": 1703, "background": [1703, 1725, 1726], "inform": [1703, 1724], "analyt": 1703, "output": 1703, "u": 1703, "reus": [1704, 1708], "hipfft": 1704, "rocfft": 1704, "larg": 1705, "fleet": 1705, "wide": 1705, "attach": 1705, "metadata": 1705, "consider": 1705, "block": 1706, "neural": 1706, "tip": [1708, 1720], "fight": 1708, "deadlock": 1708, "through": 1708, "queue": 1708, "e": 1708, "g": 1708, "hogwild": 1708, "accuraci": [1709, 1719, 1720], "extrem": 1709, "bf16": 1709, "instinct": 1709, "mi200": 1709, "reproduc": 1710, "nondeterminist": 1710, "algorithm": [1710, 1715, 1725], "content": [1711, 1716], "preserv": 1711, "them": [1711, 1716], "version": 1711, "integ": 1711, "divis": 1711, "alwai": 1711, "includ": [1712, 1716], "compon": 1712, "speed": 1712, "One": 1712, "cffi": 1712, "cpp": 1712, "found": 1712, "win": 1712, "channel": 1712, "without": 1712, "claus": 1712, "protect": 1712, "broken": 1712, "pipe": [1712, 1717], "driver": 1712, "shut": 1712, "down": 1712, "ipc": 1712, "alexnet": 1713, "vs": 1713, "shape": 1713, "differ": 1713, "index": [1713, 1735], "read": 1713, "aten": [1713, 1714], "pythonop": 1713, "inlin": 1713, "discov": 1713, "unconvert": 1713, "onc": 1713, "closur": 1715, "base": 1715, "adjust": 1715, "learn": 1715, "rate": 1715, "stochast": 1715, "averag": 1715, "swa": 1715, "schedul": 1715, "care": 1715, "put": 1715, "togeth": 1715, "your": 1716, "do": 1716, "see": 1716, "insid": 1716, "treat": 1716, "archiv": 1716, "file_structur": 1716, "given": 1716, "wa": 1716, "depend": [1716, 1725], "arbitrari": 1716, "resourc": 1716, "later": 1716, "whether": 1716, "patch": 1716, "distinguish": 1716, "export": 1716, "explan": 1716, "format": 1716, "framework": [1716, 1724], "user": [1716, 1726], "find": 1716, "s": 1716, "analyz": 1716, "extern": 1716, "mock": 1716, "refactor": 1716, "sharp": 1716, "global": 1716, "isol": 1716, "each": 1716, "mangl": 1716, "pipelin": 1717, "skip": 1717, "connect": 1717, "eager": 1719, "awar": 1719, "prototyp": [1719, 1720], "engin": 1719, "observ": [1719, 1722], "hardwar": 1719, "nativ": [1719, 1721], "configur": [1719, 1721], "kernel": 1719, "insensit": 1720, "int8": 1720, "sensit": 1720, "top": 1722, "quantize_fx": 1722, "relat": 1722, "fake_quant": 1722, "intrins": 1722, "qat": 1722, "scheme": 1722, "rpc": 1724, "tensorpip": 1724, "rref": [1724, 1726], "remotemodul": 1724, "record": 1725, "dure": 1725, "smart": 1725, "end": 1725, "protocol": 1726, "assumpt": 1726, "lifetim": 1726, "reason": 1726, "scenario": 1726, "owner": 1726, "argument": 1726, "coo": 1727, "hybrid": 1727, "uncoalesc": 1727, "csr": 1727, "csc": 1727, "bsr": 1727, "bsc": 1727, "memory_format": 1730, "tensorboard": 1732, "creation": 1735, "mutat": 1735, "sampl": 1735, "quasi": 1735, "pointwis": 1735, "spectral": 1735, "bla": 1735, "lapack": 1735, "tag": 1735, "ao": [1736, 1737], "ns": [1736, 1737], "_numeric_suit": 1736, "_numeric_suite_fx": 1737, "info": 1739, "finfo": 1739, "iinfo": 1739}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})